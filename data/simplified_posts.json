[
  {
    "user_id": 1215,
    "conversation": "[md1639 (2024-07-18T05:06:53.683Z)]: Description\n\nI’m trying to batch import data into a collection like so:\nwith filings_collection.batch.dynamic() as batch:\n    for fc in tqdm(filngs_chunked):\n        batch.add_object(\n            properties=fc,\n        )\n\nI’m having trouble catching errors. I find that there is a number_errors attribute, however this doesn’t tell me which object exactly has failed, or what the error is\nServer Setup Information\n\nWeaviate Server Version:  1.25.5\nDeployment Method: embed\nMulti Node? Number of Running Nodes: No, 1 node\nClient Language and Version: Python 3.12.4, weaviate version 4.6.5\nMultitenancy?: No\n\nAny additional Information\n\n----------\n\n[Mohamed_Shahin (2024-07-18T07:48:19.231Z)]: Hello @md1639,\nWelcome to our community! it’s great to have you here \nYou can consider capture more information about errors and failed objects by implementing error handling and logging during the batch process by using client.batch.failed_objects & client.batch.failed_references.\nError Handling → \n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYou will find a good example in the documentation:\n\nfailed_objs_b = client.batch.failed_objects  # Get failed objects\nfailed_refs_b = client.batch.failed_references  # Get failed references\n\nAdditionally, Weaviate Pythin Client, the following exception handling can help raises various error conditions:\n\nweaviate.exceptions.WeaviateConnectionError for failed connections.\nweaviate.exceptions.WeaviateQueryError for failed queries.\nweaviate.exceptions.WeaviateBatchError for failed batch operations.\nweaviate.exceptions.WeaviateClosedClientError for operations on a closed client.\n\nYou can review this module which defines the exceptions that can be raised by the client library.\nException handling → \n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate - Vector Database\n\n  Overview",
    "date_created": "2024-07-18T05:06:53.619Z",
    "has_accepted_answer": false,
    "title": "How to catch errors with dynamic batch import",
    "topic_id": 3081
  },
  {
    "user_id": 3263,
    "conversation": "[Abhishek_Yadav (2025-01-24T11:43:44.793Z)]: I am reaching out to request assistance with retrieving all the embeddings associated with my collection named “productdata” in my Weaviate cluster. Below are the relevant details:\n\nCollection Name: productdata\nCloud Region: US East\nCreated At: 9/30/2024, 5:56 PM\n\nCould you please guide me on how to retrieve all embeddings or assist with the process? Let me know if you require any further details to facilitate this request.\n\n----------\n\n[Mohamed_Shahin (2025-01-24T11:46:11.668Z)]: Good morning @Abhishek_Yadav,\nWelcome to our community and glad to see you here as well.\nAbsolutely, you can easily read all your properties and data, including vector embeddings, from your collections by following this guide:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nRead all objects | Weaviate\n\n  Weaviate provides the necessary APIs to iterate through all your data. This is useful when you want to manually copy/migrate your data (and vector embeddings) from one place to another.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHere’s a code snippet I wrote for you to make things easier. You can use it right away—just pass the client to the function:\nimport pandas as pd\n\ndef get_all_collections_data(client):\n    all_data = []\n    collections = client.collections.list_all()\n    \n    for col_name in collections:\n        try:\n            collection = client.collections.get(col_name)\n            collection_data = []\n            \n            for item in collection.iterator(include_vector=True):\n                row = item.properties.copy()\n                row['vector'] = item.vector\n                collection_data.append(row)\n            \n            if collection_data:\n                df = pd.DataFrame(collection_data)\n                df['collection'] = col_name\n                all_data.append(df)\n                print(f\"Successfully processed: {col_name}\")\n                \n        except Exception as e:\n            print(f\"Error in {col_name}: {str(e)}\")\n            continue\n    \n    return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n\nget_all_collections_data(client)\n\nI hope this helps, also I have followed up on your Support Ticket in our cloud as you are cloud customer so you can always use our support ticketing system.\nHave a lovely weekend!\nRegards,\nMohamed Shahin\nWeaviate Support",
    "date_created": "2025-01-24T11:43:44.731Z",
    "has_accepted_answer": true,
    "title": "Retrieve all Embeddings for Collection \"Productdata\"",
    "topic_id": 9887
  },
  {
    "user_id": 3276,
    "conversation": "[Habetuz (2025-01-27T18:42:53.867Z)]: Description\nI am using Weaviate together with Langchain as a vectorstore. When embedding new documents I have to check wether the documents are already added to Weaviate to avoid embedding the same document multiple times.\nFor this I am using the client.collections.get(\"MyCollection\").data.exists(\"ID\") function for EVERY document. This is a bottleneck for me, because I have to send a HEAD request for each individual document.\nThere are already functions for inserting and deleting many, a exists_many function that takes a list of IDs and returns a list of booleans while sending the HEAD requests in batches would be awesome. Or am I missing another simpler way of checking many IDs to avoid embedding documents that are already added?\n\n----------\n\n[DudaNogueira (2025-01-27T19:43:24.982Z)]: hi @Habetuz !!\nWelcome to our community \nYou can do an “upsert” if you perform a batch with a deterministic id, on cases you can tie that object with a unique id:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCreate objects | Weaviate\n\n  The examples on this page demonstrate how to create individual objects in Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNow when you import objects using batch and providing the id, it will update the object o create it:\nfrom weaviate.util import generate_uuid5  # Generate a deterministic ID\n\ndata_rows = [{\"title\": f\"Object {i+1}\"} for i in range(5)]\n\ncollection = client.collections.get(\"MyCollection\")\n\nwith collection.batch.dynamic() as batch:\n    for data_row in data_rows:\n        obj_uuid = generate_uuid5(data_row)\n        batch.add_object(\n            properties=data_row,\n            uuid=obj_uuid\n        )\n\nIf, despite the mentioned approach, you want to select multiple IDs at once, you can use containsany against the id property, like so:\nresponse = collection.query.fetch_objects(\n    filters=Filter.by_id().contains_any(ids),\n    limit=10\n)\n\nLet me know if that helps!",
    "date_created": "2025-01-27T18:42:53.811Z",
    "has_accepted_answer": false,
    "title": "Checking existence of many IDs",
    "topic_id": 9911
  },
  {
    "user_id": 427,
    "conversation": "[Sandip (2024-11-08T07:02:03.772Z)]: I’m trying to index and search articles in Weaviate, but I’m encountering an error when querying with near_vector. Here’s my process:\n\nIndexing: I successfully index articles in the “Test” class, with each article having an article_id, title, and body. The vectors are correctly linked based on article_id.\n\n{\n  \"class_name\": \"test\",\n  \"data\": [\n    { \"article_id\": \"0\", \"title\": \"title0\", \"body\": \"body0\" },\n    { \"article_id\": \"1\", \"title\": \"title1\", \"body\": \"body1\" },\n    ...\n  ],\n  \"vectors\": {\n    \"0\": [3.7, 1.4, 4.9, 2.1, 5.6, 7.2, 8.3, 6.5],\n    ...\n  }\n}\n\n\nSearch: When I query with near_vector to retrieve title and distance, I get the following error:\n\n   raise ValueError(f\"An error occurred while performing weaviate search : {e}\")\nValueError: An error occurred while performing weaviate search : Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"no such prop with name 'title' found in class 'Test' in the schema. Check your schema files for which properties in this class are available\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-11-08T12:25:18.79653+05:30\", grpc_status:2, grpc_message:\"no such prop with name \\'title\\' found in class \\'Test\\' in the schema. Check your schema files for which properties in this class are available\"}\"\n\n\nThe indexing appears successful, and I see no issues in the schema setup. Why is this property not accessible in the search query?\n\nCode:\nresponse = weaviate_client.collections.get(weaviate_class_name).query.near_vector(\n    near_vector=embedding,\n    limit=20,\n    return_metadata=MetadataQuery(distance=True),\n    return_properties=['title']\n)\n\nAny suggestions? Thank you!\n\n----------\n\n[DudaNogueira (2024-11-08T11:23:45.000Z)]: hi!!\nCan you share a reproducible code?\nIf possible, with the same code you are using to create the collection, some code similar to what you use to index.\nAlso, please, always provide the requested information, such as server version, client version, etc.\nThanks!\n\n----------\n\n[Sandip (2024-11-10T06:05:49.173Z)]: def batch_upload(\n        client: weaviate.WeaviateClient,\n        weaviate_class: str,\n        content: List[Dict],\n        vectors: Dict,\n        batch_size: int,\n        id_field: str\n):\n    indexed_article = 0\n\n    collection = client.collections.get(weaviate_class)\n\n    with collection.batch.dynamic() as batch:\n        batch.batch_size = batch_size\n        for article in content:\n            batch.add_object(\n                references=article,\n                vector=vectors[f\"{article[id_field]}\"]\n            )\n            indexed_article += 1\n\n    return indexed_article\n\n\n\ndef create_index(index_name: str, weaviate_client: weaviate.WeaviateClient):\n    try:\n        weaviate_client.collections.create(name=index_name)\n    except Exception as e:\n        raise ValueError(f\"An error occurred when creating a weaviate class : {e}\")\n\n\n\ndef check_index_exist(index_name: str, client: weaviate.WeaviateClient) -> bool:\n    return client.collections.exists(name=index_name)\n\n\n\ndef index_data_weaviate(\n        weaviate_client: weaviate.WeaviateClient,\n        index_name: str,\n        content: List[Dict[str, Any]],\n        vectors: Dict[str, list[float]],\n        id_field: str = 'article_id'\n) -> int:\n    batch_size = 50\n    if check_index_exist(index_name, weaviate_client):\n        delete_index(index_name, weaviate_client)\n\n    create_index(index_name, weaviate_client)\n\n    indexed_articles = batch_upload(\n        weaviate_client,\n        index_name,\n        content,\n        vectors,\n        batch_size,\n        id_field\n    )\n    print(f\"Total documents indexed : {indexed_articles}\")\n    return indexed_articles\n\nI use above code to index the data.\nI use index_data_weaviate function for indexing the data.\nAlso I use following data for indexing:\n{\n  \"class_name\": \"test\",\n  \"data\": [\n    {\n      \"article_id\": \"0\",\n      \"title\": \"title0\",\n      \"body\": \"body0\"\n    },\n    {\n      \"article_id\": \"1\",\n      \"title\": \"title1\",\n      \"body\": \"body1\"\n    }\n  ],\n  \"vectors\": {\n    \"0\": [3.7, 1.4, 4.9, 2.1, 5.6, 7.2, 8.3, 6.5],\n    \"1\": [8.1, 3.6, 7.0, 0.9, 6.8, 1.3, 4.4, 5.2]\n  }\n}\n\nWeaviate image version I use is : weaviate:1.25.11,\nAnd weaviate client version is : weaviate-client-4.9.3\n\n----------\n\n[Sandip (2024-11-10T07:15:54.401Z)]: Issue is all resolved. I was doing it all incorrectly.\n\nI changed the index creation code. Earlier property data types was not mentioned in my code.\n\ndef create_index(index_name: str, weaviate_client: weaviate.WeaviateClient):\n    try:\n        weaviate_client.collections.create(\n            name=index_name,\n            vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n            properties=[\n                wvc.config.Property(name='article_id', data_type=wvc.config.DataType.TEXT),\n                wvc.config.Property(name='title', data_type=wvc.config.DataType.TEXT),\n                wvc.config.Property(name='body', data_type=wvc.config.DataType.TEXT)\n            ]\n        )\n    except Exception as e:\n        raise ValueError(f\"An error occurred when creating a weaviate class : {e}\")\n\n\nIn the batch upload part I was giving reference to as article, which was incorrect. And In the properties part I am actually passing dictionary with property name and value. Following is the working code:\n\ndef batch_upload(\n        client: weaviate.WeaviateClient,\n        weaviate_class: str,\n        content: List[Dict],\n        vectors: Dict,\n        batch_size: int,\n        id_field: str\n):\n    indexed_article = 0\n\n    collection = client.collections.get(weaviate_class)\n\n    with collection.batch.dynamic() as batch:\n        batch.batch_size = batch_size\n        for article in content:\n            batch.add_object(\n                vector=vectors[f\"{article[id_field]}\"],\n                properties={\n                    \"article_id\": article[\"article_id\"],\n                    \"title\": article[\"title\"],\n                    \"body\": article[\"body\"]\n                }\n            )\n            indexed_article += 1\n\n    return indexed_article\n\n\nAnd finally the vector search code:\n\ndef weaviate_vector_search(\n        weaviate_client: weaviate.WeaviateClient,\n        weaviate_class_name: str,\n        k,\n        embedding,\n):\n    try:\n        response = weaviate_client.collections.get(weaviate_class_name).query.near_vector(\n            near_vector=embedding,\n            limit=20,\n            return_metadata=MetadataQuery(distance=True),\n            return_properties=['article_id']\n        )\n    except Exception as e:\n        raise ValueError(f\"An error occurred while performing weaviate search : {e}\")\n\n    for o in response.objects:\n        print(o.properties)\n        print(o.metadata.distance)\n\nThanks @ DudaNogueira for your quick attention. We can mark this as resolved.\n\n----------\n\n[DudaNogueira (2024-11-10T11:13:19.003Z)]: Hi @Sandip !!\nThanks for sharing!\nIf you have an article id for each object, you may as well use deterministic ids.\nSomething like:\nfrom weaviate.util import generate_uuid5\n            ...\n            batch.add_object(\n                uuid=generate_uuid5(article[\"article_id\"]),\n                vector=vectors[f\"{article[id_field]}\"],\n                properties={\n                    \"article_id\": article[\"article_id\"],\n                    \"title\": article[\"title\"],\n                    \"body\": article[\"body\"]\n                }\n            )\n            ...\n\nNow your batch_upload can be used to both create and update an object \nHappy building!",
    "date_created": "2024-11-08T07:02:03.706Z",
    "has_accepted_answer": true,
    "title": "No such prop with name 'title' found in class 'Test' in the schema\" when querying Weaviate with near_vector",
    "topic_id": 7498
  },
  {
    "user_id": 2410,
    "conversation": "[bam (2024-12-03T02:12:56.828Z)]: I’ve found that sometimes Weaviate tells me a file already exists in the db, even tho’ the file (completely different file) I’m importing is being added for he first time and has a different name.\nHave you seen this before?\n\n----------\n\n[DudaNogueira (2024-12-03T12:38:29.068Z)]: hi @bam !\nDo you mean a collection?\nYou cannot add files do Verba directly\n\n----------\n\n[bam (2024-12-03T14:10:38.493Z)]: Maybe I’m using the wrong term. The button I’m pressing in Verba says import file and I’m choosing a file.\n\n----------\n\n[DudaNogueira (2024-12-03T18:49:35.994Z)]: I am sorry!\nYou can import files into Verba, but not into Weaviate \nSo I believe you are using Verba \nCan you copy the entire error message here?",
    "date_created": "2024-12-03T02:12:56.781Z",
    "has_accepted_answer": false,
    "title": "Importing New File Errors out as Already Exists in DB",
    "topic_id": 9063
  },
  {
    "user_id": 800,
    "conversation": "[ggapac (2024-04-10T13:32:06.697Z)]: Hi!\nI am trying to use a local setup of Weaviate without a specified vectorizer as I would prefer to generate my own embeddings. I am using the v4 Python client and running into an issue. Here is my reproducible example:\nimport weaviate\nfrom sentence_transformers import SentenceTransformer\n\n\nclient_weaviate = weaviate.connect_to_local()\nprint(client_weaviate.is_ready()) # True\nprint(client_weaviate.is_live()) # True\nprint(client_weaviate.is_connected()) # True\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\ntest_string = \"test_string\"\nemb = model.encode([test_string])\n\nIn this code chunk I am unable to retrieve the model (I get stuck on the line with model = …). However, if I move the model chunk above the weaviate client chunk, it works as intended. I am not sure what could be the issue here and I would appreciate some help.\nBelow you can also see my Docker file:\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.5\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      CLUSTER_HOSTNAME: 'node1'\nvolumes:\n  weaviate_data:\n\nThanks for your help!\n\n----------\n\n[DudaNogueira (2024-04-10T15:11:05.718Z)]: hi @ggapac ! Welcome to our community \nThat’s interesting. I will try to reproduce this later today.\nMeanwhile, are you aware you can run this model on a container for itself and integrate with Weaviate?\nCheck here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\ntext2vec-transformers | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!\n\n----------\n\n[ggapac (2024-04-11T06:32:21.965Z)]: Hi @DudaNogueira, thanks for the info. I am aware of this, but for our use case we are using some of our own fine-tuned models (that also use the sentence_transformers library) and would like to keep the two separate.\n\n----------\n\n[DudaNogueira (2024-04-16T12:11:19.664Z)]: Ah! Nice!\nAs long as you can produce a container that respond on those endpoints you can you your own transformers.\n\n----------\n\n[Bevani (2024-07-22T23:15:55.793Z)]: Hi @DudaNogueira ,\nI have a similar requirement and I understood the resolution you shared. However, I was wondering if it would be easier to just change the model path to the fine-tuned model (given that I am fine-tuning a sentence transformer model) in the Docker Compose YAML file. This is probably not implemented as far as I can tell from looking at the codebase, but I was wondering if it would be feasible and what the pros and cons would be.\n\n----------\n\n[DudaNogueira (2024-07-24T20:48:58.009Z)]: hi @Bevani !!\nWelcome to our community \nThere is a new approach I have just discovered the other day.\nYou can use tools like https://lmstudio.ai/, that will run different models both for LLM and embedding and emulate open ai interface.\nWith that you can point the text2vec_openai to that endpoint and it should use your custom models.\nCheck this thread:\n  \n    \n    \n    How to use weaviate with LM Studio? Support\n  \n  \n    Yes that is very helpful! \nIt’s confusing because the docs pages for the text2vec_openai module (text2vec-openai | Weaviate - Vector Database) refer to it in camel case like “baseURL” \nHowever now I’m getting this error: \nFailed to import 1 objects \ne.g. Failed to import object with error: WeaviateInsertManyAllFailedError(‘Every object failed during insertion. Here is the set of all errors: send POST request: Post “http://host.docker.internal:1234/v1/embeddings”: context deadline exceeded (Clien…",
    "date_created": "2024-04-10T13:32:06.626Z",
    "has_accepted_answer": false,
    "title": "Using sentence_transformers together with Weaviate",
    "topic_id": 1973
  },
  {
    "user_id": 3185,
    "conversation": "[AnnTade (2025-01-23T13:09:01.715Z)]: Hello everyone.\nWe are faced with the task to migrate around 10 million records from one weaviate instance to another weaviate cluster hosted on openstack, that has 3 nodes. Our schema’s sharding is set to 3, replication factor is set to 3. We are using weaviate client 4\nIn our client connection code, in additional config, we have Timeout(init = 120, query = 120, insert = 400)\nWe have tried multiple experiments and we are getting suspiciously low QPS of around 10-11.\nHere are some of the things we’ve tried.\n\nHaving bulk 10k records, using dynamic batching with default consistency level - it inserted only about 2k records.\nHaving bulk 2k records, using dynamic batching with default consistency level - it inserted only about 1.9k records.\n\nThe above ones gave us the following error in our logs after the run has been completed\n\nERROR:weaviate-client:{‘message’: ‘Failed to send all objects in a batch of 903’, ‘error’: ‘WeaviateBatchError('Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.DEADLINE_EXCEEDED\\n\\tdetails = “Deadline Exceeded”\\n\\tdebug_error_string = “UNKNOWN:Error received from peer  {created_time:“2025-01-22T20:13:54.414688058+00:00”, grpc_status:4, grpc_message:“Deadline Exceeded”}”\\n>.')’}ERROR:weaviate-client:{‘message’: ‘Failed to send 903 objects in a batch of 903. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\n\n\nHaving bulk 1k objects, using dynamic batching with default consistency level - the insertion was successful and took about 90 seconds = about 11 QPS\nHaving bulk 1.5k objects, using dynamic batching with default consistency level - the insertion was successful and took about 134 seconds = about 11 QPS\nHaving 5 parallel processes, using dynamic batching with default consistency level, each process having about 2k bulk objects - it failed to insert all of them and gave us the same error\nHaving 5 parallel processes, using dynamic batching with consistency level set to ONE, each process having about 2k bulk objects - it failed to insert all of them and gave us the same error\nHaving 5 parallel processes, using fixed batching with batch size 200, concurrent requests 2, process having about 2k bulk objects - it failed to insert all of them and gave us the same error\nHaving 5 parallel processes, using fixed batching with batch size 200, concurrent level 2, consistency level set to ONE, process having about 2k bulk objects - it failed to insert all of them and gave us the same error\n\nWe have tried other variations too, mix and match of these, such as each processes having 5k objects to insert, increasing the batch size to 500 in fixed batch size, increasing concurrent requests to 5. However, we always get the gRPC DEADLINE EXCEEDED error after the run in the logs, it doesn’t insert all the objects and with however many objects are inserted, we are getting QPS of 10-11.\nShouldn’t QPS be higher with gRPC? What are the possible causes of this issue?\n\n----------\n\n[DudaNogueira (2025-01-27T20:36:14.075Z)]: hi @AnnTade !!\nWhat is the server version?\nThis scenario point fingers at not enough resource allocated. Do you have any readings from memory?\nWhat is the dimensionality and what was you resource plan?\nAlso, do you see anything on server logs?\nThanks!",
    "date_created": "2025-01-23T13:09:01.662Z",
    "has_accepted_answer": false,
    "title": "Low QPS when using gRPC (v4) to batch insert data",
    "topic_id": 9864
  },
  {
    "user_id": 1314,
    "conversation": "[GustafB (2024-08-16T12:26:40.095Z)]: Description\nHello, I’m trying to setup Weaviate and Ollama, with both running in separate Docker containers, Weaviate is setup as default, and Ollama is can be accessed via port 11435. However when I try to ingest a document using text2vec-ollama I receive a connection refused error.\ndocker-compose.yaml\nversion: \"3.9\"\nservices:\n  ollama:\n    image: gb/ollama\n    ports:\n      - 11435:11434\n      - 11434:11434\n    restart: unless-stopped\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              capabilities: [\"gpu\"]\n              count: all\n    volumes:\n      - \"ollama-data:/root/.ollama\"\n\n  weaviate:\n    image: gb/weaviate\n    ports:\n      - 8080:8080\n      - 50051:50051\n    restart: unless-stopped\n    volumes:\n      - weaviate-data:/var/lib/weaviate\n\nvolumes:\n  ollama-data:\n  weaviate-data:\n\nweaviate/Dockerfile\nFROM cr.weaviate.io/semitechnologies/weaviate:1.26.1\n\nENV ENABLE_MODULES=\"text2vec-ollama\"\nENV DEFAULT_VECTORIZER_MODULE=\"text2vec-ollama\"\n\nEXPOSE 8080\n\nCMD [ \"--host\", \"0.0.0.0\", \"--port\", \"8080\", \"--scheme\", \"http\"]\n\ngolang program\nI am running my client in Go, see below for relevant sections in addition to the full program.\nfunc (store *VectorStore) createSchema() error {\n\tsaporoSchema := &models.Class{\n\t\tClass:      \"SaporoData2\",\n\t\tVectorizer: \"text2vec-ollama\",\n\t}\n\treturn store.Client.Schema().ClassCreator().WithClass(saporoSchema).Do(context.Background())\n}\n\nfunc (store *VectorStore) populate() error {\n\tdata, err := http.DefaultClient.Get(\"https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer data.Body.Close()\n\n\t// Decode the data\n\tvar items []map[string]string\n\tif err := json.NewDecoder(data.Body).Decode(&items); err != nil {\n\t\tpanic(err)\n\t}\n\n\t// convert items into a slice of models.Object\n\tobjects := make([]*models.Object, len(items))\n\tfor i := range items {\n\t\tobjects[i] = &models.Object{\n\t\t\tClass: \"SaporoData2\",\n\t\t\tProperties: map[string]any{\n\t\t\t\t\"category\": items[i][\"Category\"],\n\t\t\t\t\"question\": items[i][\"Question\"],\n\t\t\t\t\"answer\":   items[i][\"Answer\"],\n\t\t\t},\n\t\t}\n\t}\n\n\t// batch write items\n\tbatchRes, err := store.Client.Batch().ObjectsBatcher().WithObjects(objects...).Do(context.Background())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, res := range batchRes {\n\t\tif res.Result.Errors != nil {\n\t\t\treturn fmt.Errorf(\"batch write failed, %+v\", res.Result.Errors.Error[0])\n\t\t}\n\t}\n\n\treturn nil\n}\n\n\n  Full Program\npackage main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"github.com/sirupsen/logrus\"\n\t\"github.com/weaviate/weaviate-go-client/v4/weaviate\"\n\t\"github.com/weaviate/weaviate-go-client/v4/weaviate/graphql\"\n\t\"github.com/weaviate/weaviate/entities/models\"\n)\n\ntype (\n\tVectorStore struct {\n\t\tClient *weaviate.Client\n\t\tHost   string\n\t\tScheme string\n\t}\n)\n\nfunc (store *VectorStore) connect() error {\n\tcfg := weaviate.Config{\n\t\tHost:    store.Host,\n\t\tScheme:  \"http\",\n\t\tHeaders: nil,\n\t}\n\n\tclient, err := weaviate.NewClient(cfg)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Check the connection\n\tlive, err := client.Misc().LiveChecker().Do(context.Background())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif live {\n\t\tstore.Client = client\n\t}\n\n\treturn nil\n}\n\nfunc makeVectorStore(host string) (*VectorStore, error) {\n\tstore := VectorStore{\n\t\tHost: host,\n\t}\n\n\tif err := store.connect(); err != nil {\n\t\tlogrus.Errorf(\"unable to connect to vector store, err='%s'\", err)\n\t\treturn nil, err\n\t}\n\n\treturn &store, nil\n}\n\nfunc (store *VectorStore) createSchema() error {\n\tsaporoSchema := &models.Class{\n\t\tClass:      \"SaporoData2\",\n\t\tVectorizer: \"text2vec-ollama\",\n\t}\n\treturn store.Client.Schema().ClassCreator().WithClass(saporoSchema).Do(context.Background())\n}\n\nfunc (store *VectorStore) populate() error {\n\tdata, err := http.DefaultClient.Get(\"https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer data.Body.Close()\n\n\t// Decode the data\n\tvar items []map[string]string\n\tif err := json.NewDecoder(data.Body).Decode(&items); err != nil {\n\t\tpanic(err)\n\t}\n\n\t// convert items into a slice of models.Object\n\tobjects := make([]*models.Object, len(items))\n\tfor i := range items {\n\t\tobjects[i] = &models.Object{\n\t\t\tClass: \"SaporoData2\",\n\t\t\tProperties: map[string]any{\n\t\t\t\t\"category\": items[i][\"Category\"],\n\t\t\t\t\"question\": items[i][\"Question\"],\n\t\t\t\t\"answer\":   items[i][\"Answer\"],\n\t\t\t},\n\t\t}\n\t}\n\n\t// batch write items\n\tbatchRes, err := store.Client.Batch().ObjectsBatcher().WithObjects(objects...).Do(context.Background())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, res := range batchRes {\n\t\tif res.Result.Errors != nil {\n\t\t\treturn fmt.Errorf(\"batch write failed, %+v\", res.Result.Errors.Error[0])\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (store *VectorStore) search(query string) error {\n\tfields := []graphql.Field{\n\t\t{Name: \"question\"},\n\t\t{Name: \"answer\"},\n\t\t{Name: \"category\"},\n\t}\n\n\tnearText := store.Client.GraphQL().\n\t\tNearTextArgBuilder().\n\t\tWithConcepts([]string{query})\n\n\tresult, err := store.Client.GraphQL().Get().\n\t\tWithClassName(\"SaporoData2\").\n\t\tWithFields(fields...).\n\t\tWithNearText(nearText).\n\t\tWithLimit(2).\n\t\tDo(context.Background())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfmt.Println(\"Result Size = \", len(result.Data))\n\n\tfor k, r := range result.Data {\n\t\tfmt.Println(k, r)\n\t}\n\n\treturn nil\n}\n\nfunc main() {\n\tstore, err := makeVectorStore(\"localhost:8080\")\n\tif err != nil {\n\t\tlogrus.Errorf(\"unable to create store, err='%s'\", err)\n\t}\n\n\tif err := store.createSchema(); err != nil {\n\t\tlogrus.Errorf(\"unable to create SaporoData schema, err='%s'\", err)\n\t}\n\n\tif err := store.populate(); err != nil {\n\t\tlogrus.Errorf(\"unable to populate database, err='%s'\", err)\n\t}\n\n\tstore.search(\"biology\")\n}\n\n\nerror from weaviate\nsend POST request: Post \"http://localhost:11434/api/embeddings\": dial tcp [::1]:11434: connect: connection refused\n\nQuestion\nCurious if anyone has any ideas of how I can resolve this? I see that you can specify the endpoint explicitly in the python API but I don’t see that being an option in the go library. Running Ollama locally is not an option as our entire system runs in Docker.\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method: \nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Golang 1.22\nMultitenancy?: No\n\nAny additional Information\n\n----------\n\n[GustafB (2024-08-16T12:51:41.193Z)]: Have also tried setting the ModuleConfig when creating the schema class as:\n\tsaporoSchema := &models.Class{\n\t\tClass:      \"SaporoData2\",\n\t\tVectorizer: \"text2vec-ollama\",\n\t\tModuleConfig: map[string]map[string]any{\n\t\t\t\"text2vec-ollama\": {\n\t\t\t\t\"apiEndpoint\": \"http://localhost:11435\",\n\t\t\t\t\"model\":       \"Saporo\",\n\t\t\t},\n\t\t},\n\t}\n\nBut that doesn’t seem to have any effect either.\n\n----------\n\n[DudaNogueira (2024-08-16T13:40:24.883Z)]: Hi! Welcome to our community  !!\nAs you are using the ollama in docker, you should probably change:\n“apiEndpoint”: “http://localhost:11435”,\nto\n“apiEndpoint”: “http://ollama:11435”,\nLet me know if this helps!\n\n----------\n\n[GustafB (2024-08-16T13:57:58.618Z)]: Thank you for the prompt response!\nIndeed that did the trick, must’ve messed something up earlier because as far as I could tell my moduleConfig wasn’t being used.\nAppreciate the help!",
    "date_created": "2024-08-16T12:26:40.040Z",
    "has_accepted_answer": true,
    "title": "Connection refused text2vec-ollama",
    "topic_id": 3371
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-09-01T04:57:11.317Z)]: Description\nWhen I just specify multi-tenancy, all my insert / updates work.\nHowever, when I just add properties to the schema declaration, I start to get this error:\n\nweaviate.exceptions.UnexpectedStatusCodeError: Object was not updated.! Unexpected status code: 422, with response body: {‘error’: [{‘message’: ‘msg:repo.object code:422 err:search index nodes: class Nodes has multi-tenancy disabled, but request was with tenant’}]}.\n\nThis is the code:\nnodes_collection = client.collections.create(\n\t\tname=\"Nodes\",\n\t\tvectorizer_config=wvc.config.Configure.Vectorizer.none(),\n\t\tvector_index_config=Configure.VectorIndex.hnsw(\n\t\t\tdistance_metric=VectorDistances.COSINE\n\t\t),\n\t\t# Multi tenancy to separate each user's data\n\t\tmulti_tenancy_config=Configure.multi_tenancy(enabled=True, auto_tenant_creation=True, auto_tenant_activation=True),\n\t\t# Specify some properties beforehand to set right data type (i.e. obj[] instead of string[])\n\t\tproperties=[\n\t\t\tProperty(name=\"tags\", data_type=DataType.OBJECT_ARRAY),\n\t\t]\n\t)\n\nIf I remove the properties field, then it will work again.\nThis is an example insert code:\ndef get_tenant_collection(name):\n\ttry:\n\t\treturn nodes_collection.with_tenant(name)\n\texcept:\n\t\tnodes_collection.tenants.create(name)\n\t\treturn nodes_collection.with_tenant(name)\n\ntenant_collection = get_tenant_collection(tenant_name)\n\t\ntenant_collection.data.insert(\n\tvector=record.vector,\n\tproperties=record.properties,\n\tuuid=record.uniqueid\n)\n\nEven update / delete, all operations trigger the multi-tenancy error. I can confirm the rest of the code is working including getting the tenant collection because just commenting out properties, will make everything start working\nnodes_collection = client.collections.create(\n\t\tname=\"Nodes\",\n\t\tvectorizer_config=wvc.config.Configure.Vectorizer.none(),\n\t\tvector_index_config=Configure.VectorIndex.hnsw(\n\t\t\tdistance_metric=VectorDistances.COSINE\n\t\t),\n\t\t# Multi tenancy to separate each user's data\n\t\tmulti_tenancy_config=Configure.multi_tenancy(enabled=True, auto_tenant_creation=True, auto_tenant_activation=True),\n\t\t# Commenting this out makes all operations work again\n\t\t# properties=[\n\t\t# \tProperty(name=\"tags\", data_type=DataType.OBJECT_ARRAY),\n\t\t# ]\n\t)\n\nServer Setup Information\n\nWeaviate Server Version: Cloud\nMulti Node? Number of Running Nodes: No\nClient Language and Version: Python v4\nMultitenancy?:  Yes\n\n----------\n\n[DudaNogueira (2024-09-02T18:09:52.950Z)]: hi @Tejas_Sharma !!\nI believe you are facing this issue:\n\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      WeaviateQueryError when searching for objects stored as a refrence property in a multitenant collection or schema\n    \n\n    \n      \n        opened 11:55AM - 02 Jul 24 UTC\n      \n\n\n      \n        \n          \n          rthiiyer82\n        \n      \n    \n\n    \n        \n          bug\n        \n    \n  \n\n\n  \n    ### How to reproduce this bug?\n\nAs per the weaviate documentation one should be …able to cross reference from a multi tenant to a non multi tenant.\n\nRun the below script\n```\nimport random\nimport string\nfrom weaviate.classes.config import Property, DataType, ReferenceProperty\nimport weaviate\nimport weaviate.classes.config as wvc\nfrom weaviate.classes.tenants import Tenant\nfrom weaviate.classes.query import QueryReference\n\nclient = weaviate.connect_to_local()\n\n# Create collection\nif (client.collections.exists(\"JeopardyCategory\")):\n  # delete collection \"Article\" - THIS WILL DELETE THE COLLECTION AND ALL ITS DATA\n  client.collections.delete(\"JeopardyCategory\")  # Replace with your collection name\n\n# Create collection\nif (client.collections.exists(\"JeopardyQuestion\")):\n  # delete collection \"Article\" - THIS WILL DELETE THE COLLECTION AND ALL ITS DATA\n  client.collections.delete(\"JeopardyQuestion\")  # Replace with your collection name\n\n\ncategory = client.collections.create(\n    name=\"JeopardyCategory\",\n    description=\"A Jeopardy! category\",\n    properties=[\n        Property(name=\"title\", data_type=DataType.TEXT)\n    ],\n     replication_config=wvc.Configure.replication(factor=1),\n    \n)\n\n\njeopardy_question= client.collections.create(\n    name=\"JeopardyQuestion\",\n    description=\"A Jeopardy! question\",\n    properties=[\n        Property(name=\"question\", data_type=DataType.TEXT),\n        Property(name=\"answer\", data_type=DataType.TEXT),\n    ],\n    references=[\n        ReferenceProperty(\n            name=\"hasCategory\",\n            target_collection=\"JeopardyCategory\"\n        )\n    ],\n    replication_config=wvc.Configure.replication(factor=1),\n    multi_tenancy_config=wvc.Configure.multi_tenancy(enabled=True, auto_tenant_creation=True, auto_tenant_activation=True)\n\n)\n\n# Create tenant on JeopardyQuestion\njeopardy_question.tenants.create(\n    tenants=[\n        Tenant(name=\"tenantA\"),\n        Tenant(name=\"tenantB\"),\n    ]\n)\n\n# Insert objects to the collection\ndef get_random_string(length):\n    # choose from all lowercase letter\n    letters = string.ascii_lowercase\n    result_str = ''.join(random.choice(letters) for i in range(length))\n    return result_str\n    # print(\"Random string of length\", length, \"is:\", result_str)\n\n# Add category to JeopardyCategory\n\njeopardy = client.collections.get(\"JeopardyCategory\")\n\ncategory_uuid = jeopardy.data.insert({\n    \"title\": get_random_string(10)\n})\n\nquestions= jeopardy_question.with_tenant(tenant=\"tenantA\")\n\nquestions.data.insert({\n    \"question\": \"question\" + get_random_string(10),\n    \"answer\" : \"answer\"+ get_random_string(10)\n},\n    references={\"hasCategory\": category_uuid},  # e.g. {\"hasCategory\": \"583876f3-e293-5b5b-9839-03f455f14575\"}\n)\n\nresponse = questions.query.fetch_objects(return_references=QueryReference(link_on=\"hasCategory\", return_properties=[\"question\", \"answer\"]))\n\nfor o in response.objects:\n    print(o.properties)\n\nclient.close()\n\n```\n\n### What is the expected behavior?\n\nNo error should be displayed and user should be able to query the reference property in a multitenant collection.\n\n### What is the actual behavior?\n\n```\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n        status = StatusCode.UNKNOWN\n        details = \"explorer: list class: search: resolve cross-refs: build reference cache: build request cache: fetch job list: index \"jeopardycategory\": class JeopardyCategory has multi-tenancy disabled, but request was with tenant\"\n        debug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-07-01T19:38:14.318273+01:00\", grpc_status:2, grpc_message:\"explorer: list class: search: resolve cross-refs: build reference cache: build request cache: fetch job list: index \\\"jeopardycategory\\\": class JeopardyCategory has multi-tenancy disabled, but request was with tenant\"}\"\n>.\n\n```\n\n### Supporting information\n\nhttps://weaviate.io/developers/weaviate/manage-data/multi-tenancy#cross-references\n\n### Server Version\n\n1.25.6\n\n### Code of Conduct\n\n- [X] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nPlease, make sure to leave a  on that issue so we can prioritize it.\nTHanks!\n\n----------\n\n[Tejas_Sharma (2024-09-03T05:05:54.163Z)]: Hi @DudaNogueira ,\nI think mine is completely different because their bug is about multi-tenant to non-tenant but mine is that there is a bug in the SDK that if both multi tenancy and properties are specified, then everything breaks\n\n----------\n\n[DudaNogueira (2024-09-03T12:15:39.968Z)]: Oh, sorry.\nDo you think you can create a reproducible python code?\nWith that we better understand the issue by reproducing or fixing any code or assumptions along the way.\nThat issue has a python code that can server as starting point.\nThanks!\n\n----------\n\n[Tejas_Sharma (2024-09-03T16:54:47.661Z)]: Okay thanks Duda, will try to get it out soon\n\n----------\n\n[Tejas_Sharma (2024-09-12T16:22:04.618Z)]: Hi @DudaNogueira , aplogies for the delay, here’s the minimal reproducible code:\nimport uuid\nimport weaviate\nimport weaviate.classes as wvc\nfrom weaviate.classes.query import Filter, MetadataQuery\nfrom weaviate.classes.config import Configure, VectorDistances, Property, DataType\nfrom weaviate.classes.tenants import Tenant\nfrom datetime import datetime, timedelta\nimport pytz\n\ntry:\n\t# TODO: use different credentials for production\n\t# Best practice: store your credentials in environment variables\n\twcd_url = \"\"\n\twcd_api_key = \"\"\n\n\tclient = weaviate.connect_to_weaviate_cloud(\n\t\tcluster_url=wcd_url,                                    # Replace with your Weaviate Cloud URL\n\t\tauth_credentials=wvc.init.Auth.api_key(wcd_api_key),    # Replace with your Weaviate Cloud key\n\t)\nexcept Exception as e:\n\tprint(e)\n\t# exit\n\tpass\n\n\ntry:\n\t# For all objects\n\tnodes_collection = client.collections.create(\n\t\tname=\"Nodes\",\n\t\tvectorizer_config=wvc.config.Configure.Vectorizer.none(),\n\t\tvector_index_config=Configure.VectorIndex.hnsw(\n\t\t\tdistance_metric=VectorDistances.COSINE\n\t\t),\n\t\t# Multi tenancy to separate each user's data\n\t\tmulti_tenancy_config=Configure.multi_tenancy(enabled=True, auto_tenant_creation=True, auto_tenant_activation=True),\n\t\tinverted_index_config=Configure.inverted_index( \n\t\t\tindex_null_state=True,\n        \tindex_property_length=True,\n\t\t\tindex_timestamps=True\n\t\t)\n\t\t# Specify some properties beforehand to set right data type (i.e. obj[] instead of string[])\n\t\tproperties=[\n\t\t\tProperty(name=\"tags\", data_type=DataType.OBJECT_ARRAY),\n\t\t]\n\t)\nexcept:\n\tnodes_collection = client.collections.get(\"Nodes\")\n\ntry:\n\t# Create tenant on Node\n\tnodes_collection.tenants.create(\n\t\ttenants=[\n\t\t\tTenant(name=\"tenantA\"),\n\t\t\tTenant(name=\"tenantB\"),\n\t\t]\n\t)\nexcept:\n\tpass\n\n\n# Will cause an error\nnodes_collection.with_tenant('tenantA').data.insert(\n\tvector=[0.0] * 384,\n\tproperties={'lastUpdateDeviceId': 'device-78C24351-F40A-4E37-8953-F003FA474877'},\n\tuuid=str(uuid.uuid4())\n)\n\n----------\n\n[DudaNogueira (2024-09-16T13:59:18.759Z)]: Hi @Tejas_Sharma !!\nYou need to specify at least one nested property if using the object. Also, there was a missing , in your code, right after inverted_index_config \nHere is a working example:\nimport uuid\nimport weaviate\nimport weaviate.classes as wvc\nfrom weaviate.classes.query import Filter, MetadataQuery\nfrom weaviate.classes.config import Configure, VectorDistances, Property, DataType\nfrom weaviate.classes.tenants import Tenant\nfrom datetime import datetime, timedelta\nimport pytz\n\n# For all objects\nclient.collections.delete(\"Test\")\nnodes_collection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n    vector_index_config=Configure.VectorIndex.hnsw(\n        distance_metric=VectorDistances.COSINE\n    ),\n    # Multi tenancy to separate each user's data\n    multi_tenancy_config=Configure.multi_tenancy(enabled=True, auto_tenant_creation=True, auto_tenant_activation=True),\n    inverted_index_config=Configure.inverted_index( \n        index_null_state=True,\n        index_property_length=True,\n        index_timestamps=True\n    ),\n    # Specify some properties beforehand to set right data type (i.e. obj[] instead of string[])\n    properties=[\n        wvc.config.Property(\n            name=\"tags\",\n            data_type=wvc.config.DataType.OBJECT,\n            nested_properties=[\n                wvc.config.Property(\n                    name=\"sub_property1\",\n                    data_type=wvc.config.DataType.TEXT\n                ),\n                wvc.config.Property(\n                    name=\"sub_property2\",\n                    data_type=wvc.config.DataType.INT\n                )\n            ]\n        )\n    ]\n)\n\n\n# Create tenant on Node\nnodes_collection.tenants.create(\n    tenants=[\n        Tenant(name=\"tenantA\"),\n        Tenant(name=\"tenantB\"),\n    ]\n)\n\n# Will cause an error\nnodes_collection.with_tenant('tenantA').data.insert(\n\tvector=[0.0] * 384,\n\tproperties={\n        'lastUpdateDeviceId': 'device-78C24351-F40A-4E37-8953-F003FA474877',\n        \"tags\": {\"sub_property1\": \"somedata\", \"sub_property2\": 123}        \n    },\n\tuuid=str(uuid.uuid4())\n)\n\nLet me know if this helps.\nThanks!\n\n----------\n\n[Tejas_Sharma (2024-09-16T18:14:54.556Z)]: Ah okay, thanks Duda. We actually found a workaround solution of just creating the first record with tags specified to prevent this error but will try this out in the future.\nI would like to add though  that it would help if it specified that error during the node creation rather than the multi tenancy error since the error it was giving was not related to the fix and would thus be hard to debug\n\n----------\n\n[DudaNogueira (2024-09-16T21:08:46.793Z)]: Oh, I see. This is a pitfall of the AUTOSCHEMA_ENABLED feature.\nNote that we do not recommend leaving AUTOSCHEMA_ENABLED in production as it can create new properties if you specify a wrong property name.\nIf you have AUTOSCHEMA_ENABLED and do not specify a property at collection creation, the first property inserted will change your schema for you.\nThis code will fail on collection creation, and not on tenant creation:\nnodes_collection = client.collections.create(\n    name=\"Nodes\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n    vector_index_config=Configure.VectorIndex.hnsw(\n        distance_metric=VectorDistances.COSINE\n    ),\n    # Multi tenancy to separate each user's data\n    multi_tenancy_config=Configure.multi_tenancy(enabled=True, auto_tenant_creation=True, auto_tenant_activation=True),\n    inverted_index_config=Configure.inverted_index( \n        index_null_state=True,\n        index_property_length=True,\n        index_timestamps=True\n    ),\n    # Specify some properties beforehand to set right data type (i.e. obj[] instead of string[])\n    properties=[\n        Property(name=\"tags\", data_type=DataType.OBJECT_ARRAY),\n    ]\n)\n\nerror message:\n\nUnexpectedStatusCodeError: Collection may not have been created properly.! Unexpected status code: 422, with response body: {‘error’: [{‘message’: “Property ‘tags’: At least one nested property is required for data type object/object”}]}.",
    "date_created": "2024-09-01T04:57:11.252Z",
    "has_accepted_answer": true,
    "title": "Specifying properties with multi-tenancy causes bug",
    "topic_id": 3946
  },
  {
    "user_id": 1143,
    "conversation": "[andrewisplinghoff (2024-07-09T19:21:07.735Z)]: Description\nWe are performing a batch import where in the last step we create cross-references between the objects. While doing so, we perform consistency checks that all objects that were written in the previous step can also be retrieved. In our last run, this was not always the case. We did not receive a client-side error during the batch import, but at the time of the import i the server logs there was (among others) the following error:\n{\"action\":\"lsm_memtable_flush\",\"class\":\"PageNode_v3\",\"error\":\"flush: unlinkat /var/lib/weaviate/pagenode_v3/kUuKzkTaWVxi/lsm/objects/segment-1720459484309792404.scratch.d: directory not empty\",\"index\":\"pagenode_v3\",\"level\":\"error\",\"msg\":\"flush and switch failed\",\"path\":\"/var/lib/weaviate/pagenode_v3/kUuKzkTaWVxi/lsm/objects\",\"shard\":\"kUuKzkTaWVxi\",\"time\":\"2024-07-08T17:25:48Z\"}\n\nThe following query did not return any objects although they had been inserted before:\nweaviate_client.query.get(\n            'PageNode_v3',\n            ['page_id', 'node_index']\n        )\n        .with_where({\n            \"path\": [\"page_id\"],\n            \"operator\": \"Equal\",\n            \"valueText\": page_id\n        })\n        .with_limit(100_000)\n        .do()\n\nInterestingly, after a server restart (we upgraded to 1.25.7 during that restart, but I do not think that that made a difference), the objects are now retrievable. During server startup, the following messages related to this shard were printed to the log:\n{\"action\":\"lsm_segment_init\",\"class\":\"PageNode_v3\",\"index\":\"pagenode_v3\",\"level\":\"info\",\"msg\":\"discarded (partially written) LSM segment, because an active WAL for the same segment was found. A recovery from the WAL will follow.\",\"path\":\"/var/lib/weaviate/pagenode_v3/kUuKzkTaWVxi/lsm/objects/segment-1720459484309792404.db\",\"shard\":\"kUuKzkTaWVxi\",\"time\":\"2024-07-09T10:49:47Z\",\"wal_path\":\"segment-1720459484309792404.wal\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"PageNode_v3\",\"index\":\"pagenode_v3\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/var/lib/weaviate/pagenode_v3/kUuKzkTaWVxi/lsm/objects/segment-1720459484309792404\",\"shard\":\"kUuKzkTaWVxi\",\"time\":\"2024-07-09T10:49:47Z\"}\n\nObviously having to restart the server to have all objects readable is not optimal. Could you please help us understand what is happening here and if there is a chance of having this not happen in the first place?\nServer Setup Information\n\nWeaviate Server Version: 1.25.6\nDeployment Method: k8s using helm\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python, 3.26.2\nMultitenancy?: no\n\n----------\n\n[andrewisplinghoff (2024-07-10T08:56:56.584Z)]: BTW we have the text2vec-openai vectorizer enabled for the collection, if that might be related to the problem as I assume that Weaviate waits for the vectorization to complete before writing the final object to the file system.\nThis was a fresh install of Weaviate 1.25, we did not perform an upgrade from 1.24 on this cluster.\n\n----------\n\n[DudaNogueira (2024-07-11T20:11:53.758Z)]: hi @andrewisplinghoff !!\nHow big is this cluster?\nI have searched internally and have found some discussions on this very same error log. This may be a hardware limit \nLet me know about this.\nConsidering you only have 1 node, if you have a lot of objects, maybe it is time to think about scaling your cluster.\n\n----------\n\n[andrewisplinghoff (2024-07-12T09:34:07.823Z)]: There’s not really so much data in the cluster, overall 1.7G (Size of PVC weaviate-data-weaviate-0).\nCollection Counts:\nPage_v3: 13199\nPageNode_v3: 64392\nAre there recommendations when multiple nodes should be used?\n\n----------\n\n[DudaNogueira (2024-07-15T18:48:59.051Z)]: Oh, that’s not a lot of objects.\nWhere are you running this? One thing to look for is the hardware of that server, specially on hard drive specs.\n\n----------\n\n[andrewisplinghoff (2024-07-16T15:22:27.205Z)]: This is running on Azure, disk space provided using a\nNetApp Cloud Volume (CVO) via NFS3.\n\n----------\n\n[DudaNogueira (2024-07-16T16:25:18.587Z)]: With that amount of objects, can you try reindexing on a new collection?\nThis could be an indexing error and reindexing shouldn’t be a lot of efforts.\nLet me know if this is possible.\nTHere is a migration guide here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nthat can get your data from one collection to the new one.\n\n----------\n\n[andrewisplinghoff (2024-07-16T16:44:37.900Z)]: Not quite sure what the reindexing would help with the original issue? The data is available now after a server restart, the question is just why did it require a server restart to recover it. So what would reindexing do? The data is already available now.\n\n----------\n\n[DudaNogueira (2024-07-17T15:43:17.749Z)]: Oh ok.\nMy guess is that after the restart, it recovered the missing batch objects.\nI thought it was still missing, or broken.\nGlad it solved, then.",
    "date_created": "2024-07-09T19:21:07.681Z",
    "has_accepted_answer": false,
    "title": "Some objects not readable after batch import / flush and switch failed",
    "topic_id": 2991
  },
  {
    "user_id": 2968,
    "conversation": "[Kesav_S (2024-12-05T05:01:02.128Z)]: Description\nI am using docker compose to start weaviate with backup-gcs included in the module section. I get the following error:-\n{\"action\":\"startup\",\"error\":\"init modules: init module 2 (\\\"backup-gcs\\\"): init gcs client: find default credentials: google: error getting credentials using GOOGLE_APPLICATION_CREDENTIALS environment variable: open <path in server>/credential.json: no such file or directory\",\"level\":\"fatal\",\"msg\":\"modules didn't initialize\",\"time\":\"2024-12-04T06:38:01Z\"}\n\nServer Setup Information\n\nWeaviate Server Version: v1.25.6\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: nodejs\nMultitenancy?: yes\n\nAny additional Information\nAdding the docker compose file here for reference (i have removed sensitive information from the below file):\n---\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: <path>/weaviate:1.25.6\n    ports:\n    - 5500:8080\n    - 50051:50051\n    volumes:\n    - /home/ubuntu/<path>:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'\n      IMAGE_INFERENCE_API: 'http://i2v-neural:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'\n      ENABLE_MODULES: 'text2vec-transformers,img2vec-neural,backup-gcs'\n      CLUSTER_HOSTNAME: 'node1'\n      AUTHENTICATION_APIKEY_ENABLED: 'true'\n      AUTHENTICATION_APIKEY_ALLOWED_KEYS: <key>\n      AUTHENTICATION_APIKEY_USERS: <user>\n      BACKUP_GCS_BUCKET: <bucket>\n      BACKUP_GCS_PATH : <path>\n      BACKUP_GCS_USE_AUTH : 'true'\n      GOOGLE_APPLICATION_CREDENTIALS : <path in server>/credential.json\n      GCP_PROJECT: <gcp-project>\n  t2v-transformers:\n    image: <image>\n    environment:\n      ENABLE_CUDA: '0'\n  i2v-neural:\n    image: <image>\n    environment:\n      ENABLE_CUDA: '0'\n...\n\n----------\n\n[DudaNogueira (2024-12-06T21:11:47.038Z)]: hi @Kesav_S !!\nWelcome to our community \nThat’s strange. This has worked for me:\n      ....\n      GOOGLE_APPLICATION_CREDENTIALS: /var/lib/weaviate/duda-project-425315-7c9f819c0366.json\n      BACKUP_GCS_BUCKET: \"duda-test\"\n    volumes:\n    - ./data:/var/lib/weaviate\n\nCan you see the credential.json in your path?\nyou can check it like this:\ndocker compose exec -ti weaviate sh -c 'ls /var/lib/weaviate/*.json'\n\n\n/var/lib/weaviate/duda-project-425315-7c9f819c0366.json\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Josh (2025-02-11T09:34:08.022Z)]: I had the same issue, and adding\n...\nvolumes:\n    - /home/ubuntu/<path>:/var/lib/weaviate\n    - <path-to-local-json-file>:/<some-dir>/<json-file-name-in-container>\n...\n# And updating the `GOOGLE_APPLICATION_CREDENTIALS` value in environment to match the mounted volume\nenvironment:\n    ...\n    GOOGLE_APPLICATION_CREDENTIALS: /<some-dir>/<json-file-name-in-container>\n    ...\n\nsolved it for me.\nLet me know if this solved it for you as well.",
    "date_created": "2024-12-05T05:01:02.080Z",
    "has_accepted_answer": false,
    "title": "Docker compose with backup-gcs not fetching credentials file",
    "topic_id": 9104
  },
  {
    "user_id": 1636,
    "conversation": "[Jekabsons (2024-10-04T13:52:01.698Z)]: Description\nIn short, when I run automatic object uploader, that attempts to upload a set of objects one after another, my weaviate instance batcher doesn’t upload couple of provided sets. It returns a valid message “resp” in resp, err := batcher.Do(ctx) containing all of the fields and vectors for the provided object but doesn’t include the object in the database. Furthermore, when I upload large amounts of objects to the database, at some point I can’t even upload any object sets to the respective collection, but they do successfully upload to any other collection containing less elements.\nHere is my code snippet:\nbatcher := client.Batch().ObjectsBatcher()\n\n\t// uploads data in batches of 20 or less chapters to prevent weaviate timeout\n\tbatchCount := int(math.Ceil(float64(len(ObjectSet)) / batchSize))\n\n\tObjectSetLen := len(ObjectSet)\n\n\tfor i := 0; i < batchCount; i += 1 {\n        // calculates the last object index for the object array that needs to be batched\n\t\tlastBatchElementIndex := (i + 1) * batchSize\n\t\tif lastBatchElementIndex > ObjectSetLen {\n\t\t\tlastBatchElementIndex = ObjectSetLen\n\t\t}\n\n        // sets up the batcher and batches the objects\n\t\tfor j := (i * batchSize); j < lastBatchElementIndex; j += 1 {\n        //To avoid empty content error, makes a content check\n\t\t\ttest := strings.ReplaceAll(ObjectSet[j].Content, \" \", \"\")\n\t\t\tif test == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tdataObj := requests.SetSectionObj{\n\t\t\t\tCategory:     ObjectSet[j].Title,\n\t\t\t\tContent:      ObjectSet[j].Content,\n\t\t\t}\n\n\t\t\tbatcherObject := &models.Object{\n\t\t\t\tClass:      class,\n\t\t\t\tProperties: dataObj,\n\t\t\t}\n\n\t\t\tbatcher.WithObjects(batcherObject)\n\n\t\t}\n\n\t\tresp, err := batcher.Do(ctx)\n\t\tif err != nil {\n\t\t\tutils.SetError(ctx, fasthttp.StatusInternalServerError, err.Error())\n\t\t\treturn\n\t\t}\n\t\tlog.Print(resp)\n\t}\n\n\tctx.StatusCode(fasthttp.StatusNoContent)\n\nServer Setup Information\n\nWeaviate Server Version: 1.25.19\nDeployment Method: Docker\nMulti Node? Number of Running Nodes:  1\nClient Language and Version:  Go 1.23\nMultitenancy?: No\n\nAny additional Information\nWeaviate logs do not provide any information in regards to this and does not throw any errors\n\n----------\n\n[DudaNogueira (2024-11-01T14:52:39.406Z)]: hi @Jekabsons !!\nSorry, we missed this message \nWere you able to overcome this?\nThanks!\n\n----------\n\n[Jekabsons (2024-11-08T21:12:09.115Z)]: Hi, yes, the problem in the end was that I fetched the objects using this method:\nresp, err := client.GraphQL().Get().WithClassName(\"ABCD\").Do(context.Background())\n\nAnd as it turns out I wasn’t familiar with pagination concept before and didn’t now that the maximum amount of objects a GraphQL query return\nis 100. But I fixed the issue by using .WithOffset(100) method, and looping through the whole dataset.\n\n----------\n\n[DudaNogueira (2024-11-10T11:14:48.552Z)]: Thanks for sharing!!",
    "date_created": "2024-10-04T13:52:01.653Z",
    "has_accepted_answer": true,
    "title": "BUG: Batcher doesn't upload the objects to the weaviate db",
    "topic_id": 4421
  },
  {
    "user_id": 1997,
    "conversation": "[Outlast_Assistenza (2024-10-21T10:11:38.541Z)]: Description\n\nEverything is working fine, but even after updating the file OpenAiGenerator the model is still working on the 4o.\n\n----------\n\n[DudaNogueira (2024-10-21T21:55:30.254Z)]: hi @Outlast_Assistenza !! Welcome to our community \nYou will need to reindex your data.\nFor that, this migration guide can help:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYou will need to create the collection with the new vectorizer/generative configuration, and then copy your data over.\nBecause the the vectors generated by one model are different from other models, you will need to re vectorizer everything \nLet me know if this helps!\nTHanks!",
    "date_created": "2024-10-21T10:11:38.491Z",
    "has_accepted_answer": false,
    "title": "I would like to update the model from gpt-4o to gpt-4o-mini, any tip?",
    "topic_id": 5814
  },
  {
    "user_id": 1548,
    "conversation": "[albusseverus (2024-09-17T05:31:00.076Z)]: Hi, I have setup a binary quantization on my collection like this\ncollection = client.collections.create(\n        name=collection_name,\n        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_cohere(model=\"embed-multilingual-v3.0\"),    \n        generative_config=wvc.config.Configure.Generative.anthropic(),            \n         # Configure the vector index\n        vector_index_config=wvc.config.Configure.VectorIndex.flat(  # Or `flat` or `dynamic`\n            distance_metric=wvc.config.VectorDistances.COSINE,\n            vector_cache_max_objects=100000,\n            quantizer=wvc.config.Configure.VectorIndex.Quantizer.bq(\n                cache=True,\n                rescore_limit=200\n            )\n        ),\n\nAfter inserting data, I attempted to retrieve the data from the collection, including the vector. However, the vector was not stored as binary but as float32. Is this correct ? Does it mean the original vectors are stored on disk, not the binary vectors. So where were all the binary vectors stored? Memory ?\nIt’s my first time trying to use binary quantization, so sorry if i ask too many questions.\nvector={'default': [0.0295257568359375, 0.03265380859375, -0.0278778076171875, 0.01934814453125, 0.00127410888671875, 0.0172271728515625, 0.01560211181640625, -0.05621337890625, -0.00555419921875, 0.00482177734375, 0.008...]}\n\n----------\n\n[DudaNogueira (2024-09-18T22:00:37.503Z)]: hi @albusseverus !!\nWelcome to our community \nAFAIK, the compressed vectors are not exposed to the client, but only used internally.\nLet me know if this helps.\n\n----------\n\n[00.lope.naughts (2024-11-11T20:21:00.337Z)]: I am testing out binary quantization without any vectorizer module, that’s \"I bring my own vectors). am I define my collection:\n client.collections.create(\n   name=\"Listing_Image\",\n   vectorizer_config=Configure.Vectorizer.none(),\n   vector_index_config=Configure.VectorIndex.hnsw(\n       quantizer=wc.Configure.VectorIndex.Quantizer.bq(),\n       distance_metric=weaviate.classes.config.VectorDistances.COSINE,\n       max_connections=64,\n       ef_construction=128,\n       cleanup_interval_seconds=300,\n       vector_cache_max_objects=2000000\n   ), etc.\n\nI am also observing that after I insert my docs, and then try to get it back, including the vectors, the vector is a List[float], just like what @albusseverus saw. And I do have the same question.\nbut it looks @DudaNogueira had responded “the compressed vectors are not exposed to client”. Does this implies internally, it is using the faster binary version, but then if a client asks for a doc’s vector, it restores the original precision version, so the compression isnt lossless? One primary reason I am looking at binary compression is not only for speed, but also reduce space requirement. Does this also mean space saving is not as much?\nI also read in another thread that Binary Quantization is not supported in “bring my own vector” scenario? and this could explain it (it silently just ignore the quantizer config).\n\n----------\n\n[DudaNogueira (2024-11-12T13:48:55.598Z)]: hi @00.lope.naughts !!\nThat’s accurate.\n\n\n\n 00.lope.naughts:\n\nDoes this implies internally, it is using the faster binary version, but then if a client asks for a doc’s vector, it restores the original precision version, so the compression isnt lossless?\n\n\nWhen you do request, at query level, and ask the vector to be returned (include_vectors=True), it will return the original vector.\nNow Weaviate will store both compressed and uncompressed vectors at disk. So you don’t get disk saving, much the opposite: it will require more disk space to store the vector in both dimensionalities. However, it will require less memory to hold the quantized vectors.\nThis not accurate, AFAIK:\n\nI also read in another thread that Binary Quantization is not supported in “bring my own vector” scenario? and this could explain it (it silently just ignore the quantizer config).\n\nFor Weaviate, if you bring your own vectors or get it vectorized at ingestion time using a module, should be all the same \nHere we can find more info on BQ:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCompression (Vector Quantization) | Weaviate\n\n  Vector quantization reduces the memory footprint of the vector index by compressing the vector embeddings, and thus reduces deployment costs and improves the speed of the vector similarity search process.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!",
    "date_created": "2024-09-17T05:31:00.019Z",
    "has_accepted_answer": false,
    "title": "Binary Quantization Vector Not Found in Collection",
    "topic_id": 4179
  },
  {
    "user_id": 2518,
    "conversation": "[JCP (2024-11-17T14:01:26.640Z)]: Hi all,\nI’m trying to build a simple RAG application in Golang. Everything is working fine, except when I try to get data for the final inference: client.GraphQL().Get() tries to use llama3 instead of the model I want.\nI surely missed something as llama3 is the default model, but I could not find where I forgot to indicate the right model to be used.\nDescription\nLocal Weaviate built from sources\nLocal Ollama server\n\n\nI created a class with this code:\nclassObj := &models.Class{\nClass:\t\tclassName,\nVectorizer:\t“text2vec-ollama”,\nModuleConfig: map[string]interface{}{\n“text2vec-ollama”: map[string]interface{}{ // Configure the Ollama embedding integration\n“apiEndpoint”: weaviateOllamaURL, // Allow Weaviate from within a Docker container to contact your Ollama instance\n“model”:       ollamaEmbeddingModel, // The model to use\n},\n“generative-ollama”: map[string]interface{}{ // Configure the Ollama generative integration\n“apiEndpoint”: weaviateOllamaURL, // Allow Weaviate from within a Docker container to contact your Ollama instance\n“model”:       ollamaModel,  // The model to use\n},\n},\n}\nerr = client.Schema().ClassCreator().WithClass(classObj).Do(ctx)\n\n\nI added data with this code:\n_, err := client.Data().Creator().\nWithClassName(className).\nWithProperties(map[string]interface{}{\n“Title”: braveResponse.Web.Results[r].Title,\n“URL”: braveResponse.Web.Results[r].URL,\n“Content”: resp.Response,\n}).\nDo(ctx)\n\n\nFinally I get the data with this code:\ngs := graphql.NewGenerativeSearch().GroupedResult(prompt)\nresponse, err := client.GraphQL().Get().\nWithClassName(className).\nWithFields(\ngraphql.Field{Name: “title”},\ngraphql.Field{Name: “content”},\n).\nWithGenerativeSearch(gs).\nWithNearText((&graphql.NearTextArgumentBuilder{}).\nWithConcepts(string{concepts})).\nWithLimit(200).\nDo(ctx)\n\n\nHere I get an error as Weaviate tries to use llama3. As workaround I had to do this:\nollama cp qwen2.5:7b “llama3”, but this is dirty and not handy.\n\n\nServer Setup Information\n\n\nWeaviate Server Version: latest (git cloned yesterday)\nbuild_wv_version=1.28.0-dev\n\n\nDeployment Method: local, build from sources, and started with:\n./tools/dev/run_dev_server.sh local-ollama\nI even edited the script:\nlocal-ollama)\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true \nDEFAULT_VECTORIZER_MODULE=text2vec-ollama \nENABLE_MODULES=“text2vec-ollama,generative-ollama” \nOLLAMA_MODEL=“qwen2.5:7b” \ngo_run ./cmd/weaviate-server \n–scheme http \n–host “127.0.0.1” \n–port 8080 \n–read-timeout=600s \n–write-timeout=600s\n;;\n\n\nMulti Node? No\n\n\nClient Language and Version:\ngithub.com/weaviate/weaviate-go-client/v4@v4.16.0\ngo1.23.3\n\n\nMultitenancy?: No\n\n\nKind regards,\nJC\n\n----------\n\n[DudaNogueira (2024-11-18T13:21:20.190Z)]: hi @JCP !!\nWelcome to our community \nWhen you first create your collection, and specify the generative configuration, it will set some defaults for you.\nThis is probably your scenario. You can specify the model to use for generation while creating the collection.\nSince 1.27.1 you can also reconfigure that option, setting different generative_config after the collection was created.\nPS: This feature “dynamic RAG” - or the ability to specify different generative configurations - will eventually be available at query time.\nLet me know if that helps!\nThanks!\n\n----------\n\n[JCP (2024-11-19T17:45:30.281Z)]: Hi Duda,\nThank you for your answer!\nI managed to make my code work. It seems I made some error while creating the collection, and it did keep the default llama3. It now uses the right model after re-creation.\nThanks and kind regards!\nJC\n\n----------\n\n[DudaNogueira (2024-11-21T12:35:12.953Z)]: Oh! Glad to hear that, @JCP !\nThanks for sharing!\nIf you need any other help in your Weaviate journey, we are here to help!\n\n----------\n\n[JCP (2024-11-23T20:03:46.676Z)]: Thanks, sure I will!\nFYI, I just posted this about the experience I had so far with your excellent product: My first steps with Weaviate (and why I hate Python ;) )\nKeep up the good work!",
    "date_created": "2024-11-17T14:01:26.592Z",
    "has_accepted_answer": true,
    "title": "client.GraphQL().Get() tries to use llama3 instead of the model I want",
    "topic_id": 7611
  },
  {
    "user_id": 3159,
    "conversation": "[Sherry (2025-01-07T12:41:57.715Z)]: Description\n\nI installed the latest version of weaviate on my local with docker, I would like to know how to access the data with the some kind of GUI console， does it support a default console , or is there a GUI client to access the data?\ndocker run -d \\ \n–name weaviate \n-p 8080:8080 \n-e QUERY_DEFAULTS_LIMIT=20 \n-e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true \n-e PERSISTENCE_DATA_PATH=/var/lib/weaviate \n-e ENABLE_MODULES=text2vec-openai \n-e OPENAI_APIKEY=\n-e CLUSTER_HOSTNAME=weaviate-node \n-e CLUSTER_DISCOVERY_METHOD=none \nsemitechnologies/weaviate:latest\nServer Setup Information\n\nWeaviate Server Version: latest\nDeployment Method: docker\nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[Mohamed_Shahin (2025-01-07T13:30:48.613Z)]: Hello @Sherry,\nWelcome to our community! We’re happy to have you here—enjoy your journey Weaviating!\nWe have a GUI that apps, and tools are designed to internal with Weaviate DB, incredibly helpful and user-friendly. However, these are currently available only within our cloud environment. If you deploy a cluster in our cloud, you’ll be able to access and interact with these features\nimage2015×501 36.7 KB\nBest regards,\nMohamed Shahin\nWeaviate Support\n\n----------\n\n[Sherry (2025-01-08T03:07:54.679Z)]: Hi @Mohamed_Shahin Thanks for your reply \nOne more question: how to set the customized model (I would like to use Zhipu’s model)when I initiate a Weaviate DB instance, and use it to create the object? Can we set the environment variables (DEFAULT_VECTORIZER_MODULE=custom,CUSTOM_VECTORIZER_URL)for the cloud instance?\nversion: '3.4'\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:latest\n    ports:\n      - \"8080:8080\"\n    environment:\n      - QUERY_DEFAULTS_LIMIT=20\n      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true\n      - PERSISTENCE_DATA_PATH=/var/lib/weaviate\n      - DEFAULT_VECTORIZER_MODULE=custom\n      - CUSTOM_VECTORIZER_URL=http://zhipu-api-url/v1/vectorize\n      - CUSTOM_VECTORIZER_API_KEY=your_zhipu_api_key\n\n----------\n\n[Mohamed_Shahin (2025-01-14T14:30:27.547Z)]: Hi @Sherry,\nI am not sure if we currently working on integration with Zhipu models. Our available model providers here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nModel provider integrations | Weaviate\n\n  Weaviate integrates with a variety of self-hosted and API-based models from a range of providers.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAlternatively until then, if you are able to vectorize your data outside of Weaviate, you can embed the vectors into Weaviate using the “Bring Your Own Vectors” feature.\nIf you’d like integration with Zhipu models, you can open a feature request\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nweaviate/weaviate\n\n  Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of ...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBest regards,\nMohamed Shahin\nWeaviate Support",
    "date_created": "2025-01-07T12:41:57.665Z",
    "has_accepted_answer": true,
    "title": "Is there a GUI console to access the db data after install the weaviate?",
    "topic_id": 9609
  },
  {
    "user_id": 3148,
    "conversation": "[tornadijo (2025-01-05T02:26:15.270Z)]: Hello, first of all thank you very much for your time.\nI am experiencing the error:\nlocalhost:11434/api/embed\": dial tcp [::1]:11434: connect: connection refused\"\n\n\nWhich is very much asked already on the forum, but I think that my bug is different.\nI have ollama and weaviate in docker. (latest versions)\nI manage to create a collection without problems to ingest pdf documents:\n\nclient = weaviate.connect_to_local()\nclient.collections.create(\n    name=collection_name,\n    vectorizer_config=Configure.Vectorizer.text2vec_ollama(\n        api_endpoint=\"http://ollama:11434\",\n        model=\"nomic-embed-text\",               \n    ),\n    generative_config=Configure.Generative.ollama(\n        api_endpoint=\"http://ollama:11434\",\n        model=\"llama3.2\",                                       \n    )\n)\n\nAnd I even manage to do nearText or BM25 searchs without errors:\nresponse = questions.query.near_text(query=\"siniestros\", limit=3)\nfor o in response.objects:\n    print(o.properties)\nclient.close()\n\n{'content': 'Los siniestros se resuelven entre 2 y 12 meses.', 'source': 'procedimientos_siniestros [Grupo Impultec - Genei].pdf'}\n{'content': '¿Necesitan peritar la mercancía en caso de siniestro? Las agencias que exigen la peritación son Zeleris, CTT, Seur DPD y UPS. Aunque el resto de agencias también pueden', 'source': 'ayudagenei.pdf'}\n\nBut as soon as I switch to hybrid search, to use embeddings\n:\nresponse = questions.query.hybrid(query=\"siniestros\", limit=3)\n\n\nI get the error:\n File \"/home/carlos/python311/lib/python3.11/site-packages/weaviate/collections/grpc/query.py\", line 805, in __call\n    res = await _Retry(4).with_exponential_backoff(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/carlos/python311/lib/python3.11/site-packages/weaviate/collections/grpc/retry.py\", line 31, in with_exponential_backoff\n    raise e\n  File \"/home/carlos/python311/lib/python3.11/site-packages/weaviate/collections/grpc/retry.py\", line 28, in with_exponential_backoff\n    return await f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/carlos/python311/lib/python3.11/site-packages/grpc/aio/_call.py\", line 327, in __await__\n    raise _create_rpc_error(\ngrpc.aio._call.AioRpcError: <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"remote client vectorize: send POST request: Post \"http://localhost:11434/api/embed\": dial tcp [::1]:11434: connect: connection refused\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-01-05T02:58:16.881580242+01:00\", grpc_status:2, grpc_message:\"remote client vectorize: send **POST request: Post \\\"http://localhost:11434/api/embed\\\": dial tcp [::1]:11434: connect: connection refused\"}\"**\n>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/carlos/codigotfm/weaviate/getpdf2.py\", line 7, in <module>\n    **response = questions.query.hybrid(query=\"siniestros\", limit=3)**\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nMy weaviate docker-compose  (ollama and weaviate are on the same docker network)\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: always\n    environment:\n      OLLAMA_URL: http://ollama:11434\n      OLLAMA_MODEL: llama3.2:latest\n      OLLAMA_EMBED_MODEL: snowflake-arctic-embed:latest\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-ollama'\n      ENABLE_MODULES: 'text2vec-ollama,generative-ollama'\n      CLUSTER_HOSTNAME: 'node1'\n    networks:\n      - ollama-weviate\nvolumes:\n  weaviate_data:\nnetworks:\n  ollama-weviate:\n    name: ollama-weviate\n    external: false\n\n\nSince I have ollama port 11434 exposed to the outside, I can query ollama without any problems:\ncurl http://localhost:11434/api/embed -d '{\n  \"model\": \"nomic-embed-text\",\n  \"input\": \"Why is the sky blue?\"\n}'\n{\"model\":\"nomic-embed-text\",\"embeddings\":[[0.009785417,0.044247437,-0.14055912,0.0012672294,0.032222837,0.10741186,-0.008397134,0.010254115,0.00074357603,-0.035431717,0.033934534,0.062272973,0.102648675,0.08567975,0.023684556,0.033663988,-0.03359353,-0.018589992,0.048080757,-0.027181087,-0.056390814,-0.0436777,0.01647538,-0.035050847,0.063383594,0.043157343,0.03345559...\n\n\nAnd i can also run a query to ollama from inside another container in the same network\ndocker compose exec -ti weaviate sh -c \"wget --header=\\\"Content-Type: application/x-www-form-urlencoded\\\" --post-data=\\$'{\\\\n  \\\"model\\\": \\\"llama3.2:latest\\\",\\\\n  \\\"prompt\\\": \\\"Why is the sky blue?\\\"\\\\n}' --output-document - http://ollama:11434/api/generate\"\nConnecting to ollama:11434 (172.19.0.2:11434)\nwriting to stdout\n{\"model\":\"llama3.2:latest\",\"created_at\":\"2025-01-05T02:30:24.892773828Z\",\"response\":\"The\",\"done\":false}\n{\"model\":\"llama3.2:latest\",\"created_at\":\"2025-01-05T02:30:24.899061635Z\",\"response\":\" sky\",\"done\":false}\n....\n\n\nAnd I have several LLMs running well\ndocker exec ollama ollama list\nNAME                             ID              SIZE      MODIFIED    \nall-minilm:latest                1b226e2802db    45 MB     2 hours ago    \nsnowflake-arctic-embed:latest    21ab8b9b0545    669 MB    2 hours ago    \nllama3:8b-instruct-q5_1          662158bc9277    6.1 GB    2 days ago     \nllama3.2:latest                  a80c4f17acd5    2.0 GB    2 days ago     \ndolphin-mixtral:8x7b             4f76c28c0414    26 GB     3 days ago     \nmistral:instruct                 f974a74358d6    4.1 GB    3 days ago     \nnomic-embed-text:latest          0a109f422b47    274 MB    3 days ago   \n\nI don’t know why the error is about a connection to ollama localhost\n(http://localhost:11434)\n\nif I specify that it is\nhttp://ollama:11434\n\nThank you very much for some help!\n\n----------\n\n[DudaNogueira (2025-01-06T16:03:55.835Z)]: hi @tornadijo !!\nWelcome to our community \nThis has worked for me. Let me know if this helps you:\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: always\n    environment:\n      OLLAMA_URL: http://ollama:11434\n      OLLAMA_MODEL: llama3.2:latest\n      OLLAMA_EMBED_MODEL: snowflake-arctic-embed:latest\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-ollama'\n      ENABLE_MODULES: 'text2vec-ollama,generative-ollama'\n      CLUSTER_HOSTNAME: 'node1'\n    networks:\n      - ollama-weviate\n  ollama:\n    image: ollama/ollama\n    ports:\n      - 11434:11434\n    volumes:\n      - ollama_data:/root/.ollama\n      #- ./entrypoint.sh:/entrypoint.sh\n    container_name: ollama\n    pull_policy: always\n    tty: true\n    restart: always\n    networks:\n      - ollama-weviate    \n    #entrypoint: [\"/bin/bash\", \"/entrypoint.sh\"]      \nvolumes:\n  weaviate_data:\n  ollama_data:\nnetworks:\n  ollama-weviate:\n    name: ollama-weviate\n    external: false\n\nand now the code:\nimport weaviate\nfrom weaviate import classes as wvc\nclient = weaviate.connect_to_local()\nprint(f\"Client: {weaviate.__version__}, Server: {client.get_meta().get('version')}\")\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n        api_endpoint=\"http://ollama:11434\",\n        model=\"nomic-embed-text\",               \n    ),\n    generative_config=wvc.config.Configure.Generative.ollama(\n        api_endpoint=\"http://ollama:11434\",\n        model=\"llama3.2\",                                       \n    )\n)\n\ncollection.data.insert({\"text\": \"Hello World!\"})\n\nprint(collection.generate.fetch_objects(limit=1, single_prompt=\"Translate to Spanish: {text}\").objects[0].generated)\n\n\nthis ouputs:\n\n‘Hola Mundo!\\n\\n(Note: The phrase “Hello World!” is often used as a greeting in programming and computer science, but it's also widely recognized as a traditional way of saying “hello” in English. In this context, the translation is essentially the same.)’\n\n----------\n\n[tornadijo (2025-01-08T21:21:49.554Z)]: Thanks!, it works like a charm!\n\n----------\n\n[DudaNogueira (2025-01-23T14:58:17.259Z)]: hi @AbhinavKasubojula !!\nCan you create a new post and provide the required infos? That helps us to understand your scenario better.\nThanks!\n\n----------\n\n[DudaNogueira (2025-01-23T14:58:19.942Z)]: ",
    "date_created": "2025-01-05T02:26:15.211Z",
    "has_accepted_answer": true,
    "title": "Unable to run hybrid search (but nearText works) : Connection refused to ollama",
    "topic_id": 9569
  },
  {
    "user_id": 3291,
    "conversation": "[Rajat_m7 (2025-01-30T06:25:21.949Z)]: Description\nI am using weaviate to search based on a column in schema. I defined a string as ‘doc_id’ in schema. Doing exact search using filters=wq.Filter.by_property(“doc_id”).equal(doc_id)\nis considering approximate search instead of exact(equals) search. So searching of doc_id =“MY-DOC” is returning “44-MY-DOC” as well and it doesnt work with containsALL and containsAny. How to resolve this ?\n\n----------\n\n[DudaNogueira (2025-01-30T13:30:34.700Z)]: hi @Rajat_m7 !!\nThat’s expected because how you have configured the tokenization. If you didn’t set a specific tokenization for that property it defaults to word.\nCheck here for more on tokenization:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nOverview of tokenization | Weaviate\n\n  Tokenization is the process of breaking text into smaller units, called tokens. This is an important step that impacts how text is processed in a variety of contexts.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThis means that:\n44-MY-DOC will become three tokens: 44 MY and DOC\nMY-DOC will become two tokens: MY and DOC\nIn order to search like you mentioned, you need to set the doc_id to use the field tokenization, so you will endup with a 44-MY-DOC token instead of three separate ones.\nLet me know if this helps!\nTHanks!",
    "date_created": "2025-01-30T06:25:21.898Z",
    "has_accepted_answer": false,
    "title": "Exact Query Filter",
    "topic_id": 9961
  },
  {
    "user_id": 1033,
    "conversation": "[Luka_Secerovic (2024-12-26T14:15:10.707Z)]: I’m using the following code to import to a collection:\nwith collection.batch.dynamic() as batch:\n    for data_row in [\n        {\n            \"filename\": \"feeds.pdf\",\n            \"chunk\": content,\n            \"chunk_n\": 1,\n        },\n...\n    ]:\n        uuid = batch.add_object(\n            properties=data_row,\n        )\n        print(uuid)\n\n\nSome of the objects didn’t get ingested - I noticed that by counting the expected number of documents and the actual number of documents in the db.\nI had to do some debugging and figured it’s because some of the chunks were too big for the embedding model.\nIs there a way to know if an ingestion during batch went correctly? There was no error.\n\n----------\n\n[DudaNogueira (2024-12-26T14:57:08.983Z)]: hi @Luka_Secerovic !!\nYou need to inspect the end result of your batch.\nfor example, consider this code:\nimport weaviate\n\nclient = weaviate.connect_to_local()\nobjects = [\n    {\"text\": \"object 1\", \"vector\": [1,2,3]},\n    {\"text\": \"object 2\", \"vector\": [1,2,3,4,5]},\n]\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\"Test\")\n\nwith collection.batch.dynamic() as batch:\n    for obj in objects:\n        batch.add_object(\n            properties={\"text\": obj[\"text\"]}, \n            vector=obj[\"vector\"]\n        )\n\nthis will not be imported, because we have objects with different sized vectors.\nAfter running this code, you should see the following in logs:\n{'message': 'Failed to send 1 objects in a batch of 2. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\nnow, in collection.batch.failed_objects with have\n\n[ErrorObject(message=‘inconsistent vector lengths: 5 != 3’, object_=_BatchObject(collection=‘Test’, vector=[1.0, 2.0, 3.0], uuid=‘1d64911a-b270-42a6-9346-ecbda0275e9d’, properties={‘text’: ‘object 1’}, tenant=None, references=None, index=0, retry_count=0), original_uuid=‘1d64911a-b270-42a6-9346-ecbda0275e9d’)]\n\nLet me know if that helps!\nThanks!",
    "date_created": "2024-12-26T14:15:10.664Z",
    "has_accepted_answer": false,
    "title": "Batch import silently fails",
    "topic_id": 9460
  },
  {
    "user_id": 2699,
    "conversation": "[jaehyoyoo (2025-02-04T08:45:19.088Z)]: Hi, I’m trying to use weaviate for large-scale text data. But I think Its real usage is too large than I expected.\nI stored about 50GB artifical text for test. There is no extra metadata for each document. The total number of chunks is 10436101, and the dimension of each vector is 1024. As I Know, 2 * vector_size byte is needed for each vector. So, each vector needs 1024 * 2 * 8 bytes, and we have 10436101 chunks so about 170GB is needed as the prediction.\nHowever, We failed to insert due to the lack of storage. We checked the weaviate data and found about 380GB used. property_text, property_text_searchable is the most largest folder, but however, we used 50GB texts, 380GB is too big for our expectations.\nCould I get a brief explanation of how the storage is used?\n\n----------\n\n[DudaNogueira (2025-02-05T19:47:31.704Z)]: hi @jaehyoyoo !!\nThe artificially generated content can contribute for the size of the the index, as it may have lots of words with very few documents.\nWe are working on a new implementation that will make this more efficient, called BlockMax WAND-based BM25, that will be released as experimental in 1.29:\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nRelease v1.29.0-rc.0 - RBAC, Async Replication, ColBERT, Blazing Fast BM25 ·...\n\n  This is a release candidate for the upcoming v1.29.0 release\nA release candidate (RC) means the release is considered feature complete and has finished beta-testing. Any issues discovered during th...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThe current indisk format is not very efficient and wastes a lot of disk space on most properties.\nLet me know if this helps.\nThanks!",
    "date_created": "2025-02-04T08:45:19.034Z",
    "has_accepted_answer": false,
    "title": "Weaviate Disk Usage Question",
    "topic_id": 10013
  },
  {
    "user_id": 2507,
    "conversation": "[AU_Jay (2024-11-15T03:39:34.987Z)]: Hi, there is a self-hosted WeaviateDB (v1.19.0) running by docker compose in my project.  Is it possible to upgrate the DB to the latest version (v1.27.x)?  If yes, what is the steps to upgrate or migrate ? And is there any risk?\n\n----------\n\n[Mohamed_Shahin (2024-11-15T09:21:55.955Z)]: Good morning @AU_Jay,\nWelcome to our community! It’s lovely to have you here.\nThat’s an absolutely great question. Generally, we recommend upgrading one major release at a time as there are new implementations and significant changes that can be crucial. After each upgrade, allow Weaviate to restart and load, then run a node-status check to ensure everything is healthy before proceeding to the next major release. For example:\n• 1.20 > 1.21 > 1.22, and so on.\nIf there’s no higher risk on your end and you have backups, I would suggest using the latest stable release in each major version as follows:\n• 1.19 > 1.23.16\n• 1.23.16 > 1.24.25\n• 1.24.25 > 1.25.21 (RAFT Schema Implementation)\n• 1.25.21 > 1.26.7\n• 1.26.7 > 1.27.3\nI’ve tested locally upgrading from 1.23.16 to 1.25.21 and then from 1.25.21 to 1.27.3. However, please note that my test environment was simple and not representative of more complex use cases.\nAlternatively, if you find this process too complicated, you could spin up a new cluster with the latest version (1.27.3) and migrate your data from the old cluster using the migration scripts available on our website. If you have a small amount of data, the migration should only take a few minutes.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Learn how to migrate data within Weaviate for easy data handling.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI hope that helps",
    "date_created": "2024-11-15T03:39:34.944Z",
    "has_accepted_answer": false,
    "title": "Migrate from v1.19 to v1.27",
    "topic_id": 7581
  },
  {
    "user_id": 2946,
    "conversation": "[e-p-armstrong (2024-12-03T02:12:33.126Z)]: Description\nDescription\nI am running into inconsistent errors regarding not being able to connect to weaviate. This is when I am attempting to run locally with Ollama. The error only appears occasionally; often, regenerating the message will be enough to fix it, but it is occurring very often and is quite annoying:\nINFO:     127.0.0.1:61907 - \"POST /api/get_suggestions HTTP/1.1\" 200 OK\n✔ Received query: somequery\n✔ Connecting new Client\nℹ Connecting to Weaviate Embedded\n✘ Couldn't connect to Weaviate, check your URL/API KEY: Embedded DB did\nnot start because processes are already listening on ports http:8079 and\ngrpc:50050use weaviate.connect_to_local(port=8079, grpc_port=50050) to connect\nto the existing instance\n⚠ Query failed: Couldn't connect to Weaviate, check your URL/API KEY:\nEmbedded DB did not start because processes are already listening on ports\nhttp:8079 and grpc:50050use weaviate.connect_to_local(port=8079,\ngrpc_port=50050) to connect to the existing instance\nINFO:     127.0.0.1:61898 - \"POST /api/query HTTP/1.1\" 200 OK\n✔ Succesfully Connected to Weaviate\n\n(I can’t embed multiple things in a post here so here’s a link to the github issue I am mostly crossposting this from: \"Couldn't connect to Weaviate, check your URL/API KEY\" · Issue #335 · weaviate/Verba · GitHub)\nSo I don’t know why this is failing sometimes and succeeding others:\nimage1460×772 72.4 KB\n^ Example of two failed tries and one success, the only difference between them being the time of the submission\nInstallation\n\n[ x ] pip install goldenverba\n pip install from source\n Docker installation\n\nIf you installed via pip, please specify the version:\nPython version? 3.11\npackage version? Whatever’s latest on pip\nWeaviate Deployment\n\n[x ] Local Deployment\n Docker Deployment\n Cloud Deployment\n\nConfiguration\nReader: ?\nChunker: ?\nEmbedder: Ollama (nomic embed text)\nRetriever: Advanced\nGenerator: Ollama (custom finetuned llama 3)\nSteps to Reproduce\nPip install;\nRun both embedding and generator with ollama\nUpload 47 .md documents\nchat a few times\nexperience issue\nAdditional context\nFor some reason Verba does not seem to be working when offline either, even though I assume local deployment is just that – local. What’s going on and how do I force this to 1) run locally and 2) correctly connect to the server so I don’t get this issue? I’ll make a separate post for true local running issues if need be, I put the full traceback for the second issue (not being able to run local offline) in a gist so that it doesn’t clutter this post up needlessly: offline_run_attempt · GitHub\n\n----------\n\n[DudaNogueira (2024-12-03T12:49:09.856Z)]: hi @e-p-armstrong !! Welcome to our community \nConsidering the error message, it seems that there you have another weaviate embedded running before starting Verba.\nif you run:\nps aux | grep weaviate\n\nyou should see a running weaviate server. You need to kill that PID before starting verba, otherwise you will run in to this issue.\nLet me know if I can assist you further on this.\nThanks!",
    "date_created": "2024-12-03T02:12:33.069Z",
    "has_accepted_answer": false,
    "title": "[Verba] On sending message: \"Couldn't connect to Weaviate, check your URL/API KEY\"",
    "topic_id": 9062
  },
  {
    "user_id": 3247,
    "conversation": "[fiellin (2025-01-21T16:46:25.906Z)]: Hi, I’m building Weaviate with Docker and have set the volume to a server path user/weaviate-data. I tried moving my Docker Compose setup to a different location but did not modify the existing configuration, including the cluster name and other settings. When I rebuild and test, the logs from Weaviate show that a new shard is being created in user/weaviate-data.\nFor example, instead of using the existing user/weaviate/name_of_collection/Qf7ezAZ8ZUPp, it creates a new one like user/weaviate/name_of_collection/jLqfginscazS. Is there a way to use the existing local data?\nThank you in advance!\n\n----------\n\n[DudaNogueira (2025-01-27T20:46:24.176Z)]: hi @fiellin !!\nWelcome to our community! \nNot sure I understood the steps you went were. \nLet’s say you have a folder named my_app, with:\n\nfolder: weaviate_data (mapped to weaviate)\nfile: compose.yaml\n\nYou then moved that folder to a different location?\nTHanks!",
    "date_created": "2025-01-21T16:46:25.863Z",
    "has_accepted_answer": false,
    "title": "Issue with Shard Creation After Moving Docker Compose Setup - How to Use Existing Local Data?",
    "topic_id": 9840
  },
  {
    "user_id": 778,
    "conversation": "[Mariam (2024-08-07T06:24:10.518Z)]: Description\nWhen can we expect to have a production-grade embedded model ready for local deployment?\n\n----------\n\n[DudaNogueira (2024-08-07T18:39:32.337Z)]: Hi @Mariam !\nFor production grade I understand that it must be a multi node cluster.\nI don’t think the Weaviate Embedded install method will be able to deliver that alone.\nWhat this installation method does is to run Weaviate go binary directly from the client.\nSo for running locally, there are tools that can better manage Weaviate as a service, using for example docker or supervisord.\nLet me know if this helps!\nThanks!",
    "date_created": "2024-08-07T06:24:10.461Z",
    "has_accepted_answer": false,
    "title": "By when we would have a production grade embedded model for local serve?r deployment?",
    "topic_id": 3284
  },
  {
    "user_id": 164,
    "conversation": "[alt-glitch (2023-07-10T05:53:47.535Z)]: Hi\nJust starting out with Weaviate. I had a 1000 documents that i split into 200 size chunks. I then attempted importing them into weaviate. Mostly followed the tutorial and getting started guides.\nFollowing is the schema and the import code.\nclass_obj = {\n    'class': 'className',\n    'description': 'description',\n    'properties': [\n        {\n            'name': 'title',\n            'description': 'Title',\n            'dataType': ['text']\n        },\n        {\n            'name': 'source',\n            'description': 'Source',\n            'dataType': ['text']\n        },\n        {\n            'name': 'content',\n            'description': 'Content',\n            'dataType': ['text']\n        },\n    ],\n    'vectorizer': 'text2vec-openai',\n    'moduleConfig': {\n        'text2vec-openai': {  # this must match the vectorizer used\n            'vectorizeClassName': False,\n            'model': 'ada',\n            'modelVersion': '002',\n            'type': 'text'\n       }\n    }\n}\n\n# ===== Import data =====\n# Configure the batch import\nclient.batch.configure(\n    batch_size=100,\n)\n\nfor document in documents:\n    properties = {\n        \"title\": document.metadata[\"title\"],\n        \"content\": document.page_content,\n        \"source\": document.metadata[\"source\"]\n    }\n    try:\n        client.batch.add_data_object(properties, \"className\")\n    except Exception as e:\n        print(e)\n        print(document.metadata[\"title\"])\n\nclient.batch.flush()\n\nHowever this took quite a bit of time, 30+ mins and at the only about 60% of the documents had been added to weaviate. I am using OpenAI to generate embeddings.\nWhat is the bottleneck in this situation?\nMy theory is that i’m being rate limited by OpenAI.\n\n----------\n\n[jphwang (2023-07-10T09:00:47.507Z)]: Hi @alt-glitch - welcome!\nThat does seem like it’s taking a while. Some questions to help us diagnose:\n\nWhat version of Weaviate are you running?\nWhat version of the Weaviate client are you running?\nAre you running Weaviate locally or on the cloud?\nHow many objects are you importing, given the chunk size? (or, how long are the documents?)\n\nAdditionally, I see that the batch process is not instantiated explicitly. We recommend using a context manager like this:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\n(Batch) Import items | Weaviate - vector database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nDoes it make a difference if you instantiate the batch with with client.batch() as batch: and add the data accordingly?\nCheers,\nJP\n\n----------\n\n[Dirk (2023-07-10T15:41:26.296Z)]: a) Is there any output from the client?\nb) Could you try a smaller batch size?\n\n----------\n\n[alt-glitch (2023-07-11T02:02:53.804Z)]: Hello! Thanks for the response!\nI am running Weaviate version: 1.19.11 in a trial cluster on the cloud. Using the weaviate python client version 3.22.1.\nI instantiated the batch as you mentioned, reduced the number of documents and the number of workers (so as to not hit OpenAI’s limit)\nThe problem seems to have been solved. Now the documents get indexed within a couple minutes.\nThank you!\n\n----------\n\n[Amir_Sohail (2024-09-27T10:55:32.326Z)]: Hi @Dirk I am using weaviate with llamindex and running custom weaviate instance on ec2. When I upload a document of around 300 pages and create embeddings it takes around 10 minutes but still keeps running. But when I run my flask code and weaviate instance locally it completes the same file embeddings in 1 minute.",
    "date_created": "2023-07-10T05:53:47.339Z",
    "has_accepted_answer": true,
    "title": "Indexing embeddings taking too long. What am I doing wrong?",
    "topic_id": 342
  },
  {
    "user_id": 977,
    "conversation": "[Nancy_Viviana_Espino (2024-08-16T14:42:20.916Z)]: Good morning!\nA question, we are batch processing a set of data, we have noticed that after processing the first batch we started to receive this error:\n Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.DEADLINE_EXCEEDED\n\tdetails = \"Deadline Exceeded\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-08-15T22:09:21.067965744-04:00\", grpc_status:4, grpc_message:\"Deadline Exceeded\"}\"\n>.  [level: ERROR]\nException in thread Thread-30 (worker_thread):\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/weaviate/collections/grpc/query.py\", line 762, in __call\n    res = await self._connection.grpc_stub.Search(\n  File \"/usr/local/lib/python3.10/site-packages/grpc/aio/_call.py\", line 318, in __await__\n    raise _create_rpc_error(\ngrpc.aio._call.AioRpcError: <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.DEADLINE_EXCEEDED\n\tdetails = \"Deadline Exceeded\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-08-15T22:09:21.067965744-04:00\", grpc_status:4, grpc_message:\"Deadline Exceeded\"}\"\n\nwe have tried to change the batch size, but something similar happens to us, after processing a small number of batches they start to appear. what we do is to find for each vector the nearest vectors (query.near_object).\ndoes anybody know if it could be because of the number of vectors? do you know how we can optimize this process?\n\nweaviate-client = “4.7.1”\nversion=“1.24.9”\n\n----------\n\n[DudaNogueira (2024-08-16T18:50:44.318Z)]: hi @Nancy_Viviana_Espino !!\nWhat is the batch configuration you are using?\nWe suggest using something like this as a base, and start tweaking the batch size and concurrent requests according to the resources you have for you cluster:\nwith movies.batch.fixed_size(batch_size=20, concurrent_requests=2) as batch:\n    for i, row in df.iterrows():\n        obj_body = {\n            c: row[c] for c in data_columns\n        }\n        batch.add_object(\n            properties=obj_body\n        )\n\nLet me know if this helps.\nThanks!\n\n----------\n\n[Nancy_Viviana_Espino (2024-08-16T19:14:31.604Z)]: Thank you for reviewing this case.\nI would like to clarify that we use batches mainly to process our vectors, and not to add data to the collection. However, we have faced a problem when searching for nearby vectors, as there is a disconnect in the GRCP communication. Also, I mentioned that we process each batch on a different thread, with the intent to determine if I might be overloading the system by using this connection.\n\n----------\n\n[DudaNogueira (2024-08-16T19:19:14.375Z)]: You mean that you ingest not only the data but also the vectors, right?\nYou can also do that with batch:\nwith collection.batch.dynamic() as batch:\n    for i, data_row in enumerate(data_rows):\n        batch.add_object(\n            properties=data_row,\n            vector=vectors[i]\n        )\n\nDo you have any readings on this cluster memory and cpu usage? do they still have resources?\nHow is this cluster deployed? Have you tried changing some of the options as stated here?\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nResource Planning | Weaviate - Vector Database\n\n  Weaviate scales well for large projects. Smaller projects, less than 1M objects, do not require resource planning. For medium and large-scale projects, you should plan how to get the best performance from your resources. While you design you system,...\n\n----------\n\n[Nancy_Viviana_Espino (2024-08-16T20:10:48.641Z)]: Effectively, we generate the vectors in another independent flow and, during this process we download them, upload them to a collection in order to process them and find the closest one for each vector. I have been monitoring the process and have noticed some warning messages, such as the following:\n/usr/local/lib/python3.10/asyncio/selector_events.py:701: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=598 read=idle write=<idle, bufsize=0>>\n  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n\nI leave an image of the memory and cpu monitor.\nScreenshot 2024-08-16 at 3.05.43 PM940×207 22.1 KB\n\n----------\n\n[DudaNogueira (2024-08-19T15:41:04.099Z)]: Hi @Nancy_Viviana_Espino !\nHow are you uploading the vectors? Have you tried changing some config as per the resource planning doc?\nOne option is try using the ASYNX_INDEXING.\nMy guess here is that the cluster is having a hard time both indexing your content and ingesting new data.",
    "date_created": "2024-08-16T14:42:20.867Z",
    "has_accepted_answer": false,
    "title": "GRCP connection failure when processing data-intensive batches",
    "topic_id": 3372
  },
  {
    "user_id": 3462,
    "conversation": "[pdp (2025-02-16T17:30:38.778Z)]: Description\nOur “serverless” cluster is failing to insert new records due to disk usage being to high.\nput object: import into index record: put local object: shard=“C3Alih6pvtKv”: store is read-only due to: disk usage too high. Set to read-only at 90.38%, threshold set to 90.00%\"\nServer Setup Information\n\nWeaviate Server Version: 1.28.4\nDeployment Method: serverless\nMulti Node? Number of Running Nodes: serverless\nClient Language and Version: curl\nMultitenancy?: no\n\nAny additional Information\nI am confused as to what serverless offering does as it seems to me it does it not scale well at all with errors like this.\n\n----------\n\n[DudaNogueira (2025-02-16T20:34:50.881Z)]: hi @pdp !!\nThis can happen on recently created clusters, where the disk usage is not known yet.\nNow, when you start ingesting objects, and do it aggressively, the auto scaler will not have enough time to kick in.\nOnce we provision enough disk, it can support more aggressive imports as it has more room and data to work with.\nFor any issues related to clusters hosted at our cloud, the best place for support is from our Console, where you will be instructed on how to create a support ticket.\nThis will help us get access to your cluster and fix it faster.\nLet me know if that helps!\nThanks!\n\n----------\n\n[pdp (2025-02-16T20:56:48.249Z)]: Hey, thanks for the reply.\nI did reach out to the support team but nothing yet.\nIs it normal for the cluster to be in this state for 4 hours?\n\n----------\n\n[DudaNogueira (2025-02-17T12:27:36.921Z)]: Hi @pdp !!\nIt is not normal. Sorry for the inconvenience.\nif you create a new cluster in our cloud and want to perform an aggressive ingestion in a short period of time, you can reach out to us so we can allocate enough resources beforehand, so you migration/ingestion can go smoothly.\nPlease, let me know if you got  a response already from the support line.\nThanks!",
    "date_created": "2025-02-16T17:30:38.719Z",
    "has_accepted_answer": false,
    "title": "Weviate Serverless Disk Usage Too High",
    "topic_id": 10407
  },
  {
    "user_id": 1159,
    "conversation": "[bahtman (2024-07-04T08:35:42.254Z)]: Description\nWe are currently ingesting multiple documents from 3-4 sources into a single Class. We would like users of our RAG application to choose which of the sources to use for grounding answers.\nOur proposed solution would be to use filters at query time to get relevant chunks. We worry that having a single Class, with nightly delta loads to update the chunks might be too instable. (We’ve had issues with delete operations corrupting a Class)\nIs there a best practice, for this particular setup?\nThank you in advance!\nAnton\nServer Setup Information\n\nWeaviate Server Version: 1.25.0\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 2\nClient Language and Version: Python 4.5.2\nMultitenancy?: Not currently\n\n----------\n\n[DudaNogueira (2024-07-04T20:52:00.395Z)]: hi @bahtman !! Welcome to our community \nCould you elaborate more on the issues you had with nightly delta loads and how are you doing it? Also, was it in latest 1.25 or older versions?\nIf you have have a high number of update/delete operations, a good tip is to tune the TOMBSTONE env var. Also monitoring those metrics.\nWhen you delete an object, Weaviate will not delete it right away, as those operations are costly. It will mark it as deleted and process it later.\nMore info on this here: Weaviate, a vector database with ANN Index and CRUD support | Weaviate - Vector Database\nRegarding your question, you could treat each document as a tenant, or a separate collection, however, it wouldn’t be possible to let the user to select for more than one of those documents to perform a query.\nWith that said, having a property to filter on document is usually the best approach.\nAs a best practice, I believe you could check out how we do it in Verba: GitHub - weaviate/Verba: Retrieval Augmented Generation (RAG) chatbot powered by Weaviate.\nLet me know if this helps!\nThanks!\n\n----------\n\n[ottman (2024-07-08T09:49:29.792Z)]: Hi @DudaNogueira\nI am a colleague of @bahtman.\nWe are currently using version 1.25.4, and has since had a “corruption” issue again.  Our delta load runs every hour, and does a “delete_many” operation from the Python library (V. 4.5.2). Seemingly randomly the collection becomes corrupted, and will return\n“Query call with protocol GRPC search failed with message explorer: get class: vector search: object vector search at index xyz: shard xyz_6vkltMpybcdF: vector search: entrypoint was deleted in the object store, it has been flagged for cleanup and should be fixed in the next cleanup cycle”\nIf i check the logs in k8s i can also find this operation;\n{“action”:“hybrid”,“error”:“explorer: get class: vector search: object vector search at index xyz: remote shard 6vkltMpybcdF: status code: 500, error: shard xyz_6vkltMpybcdF: vector search: entrypoint was deleted in the object store, it has been flagged for cleanup and should be fixed in the next cleanup cycle\\n: context deadline exceeded”,“level”:“error”,“msg”:“denseSearch failed”,“time”:“2024-07-05T11:13:40Z”}\nThis happened friday, and if i try to query the collection now it will still throw the same error.\nWhat do you propose here for settings with regards to tombstone? We are okay with deleting often if it means we can avoid this “corruption” issue \nBest regards,\nAnders\n\n----------\n\n[DudaNogueira (2024-07-08T17:40:18.735Z)]: hi @ottman !\nHave you tried defining a value for TOMBSTONE_DELETION_MAX_PER_CYCLE?\nThis can help. Also, I suggest upgrading to the latest 1.25.X as those issues have surfaced recently and there are patches on latest verison, IIRC\n\n----------\n\n[ottman (2024-07-09T06:03:24.651Z)]: Hi @DudaNogueira, thanks for the quick reply.\nI just checked again and we are actually using version 1.25.6 where this problem occur. What kind of value would you recommend for TOMBSTONE_DELETION_MAX_PER_CYCLE? Its a fairly small cluster (for now) so we only have ~ 10k object shards on each node.\n\n----------\n\n[DudaNogueira (2024-07-09T11:17:16.685Z)]: Hi!\non that case, this shouldn’t interfere.\nas per the doc:\n\nMaximum number of tombstones to delete per cleanup cycle. Set this to limit cleanup cycles, as they are resource-intensive. As an example, set a maximum of 10000000 (10M) for a cluster with 300 million-object shards. (Default: none)\n\n10k objects isn’t that much to consume significant resources to degrade performance.\n\n----------\n\n[ottman (2024-07-09T11:50:20.555Z)]: That sounds good @DudaNogueira. Do you have any other idea why we end up with the corrupted collection/shard then? The only fix is essentially to delete the collection and recreate it - but eventually it happens again.\n\n----------\n\n[DudaNogueira (2024-07-09T14:22:19.822Z)]: We have just released a patch (1.25.7) and on previous versions there were some fix around that.\nAre you running 1.25.0?\nDo you see the same results on latest 1.25.7?\n\n----------\n\n[ottman (2024-07-10T06:32:12.901Z)]: That sounds great @DudaNogueira. We are at 1.25.6 currently (helm version 17.1.0). I would like to upgrade to 1.25.7, but there are not helmchart with that version yet.\n\n----------\n\n[DudaNogueira (2024-07-11T20:26:00.076Z)]: hi!\nYou can define specific Weaviate version on your values.yml here\nSo you change the values.yaml and upgrade the helm deployment.\nLet me know if that helps.\nThanks!\n\n----------\n\n[ottman (2024-07-12T12:24:49.910Z)]: I tried updating to 1.25.7 - i will return next week with whether it helped or not. Thank you for the help so far!",
    "date_created": "2024-07-04T08:35:42.210Z",
    "has_accepted_answer": false,
    "title": "Best practice of representing sources for RAG applications",
    "topic_id": 2932
  },
  {
    "user_id": 1303,
    "conversation": "[marekzebrowski (2024-08-12T17:09:31.456Z)]: I have a behavior that I can’t explain:\nI have a docker image - python:3.11 weaviate client 4.7.1\ncode is super simple:\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=WV_URL,  # Replace with your Weaviate Cloud URL\n    auth_credentials=Auth.api_key(WV_APIKEY), \n)```\n\nand the best part - the same docker image when run locally connects fine, but run from other environment - inside kubernetes on amazon fails with:\n\nTraceback (most recent call last):\nFile \"/app/server.py\", line 21, in <module>\nclient = weaviate.connect_to_weaviate_cloud(\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.11/site-packages/weaviate/connect/helpers.py\", line 79, in connect_to_weaviate_cloud\nreturn __connect(\n^^^^^^^^^^\nFile \"/usr/local/lib/python3.11/site-packages/weaviate/connect/helpers.py\", line 410, in __connect\nraise e\nFile \"/usr/local/lib/python3.11/site-packages/weaviate/connect/helpers.py\", line 406, in __connect\nclient.connect()\nFile \"/usr/local/lib/python3.11/site-packages/weaviate/syncify.py\", line 23, in sync_method\nreturn _EventLoopSingleton.get_instance().run_until_complete(\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.11/site-packages/weaviate/event_loop.py\", line 40, in run_until_complete\nreturn fut.result()\n^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.11/concurrent/futures/_base.py\", line 456, in result\nreturn self.__get_result()\n^^^^^^^^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\nraise self._exception\nFile \"/usr/local/lib/python3.11/site-packages/weaviate/client_base.py\", line 152, in connect\nawait self._connection.connect(self._skip_init_checks)\nFile \"/usr/local/lib/python3.11/site-packages/weaviate/connect/v4.py\", line 146, in connect\nawait self._open_connections(self._auth, skip_init_checks)\nFile \"/usr/local/lib/python3.11/site-packages/weaviate/connect/v4.py\", line 239, in _open_connections\nself.__make_clients()\nFile \"/usr/local/lib/python3.11/site-packages/weaviate/connect/v4.py\", line 228, in __make_clients\nself._client = self.__make_async_client()\n^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.11/site-packages/weaviate/connect/v4.py\", line 222, in __make_async_client\nreturn AsyncClient(\n^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.11/site-packages/httpx/_client.py\", line 1389, in __init__\nsuper().__init__(\nFile \"/usr/local/lib/python3.11/site-packages/httpx/_client.py\", line 183, in __init__\nself.headers = Headers(headers)\n^^^^^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.11/site-packages/httpx/_models.py\", line 72, in __init__\nself._list = [\n^\nFile \"/usr/local/lib/python3.11/site-packages/httpx/_models.py\", line 76, in <listcomp>\nnormalize_header_value(v, encoding),\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.11/site-packages/httpx/_utils.py\", line 53, in normalize_header_value\nreturn value.encode(encoding or \"ascii\")\n\nProbably environment error, but is there a way to debug it ?\n\n----------\n\n[DudaNogueira (2024-08-12T19:51:42.877Z)]: hi @marekzebrowski !!\nWelcome to our community \nthe connect_to_weaviate_cloud should only be used when connecting to our cloud.\nAnd thats because we have a specific way of exposing our weaviate instances, as you can see here.\nIf you expose your cluster exactly like we do in our cloud, you could also use that method too.\nSo client.connect_to* methods will “configure” how the client connects to the server.\nWith that said, you will want to take a look at connect_to_custom, and provide all the hosts/ports/security you have used to properly expose your Weaviate cluster.\nCheck here for more on connect_to_custom\nfor example, this is the equivalent to connect_to_local\nimport weaviate\n\nclient = weaviate.connect_to_custom(\n    http_host=\"localhost\",\n    http_port=\"8080\",\n    http_secure=False,\n    grpc_host=\"localhost\",\n    grpc_port=\"50051\",\n    grpc_secure=False,\n    headers={\n        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\")  # Or any other inference API keys\n    }\n)\n\nLet me know if this helps \nThanks!\n\n----------\n\n[marekzebrowski (2024-08-12T21:49:23.714Z)]: but… I am trying to connect to weaviate cloud - in both cases. wqpzmrins6y4jyhqg4pvcw.c0.europe-west3.gcp.weaviate.cloud to be specific.\nI don’t expect anything special in the client - I suspect networking inside k8s to be tainted. I just wonder if there is a way to debug such problem - like debug log or something similar.\n\n----------\n\n[DudaNogueira (2024-08-12T23:16:40.717Z)]: Oh @marekzebrowski !! I am really sorry.\nI though you were running Weaviate on Kubernetes \nWeaviate will provide basically two endpoints, HTTP and GRPC.\nfor testing http a simple curl to the endpoint will be enough.\nFor GRPC, you can use a tool called grpcurl.\non this thread there is an explanation on how to do that:\n\n  \n    \n    \n    Weaviate with Traefik and gRPC Support\n  \n  \n    Hi @qnlbnsl ! Sorry for the delay here. \nLooks like I was finally able to tame this \nHere is what I got: \nNOTE: Check this updated gist on how to correctly expose Weaviate under SSL/TLS using Traefik and running everything with a docker compose \n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:1.23.5\n    #ports:\n    # - 8081:8080 # unsafe http\n    # - 50052:50051 # unsafe grpc…\n  \n\n\nLet me know if this heps.\n\n----------\n\n[ajay (2024-10-07T10:39:43.415Z)]: @marekzebrowski Is this issue resolved? I am also facing similar issue.\n\n----------\n\n[marekzebrowski (2024-10-07T11:52:32.000Z)]: YES. It turned out to be bad decoding of AWS secret, that mangled API key.\nin AWS use none instead of auto - that helped me.\n\n----------\n\n[ajay (2024-10-07T14:53:38.103Z)]: do you mean weaviate api key was incorrect that was read from AWS secret? I did not follow you completely.\n\n----------\n\n[marekzebrowski (2024-10-07T18:18:56.000Z)]: Exactly. Root cause of my problem was decoding of AWS secret. In that secret I stored Weaviate api key.\n\n----------\n\n[DudaNogueira (2024-10-14T21:17:03.966Z)]: Thanks for sharing, @marekzebrowski !!!",
    "date_created": "2024-08-12T17:09:31.376Z",
    "has_accepted_answer": true,
    "title": "[Question] Python - weaviate client 4.0 cannot connect from inside kubernetes",
    "topic_id": 3335
  },
  {
    "user_id": 3135,
    "conversation": "[darklord.thevader (2025-01-04T10:19:41.637Z)]: I have installed langchain core community on my server and weaviate community on my server through docker image, Weaviate is running properly, however REST api are not functioning properly which is another issue, however the core concern is that I felt API might not be required since Langchain and Weaviate being on same server can integrate easily with langchain framework.\nHowever I have tried couple of times but not getting luck.\nCan you please tell me what is the process of integrationg of weaviate with langchain ? are there any quick connectors which we can use like python driver or anything?\nRegards\n\n----------\n\n[DudaNogueira (2025-01-06T14:03:45.650Z)]: Hi @darklord.thevader !!\nConnecting Langchain + Weaviate is a matter of passing a working client into the Vector Store instantiation.\nI have written a recipe for langchain here:\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/llm-frameworks/langchain/loading-data at main ·...\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHave seen those?\nCan you provide any error logs?\nThanks!",
    "date_created": "2025-01-04T10:19:41.588Z",
    "has_accepted_answer": false,
    "title": "Integrating Weaviate Community with Langchain Core",
    "topic_id": 9562
  },
  {
    "user_id": 1255,
    "conversation": "[HYK97 (2024-07-29T01:09:57.288Z)]: I’m currently doing the following for my index\nI want to be able to embed and use it externally, so I’m using the\nConfigure.Vectorizer.none()\nindexing\n    wv_client.collections.create(\n        name=class_name,\n        description=\"건강 식품 컬렉션\",\n        replication_config=Configure.replication(\n            factor=1\n        ),\n        vectorizer_config=Configure.Vectorizer.none(),\n        vector_index_config=Configure.VectorIndex.hnsw(\n            distance_metric=VectorDistances.COSINE\n        ),\n        properties=[\n            Property(name=\"product_no\", description=\"상품 번호\", data_type=DataType.NUMBER),\n            Property(name=\"original_review\", description=\"원본 리뷰\", data_type=DataType.TEXT,\n                     tokenization=Tokenization.WORD),\n            Property(name=\"original_title\", description=\"원본 상품명\", data_type=DataType.TEXT,\n                     tokenization=Tokenization.WORD),\n            Property(name=\"original_detail\", description=\"원본 OCR\", data_type=DataType.TEXT,\n                     tokenization=Tokenization.WORD),\n            Property(name=\"title\", description=\"상품명\", data_type=DataType.TEXT),\n            Property(name=\"review\", description=\"리뷰\", data_type=DataType.TEXT),\n            Property(name=\"detail\", description=\"OCR\", data_type=DataType.TEXT)\n        ]\n    )\n\n......\n\n    with coll.batch.dynamic() as batch:\n        for i, item in enumerate(dumps):\n            product_no = item['product_no']\n            product_name = item['prd_nm']\n            review_text = item['review_text']\n            ocr_text = item['ocr_text']\n\n            title_embedding, review_embedding, detail_embedding = embeddings[i * 3:i * 3 + 3]\n            title_embeddings.append(title_embedding)\n            review_embeddings.append(review_embedding)\n            detail_embeddings.append(detail_embedding)\n\n            uuid = generate_uuid5(product_no)\n            batch.add_object(\n                properties={\n                    \"product_no\": product_no,\n                    \"original_title\": product_name,\n                    \"original_review\": review_text,\n                    \"original_detail\": ocr_text\n                },\n                vector={\n                    \"title\": title_embedding,\n                    \"review\": review_embedding,\n                    \"detail\": detail_embedding\n                },\n                uuid=uuid\n            )\n\n\nThe problem is that I get this error when searching, how do I fix it?\nsearch\ndef search_weaviate(client, query_vector, class_name, feature, limit):\n    col = client.collections.get(class_name)\n    results = col.query.near_vector(near_vector=query_vector, limit=limit,\n                                    return_properties=[\"product_no\", \"original_review\"],\n                                    include_vector=\"True\",\n                                    return_metadata=MetadataQuery(distance=True,\n                                                                  creation_time=True),\n                                    target_vector=\"detail\")\n\n    ....\n\n    client.close()\n\nQuery call with protocol GRPC search failed with message extract target vectors: class Health_food does not have named vector detail configured. Available named vectors map[].\n\n----------\n\n[DudaNogueira (2024-07-29T15:43:37.544Z)]: hi @HYK97\nYou never defined a named vector called detail in your collection.\nSo all vectors you add to this collection, will be added to the default named vector, called default\nTo fix this issue, you can either remove the target_vectors parameter, or set it to “default”\nLet me know if this helps.\nThanks!\n\n----------\n\n[HYK97 (2024-07-30T05:16:36.460Z)]: HYK97:\n\n                vector={\n                    \"title\": title_embedding,\n                    \"review\": review_embedding,\n                    \"detail\": detail_embedding\n                },\n\n\n\nDoesn’t this create a named vector?\nI thought I was creating 3 vectors like above and searching them using target_vector.\nBecause it saved the data properly, as shown in the photo below!\n\nIf you clear the target_vector parameter, it will not respond with any value when debugging, as shown in the photo below\nimage1182×1400 151 KB\n\n----------\n\n[DudaNogueira (2024-07-30T20:21:28.763Z)]: Hi!\nThat would be a cool feature, hahaha.\nI am not sure it creates, to be honest. AFAIK, the Auto Schema should only kick in for property.\nI have written some code here to do what you want:\n  \n    \n    \n    [Question] YOUR TOPIC Support\n  \n  \n    hi! \nYou never defined the named vectors to begin with  \nCheck here some nice academy we have about this: \n\nthis is how your collection should look like: \nimport weaviate\nfrom weaviate import classes as wvc\n\nclient = weaviate.connect_to_local()\n\nfrom weaviate import classes as wvc\n\nclient.collections.delete(\"MyCollection\")\nclient.collections.create(\n        name=\"MyCollection\",\n        description=\"collection_1\",\n        replication_config=wvc.config.Configure.replication(\n            …\n  \n\n\nLet me know if this helps.\nThanks!",
    "date_created": "2024-07-29T01:09:57.218Z",
    "has_accepted_answer": false,
    "title": "Own embedding value not vector search",
    "topic_id": 3201
  },
  {
    "user_id": 1086,
    "conversation": "[mathieu (2024-10-02T08:53:50.700Z)]: I deployed Weaviate on a Kubernetes cluster using a Helm chart deployment. The cluster has 2 nodes and 6 pods, which allows Weaviate to manage sharding and replication. However, I have a problem: when one of the pods becomes unhealthy (ressources reason for exemple), the connection to Weaviate remains active so that’s good, but data indexing fails on this unhealthy pod. What’s more, the data is not automatically redirected to the other healthy pods. How can I solve this problem to ensure that indexing is redirected to functional pods ?\n\n----------\n\n[DudaNogueira (2024-10-02T12:19:37.843Z)]: hi @mathieu ! The number of nodes shouldn’t matter here as it is the number of pods that will make it resilient or not.With that said, and considering that your cluster has 6 pods, are you creating the collection with the correct replication factor?\nCheck here more about replication, specially this part",
    "date_created": "2024-10-02T08:53:50.651Z",
    "has_accepted_answer": false,
    "title": "[Question] Unhealthy pod : redirected indexation to healthy pods while indexing",
    "topic_id": 4399
  },
  {
    "user_id": 1074,
    "conversation": "[DeltaBoukensha (2024-12-31T15:56:13.656Z)]: Hi I am using the latest v4 weaviate client and wish to query a collection using nearText and filter by properties at the same time. How can I achieve this? Thanks\n\n----------\n\n[DudaNogueira (2025-01-02T17:34:05.135Z)]: hi @DeltaBoukensha !!\nWelcome to our community \nCheck here how you can filter by properties:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nFilters | Weaviate\n\n  Filters let you include, or exclude, particular objects from your result set based on provided conditions.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor instance:\nfrom weaviate.classes.query import Filter\n\njeopardy = client.collections.get(\"JeopardyQuestion\")\nresponse = jeopardy.query.fetch_objects(\n    filters=Filter.by_property(\"round\").equal(\"Double Jeopardy!\"),\n    limit=3\n)\n\nfor o in response.objects:\n    print(o.properties)\n\nLet me know if this helps!\nThank!\n\n----------\n\n[DeltaBoukensha (2025-03-17T05:41:40.954Z)]: Hi thanks for reply. How do I use filters in combination with nearText queries?\nIn your example you filter only by the property round.\nIf there would be another property called “description” how could I for example filter by description nearText “positive customer review” AND property round AND datetime perhaps?\n\n----------\n\n[DudaNogueira (2025-03-17T14:30:43.787Z)]: hi @DeltaBoukensha !!\nYou can filter with multiple conditions and nested filters.\nFor example:\nfrom weaviate.classes.query import Filter\n\nfilters = Filter.by_property(\"answer\").like(\"*bird*\") &\n            (Filter.by_property(\"points\").greater_than(700) | Filter.by_property(\"points\").less_than(300))\n\njeopardy = client.collections.get(\"JeopardyQuestion\")\nresponse = jeopardy.query.fetch_objects(\n    filters=filters,\n    limit=3\n)\n\nfor o in response.objects:\n    print(o.properties)\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[DeltaBoukensha (2025-03-18T13:16:57.170Z)]: Like function seems to be a regexp. Is there a way to combine and use nearText search instead? Or otherways to combine vector search?\nIf it is not possible please just say so instead of suggesting alternatives. I would prefer you just confirm that it is not possible to use nearText search in combination with other filters.\n\n----------\n\n[DeltaBoukensha (2025-03-18T13:36:58.534Z)]: I tried this but I get a type error since I’m using typescript. Please help me, what could missing from the filters?\n  const adventures = await client.collections.get(\"adventures\").query.nearText(description, {\n    filters: [\n      client.collections.get(\"adventures\").filter.byProperty('startDate').greaterThan(new Date()),\n    ],\n    targetVector: \"vDescription\",\n    limit: 1000,\n  });\n  return adventures;\n\n    No overload matches this call.\n  Overload 1 of 3, '(query: string | string[], opts?: BaseNearTextOptions<undefined>): Promise<WeaviateReturn<undefined>>', gave the following error.\n    Type 'FilterValue<Date>[]' is missing the following properties from type 'FilterValue': operator, value\n  Overload 2 of 3, '(query: string | string[], opts: GroupByNearTextOptions<undefined>): Promise<GroupByReturn<undefined>>', gave the following error.\n    Type 'FilterValue<Date>[]' is missing the following properties from type 'FilterValue': operator, value\n  Overload 3 of 3, '(query: string | string[], opts?: NearTextOptions<undefined>): QueryReturn<undefined>', gave the following error.\n    Type 'FilterValue<Date>[]' is missing the following properties from type 'FilterValue': operator, valuets(2769)\ntypes.d.ts(61, 3): The expected type comes from property 'filters' which is declared here on type 'BaseNearTextOptions<undefined>'\ntypes.d.ts(61, 3): The expected type comes from property 'filters' which is declared here on type 'GroupByNearTextOptions<undefined>'\ntypes.d.ts(61, 3): The expected type comes from property 'filters' which is declared here on type 'NearTextOptions<undefined>'\n(property) filters?: weaviate.FilterValue\nThe filters to be applied to the query. Use weaviate.filter.* to create filters\n\n----------\n\n[DudaNogueira (2025-03-18T13:41:04.571Z)]: Hi @DeltaBoukensha !\nAFAIK, like will only support * and ?\nYou can use the same filter with near_text or hybrid instead of  fetch_objects\nI see you are using JS, so it should be like this:\nimport weaviate, { Filters } from 'weaviate-client';\n\nconst jeopardy = client.collections.get('JeopardyQuestion');\n\nconst result = await jeopardy.query.nearText({\n  filters: Filters.and(\n    jeopardy.filter.byProperty('answer').like('*bird*'),\n\n    Filters.or(\n      jeopardy.filter.byProperty('points').greaterThan(700),\n      jeopardy.filter.byProperty('points').lessThan(300)\n    )\n  ),\n  limit: 3\n})\n\nLet me know if this helps.\n\n----------\n\n[DeltaBoukensha (2025-03-18T13:44:27.771Z)]: DudaNogueira:\n\nFilters\n\n\nThank you so much. This helps",
    "date_created": "2024-12-31T15:56:13.608Z",
    "has_accepted_answer": true,
    "title": "How to filter by properties and nearText in v4?",
    "topic_id": 9535
  },
  {
    "user_id": 181,
    "conversation": "[Faizan_Muzaffar (2023-07-17T11:26:12.166Z)]: Hello Everyone,\nDoes Weaviate provide a multi-vector search for the single class?\nI have a scenario where I have a class named Sites, it has the following properties:\nSite title, Description, and keywords\nnow when a user queries similar sites currently i am providing the title vector of the site in the near_vector parameter but is there any other way I can also add the description and keywords vector?\n\n----------\n\n[jphwang (2023-07-17T19:29:02.236Z)]: Hi Faizan,\nIn Weaviate, currently each object has one vector attached to it.\nSo to do what you are describing, you could create different classes which are linked to each other. Alternatively, you could create multiple objects in each class, each vectorized differently.\n\n----------\n\n[Faizan_Muzaffar (2023-07-18T04:55:00.523Z)]: Hello Jphwang,\nRegarding that, I read the documentation for cross reference,  & I think my solution will be to create a cross-reference between the classes.\nIn cross-reference is there any way we can do a parent childs relation?\n\n----------\n\n[jphwang (2023-07-18T09:13:45.766Z)]: Hi @Faizan_Muzaffar. I’m not sure what you mean specifically by “parent” and “child” relationship, but each cross reference is one-directional, so there’s a distinction between a reference “from” and a reference “to”.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCross-references | Weaviate - vector database\n\n  Overview\n\n----------\n\n[Faizan_Muzaffar (2023-07-18T09:42:56.812Z)]: Thanks @jphwang, Just another question when searched with the near vector FROM class, will it return the TO class?\n\n----------\n\n[Faizan_Muzaffar (2023-07-18T10:40:04.512Z)]: Multi Vector Search in a single class Support\n  \n  \n    Hi @Faizan_Muzaffar. I’m not sure what you mean specifically by “parent” and “child” relationship, but each cross reference is one-directional, so there’s a distinction between a reference “from” and a reference “to”.\n  \n\n\nHi @jphwang,\nI just want to ask if we can create the cross-reference using graphQL.\nbecause I am currently using a PHP client(GitHub - timkley/weaviate-php: A PHP client to communicate with a Weaviate instance). and in this plugin, there is no endpoint to create the cross-reference.\nso can we do this using graphQL and if yes, is there any example you can provide?\n\n----------\n\n[jphwang (2023-07-18T11:00:08.431Z)]: HI @Faizan_Muzaffar\nI am not sure what the PHP client can and can’t do, but you can create cross-references with the REST endpoints directly in Weaviate.\nPlease take a look here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nREST - /v1/objects | Weaviate - vector database\n\n  List data objects\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI note that the GraphQL is used for queries.\nCheers,\nJP\n\n----------\n\n[Hari_Wu (2024-07-14T09:52:21.996Z)]: I hope this can help you. Create objects",
    "date_created": "2023-07-17T11:26:12.111Z",
    "has_accepted_answer": true,
    "title": "Multi Vector Search in a single class",
    "topic_id": 383
  },
  {
    "user_id": 2045,
    "conversation": "[Muhammad_Ashir (2025-01-08T14:38:08.627Z)]: Hi there I creating my collection depending upon my database names, but I am unable to I am getting this error:\nnames I am trying to set : 83cdb7b2569a428095e38b73e8348168\nother : 83cdb7b2-569a-4280-95e3-8b73e8348168\nraise UnexpectedStatusCodeError(error_msg, response=res)\nweaviate.exceptions.UnexpectedStatusCodeError: Collection may not have been created properly.! Unexpected status code: 422, with response body: {‘error’: [{‘message’: “‘83cdb7b2569a428095e38b73e8348168’ is not a valid class name”}]}.\n\n----------\n\n[DudaNogueira (2025-01-08T15:29:23.403Z)]: Hi!\nThe collection cannot start with a number nor have - or _\nTry this instead:\n“collection_83cdb7b2-569a-4280-95e3-8b73e8348168”\nLet me know if this works!\nThanks!\n\n----------\n\n[Muhammad_Ashir (2025-01-08T20:19:15.015Z)]: it worked, thanks a lot",
    "date_created": "2025-01-08T14:38:08.579Z",
    "has_accepted_answer": false,
    "title": "Unable to create class with GUIDs",
    "topic_id": 9634
  },
  {
    "user_id": 3238,
    "conversation": "[ilsg (2025-01-23T15:38:54.163Z)]: I have a test database on a local machine for experiments.\nWith the following settings:\n    environment:\n      - LOG_LEVEL=info\n      - LIMIT_RESOURCES=true\n      - CLUSTER_HOSTNAME=weaviate\n      - CLUSTER_GOSSIP_BIND_PORT=7100\n      - CLUSTER_DATA_BIND_PORT=7101\n      - IMAGE_INFERENCE_API=http://i2v:8082\n      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true\n      - PERSISTENCE_DATA_PATH=/var/lib/weaviate\n      - DEFAULT_VECTORIZER_MODULE=img2vec-neural\n      - ENABLE_MODULES=img2vec-neural\n      - ASYNC_INDEXING=true\n      - PROMETHEUS_MONITORING_ENABLED=true\n      - TOMBSTONE_DELETION_MIN_PER_CYCLE=30000\n      - TOMBSTONE_DELETION_MAX_PER_CYCLE=300000\n      - QUERY_DEFAULTS_LIMIT=40\n      - PERSISTENCE_LSM_MAX_SEGMENT_SIZE=50GB\n\nI have about 4 million vectors written, the Estimated Sizes LSM stores value shows 772 GB usage and it almost matches the real disk usage value.\nI did a large deletion of vectors, I deleted about 600 thousand vectors, but the size of LSM stores did not change at all, and the occupied disk space did not change either.\nAlthough during the deletion there were messages in the log like:\n{\"action\":\"tombstone_cleanup_complete\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"class\":\"Test\",\"duration\":45083524945,\"level\":\"info\",\"msg\":\"class Test: shard 4FOgY9AQitCU: completed tombstone cleanup in 45.083524945s\",\"shard\":\"4FOgY9AQitCU\",\"time\":\"2025-01-23T15:21:18Z\",\"tombstones_in_cycle\":162375,\"tombstones_total\":162375}\n{\"action\":\"hnsw_condensing_complete\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"level\":\"info\",\"msg\":\"completed hnsw condensing\",\"time\":\"2025-01-23T15:21:18Z\"}\n\n\nIt was expected that after deletion the disk space would be freed.\nСan you find out more about how exactly the deletion happens and why the disk space never decreases?\nServer Setup Information\n\nWeaviate Server Version:  1.28.2\nDeployment Method: docker\nMulti Node? Number of Running Nodes:  One node\nClient Language and Version: python, 4.9.2\nMultitenancy?: no\n\n----------\n\n[DudaNogueira (2025-01-24T20:43:50.566Z)]: hi @ilsg !!\nThat’s strange. The size should reduce after a the tombstone clean up.\nCan you confirm that after some time the disk size still has not decreased?\nThanks!\n\n----------\n\n[ilsg (2025-01-26T16:33:41.586Z)]: Yes, I deleted several hundred thousand more vectors to make the cleanup happen, but after that the size of the data on the disk did not decrease either.\nData in the log after cleaning in info mode:\n{\"action\":\"tombstone_cleanup_complete\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"class\":\"Test\",\"duration\":44520095647,\"level\":\"info\",\"msg\":\"class Test: shard 4FOgY9AQitCU: completed tombstone cleanup in 44.520095647s\",\"shard\":\"4FOgY9AQitCU\",\"time\":\"2025-01-26T16:10:47Z\",\"tombstones_in_cycle\":134207,\"tombstones_total\":134207}\n{\"action\":\"hnsw_condensing_complete\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"level\":\"info\",\"msg\":\"completed hnsw condensing\",\"time\":\"2025-01-26T16:10:48Z\"}\nSecond tombstone_cleanup\n{\"action\":\"hnsw_condensing_complete\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"level\":\"info\",\"msg\":\"completed hnsw condensing\",\"time\":\"2025-01-26T16:16:17Z\"}\n{\"action\":\"tombstone_cleanup_complete\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"class\":\"Test\",\"duration\":30373802263,\"level\":\"info\",\"msg\":\"class Test: shard 4FOgY9AQitCU: completed tombstone cleanup in 30.373802263s\",\"shard\":\"4FOgY9AQitCU\",\"time\":\"2025-01-26T16:16:18Z\",\"tombstones_in_cycle\":87434,\"tombstones_total\":87434}\n\n\nI also switched the log mode to debug, here are some lines that might be of interest:\n{\"action\":\"tombstone_cleanup_progress\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"class\":\"Test\",\"level\":\"debug\",\"msg\":\"class Test: shard 4FOgY9AQitCU: 3000000/4600858 nodes processed\",\"processed_nodes\":3000000,\"shard\":\"4FOgY9AQitCU\",\"time\":\"2025-01-26T16:25:28Z\",\"total_nodes\":4600858}\n{\"action\":\"attach_tombstone_to_deleted_node\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"level\":\"debug\",\"msg\":\"found a deleted node (1833291) without a tombstone, tombstone was added\",\"node_id\":1833291,\"time\":\"2025-01-26T16:25:35Z\"}\n{\"action\":\"lsm_memtable_flush_complete\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"class\":\"Test\",\"index\":\"test\",\"level\":\"debug\",\"msg\":\"flush and switch took 11.171313ms\\n\",\"path\":\"/var/lib/weaviate/test/4FOgY9AQitCU/lsm/property_post_id\",\"shard\":\"4FOgY9AQitCU\",\"time\":\"2025-01-26T16:25:42Z\",\"took\":11171313}\n{\"action\":\"tombstone_cleanup_complete\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"class\":\"Test\",\"duration\":49417121838,\"level\":\"info\",\"msg\":\"class Test: shard 4FOgY9AQitCU: completed tombstone cleanup in 49.417121838s\",\"shard\":\"4FOgY9AQitCU\",\"time\":\"2025-01-26T16:25:49Z\",\"tombstones_in_cycle\":152320,\"tombstones_total\":152320}\n{\"action\":\"lsm_precompute_disk_segment_build_bloom_filter_primary\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"class\":\"Test\",\"index\":\"test\",\"level\":\"debug\",\"msg\":\"building bloom filter took 6.54414ms\\n\",\"path\":\"/var/lib/weaviate/test/4FOgY9AQitCU/lsm/property_uid/segment-1737908620745905701_1737908681565500141.db\",\"shard\":\"4FOgY9AQitCU\",\"time\":\"2025-01-26T16:25:49Z\",\"took\":6544140}\n{\"action\":\"lsm_precompute_disk_segment_build_bloom_filter_primary\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"class\":\"Test\",\"index\":\"test\",\"level\":\"debug\",\"msg\":\"building bloom filter took 3.035396ms\\n\",\"path\":\"/var/lib/weaviate/test/4FOgY9AQitCU/lsm/property_post_id/segment-1737908559463092956_1737908681523994626.db\",\"shard\":\"4FOgY9AQitCU\",\"time\":\"2025-01-26T16:25:52Z\",\"took\":3035396}\n{\"action\":\"lsm_replace_compacted_segments_blocking\",\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"class\":\"Test\",\"index\":\"test\",\"level\":\"debug\",\"msg\":\"replacing compacted segments took 3.113686ms\",\"path_left\":\"/var/lib/weaviate/test/4FOgY9AQitCU/lsm/property_uid/segment-1737908399384048762.db\",\"path_right\":\"/var/lib/weaviate/test/4FOgY9AQitCU/lsm/property_uid/segment-1737908681565500141.db\",\"segment_index\":3,\"shard\":\"4FOgY9AQitCU\",\"time\":\"2025-01-26T16:25:56Z\",\"took\":3113686}\n\nThis is a big problem for me because I use fast m2 nvme drives for maximum performance and they run out of space because the data size does not shrink after deletion.",
    "date_created": "2025-01-23T15:38:54.108Z",
    "has_accepted_answer": false,
    "title": "Disk usage for weaviate and tombstone cleanup",
    "topic_id": 9870
  },
  {
    "user_id": 1497,
    "conversation": "[Minyus (2024-09-08T14:21:13.853Z)]: Description\nCan replication/raft be disabled for embedded Weaviate?\nI see warning/error log apparently related to raft as follows.\nweaviate_version = \"1.26.4\"\n\nclient = weaviate.WeaviateClient(\n    embedded_options=EmbeddedOptions(\n        additional_env_vars={\n            \"LOG_LEVEL\": \"warning\",\n        },\n        version=weaviate_version,\n    )\n)\n\noutput log:\n{“action”:“raft”,“build_git_commit”:“584532a6b”,“build_go_version”:“go1.23.0”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.4”,“last-leader-addr”:“”,“last-leader-id”:“”,“level”:“warning”,“msg”:“raft heartbeat timeout reached, starting election”,“time”:“2024-09-08T21:57:38+08:00”}\nclient.close()\n\noutput log:\n{“build_git_commit”:“584532a6b”,“build_go_version”:“go1.23.0”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.4”,“error”:“cannot find peer”,“level”:“error”,“msg”:“transferring leadership”,“time”:“2024-09-08T21:57:40+08:00”}\nI’m seeing this behavior in my dev machine MacOS Sonoma 14.6.1 before using actual data in Linux (CentOS).\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: embedded\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python 3.11 weaviate-client==4.7.1\nMultitenancy?: No\n\n----------\n\n[Mohamed_Shahin (2024-09-09T09:07:26.084Z)]: Good morning @Minyus,\nWelcome to the Weaviate community! It’s awesome to have you here with us.\nI understand that you’re looking to disable some warning messages related to RAFT. In release 1.25, we introduced the RAFT mechanism,\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nWeaviate 1.25.0 | Weaviate\n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nRAFT is a robust consensus algorithm that improves the fault tolerance of multi-node clusters. With larger Weaviate clusters, coordination between nodes becomes more important, and RAFT helps ensure reliable performance even under heavy loads.\nSince you’re currently running version 1.26.4 on a single node, have you considered upgrading to a 3-node cluster? This setup is highly recommended.\nAlternatively, if you remain on one node for now and want to reduce the log output on a single node, you could consider setting the LOG_LEVEL to one of the following:\n\npanic: Panic entries only.\nfatal: Fatal entries only.\nerror: Error entries only.\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nEnvironment variables | Weaviate\n\n  To configure Weaviate in a Docker or a Kubernetes deployment, set these environment variables\n\n----------\n\n[DudaNogueira (2024-09-09T14:43:23.510Z)]: hi @Minyus !\nYou can get rid of that message by setting RAFT_EXPECT_JOIN to 1.\nBear in mind that this is not necessary, as it will have this error log, but it should not affect Weaviate operations, but reduce the error logs on this scenario.\nAlso, I noticed you are using the python v3 client syntax. Please, consider using the new python v4 client, as it will deliver a lot of improvements.\nHere is an example:\nimport weaviate\nclient = weaviate.connect_to_embedded(\n    environment_variables={\n            \"LOG_LEVEL\": \"warning\",\n            \"RAFT_BOOTSTRAP_EXPECT\": \"1\"\n        }\n)\n\nthis was the output I got:\n\n{“level”:“warning”,“msg”:“Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.”,“time”:“2024-09-09T11:39:12-03:00”}\n{“action”:“raft”,“last-leader-addr”:“”,“last-leader-id”:“”,“level”:“warning”,“msg”:“raft heartbeat timeout reached, starting election”,“time”:“2024-09-09T11:39:14-03:00”}\n\nLet me know if this helps!\nTHanks!",
    "date_created": "2024-09-08T14:21:13.799Z",
    "has_accepted_answer": false,
    "title": "Disable replication/raft for embedded Weaviate",
    "topic_id": 4019
  },
  {
    "user_id": 990,
    "conversation": "[moaabid (2024-10-05T03:53:34.067Z)]: I have build a multi modal similarity search using CLIP model for both text and image based search. CLIP models are old. Wanted to try out different models and compare the results. Is there any example code on how to integrate with paligemma or any other multi modal model?. Instead of CLIP.\n\n----------\n\n[DudaNogueira (2024-10-06T17:46:14.184Z)]: hi @moaabid !!\nWhile I am not sure we do have an example with paligemma, we do have an example with multi2vec-bind here:\n\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate-tutorials/multimodal-workshop\n\n    Contribute to weaviate-tutorials/multimodal-workshop development by creating an account on GitHub.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI did a quick search on paligemma, and it doesn’t seems to be an embedding model \nLet me know if the multi2vec-bind is what you are looking for.\nThanks!\n\n----------\n\n[moaabid (2024-10-07T03:23:54.733Z)]: multi2vec bind is a good option. But Paligemma is a vision language embedding model. It can encode images into embeddings is what i read. I’m new to this whether this kind of new models example phi-3 vision or paligemma is supported in the weaviate?. These are multimodel so i thought it can be used along with weaviate. My usecase is jewellery image and text similarity search. its complex use case where shape, color, different style were involved. Wanted to try out different models so that can able to compare.\n@zainhas also tweeted about paligemma and phi-3 x.com\n\n----------\n\n[DudaNogueira (2024-10-07T09:18:42.345Z)]: Sorry, I don’t know about this enough.\nHowever, if the model indeed produces embeddings, and you see that Weaviate doesn’t have support for that model yet, feel free to open an feature request:\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nIssues · weaviate/weaviate\n\n  Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of ...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAlso, you can always use any embeddings model, considering that you will need to vectorize your data yourself and “bring your own vectors”, as explained here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBring your own vectors | Weaviate\n\n  Weaviate is a vector database. Vector databases store data objects and vectors that represent those objects. The vector representation is also called an \"embedding.\"\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThans!",
    "date_created": "2024-10-05T03:53:34.027Z",
    "has_accepted_answer": false,
    "title": "Custom Model integration Instead of CLIP",
    "topic_id": 4433
  },
  {
    "user_id": 1323,
    "conversation": "[Edward (2024-08-19T23:21:29.196Z)]: Is there a recommended way to query for multiple objects, based on their id, when using the JS/TS v3 client?\nI see that I can query against a single id as follows:\nconst jeopardy = client.collections.get('JeopardyQuestion')\nconst response = await jeopardy.query.fetchObjectById('ed89d9e7-4c9d-4a6a-8d20-095cb0026f54')\n\nHowever, I need to retrieve large batches; I can’t use a one-query-per-object approach.\nI tried using fetchObjects and filters, using variations on something like this:\nconst result = await jeopardy.query.fetchObjects({\n  filters: jeopardy.filter.byProperty('id').containsAny([\"id1\", \"id2\"])\n})\n\nBut either the ‘id’ property cannot be accessed this way, or it must have a different name than either ‘id’, ‘uuid’, or ‘_additional.id’.\nI saw this related question, which provided an approach for Python: Best way to query objects using id at once\nBut, it seems like the JS/TS v3 sdk cannot be used in this way.  I suppose I can look at just POSTing the graphql queries myself, though naturally I prefer the uniformity of using the JS/TS v3 client, and it seems like it should have this functionality.\nIs there a recommended way to query for multiple objects, based on their id, when using the JS/TS v3 client?\n\n----------\n\n[Dirk (2024-08-20T06:20:31.944Z)]: Hi, you can do\nconst myArticleCollection = client.collections.get('Article');\nconst creationTime = '2020-01-01T00:00:00+00:00'\n\nresult = await myArticleCollection.query.fetchObjects({\n  filters: jeopardy.filter.byCreationTime().greaterOrEqual(creationTime),\n  returnMetadata: ['creationTime']\n})\n\nfor (let object of result.objects) {\n  console.log(JSON.stringify(object.properties, null, 2));\n}\n\nSee here: Filters | Weaviate - Vector Database\n\n----------\n\n[Edward (2024-08-26T23:30:44.399Z)]: I think this must be the answer to a different question, since I’m asking about fetching multiple records by id.\n\n----------\n\n[Dirk (2024-08-27T11:47:58.833Z)]: I copied the wrong code example, but the link shows how to filter by id. Simply replace the .equal() in the example with . containsAny()\n\n----------\n\n[Edward (2024-08-29T17:35:10.382Z)]: Thank you Dirk!  Now it’s clear.  I appreciate your help!",
    "date_created": "2024-08-19T23:21:29.146Z",
    "has_accepted_answer": false,
    "title": "How can I batch query by id when using JS/TS v3?",
    "topic_id": 3398
  },
  {
    "user_id": 959,
    "conversation": "[Horsemann (2024-05-17T22:56:41.485Z)]: Description\nI cloned the git repo and I am running python 3.11.9. I updated the .env file with my ollama info and local model. I also added openai-api key. When accessing the verba page on my Linux laptop the Verba page comes up but there are no variables in the overview tab. It is completely empty. I also made sure all other docker containers were stopped. Only the two, verba_verba_1 and verba_weaviate_1 are running. Looking at docker logs for the containers I see no errors.\nServer Setup Information\n\nWeaviate Server Version: docker container pulled via github\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version:  english\n\nAny additional Information\nFollowed instructions here.\n(GitHub - weaviate/Verba: Retrieval Augmented Generation (RAG) chatbot powered by Weaviate)\nI want also to say, I am excited to use this. It is pretty much exactly what I am looking for.\n\n----------\n\n[Horsemann (2024-05-17T23:04:08.477Z)]: Sorry folks, I was using the IP address to access not the localhost. So this problem has to do with the binding to the IP. I would like it to bind to the localhost and the IP. But I can figure that out.\n\nRod\n\n----------\n\n[DudaNogueira (2024-05-20T14:19:49.214Z)]: Thanks for sharing!!\n\n----------\n\n[Ricky_D (2024-07-25T13:15:54.528Z)]: Hi,\nI have used the instruction in the github, i got a verba v0.3.1 but the latest version that is on github is right now v1.0.3.\nI am not sure where i am doing the wrong so wrong the updated version is not there.\nplease help.\n//Ricky\n\n----------\n\n[DudaNogueira (2024-07-25T15:43:07.923Z)]: hi @Ricky_D !\nYou need to clone the repository and build up the docker image.\nThen you can point it to your Weaviate Server using the environment variables.\nHere we have a doc on this:\n  \n      \n\n      github.com\n  \n\n  \n    GitHub - weaviate/Verba: Retrieval Augmented Generation (RAG) chatbot powered by...\n\n  main\n\n  Retrieval Augmented Generation (RAG) chatbot powered by Weaviate - weaviate/Verba\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Ricky_D (2024-07-26T07:42:42.070Z)]: Thanks @DudaNogueira\nI tried as the instruction says in github, still i have the older version.\nHere is my .env file:\nOLLAMA_URL=http://localhost:11434\nOLLAMA_MODEL=llama3.1\nOLLAMA_EMBED_MODEL=mxbai-embed-large\nWEAVIATE_URL_VERBA=http://localhost:8080\nOPENAI_BASE_URL=https://api.openai.com/v1\nOPENAI_API_KEY=sk-XXX\nCOHERE_API_KEY=XXXXXX\nStill not getting where is the error.\nThanks for help in advance.\n\n----------\n\n[Ricky_D (2024-07-29T12:10:49.301Z)]: Hi @DudaNogueira and All,\nI have done the following:\n\nCloned the verba from the Github\nSet  the .env under “goldenverba” folder, which looks like this:\nOLLAMA_URL=http://localhost:11434\nOLLAMA_MODEL=llama3.1\nOLLAMA_EMBED_MODEL=mxbai-embed-large\nWEAVIATE_URL_VERBA=http://localhost:8080\nOPENAI_BASE_URL=https://api.openai.com/v1\nOPENAI_API_KEY=sk-XXX\nCOHERE_API_KEY=XXXXXX\nrun the “docker compose --env-file goldenverba/.env up -d” and run the docker\nnow i can access Verba using \" localhost:8080\"\nBut the problem is that it is showing “verba v0.3.1” not “v1.0.3”.\nI am not finding where i am doing the mistake to show the latest Verba verison. (FYI, I am using windows 10, Docker desktop)\nThanks for your help in advance.\n//Ricky\n\n----------\n\n[DudaNogueira (2024-07-29T18:32:02.580Z)]: hi @Ricky_D !!\nYou need to rebuild the image.\nTry this:\ndocker compose --env-file goldenverba/.env up -d --build\n\nnote the --build at the end :\nLet me know if this works.\nThanks!\n\n----------\n\n[Ricky_D (2024-07-30T07:38:52.222Z)]: Thanks @DudaNogueira for the great help.\nit worked.\n//Ricky",
    "date_created": "2024-05-17T22:56:41.431Z",
    "has_accepted_answer": true,
    "title": "Installing Verba with Docker",
    "topic_id": 2378
  },
  {
    "user_id": 1239,
    "conversation": "[hanumanhuda (2024-09-18T07:40:56.470Z)]: Description\nWe have upgraded from 1.24.23 to 1.26.4. Earlier weaviate was able to start up within a second, however after upgrading, it takes 2-10 seconds to come up for small dataset. As per documentation, that it takes time to migration the schema due to RAFT, however this is not only taking time once during upgrade instead it takes whenever it restarts after the upgrade.\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: python and v3\nMultitenancy?: No\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-09-18T21:57:18.556Z)]: Hi!\nHow small is this dataset?\nCan you try testing it on a second cluster that doesn’t do migration?\nAlso, do you see any outstanding logs during the startup?\n\n----------\n\n[Dirk (2024-09-19T06:40:20.922Z)]: I think the RAFT startup takes longer than the old startup-code. I also noticed that\n\n----------\n\n[hanumanhuda (2024-09-25T09:08:52.558Z)]: yes, it takes similar time with a new index without any documents.",
    "date_created": "2024-09-18T07:40:56.426Z",
    "has_accepted_answer": false,
    "title": "Weaviate startup time has increased with 1.25 onwards",
    "topic_id": 4190
  },
  {
    "user_id": 1266,
    "conversation": "[fr_yuan (2024-07-31T09:30:14.291Z)]: Hello Weaviate Community,\nI am encountering an issue with my Weaviate instance that I deployed using Docker. When attempting to store data, I receive the following error message:\nput object: import into index business10007scene1000704strategy89: put local object: shard=“rbGyIAVZC9Nl”: store is read-only\nI believe this issue is related to the data persistence configuration, but I am not certain. I have taken a proactive step to check the disk usage on the host system and can confirm that it has not reached the 90% threshold, which I understand could be a potential cause for a read-only state.\nThank you in advance for your help. I am looking forward to your responses.\n\n----------\n\n[Mohamed_Shahin (2024-07-31T12:04:20.843Z)]: Hello @fr_yuan,\nWelcome to our community! It’s great to have you here \nThe issue is likely due to running out of disk space. However, since you’ve checked and everything seems fine, I suggest setting the shard status to READY.\nYou can find more information on how to do this here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage collections | Weaviate - Vector Database\n\n  Every object in Weaviate belongs to exactly one collection. Use the examples on this page to manage your collections.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThis should resolve the issue, but please keep an eye on the disk volume in the meantime.\nI hope this helps!",
    "date_created": "2024-07-31T09:30:14.234Z",
    "has_accepted_answer": false,
    "title": "Issue with ‘store is read-only’ in Weaviate Docker Deployment",
    "topic_id": 3230
  },
  {
    "user_id": 1276,
    "conversation": "[gdrajhasekarun (2024-08-01T16:31:13.647Z)]: Description\nI have weaviate installed on my local docker and proxied 8080 to an url and 50051 to another one. using the following code, I’m connecting to them\nclient = weaviate.connect_to_custom(\n            http_host='host-a',\n            grpc_host='host-b',\n            http_port=443,\n            http_secure=True,\n            grpc_port=443,\n            grpc_secure=True,\n            skip_init_checks=True,\n            additional_config=AdditionalConfig(\n                connection=ConnectionConfig(\n                                session_pool_connections=30,\n                                session_pool_maxsize=200,\n                                session_pool_max_retries=3,\n                            ),\n                    # timeout=(60, 180),\n                timeout=Timeout(init=60, query=60, insert=180)  # Values in seconds\n            )\n        )\n\ngetting the following errors when i do self.vectorstore.add_documents(\ndocuments=document,\n)\n2024-Aug-01 11:19 AM - langchain_weaviate.vectorstores - ERROR - Failed to add object: None\nReason: WeaviateBatchError(‘Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.PERMISSION_DENIED\\n\\tdetails = “Received http2 header with status: 403”\\n\\tdebug_error_string = “UNKNOWN:Error received from peer  {created_time:“2024-08-01T11:19:42.004222-05:00”, grpc_status:7, grpc_message:“Received http2 header with status: 403”}”\\n>.’)\n\n----------\n\n[DudaNogueira (2024-08-02T13:28:20.899Z)]: hi @gdrajhasekarun !!\nWelcome to our community \nThis indicates an error on exposing your Weaviate.\nCan you share more info on how you have exposed?\nAlso, check this forum thread on this topic:\n  \n    \n    \n    Weaviate with Traefik and gRPC Support\n  \n  \n    Hi @qnlbnsl ! Sorry for the delay here. \nLooks like I was finally able to tame this \nHere is what I got: \nNOTE: Check this updated gist on how to correctly expose Weaviate under SSL/TLS using Traefik and running everything with a docker compose \n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:1.23.5\n    #ports:\n    # - 8081:8080 # unsafe http\n    # - 50052:50051 # unsafe grpc…\n\n----------\n\n[gdrajhasekarun (2024-08-02T14:35:42.436Z)]: This is my docker compose file.\nversion: '3.4'\nnetworks:\n  frontend:\n    external: true\n  backend:\n    external: true\n    \nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.9\n    # ports:\n    # - 8080:8080\n    # - 50051:50051\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node1'\n    networks:\n      - frontend\n      - backend\n    labels:\n      - 'traefik.enable=true'\n      - 'traefik.docker.network=frontend'\n      - 'traefik.http.routers.weavite.entrypoints=websecure'\n      - 'traefik.http.routers.weavite.tls=true'\n      - 'traefik.http.routers.weavite.tls.certresolver=production'\n      - 'traefik.http.routers.weavite.service=weavite_1'\n      - 'traefik.http.services.weavite_1.loadbalancer.server.port=8080'\n      - 'traefik.http.routers.weavite.rule=Host(`weavite.<domain>`)'\n\n      - 'traefik.http.routers.grc_weavite.entrypoints=websecure'\n      - 'traefik.http.routers.grc_weavite.tls=true'\n      - 'traefik.http.routers.grc_weavite.tls.certresolver=production'\n      - 'traefik.http.routers.grc_weavite.service=grc_weavite_1'\n      - 'traefik.http.services.grc_weavite_1.loadbalancer.server.port=50051'\n      - 'traefik.http.routers.grc_weavite.rule=Host(`grc-weavite.<domain>`)'\nvolumes:\n  weaviate_data:\n\ngetting the following error\n2024-Aug-01 11:19 AM - langchain_weaviate.vectorstores - ERROR - Failed to add object: None\nReason: WeaviateBatchError(‘Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.PERMISSION_DENIED\\n\\tdetails = “Received http2 header with status: 403”\\n\\tdebug_error_string = “UNKNOWN:Error received from peer  {created_time:“2024-08-01T11:19:42.004222-05:00”, grpc_status:7, grpc_message:“Received http2 header with status: 403”}”\\n>.’)\n\n----------\n\n[DudaNogueira (2024-08-02T14:44:08.271Z)]: Check this gist:\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nBuild software better, together\n\n  GitHub is where people build software. More than 100 million people use GitHub to discover, fork, and contribute to over 420 million projects.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThose are the traefik labels I was able to make correctly exposing:\n    labels:\n      - \"traefik.enable=true\"\n      # http\n      - \"traefik.http.services.weaviate_http_service.loadbalancer.server.port=8080\"\n      - \"traefik.http.routers.weaviate_http_router.rule=Host(`weaviate.yourdomain.com`)\"\n      - \"traefik.http.routers.weaviate_http_router.entrypoints=websecure\"\n      - \"traefik.http.routers.weaviate_http_router.service=weaviate_http_service\"\n      - \"traefik.http.routers.weaviate_http_router.tls.certresolver=myresolver\"\n      # # grpc\n      - \"traefik.http.services.weaviate_grpc_service.loadbalancer.server.scheme=h2c\"\n      - \"traefik.http.services.weaviate_grpc_service.loadbalancer.server.port=50051\"\n      - \"traefik.http.routers.weaviate_grpc_router.rule=Host(`grpc.weaviate.yourdomain.com`)\"\n      - \"traefik.http.routers.weaviate_grpc_router.entrypoints=grpc\"\n      - \"traefik.http.routers.weaviate_grpc_router.service=weaviate_grpc_service\"\n      - \"traefik.http.routers.weaviate_grpc_router.tls.certresolver=myresolver\"\n\n----------\n\n[gdrajhasekarun (2024-08-02T19:14:33.898Z)]: Thank you.\nStill my issues is not resolved. Is it possible to get me the Traefik config for grpc.\n\n----------\n\n[DudaNogueira (2024-08-02T20:27:39.491Z)]: Sure. It is on that thread I pasted above.\nhere the gist:\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nBuild software better, together\n\n  GitHub is where people build software. More than 100 million people use GitHub to discover, fork, and contribute to over 420 million projects.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\non that same thread there are some ways to test the grpc endpoint.\nNote that this should work with any grpc expose method in a reverse proxy.\nThanks!\n\n----------\n\n[gdrajhasekarun (2024-08-11T13:44:40.580Z)]: I followed the the steps mentioned in the thread.\n\nOpened GRPC in Cloudflare (No gateway config)\nFollowed the steps for Traefik and Weaviate.\n\nI was not able to connect to Grpc using the command\ngrpcurl -d ‘{“service”: “Weaviate”}’ -proto health.proto grpc.weaviate.mydomain.com:50051 grpc.health.v1.Health/Check\n\n----------\n\n[DudaNogueira (2024-08-12T21:38:03.746Z)]: Oh, that indicates your GRPC service may not be properly exposed.\nWhat is the error message?\n\n----------\n\n[gdrajhasekarun (2024-08-12T21:59:16.399Z)]: Failed to dial target host “:50051”: context deadline exceeded\n\n----------\n\n[gdrajhasekarun (2024-08-12T22:29:12.576Z)]: Even I did the following. Exposed weaviate with 8080 and 50051 as part of docker instances. now localhost:8080 is responding me with the following response\nCommand: curl http://localhost:8080/v1/nodes\nResponse:\n{“nodes”:[{“batchStats”:{“queueLength”:0,“ratePerSecond”:0},“gitHash”:“6aeae65”,“name”:“node1”,“shards”:null,“stats”:{“objectCount”:0,“shardCount”:1},“status”:“HEALTHY”,“version”:“1.23.5”}]}\nWith GRPC, I did the following.\nCommand: grpcurl -d ‘{“service”: “Weaviate”}’ -proto health.proto localhost:50051 grpc.health.v1.Health/Check\nResponse Failed to dial target host “localhost:50051”: tls: first record does not look like a TLS handshake\n\n----------\n\n[DudaNogueira (2024-08-12T22:42:19.344Z)]: Oh, wait. If you don’t have SSL, you need to pass the -plaintext, like so\ngrpcurl --plaintext -d '{\"service\": \"Weaviate\"}' -proto health.proto localhost:50051 grpc.health.v1.Health/Check\n\nThanks!\n\n----------\n\n[gdrajhasekarun (2024-08-12T22:52:37.727Z)]: DudaNogueira:\n\ngrpcurl --plaintext -d '{\"service\": \"Weaviate\"}' -proto health.proto localhost:50051 grpc.health.v1.Health/Check\n\n\nI was able to make it working in local host using the command you gave me. Let me try with the traefik and cloud flare level.\nCloudflare - Opened GRPC at domain level. I was using Zero trust tunnel.\n\n----------\n\n[DudaNogueira (2024-08-12T23:13:16.705Z)]: Oh! Is it working now?\n\n----------\n\n[gdrajhasekarun (2024-08-12T23:14:18.136Z)]: Yes, at localhost level. But not at traefik and Cloudflare level. I’m researching on that.\n\n----------\n\n[gdrajhasekarun (2024-08-13T15:13:17.396Z)]: Cloudflare needs all GRPC services to expose as http2. So I’m routing the hostname “weaviate.grpc.” in Traefik with port as 443. Traefik connect using the url to the docker url “http://172.19.0.14:50051”. Do you see any issues here.\nI’m mostly a developer with little knowledge on networking.",
    "date_created": "2024-08-01T16:31:13.589Z",
    "has_accepted_answer": false,
    "title": "Unable to connect to weaviate running behind reverse proxy",
    "topic_id": 3252
  },
  {
    "user_id": 2012,
    "conversation": "[Radomir_Babek (2024-10-21T12:34:05.456Z)]: I have a problem connecting to the custom instance because of the way V4 client parses the connection http urls.\nMy url where the server is located looks like this:\nhttps://www.host.com/cloud/weaviate/\nThe way v4 parses the http url is currently as follows:\n    @property\n    def _http_url(self) -> str:\n        return f\"{self._http_scheme}://{self.http.host}:{self.http.port}\"\n\nI can’t connect to the server because it creates this url:\nhttps://www.host.com/cloud/weaviate/:443/v1/meta\nHow should I solve this issue if I can’t get rid of “/cloud/weaviate/” part of the url?\n\n----------\n\n[DudaNogueira (2024-10-21T21:46:17.192Z)]: hi @Radomir_Babek !!\nThat’s an interesting edge case \nFor now, and only because of that, I would say that Weaviate doesn’t support   being exposed on a subpath.\nI don’t know also if GRPC will allow being exposed on subpath.\nI will need to escalate this with our client team as they have help us here.\nHang tight \nTHanks!\n\n----------\n\n[Dirk (2024-10-22T08:23:15.565Z)]: Hello!\nCould you try this PR? I added an optional path keyword to the connect_to_custom method.\nYou can install it by either downloading the wheel from here or doing\npip install git+https://github.com/weaviate/weaviate-python-client.git@2adaae3605a6a6a97bcc0babc36f059e6b76926a\n\nCan’t quickly test it myself and not sure if GRPC works with custom paths, but please give it a try\n\n----------\n\n[Radomir_Babek (2024-10-22T13:46:15.811Z)]: Hello Dirk and Duda,\nthank you very much for your support.\nThere is a small typo in the PR that uses grpc.path instead of http.path on line 141 of file base.py\nAdditionally there is a validation check that forbids the same hosts and ports that doesn’t consider different paths.\nThis results in the following error message:\n“Value error, http.port and grpc.port must be different if using the same host”.\nYou are probably right that gRPC will not allow exposure on a subpath. Trying to connect to the gRPC server raises the WeaviateGRPCUnavailableError. Unfortunatelly I can’t check right now if this is a firewall issue.\nNot sure what to do right now, anyway, thank you for your answers.\n\n----------\n\n[Dirk (2024-10-23T07:18:11.022Z)]: Hi, sorry missed those! Could you try again with commit 29d6e6e8670b9f6a92daa4ecf62a9676a123d4f6? Just replace in the pip command above\nYou should also be able to directly create a weaviate.WeaviateClient(). You’d just need to create the connection_params: Optional[ConnectionParams] yourself\n\n----------\n\n[light (2024-10-24T02:10:23.290Z)]: Hey,\nTesting this setup and attempting to provide as much context/info as possible which seems a bit much to dump on this forum, is a GH issue a better space for all this info, or use something like pastebin for below logs?\nI am also hosting an instance with a subpath and an auth header requirement and was having trouble with this config:\n\ntoken = get_bearer_token()\nhost = “subdomain.labs.company.com”\nclient = weaviate.connect_to_custom(\nhttp_host=host,  # Hostname for the HTTP API connection\nhttp_port=443,\npath=“/8b449c1e-bdfd-4d87-b6f5-70b31bd03ae5/llm-tool-weaviate-master-weaviate/v1”,\nhttp_secure=True,\ngrpc_host=host + “grpc”,\ngrpc_port=443,\ngrpc_secure=True,\nheaders={“Authorization”: token},\n)\n\n\nCreated wheel for weaviate-client: filename=weaviate_client-4.9.1.dev4+g29d6e6e8-py3-none-any.whl size=378508 sha256=7200425a349cc28d48a99a65035ac4242f9fa07b811bb609257918d4450396bb\nStored in directory: /home/lochy/.cache/pip/wheels/be/17/ea/f64fb007c3c821e6b3b0d4350b014e7e57e528bb653af3d0fe\nSuccessfully built weaviate-client\nInstalling collected packages: weaviate-client\nAttempting uninstall: weaviate-client\nFound existing installation: weaviate-client 4.9.0\nUninstalling weaviate-client-4.9.0:\nSuccessfully uninstalled weaviate-client-4.9.0\nSuccessfully installed weaviate-client-4.9.1.dev4+g29d6e6e8\n\n\nTraceback (most recent call last):\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/demo.py”, line 26, in \nclient = weaviate.connect_to_custom(\nTypeError: connect_to_custom() got an unexpected keyword argument ‘path’\n\nChanged to http_path and got this error instead:\n\nTraceback (most recent call last):\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/demo.py”, line 32, in \nclient = weaviate.connect_to_custom(\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/weaviate/connect/helpers.py”, line 390, in connect_to_custom\nreturn __connect(\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/weaviate/connect/helpers.py”, line 416, in __connect\nraise e\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/weaviate/connect/helpers.py”, line 412, in __connect\nclient.connect()\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/weaviate/syncify.py”, line 23, in sync_method\nreturn _EventLoopSingleton.get_instance().run_until_complete(\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/weaviate/event_loop.py”, line 40, in run_until_complete\nreturn fut.result()\nFile “/home/lochy/.asdf/installs/python/3.10.13/lib/python3.10/concurrent/futures/_base.py”, line 458, in result\nreturn self.__get_result()\nFile “/home/lochy/.asdf/installs/python/3.10.13/lib/python3.10/concurrent/futures/_base.py”, line 403, in __get_result\nraise self._exception\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/weaviate/client_base.py”, line 153, in connect\nawait self._connection.connect(self._skip_init_checks)\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/weaviate/connect/v4.py”, line 146, in connect\nawait self._open_connections(self._auth, skip_init_checks)\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/weaviate/connect/v4.py”, line 242, in _open_connections\nself.__make_clients()\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/weaviate/connect/v4.py”, line 227, in __make_clients\nself._client = self.__make_async_client()\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/weaviate/connect/v4.py”, line 220, in __make_async_client\nreturn AsyncClient(\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/httpx/_client.py”, line 1389, in init\nsuper().init(\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/httpx/_client.py”, line 183, in init\nself.headers = Headers(headers)\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/httpx/_models.py”, line 72, in init\nself._list = [\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/httpx/_models.py”, line 76, in \nnormalize_header_value(v, encoding),\nFile “/home/lochy/repos/llm-tools/llm-tool-weaviate/.venv/lib/python3.10/site-packages/httpx/_utils.py”, line 53, in normalize_header_value\nreturn value.encode(encoding or “ascii”)\nAttributeError: ‘NoneType’ object has no attribute ‘encode’\n\n----------\n\n[Dirk (2024-10-24T06:23:58.425Z)]: Would it be possible to get access to a weaviate instance with a custom path? It is hard for me to try to debug it if I can’t try it out and I don’t have the time to set one up myself - feel free to write me a DM here or on slack\n\n----------\n\n[light (2024-10-24T08:53:54.918Z)]: Dirk:\n\nWould it be possible to get access to a weaviate instance with a custom path? It is hard for me to try to debug it if I can’t try it out and I don’t have the time to set one up myself - feel free to write me a DM here or on slack\n\n\nUnfortunately, not, it’s a work instance with no external access.\nNot sure if the issue is directly related to my instance/setup or just a general configuration client issue.\nI’ve been able to curl my instance successfully, but having trouble replicating rest connection via python client so far.\nIf there’s any way to debug further or grab other logs, that might be good too.\n\n----------\n\n[Dirk (2024-10-24T09:14:24.664Z)]: light:\n\nUnfortunately, not, it’s a work instance with no external access.\n\n\nBummer\nDo you feel comfortable digging into a client with a debugger?\nSomething seems like it is None here that should not be None weaviate/connect/v4.py”, line 220, in __make_async_client\n\n----------\n\n[light (2024-10-24T11:52:22.373Z)]: I can see it’s giving me URL:\n'https://subdomain.subdomain.domain.com:443/8b449c1e-bdfd-4d87-b6f5-70b31bd03ae5/llm-tool-weaviate-master-weaviate/v1/'\nCould the port there be causing issues?\nI can’t put port None either.\n\n----------\n\n[Dirk (2024-10-25T07:25:02.136Z)]: Could you try to directly initialize weaviate.WeaviateClient(connection_params: Optional[ConnectionParams]) without going through our helpers? Then you should be able to put in any combination. Might also make sense to create your own ConnectionParams class by inheriting from ours and overwrite the functions that return the the paths.\nSorry that I can’t help more, but without a setup it is hard to figure out what could go wrong\n\n----------\n\n[light (2024-10-25T12:22:35.667Z)]: Getting SSL issues on work machine, any suggestions how to ignore that here?\nI’ve tried using work certs which haven’t worked so far.\n\n----------\n\n[DudaNogueira (2024-10-25T12:29:02.855Z)]: hi @light !\nYou may have a http ssl proxy of some sort, like zscaler or fortigate.\nYou can work around this by getting the Root CA and patching the certifi one.\nThis is an example for zscaler:\ncat ZscalerRootCA.pem >> $(python -m certifi)\n\nas per this doc\nLet me know if this is your scenario.\nThanks\n\n----------\n\n[light (2024-10-25T12:50:15.148Z)]: DudaNogueira:\n\ncat ZscalerRootCA.pem >> $(python -m certifi)\n\n\nI think our company uses palo/GP for packet inspection stuff replacing all our certs. So can be annoying to work around that, so often I just try set to verify=false or ignore tls/ssl etc.\nAlso don’t have grpc endpoint setup yet, not sure if a fake one will cause issues and allow us to use rest only or something.\n\n----------\n\n[Radomir_Babek (2024-10-29T07:43:33.444Z)]: Hi, sorry for the response delay. Http works just fine. I can acccess meta endpoint so I guess there won’t be other problems.\nUnfortunatelly after some research I came to the conclusion gRPC cannot be hosted on the custom path. We as a team will probably have to do some additional set up, it’s up to you if you want to include the http path option.\nEDIT: I should probably include the error message, seems it fails on DNS resolution, might look at it a little more\nTraceback (most recent call last):\nFile “X\\Python310\\site-packages\\weaviate\\connect\\v4.py”, line 701, in _ping_grpc\nres: health_pb2.HealthCheckResponse = await self._grpc_channel.unary_unary(\nFile “X\\Python310\\site-packages\\grpc\\aio_call.py”, line 327, in await\nraise _create_rpc_error(\ngrpc.aio._call.AioRpcError: <AioRpcError of RPC that terminated with:\nstatus = StatusCode.UNAVAILABLE\ndetails = “DNS resolution failed for https://www.Y.com:443/weaviate/grpc: UNAVAILABLE: getaddrinfo: WSA Error (Unable to retrieve error string – 11001)”\ndebug_error_string = “UNKNOWN:Error received from peer  {grpc_message:“DNS resolution failed for https://www.Y.com:443/weaviate/grpc UNAVAILABLE: getaddrinfo: WSA Error (Unable to retrieve error string – 11001)”, grpc_status:14, created_time:“2024-10-29T07:37:51.2977311+00:00”}”\n\n----------\n\n[Dirk (2024-10-29T15:43:27.649Z)]: Radomir_Babek:\n\nUnfortunatelly after some research I came to the conclusion gRPC cannot be hosted on the custom path\n\n\nThank you for getting back! I think in this case we will not add an additional path argument for http\n\n----------\n\n[Radomir_Babek (2024-10-30T12:14:36.578Z)]: Very much understandable. Thank you for your effort",
    "date_created": "2024-10-21T12:34:05.396Z",
    "has_accepted_answer": false,
    "title": "V4 Client can't parse my custom url",
    "topic_id": 5818
  },
  {
    "user_id": 3257,
    "conversation": "[Tatali (2025-02-04T09:01:54.719Z)]: Description\nI followed this documentation Multimodal Embeddings | Weaviate to use jinaa model (jina-embeddings-v3) to create images embeddings with WCS. But I end uo with the followinf error:\nConfigure.NamedVectors.multi2vec_jinaai(\nAttributeError: type object ‘_NamedVectors’ has no attribute ‘multi2vec_jinaai’. Did you mean: ‘multi2vec_bind’?\nSo I’ll  like to know how to use the jina-embeddings-v3 model.\n\n----------\n\n[DudaNogueira (2025-02-04T12:59:37.396Z)]: hi @Tatali !!\nWhat is the version of your client?\nThis can happen if you have an outdated client.",
    "date_created": "2025-02-04T09:01:54.672Z",
    "has_accepted_answer": false,
    "title": "'_NamedVectors' has no attribute 'multi2vec_jinaai'",
    "topic_id": 10014
  },
  {
    "user_id": 3413,
    "conversation": "[Bennett_Summy (2025-02-12T18:42:59.224Z)]: Description\n\nI am struggling with my implementation, and I haven’t been able to figure out why this has been happening in the documentation. I am using a hybrid query, and attempting to encode a legal document. However, no matter what I try, I keep getting the same error. It seems like I’m configuring something wrong, but I don’t feel like this error message or the docs are useful.\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\nstatus = StatusCode.UNKNOWN\ndetails = “object search at index schema_section: local shard object search schema_section_tAdIk3D5F6jA: Searching by property ‘article_number’ requires inverted index. Is indexSearchable option of property ‘article_number’ enabled? Set it to true or leave empty”\n            properties=[\n                Property(name=\"content\", data_type=DataType.TEXT, indexSearchable=True),\n                Property(name=\"title\", data_type=DataType.TEXT, indexSearchable=True),\n                Property(name=\"article_number\", data_type=DataType.INT),\n                Property(name=\"section_number\", data_type=DataType.INT, nullable=True),\n                Property(name=\"category\", data_type=DataType.TEXT),\n                Property(name=\"effective_date\", data_type=DataType.DATE),\n                Property(name=\"document_source\", data_type=DataType.TEXT),\n            ]\n\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2025-02-12T21:55:26.438Z)]: hi @Bennett_Summy !!\nWelcome to our community  !!\nIndexSearchable will only be applicable to text and text, as per this doc. So you cannot search an integer field.\nindexFilterable on the other hand will allow you to filter by that property.\nIt means you can do this:\ncollection.query.bm25(query=\"greeting\", filters=wvc.query.Filter.by_property(\"article_number\").equal(1))\n\nHowever, you cannot do this:\ncollection.query.bm25(query=\"Hello\", query_properties=[\"article_id\"])\n\nNow, if you want to check the resulting properties, you can check with:\ncollection.config.get().to_dict().get(\"properties\")\n\nfor instance:\n[{'name': 'content',\n  'dataType': ['text'],\n  'indexFilterable': True,\n  'indexSearchable': True,\n  'indexRangeFilters': False,\n  'tokenization': 'word',\n  'moduleConfig': {'none': {}}},\n {'name': 'title',\n  'dataType': ['text'],\n  'indexFilterable': True,\n  'indexSearchable': True,\n  'indexRangeFilters': False,\n  'tokenization': 'word',\n  'moduleConfig': {'none': {}}},\n {'name': 'article_number',\n  'dataType': ['int'],\n  'indexFilterable': True,\n  'indexSearchable': False,\n  'indexRangeFilters': False,\n  'tokenization': None,\n  'moduleConfig': {'none': {}}},\n {'name': 'section_number',\n  'dataType': ['int'],\n  'indexFilterable': True,\n  'indexSearchable': False,\n  'indexRangeFilters': False,\n  'tokenization': None,\n  'moduleConfig': {'none': {}}},\n {'name': 'category',\n  'dataType': ['text'],\n  'indexFilterable': True,\n  'indexSearchable': True,\n  'indexRangeFilters': False,\n  'tokenization': 'word',\n  'moduleConfig': {'none': {}}},\n {'name': 'effective_date',\n  'dataType': ['date'],\n  'indexFilterable': True,\n  'indexSearchable': False,\n  'indexRangeFilters': False,\n  'tokenization': None,\n  'moduleConfig': {'none': {}}},\n {'name': 'document_source',\n  'dataType': ['text'],\n  'indexFilterable': True,\n  'indexSearchable': True,\n  'indexRangeFilters': False,\n  'tokenization': 'word',\n  'moduleConfig': {'none': {}}}]\n\nLet me know if this helps!\nThanks!",
    "date_created": "2025-02-12T18:42:59.170Z",
    "has_accepted_answer": false,
    "title": "Help with isIndexSearchable",
    "topic_id": 10287
  },
  {
    "user_id": 2974,
    "conversation": "[ReverseHobo (2024-12-09T23:01:16.843Z)]: Hey, was wondering if it is possible to apply a like filter to match any text from a property that is a text array?\nFor example, here we filter so that the “answer” (text type) must match *inter*.\njeopardy = client.collections.get(\"JeopardyQuestion\")\nresponse = jeopardy.query.fetch_objects(\n    filters=Filter.by_property(\"answer\").like(\"\\*inter*\"),\n    limit=3\n)\n\nBut say that each object had multiple answers, stored in in a TEXT ARRAY called “answers”. How could we then filter to only include objects where any of the texts in “answers” match like *inter*?\nSo what I’m asking, is it possible use a like filter to match any in strings from a TEXT ARRAY property?\n\n----------\n\n[DudaNogueira (2024-12-10T00:50:56.553Z)]: hi @ReverseHobo !\nI believe this is what you are asking:\ncollection.data.insert({\"text\": \"this is a test\", \"array\": [\"one\", \"two\", \"three\"]})\ncollection.data.insert({\"text\": \"this one test\", \"array\": [\"four\", \"five\", \"six\"]})\n\n# now we filter with like, or equal\ncollection.query.fetch_objects(\n    filters=wvc.query.Filter.by_property(\"array\").like(\"*ive\")\n).objects\n\ncollection.query.fetch_objects(\n    filters=wvc.query.Filter.by_property(\"array\").equal(\"four\")\n).objects\n\n\nThis is because everything will become a token. So you are not matching against a field (unless you specify the tokenization to field, more on tokenization here), but against tokens.\nLet me know if this clarifies it.\nThanks!",
    "date_created": "2024-12-09T23:01:16.800Z",
    "has_accepted_answer": false,
    "title": "Using like filter on text array",
    "topic_id": 9172
  },
  {
    "user_id": 1055,
    "conversation": "[Hamza_Rezgui (2024-08-24T09:01:26.880Z)]: Description\nSo i’m using weaviate to store chunks of my documents so i can perform a similarity search between a sent query and these chunks, my problem is that im not getting the chunks that are really related to my query, so my question would be how can i know that i setup the schema in the correct way and that im using the right similarity search function.\nWeaviate setup\nclient = weaviate.connect_to_local(host=\"weaviate\")\nSchema creation & Initialization\ndef create_schema():\n    client.collections.create(\n    \"DocumentChunk\",\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_transformers(\n            name=\"vector\",\n            source_properties=[\"chunk\"]\n        )\n    ],\n    properties=[\n        Property(name=\"source_document\", data_type=DataType.TEXT),\n        Property(name=\"chunk\", data_type=DataType.TEXT),\n    ]\n)\n\ndef initialize_schema():\n    try:\n        # Check if the schema already exists\n        response = client.collections.list_all(simple=False)\n        classes = [cls['class'] for cls in response['classes']]\n        if 'DocumentChunk' not in classes:\n            create_schema()\n            print(\"Schema created.\")\n        else:\n            print(\"Schema already exists.\")\n    except Exception as e:\n        print(f\"Error initializing schema: {str(e)}\")\n\nSimilarity search to my query\ndef search_vectors_comment(query):\n    collection = client.collections.get(\"DocumentChunk\")\n    response = collection.query.near_text(\n    query=query,  # The model provider integration will automatically vectorize the query\n    limit=3,\n    distance=0.75\n    )\n    search_results = []\n    for obj in response.objects:\n        result = OrderedDict([\n            (\"title\", obj.properties[\"source_document\"]),\n            (\"snippet\", obj.properties[\"chunk\"]),\n            (\"distance\", obj.metadata)\n        ])\n        search_results.append(result)\n    return search_results\n\nthe meta data attribute in the return values gives me this object on each returned chunk\n{\n    distance: {\n      certainty: null,\n      creation_time: null,\n      distance: null,\n      explain_score: null,\n      is_consistent: null,\n      last_update_time: null,\n      rerank_score: null,\n      score: null\n    }\n\nI would seriously want to know what’s the issue and how I can really fix it this is all new to me and thanks !\n\n----------\n\n[Fakhri_Prayatna_Putr (2024-08-24T12:52:26.384Z)]: Where is the target vector in your query?\n\n----------\n\n[Hamza_Rezgui (2024-08-25T06:25:05.852Z)]: So i did specifiy a target vector in my search query but it did not change anything !\n\n----------\n\n[DudaNogueira (2024-08-26T12:37:25.668Z)]: hi @Hamza_Rezgui !!\nYou need to specify which metadata you want to return in your query, like so:\nresponse = collection.query.near_text(\n    query=\"teste\",  # The model provider integration will automatically vectorize the query\n    limit=3,\n    distance=0.75,\n    return_metadata=wvc.query.MetadataQuery(\n        distance=True, creation_time=True, certainty=True, explain_score=True,\n        is_consistent=True, last_update_time=True, score=True\n    )\n)\nfor obj in response.objects:\n    print(obj.metadata)\n\nnote that explain_score and score for example should not have anything, as it is only used for hybrid and bm25.\nLet me know if this helps.\nThanks!",
    "date_created": "2024-08-24T09:01:26.832Z",
    "has_accepted_answer": true,
    "title": "Similarity search issues",
    "topic_id": 3444
  },
  {
    "user_id": 1789,
    "conversation": "[teapotboy (2024-11-01T16:13:47.967Z)]: Description\n\nI’m trying to multiprocess my RAG with around 4 million queries. The queries are over one cluster but with different metadata filters. I have used ThreadPoolExecutor but there seems to be no improvement. I thought that each query can be paralleled on one cpu. Any idea how I should speed up the whole process? Thank you!\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-11-04T14:19:33.803Z)]: Hi @teapotboy\nCan you provide the version of both server and client you are using?\nAre you running a multinode environment?\nThanks!\n\n\n\n teapotboy:\n\n\nWeaviate Server Version:\nDeployment Method:\nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\n----------\n\n[Dirk (2024-11-04T14:51:39.170Z)]: You could try the async API: Async API | Weaviate",
    "date_created": "2024-11-01T16:13:47.923Z",
    "has_accepted_answer": false,
    "title": "Best way to multiprocess",
    "topic_id": 7377
  },
  {
    "user_id": 509,
    "conversation": "[2020ashish (2024-11-08T08:43:47.236Z)]: Description\n\nHello I am getting hnsw_vector_cache_prefill in log very frequently.\nimage3072×377 137 KB\nI don’t information on this log.\nIn addition of above, I am also getting  Query call with protocol GRPC batch failed with message Deadline Exceeded and also\n\nCan any one help me ?\nServer Setup Information\n\nWeaviate Server Version: 1.27.1\nDeployment Method: \nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python-latest\nMultitenancy?:  Yes\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-11-08T11:11:11.886Z)]: hi @2020ashish !!\nWelcome to our community \nthe hnsw_vector_cache_prefill is just a INFO log, so no worries here.\nCan you paste the entire stack trace error for the second issue?\n\n----------\n\n[2020ashish (2024-11-12T11:26:59.422Z)]: Apologize, for late reply\nIt was from OOMKill issue.\nI have few question.\nIn our case we have ingest all of data which is semi structured.\nWhile ingesting there are so many read/ write operation to update previous data.\n\nWhile ingestion, First I check if data exist or not then update certain field. Ingestion time is less compare to updation time. What should be best approach ?\n\n----------\n\n[DudaNogueira (2024-11-12T12:40:38.097Z)]: Hi! The best approach is doing a batch with deterministic IDs.\nIf you want to define a fixed ID for each object, that’s the way to go:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCreate objects | Weaviate\n\n  The examples on this page demonstrate how to create individual objects in Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nRemember to use batch instead of insert or insert_many\nLet me know if this helps!\nThanks!\n\n----------\n\n[2020ashish (2024-11-12T13:13:00.113Z)]: We are using batch.\nWhile ingestion we need to check if record exist or not than inserting.\nSample code provide, how we are ingesting data in some case.\nwhile updation time is huge for below approach.\nPlease suggest any optimized way ?\nclass_name = \"Book\"\nif client.collections.exists(class_name):\n    client.collections.delete(class_name)\nclient.collections.create(\n    name=class_name,\n    vectorizer_config=wcc.Configure.Vectorizer.text2vec_transformers(),\n    multi_tenancy_config=wcc.Configure.multi_tenancy(enabled=True),\n    inverted_index_config=wcc.Configure.inverted_index(\n        index_timestamps = True\n    ),\n    properties=[\n        wcc.Property(\n            name=\"Book_name\",\n            data_type=wcc.DataType.TEXT,\n            tokenization=wcc.Tokenization.FIELD,\n        ),\n        wcc.Property(\n            name=\"Author\",\n            data_type=wcc.DataType.TEXT,\n            tokenization=wcc.Tokenization.WORD,\n            skip_vectorization=True,\n        ),\n        wcc.Property(\n            name=\"Book_Summary\",\n            data_type=wcc.DataType.TEXT,\n            tokenization=wcc.Tokenization.FIELD,\n            \n        ),\n        wcc.Property(\n            name=\"Update_date\",\n            data_type=wcc.DataType.TEXT,\n            tokenization=wcc.Tokenization.FIELD,\n            skip_vectorization=True,\n        ),\n    ],\n)\n\n\ndef check_book_exist(client, class_name, value, tenant):\n    filter = wvc.query.Filter.by_property(\"Book_name\").equal(value)\n    class_obj = client.collections.get(class_name).with_tenant(tenant)\n    response = class_obj.query.fetch_objects(filters=filter, limit=1)\n    uuid = None\n    for o in response.objects:\n        uuid = o.uuid\n    return uuid\n\ndef update_records(uuid, collection, data, tenant, client):\n    class_obj = client.collections.get(collection).with_tenant(tenant)\n    class_obj.data.update(\n        uuid=uuid,\n        properties=data,\n    )\n\ndef parser(data,tenant):\n    with client.batch.fixed_size(batch_size=100) as batch:\n        book_uuid = check_book_exist(\n            client = client,\n        class_name= \"Book\",\n            value = data.get(\"Book_name\"),\n            tenant = tenant,\n        )\n        if book_uuid is None:\n            book_data = { \"Book_name\": data.get(\"Book_name\"),\n                        \"Author\": data.get(\"Author\"),\n                        \"Book_Summary\": data.get(\"Book_Summary\"),\n                        \"Update_date\": data.get(\"Update_date\"),\n                }\n            batch.add_object(\n                properties=book_data,\n                collection=\"Book\",\n                tenant=tenant,\n            )\n            print(\"Added the record for book name\", data.get(\"Book_name\"))\n        else:\n            update_records(\n                tenant=tenant,\n                client=client,\n                uuid=book_uuid,\n                collection=\"Book\",\n                data={\"Update_date\": data.get(\"Update_date\")},\n            )\n            print(\"Update the record for book name\", data.get(\"Book_name\"))\n\n----------\n\n[DudaNogueira (2024-11-12T13:40:02.639Z)]: Hi!\nIf you can define an id per book, you can do this:\nimport numpy as np\n\nfrom weaviate.util import generate_uuid5\nx = 1000\ncollection_name = \"Book\"\n\ncollection = client.collections.get(collection_name)\nwith collection.batch.dynamic() as batch:\n    for i in range(x):\n        batch.add_object(\n            {\"text\": f\"{collection_name}, object {i}\"},\n            vector=np.random.rand(1536),\n            uuid=generate_uuid5(f\"book-id-{i}\")\n        )\n\nif collection.batch.failed_objects:\n    print(\"Failed Objects: \", collection.batch.failed_objects)\n\nSo passing a fixed uuid (generated from a book-id from your system, for example) will make the batch process to insert or update. if there is an object with the same id: it updates or do nothing, and if there isn’t, it creates.\n\n----------\n\n[2020ashish (2024-11-13T10:04:08.355Z)]: {“action”:“lsm_replace_compacted_segments_blocking”,“build_git_commit”:“05de0db”,“build_go_version”:“go1.22.8”,“build_image_tag”:“v1.27.1”,“build_wv_version”:“1.27.1”,“class”:“Book”,“index”:“Book”,“level”:“warning”,“msg”:“replacing compacted segments took 343.492803ms”,“path_left”:“/var/lib/weaviate/Book/4921/lsm/property_exploit_available_nullState/segment-1731491661482528037.db”,“path_right”:“/var/lib/weaviate/Book/4921/lsm/property_exploit_available_nullState/segment-1731491804128129752.db”,“segment_index”:7,“shard”:“4921”,“time”:“2024-11-13T09:59:06Z”,“took”:343492803}\nHey @DudaNogueira\nIn this logs what is “took”:343492803. What is problem with weaviate ?\n\n----------\n\n[2020ashish (2024-11-13T12:08:58.053Z)]: I have multiple cases and need help optimizing the code:\n\nCase 1: Suppose I have an additional property, \"is_new\", in the Book schema. Initially, is_new will be set to True when a book is added for the first time. If the same book title appears again, is_new should be set to False.\n\nwcc.Property(\n            name=\"is_new\",\n            data_type=wcc.DataType.BOOL         \n        )\n\nCase 2: I have another collection called Publication, which has its own properties and a cross-reference between Book and Publication.\n properties=[\n        wcc.Property(\n            name=\"Publication_Title\",\n            data_type=wcc.DataType.TEXT,\n        ),\n        wcc.Property(\n            name=\"Publication_Date\",\n            data_type=wcc.DataType.TEXT,\n             ),\n        wcc.ReferenceProperty(\n            name=\"Book_Reference\",\n            target_collection=\"Book,\n    ],\n\nI have two separate files for ingestion: book.csv, which contains author details, and publication.csv, which contains publication details. Each collection is ingested separately, with book.csv ingested first, followed by publication.csv.\nDuring publication.csv ingestion, we need to check if each book exists in the Book collection (mapping by a non-UUID field),  fetch its UUID, and then link it to Publication.\nHow can we verify ( if Book exist ) then link ( Publication & Book), and ingest the data effectively?\n\n----------\n\n[Mohamed_Shahin (2024-11-15T10:45:58.050Z)]: Hey @2020ashish, as per thread Metadata properties - #3 by 2020ashish,\nMy answer based on your last message in this thread, since you have two files and are batching each separately, I would recommend going with a cross-reference approach. It will work well in your case, especially when you need to query and filter metadata. I wouldn’t go for a boolean property (is_new) unless there’s a compelling reason for it.\nWith two collections and one cross-reference, performance should not be an issue unless your queries become unusually complex. Based on my experience with similar use cases, a cross-reference is a solution for this scenario. This approach is clean, and maintainable for batching workflow.\nDoes that help?",
    "date_created": "2024-11-08T08:43:47.157Z",
    "has_accepted_answer": false,
    "title": "I am getting hnsw_vector_cache_prefill frequently",
    "topic_id": 7501
  },
  {
    "user_id": 132,
    "conversation": "[Krishna_C (2024-10-04T02:49:30.180Z)]: Hi, we are trying to create a schema which will support multimodal search where user can use text queries but needs to do semantic search across columns containing text or vectors.\nBelow is the schema  where image_embeddings is a Bring your own vector column where we will generate the embeddings for a imageand dont want weaviate to create vectors, but this needs to be part of multimodal search with other fields like filename, tags, mime_type. Please provide the correct way to define schema for this multimodal search with Bring your own vector?\nclient.collections.create(\n    name=\"SemanticSchema\",  # The name of the collection ('NV' for named vectors)\n    properties=[\n        wc.Property(name=\"lcid\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"checksum\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"filename\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"tags\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"mime_type\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"person_names\", data_type=wc.DataType.TEXT_ARRAY),\n        wc.Property(name=\"location\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"image_embeddings\", data_type=wc.DataType.NUMBER_ARRAY),\n    ],\n    # Define & configure the vectorizer module\n    vectorizer_config=[\n\n        wc.Configure.NamedVectors.multi2vec_clip(\n            name=\"filename\", text_fields=[\"filename\"]\n        ),\n\n        wc.Configure.NamedVectors.multi2vec_clip(\n            name=\"tags\", text_fields=[\"tags\"]\n        ),\n\n        wc.Configure.NamedVectors.multi2vec_clip(\n            name=\"mime_type\", text_fields=[\"mime_type\"]\n        ),\n\n        wc.Configure.NamedVectors.multi2vec_clip(\n            name=\"location\", text_fields=[\"location\"]\n        ),\n \n        wc.Configure.NamedVectors.multi2vec_clip(\n            name=\"image_filename_tags\",\n            image_fields=[\n                wc.Multi2VecField(name=\"image_embeddings\")\n            ],  # 90% of the vector is from the poster\n            text_fields=[\n                wc.Multi2VecField(name=\"filename\"),\n                wc.Multi2VecField(name=\"tags\"),\n                wc.Multi2VecField(name=\"mime_type\"),\n                wc.Multi2VecField(name=\"location\"),\n            ],  # 10% of the vector is from the title\n        ),\n    ],\n    # Define the generative module\n    #generative_config=wc.Configure.Generative.openai(),\n\n    # Add sharding configuration\n    sharding_config=Configure.sharding(\n       virtual_per_physical=128,\n       desired_count=2,\n       desired_virtual_count=128,\n    ),\n    replication_config=Configure.replication(\n        factor=2,\n        async_enabled=True,\n    ),\n)\n\n----------\n\n[DudaNogueira (2024-10-04T08:48:03.206Z)]: hi @Krishna_C !!\nWelcome back to our forums \nThere are some problems with this schema, and some couple of things you must understand on how our multi2vec_clip works so you can make the most out of it.\nFirst, I see you may be storing the image embeddings as a property. This is far from optimal, as the inverted index will create keyword indexes for your vectors\nThat will lead to unnecessary memory usage, as you don’t want to perform keyword searches on your vector dimensions \nIf you really want to do that, you need to make sure to specify that this property shouldn’t be searchable nor filterable, like so:\n        wvc.config.Property(\n            name=\"image_embeddings\", \n            data_type=wc.DataType.NUMBER_ARRAY, \n            index_filterable=False, \n            index_searchable=False\n        ),\n\nThe second issue I see is this:\n            image_fields=[\n                wc.Multi2VecField(name=\"image_embeddings\")\n            ],\n\nAnd the problem here is that the image field must be a blob, and not the image vector, as we state in our docs:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMultimodal (CLIP) Embeddings | Weaviate\n\n  Weaviate's integration with the Hugging Face Transformers library allows you to access their CLIP models' capabilities directly from Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNow, the way that our multi2vec_clip works is that Weaviate will generate a vector for all texts fields and image fields, and combine those vectors.\nSo you may not need to have one named vector for each of the properties isolated. If you have one vector for all text and image, that vector will ve a representation of those content.\nLet me know if this clarifies and how I can help you further.\nThanks!\n\n----------\n\n[Krishna_C (2024-10-07T06:49:43.196Z)]: thanks @DudaNogueira  !   I still have below questions-  pls clarify\nin weavite, in below schema if i use below schema and later set the vector field as a bring your own vector where i am using SentenceTransformer(‘clip-ViT-B-32’) model then while searching for the text query, should i vectorize the query (query=“button”) before searching so that it can perform serach across the dfferent vectors in the schema?\nWill the result be a union of matches among different vectors (tags, multi2vec_clip vectors defined and the vector field set while data import - vector=image_embeddings.tolist(),)?\nsearch code:\nsemanticSchema = client.collections.get(“SemanticSchema”)\nresponse = semanticSchema.query.hybrid(\nquery=“button”,\ntarget_vector=“image_filename_tags”,\nreturn_metadata=MetadataQuery(score=True, explain_score=True),\nlimit=3,\n)\nschema definition:\nclient.collections.create(\nname=“SemanticSchema_BYOV”,  # The name of the collection (‘NV’ for named vectors)\nproperties=[\nwc.Property(name=“lcid”, data_type=wc.DataType.TEXT),\nwc.Property(name=“checksum”, data_type=wc.DataType.TEXT),\nwc.Property(name=“filename”, data_type=wc.DataType.TEXT),\nwc.Property(name=“tags”, data_type=wc.DataType.TEXT, vectorizer=“multi2vec-clip”),\nwc.Property(name=“mime_type”, data_type=wc.DataType.TEXT),\nwc.Property(name=“person_names”, data_type=wc.DataType.TEXT_ARRAY, vectorizer=“multi2vec-clip”),\nwc.Property(name=“location”, data_type=wc.DataType.TEXT),\nwc.Property(name=“image_embeddings”, data_type=wc.DataType.NUMBER_ARRAY,index_filterable=False,index_searchable=False),\n],\n# Define & configure the vectorizer module\n# Define the vectorizer module (none, as we will add our own vectors)\n# Define & configure the vectorizer module\nvectorizer_config=wc.Configure.Vectorizer.multi2vec_clip(\ntext_fields=[\nwc.Multi2VecField(name=“filename”),\nwc.Multi2VecField(name=“tags”),\nwc.Multi2VecField(name=“mime_type”),\nwc.Multi2VecField(name=“location”),\n]),\n# Define the generative module\n#generative_config=wc.Configure.Generative.openai(),\n    # Add sharding configuration\n    sharding_config=Configure.sharding(\n       virtual_per_physical=128,\n       desired_count=2,\n       desired_virtual_count=128,\n    ),\n    replication_config=Configure.replication(\n        factor=2,\n        async_enabled=True,\n    ),\n)\n\nData insert of Bring Your own vector :\nDefine the function to generate embeddings using CLIP\ndef generateEmbeddingsForImage(img_path):\nmodel = SentenceTransformer(‘clip-ViT-B-32’)\nimage = Image.open(img_path).convert(‘RGB’)\nembeddings = model.encode(image)\nreturn embeddings\nInsert the single record into Weaviate\ndata_object = {\n“lcid”: “a510a7badc1849eb997555073e3953fe1”,\n“checksum”: “checksum1”,\n“filename”: “Albert-Einstein”,\n“mime_type”: “jpg”,\n“person_names”: [“Albert Einstein”],\n“tags”: json.dumps([\n{“name”: “human face”, “confidence”: 0.9927250146865845},\n{“name”: “clothing”, “confidence”: 0.9834420680999756},\n{“name”: “person”, “confidence”: 0.9827311038970947},\n{“name”: “wrinkle”, “confidence”: 0.9579571485519409},\n{“name”: “portrait”, “confidence”: 0.954142689704895},\n{“name”: “forehead”, “confidence”: 0.924140453338623},\n{“name”: “chin”, “confidence”: 0.9210121631622314},\n{“name”: “senior citizen”, “confidence”: 0.8994851112365723},\n{“name”: “human”, “confidence”: 0.8762668371200562},\n{“name”: “jaw”, “confidence”: 0.8676725625991821},\n{“name”: “indoor”, “confidence”: 0.758019089698791}\n]),\n“location”: “Germany”,\n“image_embeddings”: image_embeddings.tolist()  # Convert embeddings to a list for insertion\n}\nInsert the object into Weaviate under the “SemanticSchema” class\ntry:\nGenerate image embeddings for the provided image\nimage_embeddings = generateEmbeddingsForImage(“./pics/Albert-Einstein.jpg”)\nsemanticSchema = client.collections.get(\"SemanticSchema_BYOV\")\nuuid = semanticSchema.data.insert(\n    properties=data_object,\n    **vector=image_embeddings.tolist(),**\n    uuid=generate_uuid5(data_object),\n)\nprint(\"Data successfully inserted into Weaviate.\")\n\n----------\n\n[DudaNogueira (2024-10-07T09:16:45.818Z)]: hi!\nIf you define the vectorizer properly, you can still provide your own vector, and use the near_text.\nWhat will happen “under the hood” is that Weaviate will vectorize your query.\nIf you do not define the vectorizer for your named vector, Weaviate has no way on vectorizing your data.\nSo you will need to vectorize your query too, and provide it when querying, so instead of query, you will use the query_vector.\nLet me know if this helps.\n\n----------\n\n[Krishna_C (2024-10-07T10:42:40.655Z)]: But how to search over my Bring your own vector and also the named vectors in a single search query?\n\n----------\n\n[Krishna_C (2024-10-07T13:41:06.229Z)]: @DudaNogueira  pls advise how to modify the below schema and perform a hybrid search for the Bring your own vector scenario; Also if i have to have another field like tags for which i need  to vectorize usign weaviate vectorizer , how to define the schema and search ? Basically i need a\na) image_embeddings field that needs to store Bring Your Own vector and\nb) another vector on a combination of one or more fields like (filename, tags)\n**AND **\nc) i should be able to search across these vectors like a multi vector search or hybrid search. pls provide altered schema and data insert and search code?\nSchema:\nclient.collections.create(\nname=“SemanticSchema_BYOV1”,  # The name of the collection (‘NV’ for named vectors)\nproperties=[\nwc.Property(name=“lcid”, data_type=wc.DataType.TEXT),\nwc.Property(name=“checksum”, data_type=wc.DataType.TEXT),\nwc.Property(name=“filename”, data_type=wc.DataType.TEXT),\nwc.Property(name=“tags”, data_type=wc.DataType.TEXT),\nwc.Property(name=“mime_type”, data_type=wc.DataType.TEXT),\nwc.Property(name=“person_names”, data_type=wc.DataType.TEXT_ARRAY),\nwc.Property(name=“location”, data_type=wc.DataType.TEXT),\nwc.Property(name=“image_embeddings”, data_type=wc.DataType.NUMBER_ARRAY, vectorizer_config=Configure.Vectorizer.none),\n],\n# Configure the multi2vec-clip vectorizer for text fields\nvectorizer_config=Configure.Vectorizer.multi2vec_clip(\ntext_fields=[\nwc.Multi2VecField(name=“filename”),\nwc.Multi2VecField(name=“tags”),\nwc.Multi2VecField(name=“mime_type”),\nwc.Multi2VecField(name=“location”)\n]\n),\n# Define the generative module\n#generative_config=wc.Configure.Generative.openai(),\n    # Add sharding configuration\n    sharding_config=Configure.sharding(\n       virtual_per_physical=128,\n       desired_count=3,\n       desired_virtual_count=128,\n    ),\n    replication_config=Configure.replication(\n        factor=2,\n        async_enabled=True,\n    ),\n)\n\nInsert Data code:\nInsert the single record into Weaviate\n     data_object = {\n        \"lcid\": lcid,\n        \"checksum\": checksum,\n        \"filename\": file_name,\n        \"mime_type\": mine_type,\n        \"person_names\": [\"person\"],\n        \"tags\": json.dumps(tags),\n        \"location\": location,\n        \"image_embeddings\": image_embeddings  # Bring your own vector\n     }\n\nAdd object to batch queue\n     uuid = semanticSchema.data.insert(\n         properties=data_object,\n         uuid=generate_uuid5(data_object),\n     )\n\n----------\n\n[Krishna_C (2024-10-08T08:05:16.360Z)]: @DudaNogueira  pls provide schema for abv ? I am unable to find a solution for a combination of Bring your own vector and fileds which use wvt vectorizers. I need to make a presentation today. Your inputs will help me! Thanks!\n\n----------\n\n[DudaNogueira (2024-10-14T21:35:53.705Z)]: hi @Krishna_C !\nSorry for the delay.\nThis is how you would insert and query a named vector with bring your own vector:\n# create the collection\nclient.collections.delete(\"NamedVectorCollection\")\ncollection = client.collections.create(\n    name=\"NamedVectorCollection\",\n    vectorizer_config=[\n        wvc.config.Configure.NamedVectors.none(name=\"text_vector\"),\n        wvc.config.Configure.NamedVectors.none(name=\"title_vector\")\n    ],\n    properties=[\n        wvc.config.Property(\n            name=\"text\",\n            data_type=wvc.config.DataType.TEXT,\n            vectorize_property_name=True\n        ),\n        wvc.config.Property(\n            name=\"title\",\n            data_type=wvc.config.DataType.TEXT,\n            vectorize_property_name=True\n        ),\n    ]\n)\n# now we insert data\ncollection.data.insert({\n        \"text\": \"this is a text\",\n        \"title\": \"this is a title\"\n    },\n    vector={\n        \"text_vector\": [1,2,3,4,5],\n        \"title_vector\": [1,2,3,4,5,6,7,8,9,10]\n    }\n)\n# now we query\nquery = collection.query.near_vector(\n    target_vector=[\"text_vector\"],\n    near_vector=[5,4,3,2,1],\n    return_metadata=wvc.query.MetadataQuery(distance=True)\n)\nprint(query.objects[0].properties)\nprint(query.objects[0].metadata.distance)\n\nThis was my output:\n\n{‘text’: ‘this is a text’, ‘title’: ‘this is a title’}\n0.3636362552642822\n\nLet me know if that helps!\n\n----------\n\n[Krishna_C (2024-10-21T10:04:41.039Z)]: Thanks for your response @DudaNogueira ! Could you pls provide a code for Multivector search with bring your own vector field, along with a multivector which use multi2vec vectorizor. The search should happen across these vecors. Is this possible? The Bring Your own vector should not be part of the Multi2vecclip config. The search should be acorss 2 or more vectors. One of them is Bringyourownvector And ((multi2vec) Or Other named vector)",
    "date_created": "2024-10-04T02:49:30.135Z",
    "has_accepted_answer": false,
    "title": "Multimodal search with Bring your own vector",
    "topic_id": 4416
  },
  {
    "user_id": 3103,
    "conversation": "[ziemowit-s (2024-12-25T12:06:48.212Z)]: Hi guys! \nI noticed a strange but important issue (bug?) with cosine similarity in Weaviate. I’m using external SentenceTransformer for vectorization, and when I compare cosine similarity obtained with ScikitLearn - it’s strangely completely different.\nSince I want to be precise I will past my code with both texts where I noticed the difference (they are in polish, but for those who doesn’t know → the first one is the closest answer),  hopefully it’s still be pleasant to read \nSentence Transformer vectorizer:\nmodel = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n\nMy text query and 2 texts to compare:\nquery = \"jakie są kary w kodeksie karnym?\"\n\ntext1 = \"kodeks karny. Start. Kary. 32. Katalog kar. Karami są:1)grzywna;2)ograniczenie wolności;3)pozbawienie wolności;4)(uchylony);5)dożywotnie pozbawienie wolności.\"\n\ntext2 = \"\"\"kodeks karny skarbowy. Część ogólna. Przestępstwa skarbowe. 22. Kary oraz środki karne i zabezpieczające. § 1.Karami za przestępstwa skarbowe są:1)kara grzywny w stawkach dziennych;2)kara ograniczenia wolności;3)kara pozbawienia wolności.\n§ 2.Środkami karnymi są:1)dobrowolne poddanie się odpowiedzialności;2)przepadek przedmiotów;3)ściągnięcie równowartości pieniężnej przepadku przedmiotów;4)przepadek korzyści majątkowej;4a)ściągnięcie równowartości pieniężnej przepadku korzyści majątkowej;5)zakaz prowadzenia określonej działalności gospodarczej, wykonywania określonego zawodu lub zajmowania określonego stanowiska;6)podanie wyroku do publicznej wiadomości;7)pozbawienie praw publicznych;8)środki związane z poddaniem sprawcy próbie:a)warunkowe umorzenie postępowania karnego,b)warunkowe zawieszenie wykonania kary,c)warunkowe zwolnienie.\n§ 3.Środkami zabezpieczającymi są:1)elektroniczna kontrola miejsca pobytu;2)terapia;3)terapia uzależnień;4)pobyt w zakładzie psychiatrycznym;5)przepadek przedmiotów;6)zakazy wymienione w § 2 pkt 5.\"\"\"\n\nScikitLearn cosine implementation:\nquery_embedding = model.encode(query)\nsentence1_embedding = model.encode(ss1)\nsentence2_embedding = model.encode(ss2)\n\n# Compute cosine similarity\nsimilarity = cosine_similarity([query_embedding], [sentence1_embedding])\nprint(\"Text 1 Score:\", similarity[0][0])\n# score: 0.28450348362745925\n\nsimilarity = cosine_similarity([query_embedding], [sentence2_embedding])\nprint(\"Text 2 Score:\", similarity[0][0])\n# score: 0.5143749261108472\n\nScikitLearn results are:\n\nfor the text 1: 0.28450348362745925\nfor the text 2: 0.5143749261108472\n\n\nAs you can see SciKit cosine silimarity correctly distinguishes first text as more similar than the second one.\nWeaviate: collection creation\nvector_config = Configure.VectorIndex.hnsw(\n      distance_metric=VectorDistances.COSINE\n)\n\ncollection = client.collections.create(collection_name,\n                                                                 vector_index_config=vector_config,\n                                                                 vectorizer_config=Configure.Vectorizer.none())\n\nWeaviate: batch adding\nembeddings = model.encode(query).tolist()\nwith collection.batch.dynamic() as batch:\n    for vector, data_row in zip(embeddings, docs):\n        obj_uuid = generate_uuid5(data_row)\n        batch.add_object(\n            properties=data_row,\n            uuid=obj_uuid,\n            vector=vector\n)\n\nWeaviate: near vector search\nfrom weaviate.collections.classes.grpc import MetadataQuery\n\nvector = vectorizer.model.encode(search_query).tolist()\n\nresults = obj.collection.query.near_vector(\n    near_vector=vector,  # your query vector goes here\n    limit=2,\n    return_metadata=MetadataQuery(distance=True, certainty=True))\n\nfor rr in results.objects:\n    print(rr.metadata.distance)\n    print(rr.properties['content'])\n\nWeaviate results are:\n\nfor the text 1: 0.7154964208602905\nfor the text 2: 0.4856252074241638\n\nfor testing I added only those 2 documents to the database.\nI also checked if stored vectors are the same with:\nweaviate_vec = (obj.collection.query.fetch_object_by_id('id_of_first_object', include_vector=True).vector['default'])\n\nnp.sum(np.array(weaviate_vec) - np.array(sentence1_embedding))\n# 0\n\nand they are.\nDo anyone has any idea what’s might going on? I will be very appreciate of your help\n\n----------\n\n[Magdalena_Sochacka (2025-01-14T14:01:29.946Z)]: Hey. Just a suggestion, you used embedding with sklearn as sentence transformer and I’m not sure, but check if in weaviate you have had vectorised it like sentence transformers way or basic like hugging face. I’ve just seen this on custom model page and maybe this is also the case:\nimage1087×260 23.5 KB",
    "date_created": "2024-12-25T12:06:48.150Z",
    "has_accepted_answer": false,
    "title": "Weaviate cosine similarity completelly different than ScikitLearn with SentenceTransformer vectorizer",
    "topic_id": 9436
  },
  {
    "user_id": 3256,
    "conversation": "[Justin_Independent (2025-01-23T13:23:07.261Z)]: Description\nI’m a non-technical user attempting to use Verba with Weaviate to parse and import documents locally. I have explicitly configured my environment to avoid using the Unstructured API by installing the unstructured[local-inference] library in the Dockerfile. However, every attempt to import a document fails with an error that seems to indicate it’s still looking for an API Key.\nHere’s the error I’m seeing in the logs:\nFileStatus.ERROR | Import failed: Reader Unstructured IO failed with:\nNo Unstructured API Key detected\nThe error suggests that the system is expecting an API Key, but my intent is to use local inference exclusively and bypass the need for an API entirely.\nSteps I’ve taken so far:\n\nConfigured Docker:\n\n• Updated the Dockerfile to install the necessary libraries for local inference:\n• unstructured[local-inference] for local document parsing.\n• System dependencies: poppler-utils, tesseract-ocr, and libmagic1.\n• Verified that these libraries are installed in the Docker container during the build process.\n\nEnvironment Variables:\n\n• Removed references to UNSTRUCTURED_API_KEY to avoid reliance on the API.\n• Set DEFAULT_DEPLOYMENT=Local in the .env file to indicate local-only operation.\n\nTesting:\n\n• Verba runs fine and is accessible at localhost:8000.\n• Parsing fails for any document I try to import, whether a .txt or .docx.\nDespite these steps, the system still appears to check for an API Key during parsing, which seems inconsistent with a local-only configuration.\nServer Setup Information\n• Weaviate Server Version: 1.25.10\n• Deployment Method: Docker Compose\n• Multi Node? Number of Running Nodes: No, single-node setup.\n• Client Language and Version: Python, using goldenverba[huggingface] and unstructured[local-inference].\n• Multitenancy?: No\nAny Additional Information\nDocker Compose File:\nservices:\n  verba:\n    build:\n      context: ./\n      dockerfile: Dockerfile\n    ports:\n      - 8000:8000\n    environment:\n      - WEAVIATE_URL_VERBA=http://weaviate:8080\n      - DEFAULT_DEPLOYMENT=Local\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    networks:\n      - verba-network\n\n  weaviate:\n    image: semitechnologies/weaviate:1.25.10\n    ports:\n      - 8080:8080\n    networks:\n      - verba-network\n\nnetworks:\n  verba-network:\n    driver: bridge\n\nDockerfile:\nFROM python:3.11\n\nRUN apt-get update && apt-get install -y \\\n    poppler-utils \\\n    tesseract-ocr \\\n    libmagic1 \\\n    && rm -rf /var/lib/apt/lists/*\n\nRUN pip install \\\n    \"unstructured[local-inference]\" \\\n    \"goldenverba[huggingface]\"\n\nWORKDIR /Verba\nCOPY . /Verba\nRUN pip install \".\"\n\nEXPOSE 8000\nCMD [\"verba\", \"start\", \"--port\", \"8000\", \"--host\", \"0.0.0.0\"]\n\nLogs from Verba:\nINFO:     Will watch for changes in these directories: [‘/Verba’]\nWARNING:  “workers” flag is ignored when reloading is enabled.\nINFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\nINFO:     Application startup complete.\nFileStatus.ERROR | Import failed: Reader Unstructured IO failed with:\nNo Unstructured API Key detected\nSteps Taken:\n• Confirmed the necessary dependencies in Dockerfile.\n• Rebuilt the Docker image with --no-cache.\n• Verified that DEFAULT_DEPLOYMENT=Local is set in the .env file to indicate local-only inference.\n• Removed any reference to UNSTRUCTURED_API_KEY.\nI’m looking for guidance on why the system still expects an API Key despite being configured for local inference. Is there additional setup required to fully enable local inference, or am I missing a step? Any help is appreciated!\n\n----------\n\n[Justin_Independent (2025-01-24T01:20:15.648Z)]: Yikes…no responses? Come on kiddos help me out\n\n----------\n\n[DudaNogueira (2025-01-27T19:47:24.514Z)]: hi @Justin_Independent !!\nJust by removing UNSTRCUTURED api key will not make it run locally.\nThe code for this integration leaves here, and it will only work for the API Service.\nIn order to use that integration locally, a new integration need to be developed.\nThe best place to gathering interest around this is creating a new feature request at:\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nweaviate/Verba\n\n  Retrieval Augmented Generation (RAG) chatbot powered by Weaviate - weaviate/Verba\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!",
    "date_created": "2025-01-23T13:23:07.157Z",
    "has_accepted_answer": false,
    "title": "Help with Verba Integration: Local Inference Failing, Still Asking for API Key",
    "topic_id": 9867
  },
  {
    "user_id": 1220,
    "conversation": "[noban (2024-07-19T08:22:36.031Z)]: Description\nI literally can’t find documentation on how to use (create and perform vector search) namedVectors (like 2 vectors per collection) using my custom vectors. Can anyone point me to the sample script showing how to do that, preferably using V4 syntax?\n\n----------\n\n[DudaNogueira (2024-07-31T21:02:43.054Z)]: hi @noban !!\nWelcome to our community!\nSorry! Missed this message. \nJust discovered some messages that went under my radar \nHope you were able to solve this already \nLuckly, I have just crafted some sample code that can help you on this topic (or for other in the future):\n\n  \n    \n    \n    Authorization header is correct, but the token seems invalid Support\n  \n  \n    hi @Anna_Caroline_Symond !! \nWelcome to our community  \nThis message comes directly from hugging face Api. It indicates that your Hugging Face api token is wrong, not Weaviate’s. \nAlso, there are some other issues with this code, like not passing the vectors your encoded yourself. This will trigger Weaviate to vectorize your object using the Hugging Face. \nYou also created a named vector that uses  title property as source, but was using text as the property receiving the  data. \nI also ch…\n  \n\n\nThis example shows how to use a custom embed model (running locally), that is also offered by Hugging face.\nNow, if you provide the named vectors, like in here:\n            batch.add_object(\n                properties={\"title\": line},\n                vector={\n                    \"title_vector\": vector\n                }\n            )\n\nWeaviate will not reach out to Hugging face to vectorize the object.\nWhile performing searches, you can do the same. For example:\nclient.connect()\ncollection = client.collections.get(\"Test\")\n\nquery_vector = model.encode([\"pet animals\"])\n\nobjects = collection.query.near_vector(\n    near_vector=query_vector[0], \n    return_metadata=wvc.query.MetadataQuery(distance=True),\n    include_vector=True,\n    target_vector=\"title_vector\"\n).objects\nfor object in objects:\n    print(\"#\" * 10)\n    print(object.metadata.distance)\n    print(object.properties)\n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-07-19T08:22:35.980Z",
    "has_accepted_answer": false,
    "title": "namedVectors with custom embedder?",
    "topic_id": 3101
  },
  {
    "user_id": 766,
    "conversation": "[Rohan_Purohit (2024-10-30T01:24:05.046Z)]: I’m trying to deploy the LaBSE model from Hugging Face (sentence-transformers/LaBSE · Hugging Face) to AWS SageMaker and use it for embeddings in Weaviate. I have configured Weaviate with the following multi_tenancy settings:\n{\n  \"classes\": [\n    {\n      \"class\": \"BMP\",\n      \"multiTenancyConfig\": {\"enabled\": True},\n      \"description\": \"File uploaded\",\n      \"moduleConfig\": {\n        \"text2vec-aws\": {\n          \"name\": \"title_vector\",\n          \"region\": \"us-east-1\",\n          \"service\": \"sagemaker\",\n          \"endpoint\": \"https://runtime.sagemaker.us-east-1.amazonaws.com/endpoints/hf-labse-st-******/invocations\"\n        }\n      },\n      \"properties\": [\n        {\n          \"name\": \"fileName\",\n          \"dataType\": [\"text\"],\n          \"description\": \"Name of the file\"\n        },\n        {\n          \"name\": \"content\",\n          \"dataType\": [\"text\"],\n          \"description\": \"The content of the file\"\n        },\n        {\n          \"name\": \"source\",\n          \"dataType\": [\"text\"],\n          \"description\": \"The source of the uploaded file\"\n        }\n      ],\n      \"vectorizer\": \"text2vec-aws\"\n    }\n  ]\n}\n\nI am encountering repeated errors in response, specifically:\n{'error': [{'message': \"unmarshal response body: invalid character '<' looking for beginning of value\"}]}\n\nThis error appears to occur during the response parsing, possibly due to unexpected response content.\nServer Setup Information\n\nDeployment Method: Docker\nMulti Node? Number of Running Nodes: Single Node\nClient Language and Version: Python, weaviate-client version 4.5.5\nMultitenancy?: Enabled\n\nAny Additional Information\nI have double-checked the SageMaker endpoint, and the configuration seems correct based on the Weaviate documentation.\nI would appreciate any guidance on resolving this error, as it appears to be related to response parsing from SageMaker.\n\n----------\n\n[Dirk (2024-10-30T09:30:04.931Z)]: Hello,\nI just merged a PR that includes the body in the error message if we cannot parse it. This will be included in the next release\n\n----------\n\n[Rohan_Purohit (2024-10-30T15:41:48.801Z)]: Hi Dirk thanks for the update.\nWill check that for sure.\nBut meanwhile can you tell me if there is anything obvious i’m missing in the config?\n\n----------\n\n[Dirk (2024-10-31T07:13:57.079Z)]: No idea, sorry - @DudaNogueira maybe?\n\n----------\n\n[Rohan_Purohit (2024-11-06T12:46:31.000Z)]: With the latest release this is the response i get\nObject was not added! Unexpected status code: 500, with response body: {'error': [{'message': \"vectorize target vector title_vector: update vector: unmarshal response body. Got: <UnknownOperationException/>\\n: invalid character '<' looking for beginning of value\"}]}.\n\nnot much help! please advice what to do next\n\n----------\n\n[DudaNogueira (2024-11-06T13:53:05.093Z)]: hi @Rohan_Purohit !!\nCan you replace the apiurl at run time? Maybe we can reproduce the exact same call so we can catch that exception with in it’s full context while adding that object.",
    "date_created": "2024-10-30T01:24:04.992Z",
    "has_accepted_answer": false,
    "title": "Setup issues with sagemaker endpoint",
    "topic_id": 7285
  },
  {
    "user_id": 1312,
    "conversation": "[pc10 (2024-08-27T21:18:47.152Z)]: Description\n\nI am trying to install weaviate as deployment in our existing helm-chart .\nPreviously I was able to set it up  using docker-compose and it worked fine.\nHowever I want to integrate weaviate into our existing kube cluster, within same helm-chart.\nI see the documentation on weaviate for kubernetes as stand-alone helm-chart deployment, and could find information to support otherwise. Here is my deployment chat. Appreciate any help with this.\nWe already have a weaviate-deployment running on v3 client.I am trying to migrate to v4 and so testing out a deployment with different HTTP and GRPC ports\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: weaviate-v4\n  labels:\n    app: weaviate-v4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: weaviate-v4\n  template:\n    metadata:\n      labels:\n        app: weaviate-v4\n    spec:\n      terminationGracePeriodSeconds: 5\n      imagePullSecrets:\n        - name: regcred\n      containers:\n        - name: weaviate-v4\n          image: semitechnologies/weaviate:1.26.1\n          command:\n            - /bin/sh\n            - -c\n            - |\n              /bin/weaviate \\\n              --host 0.0.0.0 \\\n              --port 4080 \\\n              --scheme http\n              --read-timeout=600s\n              --write-timeout=600s\n          imagePullPolicy: IfNotPresent\n          ports:\n            - containerPort: 4080\n            - containerPort: 50052\n          env:\n           - name: RERANKER_INFERENCE_API\n              value: 'http://vectorstore-reranker:8080'\n            - name: TRANSFORMERS_INFERENCE_API\n              value: \"http://vectorstore-transformers:8080\"\n            - name: QUERY_DEFAULTS_LIMIT\n              value: \"25\"\n            - name: PERSISTENCE_DATA_PATH\n              value: \"/var/lib/weaviate\"\n            - name: DEFAULT_VECTORIZER_MODULE\n              value: \"text2vec-transformers\"\n            - name: ENABLE_MODULES\n              value: \"text2vec-transformers, text2vec-huggingface, reranker-transformers\"\n            - name: CLUSTER_HOSTNAME\n              value: \"node1\"\n          volumeMounts:\n            - mountPath: /var/lib/weaviate\n              name: vectorstore-vol\n      volumes:\n        - name: vectorstore-vol\n          persistentVolumeClaim:\n            claimName: vectorstore-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: weaviate-v4\n  labels:\n    app: weaviate-v4\nspec:\n  type: ClusterIP\n  clusterIP: None\n  selector:\n    app: weaviate-v4\n\n\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method:  k8s\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python\nMultitenancy?:  No\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-08-30T18:39:06.251Z)]: HI! We do have an official helm chart:\n\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate/weaviate-helm: Helm charts to deploy Weaviate to k8s\n\n    Helm charts to deploy Weaviate to k8s\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nMaybe that can help you on customizing it?\n\n----------\n\n[pc10 (2024-09-03T16:50:49.992Z)]: It worked with creating a separate docker-entrypoint instead of adding args and command in the chart itself to provide custom-configs. Thanks much",
    "date_created": "2024-08-27T21:18:47.102Z",
    "has_accepted_answer": true,
    "title": "Install Weaviate in Existing Helm-Chart",
    "topic_id": 3755
  },
  {
    "user_id": 1414,
    "conversation": "[vrano (2024-08-27T11:40:02.293Z)]: Hello,\nI’m building a reverse image search using Weaviate. I use CLIP to embed a product’s title and image and store it into the database. I also have additional properties such as product price which aren’t vectorized but might be used for filtering later on. I was wondering if there was a way to do image and text vectorized search without having the vector or object id at hand. So far the only way I have managed to do it is by generating a vector for the image & title I’m using for search, and searching by vector using that. I also wonder what’s the best way to handle deduplication.\nThanks in advance.\n\n----------\n\n[DudaNogueira (2024-08-27T12:18:50.847Z)]: hi @vrano !! Welcome to our community \nFor avoiding duplicate entries, the best approach is to leverage deterministic ids, which means that you generate the IDs based on some unique id you may have for your objects.\nif you want to do media search, you can use the near_image or near_media (videos/audios) to search. Considering you have vectorizer properly configured on that collection, Weaviate will vectorize the image used in query and use that vector to perform the search.\nHere we have a recipe for multimodal, while it is using multi2vec-bind, it should be the same if using clip:\n\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate-tutorials/multimodal-workshop\n\n    Contribute to weaviate-tutorials/multimodal-workshop development by creating an account on GitHub.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!\nTHanks!\n\n----------\n\n[vrano (2024-08-27T13:17:47.619Z)]: HI @DudaNogueira,\nthat answers all my questions. Thank you for the quick response!\n\n----------\n\n[DudaNogueira (2024-08-27T15:06:28.984Z)]: Glad to hear that!\nBy the way, here is the docs for deterministic ids:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCreate objects | Weaviate - Vector Database\n\n  The examples on this page demonstrate how to create individual objects in Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIf you have any questions, we are here to help!",
    "date_created": "2024-08-27T11:40:02.239Z",
    "has_accepted_answer": true,
    "title": "[Question] Multimodal search",
    "topic_id": 3691
  },
  {
    "user_id": 1789,
    "conversation": "[teapotboy (2024-10-14T10:44:16.543Z)]: Description\n\nI can’t connect to the serverless after uploading a large number of vectors with an error 503. The webpage says Your cluster is being prepared, it may take a few minutes.\nCode and log:\nclient = weaviate.connect_to_wcs(\ncluster_url=os.environ[“WEAVIATE_URL”],\nauth_credentials=weaviate.auth.AuthApiKey(api_key=os.environ[“WEAVIATE_API_KEY”]),\n)\nUnexpectedStatusCodeError                 Traceback (most recent call last)\nCell In[7], line 1\n----> 1 client = weaviate.connect_to_wcs(\n2     cluster_url=os.environ[“WEAVIATE_URL”],\n3     auth_credentials=weaviate.auth.AuthApiKey(api_key=os.environ[“WEAVIATE_API_KEY”]),\n4 )\nFile c:\\Users\\anaconda3\\Lib\\site-packages\\weaviate\\connect\\helpers.py:145, in connect_to_wcs(cluster_url, auth_credentials, headers, additional_config, skip_init_checks)\n94 def connect_to_wcs(\n95     cluster_url: str,\n96     auth_credentials: Optional[AuthCredentials],\n(…)\n99     skip_init_checks: bool = False,\n100 ) → WeaviateClient:\n101     “”\"\n102     Connect to a Weaviate Cloud (WCD) instance. This method is deprecated and will be removed in a future release. Use connect_to_weaviate_cloud instead.\n103\n(…)\n143         >>> # The connection is automatically closed when the context is exited.\n144     “”\"\n → 145     return connect_to_weaviate_cloud(\n146         cluster_url, auth_credentials, headers, additional_config, skip_init_checks\n147     )\nFile c:\\Users\\anaconda3\\Lib\\site-packages\\weaviate\\connect\\helpers.py:80, in connect_to_weaviate_cloud(cluster_url, auth_credentials, headers, additional_config, skip_init_checks)\n34 “”\"\n35 Connect to a Weaviate Cloud (WCD) instance.\n36\n(…)\n77     >>> # The connection is automatically closed when the context is exited.\n78 “”\"\n79 cluster_url, grpc_host = __parse_weaviate_cloud_cluster_url(cluster_url)\n—> 80 return __connect(\n81     WeaviateClient(\n82         connection_params=ConnectionParams(\n83             http=ProtocolParams(host=cluster_url, port=443, secure=True),\n84             grpc=ProtocolParams(host=grpc_host, port=443, secure=True),\n85         ),\n86         auth_client_secret=auth_credentials,\n87         additional_headers=headers,\n88         additional_config=additional_config,\n89         skip_init_checks=skip_init_checks,\n90     )\n91 )\nFile c:\\Users\\anaconda3\\Lib\\site-packages\\weaviate\\connect\\helpers.py:411, in __connect(client)\n409 except Exception as e:\n410     client.close()\n → 411     raise e\nFile c:\\Users\\anaconda3\\Lib\\site-packages\\weaviate\\connect\\helpers.py:407, in __connect(client)\n405 def __connect(client: WeaviateClient) → WeaviateClient:\n406     try:\n → 407         client.connect()\n408         return client\n409     except Exception as e:\nFile c:\\Users\\anaconda3\\Lib\\site-packages\\weaviate\\syncify.py:23, in convert..sync_method(self, __new_name, *args, **kwargs)\n20 @wraps(method)  # type: ignore\n21 def sync_method(self, *args, __new_name=new_name, **kwargs):\n22     async_func = getattr(cls, __new_name)\n—> 23     return _EventLoopSingleton.get_instance().run_until_complete(\n24         async_func, self, *args, **kwargs\n25     )\nFile c:\\Users\\anaconda3\\Lib\\site-packages\\weaviate\\event_loop.py:40, in _EventLoop.run_until_complete(self, f, *args, **kwargs)\n38     raise WeaviateClosedClientError()\n39 fut = asyncio.run_coroutine_threadsafe(f(*args, **kwargs), self.loop)\n—> 40 return fut.result()\nFile c:\\Users\\anaconda3\\Lib\\concurrent\\futures_base.py:456, in Future.result(self, timeout)\n454     raise CancelledError()\n455 elif self._state == FINISHED:\n → 456     return self.__get_result()\n457 else:\n458     raise TimeoutError()\nFile c:\\Users\\anaconda3\\Lib\\concurrent\\futures_base.py:401, in Future.__get_result(self)\n399 if self._exception:\n400     try:\n → 401         raise self._exception\n402     finally:\n403         # Break a reference cycle with the exception in self._exception\n404         self = None\nFile c:\\Users\\anaconda3\\Lib\\site-packages\\weaviate\\client_base.py:153, in _WeaviateClientBase.connect(self)\n151 if self._connection.is_connected():\n152     return\n → 153 await self._connection.connect(self._skip_init_checks)\nFile c:\\Users\\anaconda3\\Lib\\site-packages\\weaviate\\connect\\v4.py:158, in ConnectionV4.connect(self, skip_init_checks)\n156 # need this to get the version of weaviate for version checks\n157 try:\n → 158     meta = await self.get_meta()\n159     self._weaviate_version = _ServerVersion.from_string(meta[“version”])\n160 except (\n161     WeaviateConnectionError,\n162     ReadError,\n163     RemoteProtocolError,\n164     SSLZeroReturnError,  # required for async 3.8,3.9 due to ssl.SSLZeroReturnError: TLS/SSL connection has been closed (EOF) (_ssl.c:1131)\n165 ) as e:\nFile c:\\Users\\anaconda3\\Lib\\site-packages\\weaviate\\connect\\v4.py:587, in ConnectionV4.get_meta(self)\n583 “”\"\n584 Returns the meta endpoint.\n585 “”\"\n586 response = await self.get(path=“/meta”)\n → 587 res = _decode_json_response_dict(response, “Meta endpoint”)\n588 assert res is not None\n589 return res\nFile c:\\Users\\anaconda3\\Lib\\site-packages\\weaviate\\util.py:930, in _decode_json_response_dict(response, location)\n927     except JSONDecodeError:\n928         raise ResponseCannotBeDecodedError(location, response)\n → 930 raise UnexpectedStatusCodeError(location, response)\nUnexpectedStatusCodeError: Meta endpoint! Unexpected status code: 503, with response body: None.\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: Weaviate Serverless Cloud\nMulti Node? Number of Running Nodes:\nClient Language and Version: Python v4 Client\nMultitenancy?:\n\nAny additional Information\n\nThe upload broke in the middle, and after that the server was not accessible. Async was not used.\n\n----------\n\n[Mohamed_Shahin (2024-10-15T14:57:37.297Z)]: Hello @teapotboy,\nWelcome to our community! It’s great to have you here.\nI see that you have a cloud cluster with us. Please feel free to log a support ticket by emailing us at support@weaviate.io, and we’ll be happy to look into the details of your cluster and assist you further.\nLooking forward to helping you!",
    "date_created": "2024-10-14T10:44:16.485Z",
    "has_accepted_answer": false,
    "title": "Cannot connect to the serverless",
    "topic_id": 5243
  },
  {
    "user_id": 1055,
    "conversation": "[Hamza_Rezgui (2024-08-31T09:45:32.514Z)]: Description\nso i deployed my app which works fine on my local computer but when i deployed it on an aws instance  using docker compose , some services aren’t really that linked to each other. I would like to know what should i change in my compose file and my code to make it work.\nServer Setup Information\n  flask-app:\n    image: #private docker registry here\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - \"volume-flaskapi:/usr/src/app\"\n    environment:\n      FLASK_APP: app.py\n      FLASK_ENV: development\n    command: bash -c \"python -m venv venv && source venv/bin/activate && pip install --no-cache-dir -r requirements.txt && flask run --host=0.0.0.0 --reload\"\n    depends_on:\n      weaviate:\n        condition: service_healthy\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.18\n    ports:\n      - 8080:8080\n      - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    environment:\n      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'\n      ENABLE_MODULES: 'text2vec-transformers'\n      CLUSTER_HOSTNAME: 'node1'\n    healthcheck:\n      test: [\"CMD\", \"nc\", \"-z\", \"localhost\", \"8080\"]\n      interval: 20s\n      timeout: 5s\n      retries: 5\n      start_period: 30s\n\n  t2v-transformers:\n    image: cr.weaviate.io/semitechnologies/transformers-inference:sentence-transformers-paraphrase-multilingual-MiniLM-L12-v2\n    environment:\n      ENABLE_CUDA: '0'\n\nconnection to weaviate in flask app\nclient = weaviate.connect_to_local(host=\"weaviate\")\n\n----------\n\n[DudaNogueira (2024-09-02T12:24:01.099Z)]: hi @Hamza_Rezgui !!\nin your scenario, you should avoid using connect_to_local, and use connect_to_custom instead.\nor if using connect_to_local, also provide grpc_host  as “weaviate”\nI believe this will work for you:\nclient = weaviate.connect_to_custom(\n    http_host=\"weaviate\",\n    http_port=8080,\n    http_secure=False,\n    grpc_host=\"weaviate\",\n    grpc_port= 50051,\n    grpc_secure=False,\n)\n\nprint(client.is_ready())\n\nLet me know if this helps!\nTHanks!",
    "date_created": "2024-08-31T09:45:32.451Z",
    "has_accepted_answer": false,
    "title": "Weaviate and t2v on an aws instance",
    "topic_id": 3938
  },
  {
    "user_id": 8490,
    "conversation": "[Lynn_Mikami (2025-03-09T02:31:59.799Z)]: I’m looking for recommendations for alternative tools to Postman for testing APIs. What do you use when working with Weaviate’s API endpoints?\n\n----------\n\n[Naomi_Clarkson (2025-03-09T02:36:10.812Z)]: There are several good alternatives to Postman out there - I’ve been exploring quite a few of them lately!  Let me share the ones I’ve found particularly useful, If anyone else has been thinking about making a switch, here are some solid options I can recommend:\n\nApiDog: A comprehensive API platform with a modern interface, supporting multiple protocols and offering a smoother team collaboration experience.\nBruno: Simple but powerful, available as both CLI and desktop app.\nInsomnia: Clean, open-source REST client with excellent GraphQL support.\nThunder Client: A lightweight VS Code extension that lets you test APIs directly in your IDE.\n\nAll of these work well with testing API endpoints.",
    "date_created": "2025-03-09T02:31:59.756Z",
    "has_accepted_answer": false,
    "title": "Is there a good postman alternative for testing APIs?",
    "topic_id": 16698
  },
  {
    "user_id": 2045,
    "conversation": "[Muhammad_Ashir (2025-01-23T16:41:12.457Z)]: Here is my code\nclient = weaviate.connect_to_local(\n    host=\"localhost\",  # Use a string to specify the host\n    port=8080,\n    grpc_port=50051,\n    additional_config=AdditionalConfig(\n        timeout=Timeout(init=600, query=500, insert=1000)  # Values in seconds\n    )\n)\n\n        with collection.batch.rate_limit(requests_per_minute=10) as batch:\n            batch.add_object(properties=data_row)\n\n        if len(collection.batch.failed_objects) > 0:\n            print(collection.batch.failed_objects)\n           \n\n\nits giving me error related to timeout even though I have increased the timeout as well in above connection thing here is the error I am facing I have content of almost 10K words.\n[ErrorObject(message=‘WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: send POST request: Post “http://t2v-transformers:8080/vectors”: context deadline exceeded (Client.Timeout exceeded while awaiting headers)')’, object_=_BatchObject(collection=‘Collection_83cdb7b2569a428095e38b73e8348168’, vector=None, uuid=‘f42b6ee8-f256-4bd3-9f6a-c53ec77fe27d’,\nI have tired dynamic import as well.\n\n----------\n\n[DudaNogueira (2025-01-23T19:55:18.328Z)]: hi @Muhammad_Ashir !!\nThe issue here seems to be the time out from Weaviate server to your embedding service at http://t2v-transformers:8080/vectors.\nSo changing the timeout on client will take no effect and the fact that it is timeouting is because you are away from an acceptable threshold \nWe have two options from here:\n\n\nIncrease the resource of your embedding service, making sure you get it is below to what Weaviate understands as acceptable.\n\n\nIncrease the module client timeout (default as I write 50s), allowing Weaviate to wait for this vectorization for more time by setting a different MODULES_CLIENT_TIMEOUT as documented here.\n\n\nLet me know if that helps!\nThanks!",
    "date_created": "2025-01-23T16:41:12.388Z",
    "has_accepted_answer": false,
    "title": "Client.Timeout exceeded while awaiting headers - During insertion data in weaviate",
    "topic_id": 9871
  },
  {
    "user_id": 2486,
    "conversation": "[taigofranca (2025-01-17T19:57:20.739Z)]: Description\nI created a collection with the following parameters:\n...\nself.__client.collections.create(\n        self.__collection_name,\n        vectorizer_config=[Configure.NamedVectors.text2vec_aws(\n             name=self.__collection_name,\n             region='us-east-1',\n             service='bedrock',\n             model='cohere.embed-multilingual-v3'\n        )],\n        generative_config=Configure.Generative.aws(\n             region='us-east-1',\n             service='bedrock',\n             model='anthropic.claude-3-5-sonnet-20240620-v1:0'\n        )\n)\n...\n\nAnd the RAG is like this:\nresponse = collection.generate.near_text(\n              query=prompt,\n              limit=3,\n              grouped_properties=['description'],\n              grouped_task=f'Gere uma descrição longa para um produto na forma de um texto comercial que reforçe suas características e usando o contexto fornecido.\\n\\n{prompt}'\n          )\n\ngenerated = response.generated\nprint(generated)\n\nThe generated string, which is stored in the generated variable, is incomplete. More words were generated, but they were not returned, leaving the generated description meaningless.\nI saw that Claude Sonnet 3.5 on Amazon Bedrock has a length parameter, which limits the size of the response.\nHow can I inform this parameter through Weaviate?\nBig hug, everyone.\nServer Setup Information\n\nWeaviate Server Version: 1.27.0\nDeployment Method: Local\nMulti Node?  No\nClient Language and Version: Python v4\nMultitenancy? No\n\n----------\n\n[DudaNogueira (2025-01-22T14:03:20.512Z)]: Hi!! @taigofranca !!\nAwesome question!\nI see that the generative for anthropic has this parameter exposed on client, but not for the generate.aws.\nI have checked with our team, and indeed it is missing.\nSo we could either add it to generative.bedrock or create a new generative.bedrock_anthropic\nIssue created: Missing parameters when using anthropic on amazon bedrock · Issue #1520 · weaviate/weaviate-python-client · GitHub\nThanks for pointing it out!",
    "date_created": "2025-01-17T19:57:20.680Z",
    "has_accepted_answer": false,
    "title": "Size of the generated response",
    "topic_id": 9805
  },
  {
    "user_id": 3095,
    "conversation": "[DevelMyCry (2025-01-06T09:53:42.468Z)]: Due to the decrease in performance of Weaviate with the use of product quantization, it is necessary to select the optimal parameters of the HNSW index for minimal loss of accuracy with higher performance compared to HNSW without compression with current (not modified parameters).\n\nWeaviate Server Version: 1.26.0\nDeployment Method: Docker-compose\nStandalone\n\nCurrent HNSW parameters for two named vectors:\nVector A:\nef = 320, efConstruction = 320, maxConnections = 100.\nVector Length = 768.\nVector B:\nef = 480, efConstruction = 480, maxConnections = 120\nWithout PQ search average QPS: 145 obj/s\nWith PQ (segments=6) search average QPS: 75 obj/s. With other segments values QPS is not higher, and often lower. Dataset size was 5 million and training size = 100 000 - 150 000. It is expected to store 20+ million vectors.\nWhy does vector compression degrade performance so much? I suspect that the parameters of the HNSW need to be adjusted, but it is not yet clear how to maintain balance and how much they should change for PQ…\n\n----------\n\n[DudaNogueira (2025-01-06T18:54:58.060Z)]: Hi @DevelMyCry !!\nFirst, any specific reason to use 1.26.0?\nThe latest one from this branch is 1.26.13, and those 13 releases are the ones that bring all patches we backported from 1.28\nOf course, 1.28 will probably get you even better results. For example, you may try using ACORN, that can help on specific queries.\nBy the way, not sure if you saw this article in our academy:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nChunking long texts | Weaviate\n\n  Explore data chunking in Weaviate standalone for optimized storage and performance in Python.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nthere is some interesting information there.\nThanks!",
    "date_created": "2025-01-06T09:53:42.416Z",
    "has_accepted_answer": false,
    "title": "How to planning HNSW index ef, efConstruction and maxConnections parameters with PQ?",
    "topic_id": 9579
  },
  {
    "user_id": 2528,
    "conversation": "[lei_shi (2024-11-18T13:28:59.013Z)]: How to support keyword search in Chinese\n\n----------\n\n[DudaNogueira (2024-11-18T13:30:21.582Z)]: hi @lei_shi !!\nWelcome to our community \nYou need to enable the GSE tokenization by setting an environment variable:\nCheck here in our doc: Collection definition | Weaviate",
    "date_created": "2024-11-18T13:28:58.971Z",
    "has_accepted_answer": false,
    "title": "[Question] How to support keyword search in Chinese",
    "topic_id": 7649
  },
  {
    "user_id": 1278,
    "conversation": "[vk_Cheung (2024-08-05T04:51:53.605Z)]: Hi,\nI setup weaviate with follow docker compose:\nversion: \"3.4\"\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:1.25.10\n    ports:\n      - \"8088:8080\"\n      - \"50051:50051\"\n    volumes:\n      - ./data:/var/lib/weaviate\n    restart: on-failure:0\n    networks:\n      - weaviate_default\n    environment:\n      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'\n      RERANKER_INFERENCE_API: 'http://reranker-transformers:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'\n      ENABLE_MODULES: 'text2vec-transformers,reranker-transformers'\n      CLUSTER_HOSTNAME: 'node1'\n  t2v-transformers: \n    image: semitechnologies/transformers-inference:baai-bge-m3-onnx\n    networks:\n      - weaviate_default\n    environment:\n      ENABLE_CUDA: 0 # set to 1 to enable\n  reranker-transformers:\n    build:\n      context: reranker-transformers-1.1.1\n      dockerfile: Dockerfile\n      args:\n        HF_ENDPOINT: \"https://hf-mirror.com\"\n        MODEL_NAME: \"BAAI/bge-reranker-large\"\n    image: weaviate-reranker-transformers:latest\n    networks:\n      - weaviate_default\n    environment:\n      ENABLE_CUDA: '0'\nnetworks:\n  weaviate_default:\n    driver: bridge\n\nAnd I connet it via weaviate client, which version is 4.7.1, with following code\nclient = weaviate.connect_to_custom(\n        http_host=os.getenv('WEAVIATE_HOST'),\n        http_port=int(os.getenv('WEAVIATE_HTTP_PORT').strip()),\n        http_secure=False,\n        grpc_host=os.getenv('WEAVIATE_HOST'),\n        grpc_port=int(os.getenv('WEAVIATE_GRPC_PORT').strip()),\n        grpc_secure=False,\n        additional_config=AdditionalConfig(\n            timeout=Timeout(init=30, query=60, insert=120)  # Values in seconds\n        ),\n    )\n\nWhen I use following code to create a collection, got a Error with status code 422, and response body {‘error’: [{‘message’: “module ‘text2vec-transformers’: invalid combination of properties”}]}.\nclient.collections.create(\n                name=index_name,\n                properties=[\n                    wvc.config.Property(name='j_key', data_type=wvc.config.DataType.INT,\n                                        index_filterable=True,\n                                        index_searchable=False,\n                                        skip_vectorization=True,\n                                        vectorize_property_name=False,\n                                        ),\n                ],\n                vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_transformers(\n                    vectorize_collection_name=False,\n                    inference_url='http://t2v-transformers:8080',\n\n                ),\n\n            )\n\nAnd the client.get_meta() ,return\n{\n    \"hostname\": \"http://[::]:8080\",\n    \"modules\": {\n        \"reranker-transformers\": {\n            \"model\": {\n                \"_name_or_path\": \"./models/model\",\n                \"add_cross_attention\": false,\n                \"architectures\": [\n                    \"XLMRobertaForSequenceClassification\"\n                ],\n                \"attention_probs_dropout_prob\": 0.1,\n                \"bad_words_ids\": null,\n                \"begin_suppress_tokens\": null,\n                \"bos_token_id\": 0,\n                \"chunk_size_feed_forward\": 0,\n                \"classifier_dropout\": null,\n                \"cross_attention_hidden_size\": null,\n                \"decoder_start_token_id\": null,\n                \"diversity_penalty\": 0,\n                \"do_sample\": false,\n                \"early_stopping\": false,\n                \"encoder_no_repeat_ngram_size\": 0,\n                \"eos_token_id\": 2,\n                \"exponential_decay_length_penalty\": null,\n                \"finetuning_task\": null,\n                \"forced_bos_token_id\": null,\n                \"forced_eos_token_id\": null,\n                \"hidden_act\": \"gelu\",\n                \"hidden_dropout_prob\": 0.1,\n                \"hidden_size\": 1024,\n                \"id2label\": {\n                    \"0\": \"LABEL_0\"\n                },\n                \"initializer_range\": 0.02,\n                \"intermediate_size\": 4096,\n                \"is_decoder\": false,\n                \"is_encoder_decoder\": false,\n                \"label2id\": {\n                    \"LABEL_0\": 0\n                },\n                \"layer_norm_eps\": 1e-05,\n                \"length_penalty\": 1,\n                \"max_length\": 20,\n                \"max_position_embeddings\": 514,\n                \"min_length\": 0,\n                \"model_type\": \"xlm-roberta\",\n                \"no_repeat_ngram_size\": 0,\n                \"num_attention_heads\": 16,\n                \"num_beam_groups\": 1,\n                \"num_beams\": 1,\n                \"num_hidden_layers\": 24,\n                \"num_return_sequences\": 1,\n                \"output_attentions\": false,\n                \"output_hidden_states\": false,\n                \"output_past\": true,\n                \"output_scores\": false,\n                \"pad_token_id\": 1,\n                \"position_embedding_type\": \"absolute\",\n                \"prefix\": null,\n                \"problem_type\": null,\n                \"pruned_heads\": {},\n                \"remove_invalid_values\": false,\n                \"repetition_penalty\": 1,\n                \"return_dict\": true,\n                \"return_dict_in_generate\": false,\n                \"sep_token_id\": null,\n                \"suppress_tokens\": null,\n                \"task_specific_params\": null,\n                \"temperature\": 1,\n                \"tf_legacy_loss\": false,\n                \"tie_encoder_decoder\": false,\n                \"tie_word_embeddings\": true,\n                \"tokenizer_class\": null,\n                \"top_k\": 50,\n                \"top_p\": 1,\n                \"torch_dtype\": \"float32\",\n                \"torchscript\": false,\n                \"transformers_version\": \"4.41.2\",\n                \"type_vocab_size\": 1,\n                \"typical_p\": 1,\n                \"use_bfloat16\": false,\n                \"use_cache\": true,\n                \"vocab_size\": 250002\n            }\n        },\n        \"text2vec-transformers\": {\n            \"model\": {\n                \"_name_or_path\": \"./models/model\",\n                \"add_cross_attention\": false,\n                \"architectures\": [\n                    \"XLMRobertaModel\"\n                ],\n                \"attention_probs_dropout_prob\": 0.1,\n                \"bad_words_ids\": null,\n                \"begin_suppress_tokens\": null,\n                \"bos_token_id\": 0,\n                \"chunk_size_feed_forward\": 0,\n                \"classifier_dropout\": null,\n                \"cross_attention_hidden_size\": null,\n                \"decoder_start_token_id\": null,\n                \"diversity_penalty\": 0,\n                \"do_sample\": false,\n                \"early_stopping\": false,\n                \"encoder_no_repeat_ngram_size\": 0,\n                \"eos_token_id\": 2,\n                \"exponential_decay_length_penalty\": null,\n                \"finetuning_task\": null,\n                \"forced_bos_token_id\": null,\n                \"forced_eos_token_id\": null,\n                \"hidden_act\": \"gelu\",\n                \"hidden_dropout_prob\": 0.1,\n                \"hidden_size\": 1024,\n                \"id2label\": {\n                    \"0\": \"LABEL_0\",\n                    \"1\": \"LABEL_1\"\n                },\n                \"initializer_range\": 0.02,\n                \"intermediate_size\": 4096,\n                \"is_decoder\": false,\n                \"is_encoder_decoder\": false,\n                \"label2id\": {\n                    \"LABEL_0\": 0,\n                    \"LABEL_1\": 1\n                },\n                \"layer_norm_eps\": 1e-05,\n                \"length_penalty\": 1,\n                \"max_length\": 20,\n                \"max_position_embeddings\": 8194,\n                \"min_length\": 0,\n                \"model_type\": \"xlm-roberta\",\n                \"no_repeat_ngram_size\": 0,\n                \"num_attention_heads\": 16,\n                \"num_beam_groups\": 1,\n                \"num_beams\": 1,\n                \"num_hidden_layers\": 24,\n                \"num_return_sequences\": 1,\n                \"output_attentions\": false,\n                \"output_hidden_states\": false,\n                \"output_past\": true,\n                \"output_scores\": false,\n                \"pad_token_id\": 1,\n                \"position_embedding_type\": \"absolute\",\n                \"prefix\": null,\n                \"problem_type\": null,\n                \"pruned_heads\": {},\n                \"remove_invalid_values\": false,\n                \"repetition_penalty\": 1,\n                \"return_dict\": true,\n                \"return_dict_in_generate\": false,\n                \"sep_token_id\": null,\n                \"suppress_tokens\": null,\n                \"task_specific_params\": null,\n                \"temperature\": 1,\n                \"tf_legacy_loss\": false,\n                \"tie_encoder_decoder\": false,\n                \"tie_word_embeddings\": true,\n                \"tokenizer_class\": null,\n                \"top_k\": 50,\n                \"top_p\": 1,\n                \"torch_dtype\": \"float32\",\n                \"torchscript\": false,\n                \"transformers_version\": \"4.39.3\",\n                \"type_vocab_size\": 1,\n                \"typical_p\": 1,\n                \"use_bfloat16\": false,\n                \"use_cache\": true,\n                \"vocab_size\": 250002\n            }\n        }\n    },\n    \"version\": \"1.25.10\"\n}\n\nPlease help.\nThanks.\n\n----------\n\n[DudaNogueira (2024-08-05T19:03:35.725Z)]: hi @vk_Cheung !!\nWelcome to our community \nThe problem here is that you have nothing to vectorize.\nYou don’t vectorize the collection name nor the property name. and the only property you have is an integer and is also marked to skip.\nHowever, this seems to be a bug in the text2vec_transformers integration, as the very same collection, if setting the text2vec-openai will work without any problem.\nAs a workaround, for now, try adding a second collection that will be vectorized, or setting  vectorize_collection_name=True.\nI will escalate this to check if this is indeed a bug.\nThanks!\n\n----------\n\n[vk_Cheung (2024-08-06T01:19:12.257Z)]: Thanks @DudaNogueira.\nI change the value of vectorizer_config, and it work for me.\nweaviate_client.collections.create(\n        name=index_name,\n        properties=[\n            wvc.config.Property(name='j_key', data_type=wvc.config.DataType.INT,\n                                index_filterable=True,\n                                index_searchable=False,\n                                skip_vectorization=True,\n                                vectorize_property_name=False,\n                                ),\n        ],\n        vectorizer_config=[\n            wvc.config.Configure.NamedVectors.text2vec_transformers(\n                name=field_name,\n                source_properties=[\"text\"]\n            )],\n\n    )",
    "date_created": "2024-08-05T04:51:53.546Z",
    "has_accepted_answer": true,
    "title": "'text2vec-transformers': invalid combination of properties\"",
    "topic_id": 3260
  },
  {
    "user_id": 2495,
    "conversation": "[Oleksandr_Yakovliev (2024-11-12T09:03:29.601Z)]: Description\nI’m trying to insert documents with inverted indexes into weaviate (local instance) but embeddings aren’t being created. As embedding model I’m using Azure OpenAI model “text-embedding-3-small”. When collection is being inserted I’m getting the next error for each document:\n{\n      message: 'API Key: no api key found neither in request header: X-Openai-Api-Key nor in environment variable under OPENAI_APIKEY',\n      object: [Object],\n      originalUuid: undefined\n    }\n\nQuestion: why the client is trying to use X-Openai-Api-Key key instead of X-Azure-Api-Key for text2VecAzureOpenAI vectorizer? I also tried to replace text2vec-openai module in docker with text2vec-azure-openai one but got the error that such module doesn’t exists. When I replaced X-Azure-Api-Key with X-Openai-Api-Key the client tried to connect to OpenAI API and not Azure.\nIs it possible to use remote (azure) embedding model for local weaviate instance running in docker?\nHere is my config:\nConnection to local instance (working):\nconst client = await weaviate.connectToLocal({\n      host: \"172.16.41.55\",\n      port: 8080,\n      grpcPort: 50051, \n      headers: {\n        'X-Azure-Api-Key': this.embeddings.azureOpenAIApiKey || '',\n      }\n    });\nawait client.isReady()\n\nCreate collection function call:\nclient.collections.create({\n      name: `${collection}_${this.context.id}`,\n      properties: [\n        {\n          name: 'document',\n          dataType: dataType.TEXT,\n          description: 'Splitted document' as const,\n          vectorizePropertyName: true,\n        },\n      ],\n      invertedIndex: configure.invertedIndex({\n        indexNullState: true,\n        indexPropertyLength: true,\n        indexTimestamps: true,\n      }),\n      vectorizers: [\n        weaviate.configure.vectorizer.text2VecAzureOpenAI(\n          {\n            name: 'title_vector',\n            sourceProperties: ['title'],\n            resourceName: this.embeddings.azureOpenAIApiInstanceName || '',\n            deploymentId: this.embeddings.azureOpenAIApiDeploymentName || '',\n          },\n        ),\n      ],\n});\n\nServer Setup Information\n\nWeaviate Server Version: 1.27.1\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: TS (3.2.2)\nMultitenancy?:\n\nAny additional Information\nWeaviate service in docker-compose file:\nweaviate:\n    command: --host 0.0.0.0 --port '8080' --scheme http\n    container_name: dowow-weaviate\n    image: cr.weaviate.io/semitechnologies/weaviate:1.27.1\n    restart: always\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    networks:\n      dowow:\n        ipv4_address: 172.16.41.55\n    ports:\n    - 8086:8080\n    - 50051:50051\n    - 2112:2112\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'\n      ENABLE_MODULES: 'text2vec-openai'\n      CLUSTER_HOSTNAME: 'node1'\n\nvolumes:\n  weaviate_data:\n    driver: local\n\nResponse from /v1/meta endpoint:\n{\n    \"grpcMaxMessageSize\": 10485760,\n    \"hostname\": \"http://[::]:8080\",\n    \"modules\": {\n        \"text2vec-openai\": {\n            \"documentationHref\": \"https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\",\n            \"name\": \"OpenAI Module\"\n        }\n    },\n    \"version\": \"1.27.1\"\n}\n\n----------\n\n[DudaNogueira (2024-11-20T18:54:02.451Z)]: Hi!\nSorry for the delay here \nI was not able to reproduce this.\nHere is the code I used:\nimport weaviate, { Collection, WeaviateClient } from 'weaviate-client';\n\nasync function runFullExample() {\n    const client = await weaviate.connectToLocal({\n        host: process.env.WEAVIATE_HOST || 'localhost',\n        port: parseInt(process.env.WEAVIATE_PORT || '8080'),\n        grpcPort: parseInt(process.env.WEAVIATE_GRPC_PORT || '50051'),\n        headers: {\n            'X-Azure-Api-Key': \"my api key here\",\n        }\n    });\n    console.log(`Server Version: ${(await client.getMeta()).version}`)\n    // delete test collection\n    await client.collections.delete(\"JeopardyQuestions\");\n    // create test collection\n    const collection = await client.collections.create({\n        name: 'JeopardyQuestions',\n        properties: [\n            {\n                name: 'category',\n                dataType: 'text',\n            },\n            {\n                name: 'question',\n                dataType: 'text',\n            },\n            {\n                name: 'answer',\n                dataType: 'text',\n            },\n        ],\n\n        vectorizers: [\n            weaviate.configure.vectorizer.text2VecAzureOpenAI({\n                name: 'my_vector',\n                sourceProperties: ['category', 'answer', 'question'],\n                resourceName: 'duda-instance',\n                deploymentId: 'duda-deployment-id'\n              },\n            ),\n        ],\n    });\n    // add some data\n    await collection.data.insert({\n        \"category\": \"example\",\n        \"question\": \"is this an example?\",\n        \"answer\": \"yes! this is an example.\"\n    })\n    // show data\n    const query =  await collection.query.fetchObjects({\n        includeVector: true\n    })\n    await query.objects.map(object=>{\n        console.log(object.vectors)\n    })\n}\nrunFullExample();\n\nLet me know if this helps!",
    "date_created": "2024-11-12T09:03:29.525Z",
    "has_accepted_answer": false,
    "title": "Why weaviate client (typescript) is not using configured text2VecAzureOpenAI vectorizer?",
    "topic_id": 7549
  },
  {
    "user_id": 164,
    "conversation": "[alt-glitch (2023-09-06T08:24:46.397Z)]: Hi there!\nOn importing data to weaviate, I check if the class exists.\nBut quite often it fails to check if a class exists.\nrequests.exceptions.ConnectionError: Checking class existence could not be done.\n\nI think it’s because the server closes the connection unexpectedly.\nThis is how I check for the class existence.\n# PYTHON CODE TO SAVE OBJECT \nsource_class = settings.KNOWLEDGE_SOURCE_CLASS.format(user_id)\ncontent_class = settings.CONTENT_CLASS.format(user_id)\n    try:\n        if not client.schema.exists(source_class):\n            print(\"[!] Schema doesn't exist. Initializing...\")\n            logger.debug(f\"Initializing {user_id} schema\")\n            knowledge_source = {...}\n            content = {...}\n            client.schema.create({\"classes\": [knowledge_source, content]})\n\nI end up getting the following error:\n  File \"/home/glitch/nous-backend/src/indexer.py\", line 34, in indexer\n    if not client.schema.exists(source_class):\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/glitch/nous-backend/.venv/lib/python3.11/site-packages/weaviate/schema/crud_schema.py\", line 318, in exists\n    raise RequestsConnectionError(\nrequests.exceptions.ConnectionError: Checking class existence could not be done.\n\nGoing through the stack trace i think these are the chunks:\n.....\n  File \"/usr/lib/python3.11/http/client.py\", line 287, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\n.....\n  File \"/usr/lib/python3.11/http/client.py\", line 287, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n\nDuring handling of the above exception, another exception occurred:\n.......\n  File \"/home/glitch/nous-backend/.venv/lib/python3.11/site-packages/requests/adapters.py\", line 501, in send\n    raise ConnectionError(err, request=request)\nrequests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n\nThe above exception was the direct cause of the following exception:\n.....\n\n  File \"/home/glitch/nous-backend/.venv/lib/python3.11/site-packages/weaviate/schema/crud_schema.py\", line 318, in exists\n    raise RequestsConnectionError(\nrequests.exceptions.ConnectionError: Checking class existence could not be done.\n\n----------\n\n[DudaNogueira (2023-09-06T08:58:43.866Z)]: Hi! Where is your weaviate? Locally or at our WCS?\n\n----------\n\n[alt-glitch (2023-09-06T09:45:01.451Z)]: Should have mentioned that!\nI’m using a trial cluster at WCS.\n\n----------\n\n[DudaNogueira (2023-09-06T15:08:54.665Z)]: This may be an unstable connection from the client to the server.\nCan you try the same code but with a local weaviate? So local client connecting to a local weaviate server?\n\n----------\n\n[alt-glitch (2023-09-06T15:40:13.000Z)]: This code is running on a Google Cloud instance deployed. I don’t think it would have internet connection issues?\nIt is deployed on an Asian region though. Could that be a reason?\n\n----------\n\n[DudaNogueira (2023-09-06T18:23:14.983Z)]: It can be a network/route issue, a WCS (Saas) issue itself, or a Weaviate (Product) issue.\nSo if we are able to remove the networking part of the equation, run it all local, and still be able to reproduce it, we can have a path to follow.\nAlso, running it locally, would allow you to have a look at logs, so we can check for any outstanding messages.\nThanks!\n\n----------\n\n[James_Tan (2024-09-03T04:24:50.571Z)]: i have this issue locally\nopening on browser works fine\nConnectionClosed: The socket connection was closed unexpectedly. For more information, pass verbose: true in the second argument to fetch()\npath: “http://localhost:8086/v1/objects”\n\n----------\n\n[James_Tan (2024-09-03T04:30:34.453Z)]: i think i might have found the issue, some kind of data corruption. making a new data store seems to work:\n    - ./data2:/var/lib/weaviate\n\nwas on ./data:/var/lib/weaviate\n\n----------\n\n[DudaNogueira (2024-09-03T12:12:01.872Z)]: hi @James_Tan !! Welcome to our community \nThanks for sharing.\nWere you able to get any error logs related to this from the server side?\nThanks!",
    "date_created": "2023-09-06T08:24:46.352Z",
    "has_accepted_answer": true,
    "title": "Weaviate server closes connection unexpectedly",
    "topic_id": 626
  },
  {
    "user_id": 1329,
    "conversation": "[Abg79 (2024-09-25T17:12:18.686Z)]: Hello Weaviate Community,\nI am currently working on setting up a Weaviate Vector DB in our development environment. As part of this setup, I need to configure login credentials to ensure secure access to the database. In our current setup, we use a username and password for logging into our Oracle database, and we store these credentials securely in AWS Secrets Manager.\nI am looking for guidance on how to implement a similar setup for Weaviate. Here are a few specific questions I have:\n\nConfiguration Files: Which configuration files need to be modified to set up login credentials for Weaviate? Are there any specific parameters that need to be added or updated?\nEnvironment Variables: Is it possible to use environment variables for storing login credentials? If so, what is the recommended way to configure these variables in Weaviate?\nAWS Secrets Manager Integration: Can Weaviate integrate with AWS Secrets Manager for storing and retrieving login credentials? If yes, what are the steps to configure this integration?\nAuthentication Methods: What authentication methods are supported by Weaviate for securing access to the vector database? Are there any preferred methods for a development environment?\nSecurity Best Practices: Are there any security best practices or recommendations for managing and securing login credentials in a development environment, especially when using cloud services like AWS?\nCommon Pitfalls: What are some common pitfalls or issues that developers might encounter when setting up login credentials for Weaviate, and how can they be avoided?\n\nAny detailed guidance, examples, or references to documentation would be greatly appreciated. Thank you in advance for your assistance!\nBest regards\n\n----------\n\n[Joe (2024-09-25T19:24:24.561Z)]: Hey!\nThere are 2 areas you are going to want to potentially explore depending on how you are installing your Weaviate Instance:\n\nIf you are using Docker, you will want to reference our documentation here:Authentication | Weaviate\nIf you are using Kubernetes you will want to reference our documentation here: Kubernetes | Weaviate\n\nThese both go over setting up the authentication which does utilizing env variable in either your docker compose or values.yaml file.\nYou can integrate with AWS Secretes manager by setting the env variables in your docker compose or your values file, then configure the module accordingly.   We do have that documented here: Text Embeddings | Weaviate\nThe methods we offer are API-key or OIDC authentication which is gone over in the above docs!\nAs far as best practices,  I would ensure you are utilizing your Read-only keys for any client that is only performing read operations on your objects and that you utilize ENV variables when possible.\nCommon pitfalls I’ve seen are users using an admin key for CRUD operations, and not Cycling the API keys when users should no longer have access to them.\nI hope this helps!\nJoe\nSupport Engineer\nWeaviate\n\n----------\n\n[Abg79 (2024-10-25T22:58:53.783Z)]: Thank you so much. We will be able to figure it out using your help.\n\n----------\n\n[Rohini_vaidya (2025-03-18T07:01:19.853Z)]: Hi @Joe,\nIf I want to use API key based authentication, can i use it if I am connecting to weaviate locally.\nclient = weaviate.connect_to_local()\nwhere i am not using any weaviate url, username or password.\nHow we can secure weaviate db when we are connecting using docker locally.\nthank you in advance.\n\n----------\n\n[DudaNogueira (2025-03-18T11:00:05.935Z)]: hi @Rohini_vaidya !!\nBoth connect_to_local and connect_to_weaviate_cloud will use, under the hood, the connect_to_custom.\nThis means that while using connect_to_local, you can overwrite some of it’s parameters.\nFor example, this is how you can connect to a custom Weaviate cluster:\nclient = weaviate.connect_to_custom(\n    http_host=http_host,        # Hostname for the HTTP API connection\n    http_port=443,              # Default is 80, WCD uses 443\n    http_secure=True,           # Whether to use https (secure) for the HTTP API connection\n    grpc_host=grpc_host,        # Hostname for the gRPC API connection\n    grpc_port=443,              # Default is 50051, WCD uses 443\n    grpc_secure=True,           # Whether to use a secure channel for the gRPC API connection\n    auth_credentials=Auth.api_key(weaviate_api_key),    # API key for authentication\n)\n\nSo in your case, you can just pass auth_credentials to your client instantiation:\nclient = weaviate.connect_to_local(\n    auth_credentials=Auth.api_key(weaviate_api_key)\n)\n\nLet me know if that helps!\nThanks!\n\n----------\n\n[Rohini_vaidya (2025-03-18T11:48:41.929Z)]: Thank you @DudaNogueira\nThis works for me.\nThank you quick response !\n\n----------\n\n[DudaNogueira (2025-03-18T12:16:25.465Z)]: Any time, my friend.\nWe are here to help \nHappy coding\n\n----------\n\n[Rohini_vaidya (2025-03-20T11:47:57.767Z)]: Hi @DudaNogueira,\nI am setting up authentication for Weaviate using API keys. Here’s what I have configured in my docker-compose\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'false'  \nAUTHENTICATION_APIKEY_ENABLED: 'true'  \nAUTHENTICATION_APIKEY_ALLOWED_KEYS: 'api_key1,api_key2'  \nAUTHENTICATION_APIKEY_USERS: 'user1,user2'  \n\nFor connecting to Weaviate, I am using the following approach\nclient = weaviate.connect_to_local(  \n    auth_credentials=Auth.api_key(weaviate_api_key)  \n)\n\nI have a few doubts regarding access control:\n\nIf I have multiple users (e.g., user1 and user2), each with a separate API key, does Weaviate ensure that user1 can access only their own data, or will they have access to data from user2 as well?\nIf this setup does not enforce access control at the data level, what would be the recommended approach to ensure that each user can only access and manage their own data in Weaviate?\n\nAny guidance on this would be greatly appreciated!\nThanks!\n\n----------\n\n[DudaNogueira (2025-03-20T12:48:44.042Z)]: Hi @Rohini_vaidya !\nRBAC, or Role Based Access Control was just implemented in our 1.29 version, the latest as I write.\nYou can find the documentation here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAuthorization | Weaviate\n\n  Authentication and authorization are closely related concepts, and sometimes abbreviated as AuthN and AuthZ. Authentication (AuthN) is the process of verifying the identity of a user, while authorization (AuthZ) is the process of determining what...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAnd yes, we are working on a “dynamic” RBAC that doesn’t require to restart the server to add/change/remove new users. \nLet me know if this help!\n\n----------\n\n[Rohini_vaidya (2025-03-20T18:12:22.169Z)]: Thank you @DudaNogueira  !!!",
    "date_created": "2024-09-25T17:12:18.644Z",
    "has_accepted_answer": true,
    "title": "How to Set Up Login Credentials for Weaviate Vector DB in Development Environment?",
    "topic_id": 4322
  },
  {
    "user_id": 1298,
    "conversation": "[Rahul_Subramani (2024-08-09T17:47:24.926Z)]: Error while connecting to Azure OpenAI:\nWeaviateInsertManyAllFailedError: Every object failed during insertion. Here is the set of all errors: connection to: Azure OpenAI API failed with status: 400 error: please send a valid json string with appkey as {“appkey” : “value”} in ‘user’ parameter in request, reach out if you need an appkey\nconnection to: Azure OpenAI API failed with status: 429\nWe procured weaviate instance for our organization. And also we have procured Azure OpenAI License. Azure OpenAI connection will reuqired client id, client secret and an appkey.\nFrom client id and client secret we can generate api key/ access token which i have configured in the additional headers\nHeaders:\n‘X-Azure-Api-Key’: azure_openai_key,\n‘X-Openai-Api-Key’ : azure_openai_key,\nVectors Config\nfrom weaviate import classes as wvc\nsamples = client.collections.create(\nname=“Samples”,\nvectorizer_config=wvc.config.Configure.Vectorizer.text2vec_azure_openai(\nresource_name=“XXX”,\ndeployment_id=“text-embedding-3-large”,\nbase_url=“https://chat-ai..com”\n)\n)\nI need to pass additional parameters called “appkey”. Not able to find it in any documentation. Can somebody please help\n\n----------\n\n[DudaNogueira (2024-08-12T21:20:46.842Z)]: hi @Rahul_Subramani !!\nWelcome to our community!\nPlease, what is the version of client and server you are running?\nDoes it happen also on latest?\nThis message is coming directly from Azure/OpenAI. Have you set those accordingly?\nCheck here for more information on tet2vec-openai with azure:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAzure OpenAI + Weaviate | Weaviate - Vector Database\n\n  Microsoft Azure offers a wide range of OpenAI models for natural language processing and generation. Weaviate seamlessly integrates with Microsoft Azure's APIs, allowing users to leverage OpenAI's models directly within the Weaviate database.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!\n\n----------\n\n[Rahul_Subramani (2024-08-13T15:46:53.788Z)]: Python Client V4\nVersion: 1.25.7\nWe can able to connect directly using the OpenAI module. Here’s the connection function. But inside weaviate we are not sure on the configuration\nimport os\nfrom openai import AzureOpenAI\nclient = AzureOpenAI(\nazure_endpoint = ‘https://..com’,\napi_key=token_response.json()[“access_token”],\napi_version=“2023-08-01-preview”\n)\nresponse = client.chat.completions.create(\nmodel=“gpt-35-turbo”,\nmessages=messages,\nuser=f’{{“appkey”: “{app_key}”}}',\nfunctions=functions,\nfunction_call=“auto”\n)\n\n----------\n\n[DudaNogueira (2024-08-13T19:56:02.712Z)]: Hi!\ncan you check you are using the latest python client?\nimport weaviate\nprint(weaviate.__version__)",
    "date_created": "2024-08-09T17:47:24.860Z",
    "has_accepted_answer": false,
    "title": "Appkey Configuration - Azure OpenAI",
    "topic_id": 3324
  },
  {
    "user_id": 1329,
    "conversation": "[Abg79 (2024-08-21T19:29:18.340Z)]: Description: I am seeking help to resolve the issue where the vector search in Weaviate returns no results. Any insights or suggestions on what might be going wrong or what additional configurations might be needed would be highly appreciated. Thank you!\nDescription: I have set up a Weaviate instance on an Amazon EC2 instance using Docker Compose. I followed the official Weaviate documentation for the installation process. My setup involves generating embeddings using Amazon Titan and performing vector searches within Weaviate. Despite following the instructions and modifying the docker-compose.yml file to include the necessary modules, I am encountering issues with the vector search functionality. Specifically, the search returns no results. Below is a detailed description of my setup and the issue I am facing. Any assistance to resolve this would be greatly appreciated.\nInstallation and Version: My V4 Weaviate instance with Docker Compose is hosted on an Amazon EC2 instance. I followed this instruction to set up my Weaviate instance in AWS EC2:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nDocker | Weaviate - Vector Database\n\n  Weaviate supports deployment with Docker.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nSteps Taken in Coding:\n\nConnecting to Weaviate Instance on AWS EC2:\n\nPython\nhost_dns = \"host_dns.amazonaws.com\"\nclient = weaviate.WeaviateClient(\n    connection_params=ConnectionParams.from_params(\n        http_host=host_dns,\n        http_port=\"8080\",\n        http_secure=False,\n        grpc_host=host_dns,\n        grpc_port=\"50051\",\n        grpc_secure=False,\n    ),\n    additional_config=AdditionalConfig(\n        timeout=Timeout(init=30, query=60, insert=120),\n    ),\n    skip_init_checks=True\n)\n\nclient.connect()  # Connect to Weaviate\n\n\nCreating Embeddings Using Amazon Titan:\n\nPython\nmodelId = \"amazon.titan-embed-text-v1\"\naccept = \"application/json\"\ncontentType = \"application/json\"\nclient_titan = boto3.client('bedrock-runtime', region_name='us-west-2')\n\ndef generate_embedding(value):\n    try:\n        body = json.dumps({\"inputText\": value})\n        response = client_titan.invoke_model(\n            body=body, modelId=modelId, accept=accept, contentType=contentType\n        )\n        response_body = json.loads(response.get(\"body\").read())\n        embeddings = response_body['embedding']\n        return embeddings\n    except botocore.exceptions.ClientError as error:\n        print(error)\n\nembeddings_updated = []\nfor index, row in df_new.iterrows():\n    embeddings_updated.append(generate_embedding(row['title_chunks']))\n\n\nDefining the Collection for the ‘Document’ Class:\n\nPython\ncollection_new = {\n    \"class\": \"Document_new\",\n    \"description\": \"A class to represent documents\",\n    \"vectorizer\": \"none\",  # Set to \"none\" because embeddings are provided\n    \"moduleConfig\": {\n        # \"text2vec-openai\": {},  # Configure if using OpenAI vectorization\n        # \"generative-openai\": {}  # Configure if using generative queries\n    },\n    \"properties\": [\n        {\"name\": \"url\", \"dataType\": [\"string\"]},\n        {\"name\": \"title\", \"dataType\": [\"string\"]},\n        {\"name\": \"chunks\", \"dataType\": [\"string\"]},\n        {\"name\": \"embeddings_updated\", \"dataType\": [\"blob\"]},  # Use \"blob\" or \"float[]\" depending on your Weaviate setup\n    ]\n}\n\n\nBatch Import Objects from the DataFrame into Weaviate:\n\nPython\nwith client.batch.dynamic() as batch:\n    for i, row in df_new.iterrows():\n        print(f\"Importing document: {i+1}\")\n        properties = {\n            \"url\": row[\"url\"],\n            \"title\": row[\"title\"],\n            \"chunks\": row[\"chunks\"],\n            \"embeddings_updated\": row[\"embeddings_updated\"]\n        }\n        batch.add_object(\n            collection=\"Document_new\",  # Specify the collection name here\n            properties=properties\n        )\n\nprint(\"Batch import completed successfully.\")\n\n\nPerforming the Vector Search in Weaviate:\n\nPython\nfrom weaviate.classes.query import MetadataQuery\n\ndocument_collection = client.collections.get(\"Document_new\")\n# Generate query embeddings\nquery_vector = generate_embedding(prompt)\nresponse = document_collection.query.near_vector(\n    near_vector=query_vector,  # your query vector goes here\n    limit=10,\n    return_metadata=MetadataQuery(distance=True)\n)\n\nfor o in response.objects:\n    print(o.properties)\n    print(o.metadata.distance)\n\nResult: No results are returned from the vector search.\nDocker-Compose Configuration: I modified the docker-compose.yml to add text2vec-aws as the default model following the suggested resolutions to the same issue reported by another user. However, the issue persists. Even though we added or enabled models, we get an error that the model is not present.\n\n  \n    \n    \n    UnexpectedStatusCodeError: Create class! Unexpected status code: 422, with response body: {'error': [{'message': 'vectorizer: no module with name \"text2vec-aws\" present'}]} Support\n  \n  \n    Description\nI use aws weaviate api to create class with vectorizer: text2vec-aws,but it said no module with name “text2vec-aws” present’. I mask my url and keys, the client is ready to connect. \nServer Setup Information\ni am using python 3.12 , have below code to setup weaviate client, and create class: \nimport weaviate \nclient = weaviate.Client( \nurl = “https:// *****”, \nauth_client_secret=weaviate.auth.AuthApiKey(api_key=\" ****“), \nadditional_headers= { \n“X-AWS-Access-Key”: \" ******”, \n“X-AWS-…\n  \n\n\nDocker-Compose.yml:\nYAML\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.1\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,generative-claude,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node1'\n      AWS_REGION: 'us-west-2'\n      BEDROCK_ENDPOINT: 'https://bedrock.us-west-2.amazonaws.com'\n      TITAN_ENDPOINT: 'https://titan.us-west-2.amazonaws.com'\n      CLAUDE_ENDPOINT: 'https://claude.us-west-2.amazonaws.com' # Add Claude endpoint if required\nvolumes:\n  weaviate_data:\n\n----------\n\n[DudaNogueira (2024-08-21T19:37:53.488Z)]: hi @Abg79 !!\nWelcome to our community \nFirst, it is always important to do proper error handling.\nYou can do that by inspecting client.batch.failed_objects as stated here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNow, assuming that row[\"embeddings_updated\"] is your generated vector for that object, and that you want to generate them yourself (instead of allowing Weaviate to do it for you while ingesting, using the appropriate model), you should pass your vectors while ingesting using the vector parameter.\nthis is how:\nwith client.batch.dynamic() as batch:\n    for i, row in df_new.iterrows():\n        print(f\"Importing document: {i+1}\")\n        properties = {\n            \"url\": row[\"url\"],\n            \"title\": row[\"title\"],\n            \"chunks\": row[\"chunks\"],\n        }\n        batch.add_object(\n            collection=\"Document_new\",  # Specify the collection name here\n            vector=row[\"embeddings_updated\"],\n            properties=properties\n        )\n\nYou are passing row[\"embeddings_updated\"] as an object property. This will very quickly lead to a huge memory consumption, as you are indexing each dimension of your vector so you can perform bm25 searches on it \nLet me know if this helps.\nThanks!\n\n----------\n\n[Abg79 (2024-08-21T20:59:58.372Z)]: Hey DudaNogueira,\nThank you for the warm welcome to the forum and for your prompt guidance regarding the issue I was experiencing with weaviate.\nYour suggested solution worked perfectly, and my issue has been resolved. I greatly appreciate your assistance.",
    "date_created": "2024-08-21T19:29:18.285Z",
    "has_accepted_answer": true,
    "title": "Issue with Vector Query in Weaviate V4 on AWS EC2",
    "topic_id": 3421
  },
  {
    "user_id": 1329,
    "conversation": "[Abg79 (2024-09-04T19:23:56.723Z)]: Hi everyone,\nI’m currently working with Weaviate and I have a question regarding querying multiple indexes in one go.\nRight now, I am using the following code to query a single index:\ndocument_collection = client.collections.get(\"Document_snap_updated\")\nresponse = document_collection.query.near_vector(\n    near_vector=query_vector, \n    limit=2,\n    return_metadata=MetadataQuery(distance=True)\n)\n\nfor o in response.objects:\n    print(o.properties)\n    print(o.metadata.distance)\n\nThis works perfectly for querying a single index. However, I would like to know if there is a way to query multiple indexes simultaneously. Ideally, I would like to do something like this:\nPython\ndocument_collection = client.collections.get(\"Document_1\", \"Document_2\", \"Document_3\")\nresponse = document_collection.query.near_vector(\n    near_vector=query_vector, \n    limit=2,\n    return_metadata=MetadataQuery(distance=True)\n)\n\nfor o in response.objects:\n    print(o.properties)\n    print(o.metadata.distance)\n\nIs there a built-in way to achieve this in Weaviate, or would I need to query each index separately and then merge the results manually? Any guidance or examples would be greatly appreciated.\nThanks in advance for your help!\n\n----------\n\n[DudaNogueira (2024-09-04T20:42:14.849Z)]: hi @Abg79 !\nYou cannot perform one query on multiple indexes.\nWhat you can do is to use, that can be closer to what you want, depending on your use case, is ref2vec-centroid\nHere we have a blog post double clicking on that:\n  \n      \n\n      weaviate.io – 23 Nov 22\n  \n\n  \n    \n\nWhat is Ref2Vec and why you need it for your recommendation system | Weaviate\n\n  Weaviate introduces Ref2Vec, a new module that utilises Cross-References for Recommendation!\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAnother option would be having multiple vectors per one object (named vectors) and doing a multi target search:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMultiple target vectors | Weaviate\n\n  Multiple target vector search uses a single query to search multiple-target vectors. Weaviate searches the target vectors concurrently and automatically combines the results.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nOf course, this may or may not fit your usecase.\nLet me know if this helps.\nThanks!",
    "date_created": "2024-09-04T19:23:56.676Z",
    "has_accepted_answer": true,
    "title": "Querying Multiple Indexes in Weaviate v4",
    "topic_id": 3977
  },
  {
    "user_id": 3500,
    "conversation": "[Abel_McElroy (2025-02-20T04:57:38.321Z)]: Having a search bar on your site’s doc would be immensely helpful. I think a lot of developers, including myself, see having a docs-wide search as requisite to having good docs. please add one\n\n----------\n\n[maryannc (2025-02-20T05:17:56.619Z)]: Hi @Abel_McElroy !\nWelcome to Weaviate Community!\nWeaviate does have a search functionality on Weaviate documentation.\nAt the bottom of page, you can click on Ask AI, toogle on Search and see results across Weaviate documentation and sites. Weaviate Ask AI is now available and handy for your questions and searches.\nScreenshot 2025-02-20 at 1.14.31 PM2180×1362 181 KB\nHope this helps!",
    "date_created": "2025-02-20T04:57:38.269Z",
    "has_accepted_answer": true,
    "title": "[Docs] YOUR TOPIC",
    "topic_id": 10471
  },
  {
    "user_id": 3000,
    "conversation": "[arturs_sprogis (2024-12-10T20:29:17.982Z)]: This does not work:\ncollection.config.update(\n     multi_tenancy_config=Reconfigure.multi_tenancy(enabled=True)\n)\n\n----------\n\n[DudaNogueira (2024-12-10T20:44:01.516Z)]: hi @arturs_sprogis !!\nWelcome to our community \nNot all collection configurations are mutable. Here you have a list of what configs are:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection definition | Weaviate\n\n  Schema Configuration in Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNote that you can only change those:\ncollection.config.update(\n    multi_tenancy_config=wvc.config.Reconfigure.multi_tenancy(\n        auto_tenant_activation=True,\n        auto_tenant_creation=True\n    )\n)\n\nBecause of that you need to enable multi tenancy while creating a new collection, create a new tenant on that new collection, and migrate your data over to it.\nLet me know if this helps!\nThanks!\n\n----------\n\n[sebawita (2024-12-12T10:57:24.439Z)]: DudaNogueira:\n\nNot all collection configurations are mutable. Here you have a list of what configs are:\n\n\nTo Duda’s point, you cannot change/update a single-tenant collection into a multi-tenant collection. You need to create a new collection with multi_tenancy enabled.",
    "date_created": "2024-12-10T20:29:17.940Z",
    "has_accepted_answer": true,
    "title": "How to enable multi tenancy on the existing collection?",
    "topic_id": 9191
  },
  {
    "user_id": 1600,
    "conversation": "[izharg (2024-10-14T04:59:50.927Z)]: Hi,\nI’m running a 5-node Weaviate cluster on k8s. The node image version is semitechnologies/weaviate:1.26.3.\nI have a collection called “Chunks” (see config below). After I’ve added a property to the collection I’m getting the following error from the cluster when I try to read or write data objects:\n“msg:search index sources code:500 err:remote shard object search fdS9BqUGyiH9: status code: 401, error:”\nThis error occurs even when I create a new collection with a different schema and try writing data into it. Can you please suggest a solution?\nCollection config -\n\n{\n    \"class\": \"Chunks\",\n    \"invertedIndexConfig\": {\n        \"bm25\": {\n            \"b\": 0.75,\n            \"k1\": 1.2\n        },\n        \"cleanupIntervalSeconds\": 60,\n        \"indexNullState\": false,\n        \"indexPropertyLength\": false,\n        \"indexTimestamps\": false,\n        \"stopwords\": {\n            \"preset\": \"en\"\n        }\n    },\n    \"moduleConfig\": {},\n    \"multiTenancyConfig\": {\n        \"autoTenantActivation\": false,\n        \"autoTenantCreation\": false,\n        \"enabled\": false\n    },\n    \"properties\": [\n        {\n            \"dataType\": [\n                \"uuid\"\n            ],\n            \"indexFilterable\": true,\n            \"indexRangeFilters\": false,\n            \"indexSearchable\": false,\n            \"moduleConfig\": {\n                \"none\": {}\n            },\n            \"name\": \"source_id\",\n            \"tokenization\": null\n        },\n        {\n            \"dataType\": [\n                \"uuid\"\n            ],\n            \"indexFilterable\": true,\n            \"indexRangeFilters\": false,\n            \"indexSearchable\": false,\n            \"moduleConfig\": {\n                \"none\": {}\n            },\n            \"name\": \"groupspace\",\n            \"tokenization\": null\n        },\n        {\n            \"dataType\": [\n                \"uuid\"\n            ],\n            \"indexFilterable\": true,\n            \"indexRangeFilters\": false,\n            \"indexSearchable\": false,\n            \"moduleConfig\": {\n                \"none\": {}\n            },\n            \"name\": \"source_chunk_id\",\n            \"tokenization\": null\n        },\n        {\n            \"dataType\": [\n                \"uuid\"\n            ],\n            \"indexFilterable\": true,\n            \"indexRangeFilters\": false,\n            \"indexSearchable\": false,\n            \"moduleConfig\": {\n                \"none\": {}\n            },\n            \"name\": \"target_chunk_id\",\n            \"tokenization\": null\n        },\n        {\n            \"dataType\": [\n                \"text\"\n            ],\n            \"indexFilterable\": true,\n            \"indexRangeFilters\": false,\n            \"indexSearchable\": true,\n            \"moduleConfig\": {\n                \"none\": {}\n            },\n            \"name\": \"entry_type\",\n            \"tokenization\": \"word\"\n        },\n        {\n            \"dataType\": [\n                \"text\"\n            ],\n            \"indexFilterable\": true,\n            \"indexRangeFilters\": false,\n            \"indexSearchable\": true,\n            \"moduleConfig\": {\n                \"none\": {}\n            },\n            \"name\": \"chunk_index\",\n            \"tokenization\": \"word\"\n        },\n        {\n            \"dataType\": [\n                \"uuid\"\n            ],\n            \"description\": \"This property was generated by Weaviate\\u0027s auto-schema feature on Fri Oct 11 03:47:28 2024\",\n            \"indexFilterable\": true,\n            \"indexRangeFilters\": false,\n            \"indexSearchable\": false,\n            \"moduleConfig\": {\n                \"none\": {}\n            },\n            \"name\": \"paper_id\",\n            \"tokenization\": null\n        }\n    ],\n    \"replicationConfig\": {\n        \"asyncEnabled\": false,\n        \"factor\": 1\n    },\n    \"shardingConfig\": {\n        \"actualCount\": 5,\n        \"actualVirtualCount\": 640,\n        \"desiredCount\": 5,\n        \"desiredVirtualCount\": 640,\n        \"function\": \"murmur3\",\n        \"key\": \"_id\",\n        \"strategy\": \"hash\",\n        \"virtualPerPhysical\": 128\n    },\n    \"vectorIndexConfig\": {\n        \"distanceMetric\": \"cosine\",\n        \"flat\": {\n            \"distanceMetric\": \"cosine\",\n            \"vectorCacheMaxObjects\": 1000000000000\n        },\n        \"hnsw\": {\n            \"cleanupIntervalSeconds\": 300,\n            \"distanceMetric\": \"cosine\",\n            \"dynamicEfFactor\": 8,\n            \"dynamicEfMax\": 500,\n            \"dynamicEfMin\": 100,\n            \"ef\": -1,\n            \"efConstruction\": 128,\n            \"flatSearchCutoff\": 40000,\n            \"maxConnections\": 32,\n            \"skip\": false,\n            \"vectorCacheMaxObjects\": 1000000000000\n        },\n        \"threshold\": 10000\n    },\n    \"vectorIndexType\": \"dynamic\",\n    \"vectorizer\": \"none\"\n}\n\n----------\n\n[DudaNogueira (2024-10-15T19:12:53.617Z)]: Hi!\nWhere do you see this error?\nWhat are the errors you get both from server and from client?\n\n----------\n\n[izharg (2024-10-16T07:48:22.424Z)]: Hi,\nI see these errors in pod logs and from Python client responses.\nI have 5 pods, named weaviate-*.\nThis is the log from weaviate-0 pod:\n{\"action\":\"requests_total\",\"api\":\"rest\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"class_name\":\"\",\"error\":\"node: weaviate-3: unexpected status code 401 ()\",\"level\":\"error\",\"msg\":\"unexpected error\",\"query_type\":\"nodes\",\"time\":\"2024-10-15T05:09:37Z\"}\n\nWhen I look at weaviate-3 logs:\n{\"action\":\"requests_total\",\"api\":\"rest\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"class_name\":\"\",\"error\":\"list objects: search index sources: remote shard object search TRlmZZlax6LZ: status code: 401, error: \",\"level\":\"error\",\"msg\":\"unexpected error\",\"query_type\":\"objects\",\"time\":\"2024-10-15T04:53:49Z\"}\n\nwhen I try to call the REST API /cluster/statistics I get:\n{\n  \"error\": [\n    {\n      \"message\": \"node: weaviate-3: unexpected status code 401 ()\"\n    }\n  ]\n}",
    "date_created": "2024-10-14T04:59:50.864Z",
    "has_accepted_answer": false,
    "title": "[Question] search status code: 401",
    "topic_id": 5200
  },
  {
    "user_id": 513,
    "conversation": "[rjalex (2025-01-07T18:09:52.028Z)]: Have this very simple python code:\ndef main():\n    client = init_weaviate_client()\n    try:\n        collection = client.collections.get(os.getenv(\"COP_COPERTINE_COLLNAME\"))\n        extractor = ManifestoGPTExtractor()\n        for obj in collection.iterator():\n            extractor.process_object(collection, obj)\n    finally:\n        client.close()\n\nand I have a breakpoint on the process_object line and inspecting the obj variable I see:\nimage1156×740 74 KB\nwhere you can see we do NOT have a “editionImageStr” property which should hold a 250-300K Base64 image.\nI am positive that ALL objects in the collection DO HAVE that property as you can see from just a snapshot of one of them through Postman on the same collection:\nimage2264×1728 378 KB\ncannot find any details on why iterate() is apparently “losing” that BLOB property. I found a post by @sebawita speaking of a search function:\n\nThe Python client v4, doesn’t return blob properties by default, as these are potentially large values.\nHowever, if you run a query with return_properties , I would expect values for the selected properties to be present.\n\nbut I cannot find a way for this to work with the iterator(). May this “bug” be related?\nHere is the collection definition:\nCOPERTINE_COLL_CONFIG = {\n    \"class\": COP_COPERTINE_COLLNAME,  \n    \"description\": \"Collection of Il Manifesto newspaper covers\",\n    \"vectorizer\": \"none\",  \n    \"properties\": [\n        Property(\n            name=\"editionId\", \n            data_type=DataType.TEXT,\n            description=\"Unique identifier for the edition\",\n            tokenization=\"field\",\n            index_searchable=False\n        ),\n        Property(\n            name=\"editionDateIsoStr\",\n            data_type=DataType.DATE,\n            description=\"Publication date of the edition\"\n        ),\n        Property(\n            name=\"editionImageStr\",\n            data_type=DataType.BLOB,  \n            description=\"Base64 encoded image string\"\n        ),\n        Property(\n            name=\"captionAIStr\",\n            data_type=DataType.TEXT,  \n            description=\"Image caption as recognized by the AI model\"\n        ),\n        Property(\n            name=\"imageAIDeStr\",\n            data_type=DataType.TEXT,  \n            description=\"Image description as generated by the AI model\"\n        ),\n        Property(\n            name=\"modelAIName\",\n            data_type=DataType.TEXT,  \n            description=\"AI model name\",\n            tokenization=\"field\",\n            index_searchable=False\n        ),\n    ]\n}\n\nI do need to iterate on this collection and process the images attached to each object in that property. Thanks\nServer Setup Information\n\nWeaviate Server Version: 1.25.4\nDeployment Method: docker\nMulti Node? No\nClient Language and Version: Python 4.10.2\nMultitenancy?:  No\n\n----------\n\n[DudaNogueira (2025-01-23T21:41:24.808Z)]: Cia amigo @rjalex !!\nSorry for the late response. I was on vacanze \nHere a MVE:\nimport weaviate\nfrom langchain_huggingface import HuggingFaceEmbeddings\nimport weaviate.classes.config as wc\nfrom weaviate import classes as wvc\n\nclient = weaviate.connect_to_local()\nprint(f\"Client: {weaviate.__version__}, Server: {client.get_meta().get('version')}\")\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name = 'Test',\n    properties=[\n        wc.Property(name = 'text', data_type = wc.DataType.TEXT),\n        wc.Property(name = 'blob', data_type = wc.DataType.BLOB),\n    ]\n)\nimport base64\nwith open(\"/Users/dudanogueira/Pictures/sample.png\", 'rb') as file:\n    blob = base64.b64encode(file.read()).decode('utf-8')\ncollection.data.insert(\n    properties={\"text\": \"example\", \"blob\": blob},\n)\n# check if we have the objects:\nprint(collection.aggregate.over_all().total_count)\n\nfor o in collection.iterator(return_properties=[\"text\", \"blob\"]):\n    print(o.properties)\n\nI can see the blob there  using:\nClient: 4.10.4, Server: 1.28.3\nLet me know if this helps.\n\n----------\n\n[rjalex (2025-01-24T07:46:19.774Z)]: Never apologize for taking time out my friend \nActually after some thought I decided that architecturally in my case having images in the database was not the best pattern and decided to store them on the filesystem and just have a link for them in the weaviate object.\nHaving said that it is very useful to know that if needed it can be done.\nIf anyone will stumble on this problem/solution here is the complete revised code of your example:\npyproject.toml:\n[tool.poetry]\n\nname = \"weaviateblobtest\"\n\nversion = \"0.1.0\"\n\ndescription = \"\"\nauthors = [\"Duda & Bob <vacations@are.fun>\"]\nreadme = \"README.md\"\npackage-mode = false\n\n[tool.poetry.dependencies]\npython = \"^3.11\"\nweaviate-client = \"^4.10.4\"\npybase64 = \"^1.4.0\"\n\n[tool.poetry.group.dev.dependencies]\nmypy = \"^1.8.0\"\n\n[build-system]\nrequires = [\"poetry-core\"]\n\nbuild-backend = \"poetry.core.masonry.api\"\n\nand the full program with error handling, context manager and nice prints \n\"\"\"This module demonstrates how images can be stored and retrieved as base64-encoded blobs\nin a Weaviate collection. It shows basic operations like creating a collection with blob\nsupport, inserting an image as a blob, and retrieving it back from the collection.\n\"\"\"\nimport base64\nimport weaviate\nfrom weaviate.exceptions import WeaviateConnectionError\nimport weaviate.classes.config as wc\nfrom weaviate.collections import Collection\n\ndef create_test_collection(client: weaviate.WeaviateClient) -> Collection:\n    \"\"\"Create a test collection with text and blob properties.\"\"\"\n    # First ensure any existing collection is removed\n    try:\n        client.collections.delete(\"Test\")\n    except Exception:\n        # Ignore errors when trying to delete non-existent collection\n        pass\n    \n    return client.collections.create(\n        name='Test',\n        properties=[\n            wc.Property(name='text', data_type=wc.DataType.TEXT),\n            wc.Property(name='blob', data_type=wc.DataType.BLOB),\n        ]\n    )\n\ndef main() -> None:\n    \"\"\"Main function to demonstrate blob storage and retrieval.\"\"\"\n    try:\n        with weaviate.connect_to_local() as client:\n            print(f\"Client: {weaviate.__version__}, Server: {client.get_meta().get('version')}\")\n            \n            collection = create_test_collection(client)\n            \n            # Read and encode the image\n            try:\n                with open(\"image.jpg\", 'rb') as file:\n                    blob = base64.b64encode(file.read()).decode('utf-8')\n            except FileNotFoundError:\n                print(\"Error: image.jpg not found in the current directory\")\n                return\n            except Exception as e:\n                print(f\"Error reading image file: {e}\")\n                return\n            \n            # Insert the blob\n            try:\n                collection.data.insert(\n                    properties={\"text\": \"Text field describing the image\", \"blob\": blob},\n                )\n            except Exception as e:\n                print(f\"Error inserting data into collection: {e}\")\n                return\n            \n            # Verify the data\n            try:\n                count = collection.aggregate.over_all().total_count\n                print(f\"Total objects in collection: {count}\")\n                \n                print(\"\\nRetrieved objects:\")\n                for obj in collection.iterator(return_properties=[\"text\", \"blob\"]):\n                    properties = obj.properties\n                    print(f\"Text: {properties.get('text')}\")\n                    print(f\"Blob length: {len(str(properties.get('blob')))}\")\n            except Exception as e:\n                print(f\"Error retrieving data from collection: {e}\")\n                return\n\n    except WeaviateConnectionError:\n        print(\"Error: Could not connect to Weaviate. Make sure the Weaviate instance is running locally.\")\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n\nif __name__ == \"__main__\":\n    main()",
    "date_created": "2025-01-07T18:09:51.971Z",
    "has_accepted_answer": true,
    "title": "Iterator not returning a property",
    "topic_id": 9613
  },
  {
    "user_id": 513,
    "conversation": "[rjalex (2024-07-23T10:59:00.560Z)]: EDIT to put the solution on top. In my case the process failed since I created the collection I wanted to restore and then tried the restore. Also I find the HTTP methods to check if the restore went ok to be misleading\nPlease remember that the cURL will ask for restore to the running weaviate container.\nFor this to find the backup data, weaviate container must have been started with the host directory containing the backup (for example /backups ) mounted into the container (eg /tmp/backup) as per the docker compose service declaration.  Also the CLUSTER_HOSTNAME environment variable has to be the same of when the backup was created. Here is an example dor a cluster named finland, with the files on the host in /backups and the backup path within the container in /tmp/backup as docker compose service declaration elements:\nenvironment:\n  ENABLE_MODULES: 'backup-filesystem'\n  BACKUP_FILESYSTEM_PATH: /tmp/backup\n  CLUSTER_HOSTNAME: finland\n\nvolumes:\n  - /backups:/tmp/backup\n\nPlease note that the clustername needs to be the same on the exporting node and on the node on which you want to restore.\nAlso note that the collections you want to restore must NOT exist already on the node on which you want to restore.\nRemember that to start a new weaviate instance from scratch with no data you can stop its container, delete the data volume, recreate it anew, restart.\n— here follows the original question:\nBacked up server on nodeA. NodeA runs with the following docker compose definition:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.4\n    command:\n      - \"--host=0.0.0.0\"\n      - \"--port=8080\"\n      - \"--scheme=http\"\n    restart: unless-stopped\n    environment:\n      LOG_LEVEL: info\n      ENABLE_MODULES: 'backup-filesystem'\n      BACKUP_FILESYSTEM_PATH: /tmp/backup\n      ENABLE_CUDA: 0\n      LIMIT_RESOURCES: true\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: true\n      PERSISTENCE_DATA_PATH: /var/lib/weaviate\n      CLUSTER_HOSTNAME: finland\n      DISABLE_TELEMETRY: true\n      GOMAXPROCS: 4\n    networks:\n      - weaviate_net\n      - mema_network\n    ports:\n      - \"8080:8080\"\n      - \"50051:50051\"\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n      - /sata/backup:/tmp/backup\n    logging: *default-logging\n\nand querying this node for collection and object counts:\ncurl -L 'http://localhost:8080/v1/nodes?output=verbose'\nyields:\n{\n    \"nodes\": [\n        {\n            \"batchStats\": {\n                \"queueLength\": 0,\n                \"ratePerSecond\": 0\n            },\n            \"gitHash\": \"a61909a\",\n            \"name\": \"finland\",\n            \"shards\": [\n                {\n                    \"class\": \"Articles_intfloat_multilingual_e5_large\",\n                    \"compressed\": false,\n                    \"loaded\": true,\n                    \"name\": \"hjlaDyHIS4Yd\",\n                    \"objectCount\": 614044,\n                    \"vectorIndexingStatus\": \"READY\",\n                    \"vectorQueueLength\": 0\n                }\n            ],\n            \"stats\": {\n                \"objectCount\": 614044,\n                \"shardCount\": 1\n            },\n            \"status\": \"HEALTHY\",\n            \"version\": \"1.25.4\"\n        }\n    ]\n}\n\nI back this up with the following command:\ncurl -L 'http://localhost:8080/v1/backups/filesystem' -H 'Content-Type: application/json' -d \"{\\\"id\\\": \\\"20240722060001_mema_wv_backup\\\"}\"\nand the resulting backup tree on the host filesystem is is as follows:\nmema@newisa:/sata/backup$ tree 20240722060001_mema_wv_backup\n20240722060001_mema_wv_backup\n├── backup_config.json\n└── finland\n    ├── Articles_intfloat_multilingual_e5_large\n    │   └── chunk-1\n    └── backup.json\n\nwith the following sizes:\nmema@newisa:/sata/backup$ du -h 20240722060001_mema_wv_backup/\n2.8G    20240722060001_mema_wv_backup/finland/Articles_intfloat_multilingual_e5_large\n2.8G    20240722060001_mema_wv_backup/finland\n2.8G    20240722060001_mema_wv_backup/\n\nI transfer this file tree on the new node and place it in the /backups host directory. On this new node weaviate is also started by docker compose with the following service definition:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.4\n    command:\n      - \"--host=0.0.0.0\"\n      - \"--port=8080\"\n      - \"--scheme=http\"\n    restart: unless-stopped\n    environment:\n      LOG_LEVEL: info\n      ENABLE_MODULES: 'backup-filesystem'\n      BACKUP_FILESYSTEM_PATH: /tmp/backup\n      ENABLE_CUDA: 0\n      LIMIT_RESOURCES: true\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: true\n      PERSISTENCE_DATA_PATH: /var/lib/weaviate\n      CLUSTER_HOSTNAME: finland\n      DISABLE_TELEMETRY: true\n      GOMAXPROCS: 24\n    networks:\n      - weaviate_net\n      - mema_network\n    ports:\n      - \"8080:8080\"\n      - \"50051:50051\"\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n      - /backups:/tmp/backup\n    logging: *default-logging\n\nwhich as you can see is mostly identical save for the host /backups mounted on the container /tmp/backup.\nWhen I query the new instance, I see the collection exists and has 0 objects as expected:\ncurl -L 'http://localhost:8080/v1/nodes?output=verbose'\n{\n    \"nodes\": [\n        {\n            \"batchStats\": {\n                \"queueLength\": 0,\n                \"ratePerSecond\": 0\n            },\n            \"gitHash\": \"a61909a\",\n            \"name\": \"finland\",\n            \"shards\": [\n                {\n                    \"class\": \"[]\n                }\n            ],\n            \"stats\": {\n                \"objectCount\": 0,\n                \"shardCount\": 1\n            },\n            \"status\": \"HEALTHY\",\n            \"version\": \"1.25.4\"\n        }\n    ]\n}\n\nso I now run the restore command:\n# Execute the curl command with the provided backup_id\ncurl -X POST -H \"Content-Type: application/json\" -d \"{\\\"id\\\": \\\"$backup_id\\\"}\" \"http://localhost:8080/v1/backups/filesystem/$backup_id/restore\"\n\nwhich produces the following output:\n{\"backend\":\"filesystem\",\"classes\":[\"Articles_intfloat_multilingual_e5_large\"],\"id\":\"20240722060001_mema_wv_backup\",\"path\":\"/tmp/backup/20240722060001_mema_wv_backup\",\"status\":\"STARTED\"}\nI then check its outcome:\n# Execute the curl command with the provided backup_id\ncurl \"http://localhost:8080/v1/backups/filesystem/$backup_id\"\n{\"backend\":\"filesystem\",\"id\":\"20240722060001_mema_wv_backup\",\"path\":\"/tmp/backup/20240722060001_mema_wv_backup\",\"status\":\"SUCCESS\"}\n\nbut please note that this “SUCCESS” is available only a second later, so highly suspect \nI then check if the collection has been populated:\ncurl -L 'http://localhost:8080/v1/nodes?output=verbose'\nbut sadly the outcome is that the collection is still empty:\n{\n    \"nodes\": [\n        {\n            \"batchStats\": {\n                \"queueLength\": 0,\n                \"ratePerSecond\": 0\n            },\n            \"gitHash\": \"a61909a\",\n            \"name\": \"finland\",\n            \"shards\": [\n                {\n                    \"class\": \"Articles_intfloat_multilingual_e5_large\",\n                    \"compressed\": false,\n                    \"loaded\": true,\n                    \"name\": \"BNVEKxLMqZ1K\",\n                    \"objectCount\": 0,\n                    \"vectorIndexingStatus\": \"READY\",\n                    \"vectorQueueLength\": 0\n                }\n            ],\n            \"stats\": {\n                \"objectCount\": 0,\n                \"shardCount\": 1\n            },\n            \"status\": \"HEALTHY\",\n            \"version\": \"1.25.4\"\n        }\n    ]\n}\n\nwhat am I overlooking / doing wrong?\nFor sure I am not able to see any errors that might arise from the\n# Execute the curl command with the provided backup_id\ncurl -X POST -H \"Content-Type: application/json\" -d \"{\\\"id\\\": \\\"$backup_id\\\"}\" \"http://localhost:8080/v1/backups/filesystem/$backup_id/restore\"\n\ncommand which might help in understanding (and the SUCCESS status of the check is misleading).\nThanks a lot\n\n----------\n\n[DudaNogueira (2024-07-23T12:11:09.609Z)]: Ciao my friend!!\nDo you see any outstanding logs on the server side?\nIf I recall it correctly, you shouldn’t have the collection created, or it will yield that the collection exists already.\nI just noticed we do not have a backup recipe in our recipes repo, so I will try to both reproduce this and work on something there later today/tomorrow.\n\n----------\n\n[rjalex (2024-07-23T12:48:57.849Z)]: Hey @DudaNogueira hope life is treating you well my friend.\nI restarted the whole process with a new virgin volume for weaviate and I did NOT create that collection beforehand AND despite the query results you will see below, I WAITED some time and THEN checked and much to my joy and surprise I found the collection created and the objects restored.\nSo good for me save that maybe the queries you see below are misleading:\n# Execute the curl command with the provided backup_id\ncurl -X POST -H \"Content-Type: application/json\" -d \"{\\\"id\\\": \\\"$backup_id\\\"}\" \"http://localhost:8080/v1/backups/filesystem/$backup_id/restore\"\n\nimmediately gives:\n{\"backend\":\"filesystem\",\"classes\":[\"Articles_intfloat_multilingual_e5_large\"],\"id\":\"20240722060001_mema_wv_backup\",\"path\":\"/tmp/backup/20240722060001_mema_wv_backup\",\"status\":\"STARTED\"}\nwhich is correct. But:\n# Execute the curl command with the provided backup_id\ncurl \"http://localhost:8080/v1/backups/filesystem/$backup_id\"\n\nimmediately giving:\n{\"backend\":\"filesystem\",\"id\":\"20240722060001_mema_wv_backup\",\"path\":\"/tmp/backup/20240722060001_mema_wv_backup\",\"status\":\"SUCCESS\"}\nin my opinion is misleading. It leads you to believe that the backup FINISHED and was successfull, which is not true.\nThe backup was still underway as show by trying another:\n# Execute the curl command with the provided backup_id\ncurl -X POST -H \"Content-Type: application/json\" -d \"{\\\"id\\\": \\\"$backup_id\\\"}\" \"http://localhost:8080/v1/backups/filesystem/$backup_id/restore\"\n\nwhich gave a tale telling result:\n{\"error\":[{\"message\":\"restoration 20240722060001_mema_wv_backup already in progress\"}]}\nwhich led to me to wait some time, crossing my fingers, and after some time passed I HTTP queried weaviate instance and was happy to see:\n{\n    \"nodes\": [\n        {\n            \"batchStats\": {\n                \"queueLength\": 0,\n                \"ratePerSecond\": 0\n            },\n            \"gitHash\": \"a61909a\",\n            \"name\": \"finland\",\n            \"shards\": [\n                {\n                    \"class\": \"Articles_intfloat_multilingual_e5_large\",\n                    \"compressed\": false,\n                    \"loaded\": true,\n                    \"name\": \"hjlaDyHIS4Yd\",\n                    \"objectCount\": 614010,\n                    \"vectorIndexingStatus\": \"READY\",\n                    \"vectorQueueLength\": 0\n                }\n            ],\n            \"stats\": {\n                \"objectCount\": 614010,\n                \"shardCount\": 1\n            },\n            \"status\": \"HEALTHY\",\n            \"version\": \"1.25.4\"\n        }\n    ]\n}\n\nSo I have solved the mistery but it was  a long hunt \nThank you and take care\n\n----------\n\n[DudaNogueira (2024-07-24T20:52:26.807Z)]: Thanks for sharing, amigo!",
    "date_created": "2024-07-23T10:59:00.500Z",
    "has_accepted_answer": true,
    "title": "Unable to restore a filesystem based backup on another machine",
    "topic_id": 3129
  },
  {
    "user_id": 1264,
    "conversation": "[Cobyboss (2024-08-16T20:35:20.553Z)]: I noticed that you guys aded automatic token generation with Google. Currently, I have to do gcloud auth print-access-token to get the token, but I wanted to use the automatic token generation that has been included in the documentation.\nMy original code:\nvertex_key =\"some key\"\nheaders = {\n    \"X-Palm-Api-Key\": vertex_key,\n}\n\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=weaviate_url,                       # `weaviate_url`: your Weaviate URL\n    auth_credentials=Auth.api_key(weaviate_key),      # `weaviate_key`: your Weaviate API key\n    headers=headers\n)\n\nMy new code:\nos.environ['GOOGLE_APPLICATION_CREDENTIALS'] = json_file_path\nos.environ['USE_GOOGLE_AUTH'] = 'true'\n\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=weaviate_url,                       # `weaviate_url`: your Weaviate URL\n    auth_credentials=Auth.api_key(weaviate_key),      # `weaviate_key`: your Weaviate API key\n)\n\nI just assumed we could remove the headers since it should automatically be generating a key. However, I get\nErrorObject(message=\"WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: Google API Key: no api key found neither in request header: X-Palm-Api-Key or X-Google-Api-Key or X-Google-Vertex-Api-Key or X-Google-Studio-Api-Key nor in environment variable under PALM_APIKEY or GOOGLE_APIKEY')\n\nHow do I implement automatic token generation properly?\n\n----------\n\n[DudaNogueira (2024-08-19T12:49:42.338Z)]: Hi @Cobyboss !!\nThis is the corresponding documentation:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nGoogle AI + Weaviate | Weaviate - Vector Database\n\n  Google AI offers a wide range of models for natural language processing and generation. Weaviate seamlessly integrates with Google AI Studio and Google Vertex AI APIs, allowing users to leverage Google AI's models directly within the Weaviate...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNote that it was added in versions:\nFrom Weaviate versions 1.24.16 , 1.25.3 and 1.26 .\nWhat is the server version you are using?\n\n----------\n\n[Cobyboss (2024-08-19T18:17:23.093Z)]: I was trying to follow the documentation from that link and made changes as I showed in my code earlier, but I could not get it to work. I am using 1.25.10\n\n----------\n\n[DudaNogueira (2024-08-19T18:43:56.243Z)]: Hi!\nAs I understand, those settings as well as the credentials json must set on the server side, not on the client side.\nOnce you do that on the server side, the client can be initialized without the credentials.\nLet me know if this helps.\nThanks!\n\n----------\n\n[Cobyboss (2024-08-19T20:10:47.293Z)]: I’m pretty sure I have set up the necessary steps on the server side and have the credentials json file set up. I assumed that I no longer need to pass the headers when connecting to the weaviate cloud since the json file should set it up for me which is why my new code is:\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=weaviate_url,                       # `weaviate_url`: your Weaviate URL\n    auth_credentials=Auth.api_key(weaviate_key),      # `weaviate_key`: your Weaviate API key\n    # headers=headers\n)\n\nHowever, the error I get seems to indicate that I still need to either pass in the header or add an extra environment variable:\nno api key found neither in request header: X-Palm-Api-Key or X-Google-Api-Key or X-Google-Vertex-Api-Key or X-Google-Studio-Api-Key nor in environment variable under PALM_APIKEY or GOOGLE_APIKEY'\n\nMy question is basically do I need to set the api key in the request header or in PALM_APIKEY or GOOGLE_APIKEY if I followed the steps in the documentation and already set USE_GOOGLE_AUTH to ‘true’ and have the json file?\n\n----------\n\n[DudaNogueira (2024-08-19T20:52:55.329Z)]: Hi @Cobyboss !\nAs I never used this feature myself, I will take some time to try reproducing this myself and possibly escalating with out team.\nI’ll be back with more info.\nThanks!\n\n----------\n\n[Filipp_Trigub (2024-09-03T08:04:52.298Z)]: I am facing a similar issue.\nAll versions match, Oauth2 json file is created and the env var pointing to it is set in my local env. USE_GOOGLE_AUTH is also set.\nIt is not clear to me, what it means to make serverside changes here. My cluster does not seem to allow uploading the cred file.\nWhat am I missing?\nEDIT: this option is only for self-hosted servers, right?\n\n----------\n\n[Cobyboss (2024-09-16T22:32:19.320Z)]: Any updates? I’ve done a workaround solution in the meantime but would appreciate a better solution.\n\n----------\n\n[DudaNogueira (2024-09-18T12:20:42.832Z)]: HI!\nThis feature is only available to be set on the server side  as of now. and Not on the client side.\nWe do have a feature request to add this feature to the client side too:\n  \n\n      github.com/weaviate/weaviate-python-client\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Add an ability to refresh Google auth keys\n    \n\n    \n      \n        opened 09:38AM - 15 Mar 24 UTC\n      \n\n\n      \n        \n          \n          databyjp\n        \n      \n    \n\n    \n        \n          enhancement\n        \n        \n          usability\n        \n    \n  \n\n\n  \n    **Problem**:\nWeaviate users who use the Vertex AI integration must provide the O…Auth key for API authentication. \n\nBut this key has a very short lifetime, and currently the user must semi manually refresh the key. Eg as shown here. https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-palm#token-expiry-for-vertex-ai-users\n\n**Proposal**\n\nExtend the Weaviate Python client to perform token refresh in the background, with the user's credentials for example.\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nPlease, leave your thumbs up   there so we can prioritize it.\nThanks!",
    "date_created": "2024-08-16T20:35:20.507Z",
    "has_accepted_answer": true,
    "title": "Google automatic token generation",
    "topic_id": 3377
  },
  {
    "user_id": 1714,
    "conversation": "[Adi_Sra_Ga (2024-10-24T06:16:41.820Z)]: Hello folks and @DudaNogueira\nI have a parquet file with embeddings stored in it and the actual raw size of the parquet file is 44GB and when inserting in to the DB and post insertion the foot print is just 40GB on the persistent data path.\nMy persistent datapath is set an NFS share mounted on to the Weaviate DB server running single node .  My expectation is that  everything will be stored after insertion. To my surprise the actual size of the directory post insertion is lesser than the file size and i have not enabled any PQ or BQ compression .\nQuestions :\n\n\nDoes Weaviate uses local server cache storage + persistent data storage  like  70 -30 % or something of that fashion .  Because i could see some data written in the local cache. ?\n\n\nHow weavieate stores its vectors inside the collection , does it perform any compression by default. In my configuration PQ and BQ is disabled.\n\n\nSo i am wondering do Weaviate DB do some sort of Quantization techniques  or data compression technique’s to have lesser footprint ?\nAny pointers on how the collections are stored and retrieved .\n\n----------\n\n[DudaNogueira (2024-11-01T14:40:02.360Z)]: hi @Adi_Sra_Ga !!\nSorry for the delay here\nI am assuming that this parquet already includes the vector, right?\nThere some possible explanations here.\nFor example, Weaviate uses 32 bit floats for storing vectors. so you have 64 bit float arrays in the parquet file than could explain things.\nAlso, your parquet may have some extra paddings, spaces, etc.\nLet me know if this helps.",
    "date_created": "2024-10-24T06:16:41.770Z",
    "has_accepted_answer": false,
    "title": "How is Storage footprint reduced after inserting vectors in to Weaviate",
    "topic_id": 5860
  },
  {
    "user_id": 672,
    "conversation": "[Frosslee (2024-07-25T07:22:46.769Z)]: Hello everyone,\nI’m currently working on a project involving two different bots that use different vectorizers for creating and managing schemas and databases in Weaviate. However, I’m encountering an issue where only one of the bots’ vectorizers previews correctly in the Weaviate collections console. using amazon.titan-embed-text-v2:0\nTLDR\nThe vectorizer for GPT is working correctly, but it’s not functioning for AWS Bedrock. Attempts to fix it have been unsuccessful so far.\nDetails of Implementations:\nChatGPT Bot\nGet Client Function:\ndef get_client(database_name):\n    WCS_API_KEY, WCS_CLUSTER_URL, OPENAI_APIKEY, class_name = database_picker(database_name)\n    max_retries = 7\n    retry_delay_seconds = 2 \n    for attempt in range(1, max_retries + 1):\n        try:\n            client = weaviate.connect_to_wcs(\n                cluster_url=WCS_CLUSTER_URL,\n                auth_credentials=weaviate.auth.AuthApiKey(WCS_API_KEY),\n                headers={\"X-OpenAI-Api-Key\": OPENAI_APIKEY},\n                skip_init_checks=True\n            )\n            return client\n        except Exception as e:\n            print(f\"Attempt {attempt} failed with error: {str(e)}\")\n            if attempt < max_retries:\n                print(f\"Retrying in {retry_delay_seconds} seconds...\")\n                time.sleep(retry_delay_seconds)\n\nGenerate Database Function:\ndef generate_database(class_name, client):\n    try:\n        client.collections.create(\n            name=class_name,\n            vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n            generative_config=wvc.config.Configure.Generative.openai(),\n            properties=[\n                wvc.config.Property(\n                    name=class_name,\n                    data_type=wvc.config.DataType.TEXT\n                )\n            ]\n        )\n    except Exception as e:\n        return {\"error\": str(e)}\n    finally:\n        client.close()\n\nBedrock Bot\nusing amazon.titan-embed-text-v2:0\nGet Client Function:\nfor attempt in range(0, RETRY_AMOUNT):\n    try:\n        client = None\n        client = weaviate.connect_to_wcs(\n            cluster_url=os.getenv(\"WCS_CLUSTER_URL\"),\n            auth_credentials=AuthApiKey(os.getenv(\"WCS_API_KEY\")),\n            skip_init_checks=os.getenv(\"W_SKIP_INIT_CHECK\"),\n            headers={\n                \"X-AWS-Access-Key\": os.getenv(\"ACCESS_KEY_ID\"),\n                \"X-AWS-Secret-Key\": os.getenv(\"SECRET_ACCESS_KEY\"),\n            },\n        )\n        while client.is_ready() == False:\n            pass\n        return client\n\nGenerate Database Function:\ntry:\n    client.collections.create(\n        class_name,\n        vectorizer_config=[\n            Configure.NamedVectors.text2vec_aws(\n                name=class_name,\n                region=os.getenv(\"WEAVIATE_REGION\"),\n                service=os.getenv(\"WEAVIATE_SERVICE\"),\n                model=os.getenv(\"WEAVIATE_MODEL\"),\n            )\n        ],\n        properties=[\n            wvc.config.Property(\n                name=class_name,\n                data_type=wvc.config.DataType.TEXT\n            )\n        ],\n    )\n    return json.dumps({\"result\": \"Database class created successfully.\"})\nexcept Exception as e:\n    return {\"error\": str(e)}\n\nIssue:\nWhile both bots create schemas and databases successfully, only the ChatGPT bot’s vectorizer appears correctly in the Weaviate collections console. The Bedrock bot’s vectorizer does not show up as expected.\nThings I’ve Tried:\n\nDouble-check the configuration settings for both bots.\nVerified API keys and permissions.\nEnsured that both bots have the same class name and data type configurations.\n\nRequest for Help:\n\nHas anyone faced a similar issue with different vectorizers in Weaviate?\nAre there specific settings or configurations that I might be missing for the Bedrock bot?\nAny troubleshooting steps or advice would be greatly appreciated.\n\nThank you in advance for your help!\nimage for GPT on the console\nimage794×749 31.2 KB\nimage for the using amazon.titan-embed-text-v2:0\nimage802×475 20.8 KB\n\n----------\n\n[DudaNogueira (2024-07-25T21:47:29.730Z)]: hi @Frosslee !!\nWelcome back \nDoes the collections and queries work as expected?\nThis may be a UI problem in our console.\nLet me know if this is just the UI. I try to reproduce this meanwhile.\nThanks!\n\n----------\n\n[Frosslee (2024-07-26T04:36:02.962Z)]: HI @DudaNogueira\nSo querying works fine for GPT to get a distance lower than 0.24 bit for AWS bedrock nothing s under 0.4 really.  I did multiple tests and no distance i can’t get below 0.4 (cosine) the data returned is not usable or completely mumbled and doesn’t even return a chunk with the correct information\n\n----------\n\n[DudaNogueira (2024-07-26T23:47:05.791Z)]: Well, the absolute comparison of distance between models per se doesn’t giving it much as it can be relative to other objects, but the similarity/relevance of the results against the query that is the main thing to look for.\nHave you seen this blog post?\n\n  \n      \n\n      weaviate.io – 4 Jun 24\n  \n\n  \n    \n\nStep-by-Step Guide to Choosing the Best Embedding Model for Your Application...\n\n  How to select an embedding model for your search and retrieval-augmented generation system.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLooks like you are in to some benchmarks, so it may be relevant here \nOther than that, unless there is something going wrong on the second batch import, it points to how the model vectorized your dataset \nLet me know if this helps\n\n----------\n\n[Frosslee (2024-07-30T07:35:44.809Z)]: Thank you for the blog post recommendation. I appreciate the resource on choosing embedding models.\nHowever, the issue I’m facing isn’t with selecting the embedding model itself. The problem lies in the console’s inability to preview the vectorizer, which results in significant discrepancies in the semantic search. The distances returned are quite poor, as shown in the images and code I provided. I’m uncertain if there’s a mistake in my implementation of the Bedrock code.\nCould you provide any guidance or insight on this?",
    "date_created": "2024-07-25T07:22:46.714Z",
    "has_accepted_answer": false,
    "title": "Help Needed: Issue with Vectorizers in Weaviate Collections Console",
    "topic_id": 3166
  },
  {
    "user_id": 531,
    "conversation": "[qnlbnsl (2024-01-16T19:34:35.721Z)]: Hello everyone!. I was trying out weaviate and wanted to implement a reverse proxy. Currently weaviate is hosted on docker that runs with traefik. I was able to connect to weaviate’s REST API without any issues. However, what i was unable to do is proxy the gRPC connection.\nHere is the error is see on my debugger:\nException has occurred: WeaviateQueryException\nQuery call failed with message Stream removed.\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Stream removed\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-01-14T21:04:14.775200504-05:00\", grpc_status:2, grpc_message:\"Stream removed\"}\"\n>\n\nDuring handling of the above exception, another exception occurred:\n\n  File \"/mnt/h/src/server/database/connect.py\", line 36, in <module>\n    response = questions.generate.near_text(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nweaviate.exceptions.WeaviateQueryException: Query call failed with message Stream removed.\n\nThe console had another error (most likely thrown right before the debugger caught the above error:\nE0114 21:04:14.765458535  185327 hpack_parser.cc:999]                  Error parsing 'content-type' metadata: invalid value\n\nTill now i have tried the following configurations with traefik.\n\nCreating a grpc endpoint and directly proxying it to port 50051. Did not work.\nCreating a H2C endpoint by following this example. Did not work\nCreating an https termination on port 443 and proxying it to port 50051. Did not work\n\nMy current docker compose(swarm stack) file is like so:\nversion: '3.8'\n\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:1.23.2\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    ports:\n      - \"8080:8080\"\n      - \"50051:50051\"\n    volumes:\n      - nfs:/var/lib/weaviate\n    networks:\n      - public\n    deploy:\n      replicas: 1\n      placement:\n        constraints: [node.role != manager]\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.weaviate.rule=Host(`weaviate.mydomain.com`)\"\n        - \"traefik.http.routers.weaviate.entrypoints=websecure\"\n        - \"traefik.http.routers.weaviate.tls=true\"\n        - \"traefik.http.routers.weaviate.tls.certresolver=ssl_resolver\"\n        - \"traefik.http.routers.weaviate.tls.domains[0].main=weaviate.mydomain.com\"\n        - \"traefik.http.routers.weaviate.service=weaviate\"\n        - \"traefik.http.services.weaviate.loadbalancer.server.port=8080\"\n        - \"traefik.http.routers.weaviategrpc.rule=Host(`grpc.weaviate.mydomain.com`)\"\n        - \"traefik.http.routers.weaviategrpc.entrypoints=web\"\n#        - \"traefik.http.routers.weaviategrpc.tls=true\"\n#        - \"traefik.http.routers.weaviategrpc.tls.certresolver=ssl_resolver\"\n        - \"traefik.http.routers.weaviategrpc.tls.domains[0].main=grpc.weaviate.mydomain.com\"\n        - \"traefik.http.routers.weaviategrpc.service=weaviate\"\n        - \"traefik.http.services.weaviategrpc.loadbalancer.server.port=50051\"\n        - \"traefik.http.services.weaviategrpc.loadbalancer.server.scheme=h2c\"\n\n    environment:\n      OPENAI_APIKEY: \"${OPENAI_APIKEY}\"\n      QUERY_DEFAULTS_LIMIT: \"${QUERY_DEFAULTS_LIMIT}\"\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: \"${AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED}\"\n      PERSISTENCE_DATA_PATH: \"${PERSISTENCE_DATA_PATH}\"\n      DEFAULT_VECTORIZER_MODULE: \"${DEFAULT_VECTORIZER_MODULE}\"\n      ENABLE_MODULES: \"${ENABLE_MODULES}\"\n      CLUSTER_HOSTNAME: \"${CLUSTER_HOSTNAME}\"\n      LOG_LEVEL: \"${LOG_LEVEL}\"\n\nvolumes:\n  nfs:\n    driver_opts:\n      type: \"nfs\"\n      o: \"addr=192.168.4.2,nfsvers=4,nolock,soft,rw\"\n      device: \":/mnt/pool/docker_swarm/weaviate\"\n\nnetworks:\n  public:\n    external: true\n\n\nNOTE: Local connections WORK as expected. This is a configuration issue.\n\n----------\n\n[DudaNogueira (2024-01-19T14:14:04.754Z)]: Hi! This is an interesting thing to have documented.\nI have created awareness internally, and will try to setup an environment next week.\nThanks!\n\n----------\n\n[DudaNogueira (2024-01-27T01:22:00.280Z)]: Hi @qnlbnsl ! Sorry for the delay here.\nLooks like I was finally able to tame this\nHere is what I got:\nNOTE: Check this updated gist on how to correctly expose Weaviate under SSL/TLS using Traefik and running everything with a docker compose\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:1.23.5\n    #ports:\n    # - 8081:8080 # unsafe http\n    # - 50052:50051 # unsafe grpc\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node1'\n    labels:\n      - \"traefik.enable=true\"\n      # http\n      - \"traefik.http.services.weaviate_http_service.loadbalancer.server.port=8080\"\n      - \"traefik.http.routers.weaviate_http_router.rule=Host(`weaviate.mydomain.com`)\"\n      - \"traefik.http.routers.weaviate_http_router.entrypoints=websecure\"\n      - \"traefik.http.routers.weaviate_http_router.service=weaviate_http_service\"\n      - \"traefik.http.routers.weaviate_http_router.tls.certresolver=myresolver\"\n      # grpc\n      - \"traefik.http.services.weaviate_grpc_service.loadbalancer.server.scheme=h2c\"\n      - \"traefik.http.services.weaviate_grpc_service.loadbalancer.server.port=50051\"\n      - \"traefik.http.routers.weaviate_grpc_router.rule=Host(`grpc.weaviate.mydomain.com`)\"\n      - \"traefik.http.routers.weaviate_grpc_router.entrypoints=grpc\"\n      - \"traefik.http.routers.weaviate_grpc_router.service=weaviate_grpc_service\"\n      - \"traefik.http.routers.weaviate_grpc_router.tls.certresolver=myresolver\"\n  \n  traefik:\n    image: \"traefik:v2.11\"\n    container_name: \"traefik\"\n    command:\n      - \"--log.level=DEBUG\"\n      - \"--providers.docker.exposedbydefault=false\"\n      - \"--entrypoints.web.address=:80\"\n      - \"--entrypoints.websecure.address=:443\"\n      - \"--entrypoints.web.http.redirections.entryPoint.to=websecure\"\n      - \"--entrypoints.web.http.redirections.entryPoint.scheme=https\"\n      - \"--entrypoints.grpc.address=:50051\"\n      - \"--providers.docker\"\n      - \"--api\"\n      # - \"--certificatesresolvers.myresolver.acme.caserver=https://acme-staging-v02.api.letsencrypt.org/directory\"\n      - \"--certificatesresolvers.myresolver.acme.tlschallenge=true\"\n      - \"--certificatesresolvers.myresolver.acme.httpchallenge.entrypoint=web\"\n      - \"--certificatesresolvers.myresolver.acme.email=your@mydomain.com\"\n      - \"--certificatesresolvers.myresolver.acme.storage=/letsencrypt/acme.json\"\n\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n      - \"50051:50051\"\n    volumes:\n      - \"./letsencrypt:/letsencrypt\"\n      - \"/var/run/docker.sock:/var/run/docker.sock:ro\"\n\nvolumes:\n  weaviate_data:\n...\n\nand her how you can test your connections:\n# it should be listening http in port 80, redirecting to 443\n❯ curl http://weaviate.mydomain.com/v1/nodes\nMoved Permanently%\n\n# -L will follow redirects\n❯ curl -L http://weaviate.mydomain.com/v1/nodes\n{\"nodes\":[{\"batchStats\":{\"queueLength\":0,\"ratePerSecond\":0},\"gitHash\":\"6aeae65\",\"name\":\"node1\",\"shards\":null,\"stats\":{\"objectCount\":0,\"shardCount\":0},\"status\":\"HEALTHY\",\"version\":\"1.23.5\"}]}\n\n# also directly in https:\n❯ curl https://weaviate. mydomain.com/v1/nodes\n{\"nodes\":[{\"batchStats\":{\"queueLength\":0,\"ratePerSecond\":0},\"gitHash\":\"6aeae65\",\"name\":\"node1\",\"shards\":null,\"stats\":{\"objectCount\":1,\"shardCount\":1},\"status\":\"HEALTHY\",\"version\":\"1.23.5\"}]}\n\n# lets test our grpc connection\n❯ wget https://raw.githubusercontent.com/grpc/grpc/master/src/proto/grpc/health/v1/health.proto\n❯ grpcurl -d '{\"service\": \"Weaviate\"}' -proto health.proto grpc.weaviate.mydomain.com:50051 grpc.health.v1.Health/Check\n{\n  \"status\": \"SERVING\"\n}\n\nLet me know if that helps\n\n----------\n\n[gdrajhasekarun (2024-08-10T03:04:03.693Z)]: I tried with the steps, But I’m getting following error\nFailed to dial target host “:50051”: context deadline exceeded\n\n----------\n\n[DudaNogueira (2024-08-12T21:27:54.016Z)]: This will indicate that the grpc is not exposed properly \nyou should be able to get that SERVING status.",
    "date_created": "2024-01-16T19:34:35.666Z",
    "has_accepted_answer": true,
    "title": "Weaviate with Traefik and gRPC",
    "topic_id": 1238
  },
  {
    "user_id": 1672,
    "conversation": "[Felix (2024-10-10T08:42:04.445Z)]: Hi everyone! Thanks for this amazing product. I’m currently testing it out, but I’m encountering a few issues.\nDescription\nWhen I attempt to batch import using dynamic batching, I encounter issues feeding the data into the vector database. I discovered this was due to a hardcoded gRPC buffer size. As a workaround, I switched to fixed batching, but it doesn’t seem to be optimized.\nAnother problem I’m facing is with vectorization. When I use the client method fetch_object_by_id(..., include_vector=...) , it returns an empty vector. This makes searching impossible as it results in inconsistent objects.\nAlso the score when i perform a near_text query is always 0.0:\nfrom weaviate.classes.query import Rerank, MetadataQuery\nresponse=pages_collection.query.near_text(\n    query=\"Sample Query\",\n    limit=3,\n    return_metadata=MetadataQuery(score=True,distance=True,certainty=True)\n)\n\n# Print first result\nresult = response.objects[0]\nprint(result)\n\n\nServer Setup Information\n\nWeaviate Server Version: 1.26.5\nDeployment Method: docker\nMulti Node? Number of Running Nodes:  1\nClient Language and Version: Python Client 4.8.1\nMultitenancy?: False\n\nAny additional Information\nHere are the collections I’ve created:\ndocuments=client.collections.create(\n        name=\"Documents\",    \n        properties=[\n            Property(name=\"description\",data_type=wvc.config.DataType.TEXT),\n        ],\n        vectorizer_config=Configure.Vectorizer.multi2vec_clip(\n                text_fields=[\n                    Multi2VecField(name=\"description\", weight=1.0)\n                ]\n                ),\n        vector_index_config=Configure.VectorIndex.dynamic(),\n        reranker_config=Configure.Reranker.transformers()\n    )\n    pages=client.collections.create(\n        name=\"Pages\",\n        properties=[\n            Property(name=\"identifier\",data_type=DataType.TEXT,index_searchable=False,index_filterable=False),\n            Property(name=\"description\",data_type=DataType.TEXT),\n            Property(name=\"page\",data_type=DataType.BLOB)\n        ],\n        references=[\n            ReferenceProperty(\n                name=\"belongsTo\",\n                target_collection=\"Documents\"\n            ),\n        ],\n        vectorizer_config=Configure.Vectorizer.multi2vec_clip(\n            text_fields=[\n                Multi2VecField(name=\"description\", weight=.5)\n            ],\n            image_fields=[Multi2VecField(name=\"page\", weight=.5)],\n        ),\n        vector_index_config=Configure.VectorIndex.dynamic(),\n        reranker_config=Configure.Reranker.transformers()\n        )\n    chunks=client.collections.create(\n        name=\"Chunks\",\n        properties=[\n            Property(name=\"identifier\",data_type=DataType.TEXT,index_searchable=False,index_filterable=False),\n            Property(name=\"description\",data_type=DataType.TEXT),\n            Property(name=\"chunk\",data_type=DataType.BLOB)\n            ],\n        references=[\n            ReferenceProperty(\n                name=\"belongsTo\",\n                target_collection=\"Pages\"\n            )\n        ],\n        vectorizer_config=Configure.Vectorizer.multi2vec_clip(\n            text_fields=[\n                Multi2VecField(name=\"description\", weight=.5)\n            ],\n            image_fields=[Multi2VecField(name=\"chunk\", weight=.5)]\n        ),\n        vector_index_config=Configure.VectorIndex.dynamic(),\n        reranker_config=Configure.Reranker.transformers()\n        )\n    pages=client.collections.get(\"Pages\")\n    pages.config.add_reference(ReferenceProperty(name=\"hasChunks\", target_collection=\"Chunks\"))\n\nExample of data import:\n    with pages_collection.batch.fixed_size(18,10) as batch:\n        for page in pages_row:\n            id=page.pop(\"uuid\")\n            batch.add_object(properties=page, uuid=id)\n        if batch.number_errors>0:\n            print(batch.failed_objects)\n\nRetrieve by id:\nimport weaviate\nfrom weaviate.classes.query import Rerank, MetadataQuery\nclient=weaviate.connect_to_local()\ntry:\n    pages_collection=client.collections.get(\"Pages\")\n    object=pages_collection.query.fetch_object_by_id(\n        uuid=\"04b62467-3693-5019-b46f-0e435d00273a\",\n        include_vector=\"pages_vector\"\n        )\n    print(f\"Vector \\'pages_vector\\' :{object.vector}\")\nfinally:\n    client.close()\n\n\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.5\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      CLIP_INFERENCE_API: 'http://multi2vec-clip:8080'\n      QNA_INFERENCE_API: 'http://qna-transformers:8080'\n      RERANKER_INFERENCE_API: 'http://reranker-transformers:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'multi2vec-clip'\n      ENABLE_MODULES: 'multi2vec-clip,qna-transformers,reranker-transformers'\n      CLUSTER_HOSTNAME: 'node1'\n      ASYNC_INDEXING: 'true'\n  multi2vec-clip:\n    image: semitechnologies/multi2vec-clip:sentence-transformers-clip-ViT-B-32-multilingual-v1\n    environment:\n      ENABLE_CUDA: '1'\n      NVIDIA_VISIBLE_DEVICES: 'all'\n    deploy:\n      resources:\n        reservations:\n          devices:\n          - driver: nvidia\n            count: 1\n            capabilities: [gpu]\n  qna-transformers:\n    image: semitechnologies/qna-transformers:distilbert-base-cased-distilled-squad\n    environment:\n      ENABLE_CUDA: '1'\n      NVIDIA_VISIBLE_DEVICES: 'all'                                                                                                                                                                                  deploy:\n      resources:\n        reservations:\n          devices: \n - driver: nvidia\n            count: 1\n            capabilities: [gpu]\n  reranker-transformers:\n    image: semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2\n    environment:\n      ENABLE_CUDA: '1'\n      NVIDIA_VISIBLE_DEVICES: 'all'\n    deploy:\n      resources:\n        reservations:\n          devices:\n          - driver: nvidia\n            count: 1\n            capabilities: [gpu]\nvolumes:\n  weaviate_data:\n\n----------\n\n[DudaNogueira (2024-10-11T20:56:53.683Z)]: hi @Felix !!\nWelcome to our community \nUnfortunately, there isn’t a one size fits all when it comes to batching. This is because there is a lot of variables here.\nThe dynamic batch will try it’s best to calculate the optimal batch size. It will take into consideration the latency between the client and the server.\nThis can work on some situations, but for example, when you are on a local environment, the latency can be too fast, and then you can overwhelm the server with a big batch size.\nWhile it works on most situation, a good approach is like you did: start small and find the sweet spot combination between batch size and number of workers.\nOther factos that will influentiate are the amount of resources you have allocated for your cluster, the size of your objects and of course, the throughput  of your vectorizer models.\nRegarding the score, and I have seen this confusion a lot, you need to understand that a similarity search will give you a distance, while a keyword search (bm25) will get you a score.\nHybrid will perform both a similarity search and a keyword search, so you end up with both score and distance, that Weaviate then fuses those two into normalized score. You can get each of those with the explain_score metadata.\nIn order to understand what can be going wrong with your code, can you provide a full reproducible example including at least some data? This really helps on reproducing the same behavior you are seeing, when we have a “end to end” example where we can also run. Usually a python notebook is the best way to share this kind of code.\nLet me know if this helps.\nAnd once again, welcome to our community",
    "date_created": "2024-10-10T08:42:04.389Z",
    "has_accepted_answer": false,
    "title": "Issues with Batch Import and Vectorization",
    "topic_id": 4575
  },
  {
    "user_id": 219,
    "conversation": "[JLiz2803 (2024-10-07T22:12:15.790Z)]: Description\nHi, I am trying to execute a vector query on my data.  I am troubleshooting why Weaviate will not return a certain record.  I have noticed that when I add a where filter of\n{“path”: [“name”], “operator”: “Like”, “valueText”: “*CONVEYOR*”}\nit will return the item with a certainty score of 0.9333723783493042.  However, when I remove the where filter weaviate will return records with a certainty scores as low as 0.92 but will not include the record I am looking for.  Why does filtering have this kind of impact?\nServer Setup Information\n\nWeaviate Server Version: 1.24.8\nDeployment Method: Deployed HELM Chart on AWS EKS\nMulti Node? Number of Running Nodes:  1\nClient Language and Version:\nMultitenancy?: Yes",
    "date_created": "2024-10-07T22:12:15.739Z",
    "has_accepted_answer": false,
    "title": "How do Where filters impact Certainty Score?",
    "topic_id": 4464
  },
  {
    "user_id": 1155,
    "conversation": "[pon_raj (2024-07-17T20:11:56.550Z)]: Hello,\nI am trying to use weaviate client inside the container. Is there a weaviate-client image that I can download?\nIf there isn’t one, could you please help me to create one using Dockerfile.\nThanks.\n\n----------\n\n[DudaNogueira (2024-07-17T20:43:00.976Z)]: hi! You can run this on any python container, if using python, for example.\nIt is just a python library.\nWhat have you tried so far?\n\n----------\n\n[pon_raj (2024-07-18T18:40:10.566Z)]: Hi,\nI wanted to create an image with weaviate client installed from base image alpine with python3.\n“RUN pip install -U weavite-client” in Dockerfile failed.\nAlso, alpine expects to use apk (Alpine Package Keeper).\nAfter several attempts, the below one worked.\nRUN python3 -m pip install weaviate-client --break-system-packages\nThanks.\n\n----------\n\n[DudaNogueira (2024-07-19T16:17:26.402Z)]: Awesome!! Thanks for sharing!",
    "date_created": "2024-07-17T20:11:56.504Z",
    "has_accepted_answer": true,
    "title": "How to use weaviate client as container?",
    "topic_id": 3077
  },
  {
    "user_id": 332,
    "conversation": "[chris_hoo (2023-09-27T03:54:05.152Z)]: I want to use Docker to deploy Weaviate on two machines,The starting command for Docker is：\nmy node1 machine docker run this ：\ndocker run -d -p 3081:8080 \n-p 7100:7100 \n-p 7101:7101 \n-v $PWD/data:/var/lib/weaviate \n–name weaviate \n–restart=always \n-e AUTHORIZATION_ADMINLIST_ENABLED=true \n-e AUTHORIZATION_ADMINLIST_USERS=admin \n-e AUTHENTICATION_APIKEY_ENABLED=true \n-e AUTHENTICATION_APIKEY_ALLOWED_KEYS=WVF5RgsX3tD5ngdN8pkiy \n-e AUTHENTICATION_APIKEY_USERS=admin \n-e PERSISTENCE_DATA_PATH=/var/lib/weaviate \n-e CLUSTER_HOSTNAME=node1 \n-e CLUSTER_GOSSIP_BIND_PORT=7100 \n-e CLUSTER_DATA_BIND_PORT=7101 \nsemitechnologies/weaviate\nnode2 machine docker run this:\ndocker run  --name weaviate \n-p 3081:8080 \n-p 7102:7102 \n-p 7103:7103 \n-v $PWD/data:/var/lib/weaviate \n-e AUTHORIZATION_ADMINLIST_ENABLED=true \n-e AUTHORIZATION_ADMINLIST_USERS=admin \n-e AUTHENTICATION_APIKEY_ENABLED=true \n-e AUTHENTICATION_APIKEY_ALLOWED_KEYS= WVF5RgsX3tD5ngdN8pkiy \n-e AUTHENTICATION_APIKEY_USERS=admin \n-e PERSISTENCE_DATA_PATH=/var/lib/weaviate \n-e CLUSTER_HOSTNAME=node2  \n-e CLUSTER_GOSSIP_BIND_PORT=7102 \n-e CLUSTER_DATA_BIND_PORT=7103 \n-e CLUSTER_JOIN=10.254.140.134:7100 \nsemitechnologies/weaviate\nNode 2 starts and reports the following error:\n{“action”:“startup”,“default_vectorizer_module”:“none”,“level”:“info”,“msg”:“the default vectorizer modules is set to \"none\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer”,“time”:“2023-09-27T03:53:44Z”}\n{“action”:“startup”,“auto_schema_enabled”:true,“level”:“info”,“msg”:“auto schema enabled setting is set to \"true\"”,“time”:“2023-09-27T03:53:44Z”}\n{“action”:“broadcast_abort_transaction”,“error”:“host \"172.17.0.2:7101\": send http request: Delete \"http://172.17.0.2:7101/schema/transactions/9ecd4dc0-ace9-439c-986f-e1945ddcc389\\”: dial tcp 172.17.0.2:7101: connect: connection refused\",“id”:“9ecd4dc0-ace9-439c-986f-e1945ddcc389”,“level”:“error”,“msg”:“broadcast tx abort failed”,“time”:“2023-09-27T03:53:44Z”}\n{“action”:“startup”,“error”:“could not load or initialize schema: sync schema with other nodes in the cluster: read schema: open transaction: broadcast open transaction: host \"172.17.0.2:7101\": send http request: Post \"http://172.17.0.2:7101/schema/transactions/\\”: dial tcp 172.17.0.2:7101: connect: connection refused\",“level”:“fatal”,“msg”:“could not initialize schema manager”,“time”:“2023-09-27T03:53:44Z”}\n\n----------\n\n[DudaNogueira (2023-09-27T12:33:01.028Z)]: Hi @chris_hoo !\nI believe the problem is that those two containers might not be able to consistently communicate with each other.\nwhile using docker, you should avoid using IPs, as those are subject to be changed.\nI believe you have seen this post (saw you comment there):\n  \n    \n    \n    Can only Docker Compose be used for multi node deployment? Support\n  \n  \n    Hi @codehelen ! Welcome to our community  \nThis must be some networking issue along the way, as your docker is correct (see below) \nA starting point is making sure that weaviate-node2-IP can communicate with weaviate-node1-IP on all specified ports. \nA good example on how to run with ad-hoc containers (at the same docker host): \nFirst, create a docker attachable network\ndocker network create weaviate --atachable\n\nnote that weaviate, above, can be whatever network name you want. Mak…\n  \n\n\nWhere you able to use it?\n\n----------\n\n[DudaNogueira (2023-09-27T12:33:34.219Z)]: Ah! And welcome to our community\n\n----------\n\n[jasper2077 (2024-12-02T01:31:18.415Z)]: Hello, I’m currently facing the same issue. Have you figured out how to solve the error?",
    "date_created": "2023-09-27T03:54:05.102Z",
    "has_accepted_answer": false,
    "title": "How to deploy to two machines？",
    "topic_id": 743
  },
  {
    "user_id": 1291,
    "conversation": "[Taylor_Hickman (2024-08-08T16:36:38.481Z)]: Description\nIs there a way to set the api version for v4 Azure OpenAI vectorizer? I tried\npassing the OPENAI_API_VERSION but Weaviate seems to default to:\n/embeddings?api-version=2024-02-01\n…but our instance of Azure OpenAI uses 2023-05-15\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method: Docker\nMulti Node? Number of Running Nodes: Single\nClient Language and Version: Python weaviate_client-4.7.1\nMultitenancy?:\n\nAny additional Information\n\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:latest\n    ports:\n      - 8080:8080\n      - 50051:50051\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      AZURE_APIKEY: ${AZURE_OPENAI_API_KEY}\n      OPENAI_API_TYPE: 'azure'\n      ENABLE_MODULES: 'text2vec-azure-openai, text2vec-openai'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      OPENAI_API_VERSION: ${AZURE_OPENAI_API_VERSION}\n      AZURE_ENDPOINT: ${AZURE_OPENAI_ENDPOINT}\n      AZURE_OPENAI_BASE_URL: ${AZURE_OPENAI_BASE_URL}\n      AZURE_OPENAI_RESOURCE_NAME: ${AZURE_OPENAI_RESOURCE_NAME}\n      AZURE_OPENAI_API_VERSION: ${AZURE_OPENAI_API_VERSION}\n      AZURE_OPENAI_EMBEDDING_DEPLOYMENT: ${AZURE_OPENAI_EMBEDDING_DEPLOYMENT}\n      CLUSTER_HOSTNAME: 'node1'\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n      \n\n\nclass WeaviateStore:\n    def __init__(self, settings: Settings):\n        self.settings = settings\n        self.client: weaviate.WeaviateAsyncClient = None\n        self.class_name = settings.WEAVIATE_CLASS_NAME\n\n    async def initialize(self):\n        if self.client is None:\n            connection_params = ConnectionParams.from_params(\n                http_host=self.settings.WEAVIATE_HOST,\n                http_port=self.settings.WEAVIATE_PORT,\n                http_secure=False,\n                grpc_host=self.settings.WEAVIATE_HOST,\n                grpc_port=self.settings.WEAVIATE_GRPC_PORT,\n                grpc_secure=False,\n            )\n\n            self.client = weaviate.WeaviateAsyncClient(\n                connection_params=connection_params,\n                additional_headers={\n                    \"X-Azure-Api-Key\": self.settings.AZURE_OPENAI_API_KEY,\n                },\n            )\n            \n            await self.client.connect()\n            await self._create_or_update_schema()\n\n    async def _create_or_update_schema(self):\n        try:\n            collection = self.client.collections.get(self.class_name)\n            logger.info(f\"Collection '{self.class_name}' already exists. Updating configuration.\")\n            await self.client.collections.delete(self.class_name)\n        except UnexpectedStatusCodeError as e:\n            if e.status_code != 404:\n                logger.error(f\"Unexpected error when checking for existing collection: {str(e)}\")\n                raise\n        try:\n            properties = [\n                Property(name=\"content\", data_type=DataType.TEXT),\n                Property(name=\"metadata\", data_type=DataType.OBJECT, nested_properties=[\n                    Property(name=\"source\", data_type=DataType.TEXT),\n                    Property(name=\"document_type\", data_type=DataType.TEXT),\n                    Property(name=\"npi\", data_type=DataType.TEXT),\n                ]),\n                Property(name=\"npi\", data_type=DataType.TEXT),\n            ]\n\n            vectorizer_config = Configure.Vectorizer.text2vec_azure_openai(\n                resource_name=self.settings.AZURE_OPENAI_RESOURCE_NAME,\n                deployment_id=self.settings.AZURE_OPENAI_EMBEDDING_DEPLOYMENT,\n                base_url=self.settings.AZURE_OPENAI_ENDPOINT\n            )\n\n            logger.info(f\"Creating new collection '{self.class_name}'\")\n            await self.client.collections.create(\n                name=self.class_name,\n                properties=properties,\n                vectorizer_config=vectorizer_config\n            )\n            logger.info(f\"Successfully created collection '{self.class_name}'\")\n\n        except UnexpectedStatusCodeError as e:\n            logger.error(f\"Failed to create collection: {str(e)}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error during schema creation/update: {str(e)}\", exc_info=True)\n            raise\n\n----------\n\n[DudaNogueira (2024-08-08T21:22:40.213Z)]: hi @Taylor_Hickman !!\nI believe we have found an undocumented feature \napiVersion\nI am not sure you can pass apiVersion at query time.  I will have to ask internally as I couldn’t figure out from the PR:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n\n\n\n    \n      \n    \n\n  \n\n\n\n      \n        Fix api version support in text2vec-openai module\n      \n\n    \n      weaviate:stable/v1.24 ← weaviate:fix-api-version-support-in-text2vec-openai-module\n    \n\n      \n        \n          opened 12:50PM - 05 Apr 24 UTC\n        \n\n        \n          \n            \n            antas-marcin\n          \n        \n\n        \n          \n            +90\n            -28\n          \n        \n      \n  \n\n\n  \n    ### What's being changed:\n\nThis PR adds `apiVersion` support to `text2vec-open…ai` module.\n\nIt sets the default `apiVersion` to `2024-02-01` both in `text2vec-openai` and `generative-openai` modules.\n\n### Review checklist\n\n- [ ] Documentation has been updated, if necessary. Link to changed documentation:\n- [ ] Chaos pipeline run or not necessary. Link to pipeline:\n- [ ] All new code is covered by tests where it is reasonable.\n- [ ] Performance tests have been run or not necessary.\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYou can also change the baseUrl at query time, as documented here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\ntext2vec-openai | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI have also found some related forum threads:\n  \n    \n    \n    Weaviate Post still using api-version=2022-12-01 even though the version has been retired Support\n  \n  \n    Hello. \nI am quite new to using weaviate but have enjoyed it well. \nYesterday all of my embedding queries stopped working for my application as weaviate continues to try to connect to https://{resource}.openai.azure.com/openai/deployments/{deployment-id}/embeddings?api-version=2022-12-01. \nAs of my understanding since yesterday 2.4.2024 that version has been retired. \nI read here that weaviate should try another version automatically. But clearly it does not so for me as it still uses 2022-12-01…\n  \n\n\n\n  \n    \n    \n    Api version in Query-time parameters? Support\n  \n  \n    Yes, I added those to the collection definition and those worked for vectorizing our documents. but what about when I want to deploy the application and we are using a different base_url when deployed? \nSo if i want to vector search with “nearText” using a different base_url. Thas base_url should be added in the headers like “X-OpenAI-BaseURL”: {baseUrl} since I am making REST Api calls\n  \n\n\nLet me know if this helps!\n\n----------\n\n[DudaNogueira (2024-08-09T18:27:57.318Z)]: Hi!\nYou cannot pass the apiVersion on query time \nOur team is looking into this.\nbut right now, you will need to set the apiversion while creating a collection.",
    "date_created": "2024-08-08T16:36:38.433Z",
    "has_accepted_answer": false,
    "title": "Python V4 - Set api version for Azure OpenAI vectorizer?",
    "topic_id": 3306
  },
  {
    "user_id": 2427,
    "conversation": "[Kieran_Sears (2024-10-31T14:14:03.854Z)]: Description\nRunning windows subsystem for linux (WSL2) with docker desktop running the containerization show from windows. I have ollama started with a model, works just fine when testing it with ollama run llama3.1.\nI cook it up with:\ndocker run -d --gpus=all --name ollama --restart always -v ollama:/root/.ollama --add-host=host.docker.internal:host-gateway -p 11434:11434 ollama/ollama:0.3.10\n\nmy docker compose has env vars set to look at my .env file:\nOLLAMA_URL=http://host.docker.internal:11434/\nOLLAMA_MODEL=llama3.1:latest\nOLLAMA_EMBED_MODEL=llama3.1\n\nThis works as expected, as I can start up Verba on port 8000 and select docker deployment in the UI. The “Chat” tab page has “0 documents embedded by llama3.1:latest” so it’s definitely connecting and reading the right model, else this would show a connection error.\nBut going onto the “Import Data” tab and trying to add and import a simple txt file containing “Why is the sky blue”, throws up:\n✘ No documents imported 0 of 1 succesful tasks\nℹ FileStatus.ERROR | why_oh_why.txt | Import for why_oh_why.txt failed:\nImport for why_oh_why.txt failed: Batch vectorization failed: Vectorization\nfailed for some batches: 404, message='Not Found',\nurl=URL('http://host.docker.internal:11434/api/embed') | 0\n\nI even tried adding ollama to the same network as docker compose (docker network connect verba_default ollama) and got to the same point, but with “http://ollama:11434/api/embed” failing in the same way.\nI jumped into the code to start debugging the OllamaEmbedder:\n    async def vectorize(self, config: dict, content: list[str]) -> list[float]:\n\n        model = config.get(\"Model\").value\n\n        data = {\"model\": model, \"input\": content}\n        \n        async def on_request_end(session, trace_config_ctx, params):\n            print(f\"Ending request:\\n   method: {params.method}\\n   url: {params.url}\\n   headers: {params.headers}\")\n\n        trace_config = aiohttp.TraceConfig()\n        trace_config.on_request_end.append(on_request_end)\n\n        async with aiohttp.ClientSession(trace_configs=[trace_config]) as session:\n            async with session.post(self.url + \"/api/embed\", json=data) as response:\n                response.raise_for_status()\n                data = await response.json()\n                embeddings = data.get(\"embeddings\", [])\n                return embeddings\n\nAnd I was confused as can be on the printout changing the Method to GET:\nEnding request:\n   method: GET\n   url: http://host.docker.internal:11434/api/embed\n   headers: <CIMultiDict()>\n\nBut maybe that’s down to my poor understanding of Python and these async libraries / middleware changing things as it goes through?\nEither way when I use curl from the verba-verba-1 container I’m able to get the embeddings just fine:\ncurl http://host.docker.internal:11434/api/embed -d '{\"model\": \"llama3.1\",\"input\": \"Why is the sky blue?\"}'\n\nSo, now I’m at a loss on what else to try. Any ideas?\nServer Setup Information\n\nVera commit: 59a46d06e382dc88cc90d9d217e7c5a2a8f950dc\nDeployment Method: local docker compose\nOS: Windows + WSL2\n\n----------\n\n[DudaNogueira (2024-10-31T20:00:26.936Z)]: hi @Kieran_Sears !!\nWelcome to our community \nI was just playing around with Verba + Ollama all in docker \nI am not sure exactly how WSL2 plays with windows + docker, but can you try running everything in docker?\nOne thing to note: Whenever you start Verba, your ollama must have the models available, otherwise they will not be listed in Verba. Verba will connect to Ollama at startup and read all available models.\nHere is how I am doing:\nfirst, create a docker-compose.yaml file like this:\n---\n\nservices:\n  verba:\n    image: semitechnologies/verba\n    ports:\n      - 8000:8000\n    environment:\n      - WEAVIATE_URL_VERBA=http://weaviate:8080\n      - OLLAMA_URL=http://ollama:11434\n      - OLLAMA_MODEL=llama3.2\n      - OLLAMA_EMBED_MODEL=llama3.2\n\n    volumes:\n      - ./data:/data/\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8000 || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: semitechnologies/weaviate:1.25.10\n    ports:\n      - 8080:8080\n      - 3000:8080\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n    environment:\n      OPENAI_APIKEY: $OPENAI_API_KEY\n      COHERE_APIKEY: $COHERE_API_KEY\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'e'\n      CLUSTER_HOSTNAME: 'node1'\n\n  ollama:\n    image: ollama/ollama:0.3.14\n    volumes:\n      - ollama_data:/root/.ollama\n    ports:\n      - 11434:11434\n      \nvolumes:\n  weaviate_data: {}\n  ollama_data: {}\n...\n\n\nNow, let’s make sure we have the model we selected (in this case, llama3.2) available:\ndocker compose exec -ti ollama ollama pull llama3.2\n\nYou can check if the model is listed here:\nhttp://localhost:11434/api/tags\nok, now we can start everything up:\ndocker compose up -d\n\nNow proceed to import a document at verba, that should be running at:\nhttp://localhost:8000/\nA little after the import start, you should see  ollama eating up resources:\nimage2114×308 30.5 KB\nObs: llama was quite slow to vectorize   and while doing with large documents, it was crashing \nLet me know if this helps!\nTHanks!\n\n----------\n\n[DudaNogueira (2024-10-31T20:05:02.710Z)]: So now, for example, if you want to add a new model, you should:\nFor example, adding nomic-embed-text:\ndocker compose exec -ti ollama ollama pull nomic-embed-text\n\ndocker compose restart verba\n\nYou should now see both models listed in Verba\n\n----------\n\n[DudaNogueira (2024-10-31T20:15:27.012Z)]: Ps: While vectorizing large documents, I have faced this error:\n\n  \n\n      github.com/ollama/ollama\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Failed to acquire semaphore\" error=\"context canceled\" \n    \n\n    \n      \n        opened 02:16AM - 12 Jun 24 UTC\n      \n\n        \n          closed 04:35PM - 07 Aug 24 UTC\n        \n\n      \n        \n          \n          travisgu\n        \n      \n    \n\n    \n        \n          bug\n        \n        \n          needs more info\n        \n    \n  \n\n\n  \n    ### What is the issue?\n\nI am using embedding with AnythingLLM for RAG. I found… the embedding service always failed for several minutes calls. The error log is showing this every time. I am not sure why the context was cancelled. Please kindly help.\n\nBelow is the debug log:\n```\n[GIN] 2024/06/11 - 11:09:07 | 200 |         2m28s |   10.100.34.236 | POST     \"/api/embeddings\"\ntime=2024-06-11T11:09:07.830+08:00 level=DEBUG source=sched.go:304 msg=\"context for request finished\"\ntime=2024-06-11T11:09:07.830+08:00 level=DEBUG source=sched.go:255 msg=\"after processing request finished event\" modelPath=C:\\Users\\admin_env\\.ollama\\models\\blobs\\sha256-ada9f88e89df0ea53c31fabf8b1e7c8c0c22fa95ab3a3cad4cdd86103ce9f3d3 refCount=119\nDEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=14500 tid=\"17876\" timestamp=1718075347\nDEBUG [update_slots] slot released | n_cache_tokens=52 n_ctx=2048 n_past=52 n_system_tokens=0 slot_id=0 task_id=14500 tid=\"17876\" timestamp=1718075350 truncated=false\nDEBUG [log_server_request] request | method=\"POST\" params={} path=\"/embedding\" remote_addr=\"127.0.0.1\" remote_port=51069 status=200 tid=\"16400\" timestamp=1718075350\nDEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=14503 tid=\"17876\" timestamp=1718075350\nDEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=14504 tid=\"17876\" timestamp=1718075350\n[GIN] 2024/06/11 - 11:09:10 | 200 |         2m30s |   10.100.34.236 | POST     \"/api/embeddings\"\ntime=2024-06-11T11:09:10.289+08:00 level=DEBUG source=sched.go:304 msg=\"context for request finished\"\ntime=2024-06-11T11:09:10.290+08:00 level=DEBUG source=sched.go:255 msg=\"after processing request finished event\" modelPath=C:\\Users\\admin_env\\.ollama\\models\\blobs\\sha256-ada9f88e89df0ea53c31fabf8b1e7c8c0c22fa95ab3a3cad4cdd86103ce9f3d3 refCount=118\nDEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=14504 tid=\"17876\" timestamp=1718075350\ntime=2024-06-11T11:09:11.910+08:00 level=ERROR source=server.go:836 msg=\"Failed to acquire semaphore\" error=\"context canceled\"\ntime=2024-06-11T11:09:11.910+08:00 level=DEBUG source=sched.go:304 msg=\"context for request finished\"\ntime=2024-06-11T11:09:11.911+08:00 level=INFO source=routes.go:401 msg=\"embedding generation failed: context canceled\"\ntime=2024-06-11T11:09:11.911+08:00 level=DEBUG source=sched.go:255 msg=\"after processing request finished event\" modelPath=C:\\Users\\admin_env\\.ollama\\models\\blobs\\sha256-ada9f88e89df0ea53c31fabf8b1e7c8c0c22fa95ab3a3cad4cdd86103ce9f3d3 refCount=117\n[GIN] 2024/06/11 - 11:09:11 | 500 |         2m32s |   10.100.34.236 | POST     \"/api/embeddings\"\ntime=2024-06-11T11:09:11.911+08:00 level=ERROR source=server.go:836 msg=\"Failed to acquire semaphore\" error=\"context canceled\"\ntime=2024-06-11T11:09:11.911+08:00 level=DEBUG source=sched.go:304 msg=\"context for request finished\"\ntime=2024-06-11T11:09:11.911+08:00 level=INFO source=routes.go:401 msg=\"embedding generation failed: context canceled\"\ntime=2024-06-11T11:09:11.911+08:00 level=ERROR source=server.go:836 msg=\"Failed to acquire semaphore\" error=\"context canceled\"\n[GIN] 2024/06/11 - 11:09:11 | 500 |         2m32s |   10.100.34.236 | POST     \"/api/embeddings\"\ntime=2024-06-11T11:09:11.911+08:00 level=DEBUG source=sched.go:304 msg=\"context for request finished\"\ntime=2024-06-11T11:09:11.911+08:00 level=DEBUG source=sched.go:255 msg=\"after processing request finished event\" modelPath=C:\\Users\\admin_env\\.ollama\\models\\blobs\\sha256-ada9f88e89df0ea53c31fabf8b1e7c8c0c22fa95ab3a3cad4cdd86103ce9f3d3 refCount=116\ntime=2024-06-11T11:09:11.911+08:00 level=DEBUG source=sched.go:255 msg=\"after processing request finished event\" modelPath=C:\\Users\\admin_env\\.ollama\\models\\blobs\\sha256-ada9f88e89df0ea53c31fabf8b1e7c8c0c22fa95ab3a3cad4cdd86103ce9f3d3 refCount=115\ntime=2024-06-11T11:09:11.911+08:00 level=INFO source=routes.go:401 msg=\"embedding generation failed: context canceled\"\n```\n \n\n### OS\n\nWindows\n\n### GPU\n\nNvidia\n\n### CPU\n\nIntel\n\n### Ollama version\n\n0.1.41\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWhich I believe may be some docker env variable that need to be set.\n\n----------\n\n[Kieran_Sears (2024-11-02T21:48:54.992Z)]: Hey @DudaNogueira , thanks for the warm welcome!\nI found my issue, and it’s painfully straight forward.\nI was running it all within docker, I just had verba and weaviate on my docker compose, but the ollama image running independently in it’s own container rather than in the same docker compose file. As I say, this can be done by ensuring the ollama container is put onto the same network as verba. My ollama does have a model in it (Llama3.1), which I’ve yet to benchmark but seems to run slick considering I set it up with GPU acceleration (see docker image for details on how), I’ll test it with larger files now I’ve gotten it working. Lord knows if the embedding works as expected, but considering it’s producing content I can’t see why it wouldn’t.\nThe solution\nBut the issue was having a trailing forward slash at the end of my OLLAMA_URL environment variable. I did think it was strange my curl command could hit my endpoint but the service couldn’t? So, after removing it:\n- OLLAMA_URL=http://host.docker.internal:11434/\n+ OLLAMA_URL=http://host.docker.internal:11434\n\nI had my issue disappear, with even the logs giving the expected POST method:\nEnding request:\n   method: POST\n   url: http://host.docker.internal:11434/api/embed\n   headers: <CIMultiDict()>\n\nWhich to me is still quite infuriating that it changed the method just because the resource wasn’t found? If someone can point to the part where it’s written in the standard that this should happen, then please add it as a reply on here!\nThank you kindly for your prompt reply by the way! If you wanted to have more of a play around you could find out about how to set up the ollama image in docker compose with the GPU acceleration, that would absolutely speed things up as it’s practically instantaneous on my machine that runs a NVIDIA GFORCE RTX 3070.\nI’m quite new to contributing to open source, but I’d like to prevent anyone else from making such a rookie error that was difficult to debug. Should I open a PR that:\n\nupdates the readme with a note to say avoid tailing slashes.\nupdate the config to validate env var URLs and improve error handling so logs show when something is amiss.\nupdate the config to just strip any tailing slashes automagically.\n\nWould like to know your thoughts?\nKind regards!\n\n----------\n\n[DudaNogueira (2024-11-04T12:38:26.095Z)]: Ohhhhh. \nI believe we can improve this in Verba, properly joining the url paths here:\n\n  \n\n      github.com\n  \n\n  \n    weaviate/Verba/blob/59a46d06e382dc88cc90d9d217e7c5a2a8f950dc/goldenverba/components/embedding/OllamaEmbedder.py#L16\n\n\n\n    \n      \n          from goldenverba.components.interfaces import Embedding\n          from goldenverba.components.types import InputConfig\n          from goldenverba.components.util import get_environment\n          \n          \n          class OllamaEmbedder(Embedding):\n          \n              def __init__(self):\n                  super().__init__()\n                  self.name = \"Ollama\"\n                  self.url = os.getenv(\"OLLAMA_URL\", \"http://localhost:11434\")\n                  self.description = f\"Vectorizes documents and queries using Ollama. If your Ollama instance is not running on {self.url}, you can change the URL by setting the OLLAMA_URL environment variable.\"\n                  models = get_models(self.url)\n          \n                  self.config = {\n                      \"Model\": InputConfig(\n                          type=\"dropdown\",\n                          value=models[0],\n                          description=f\"Select a installed Ollama model from {self.url}. You can change the URL by setting the OLLAMA_URL environment variable. \",\n                          values=models,\n                      ),\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nand here\n\n  \n\n      github.com\n  \n\n  \n    weaviate/Verba/blob/59a46d06e382dc88cc90d9d217e7c5a2a8f950dc/goldenverba/components/generation/OllamaGenerator.py#L38\n\n\n\n    \n      \n              )\n          \n          async def generate_stream(\n              self,\n              config: Dict,\n              query: str,\n              context: str,\n              conversation: List[Dict] = [],\n          ) -> AsyncGenerator[Dict, None]:\n              model = config.get(\"Model\").value\n              url = f\"{self.url}/api/chat\"\n              system_message = config.get(\"System Message\").value\n          \n              if not self.url:\n                  yield self._error_response(\"Missing Ollama URL\")\n                  return\n          \n              messages = self._prepare_messages(query, context, conversation, system_message)\n              data = {\"model\": model, \"messages\": messages}\n          \n              try:\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nPlease, feel free to open an issue so we can tackle this.  We are always open to contributions, specially those that improve DX.\nThis could prevent this issue:\nfrom urllib.parse import urljoin\nbase_url = \"https://example.com/\"\nrelative_path = \"/api/v1/users\"\njoined_url = urljoin(base_url, relative_path)\n\nThere are other models that can also suffer from this issue.\nAs I use a mac, I only run models on CPU. \nI will eventually get my hands on a proper GPU to play around with with some load \nIf you are opening this issue, make sure to link to this thread for context!\nThanks!",
    "date_created": "2024-10-31T14:14:03.795Z",
    "has_accepted_answer": true,
    "title": "Vectorization failed 404 http://host.docker.internal:11434/api/embed",
    "topic_id": 7363
  },
  {
    "user_id": 1239,
    "conversation": "[hanumanhuda (2024-08-27T10:54:49.945Z)]: Description\nDimensions: 1536 and number of objects: 500k\nWe are observing high latency 490ms(p50),640ms(p90), 1.4s(p99) for throughput 32 RPS, Pod have enough CPU and memory available during the test however it is not utilizing fully. These results are not even close to benchmarks performed by Weaviate. Any suggestions to reduce the latency?\nServer Setup Information\n\nWeaviate Server Version: 1.22.8\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: single node\nClient Language and Version: python v3\nMultitenancy?: No\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-08-27T13:16:20.202Z)]: hi @hanumanhuda !!\nCurious, is there a reason to use 1.22.8?\nHave you tried latest 1.26? There is A LOT of changes that may fix something that may be causing this.\nHave you used our oficial helm chart?\nAre there any limits in place for this cluster at k8s?\nHave you changed any environment variables regarding resource planning?\nThanks!\n\n----------\n\n[hanumanhuda (2024-08-29T07:39:46.923Z)]: No, we haven’t used the helm chart for above tests, however we can try that with latest version 1.26. We haven’t changed any environment variable and going with default configuration, is there any specific recommendation for this use-case to make it faster?\n\n----------\n\n[Mohamed_Shahin (2024-08-29T11:39:03.390Z)]: Hi @hanumanhuda,\nBuilding on @DudaNogueira’s recommendation, I wanted to share some insights that could help improve your setup:\n\nRunning multiple nodes can lead to noticeable improvements. This approach improve the query as distribution across multiple nodes.\nWith a cluster setup (minimum 3 nodes), you’ll be able to set a replication factor of 3. The default consistency level for this is Quorum, which should work well for most cases.\n\n\nTo boost performance, you can set the consistency level to ONE for queries. While this trades some consistency for speed, Weaviate handles background consistency for you with repairs, so you don’t need to worry.\n\nHere is detailed technical explanations:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nReplication Architecture | Weaviate\n\n  Weaviate can automatically replicate data across nodes in the background in a cluster with multiple server nodes. This enables a variety of use cases. For example, if a node goes down, another node can shoulder the load without loss of availability...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet us know if you have any other questions or if there’s anything else we can help with!\n\n----------\n\n[DudaNogueira (2024-08-29T18:48:43.496Z)]: hi @hanumanhuda !\nGive enough resources, 500k objects will run lightning fast.\nIn order to get better latencies, as mentioned by my friend and colleague Mohamad, using newer versions than the one you are using is important as it leverages GRPC.\nThe version you are using will only expose REST/HTTP endpoints. GRPC will help it here tremendously, as it is way faster.\non top of that, there are a lot of other improvements.\nHere you find more information on GRPC:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\ngRPC | Weaviate\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAnd here you can have all information needed to run Weaviate using our oficial helm chart:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nKubernetes | Weaviate\n\n  For a tutorial on how to use minikube to deploy Weaviate on Kubernetes, see the Weaviate Academy course, Weaviate on Kubernetes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThe best way to migrate here, considering you have not used our helm in the first place, is to spin up a new Weaviate cluster using that helm, and migration your data over using this migration guide:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\n\n----------\n\n[hanumanhuda (2024-09-04T07:49:50.539Z)]: We tested the latest version 1.26.1 with 3 shards on a collection containing 500k objects, using the default settings for GOMEMLIMIT and GOMAXPROCS. The results were as follows:\n\nLatency for 32 RPS:\n\nP50: 300 ms\nP90: 490 ms\nP99: 740 ms\n\n\nLatency for 2 RPS:\n\nP50: 76 ms\nP90: 87 ms\nP99: 92 ms\n\n\n\nWe haven’t enabled replication since our primary goal is to reduce latency, not just increase availability. Although we are currently working with 500k objects, our target is to scale a single collection to 5 million objects.\nOne key observation during these tests was that none of the nodes fully utilized the available compute resources. As RPS increased, latency also increased, even though there was ample memory and compute available across the nodes. This raises the question: Is there a bottleneck preventing the utilization of compute resources across multiple queries?\n\n----------\n\n[DudaNogueira (2024-09-05T13:28:13.413Z)]: hi @hanumanhuda !\nI believe you should try tweaking those parameters according to your deployment.\nAlso, consider that replication will also give you better room for higher QPS: Use Cases (Motivation) | Weaviate\nOther index configs you can tune for better QPS are ef, efConstruction and maxConnections. More on those options here: Vector indexes | Weaviate\nLet me know if this helps.\nThanks!\n\n----------\n\n[hanumanhuda (2024-09-12T12:41:35.161Z)]: We have tried with replication factor 2 and consistency level 1 during the read, however response time is quite higher than replication factor 1 setup, which was surprising for us.  It was using memory 2 times however compute remained same.\n\n----------\n\n[hanumanhuda (2024-09-25T09:09:40.420Z)]: Any further update on this?\n\n----------\n\n[DudaNogueira (2024-09-25T11:03:58.333Z)]: Did you get the same results with replication factor 3?\n\n----------\n\n[hanumanhuda (2024-09-25T18:24:06.880Z)]: No, we didn’t do it for RF 3 If it is not improving with 2 replicas then it didn’t make sense for us to go for 3 replicas. We have used the consistency level as one with 2 replicas.\nWe are seeing interesting aspects on memory usage for 1.5M chunks(D:1536), and it is using 28 GB during queries otherwise 15GB. As per calculations it would be using at max 12GB.\n\n----------\n\n[hanumanhuda (2024-09-25T18:26:37.758Z)]: Also is there guideline how many shards should be used  to get best performance based on number of chunks?\n\n----------\n\n[Dirk (2024-09-26T05:52:27.973Z)]: Hey,\nI saw that you were starting with 1.22.6+python v3 - did you update to python v4 when you updated the weaviate version?\n\n----------\n\n[hanumanhuda (2024-10-01T13:40:24.192Z)]: yes, we did try with V4 client(GRPC), dense queries latency has improved by 40%, however sparse queries has worsen the performance by 40% for P99. This was surprise for us as we have changed client with V4 from v3 and enabled GRPC on server. Is this expected for V4 clients?",
    "date_created": "2024-08-27T10:54:49.897Z",
    "has_accepted_answer": false,
    "title": "High Query latency in Weaviate",
    "topic_id": 3686
  },
  {
    "user_id": 1293,
    "conversation": "[MartinMin (2024-08-08T17:14:21.155Z)]: weaviate-client==4.7.1\nlangchain-weaviate==0.0.2\nlangchain==0.2.11\nI am able to create a simple example to create a ‘db’ and use that db to do inference in one flow:\nfrom bge import bge_m3_embedding\n\nprint(f'Read in text ...')\nloader = TextLoader('state_of_the_union.txt')\ndocuments = loader.load()\n\nprint('Split text ...')\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)\n\nprint('Load embedding model ...')\nembedding_model = bge_m3_embedding\nprint('Embed docs ...')\nweaviate_client = weaviate.connect_to_local()\ndb = WeaviateVectorStore.from_documents(docs, embedding_model, client=weaviate_client, index_name='test')\n\n#db = WeaviateVectorStore.from_documents([], embedding_model, client=weaviate_client, index_name='test')\n# print('Perform search ...')\nquery = 'What did the president say about Ketanji Brown Jackson'\nresults = db.similarity_search_with_score(query, alpha=1)\nfor i, doc in enumerate(results):\n    print(f'{i}--->{doc[1]:.3f}')\nprint(results[0])\n#\nweaviate_client.close()\n\nThis works all fine. The db is created and similar docs are retrieved. However, now if I wan to use this ‘db’ to run the same query, I got an outofindex error:\nprint('Load embedding model ...')\nembedding_model = bge_m3_embedding\nprint('Load embedded docs ...')\nweaviate_client = weaviate.connect_to_local()\n\ndb = WeaviateVectorStore.from_documents([], embedding_model, client=weaviate_client, index_name='test')\n# print('Perform search ...')\nquery = 'What did the president say about Ketanji Brown Jackson'\nresults = db.similarity_search_with_score(query, alpha=1)\nfor i, doc in enumerate(results):\n    print(f'{i}--->{doc[1]:.3f}')\nprint(results[0])\n\nAnd the error message is below:\nTraceback (most recent call last):\n  File \"/Users/I747411/ai/lc_weaviate.py\", line 22, in <module>\n    db = WeaviateVectorStore.from_documents([], embedding_model, client=weaviate_client, index_name='test')\n  File \"/Users/I747411/ai/venv/lib/python3.10/site-packages/langchain_core/vectorstores/base.py\", line 1058, in from_documents\n    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n  File \"/Users/I747411/ai/venv/lib/python3.10/site-packages/langchain_weaviate/vectorstores.py\", line 487, in from_texts\n    weaviate_vector_store.add_texts(texts, metadatas, tenant=tenant, **kwargs)\n  File \"/Users/I747411/ai/venv/lib/python3.10/site-packages/langchain_weaviate/vectorstores.py\", line 165, in add_texts\n    embeddings = self._embedding.embed_documents(list(texts))\n  File \"/Users/I747411/ai/venv/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py\", line 331, in embed_documents\n    embeddings = self.client.encode(\n  File \"/Users/I747411/ai/venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 565, in encode\n    if all_embeddings[0].dtype == torch.bfloat16:\nIndexError: list index out of range\n/Users/I747411/ai/venv/lib/python3.10/site-packages/weaviate/warnings.py:303: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n            Please make sure to close the connection using `client.close()`.\n\nPlease see the error message: “IndexError: list index out of range”.\nWhat’s the proper way to use existing vector db to do inference? Please help!\n\n----------\n\n[MartinMin (2024-08-08T19:30:24.383Z)]: I added a little more: I am using BGE-M3 embedding:\nmodel_kwargs = {\"device\": \"cpu\"}\nfrom langchain_community.embeddings import HuggingFaceBgeEmbeddings\nbge_m3_embedding = HuggingFaceBgeEmbeddings( model_name=\"BAAI/bge-m3\", encode_kwargs=model_kwargs)\n\nAs said, this works if the building of vectorstore and query in the same flow. However, it reports the error if I do querying only:\ndb = WeaviateVectorStore.from_documents([], embedding_model, client=weaviate_client, index_name='test')\nOn the other hand, if I use OpenAI ‘text-embedding-ada-002’ embedding, it has no issue in both cases. Does it have something to do with embedding method?\nHope this additional info helps\n\n----------\n\n[DudaNogueira (2024-08-13T12:40:58.939Z)]: Hi @MartinMin !!\nO believe you are facing the same issue from this thread:\n  \n    \n    \n    Langchain WeaviateHybridSearchRetriever with filters? Support\n  \n  \n    Nevermind fixed it. \nHey, thank you for the quick replies. I have tried your example but sadly it does not work. When initialising the db, I get an “list index out of range error”. \nHere is my code: \nfrom langchain_cohere import CohereEmbeddings\nimport weaviate\nfrom weaviate.classes.init import Auth\nfrom weaviate.classes.query import Filter\n\nembeddings = CohereEmbeddings(model=EMBEDDINGS_MODEL, cohere_api_key=COHERE_API_KEY)\n\nheaders = {\n    \"X-Cohere-Api-Key\": COHERE_API_KEY,\n}\n\nclient = weavia…\n  \n\n\nThis error seems to come from hugging face interface at langchain:\nlangchain_community/embeddings/huggingface.py\", line 331,\n\ncan you try this?\ndb = WeaviateVectorStore.from_documents(embeddings=embedding_model, client=weaviate_client, index_name='test')\n\nMy guess is that the huggingface interface in langchain is not checking when the documents passed as parameter is an empty list.\n\n----------\n\n[Just_Guide7361 (2024-08-13T14:39:53.998Z)]: I think that is almost it. This should do the trick!\ndb = WeaviateVectorStore(embeddings= embeddings, client=client, index_name=index_name)\n\n----------\n\n[MartinMin (2024-08-13T16:50:27.826Z)]: The initializer way works mostly, but ‘text_key’ needs to be added:\ndb = WeaviateVectorStore(embedding=embedding_model, client=weaviate_client, index_name='test3', text_key='text')\nAnother questions:  what does ‘text_key’ exactly mean? I understand it should be the textual field that you want to index, for example:\n{\n  'title': \"a test\",\n  \"content\": 'This is a paragraph'.\n}\n\nIn this case, I would set text_key=“content”. However, you look at this example, it sets text_key = ‘text’, but the document doesn’t have ‘text’ field at all. It only have ‘page_content’, so I am confused!\nhttps://python.langchain.com/v0.2/docs/integrations/retrievers/weaviate-hybrid/\n\n----------\n\n[DudaNogueira (2024-08-13T19:54:19.143Z)]: hi!\nthe text_key, for Langchain, will be the property where it will store the actual content chunk in the vector store.\nOn your case, you can pass it as text_key as “content” and title goes as metadata.\nCheck this topic:\n  \n    \n    \n    What is text_key supposed to be when using LangChain? Support\n  \n  \n    Hi @Scott_M ! Welcome to our community  \nI am far from being a LangChain expert. On top of that, I am also a Weaviate noob myself, as I recently joined Weaviate, hehehe. \nWhat I could find is that, while you need to specify text_key for the main Class instantiation, it will have no effect while passing it to from_documents(). It is hardcoded to text here: \n\ntext_key will be the property  where text will be stored: \n [image] \nI am not sure if hardcoding text at from_texts() is a good thing,…\n  \n\n\nIt’s a little bit “old” as the code for Weaviate + Langchain has changed, but I have digged into this in the past.\n\n----------\n\n[MartinMin (2024-08-13T20:24:14.743Z)]: But in the example I pasted above, why does it still work?\nThe document doesn't have a 'text' field, but text_key='text' still work?\n\n----------\n\n[DudaNogueira (2024-08-13T21:21:55.612Z)]: This is because it will only use text_key on ingestion.\nTake this, for example:\n# single insertion\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\n\nfrom langchain.schema import Document\n\nembeddings = OpenAIEmbeddings()\ndoc1 = Document(\n    page_content=\"this is the page content\",\n    metadata={\"metadata1\": \"something\", \"metadata2\": \"other thing\"}\n)\ndb = WeaviateVectorStore.from_documents([doc1], embeddings, client=client, index_name=\"TestCollection\")\nprint(client.collections.get(\"TestCollection\").query.fetch_objects().objects[0].properties)\n\nthis will print:\n\n{‘text’: ‘this is the page content’,\n‘metadata2’: ‘other thing’,\n‘metadata1’: ‘something’}\n\nnow if we change text_key, this is what will happen:\ndb = WeaviateVectorStore.from_documents([doc1], embeddings, client=client, index_name=\"TestCollection2\", text_key=\"text_goes_here\")\nprint(client.collections.get(\"TestCollection2\").query.fetch_objects().objects[0].properties)\n\nand the output:\n\n{‘metadata2’: ‘other thing’,\n‘text_goes_here’: ‘this is the page content’,\n‘metadata1’: ‘something’}\n\nNote that, as you passed some metadata (and changed the text_key), you can now use the hybrid weights to lean your query towards a specific metadata field.\nWhen you are specifying the query properties, you will need to specify the very same text_key that you set for your collection.\nFor example, is you set text_key as text_goes_here:\ndb.similarity_search(\"thing\", query_properties=[\"text_goes_here\", \"metadata1^2\", \"metadata2\"])\n\nif you don’t provide a query_properties at query time, Weaviate will look into all searchable properties.\nMore on setting hybrid query weights on property values here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate - Vector Database\n\n  Hybrid search combines the results of a vector search and a keyword (BM25F) search by fusing the two result sets.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\n\n----------\n\n[MartinMin (2024-08-13T22:00:07.273Z)]: DudaNogueira:\n\n page_content\n\n\nYes, it definitely helps. Now I understand that the ‘page_content’ field is silently converted to ‘text’ file after the DB is created and I think that clears up my confusion.",
    "date_created": "2024-08-08T17:14:21.097Z",
    "has_accepted_answer": true,
    "title": "How to load existing db to similarity search?",
    "topic_id": 3309
  },
  {
    "user_id": 1414,
    "conversation": "[vrano (2024-09-12T10:15:35.437Z)]: Hi,\nI have an app which does multimodal searches using CLIP. The nearObject and hybrid searches for that work fine. I’d also like to be able to do text searches in the future, meaning I’d have a separate vector for pure text embeddings. I tested it and the results were pretty bad (for example search for apple laptop returns applejuice while I have a lot of macbooks embedded in the db). Another thing I’m wondering about is if we can do separate vector embedding later one, meaning I’d like to do CLIP embeddings now and do the text embeddings later on at some point. Is that possible to do?\n\n----------\n\n[Mohamed_Shahin (2024-09-12T12:17:19.051Z)]: Hi @vrano, I hope you’re having a great week! \nI completely understand your need to achieve good results both ways. Based on your message, I believe you could benefit from multi-vector capabilities.\nHave you seen this feature in Weaviate?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMultiple vectors | Weaviate\n\n  Syntax\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage collections | Weaviate\n\n  Every object in Weaviate belongs to exactly one collection. Use the examples on this page to manage your collections.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAdditionally, check out this guide for searching with multiple vectors:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMultiple target vectors | Weaviate\n\n  Multiple target vector search uses a single query to search multiple-target vectors. Weaviate searches the target vectors concurrently and automatically combines the results.\n\n----------\n\n[vrano (2024-09-12T13:47:32.330Z)]: Hi @Mohamed_Shahin,\ncan we set other vectors after creating the schema. I’d like to set it up with one vector now, and add other vectors now, meaning now I’d like to embed image and title, and possibly create an embedding for title only later down the line.\nCould you also give me guidance for the inquiry about the text search being very inacurrate - I embedded my product titles using text2vec-cohere, but when searching I got pretty bad results as mentioned in my post. I made sure to specify the target vector when using nearText search\n\n----------\n\n[Mohamed_Shahin (2024-09-18T13:25:07.317Z)]: Hi @vrano,\nSure thing! I’m always happy to help! \nFor your first point, yes, you can add properties and indexes to a collection after it’s created, but there’s an important aspect to keep in mind:\n\nIf you add a new property before importing data, there’s no impact on indexing.\nHowever, if you add a property after importing data, the indexing of existing objects won’t be updated automatically. Pre-existing objects won’t be indexed with the new property, and queries might return unexpected results because the index only includes new objects that have the added property.\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage collections | Weaviate\n\n  Every object in Weaviate belongs to exactly one collection. Use the examples on this page to manage your collections.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor the second part, please share the query you’re running, the result you’re seeing, and what you’re expecting. That way, I can take a closer look and provide some guidance.\n\n----------\n\n[Dirk (2024-09-19T06:44:08.514Z)]: vrano:\n\ncan we set other vectors after creating the schema. I’d like to set it up with one vector now, and add other vectors now, meaning now I’d like to embed image and title, and possibly create an embedding for title only later down the line.\n\n\nI think at the moment you need to create all named vectors at the beginning.\nIf you supply the vectors yourself (dont use the weaviate vectorizer feature) you could add all named vectors you might need in the future and then only provide the clip ones at the moment and add any other embedding later.\nWe will add adding named vectors after the initial creation at some point, but I don’t think it is on the roadmap yet",
    "date_created": "2024-09-12T10:15:35.390Z",
    "has_accepted_answer": false,
    "title": "Text search and multiple embeddings",
    "topic_id": 4117
  },
  {
    "user_id": 1304,
    "conversation": "[cyc00518 (2024-09-29T07:28:32.901Z)]: Description\nProblem with Docker Configuration and CUDA for Reranker-Transformers\nI followed the tutorial and used the following Docker configuration:\nreranker-transformers:  \n  # Set the name of the inference container\n  image: semitechnologies/reranker-transformers:baai-bge-reranker-v2-m3\n  container_name: reranker-transformers-container \n  network_mode: \"bridge\"\n  volumes:\n    - .:/usr/src/app\n  ports:\n    - 50051:8080\n  restart: always\n  environment:\n    ENABLE_CUDA: 0  # set to 1 to enable\n  deploy:\n    resources:\n      reservations:\n        devices:\n          - driver: nvidia\n            device_ids: ['0']\n            capabilities: [gpu]\n\nAfter successfully starting the service, when I set ENABLE_CUDA to 1, calling the service results in the following error:\nINFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)\n\nBatches:   0%|          | 0/1 [00:00<?, ?it/s]\nERROR:    Something went wrong while scoring the input.\nTraceback (most recent call last):\n  File \"/app/app.py\", line 55, in read_item\n    return await cross_encoder.do(item)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/crossencoder.py\", line 56, in do\n    return await asyncio.wrap_future(self.executor.submit(self._rerank, item))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/crossencoder.py\", line 53, in _rerank\n    return self._perform_rerank(item)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/crossencoder.py\", line 45, in _perform_rerank\n    return self._batch_rerank(item)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/crossencoder.py\", line 37, in _batch_rerank\n    scores = self.model.predict(sentences)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py\", line 375, in predict\n    self.model.to(self._target_device)\n  File \"/usr/local/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 2883, in to\n    return super().to(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1174, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1160, in convert\n    return t.to(\n           ^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\nAssertionError: Torch not compiled with CUDA enabled\n\nHowever, if I set ENABLE_CUDA to 0, there is no issue.\nWhy does this issue only happen with the reranker? I am asking because I used the transformers-inference image with ENABLE_CUDA: 1 without any problems:\nt2v-transformers:\n  image: semitechnologies/transformers-inference:baai-bge-m3-onnx\n  container_name: ccpg-t2v-transformers-container # Separate from JiaoDa naming\n  network_mode: \"bridge\"\n  volumes:\n    - .:/usr/src/app\n  ports:\n    - 50049:8080\n  restart: always\n  environment:\n    ENABLE_CUDA: 1  # set to 1 to enable\n  deploy:\n    resources:\n      reservations:\n        devices:\n          - driver: nvidia\n            device_ids: ['0']\n            capabilities: [gpu]\n\nAdditionally, I would like to know how to configure these services to load pre-downloaded models from the local machine.\nServer Setup Information\n\nGPU hardware: GH200 (aarch64)\n\n----------\n\n[DudaNogueira (2024-09-30T14:55:54.973Z)]: hi @cyc00518 !!\nIn order to have pre loaded models you will need to build a custom model.\nHere is the link that explains that in detail:\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate/reranker-transformers\n\n    Contribute to weaviate/reranker-transformers development by creating an account on GitHub.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAlso, can you yu try running this service with the following docker, from here?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nReranker | Weaviate\n\n  Weaviate's integration with the Hugging Face Transformers library allows you to access their models' capabilities directly from Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!\n\n----------\n\n[cyc00518 (2024-10-01T00:53:08.661Z)]: Hi, @DudaNogueira\nThanks for your reply!\nActually, it’s the same when using docker image semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2\n  reranker-transformers:  # Set the name of the inference container\n    image: semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2\n    container_name: reranker-transformers-container \n    network_mode: \"bridge\"\n    volumes:\n      - .:/usr/src/app\n    ports:\n      - 50051:8080\n    restart: always\n    environment:\n      ENABLE_CUDA: 1 # set to 1 to enable\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              device_ids: [ '0' ]\n              capabilities: [ gpu ]\n\n  File \"/usr/local/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\nAssertionError: Torch not compiled with CUDA enabled\n\nI think it might be caused by torch. Maybe when building the reranker image, you should use the image from NVIDIA’s nvcr.io/nvidia/pytorch to ensure that torch is installed correctly.\nBecause the current image is unable to properly detect the GPU, as shown below.\n\nFurthermore, I also do the same test on embedding model image,\nAlthough I set ENABLE_CUDA: 1, and the calling does not raise any errors, in reality, the GPU is still not being utilized.\n t2v-transformers:\n    image: semitechnologies/transformers-inference:baai-bge-m3-onnx\n    container_name: t2v-transformers-container \n    network_mode: \"bridge\"\n    ports:\n      - 50049:8080\n    restart: always\n    environment:\n      ENABLE_CUDA: 1 # set to 1 to enable\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              device_ids: [ '0' ]\n              capabilities: [ gpu ]\n\nimage695×122 3.64 KB\nI test it on both GPU card A5000 and H200, and the results were the same.\nIf I’m wrong, please correct me. Thank you!\n\n----------\n\n[DudaNogueira (2024-10-04T08:49:11.113Z)]: hi @cyc00518 !\nI believe the best course of action here is opening a github issue on that repository:\n\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate/reranker-transformers\n\n    Contribute to weaviate/reranker-transformers development by creating an account on GitHub.",
    "date_created": "2024-09-29T07:28:32.766Z",
    "has_accepted_answer": false,
    "title": "[Question] reranker image seems to fail when use gpu?",
    "topic_id": 4370
  },
  {
    "user_id": 1803,
    "conversation": "[Gaurav_Singhal (2024-10-13T18:07:21.826Z)]: Description\nYep, you read the title correctly. The health check is working but the connection doesn’t work. I tried all the solutions so far suggested on this forum but nothing seems to work.\nI am using single docker file\nversion: '3.9'\n\nnetworks:\n  redis-network:\n    driver: bridge\n  db-network:\n    driver: bridge\n  core-api-network:\n    driver: bridge\n  rabbitmq-network:\n    driver: bridge\n  internal-api-network:\n    driver: bridge\n  celery-network:\n    driver: bridge\n  weaviate-network:\n    driver: bridge\n\nvolumes:\n  postgresql-data: {}\n  weaviate_data: {}\n  shared-upload-data: {}\n  internal-mongo-data: {}\n  redis-data: {}\n\nservices:\n  db:\n    ...\n\n  redis:\n    ...\n\n  core_api_server:\n    ...\n\n  rabbitmq:\n    ...\n\n  celery-worker-1:\n    image: internal_celery\n    scale: 1\n    build:\n      context: internal\n      dockerfile: Dockerfile/local/Dockerfile.celery\n    command: python3 -m celery -A  app.celery_app:celery_app  worker -Q source_op_queue --concurrency=3 --without-heartbeat  --without-gossip --without-mingle\n    env_file:\n      - 'internal/.env/.api'\n      - 'internal/.env/.rabbitmq'\n      - 'internal/.env/.weaviate'\n    depends_on:\n      redis:\n        condition: service_started\n      rabbitmq:\n        condition: service_started\n      weaviate:\n        condition: service_healthy\n    volumes:\n      - shared-upload-data:/.upload-cache # Mount the shared volume in the fastapi_server container\n    networks:\n      - celery-network\n      - redis-network\n      - rabbitmq-network\n      - weaviate-network\n    deploy:\n      resources:\n        limits:\n          cpus: '3'\n          memory: 2G\n        reservations:\n          cpus: '2'\n          memory: 1.5G\n\n  fastapi_server:\n    image: internal_api_server\n    build:\n      context: internal\n      dockerfile: Dockerfile/local/Dockerfile.api\n    env_file:\n      - 'internal/.env/.api'\n      - 'internal/.env/.rabbitmq'\n      - 'internal/.env/.weaviate'\n    ports:\n      - '8000:8000'\n    volumes:\n      - ./internal:/app\n      - shared-upload-data:/.upload-cache\n    restart: always\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    deploy:\n      replicas: 1\n      resources:\n        limits:\n          cpus: '3'\n          memory: 2G\n        reservations:\n          cpus: '2'\n          memory: 1.5G\n    networks:\n      - redis-network\n      - rabbitmq-network\n      - core-api-network\n      - internal-api-network\n      - weaviate-network\n\n  weaviate:\n    command:\n      - \"--host=0.0.0.0\"\n      - \"--port=8080\"\n      - \"--scheme=http\"\n    image: semitechnologies/weaviate:1.26.6\n    ports:\n      - 8080:8080\n      - 50051:50051\n    env_file: 'internal/.env/.weaviate'\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s \n    networks:\n      - weaviate-network\n    deploy:\n      resources:\n        limits:\n          cpus: '2'\n          memory: 2.5G\n        reservations:\n          cpus: '1'\n          memory: 1.5G\n\nExecution steps:\nThe FastAPI app, main.py has an import statement that goes 3-4 levels inside of different files and instantiates the weaviate client.\ndef warmup_weaviate_client():\n    weaviate_host = os.environ.get('WEAVIATE_HOST', \"localhost\")\n    weaviate_url = f\"http://{weaviate_host}:8080\"\n    retries = 5\n    while retries > 0:\n        with httpx.Client() as client:\n            try:\n                response = client.get(f\"{weaviate_url}/v1/.well-known/ready\")\n                if response.status_code == 200:\n                    logger.info(\"Weaviate is ready\")\n                    client = weaviate.connect_to_local(\n                        host=weaviate_host,\n                        headers=headers,\n                        additional_config=AdditionalConfig(\n                            timeout=Timeout(init=5, query=60, insert=120)  # Values in seconds\n                        )\n                    )\n                    client.connect()\n                    return client\n                else:\n                    logger.warning(f\"Weaviate not ready, status code: {response.status_code}\")\n            except httpx.RequestError as exc:\n                logger.warning(f\"An error occurred while checking Weaviate readiness: {exc}\")\n        retries -= 1\n        if retries > 0:\n            logger.info(f\"Retrying in 5 seconds... ({retries} retries left)\")\n            time.sleep(5)\n    return None\n\ndef get_weaviate_client():\n    weaviate_host = os.environ.get('WEAVIATE_HOST', \"localhost\")\n    # weaviate_port = os.environ.get('WEAVIATE_PORT', \"8080\")\n    logger.info(\"XXXXXXX - Creating Weaviate Client\")\n        # is_anonymous = os.environ.get(\"AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED\", \"false\")\n    is_anonymous = \"true\" # For now, we are using anonymous access - API method does not work\n    if is_anonymous == \"true\":\n        auth_client_secret=None\n    else:\n        logger.info(\"Secured API connection to Weaviate is being made\")\n        weaviate_api_key = os.environ.get('WEAVIATE_API_KEY')\n        if not weaviate_api_key:\n            logger.error(f\"WEAVIATE_API_KEY missing\")\n            # return {\"error\": \"ENV_VARIABLE_MISSING\", \"reason\": \"WEAVIATE_API_KEY not found\"}\n        auth_client_secret=Auth.api_key(weaviate_api_key)\n\n    client = warmup_weaviate_client()\n    if not client:\n        logger.error(\"WEAVIATE_CONNECTION_ERROR: Weviate connection failed\")\n    logger.info(\"Weaviate connection established\")\n\n        # return {\"error\": \"WEAVIATE_CONNECTION_ERROR\", \"reason\": str(e)}\n    # Wait for Weaviate to be ready\n    wait_time_limit = 240\n    while not client.is_ready():\n        if wait_time_limit <= 0:\n            logger.error(\"WEAVIATE_TIMEOUT_ERROR: Weviate waited for too long\")\n            # return {\"error\": \"WEAVIATE_TIMEOUT_ERROR\", \"reason\": ERROR_CODES[\"WEAVIATE_TIMEOUT_ERROR\"]}\n        sys.stdout.write(f\"\\rWait for Weaviate to get ready. {wait_time_limit:02d} seconds left.\")\n        sys.stdout.flush()\n        wait_time_limit -= 5\n        time.sleep(5.0)\n    try:\n        create_collections(client)\n    except Exception as e:\n        logger.error(f\"WEAVIATE_SCHEMA_ERROR: Issues with Weviate Schema: {str(e)}\")\n        return {\"error\": \"WEAVIATE_SCHEMA_ERROR\", \"reason\": str(e)}\n    return client\n\n\n## CREATING THE CLIENT\nclient = get_weaviate_client()\nclient.close()\n\nI was so fed up with the whole issue that I had to add the health readiness step inside the code. Anyway, in the logs I see “Weaviate is ready” but not “Weaviate connection established”. It kinda proves that the container has access to http://weaviate:8080 but not able to make the connection.\nServer Setup Information\nI have a RAG application that has 1 celery containers, 1 fast API server, 1 weaviate, and 1 database.\n\nSingle docker compose file for all.\nTrying to access http://weaviate:8080 but the client is not working. When I go inside the celery or fastapi container, the health check works.\nMore importantly, when I manually execute the script in python cli inside the container, it works too. But when I try to use it as a whole application (making request from frontend) it just does not work.\n\nAny additional Information\nI tried the simpler setup where I created a dummy fastapi service which uses the same weaviate client method. That is working, but for some reason my above setup is not working.\nPlease help.\n\n----------\n\n[Dirk (2024-10-13T18:45:17.291Z)]: Hi,\ncould you try to use our async client? Async API | Weaviate\nWe got a couple of reports about problems when using the sync client in an async context and are currently debugging it.",
    "date_created": "2024-10-13T18:07:21.703Z",
    "has_accepted_answer": false,
    "title": "Getting connection error in V4 (FastAPI + Celery), health check is working though",
    "topic_id": 5117
  },
  {
    "user_id": 1026,
    "conversation": "[Ali_Osm (2024-06-01T21:49:43.890Z)]: Description\nI have weaviate v1.25.2 setup using devcontainer, and I’m talking with it using FastAPI and V4 Python client.\nI created an endpoint to create collections like this:\n@router.post('/', name='create_collection')\nasync def create_collection(\n  create_collection_request: CreateCollectionRequest,\n  client: weaviate.WeaviateClient=Depends(get_weaviate_client),\n):\n  if not client.collections.exists(create_collection_request.name):\n    client.collections.create(\n      name=create_collection_request.name,\n      properties=[\n        wc.Property(name=property.name, data_type=property.type) for property in create_collection_request.properties\n      ],\n      vectorizer_config=wc.Configure.Vectorizer.none(),\n    )\n\n    return { 'status': 'ok', 'message': f'Collection \"{create_collection_request.name}\" created successfully.' }\n  else:\n    return { 'status': 'not modified', 'message': f'Collection \"{create_collection_request.name}\" exists already.' }\n\nAnd I want to create an endpoint to get the number of objects in a collection like this:\n@router.get('/{collection_name}', name='get_collection')\nasync def get_collection(\n  collection_name: str,\n  client: weaviate.WeaviateClient=Depends(get_weaviate_client),\n) -> GetCollectionRequest:\n  if client.collections.exists(collection_name):\n    collection = client.collections.get(name=collection_name)\n    \n    return GetCollectionRequest(\n      name=collection_name,\n      size=collection.aggregate.over_all(total_count=True).total_count,\n    )\n  else:\n    return { 'status': 'not found', 'message': f'Collection \"{collection_name}\" does not exist.' }\n\nThe issue is the get request is raising the following exception:\nweaviate.exceptions.UnexpectedStatusCodeError: Query was not successful! Unexpected status code: 422, with response body: {'error': [{'message': 'no graphql provider present, this is most likely because no schema is present. Import a schema first!'}]}.\n\nI searched for hour with nothing, any thought please?\nServer Setup Information\n\nWeaviate Server Version: 1.25.2\nDeployment Method: docker/devcontainer\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python v4.6.3\nMultitenancy?: No\n\n----------\n\n[Ali_Osm (2024-06-03T09:14:14.900Z)]: Answering my own question :3\nFrom weaviate docker logs:\nweaviate-1  | {“action”:“graphql_rebuild”,“error”:“Could not build GraphQL schema, because: Schema must contain unique named types but contains multiple types named \"String\".”,“level”:“error”,“msg”:“could not (re)build graphql provider”,“time”:“2024-06-03T09:06:51Z”}\nI was testing with the default values from FastAPI endpoints explorer, and the default value for a text field is “string”, and it looks like weaviate is not accepting a collection named “string” for some reason. Changing the collection name to something else works fine.\nCan you please confirm if there is any preserved collection names? And if yes, could you please add this to the docs?\n\n----------\n\n[DudaNogueira (2024-08-22T18:41:06.802Z)]: hi @Ali_Osm !!\nThis was fixed: Fix GraphQL schema error when class name is a GraphQL primitive type name by antas-marcin · Pull Request #5370 · weaviate/weaviate · GitHub\nThanks for reporting!",
    "date_created": "2024-06-01T21:49:43.839Z",
    "has_accepted_answer": true,
    "title": "Weaviate V4 Python client not able to aggregate newly created collections",
    "topic_id": 2586
  },
  {
    "user_id": 650,
    "conversation": "[fairymane (2024-10-02T23:54:43.247Z)]: Description\nHi Team, I observed a situation that after deleting a certain amount of embeddings, the memory consumption reversely increases. What could be the reason?\nFor more detail, On a weaviate cluster (on K8s), I reduced embeddings from 203M to 195M (use\ncollection.data.delete_many with filter, and set the **consistency_level=ConsistencyLevel.ONE**\n).\nThe memory consumption, instead of decreases, increased from ~514Gb to 621 Gb…\nThe deletion happens more than 18 hrs ago and no other operation was performed after deletion. The memory consumption stays at the higher level (621 Gb) instead of coming down… Any idea on how this could happen? Is the garbage collection daemon suppose to run in the background?\nServer Setup Information\n\nWeaviate Server Version: 1.25.0\nDeployment Method: k8s\nMulti Node? Number of Running Nodes:  7\nClient Language and Version: V4\nMultitenancy?: No\n\nAny additional Information>\n\n#set env variable QUERY_MAXIMUM_RESULTS: 20000\n…\ncollection = weaviate_client.collections.get(collection_name).with_consistency_level(\nconsistency_level=ConsistencyLevel.ONE\n)\ndelete_response = collection.data.delete_many(where=Filter.by_property(“log_name”).equal(log_name))\n…\n\nBesides that, while running deletion, I observed lots of error like\n\n“Query call with protocol\nGRPC delete failed with message <AioRpcError of RPC\nthat terminated with:\nstatus = StatusCode.UNKNOWN\ndetails = “batch delete: cannot find\nobjects: find matching doc ids in shard\n“05i1dRqNYiPq”: class Data_discovery_production has\nno physical shard “05i1dRqNYiPq”: failed to execute\nquery: leader not found””\n\nor\n\n\"Query call with protocol\nGRPC delete failed with message <AioRpcError of RPC\nthat terminated with:\nstatus = StatusCode.DEADLINE_EXCEEDED\ndetails = “Deadline Exceeded”\ndebug_error_string = “UNKNOWN:Error\nreceived from peer”\n\nThis is the timeout config I set when initialize the Weaviate client\nadditional_config=AdditionalConfig(\n                timeout=Timeout(init=180, query=360, insert=360),\n            ),\n\nWhat could be the reason? I use retry with exponential back-off that the deletion could eventually succeed but still see the memory increase issue as described above.\n\n----------\n\n[DudaNogueira (2024-10-03T16:38:30.440Z)]: Hi!\nThere was a lot of changes after 1.25.X regarding this.\nSo my advice would be upgrading.\nOn top of that, it is interesting to have visibility on tombstones, and change the related environment variables for it:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nEnvironment variables | Weaviate\n\n  To configure Weaviate in a Docker or a Kubernetes deployment, set these environment variables\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.\nThanks!",
    "date_created": "2024-10-02T23:54:43.198Z",
    "has_accepted_answer": false,
    "title": "Memory consumption increases after embedding deletion",
    "topic_id": 4407
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-09-08T17:58:38.540Z)]: I want to query objects with a filter on a property that is an array of objects. Let’s say the property is tags:\n[\n{uniqueid: 123, name: ‘tag1’},\n{uniqueid: 456, name: ‘tag2’,\n]\nI want to get objects that contain a tag with unique id 456 in its tags property. Basically, I want to filter on an array of objects by checking if an object exists in the array and then get those objects that match this criteria.\nI checked the documentation, and this didn’t seem currently possible (I might have missed something though). What alternate methods could I try here?\nFor example, I tried using ContaintsAny:\n       tenant_collection =  nodes_collection.with_tenant(name)\n\t\t\n\t\tquery_result = tenant_collection.query.fetch_objects(\n\t\t\tfilters=Filter.by_property(\"tags\").contains_any([{'name': 'work', 'color': '#D5BA04', 'uniqueid': '14b06e9a-10e1-4255-a2b2-d414ecb27821'}],\n\t\t\tinclude_vector=True\n\t\t)\n\n\nBut it throws an error, and I believe this functionality might not exist yet.\nThe error thrown anyways is:\nUUID input should be a string, bytes or UUID object [type=uuid_type, input_value={'name': 'work', 'color':...4', 'uniqueid': 'sdfsd'}, input_type=dict]\n\n----------\n\n[Mohamed_Shahin (2024-09-09T12:12:09.677Z)]: Hey @Tejas_Sharma,\nHappy Monday! I hope you’re having a great start to the week!\nI understand you’re trying to filter by inside arrays of objects, and I imagine your data looks something like this:\n{\n  \"tags\": [\n    { \"uniqueid\": 123, \"name\": \"tag1\" },\n    { \"uniqueid\": 456, \"name\": \"tag2\" }\n  ]\n}\n\nIf you’re attempting to filter based on an entire property rather than the values within it, nested-filters can help:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nFilters | Weaviate\n\n  Filters let you include, or exclude, particular objects from your result set based on provided conditions.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHowever, if you’re trying to filter inside arrays of nested objects, this feature is currently not supported. I would say open a feature request here:\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nBuild software better, together\n\n  GitHub is where people build software. More than 100 million people use GitHub to discover, fork, and contribute to over 420 million projects.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAs a potential workaround, you might consider flattening your data structure and storing the uniqueids in a separate array for more straightforward filtering.\nLet me know if this helps or if you have any other questions!\n\n----------\n\n[Tejas_Sharma (2024-09-09T18:00:56.621Z)]: Ah I see Mohamed, I’ll submit a request there and it would indeed be very helpful.\nAnd thanks for the alternate workaround, that’s very smart!",
    "date_created": "2024-09-08T17:58:38.454Z",
    "has_accepted_answer": true,
    "title": "[Question] Filter on array of objects",
    "topic_id": 4020
  },
  {
    "user_id": 323,
    "conversation": "[Dharanish (2024-12-06T12:22:27.378Z)]: Team, I have created 10,000 tenants and imported 100 data for each tenant. My configured GOMAXPROCS and GOMEMLIMIT values as per the setup needs.\n\nThe above is the resource consumption for the data, and it seems very high for the flat index in terms of both CPU and memory.\nWeaviate version: 1.23.11\nPython client: 4.5.7\nVector Dimension: 384\nReplica :  2\nNo. of properties: 4\nTotal number of records : 1000000.\n\n----------\n\n[DudaNogueira (2024-12-06T18:51:51.092Z)]: hi @Dharanish !\nI would know what would be the usage on this scenario \nI am curious: Have you benchmarked this with other databases?\nThanks!\n\n----------\n\n[Dharanish (2024-12-11T13:03:25.738Z)]: Sorry for the delayed response\nNo, we are primarily using Weaviate for production; there is a new usecase and we don’t evaluate with other DBs yet.\n\n----------\n\n[DudaNogueira (2024-12-11T20:30:48.071Z)]: Oh, ok.\nSo what are the allocated values for memory and cpu, and what are the values of GOMEMLIMIT and GOMAXPROCS?\nNot sure you have read thru this nice blog article about GOMEMLIMIT:\n  \n      \n\n      weaviate.io – 15 Aug 22\n  \n\n  \n    \n\nGOMEMLIMIT is a game changer for high-memory applications | Weaviate\n\n  Go 1.19 introduced GOMEMLIMIT, which completely changes how you can manage memory limits in Go. Learn how it helps Weaviate be more reliable.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBecause you are using a flat index, your heap will not be an issue here, (you are storing on disk, not on memory), but setting those variables can force garbage collection kick in quicker and free up memory.\nLet me know if that helps!\nTHanks!\n\n----------\n\n[Dharanish (2024-12-18T09:38:59.655Z)]: @DudaNogueira , I’ve read that article before and set values for those variables based on our resource needs.\nI’ve found the catch that this resource consumption is due to PROMETHEUS_MONITORING_ENABLED. After disabled, we get\nimage2686×124 101 KB\nIt seems prometheus metrics collection plays a major role in resource consumption. We found this using go profiling tool But don’t know why the Prometheus client used in Weaviate consumes that much amount of resources.\n\n----------\n\n[DudaNogueira (2024-12-18T13:17:37.147Z)]: Nice catch!!\nDo you see the same behavior in latest versions?\nA lot has happened since 1.23…\n\n----------\n\n[Dharanish (2025-01-23T05:22:07.018Z)]: Hi , I saw the same behaviour in 1.27 too. It seems LSM specific metrics grow exponentially with respect to the number of collections and tenants.",
    "date_created": "2024-12-06T12:22:27.322Z",
    "has_accepted_answer": true,
    "title": "High resource usage in Flat Index",
    "topic_id": 9115
  },
  {
    "user_id": 354,
    "conversation": "[AN_Colab (2023-10-10T08:38:31.374Z)]: Hi all,\nI am using Embedded Weaviate (version 1.21), via python client on a shared machine. When running Weaviate in embedded mode, it listens to a number of ports.  One of them is port 6060, which is apparently used for Go profiling. I don’t need to do profiling and it is problematic if multiple instance of Weaviate are running\nIs it possible to disable Go profiling or assign a different port number than 6060?\n\n----------\n\n[DudaNogueira (2023-10-10T11:58:49.554Z)]: Hi @AN_Colab !! Welcome to our community!! \nYou can pass some parameters to Weaviate EmbeddedOptions:\nhttps://weaviate-python-client.readthedocs.io/en/stable/weaviate.html#weaviate.EmbeddedOptions\nlike so:\nimport weaviate\nfrom weaviate import EmbeddedOptions\n\nclient = weaviate.Client(\n    embedded_options=EmbeddedOptions(port=1234)\n)\n\nBut please, bear in mind that Weaviate Embedded is marked as experimental, and should not be used in production.\nLet me know if that helps\n\n----------\n\n[AN_Colab (2023-10-10T12:10:19.564Z)]: Thank you !\nI am indeed using the way you suggested to pass parameter.\nUnfortunately, I couldn’t figure out the parameter to change port 6060.\nThe port parameter changes the HTTP port, also there is a parameter to change the GRPC port, but there is nothing to to change this profiling port (or to disable profiling).\n\n----------\n\n[DudaNogueira (2023-10-11T07:55:45.554Z)]: Oh, I see. I don’t think this is possible with the embedded option as you have limited options when starting an Embedded Weaviate instance.\nI believe docker compose is the best option here, as you will be able to have a better control on port mappings.\n\n----------\n\n[Guillermo_Ripa (2024-08-21T18:12:27.347Z)]: Just answering for future reference. I haven’t tested it, but you could try disabling Go profiling altogether. At least with v4.\nimport weaviate\n\nclient = weaviate.connect_to_embedded(\n    environment_variables={\"DISABLE_GO_PROFILING\": \"true\"},\n)\n\n----------\n\n[DudaNogueira (2024-08-21T19:04:46.712Z)]: hi @Guillermo_Ripa !! Welcome to our community \nOhhhh. Now I see!  Nice catch!\nthe port 6060 comes from the Go profiling!\nIt took me some time to figure out that this env var was wrong in our docs \nSo this will work:\nclient = weaviate.connect_to_embedded(\n    environment_variables={\"GO_PROFILING_DISABLE\": \"true\"},\n)\n\nThanks for pointing it out!\nHere is the PR: Add correct go profiling env vars by dudanogueira · Pull Request #2480 · weaviate/weaviate-io · GitHub",
    "date_created": "2023-10-10T08:38:31.330Z",
    "has_accepted_answer": true,
    "title": "Embedded Weaviate Port 6060",
    "topic_id": 799
  },
  {
    "user_id": 3501,
    "conversation": "[Jotheraj_kori (2025-02-20T09:53:13.213Z)]: Hi!\nI am using weaviate via docker container\nHere is my docker code\nnetnanny-weaviate:\n    container_name: netnanny-weaviate\n    image: semitechnologies/weaviate:latest\n    ports:\n      - \"8080:8080\"\n      - \"50051:50051\"\n    environment:\n      QUERY_DEFAULTS_LIMIT: '10'\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: /var/lib/weaviate\n    volumes:\n      - ./weaviate_data:/var/lib/weaviate\n    networks:\n      - netnanny \n\nIf I keep\n PERSISTENCE_DATA_PATH: './data'\n\nand\nvolumes:\n      - weaviate_data:/var/lib/weaviate\n\nI am losing data stored in “weaviate_data” folder If I restart my docker container.\nAnd If I keep\nPERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n\nAnd\nvolumes:\n      - weaviate_data:/var/lib/weaviate\n\nI am getting this error\n{“build_git_commit”:“258edad”,“build_go_version”:“go1.22.11”,“build_image_tag”:“1.25.30”,“build_wv_version”:“1.25.30”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.27.0.2:8300”],“time”:“2025-02-20T07:02:09Z”}\n{“build_git_commit”:“258edad”,“build_go_version”:“go1.22.11”,“build_image_tag”:“1.25.30”,“build_wv_version”:“1.25.30”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.27.0.2:8300”,“status”:8,“time”:“2025-02-20T07:02:09Z”} .\nCould you please let me know what I am doing wrong here. My only aim is I don’t want to lose the data If I restart my docker container.\nThank you\n\n----------\n\n[DudaNogueira (2025-02-20T16:26:20.001Z)]: hi @Jotheraj_kori !!\nWelcome to our community \nPERSISTENCE_DATA_PATH will tell Weaviate where the data will be stored.\nAs you are running Docker, you need to make sure that this folder will be mounted as volume.\nthis docker compose:\nservices:\n  netnanny-weaviate:\n      container_name: netnanny-weaviate\n      image: semitechnologies/weaviate:latest\n      ports:\n        - \"8080:8080\"\n        - \"50051:50051\"\n      environment:\n        QUERY_DEFAULTS_LIMIT: '10'\n        AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n        PERSISTENCE_DATA_PATH: /var/lib/weaviate\n      volumes:\n        - ./weaviate_data:/var/lib/weaviate\n\n\nhave worked for me \nNotice that Weaviate content will not be stored at a folder called weaviate_data that will be side by side with the docker compose.yaml\nLet me know if that helps!\nTHanks!\n\n----------\n\n[Jotheraj_kori (2025-02-21T09:26:58.731Z)]: Hi @DudaNogueira\nThank you for response\nI have modified the code as per your suggestion.\nHere is my code\nnetnanny-weaviate:\n    container_name: netnanny-weaviate\n    image: semitechnologies/weaviate:latest\n    ports:\n      - \"8080:8080\"\n      - \"50051:50051\"\n    environment:\n      QUERY_DEFAULTS_LIMIT: '20' \n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n    volumes:\n      - ./weaviate_data:/var/lib/weaviate \n    networks:\n      - netnanny \n\nBut Still I am facing some issue .\nwhen I checked the logs of container this is what I am getting “attempted to join and failed”\nccacac6b-73a8-4655-9f30-f6b4f3e9873f822×360 13.6 KB\nThank you!\n\n----------\n\n[DudaNogueira (2025-02-21T13:27:50.013Z)]: Oh! I see. That’s only an info message.\nBecause this cluster is a single node, you can ignore it \nWith this docker-compose, were you able to retain the data?\n\n----------\n\n[Jotheraj_kori (2025-03-05T10:08:46.364Z)]: Hi @DudaNogueira Sorry , I was busy with some other tasks so couldn’t reply early.\nAs I am getting this warning  “attempted to join and failed” and at this time when I hit the API to save the data in weaviate, I am unable to do it.\nI am getting below error.\nimage775×113 5.32 KB\nAnd When I am not getting that warning  “attempted to join and failed”  and If I hit the API to save data in weaviate, It Works.\nAnd Here is my code to load the data in weaviate.\ntry:\n        weaviate_client = weaviate.connect_to_custom(\n            http_host=os.getenv('WEAVIATE_SERVER'),\n            http_port=os.getenv('WEAVIATE_PORT'),\n            http_secure=False,\n            grpc_host=os.getenv('WEAVIATE_SERVER'),\n            grpc_port=os.getenv('WEAVIATE_GRPC_PORT'),\n            grpc_secure=False)\n\n        collection_name = \"NetworkAnomaly\"\n\n        class_schema = {\n            \"class\": collection_name,\n            \"properties\": [\n                {\"name\": \"anomaly_name\", \"dataType\": [\"text\"]},\n                {\"name\": \"anomaly_details\", \"dataType\": [\"text\"]},\n                {\"name\": \"remediation\", \"dataType\": [\"text\"]},\n                {\"name\": \"recommendation\", \"dataType\": [\"text\"]}\n            ]\n        }\n\n        existing_collections = weaviate_client.collections.list_all(simple=False)\n\n        if collection_name in existing_collections:\n            logger.info(\"Weaviate schema contains NetworkAnomaly collection. Hence, deleting it!\")\n            weaviate_client.collections.delete(collection_name)\n            \n        schema = weaviate_client.collections.create_from_dict(class_schema)\n        logger.info(\"Weaviate schema created\")\n\n        # Load Data into Weaviate\n        data_objects = list()\n\n        # for i, row in df.iterrows():\n        for index, row in enumerate(rag_data_list, start=1):\n            logger.info(f\"\\nProcessing row# {index}\")\n            properties_1 = {\n                \"anomaly_name\": row['anomaly_name'],\n                \"anomaly_details\": row['anomaly_details'],\n                \"remediation\": row['remediation'],\n                \"recommendation\": row['recommendation']\n            }\n            combined_text = f\"{row['anomaly_name']} {row['anomaly_details']} {row['remediation']} {row['recommendation']}\"\n\n            vector_embeddings = []\n\n            # CX Playground\n            vector_embeddings = await cx_playground_generate_embeddings(combined_text)\n            data_object = wvc.data.DataObject(\n                properties=properties_1, \n                vector=vector_embeddings\n            )\n            data_objects.append(data_object)\n\n        response = schema.data.insert_many(data_objects)\n\n        logger.info(\"Loading data into Weaviate Vector store is complete\")\n        return True\n\n    except Exception as e:\n        logger.error(f\"Failed to update data: error {str(e)}\")\n        return False\n\n    finally:\n        weaviate_client.close()\n\nand here are my environment variables.\n\nWEAVIATE_SERVER=netnanny-weaviate\n- WEAVIATE_PORT=8080\n- WEAVIATE_GRPC_PORT=50051\n\nThank you!\n\n----------\n\n[DudaNogueira (2025-03-06T14:04:58.834Z)]: Jotheraj_kori:\n\nimage: semitechnologies/weaviate:latest\n\n\nYou should not use this. The best practice is to specify a version, otherwise it can upgrade/downgrade your cluster without you wanting.\nIs this a new cluster or are you upgrading it?\nCan you try a new docker file created here?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nDocker | Weaviate\n\n  Weaviate supports deployment with Docker.\n\n----------\n\n[Jotheraj_kori (2025-03-10T06:11:16.370Z)]: Hi @DudaNogueira,\nThank you so much! The issue has finally been resolved.\nSpecifying the exact version and deleting the old data helped me fix the problem.\nThanks again!\n\n----------\n\n[DudaNogueira (2025-03-10T15:11:45.838Z)]: Hi @Jotheraj_kori !!\nGlad to hear that!\nHappy coding!",
    "date_created": "2025-02-20T09:53:13.163Z",
    "has_accepted_answer": true,
    "title": "I want to retain my Weaviate data even If I restart my docker container",
    "topic_id": 10475
  },
  {
    "user_id": 2457,
    "conversation": "[mihajlo (2024-11-05T11:40:03.963Z)]: Description\n\nHi, we’re using the Serverless Cloud tier and get the following exception(intermittently):\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message recvmsg:Connection reset by peer\nWhen:\ncollection.query.fetch_objects(\nfilters=filters,\nlimit=batch_size,\noffset=offset)\nbatch size is 10 and offset is small either 10 or 20\nThe client is configured as so:\nvector_db_client = weaviate.connect_to_wcs(\ncluster_url=vector_db_url,\nauth_credentials=weaviate.auth.AuthApiKey(vector_db_api_key),\nadditional_config=AdditionalConfig(timeout=Timeout(init=30, query=60, insert=120)),\nskip_init_checks=True\n)\nThe code is executed on a AWS Lambda.\nAny suggestions how to fix it?\nServer Setup Information\nServerless Cloud tier\npython client version: 4.6.7\n\n----------\n\n[DudaNogueira (2024-11-06T12:15:32.066Z)]: hi @mihajlo !!\nWelcome to our community \nThe best place to ask for support on any hosted Weaviate instances that we host is here:\n\n  \n\n      console.weaviate.cloud\n  \n\n  \n    \n\nWeaviate Cloud\n\n  Weaviate Cloud\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThat’s because it will create a support ticket and we can take action right away having access to that instance.\nAre you doing some sort of large ingestion? This can happen when the instance is quickly overwhelmed with a memory/cpu load at the instance.\nSo if doing a large ingestion, it is interesting to control the load and allocate enough resources accordingly beforehand (when possible).\nPlease, go ahead and open a support with our team, and we’ll be happy to help on this issue.\nThanks!",
    "date_created": "2024-11-05T11:40:03.905Z",
    "has_accepted_answer": false,
    "title": "weaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message recvmsg:Connection reset by peer",
    "topic_id": 7453
  },
  {
    "user_id": 3139,
    "conversation": "[Rohini_vaidya (2025-01-09T06:15:45.894Z)]: hi, I’m working with hybrid search in Weaviate and have a few questions that need clarification:\n\nIs there a parameter to set a threshold value for hybrid search to filter out results with a minimum score? While I see the max_distance parameter, it appears to be specific to vector search.\nHow is the score calculated in hybrid search? My understanding is that it might use Reciprocal Rank Fusion (RRF), but I’d like confirmation on this.\nHow does the explainScore feature work in hybrid search? Since hybrid search combines keyword search and vector search, how does the explanation indicate whether the result is influenced by keyword search, vector search, or both?\n\nThank you in advance for your insights!\n\n----------\n\n[Mohamed_Shahin (2025-01-09T16:04:15.154Z)]: Hey @Rohini_vaidya, Happy New Year!\nRegarding filters with hybrid search\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nFilters | Weaviate\n\n  Filters let you include, or exclude, particular objects from your result set based on provided conditions.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThe max distance parameter relates to the vector component in similarity searches as you mentioned. While we currently don’t have a min score parameter, that sounds like a valuable feature to suggest as feature Sign in to GitHub · GitHub.\nIf you’d like more control over keyword relevance, you can adjust the alpha parameter to lean more towards keyword-based searches. Details on balancing keyword and vector searches\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate\n\n  Hybrid search combines the results of a vector search and a keyword (BM25F) search by fusing the two result sets.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor your second point:\nRelative Score Fusion is the default fusion method starting from v1.24\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate\n\n  Hybrid search combines vector search and keyword search (BM25) to leverage the strengths of both approaches. This takes into account results' semantic similarity (vector search) and exact keyword relevance (BM25), providing more comprehensive search...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLastly, Hybrid Search uses both keywords and vector searches simultaneously. Here’s how it works:\n\n\nIt retrieves the best results for both keyword (BM25) search and vector (nearXXX) search.\n\n\nAn algorithm combines these results into a weighted output.\n\n\nThe alpha parameter allows you to control the weighting:\n• Default: 0.75 (balanced between vector and keyword).\n• 1: Pure vector search.\n• 0: Pure keyword search.\nResults are ranked based on a combination of BM25 and vector scores\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate\n\n  Hybrid search combines vector search and keyword search (BM25) to leverage the strengths of both approaches. This takes into account results' semantic similarity (vector search) and exact keyword relevance (BM25), providing more comprehensive search...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBest regards,\nMohamed Shahin\nWeaviate Support",
    "date_created": "2025-01-09T06:15:45.849Z",
    "has_accepted_answer": true,
    "title": "Hybrid search in weaviate",
    "topic_id": 9646
  },
  {
    "user_id": 807,
    "conversation": "[adithya.ch (2024-11-20T01:10:14.301Z)]: Description\nWe are trying to increase the Storage volume size in Weaviate statefulset from 50 GB to 100GB. But when we deploy the changes in kubernetes through helm templates, k8s complains that PVC size can’t be increased.\nPlease let us know how to increase the PVC size along with the CPU/Memory of the pods.\nServer Setup Information\n\nWeaviate Server Version: 1.27.2\nDeployment Method: K8S\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python\nMultitenancy?: No\n\nAny additional Information\nDeployed through helm templates using ArgoCD.\n\n----------\n\n[DudaNogueira (2024-11-20T19:05:38.252Z)]: hi @adithya.ch !!\nI believe this is something related to k8. From Weaviate perspective, as long as there is space, and is not under the threshold it will enter the readonly state, it will keep writing.\nDo you see anything outstanding from Weaviate logs?",
    "date_created": "2024-11-20T01:10:14.248Z",
    "has_accepted_answer": false,
    "title": "Vertical Scaling of Weaviate cluster (PV Size)",
    "topic_id": 7713
  },
  {
    "user_id": 2471,
    "conversation": "[quybao (2024-11-07T06:35:26.035Z)]: Description\n\nMy current usecase need to restart the weaviate pod frequently. The data is quite huge, about 2687 schema. Look like enable Raft on version 1.27.1 make the boostrapping take about 45 minutes. I could not find any instructions to disable Raft to make the boostrapping time shorter, like previous version as 1.24.10. Can you help?\nServer Setup Information\n\nWeaviate Server Version: 1.27.1\nDeployment Method: K8S via Helm Chart\nMulti Node? Number of Running Nodes: Single node (1 pod)\nClient Language and Version: Python 4.9.3\nMultitenancy?: No\n\nAny additional Information\n\n# 3 first entries\n{\"build_git_commit\":\"05de0db\",\"build_go_version\":\"go1.22.8\",\"build_image_tag\":\"v1.27.1\",\"build_wv_version\":\"1.27.1\",\"level\":\"info\",\"msg\":\"Schema catching up: applying log entry: [3/2687]\",\"time\":\"2024-11-07T04:40:41Z\"}\n{\"build_git_commit\":\"05de0db\",\"build_go_version\":\"go1.22.8\",\"build_image_tag\":\"v1.27.1\",\"build_wv_version\":\"1.27.1\",\"level\":\"info\",\"msg\":\"Schema catching up: applying log entry: [4/2687]\",\"time\":\"2024-11-07T04:40:41Z\"}\n{\"build_git_commit\":\"05de0db\",\"build_go_version\":\"go1.22.8\",\"build_image_tag\":\"v1.27.1\",\"build_wv_version\":\"1.27.1\",\"level\":\"info\",\"msg\":\"Schema catching up: applying log entry: [5/2687]\",\"time\":\"2024-11-07T04:40:41Z\"}\n....\n# The last entries\n{\"action\":\"hnsw_prefill_cache_async\",\"build_git_commit\":\"05de0db\",\"build_go_version\":\"go1.22.8\",\"build_image_tag\":\"v1.27.1\",\"build_wv_version\":\"1.27.1\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-11-07T05:20:24Z\",\"wait_for_cache_prefill\":false}\n{\"build_git_commit\":\"05de0db\",\"build_go_version\":\"go1.22.8\",\"build_image_tag\":\"v1.27.1\",\"build_wv_version\":\"1.27.1\",\"level\":\"info\",\"msg\":\"Completed loading shard *** in 26.496718ms\",\"time\":\"2024-11-07T05:20:24Z\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"build_git_commit\":\"05de0db\",\"build_go_version\":\"go1.22.8\",\"build_image_tag\":\"v1.27.1\",\"build_wv_version\":\"1.27.1\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-11-07T05:20:24Z\",\"took\":213805}\n\nIt took 40 minutes to complete.\n\n----------\n\n[lreyreaud (2024-11-08T08:27:44.170Z)]: Hello quybao!\nThanks for reporting that issue. We have also noticed it in some internal deployments and we have a tentative fix in progress.\nThe problem is due to the fact that on starting up, weaviate will replay schema changes to rebuild the internal schema representation. If there are many (in your case >2000) schema changes, these can trigger a graphql rebuild everytime one is applied, this can get very expensive fast and delay the whole operation (one gql rebuild can take seconds if the schema is large).\nThe tentative fix delay rebuilding graphql until the whole schema is rebuilt internally, and then just rebuild graphql once.\nThe PR is here skip the schema callbacks when raft schema is still catching up by reyreaud-l · Pull Request #6229 · weaviate/weaviate · GitHub.\nIf you wish to try it, you can use the image preview-skip-the-schema-callbacks-when-raft-schema-is-still-catching-up-701ac1b.\nNote that it is based on the latest 1.26, as you upgraded to 1.27.1 this would mean a downgrade in your case.\nSo far it has passed all our pipelines and I’m hopeful we’ll get it merged in the next few business days and it will be included in a patch release shortly.\nI’ll update here once the fix is merged and a patch release it out.\nSorry for the inconvenience in the meantime!\n\n----------\n\n[lreyreaud (2024-11-20T09:06:11.848Z)]: The PR has been merged to our mainline and will be released to 1.25+ versions shortly.",
    "date_created": "2024-11-07T06:35:25.970Z",
    "has_accepted_answer": true,
    "title": "Raft make boostrapping take too long",
    "topic_id": 7474
  },
  {
    "user_id": 3329,
    "conversation": "[joe-barhouch (2025-02-07T18:01:04.292Z)]: Hello all,\nI’m using client v4, and i have added some documents as i usually do with no trouble.\nThis time around i have added a ‘release_date’ property to my documents (i’m using Langchain, this is the Document Metadata which i believe is the object property here)\nI need to execute a similarity search using near_text, but I also want to rank or sort my results using the relase_date property so I can get the latest results first.\nThe sorting API seems like can only be included with fetch_objects, and not near_text or hybrid. So it’s no possible to search my db and sort the results\nDoing something like:\ncollection.query.near_text(\n    ...: query=\"test query\",\n    ...: limit=25,\n    ...: return_metadata=MetadataQuery(distance=True),\n    ...: sort=Sort.by_property(name='release_date', ascending=False)\n    ...: )\n\nThis results in an error:\n_NearTextQueryAsync.near_text() got an unexpected argument 'sort' \nIs it not possible to search with sorting?\nThanks\n\n----------\n\n[Mohamed_Shahin (2025-02-10T09:46:51.626Z)]: Good morning @joe-barhouch,\nWelcome to our community—it’s great to have you here!\nSorting isn’t directly available with vector searches. But you can use the rerank feature to kinda “sort” the results. I’m also looking into improving the documentation to clarify about sorting further so it does not cause confusion.\nIt’s important to note that rerank works after the initial search, meaning it doesn’t sort the entire dataset but instead reorders the search results based on relevance. However, it should still provide a reasonable approximation for sorting by attributes.\nRegards,\nMohamed Shahin\nWeaviate Support\n\n----------\n\n[sebawita (2025-02-10T11:36:05.272Z)]: Rerank might be an overkill for sorting by date.\nMaybe you could sort the result objects in python, like this:\nresult = temp.query.near_text(\n  query=\"test query\",\n  limit=25,\n  return_metadata=MetadataQuery(distance=True),\n)\n\nsorted_results = sorted(result.objects, key=lambda x: x.properties[\"release_date\"], reverse=True)\n\nfor item in sorted_results:\n    print(item.properties)\n\n----------\n\n[joe-barhouch (2025-02-10T15:31:43.311Z)]: Thank you @Mohamed_Shahin and @sebawita\nI agree with you guys, i ended up sorting the results after the search using something similar to what was showcased.\nThank you for considering updating the documentation. I think it’s important to see more relevant examples of what and how the additional operators work. The doc is good for now but it’s sometimes difficult to understand exactly what’s going on.\nAdditionally, the Ask Documentation bot you guys have is helpful, but it will mix details from client v3 and client v4 which just gives completely wrong answers. I tried to use it to get some form of reranking working, but the implementation given was wrong (but that’s not related to this task only)",
    "date_created": "2025-02-07T18:01:04.233Z",
    "has_accepted_answer": true,
    "title": "Sorting results using properties within a search",
    "topic_id": 10042
  },
  {
    "user_id": 876,
    "conversation": "[elie (2024-12-02T19:57:44.730Z)]: I’m using Python. I have an API that returns huge amount of data as JSON objects\n\nCan Weaviate read that data? Do I need to process it before feeding it into Weaviate?\nIf the data changes, either the structure of the API response changes or the existing values got updated, is it possible to update the data in Real time, on the fly, in production? Like you update a MySQL database for example\nIs there a reliable vectorizer/embeddings I can use other than OpenAI? I plan to self host the entire project and not rely on any third party API.\n\nYes I know that this question was asked before but here I am asking it again, because the users were told to go checkout a python notebook on github that no longer exists.\nI’m not going to search git history, because even if I find the notebook, maybe the code is obsolete. The fact that it was removed from Github could mean that the ability to read JSON data is deprecated in weaviate, who knows.\n\n----------\n\n[DudaNogueira (2024-12-02T20:14:20.662Z)]: hi @elie !! Welcome back!\n\n\nNo, Weaviate will not read and store entire json data. You will need to parse that json, and store it accordingly. Note that while we do have the object datatype, it does have some limitations.\n\n\nIf you have a deterministic id for that object, you can always pass it as the object uuid during a batch operation. That way, Weaviate will insert or create that object for you. If the object has a new property that, Weaviate will create that property “on the fly”, if the AUTO_SCHEMA feature is active.\n\n\nHere you have options, such as ollama and kubeai\n\n\nWe have reorganized our recipes, so some links are now returning 404. You can find the mentioned recipe here:\n  \n\n      github.com\n  \n\n  \n    weaviate/recipes/blob/main/weaviate-features/generative-search/generative_search_openai.ipynb\n\n\n      {\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"rJD9aP9eVcsT\"\n      },\n      \"source\": [\n        \"## Dependencies\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"ReE5TWeXSDTe\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"!pip install weaviate-client\"\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBut note that at this recipe, it is not importing json, but a simple dict as it’s properties.\nLet me know if that helps!\nTHanks!\n\n----------\n\n[sebawita (2024-12-02T23:37:18.208Z)]: DudaNogueira:\n\nNo, Weaviate will not read and store entire json data. You will need to parse that json, and store it accordingly. Note that while we do have the object datatype, it does have some limitations.\n\n\nThat is partially correct.\nUnderneath, Weaviate stores data in JSON format, and it stores the whole object.\nThe limitation is mostly with nested properties (i.e. an object that contains “address”, which is made of “street” and “city”) - nested properties don’t get vectorized, however nested data can still be stored in Weaviate.\n\n----------\n\n[elie (2024-12-03T16:57:42.571Z)]: DudaNogueira:\n\nNo, Weaviate will not read and store entire json data. You will need to parse that json, and store it accordingly.\n\n\nWhat structured data type does Weaviate fully support with no limitations? So that I parse the Json into that structure. Python dicts?\n\n----------\n\n[DudaNogueira (2024-12-03T18:53:32.203Z)]: Hi @elie !!\nWhat I meant before was that you cannot pass the .json file into Weaviate. You will need to read that file and work if it’s content. For example, if using python, it will be a dict. being aware of the limitations of the object datatype as mentioned above.\nHere you can find a list of supported datatypes:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nData types | Weaviate\n\n  Data Types in Weaviate Schema\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nSo for example, if you have a nested content in your json, and you need it to be vectorized and searchable, you will need to bring that nested content to the root structure, meaning it will now become a property by itself.\nLet me know if this clarifies.\nThanks!",
    "date_created": "2024-12-02T19:57:44.680Z",
    "has_accepted_answer": false,
    "title": "Can Weaviate read JSON data?",
    "topic_id": 9054
  },
  {
    "user_id": 1255,
    "conversation": "[HYK97 (2024-07-27T13:05:26.492Z)]: I created the collection like this\n wv_client.collections.create(\n        name=class_name,\n        description=\"collection_1\",\n        replication_config=Configure.replication(\n            factor=1\n        ),\n        vectorizer_config=[\n            Configure.Vectorizer.none()\n        ],\n        vector_index_config=Configure.VectorIndex.hnsw(\n            distance_metric=VectorDistances.COSINE\n        ),\n        properties=[\n            Property(name=\"product_no\", data_type=DataType.NUMBER),\n            Property(name=\"original_review\", data_type=DataType.TEXT,\n                     tokenization=Tokenization.WORD),\n            Property(name=\"title\", data_type=DataType.TEXT, skipVectorisation=True),\n            Property(name=\"review\", data_type=DataType.TEXT, skipVectorisation=True),\n            Property(name=\"detail\", data_type=DataType.TEXT, skipVectorisation=True),\n        ]\n    )\n\nThe title, review, and detail are multi-named vector fields, but I used the Configure.Vectorizer.none() option because I’m creating and putting in vector data directly\nExample search\n    col = client.collections.get(class_name)\n    results = col.query.near_vector(near_vector=query_vector, limit=limit,\n                                    return_properties=[“product_no”, “original_review”],\n                                    include_vector=“True”,\n                                    return_metadata=MetadataQuery(distance=True,\n                                                                  creation_time=True),\n                                    target_vector=“detail”)\n\nIf you proceed like this, you will get this error\n“Query call with protocol GRPC search failed with message extract target vectors: class class_name does not have named vector detail configured. Available named vectors map.”\nHow do I fix it?\n\n----------\n\n[DudaNogueira (2024-07-30T15:01:55.767Z)]: hi!\nYou never defined the named vectors to begin with \nCheck here some nice academy we have about this:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\n220 Named vectors | Weaviate - Vector Database\n\n  Course overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nthis is how your collection should look like:\nimport weaviate\nfrom weaviate import classes as wvc\n\nclient = weaviate.connect_to_local()\n\nfrom weaviate import classes as wvc\n\nclient.collections.delete(\"MyCollection\")\nclient.collections.create(\n        name=\"MyCollection\",\n        description=\"collection_1\",\n        replication_config=wvc.config.Configure.replication(\n            factor=1\n        ),\n        vectorizer_config=[\n            wvc.config.Configure.NamedVectors.none(\n                name=\"title\",\n            ),\n            wvc.config.Configure.NamedVectors.none(\n                name=\"review\",\n            ),\n            wvc.config.Configure.NamedVectors.none(\n                name=\"detail\",\n            ),\n        ],\n        properties=[\n            wvc.config.Property(name=\"product_no\", data_type=wvc.config.DataType.NUMBER),\n            wvc.config.Property(name=\"original_review\", data_type=wvc.config.DataType.TEXT,\n                     tokenization=wvc.config.Tokenization.WORD),\n            wvc.config.Property(name=\"title\", data_type=wvc.config.DataType.TEXT, skipVectorisation=True),\n            wvc.config.Property(name=\"review\", data_type=wvc.config.DataType.TEXT, skipVectorisation=True),\n            wvc.config.Property(name=\"detail\", data_type=wvc.config.DataType.TEXT, skipVectorisation=True),\n        ]\n    )\n\nNow inserting some data:\ncollection = client.collections.get(\"MyCollection\")\ncollection.data.insert({\n        \"title\": \"This is a title\",\n        \"detail\": \"some details\",\n        \"review\": \"this seems good\"\n    },\n    vector={\n        \"title\": [1],\n        \"review\": [1, 2],\n        \"detail\": [1, 2, 3]\n    }\n)\n\nand now retrieving it:\ncollection.query.fetch_objects(include_vector=True).objects[0].vector\n\nand this should be the output:\n\n{‘detail’: [1.0, 2.0, 3.0], ‘review’: [1.0, 2.0], ‘title’: [1.0]}\n\nLet me know if this helps!!\nThanks!",
    "date_created": "2024-07-27T13:05:26.436Z",
    "has_accepted_answer": false,
    "title": "[Question] YOUR TOPIC",
    "topic_id": 3194
  },
  {
    "user_id": 1158,
    "conversation": "[Arun_Uma (2024-12-07T18:23:27.517Z)]: Hi,\nI have a weaviate instance running on K8 cluster on a GCP project.\nWhile testing my code in debug model in pycharm, I connected to the weaviate instance and i did the mistake of stopping my program abruptly. My code has a finally block with wvt_client.close() so if i had run it it would have closed the connection.\nSince it was closed abruptly i am unable to open any new connection. I get exception error  “‘Meta endpoint! Unexpected status code: 503, with response body: None.’”\nResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\nPlease make sure to close the connection using `client.close()\nis there a way to solve this without restarting the server?\nthanks\narun\n\n----------\n\n[DudaNogueira (2024-12-09T12:47:58.486Z)]: hi @Arun_Uma !!\nWelcome to our community \nWhat is the server and client version and language you are using? Is this a single node cluster or multinode? Those informations that we ask when opening the issue is important so we can understand if there was a fix or if you are using latest versions.\nYou should be able to instantiate a client without any problems, even if you already has done it.\nFor python client version 3 and typescript version 2, it should only use REST endpoints, so there isn’t a need to actually close.\nBut for latest versions, because we are now using GRPC, it is recommended to close the connection after using it.\nLet me know about this info, and if there is a way to reproduce this so I can help you further.\nThanks!\n\n----------\n\n[Arun_Uma (2024-12-09T15:46:48.789Z)]: Hi Duda, Thanks for your reply.\nI have the Weaviate instance installed on my client’s Kubernetes cluster ( 4 nodes) running on GCP.\nI am on Weaviate v16.8.7 & using Python 3.11.6 to connect.  It looks like the Pod is down due to some reason hence unable to connect.\nThanks\nArun\n\n----------\n\n[DudaNogueira (2024-12-09T19:09:46.421Z)]: Arun_Uma:\n\nv16.8.7\n\n\nHi!\nDo you mean 1.16, maybe? there isn’t a 16 version",
    "date_created": "2024-12-07T18:23:27.470Z",
    "has_accepted_answer": false,
    "title": "'Meta endpoint! Unexpected status code: 503, with response body: None.'",
    "topic_id": 9138
  },
  {
    "user_id": 1481,
    "conversation": "[Jasper_van_den_Berg (2024-09-25T12:07:02.388Z)]: Description\nI’m trying to filter on nested properties of my data, but getting this error:\n\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\nstatus = StatusCode.UNKNOWN\ndetails = “explorer: get class: vector search: object vector search at index idx_23a2d2a3005d23f9bbe689206ca32fb5: shard idx_23a2d2a3005d23f9bbe689206ca32fb5_A3OTVDfioAKG: build inverted filter allow list: nested query: nested clause at pos 7: data type “object” not supported in query”\ndebug_error_string = “UNKNOWN:Error received from peer  {created_time:“2024-09-25T13:48:00.981306+02:00”, grpc_status:2, grpc_message:“explorer: get class: vector search: object vector search at index idx_23a2d2a3005d23f9bbe689206ca32fb5: shard idx_23a2d2a3005d23f9bbe689206ca32fb5_A3OTVDfioAKG: build inverted filter allow list: nested query: nested clause at pos 7: data type \"object\" not supported in query”}”> >\n\nI’m not sure if I’m incorrectly refering to the property in the filters, which I’m doing through Filter.by_property(<property_name.nested_property_name>).\nExample of the filters:\nretriever_filters = {'filters': [_FilterValue(value='Computer Tower', operator=<_Operator.LIKE: 'Like'>, target='details.Form_Factor'), _FilterValue(value='NVIDIA', operator=<_Operator.LIKE: 'Like'>, target='details.Graphics_Card_Description'), _FilterValue(value='AMD', operator=<_Operator.LIKE: 'Like'>, target='details.Graphics_Card_Description'), _FilterValue(value=['16 GB', '32 GB', '64 GB'], operator=<_Operator.CONTAINS_ANY: 'ContainsAny'>, target='details.RAM'), _FilterValue(value=['Intel Core i7', 'Intel Core i5', 'Ryzen 5'], operator=<_Operator.CONTAINS_ANY: 'ContainsAny'>, target='details.CPU_Model'), _FilterValue(value='gaming', operator=<_Operator.LIKE: 'Like'>, target='details.Brand')]}\n\nServer Setup Information\n\nWeaviate Server Version: 1.26.3 ( Docker image )\nDeployment Method: Docker\nMulti Node? Number of Running Nodes:\nI’m not sure I’m deploying it through:\n\ndocker run -p 8080:8080 -p 50051:50051 --env-file .env.local -e QUERY_DEFAULTS_LIMIT=20 -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true -e PERSISTENCE_DATA_PATH=/data -v weaviate_data:/data semitechnologies/weaviate:1.26.3\n\nwhere .env.local:\nENVIRONMENT=local\nHOST=0.0.0.0\nPORT=80\nACCESSIBLE_HOST=localhost\nACCESSIBLE_PORT=8000\nGOOGLE_APPLICATION_CREDENTIALS=/code/app/auth.json\nWEAVIATE_SERVER_URL=http://weaviate:8080\nWEAVIATE_SERVER_GRPC_PORT=50051\nOPENAI_API_KEY=<key>\n\n\nClient Language and Version:\nlangchain-weaviate==0.0.2\nweaviate-client==4.6.4\npython 3.11.9\nMultitenancy?:\nNot that I know of, using default configs\n\nAdditional information\nThe vector store is created through the LangChain FastAPI backend using langchain-weaviate:\nWeaviateVectorStore.from_documents(\n    documents,\n    client=WeaviateClient(connection_params=ConnectionParams.from_url(\"http://localhost:8080\", 50051)),\n    embedding=OpenAIEmbeddings(api_key=os.environ[\"OPENAI_API_KEY\"]),\n    index_name=index_name\n)\n\nloaded through:\nWeaviateVectorStore(\n    client=WeaviateClient(connection_params=ConnectionParams.from_url(\"http://localhost:8080\", 50051)),\n    embedding=OpenAIEmbeddings(api_key=os.environ[\"OPENAI_API_KEY\"]),\n    index_name=index_name,\n    text_key=\"text\"\n)\n\nand queried through:\nWeaviateVectorStore.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 50, \"filters\": retriever_filters})\n\n----------\n\n[Dirk (2024-09-26T09:00:37.795Z)]: Jasper_van_den_Berg:\n\nfilter on nested properties of my data\n\n\nHi, this is not supported at the moment\n\n----------\n\n[Arnoud (2024-09-27T15:48:52.048Z)]: I noticed that it is high on the backlog and was wondering if it is expected to be integrated in the foreseeable future.\n\n----------\n\n[Dirk (2024-09-27T17:07:52.472Z)]: AFAIK it is not scheduled yet - will probably come at some point, but I sadly cannot give anything more concrete than that\n\n----------\n\n[Arnoud (2024-09-27T18:56:44.780Z)]: Thank you for your reply!\n\n----------\n\n[ublrama (2025-01-28T15:25:50.938Z)]: @Dirk IS there an update on when this will be picked up! I finally got around to implement and was very pleased with the nested object property. Now that you can filter it, makes it useless. Why offer this kind of data type if you cannot use it…",
    "date_created": "2024-09-25T12:07:02.340Z",
    "has_accepted_answer": false,
    "title": "Filtering on nested properties?",
    "topic_id": 4312
  },
  {
    "user_id": 1332,
    "conversation": "[Fakhri_Prayatna_Putr (2024-09-19T18:23:09.414Z)]: Hi just a quick question about the error i got\nI was querying with weaviate and sometimes i got an error saying [Errno -2] Name or service not known.\nAnd for note i got this error not everytime but only occur sometimes\nI’m using trafeik as reverse proxy as websecure for the http, but i set the connection to weaviate like this\nweaviate_lib.connect_to_custom(\n            http_host=WEAVIATE_REST_HOST,\n            http_port=WEAVIATE_REST_PORT,\n            http_secure=False,\n            grpc_host=WEAVIATE_GRPC_HOST,\n            grpc_port=WEAVIATE_GRPC_PORT,\n            grpc_secure=False,\n            headers={\n                \"X-OpenAI-Api-Key\": OPENAI_API_KEY,\n                \"X-OpenAI-Organization\": OPENAI_ORGANIZATION_ID\n            },\n            additional_config=AdditionalConfig(\n                connection=ConnectionConfig(\n                    session_pool_max_retries=3,\n                ),\n                timeout=Timeout(query=60, insert=120),\n            )\n        )\n\nshould i set http and grpc secure even though weaviate only communicate with non other than a service in the same reverse proxy configuration??\n\n----------\n\n[Mohamed_Shahin (2024-09-20T09:33:09.883Z)]: Hey @Fakhri_Prayatna_Putr,\nI’m not an expert in Traefik, but from what you’ve described and if it is intermittent issue. You could try:\nIncrease session_pool_max_retries, sometimes increasing the retries or extending the timeout might help in mitigating temporary DNS resolution issues.\nOr there could be some useful DNS resolution error logs in Traefik that could give insight into why the hostname sometimes fails to resolve.",
    "date_created": "2024-09-19T18:23:09.364Z",
    "has_accepted_answer": false,
    "title": "[Errno -2] Name or service not known",
    "topic_id": 4211
  },
  {
    "user_id": 3030,
    "conversation": "[rejoan.common (2024-12-17T05:17:11.768Z)]: image1818×564 31.8 KB\nIts been more than 2 hours already. still shows cluster is being prepared message. on the other hand, upgrading the existing sandbox cluster works as expected.\nnew cluster version: 1.28\nsandbox that got upgraded: 1.26\n\n----------\n\n[sebawita (2024-12-17T10:53:18.182Z)]: Hi @rejoan.common,\nI am sorry to hear that.\nPlease drop us an email at support@weaviate.io with your cluster ID. Our team will look into this.\nThanks,\nSebastian",
    "date_created": "2024-12-17T05:17:11.725Z",
    "has_accepted_answer": true,
    "title": "Creation of cluster taking ages",
    "topic_id": 9272
  },
  {
    "user_id": 1896,
    "conversation": "[ulugbekdj (2024-10-21T21:53:05.203Z)]: Hi there!\nIn version 4, is there a way to print out the list of all file titles ingested in the client?\nThank you!\n\n----------\n\n[DudaNogueira (2024-10-21T22:04:03.197Z)]: hi @ulugbekdj !\nWelcome to our community \nDo you want to show does objects right after a batch ingestion, for example, or all objects currently stored in Weaviate?\nIf the first, the object IDs at least will be available after the batch finishes, for example here, in batch.results:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIf you want to read all objects, this is the doc you will need:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nRead all objects | Weaviate\n\n  Weaviate provides the necessary APIs to iterate through all your data. This is useful when you want to manually copy/migrate your data (and vector embeddings) from one place to another.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.\nThanks!\n\n----------\n\n[ulugbekdj (2024-10-21T22:12:41.298Z)]: DudaNogueira:\n\nobject IDs at least will be available after the batch finishes, for example here, in batch.results:\n\n\nThanks, Duda, for a prompt response! The latter link was exactly what I was looking for! I appreciate a it lot!",
    "date_created": "2024-10-21T21:53:05.142Z",
    "has_accepted_answer": true,
    "title": "[Docs] Print out all files/docs ingested in the client",
    "topic_id": 5830
  },
  {
    "user_id": 1266,
    "conversation": "[fr_yuan (2024-08-28T09:02:27.073Z)]: hello，\n‘store is read-only’ is a restriction on the shard or on all? Does this issue occur because the shard is full or because the entire disk has reached its limit? We are deploying locally through Docker, and I checked that the disk is not full, so why is this happening?\nthank you！\n\n----------\n\n[Mohamed_Shahin (2024-08-28T13:45:00.104Z)]: Hi @fr_yuan,\nI hope you’re having a great week!\nWeaviate typically enters a read-only state when there’s disk pressure\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPersistence | Weaviate - Vector Database\n\n  When running Weaviate with Docker or Kubernetes, you can persist its data by mounting a volume to store the data outside of the containers. Doing so will cause the Weaviate instance to also load the data from the mounted volume when it is restarted.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThis is done to prevent file corruption or data loss. Have you monitored the disk to see if during batch or insertion, it may reach to a pressure state also check the default value.\nHere is how to set the shard back to READY\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage collections | Weaviate - Vector Database\n\n  Every object in Weaviate belongs to exactly one collection. Use the examples on this page to manage your collections.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\n\n----------\n\n[fr_yuan (2024-08-29T07:13:42.414Z)]: thank you very much！\nI have checked the status of the disk, and everything is normal. I want to know if the shard is READONLY because it has reached its limit? If so, what is the maximum limit for a shard?\n\n----------\n\n[Mohamed_Shahin (2024-08-29T13:04:06.609Z)]: Hi @fr_yuan,\nAbsolutely, I am always here to help. So you can inspect shards by running:\n\ncollection_name = client.collections.get(“collection_name”)\ncollection_shards = collection_name.config.get_shards()\nprint(collection_shards)\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage collections | Weaviate\n\n  Every object in Weaviate belongs to exactly one collection. Use the examples on this page to manage your collections.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThere isn’t a hard-coded limit for the size of a shards. However, the effective limit is typically determined by the underlying hardware resources.",
    "date_created": "2024-08-28T09:02:27.029Z",
    "has_accepted_answer": false,
    "title": "[Question] why ‘store is read-only’",
    "topic_id": 3793
  },
  {
    "user_id": 1302,
    "conversation": "[wvuser (2024-08-12T05:11:20.644Z)]: Description\nWe have a cluster with 3 nodes (and 3 replicas).\nEvery day we have ~150k vector delete/insert operations (NOT updates).\nAnd WAL’s folder grows unlimittely… 100Gb+ per day…\nBecause of this, pod’s launch takes several hours.\nHow to limit size (file count) or historicity of append’s logs?\nServer Setup Information\n\nWeaviate Server Version: 1.25.6\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: Yes, 3\nClient Language and Version: Python3, Python Client v4\nMultitenancy?: No\n\nAny additional Information\nPERSISTENCE_HNSW_MAX_LOG_SIZE: 4GiB\n\n----------\n\n[etiennedi (2024-08-12T07:26:20.527Z)]: Hi @wvuser,\nThanks for the report. Could you specify what you mean by “WAL’s folder” and show a list of entries with file sizes, timestamps, etc. (Basically, ls—lah of the folder you mentioned)?\nThanks,\nEtienne\n\n----------\n\n[wvuser (2024-08-12T08:13:57.096Z)]: Folder: main.hnsw.commitlog.d\nObjects (vectors) count are relatively constant and averages 46 million.\nWith no ‘PERSISTENCE_HNSW_MAX_LOG_SIZE’ var defined (def value?) for 2 weeks logs allocates about 1Tb+ of diskspace (compact not working effectivelly?).\nAfter setting ‘PERSISTENCE_HNSW_MAX_LOG_SIZE: 4Gib’  (at 05.08.2024) and restarts, files are compacted better, but grows any way…\n/main.hnsw.commitlog.d # ls -lah\ntotal 374G\n56.0K Aug 12 07:38 .\n122 Aug 12 07:41 …\n5.8G Aug  5 10:32 1721304967.condensed\n5.7G Aug  5 10:42 1721616213.condensed\n5.7G Aug  5 11:03 1721701799.condensed\n5.7G Aug  5 11:12 1721768839.condensed\n5.6G Aug  5 11:24 1721812184.condensed\n5.6G Aug  5 11:47 1721816899.condensed\n5.7G Aug  5 12:01 1721821425.condensed\n5.6G Aug  5 12:14 1721826313.condensed\n5.7G Aug  5 12:28 1721833078.condensed\n5.7G Aug  5 12:42 1721857267.condensed\n5.7G Aug  5 12:54 1721889914.condensed\n5.6G Aug  5 13:04 1721892801.condensed\n5.6G Aug  5 13:14 1721895375.condensed\n5.7G Aug  5 13:25 1721897847.condensed\n5.6G Aug  5 13:37 1721900266.condensed\n5.6G Aug  5 13:46 1721902840.condensed\n5.7G Aug  5 13:55 1721904982.condensed\n5.7G Aug  5 14:07 1721907333.condensed\n5.7G Aug  5 14:17 1721929267.condensed\n5.6G Aug  5 14:28 1721977300.condensed\n5.6G Aug  5 14:37 1721991570.condensed\n5.7G Aug  5 14:48 1722003586.condensed\n5.6G Aug  5 14:59 1722060942.condensed\n5.6G Aug  5 15:10 1722080272.condensed\n5.6G Aug  5 15:21 1722140928.condensed\n5.6G Aug  5 15:33 1722165809.condensed\n5.7G Aug  5 15:45 1722223985.condensed\n5.7G Aug  5 15:57 1722239502.condensed\n5.7G Aug  5 16:09 1722255331.condensed\n5.7G Aug  5 16:21 1722305960.condensed\n5.7G Aug  5 16:34 1722325728.condensed\n5.7G Aug  5 16:46 1722340285.condensed\n5.7G Aug  5 16:59 1722369381.condensed\n5.7G Aug  5 17:12 1722410655.condensed\n5.6G Aug  5 17:23 1722425059.condensed\n5.6G Aug  5 17:35 1722444431.condensed\n5.6G Aug  5 17:46 1722493142.condensed\n5.7G Aug  5 17:57 1722506115.condensed\n5.6G Aug  5 18:08 1722521950.condensed\n5.6G Aug  5 18:18 1722575516.condensed\n5.7G Aug  5 18:30 1722589113.condensed\n5.7G Aug  5 18:40 1722603175.condensed\n5.6G Aug  5 18:51 1722793765.condensed\n5.6G Aug  5 19:01 1722810983.condensed\n6.5G Aug  5 20:10 1722834472.condensed\n6.5G Aug  6 00:43 1722886138.condensed\n6.5G Aug  6 08:06 1722904983.condensed\n6.7G Aug  6 13:57 1722931570.condensed\n6.6G Aug  6 17:37 1722952621.condensed\n6.7G Aug  7 03:03 1722965804.condensed\n6.6G Aug  7 08:08 1722999771.condensed\n6.7G Aug  7 14:02 1723018055.condensed\n6.5G Aug  8 06:25 1723039265.condensed\n6.4G Aug  8 11:23 1723098273.condensed\n6.6G Aug  9 02:56 1723116143.condensed\n6.6G Aug  9 07:05 1723172167.condensed\n6.6G Aug  9 10:56 1723187096.condensed\n6.7G Aug  9 17:32 1723200973.condensed\n6.5G Aug 10 08:22 1723224692.condensed\n6.7G Aug 10 16:37 1723278109.condensed\n6.6G Aug 11 10:20 1723307819.condensed\n6.7G Aug 12 04:34 1723371566.condensed\n5.6G Aug 12 07:38 1723437244.condensed\n782.3M Aug 12 07:41 1723448296\n\n----------\n\n[etiennedi (2024-08-12T08:39:06.948Z)]: Check. Yeah, what’s happening here is that your individual chunks are already larger than the threshold to compact further. If you have PERSISTENCE_HNSW_MAX_LOG_SIZE: 4GiB that means that a file larger than 4GiB will not be considered for compaction.\nHowever, the HNSW commit logs are delta logs. If log 2 deletes something that was created in log 1, but log 1+2 are too big to be compacted, then the information from log 1 cannot be removed effectively.\nLimiting the max size is essentially a memory vs disk space trade-off. It sounds like in your case, you are suffering from a lot of disk growth, so it might be worth considering allowing some more memory, so files can still be compacted effectively. I can’t say what the ideal values are in this case, but if you still have memory available, I would try increasing the value.\nNote on all of the above: This mainly describes the current implementation and doesn’t mean this can’t be improved. We’ve discussed two options internally:\n\nSome sort of in-place compaction (where you remove redundant info from log 1 based on the fact that you know it will be present in log 2). This isn’t trivial because it’s not always clear which information has to persist and which is fully overridden. There are some commit types where it’s pretty clear (e.g. replace_links_at_level means any link set at that level previously is no longer needed)\nA full graph-to-disk dump (possibly at shutdown). If the deltas on disk have grown considerably larger than the actual graph, it might make sense to discard all logs and flush a perfect representation of the graph to disk to replace all historic logs.\n\n----------\n\n[wvuser (2024-08-15T08:29:50.840Z)]: etiennedi:\n\nIf you have PERSISTENCE_HNSW_MAX_LOG_SIZE: 4GiB that means that a file larger than 4GiB will not be considered for compaction.\n\n\nRegardless of the ‘PERSISTENCE_HNSW_MAX_LOG_SIZE’ param’s value, condensed files are always larger:\n31920×1650 384 KB\nWhy? Is ‘compact’ task ignores them in next interation?\n\n\n\n etiennedi:\n\nI can’t say what the ideal values are in this case, but if you still have memory available, I would try increasing the value.\n\n\nWith more ‘PERSISTENCE_HNSW_MAX_LOG_SIZE’, it got better, but we will still reach disk’s ‘out of space’… little later:(\nMay be we can manually ‘safely’ clear logs? Тo avoid ‘READONLY’ mode and long POD startup.\nOr optionally disable (not use) it at all on startup (if index data are valid/holistic)?\n\n\n\n etiennedi:\n\n\nA full graph-to-disk dump (possibly at shutdown). If the deltas on disk have grown considerably larger than the actual graph, it might make sense to discard all logs and flush a perfect representation of the graph to disk to replace all historic logs.\n\n\n\nInteresting idea\n\n----------\n\n[etiennedi (2024-08-22T07:28:02.799Z)]: Thanks for coming back with the details.\nSince doubling once already showed a significant improvement, can you just keep doubling it until the logs become manageable?\n\nMay be we can manually ‘safely’ clear logs? Тo avoid ‘READONLY’ mode and long POD startup.\n\nDo you have an environment where you could test that? There is a good chance that the first n logs have information that is entirely redundant. In this case, they would indeed not be needed. However, there is also a chance that some data in there is vital for good graph integrity. In that case, you might make your search results worse.\n\nOr optionally disable (not use) it at all on startup (if index data are valid/holistic)?\n\nIf you can accept the temporary downtime to experiment, what you could do is\n\nmv main.hsnw.commitlog.d main.hnsw.commitlog.d.bak\nmkdir main.hnsw.commitlog.d\nThen manually copy only the last n files (for example, the last 10)\nThen startup, if you are still happy with the search quality you can be sure that any files prior to the cutoff point can be safely deleted. If the quality suffers, you might want to retry with more files.",
    "date_created": "2024-08-12T05:11:20.589Z",
    "has_accepted_answer": false,
    "title": "WAL's folder grows unlimittely",
    "topic_id": 3332
  },
  {
    "user_id": 10545,
    "conversation": "[Johann_Conradie (2025-03-12T11:34:58.652Z)]: We are doing a POC only locally at first. But I cannot get this to work for the life of me :\nconst searchResponse = await weaviateClient.query(query);\n        const documents = searchResponse?.data?.Get?.Document;\n        if (!documents || documents.length === 0) {\n            res.status(404).json({ error: 'No relevant documents found in Weaviate' });\n            return; // 👈 Explicit return\n        }\n\nI get error that query does not exist on weaviate client.\nThis is my import code also :\nimport weaviate from ‘weaviate-client’;\nPlease help\n\n----------\n\n[Marion_Nehring (2025-03-12T13:47:34.049Z)]: Hey Johann \nI think there might be several things mixing up here.\nFirst issue could be, that you are using query on the client but in all the examples I have seen it is being used on the collection.\nSo I assume something like the following probably works better :\n\nconst collection = client.collections.get(‘MyCoolCollectionName’);\nconst searchRespose=await collection.query(query);\n\nI looked this up here: Search patterns and basics | Weaviate or Migrate from v2 to v3 | Weaviate\nalso it kind of looks like there is some mixing syntax of our old v2 TypeScript client with the v3 TypeScript client.\nIt looks like import weaviate from ‘weaviate-client' is using the new v3 package, whereas the way you are viewing the existing object is rather the old syntax. (SearchResponse?.data?…. )\nYou can inspect the returned object like this: Migrate from v2 to v3 | Weaviate\nWhere response.objects[0].properties will return the first object’s properties.\nI hope this helps you",
    "date_created": "2025-03-12T11:34:58.605Z",
    "has_accepted_answer": false,
    "title": "[Question] Query weaviate",
    "topic_id": 18899
  },
  {
    "user_id": 3173,
    "conversation": "[Yezer_Gonzalez (2025-01-08T16:04:38.383Z)]: Description\n\nI’m performing hybrid search and in some cases, the scoring curve is like the attached image. I can imagine autocut here is not effective. Does anybody know what the algorithm exactly is?\nScreenshot 2025-01-08 at 15.59.263024×718 131 KB\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAdditional operators | Weaviate\n\n  Syntax\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThank you in advance\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[Mohamed_Shahin (2025-01-16T09:39:29.494Z)]: Hi @Yezer_Gonzalez,\nIt’s lovely to have you with us, and welcome to our community!\nAutocut helps to balance the influence of both vector and keyword-based relevance scores in your search results. If you’re experiencing not effective outcome, try tuning your hybrid search.\nAlgorithms:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nSearch operators | Weaviate\n\n  Leverage search operators in Weaviate's GraphQL API for targeted data retrieval.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nMore about:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate\n\n  Hybrid search combines vector search and keyword search (BM25) to leverage the strengths of both approaches. This takes into account results' semantic similarity (vector search) and exact keyword relevance (BM25), providing more comprehensive search...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBest regards,\nMohamed Shahin\nWeaviate Support",
    "date_created": "2025-01-08T16:04:38.329Z",
    "has_accepted_answer": false,
    "title": "Is autocut effective in scoring curves where the jumps are indistinguishable",
    "topic_id": 9636
  },
  {
    "user_id": 3185,
    "conversation": "[AnnTade (2025-02-20T15:11:04.424Z)]: I have an existing schema in weaviate that contains many objects. Recently, I’ve updated my schema with another property (Boolean). I want to add an indexing property in my schema - index_null_state=True. However, my question is, how do I add this property to my existing schema which already has objects, without messing up anything?\n\n----------\n\n[DudaNogueira (2025-02-20T16:27:48.580Z)]: hi @AnnTade !\nUnfortunately, you can’t.\nNot all collection configurations are mutable. And this one is not.\nCheck here for a list of mutable configurations:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection definition | Weaviate\n\n  Schema Configuration in Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThe path here is about creating a collection with all the changes you need and migrate your data over.\nHere we have a guide on how to migrate your data:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Learn how to migrate data within Weaviate for easy data handling.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2025-02-20T15:11:04.364Z",
    "has_accepted_answer": false,
    "title": "Adding indexing property to an existing schema",
    "topic_id": 10478
  },
  {
    "user_id": 848,
    "conversation": "[sanjeev1678 (2024-09-05T09:00:55.791Z)]: Hello Team\nI am getting this error, when I am running weaviate backup(.create) method.\nThe block list may not contain more than 50,000 blocks.\\nERROR CODE: BlockListTooLong\\n--------------------------------------------------------------------------------\\n\\ufeff<?xml version=\"1.0\" encoding=\"utf-8\"?>BlockListTooLongThe block list may not contain more than 50,000 blocks.\nThis is a big dataset, and I believe this has something to do with the data block size and chunking issue.\nPlease let me know how I can fix this issue\n\nWeaviate Server Version:\nDeployment Method: Kubernetes\nNumber of Running Nodes: One node\nWeaviate Version: 1.25.0\n\n----------\n\n[DudaNogueira (2024-09-05T12:47:04.336Z)]: hi @sanjeev1678 !\nWhat is the backup module you are using?\nI did a search, and this error points to Azure: is it backup-azure?\nLet me know if it is Azure indeed.\nThanks!\n\n----------\n\n[sanjeev1678 (2024-09-05T13:47:43.407Z)]: Hello @DudaNogueira\nThanks for responding. Yes this backup-azure.\nPlease let me know if anything else needed.\n\n----------\n\n[Damien_Gasparina (2025-01-07T08:59:41.462Z)]: Hi @sanjeev1678 ,\nFollowing back this topic, I think Add environment overrides for azure blocksize and concurrency by donomii · Pull Request #6468 · weaviate/weaviate · GitHub should have fix this issue.\nIt’s should be included in the latest release. Default block sized also changed to int64(40 * 1024 * 1024)\n\n----------\n\n[sanjeev1678 (2025-03-26T08:07:17.623Z)]: Hello @Damien_Gasparina/@DudaNogueira,\nThanks for your response.\nWe are deploying Weaviate using a Helm chart and would like to request the addition of the AZURE_BLOCK_SIZE and AZURE_CONCURRENCY environment variables in helm chart as well.\nPlease let me know if any further details are needed.\n\n----------\n\n[DudaNogueira (2025-03-26T14:03:59.786Z)]: hi @sanjeev1678 !\nThanks for pointing it out. I have just documented those env vars:\nI have just documented those variables:\n  \n\n      github.com/weaviate/weaviate-io\n  \n\n  \n    \n\n\n\n    \n      \n    \n\n  \n\n\n\n      \n        Document azure backup blocksize and concurrency env vars and client header parameter\n      \n\n    \n      main ← add-azure-backup-blocksize-and-concurrency\n    \n\n      \n        \n          opened 02:01PM - 26 Mar 25 UTC\n        \n\n        \n          \n            \n            dudanogueira\n          \n        \n\n        \n          \n            +9\n            -1\n          \n        \n      \n  \n\n\n  \n    ### What's being changed:\nDocumented the new environment variables introduced o…n this PR: https://github.com/weaviate/weaviate/pull/6468\n`AZURE_BLOCK_SIZE`, `AZURE_CONCURRENCY` and a note about using `X-Azure-Block-Size` and `X-Azure-Concurrency` as client header parameters\n\n\n\n### Type of change:\n\n\n\n- [x] **Documentation** updates (non-breaking change to fix/update documentation)\n- [ ] **Website** updates (non-breaking change to update main page, company pages, pricing, etc)\n- [ ] **Content** updates – **blog**, **podcast** (non-breaking change to add/update content)\n- [ ] **Bug fix** (non-breaking change to fixes an issue with the site)\n- [ ] **Feature** or **enhancements** (non-breaking change to add functionality)\n\n### How Has This Been Tested?\n\n\n\n- [ ] **GitHub action** – automated build completed without errors\n- [x] **Local build** - the site works as expected when running `yarn start`\n\n> note, you can run `yarn verify-links` to test site links locally\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nRegarding our helm, you can pass those variables in values.yaml here:\n  \n\n      github.com/weaviate/weaviate-helm\n  \n\n  \n    weaviate/values.yaml\n\n\n  16faed309\n\n\n\n\n    \n      \n              # - api-key-user-readOnly\n          \n          query_defaults:\n            limit: 100\n          debug: false\n          \n          \n          # Insert any custom environment variables or envSecrets by putting the exact name\n          # and desired value into the settings below. Any env name passed will be automatically\n          # set for the statefulSet.\n          env:\n            CLUSTER_GOSSIP_BIND_PORT: 7000\n            CLUSTER_DATA_BIND_PORT: 7001\n          \n            # Set RAFT cluster expected number of voter nodes at bootstrap.\n            # By default helm automatically sets this value based on the cluster size.\n            # RAFT_BOOTSTRAP_EXPECT: 1\n          \n            # Set RAFT cluster bootstrap timeout (in seconds), default is 600 (seconds)\n            # which should be sufficient for most of the deployments.\n            RAFT_BOOTSTRAP_TIMEOUT: 600\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!",
    "date_created": "2024-09-05T09:00:55.721Z",
    "has_accepted_answer": true,
    "title": "Weaviate Backup - 50,000 blocks ERROR CODE: BlockListTooLong",
    "topic_id": 3982
  },
  {
    "user_id": 1302,
    "conversation": "[wvuser (2024-08-18T19:38:18.502Z)]: Description\nWe have a weaviate cluster with 3 nodes.\nAverage request latency (crud/vsearch+QUORUM) 10-70ms.\nWhen one node fails (or a pod  restarts), eg: “weaviate-2”, the requests latency  increases to 10sec for all requests directed to “weaviate-1” (visible in the log). But all requests directed to “weaviate-0” remain fast (10-70ms). Regardless of which node is down: one remaining node is “slow” and the other is “fast”. This both valid for single requests or high load…\n41102×220 15.7 KB\nServer Setup Information\n\nWeaviate Server Version: 1.25.6\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3 nodes (repl.factor=3)\nClient Language and Version: Python3, PythonClient3\nMultitenancy?: No\n\nAny additional Information\n“replicationConfig”: {\n“factor”: 3\n},\nenv:\n- name: RAFT_JOIN\nvalue: weaviate-0,weaviate-1,weaviate-2\n- name: RAFT_BOOTSTRAP_EXPECT\nvalue: ‘3’\nresources:\nlimits:\ncpu: ‘50’\nmemory: 500Gi\nrequests:\ncpu: ‘50’\nmemory: 500Gi\n\n----------\n\n[etiennedi (2024-08-19T07:29:31.824Z)]: Hi @wvuser,\nThanks for the report. You are correct, this is definitely unexpected. If a QUORUM can still be achieved and you only send your requests to nodes that report ready, there is no reason for a delay – especially not such a massive one.\nI’ll ping a few folks from our DB Core team to help narrow this down. They will probably ask you a few more detailed questions about the setup.\nIs the problem you are describing reproducible? If so a minimal reproducing example would be highly appreciated, as that can speed up a potential fix.\nBest,\nEtienne\n\n----------\n\n[Jose_Luis_Franco (2024-08-19T09:24:24.589Z)]: Hello @wvuser,\nThis is José Luis, QA at Weaviate. Thanks a lot for reporting this issue. I did manage to reproduce it with the steps you provided.\nThe good news is that this issue has been already fixed by one of our core developers and it’s on its way to the next release 1.25.12 (I managed to reproduce it in 1.25.11, but couldn’t reproduce it on the candidate release for 1.25.12). So updating to the upcoming 1.25.12 (it will be released along the week) should get rid of the high latencies during pod restarts.\nOnce more, thanks for your feedback and for reporting the issue, it’s very valuable to us and the whole community.\nRegards,\nJosé Luis\n\n----------\n\n[wvuser (2024-08-23T05:27:17.947Z)]: Hi!\n\n\n\n Jose_Luis_Franco:\n\nThe good news is that this issue has been already fixed by one of our core developers and it’s on its way to the next release 1.25.12\n\n\nUpdating to v.1.25.12 fixed the problem, thanks. But there are some comments/questions:\nThis env. variables must be explicitly specified (1.25.6 works fine without  them, other def.values?) for cluster’s fault tolerance:\nDISABLE_LAZY_LOAD_SHARDS: ‘true’ (mandatory)\nHNSW_STARTUP_WAIT_FOR_VECTOR_CACHE: ‘true’\nOtherwise the system does not respond to any requests (infinite read timeout?). All pods quickly restarts sequentally (~1min), report ‘ready’ to k8s and begin shards/logs loading. But at this time (all at ‘hnsw_deserialization’ state?) requests hang (no response).\n\n----------\n\n[wvuser (2024-08-28T06:25:23.270Z)]: Hello @Jose_Luis_Franco!\n\n\n\n Jose_Luis_Franco:\n\nThe good news is that this issue has been already fixed by one of our core developers and it’s on its way to the next release 1.25.12\n\n\nIs this fix available in version 1.26.1 (Jul 23)?\nWe have a problem with replica’s synchronization (not fixed ‘deletes’ when nodes failed/restarts) and manual ‘async-read-all’ not helps. We are thinking about upgrade to 1.26.",
    "date_created": "2024-08-18T19:38:18.445Z",
    "has_accepted_answer": true,
    "title": "Explosive growth (to 10sec) of request latency when one cluster's node fails",
    "topic_id": 3391
  },
  {
    "user_id": 1090,
    "conversation": "[jadam (2024-08-13T23:00:38.829Z)]: Description\nWhen running my python script (in an AWS fargate container) I get an invalid port error httpx.InvalidURL: Invalid port: '\"https:' when trying to connect with my cloud cluster. When I run my script locally it works just fine, read and writes with no issue.\nMy cloud url env var is formatted like following, just copied directly from the cloud settings:\nWEAVIATE_URL=https://CLUSTER_ID_HERE.c0.us-central1.gcp.weaviate.cloud \nThis is how I am creating a client:\n    WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\", \"\")\n    WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\", \"\")\n\n    client = weaviate.connect_to_weaviate_cloud(\n        cluster_url=WEAVIATE_URL,\n        auth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n    )\n\nI have dropped in print statements to confirm the env var is getting pulled in correctly, which it is.\nServer Setup Information\n\n\nWeaviate Server Version:\n\n\n1.25.10\n\n\nDeployment Method:\n\n\nAWS fargate under ECS and ECR\n\n\nMulti Node? Number of Running Nodes:\n\n\nClient Language and Version:\n\n\nMultitenancy?:\n\n\nAny additional Information\n\nFull cloudwatch logs:\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/httpx/_urlparse.py\", line 346, in normalize_port\n2024-08-13T17:33:10.665Z\nport_as_int = int(port)\n2024-08-13T17:33:10.665Z\nValueError: invalid literal for int() with base 10: '\"https:'\n2024-08-13T17:33:10.665Z\nDuring handling of the above exception, another exception occurred:\n2024-08-13T17:33:10.665Z\nTraceback (most recent call last):\n2024-08-13T17:33:10.665Z\nFile \"/app/src/main.py\", line 5, in <module>\n2024-08-13T17:33:10.665Z\nfrom utils import process_batch\n2024-08-13T17:33:10.665Z\nFile \"/app/src/utils.py\", line 19, in <module>\n2024-08-13T17:33:10.665Z\nclient = weaviate.connect_to_weaviate_cloud(\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/connect/helpers.py\", line 79, in connect_to_weaviate_cloud\n2024-08-13T17:33:10.665Z\nreturn __connect(\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/connect/helpers.py\", line 410, in __connect\n2024-08-13T17:33:10.665Z\nraise e\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/connect/helpers.py\", line 406, in __connect\n2024-08-13T17:33:10.665Z\nclient.connect()\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/syncify.py\", line 23, in sync_method\n2024-08-13T17:33:10.665Z\nreturn _EventLoopSingleton.get_instance().run_until_complete(\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/event_loop.py\", line 40, in run_until_complete\n2024-08-13T17:33:10.665Z\nreturn fut.result()\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 446, in result\n2024-08-13T17:33:10.665Z\nreturn self.__get_result()\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n2024-08-13T17:33:10.665Z\nraise self._exception\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/client_base.py\", line 152, in connect\n2024-08-13T17:33:10.665Z\nawait self._connection.connect(self._skip_init_checks)\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/connect/v4.py\", line 158, in connect\n2024-08-13T17:33:10.665Z\nmeta = await self.get_meta()\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/connect/v4.py\", line 587, in get_meta\n2024-08-13T17:33:10.665Z\nresponse = await self.get(path=\"/meta\")\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/connect/v4.py\", line 546, in get\n2024-08-13T17:33:10.665Z\nreturn await self.__send(\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/connect/v4.py\", line 467, in __send\n2024-08-13T17:33:10.665Z\nraise e\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/weaviate/connect/v4.py\", line 448, in __send\n2024-08-13T17:33:10.665Z\nreq = self._client.build_request(\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/httpx/_client.py\", line 345, in build_request\n2024-08-13T17:33:10.665Z\nurl = self._merge_url(url)\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/httpx/_client.py\", line 375, in _merge_url\n2024-08-13T17:33:10.665Z\nmerge_url = URL(url)\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/httpx/_urls.py\", line 115, in __init__\n2024-08-13T17:33:10.665Z\nself._uri_reference = urlparse(url, **kwargs)\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/httpx/_urlparse.py\", line 248, in urlparse\n2024-08-13T17:33:10.665Z\nparsed_port: int | None = normalize_port(port, scheme)\n2024-08-13T17:33:10.665Z\nFile \"/usr/local/lib/python3.9/site-packages/httpx/_urlparse.py\", line 348, in normalize_port\n2024-08-13T17:33:10.665Z\nraise InvalidURL(f\"Invalid port: {port!r}\")\n2024-08-13T17:33:10.665Z\nhttpx.InvalidURL: Invalid port: '\"https:'\n\nhttpx.InvalidURL: Invalid port: '\"https:'\n\nDocker compose file in the repo, though this part confuses me as I don’t see why we need this. Before we were running a local cluster, but have since changed to use the weaviate cloud service. So seems like this isn’t doing anything. I’m new to Vector DBs and rubbish with Docker… sorry.\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.5\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: ''\n      ENABLE_MODULES: ''\n      CLUSTER_HOSTNAME: 'node1'\nvolumes:\n  weaviate_data:\n...\n\n----------\n\n[jadam (2024-08-14T15:37:21.821Z)]: SOLVED \nSo dumb, it was how env vars were being set in AWS. They were set using the Secret Managers default “Key/value” option rather than the “Plaintext” option.\n\n----------\n\n[DudaNogueira (2024-08-15T18:24:11.051Z)]: Hi @jadam !!\nTHanks for sharing",
    "date_created": "2024-08-13T23:00:38.771Z",
    "has_accepted_answer": true,
    "title": "Invalid port - aws",
    "topic_id": 3345
  },
  {
    "user_id": 865,
    "conversation": "[justin.godden (2024-06-05T08:39:20.420Z)]: Hi, how do I filter searches by date using the python client?\nI can see in the docs how to filter by internal datetime objects: link\nWhich mentions you must set indexTimestamps to true to track these meta timestamps: Link\nBut I don’t see anything on how to filter by a user defined timestamp.\nI have a field published_at defined as such:\n...\nwc.Property(\n        name=\"published_at\",\n        data_type=wc.DataType.DATE,\n        index_searchable=False,\n        skip_vectorization=True,\n    ),\n...\n\nWhich is returned in the graphql client as a datetime: \"published_at\": \"2024-04-22T08:16:47Z\",\nIn my index I may have some published_at times that are in the future that I don’t want to retrieve. I would like to filter less than or equal to today’s date (or less than tomorrow’s date).\nHow is this done using the python client?\nThanks\n\n----------\n\n[justin.godden (2024-06-05T09:03:49.741Z)]: Solved it using regular property filter and a datetime. For anyone that may find it useful:\ndef get_tomorrow_midnight() -> datetime:\n    now = datetime.now()\n    tomorrow = now + timedelta(days=1)\n    midnight = datetime(tomorrow.year, tomorrow.month, tomorrow.day)\n    return midnight\n\nresponse = collection.query.hybrid(\n            ...,\n            filters=wq.Filter.by_property(\"published_at\").less_than(\n                get_tomorrow_midnight()\n            ),\n        )\n\nMay be worth adding something to the docs, as currently the only datetime filtering in the docs is displaying how to filter on weaviate’s meta timestamps, not user-defined ones (unless I missed it).\nCheers\n\n----------\n\n[DudaNogueira (2024-06-05T11:54:10.364Z)]: hi @justin.godden !\nThanks for sharing and pointing it out.\nAt the end of the day, the indexTimestamps fields are just a date field as published_at are \nSo all date filters will also apply to both meta properties and the ones you define.\nThanks!\n\n----------\n\n[justin.godden (2024-06-05T12:28:26.170Z)]: DudaNogueira:\n\nSo all date filters will also apply to both meta properties and the ones you define.\nThanks!\n\n\nHi Duda,\nThe only point I was making was the only example of datetime filtering in the docs is using a built-in method specifically for the meta properties - by_creation_time - from the first link: filters=wvc.query.Filter.by_creation_time().greater_or_equal(year2k)\nUnless I missed it, I didn’t see anywhere explaining filtering user defined datetimes. Perhaps it’s implied since you can do value comparison with datetimes already in python (just like using less than for strings works also).\nJust my experience that I didn’t find it clear. Up to you if you want to act on that.\nCheers\n\n----------\n\n[Dirk (2024-06-05T13:22:54.659Z)]: we will add some examples\n\n----------\n\n[DudaNogueira (2024-06-05T13:35:56.797Z)]: Oh! Got it.\nIt indeed makes sense to have an explicit example there as well as the reference for the meta properties.\nThanks!!\n\n----------\n\n[SoftwearEnginear (2024-07-12T02:29:46.109Z)]: I am having issues trying to filter results by date here.\nI want to filter out documents that are earlier than 2024-07-11, but somehow documents are not filtered. When I printed the response, I can see dates earlier than 2024-07-11 are still appearing.\nExpected retrieved documents should be only be 2024-07-11 or later.\nPlease let me know if there is a straightforward way to do this:\nimport weaviate\nfrom datetime import datetime, timezone, timedelta\nfrom weaviate.classes.query import MetadataQuery, Filter\n\nclient = weaviate.connect_to_local()\n\ndef format_to_RFC3339_date(date_str):\n  date_obj = datetime.striptime(date_str, \"%Y-%m-%d\")\n  offset = timezone(timedelta(hours=8))\n  rfc3339_date_with_offset = date_obj.replace(tzinfo=offset).isoformat()\n  return rfc3339_date_with_offset\n\ntry:\n  date_str = \"2024-07-11\"\n  formatted_date = format_to_RFC3339_date(date_str)\n\n  collection = client.collections.get(\"LlamaIndex\")\n  response = collection.query.hybrid(\n    ...,\n    filters=Filter.by_property('creation_date').greater_or_equal(formatted_date),\n    return_metadata=MetadataQuery(\n      distance=True,\n      certainty=True,\n      score=True,\n      explain_score=True,\n    )\n\n  for obj in response.objects:\n    print(obj.properties['creation_date']\n\n----------\n\n[DudaNogueira (2024-07-15T17:06:43.645Z)]: Hi! You should use timestamps.\ncheck here a simple reproducible example:\nimport weaviate\nimport os\nfrom weaviate import classes as wvc\n\nclient = weaviate.connect_to_local()\n\nclient.collections.delete(\"Collection\")\ncollection = client.collections.create(\n    \"Collection\",\n    properties=[\n        wvc.config.Property(name=\"som_date\", data_type=wvc.config.DataType.DATE),\n        wvc.config.Property(name=\"some_text\", data_type=wvc.config.DataType.TEXT)\n    ]\n)\ncollection.data.insert(\n    {\n        \"some_text\": \"2024-05-05\", \n        \"some_date\": \"2024-05-05T23:20:50.52Z\"\n    }\n)\ncollection.data.insert({\n        \"some_text\": \"2024-06-06\", \n        \"some_date\": \"2024-06-06T23:20:50.52Z\"\n    }\n)\n\nfrom weaviate.classes.query import Filter\nquery = collection.query.fetch_objects(\n    filters=Filter.by_property(\"some_date\").greater_or_equal(\"2024-05-10T23:20:50.52Z\")\n)\nfor object in query.objects:\n    print(object)\n\nLet me know if this helps.\nThanks!\n\n----------\n\n[SoftwearEnginear (2024-07-18T01:11:18.057Z)]: Hi @DudaNogueira,\nI’m currently inserting data using LlamaIndex and I assumed I could use node.metadata to filter by dates.\nfor obj in response.objects:\n     print(obj.properties.keys()) \n# dict_keys([_node_type', 'content', 'page_label', 'last_modified_date', ..., 'creation_date', ... ])\n\nIs there really no way to use this metadata for filtering? My users have inserted a significant number of documents, and I’d prefer not to delete the collection and ingest the data again.\nThank you!\nEdit:\nI have found a solution that actually have to modify how LlamaIndex queries with Weaviate.\nAlthough this have resolved my issue with integration, but still does not give me an idea how to query direct with Weaviate using the node.metadata['last_modified_date] | obj.properties['last_modified_date'].\n\n----------\n\n[DudaNogueira (2024-07-19T16:16:43.910Z)]: Hi! In order to filter for create or modified date, you need to explicitly set the collection to do so:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection schema | Weaviate - Vector Database\n\n  Introduction\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nUnfortunatelly, when using llamaindex or langchain, it will create the collection for your.\nWhat you can do is to create the collection beforehand, setting all the options you want, and then using llamaindex/langchain.\nAlso, on that same issue, when creating the collection “outside” of llamaindex/langchain, it is a good idea to set the vectorizer too.\nThat way you can both use those llm frameworks or query Weaviate directly.\nI have crafted a nice recipe here that ilustrates that (using langchain)\nhttps://github.com/weaviate/recipes/tree/main/integrations/langchain/loading-data\nLet me know if that helps.\nThanks!\nLet me know if this helps.",
    "date_created": "2024-06-05T08:39:20.362Z",
    "has_accepted_answer": true,
    "title": "How to filter by date field",
    "topic_id": 2618
  },
  {
    "user_id": 2267,
    "conversation": "[pavan (2024-10-27T23:17:01.033Z)]: Hi all, I want to integrate weaviate with starling(open source) or Aisaq for the indexing. To measure the performance . Has anyone tried  integrating the above open source indexing with weaviate?\n\n----------\n\n[DudaNogueira (2024-10-28T18:03:44.121Z)]: hi @pavan !!\nWelcome to our community \nI am not aware of a tool that would integrate those tools you mentioned.\nI would suggest your to check our spark connector, as this is a popular tool used for this kind of scenario:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nLoad data into Weaviate with Spark | Weaviate\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-10-27T23:17:00.980Z",
    "has_accepted_answer": false,
    "title": "Need to integrate weaviate with Starling or AiSAQ for indexing",
    "topic_id": 6862
  },
  {
    "user_id": 571,
    "conversation": "[Mike_Hudson (2024-02-29T19:16:10.311Z)]: In my RAG application I use Flowise to upsert a text file which is then chunked into documents of fixed chunk size. The embeddings for these chunks are stored in Weaviate. I ask a question via Flowise, which sends the question’s embeddings to Weaviate as a query. Weaviate retrieves the text chunk with the closest vector similarity to my question. All good. But how can I then query Weaviate to also retrieve the two text chunks which are located before and after that chunk in the original file? The idea is to use small chunks in the VDB for precision, but to bring (selectably) wider context back into the LLM for better reasoning.\n\n----------\n\n[DudaNogueira (2024-02-29T19:33:58.663Z)]: Hi Mike!\nThis is not possible. Also, the query should already bring those chunks, if they are relevant enough to your query, considering you have small chunks, you should be able to pass forward to the generation a bigger number of chunks.\nI believe you want to tweak the chunking size and the overlap, so it has enough context before and after.\nHave you seen this material we have on that subject?\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nChunking long texts | Weaviate - Vector Database\n\n  Unit overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.\n\n----------\n\n[Mike_Hudson (2024-02-29T20:08:10.000Z)]: Hi Duda,\nLet me try to explain more clearly. I want to use small chunks because it gives more specific similarity search results – increasing the chunk size is therefore not an option, and adjusting overlap does not solve the problem. Whenever I get a ‘hit’ on cosine similarity for a chunk, I want to retrieve that chunk and also the two chunks which are contiguous to that chunk. So, for example, let’s say I upload a book which is chunked and embedded at paragraph level. When I query the VDB if my query matches a particular paragraph I would ideally like to retrieve the whole page of the book, not just the matching paragraph. But I don’t have the concept of a page, and so as a work-around I want to get the paragraphs immediately before and after the matching paragraph. Let’s says I query the VDB and get a hit on paragraph “B”. I would also want to retrieve paragraphs A and C – even though they may not match at all for cosine similarity - I want the whole block of text A-B-C.\nI guess what this comes down to is how Weaviate stores the original text; whether contiguous chunks of text have a numbering system which reflects the order in which they were upserted, so that if the three paragraphs ABC were numbered 123 then paras A and B could perhaps be retrieved as para 2-1=1 and para 2+1=3. Vectara does something similar to this: “x sentences before and x sentences after” a matching sentence.\n\n----------\n\n[DudaNogueira (2024-02-29T20:32:15.563Z)]: One thing that could be worth trying, is doing 2 queries.\nSo first query, will get the topX objects.\nWhen you chunk those, you save the position of the chunk.\nBased on the topX chunks, you do a second query to also select the -1 +1 chunk position of the topX chunks.\nThe downside of this approach is that for generating the answer, you would have to consume the generative api yourself at code level, as you would need to “reaugment” your context window.\nLet me know if this helps.\n\n----------\n\n[Mike_Hudson (2024-02-29T21:12:32.000Z)]: Thanks Duda but I’m not sure I follow. Do you mean that Weaviate does not store the ordinal number of the chunks as they are upserted? Or are you saying that the matching chunk does have a stored ordinal number and that I should therefore:\n\nQuery Weavitate and get the chunk that matches by cosine sim;\nQuery Weaviate for that matching chunk’s ordinal number x; and\nUse that ordinal number to query Weaviate for the (possibly non-matching) chunks of ordinal number x-1 and x+1?\n\n(To make things simple let’s just assume that Top_k=1 – only one matching chunk to be retrieved, plus the chunk before and after it)\n\n----------\n\n[SomebodySysop (2024-06-05T11:03:18.750Z)]: I just had this very same thought today and Googled it and this post came up first.  I sort of figured Weaviate would have a way to do this.  Perhaps in the past 4 months they have developed something.\nBut, I was thinking of a workaround.  In my class I have a property called “docId”, which contains information about the embedding relative to it’s identifiers in my local filesystem.  In this docId is a delta, which is the sequential number of the chunk relative to it’s parent document.  So, for example, if each chunk was a paragraph, the first paragraph would have the delta 0, the following paragraph would have the delta 1, and so on.\nWhat this means is that if I do a cosine similarity search and retrieve a chunk with a high score, I could use it’s docId to retrieve the sequential chunk before it (if one exists) and the one after (if one exists) using a filtered query.  I believe this is exactly what you want to do:\n\n\n\n Mike_Hudson:\n\n\nQuery Weavitate and get the chunk that matches by cosine sim;\nQuery Weaviate for that matching chunk’s ordinal number x; and\nUse that ordinal number to query Weaviate for the (possibly non-matching) chunks of ordinal number x-1 and x+1?\n\n\n\nWhat solution did you eventually come up with?\n\n----------\n\n[SomebodySysop (2024-06-09T20:30:33.065Z)]: Found it!  Small-to-Big RAG Retrieval\n\n  \n      \n\n      Medium – 5 Nov 23\n  \n\n  \n    \n\nAdvanced RAG 01: Small-to-Big Retrieval\n\n  Child-Parent RecursiveRetriever and Sentence Window Retrieval with LlamaIndex\n\n  \n    Reading time: 7 min read\n\n----------\n\n[DudaNogueira (2024-06-10T20:55:17.896Z)]: Hi!\nOh… that’s interesting!\nTHanks for sharing\n\n----------\n\n[SomebodySysop (2024-08-28T06:58:38.285Z)]: Just a follow up to this discussion.\nIn addition to implementing my own Semantic Chunking strategy: Using gpt-4 API to Semantically Chunk Documents - #166 by SomebodySysop as well as Small-to-Big chunk retrieval (for better chunk context): Advanced RAG 01: Small-to-Big Retrieval | by Sophia Yang, Ph.D. | Towards Data Science\nI also deployed the “Deep Dive” strategy (RAG is failing when the number of documents increase - #5 by SomebodySysop - API - OpenAI Developer Forum). Essentially, I take the top 50 (or even 100) cosine similarity search results returned by Weaviate, and rate each chunk based upon it’s relationship to the actual question asked. I do one chunk at a time, which ensures the best model response. I then return the highest rated chunks together as context to the model for a complete answer.\nUsing OpenAI’s new text-embedding-3-large embed model.\nNot only is this process faster than I thought it was going to be (since each API call only returns a single rating number, in my case 0-10), but also far less expensive than I imagined (especially with the new gpt-4o-mini and gemini-1.5-flash models).\nThis works amazingly well.  it turned out to be the key to my issues with getting “comprehensive” responses.\nHope this helps someone else!\n\n----------\n\n[SomebodySysop (2024-08-28T07:07:18.701Z)]: Mike_Hudson:\n\n\nQuery Weavitate and get the chunk that matches by cosine sim;\nQuery Weaviate for that matching chunk’s ordinal number x; and\nUse that ordinal number to query Weaviate for the (possibly non-matching) chunks of ordinal number x-1 and x+1?\n\n\n\nI am doing exactly this.  However, you have to do it programmatically and  it requires that you supply the ordinal numbers in your object properties metadata.  So, when you retrieve a chunk, you can then also retrieve the preceding and following chunks.\nI created a method in PHP called getComprehensiveData() which executes this process.  Here is my ChatGPT chat on the subject: https://chatgpt.com/share/ee2bce35-0828-442e-b595-6a922caec14c\nIn my metadata, these “ordinal” numbers are referred to as “docIds”.\nIf you haven’t yet implemented something like this, give it a try.  It works beautifully in providing more context to your retrieved chunks.\n\n----------\n\n[Dirk (2024-08-28T11:47:10.033Z)]: Haven’t tested it out, but how about you add a new reference property “adjacentChunks”, add references to the chunks that you want to set as related and then also return the content of the referenced objects .\nSee here: Manage relationships with cross-references | Weaviate - Vector Database\n\n----------\n\n[SomebodySysop (2024-09-13T23:18:55.991Z)]: So, it appears that Weaviate has addressed this issue more directly:\n\n  \n      \n\n      weaviate.io – 5 Sep 24\n  \n\n  \n    \n\nLate Chunking: Balancing Precision and Cost in Long Context Retrieval | Weaviate\n\n  Learn about Late Chunking and how it may be the right fit for balancing cost and performance in your long context retrieval applications\n\n----------\n\n[kgorazda (2025-02-19T10:28:15.024Z)]: Hello everyone! I am working on a very similar problem and I am using the same strategy as most of you:\n\n\n\n Mike_Hudson:\n\n\nQuery Weavitate and get the chunk that matches by cosine sim;\nQuery Weaviate for that matching chunk’s ordinal number x; and\nUse that ordinal number to query Weaviate for the (possibly non-matching) chunks of ordinal number x-1 and x+1?\n\n\n\nHowever, I was thinking that it seems like there is a good strategy for retrieving adjacent chunks in Verba in their “context window”. It seems that they are creating separate collections for source documents and chunks, with cross-references between them. Has anyone tried this approach?",
    "date_created": "2024-02-29T19:16:10.269Z",
    "has_accepted_answer": true,
    "title": "Retrieving “Adjacent” Chunks for Better Context",
    "topic_id": 1603
  },
  {
    "user_id": 3657,
    "conversation": "[franz_hals (2025-03-03T21:55:20.222Z)]: Description\nHi guys,\nI am trying to setup weaviate as a single node in AWS ECS Fargate. I want to use an EFS to store Weaviate date if the ECS tasks needs to restart etc.\nAnyhow, when using “PERSISTENCE_DATA_PATH” = “/var/lib/weaviate” as an environment parameter in the Task definition, I am repeatedly getting the error “attempted to join and failed” after task startup until the task ultimately fails.\nIt seems like it works again after I delete all contents from the EFS - until the task gets restartet, then the error comes up again.\nDrives me crazy, I would be really happy if you could help me… Below you will find my configurations.\nServer Setup Information\n\nWeaviate Server Version: 1.29\nDeployment Method: \nMulti Node? No\nClient Language and Version:\nMultitenancy?: No\n\nAny additional Information\nThis is my ECS Fargate Task definition for the ECR container (which contains an umodified image of weaviate 1.29):\n{\n“family”: “weaviate-task”,\n“containerDefinitions”: [\n{\n“name”: “weaviate”,\n“image”: “xxx.dkr.ecr.eu-west-1.amazonaws.com/weaviate:latest”,\n“cpu”: 0,\n“memoryReservation”: 2048,\n“portMappings”: [\n{\n“containerPort”: 8080,\n“hostPort”: 8080,\n“protocol”: “tcp”\n},\n{\n“containerPort”: 50051,\n“hostPort”: 50051,\n“protocol”: “tcp”\n},\n{\n“containerPort”: 8300,\n“hostPort”: 8300,\n“protocol”: “tcp”\n}\n],\n“essential”: true,\n“environment”: [\n{\n“name”: “AZURE_APIKEY”,\n“value”: “xxx”\n},\n{\n“name”: “http_proxy”,\n“value”: “xxx:8080”\n},\n{\n“name”: “no_proxy”,\n“value”: “xxx,localhost,127.0.0.1,xxx”\n},\n{\n“name”: “ENABLE_MODULES”,\n“value”: “text2vec-azure-openai”\n},\n{\n“name”: “https_proxy”,\n“value”: “xxx”\n},\n{\n“name”: “PERSISTENCE_DATA_PATH”,\n“value”: “/var/lib/weaviate”\n},\n{\n“name”: “DEPLOYMENT_ID”,\n“value”: “xxx”\n},\n{\n“name”: “RESOURCE_NAME”,\n“value”: “xxx”\n}\n],\n“mountPoints”: [\n{\n“sourceVolume”: “weaviate-efs-volume”,\n“containerPath”: “/var/lib/weaviate”,\n“readOnly”: false\n}\n],\n“volumesFrom”: ,\n“logConfiguration”: {\n“logDriver”: “awslogs”,\n“options”: {\n“awslogs-group”: “/ecs/weaviate-task”,\n“mode”: “non-blocking”,\n“awslogs-create-group”: “true”,\n“max-buffer-size”: “25m”,\n“awslogs-region”: “eu-west-1”,\n“awslogs-stream-prefix”: “ecs”\n}\n},\n“systemControls”: \n}\n],\n“executionRoleArn”: “arn:aws:iam::xxx:role/ecsTaskExecutionRole”,\n“networkMode”: “awsvpc”,\n“volumes”: [\n{\n“name”: “weaviate-efs-volume”,\n“efsVolumeConfiguration”: {\n“fileSystemId”: “fs-xxx”,\n“rootDirectory”: “/”\n}\n}\n],\n“placementConstraints”: ,\n“requiresCompatibilities”: [\n“FARGATE”\n],\n“cpu”: “1024”,\n“memory”: “3072”,\n“runtimePlatform”: {\n“cpuArchitecture”: “X86_64”,\n“operatingSystemFamily”: “LINUX”\n},\n“enableFaultInjection”: false\n}\nHere are the errors from CloudWatch that come up repeatedly until the container shuts down:\n2025-03-03T21:35:02.599Z\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“10.22.122.166:8300”],“time”:“2025-03-03T21:35:02Z”}\n2025-03-03T21:35:02.600Z\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“10.22.122.166:8300”,“status”:14,“time”:“2025-03-03T21:35:02Z”}\n2025-03-03T21:35:03.600Z\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“10.22.122.166:8300”],“time”:“2025-03-03T21:35:03Z”}\n2025-03-03T21:35:03.601Z\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“10.22.122.166:8300”,“status”:14,“time”:“2025-03-03T21:35:03Z”}\n2025-03-03T21:35:04.601Z\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“10.22.122.166:8300”],“time”:“2025-03-03T21:35:04Z”}\n2025-03-03T21:35:04.602Z\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“10.22.122.166:8300”,“status”:14,“time”:“2025-03-03T21:35:04Z”}\n2025-03-03T21:35:05.603Z\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“10.22.122.166:8300”],“time”:“2025-03-03T21:35:05Z”}\n2025-03-03T21:35:05.603Z\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“10.22.122.166:8300”,“status”:14,“time”:“2025-03-03T21:35:05Z”}\n2025-03-03T21:35:06.603Z\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“10.22.122.166:8300”],“time”:“2025-03-03T21:35:06Z”}\n2025-03-03T21:35:06.604Z\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“10.22.122.166:8300”,“status”:14,“time”:“2025-03-03T21:35:06Z”}\n\n----------\n\n[DudaNogueira (2025-03-03T22:40:51.516Z)]: franz_hals:\n\nEFS\n\n\nHi!\nAre you aware of this ou docs?\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nKubernetes | Weaviate\n\n  For a tutorial on how to use minikube to deploy Weaviate on Kubernetes, see the Weaviate Academy course, Weaviate on Kubernetes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\n\n----------\n\n[franz_hals (2025-03-04T10:11:22.500Z)]: Note to myself and others who are facing that issue:\nThe error came up in conjunction with my corporate proxy (that is required for internet access out of the VPC): the proxy was used by weaviate to somehow connect with itself (node). Solution was to add the IP range of the load balancer/ECS containers to the no_proxy environment parameter.\n\n----------\n\n[DudaNogueira (2025-03-04T13:58:13.766Z)]: hi @franz_hals !!\nThis is the kind of issue that is almost impossible to catch without this context!\nThanks for sharing! We really appreciate it!",
    "date_created": "2025-03-03T21:55:20.147Z",
    "has_accepted_answer": true,
    "title": "\"attempt to join and failed\" when using PERSISTENCE_DATA_PATH env with efs storage",
    "topic_id": 10702
  },
  {
    "user_id": 1253,
    "conversation": "[john_j (2024-07-26T18:44:25.416Z)]: Hi im using Weaviate with the text2vec-azure-openai  module. Running the 1.26.1 docker image.\nWhen i start weaviate and init my colelctions i get\n{“error”:[{“message”:“target vector \"default\": vectorizer: no module with name \"text2vec-azure-openai\" present”}]}\nclient.getMetadata() outputs\n{\nhostname: ‘http://[::]:8080’,\nmodules: {\n‘text2vec-openai’: {\ndocumentationHref: ‘…’,\nname: ‘OpenAI Module’\n}\n},\nversion: ‘1.26.1’\n}\nmy Schemas:\nname: WEAVIATE_PARENT_COLLECTION_KEY,\nmultiTenancy: {\nenabled: true,\nautoTenantCreation: true,\n},\nproperties: [\n{\nname: ‘fileId’,\ndataType: dataType.TEXT,\n},\n{\nname: ‘content’,\ndataType: dataType.TEXT,\n},\n{\nname: ‘fileName’,\ndataType: dataType.TEXT,\nindexSearchable: false,\n},\n{\nname: ‘pageNumbers’,\ndataType: dataType.INT_ARRAY,\n},\n{\nname: ‘chunkLevel’,\ndataType: dataType.TEXT,\n},\n],\n};\n(Doesnt need a Vectorizer)\n{\nname: WEAVIATE_CHILD_COLLECTION_KEY,\nvectorizers: vectorizer.text2VecAzureOpenAI({\ndeploymentID: AZURE_OPENAI_EMBEDDING_DEPOYMENT,\nresourceName: this.configService.openai.resourceName,\n}),\nmultiTenancy: {\nenabled: true,\nautoTenantCreation: true,\n},\nproperties: [\n{\nname: ‘fileId’,\ndataType: dataType.TEXT,\nindexSearchable: false,\nskipVectorization: true,\n},\n{\nname: ‘content’,\ndataType: dataType.TEXT,\n},\n{\nname: ‘contextHeader’,\ndataType: dataType.TEXT,\n},\n{\nname: ‘parentChunkId’,\ndataType: dataType.UUID,\nindexSearchable: false,\nskipVectorization: true,\n},\n{\nname: ‘chunkLevel’,\ndataType: dataType.TEXT,\nindexSearchable: false,\nskipVectorization: true,\n},\n],\n};\n\n----------\n\n[DudaNogueira (2024-07-26T23:15:24.589Z)]: hi @john_j !! Welcome to our community \nCan you provide those?\n\nWeaviate Server Version: 1.26.1\nDeployment Method: docker\nMulti Node? Number of Running Nodes: ?\nClient Language and Version: TS?\nMultitenancy?:  ?\n\nAlso, could you share some code I could use to reproduce?\nOtherwise it is hard to investigate this further.\nThanks!",
    "date_created": "2024-07-26T18:44:25.358Z",
    "has_accepted_answer": false,
    "title": "vectorizer: no module with name \\\"text2vec-azure-openai\\\" present",
    "topic_id": 3188
  },
  {
    "user_id": 2521,
    "conversation": "[Ali_Raza (2024-11-18T08:13:12.506Z)]: Description\nHi all, I am trying to run Weaviate on Mixed Arch Kube ( Arm65 and Amd64). 3-Nodes and 3 Replicas. Nodes are geographically apart (2 Nodes at one place, 1 at another).But I am constantly getting these timeouts, only for a Tenant which has almost 3GB data.\n\n{“action”:“async_replication”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“class_name”:“Question”,“hashbeat_iteration”:1679,“level”:“warning”,“msg”:“hashbeat iteration failed: collecting differences: \"10.233.84.228:7001\": connect: Post \"http://10.233.84.228:7001/replicas/indices/Question/shards/tenantA/objects/hashtree/0?schema_version=0\\”: context deadline exceeded\",“shard_name”:“tenantA”,“time”:“2024-11-18T06:48:56Z”}\n\nCan somebody please shed some light over it. I mean, what would happen if you have 300GB data, and it has to be moved from one node to another node. So even if the network is slow it should work but just take longer.\nServer Setup Information\n\nWeaviate Server Version:  1.27\nDeployment Method: Helm Chart\nMulti Node? 4\nClient Language and Version: Python, 4.9.3\nMultitenancy?: Yes\n\nAny additional Information\nimage2072×502 47.6 KB\nActivating client, sometimes works, sometime it times out, usually problem appears after offloading to s3 and then setting the client active again.\n\n----------\n\n[jeronimo_irazabal (2024-11-18T17:40:23.240Z)]: thanks for reaching out @Ali_Raza.\nWe will review async replication connectivity in slow networking.\nWould you mind opening an issue in weaviate github repo?\n\n----------\n\n[Ali_Raza (2024-11-19T08:11:35.777Z)]: @jeronimo_irazabal sure. I am updating my complete journey on github issue.\nAsync_replication context deadline exceeded, unable to Activate Tenant · Issue #6380 · weaviate/weaviate\nso far, it seems like python client module has a potential to corrupt the complete weaviate pod.\n\n----------\n\n[jeronimo_irazabal (2024-12-19T12:44:28.915Z)]: This issue should be solved as of release 1.26.13  and 1.27.9",
    "date_created": "2024-11-18T08:13:12.447Z",
    "has_accepted_answer": false,
    "title": "Async_replication context deadline exceeded, unable to Activate Tenant",
    "topic_id": 7622
  },
  {
    "user_id": 1782,
    "conversation": "[kihumban (2024-10-12T20:10:45.244Z)]: I am getting KeyError: ‘moduleConfig’ error message when using weaviate with langchain. Weaviate is running in a docker container.\nThis is the code generating the error.\nclient = weaviate.connect_to_local()\nembeddings = OpenAIEmbeddings()\ndb2 = WeaviateVectorStore.from_documents(docs_3, embeddings, client=client)\nHere is my docker-compose.yml\nimage1726×1246 224 KB\nThis post on langchain github on the same issue recommended removing the DEFAULT_VECTORIZER_MODULE: ‘multi2vec-clip’ from the docker compose file. I did that, restarted the container but I am still getting the error.\nAny suggestions?\n\n----------\n\n[DudaNogueira (2024-10-15T21:32:46.245Z)]: hi @kihumban !!\nWelcome to our community \nWe have a nice recipe for langchain here, that I crafted myself, check it out:\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/llm-frameworks/langchain/loading-data at main ·...\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIf you could share here the sull running example as well as the docker compose in text, I can try reproducing that.\nThe recipe I liked above has all you need to use all Langchain features with Weaviate.\nLet me know if I can help you on that \nThanks!\n\n----------\n\n[kihumban (2024-10-15T23:09:51.677Z)]: @DudaNogueira thank you for sharing the recipe. I will check it out. This forum does not allow me to attach any file other than images. It flag text for having more than 2 hyperlinks. What is the best way of sharing the code and the docker file?\n\n----------\n\n[DudaNogueira (2024-10-15T23:10:39.189Z)]: You can paste the docker and code here too\n\n----------\n\n[kihumban (2024-10-16T01:55:14.151Z)]: I am basically working on this Langchain Weaviate library example. Here is the code. The last expression is the one generating the error.\n############\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import CharacterTextSplitter\nimport weaviate\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\nfrom langchain.chains import RetrievalQAWithSourcesChain\nfrom langchain_openai import OpenAI\nloader = TextLoader(“data/state_of_the_union.txt”)\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs_3 = text_splitter.split_documents(documents)\nembeddings = OpenAIEmbeddings()\nclient = weaviate.connect_to_local()\ndb2 = WeaviateVectorStore.from_documents(docs_3, embeddings, client=client)\n##############\nimage1314×898 80 KB\n######################\nInitially I had the DEFAULT_VECTORIZER_MODULE set to ‘multi2vec-clip’. However I removed it based to advise on this thread. Apparently the issue is being cause by the conflict between declaring embeddings = OpenAIEmbeddings() while DEFAULT_VECTORIZER_MODULE set to ‘multi2vec-clip’. However, updating my docker file by setting DEFAULT_VECTORIZER_MODULE  to ‘none’ did not resolve the issue.\n\n----------\n\n[kihumban (2024-10-16T01:56:31.807Z)]: Here is the LangChain thread regarding the error\n  \n\n      github.com/langchain-ai/langchain-weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Error when using `WeaviateVectorStore.from_documents()`\n    \n\n    \n      \n        opened 01:12PM - 07 May 24 UTC\n      \n\n        \n          closed 09:32PM - 07 May 24 UTC\n        \n\n      \n        \n          \n          StreetLamb\n        \n      \n    \n\n    \n        \n          bug\n        \n    \n  \n\n\n  \n    **Describe the bug**\n\nI am encountering an error where `moduleConfig` is not p…resent in the schema when running `WeaviateVectorStore.from_documents()`. \n```\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/runpy.py\", line 88, in _run_code\n    exec(code, run_globals)\n  File \"/Users/xxx/.vscode/extensions/ms-python.debugpy-2024.6.0-darwin-arm64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py\", line 39, in <module>\n    cli.main()\n  File \"/Users/xxx/.vscode/extensions/ms-python.debugpy-2024.6.0-darwin-arm64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py\", line 430, in main\n    run()\n  File \"/Users/xxx/.vscode/extensions/ms-python.debugpy-2024.6.0-darwin-arm64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py\", line 284, in run_file\n    runpy.run_path(target, run_name=\"__main__\")\n  File \"/Users/xxx/.vscode/extensions/ms-python.debugpy-2024.6.0-darwin-arm64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py\", line 321, in run_path\n    return _run_module_code(code, init_globals, run_name,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xxx/.vscode/extensions/ms-python.debugpy-2024.6.0-darwin-arm64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py\", line 135, in _run_module_code\n    _run_code(code, mod_globals, init_globals,\n  File \"/Users/xxx/.vscode/extensions/ms-python.debugpy-2024.6.0-darwin-arm64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py\", line 124, in _run_code\n    exec(code, run_globals)\n  File \"/Users/xxx/Desktop/projects/xxx/backend/app/core/test.py\", line 22, in <module>\n    db = WeaviateVectorStore.from_documents(docs, embeddings, client=weaviate_client)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xxx/Library/Caches/pypoetry/virtualenvs/app-w4MTL1IK-py3.12/lib/python3.12/site-packages/langchain_core/vectorstores.py\", line 550, in from_documents\n    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xxx/Library/Caches/pypoetry/virtualenvs/app-w4MTL1IK-py3.12/lib/python3.12/site-packages/langchain_weaviate/vectorstores.py\", line 477, in from_texts\n    weaviate_vector_store = cls(\n                            ^^^^\n  File \"/Users/xxx/Library/Caches/pypoetry/virtualenvs/app-w4MTL1IK-py3.12/lib/python3.12/site-packages/langchain_weaviate/vectorstores.py\", line 129, in __init__\n    self._multi_tenancy_enabled = self._collection.config.get(\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xxx/Library/Caches/pypoetry/virtualenvs/app-w4MTL1IK-py3.12/lib/python3.12/site-packages/weaviate/collections/config.py\", line 81, in get\n    return _collection_config_from_json(schema)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xxx/Library/Caches/pypoetry/virtualenvs/app-w4MTL1IK-py3.12/lib/python3.12/site-packages/weaviate/collections/classes/config_methods.py\", line 246, in _collection_config_from_json\n    vectorizer_config=__get_vectorizer_config(schema),\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xxx/Library/Caches/pypoetry/virtualenvs/app-w4MTL1IK-py3.12/lib/python3.12/site-packages/weaviate/collections/classes/config_methods.py\", line 78, in __get_vectorizer_config\n    vec_config: Dict[str, Any] = schema[\"moduleConfig\"].pop(schema[\"vectorizer\"])\n                                 ~~~~~~^^^^^^^^^^^^^^^^\nKeyError: 'moduleConfig'\n```\n \n**Complete Minimal Reproducible Example**\n\ndocker-compose.yml\n```\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.10\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      CLIP_INFERENCE_API: 'http://multi2vec-clip:8080'\n      RERANKER_INFERENCE_API: 'http://reranker-transformers:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'multi2vec-clip'\n      ENABLE_MODULES: 'multi2vec-clip,reranker-transformers'\n      CLUSTER_HOSTNAME: 'node1'\n  multi2vec-clip:\n    image: cr.weaviate.io/semitechnologies/multi2vec-clip:sentence-transformers-clip-ViT-B-32-multilingual-v1\n    environment:\n      ENABLE_CUDA: '0'\n  reranker-transformers:\n    image: cr.weaviate.io/semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2\n    environment:\n      ENABLE_CUDA: '0'\nvolumes:\n  weaviate_data:\n...\n```\n\nI received the error when running the following code:\n```py\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_openai import OpenAIEmbeddings\nimport weaviate\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\n\nOPENAI_API_KEY='xxxx'\n\nloader = TextLoader(\"state_of_the_union.txt\")\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)\n\nembeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\nweaviate_client = weaviate.connect_to_local(port=8080)\ndb = WeaviateVectorStore.from_documents(docs, embeddings, client=weaviate_client) # error occured here\n```\n\n\n**Expected behavior**\nI should be able to create my Weaviate vector store without issues\n\n**Tech Stack (please complete the following information):**\n- weaviate server version: 1.24.10\n- weaviate modules enabled: 'multi2vec-clip,reranker-transformers'\n- langchain-weaviate version: 0.0.1.post1\n- langchain version: 0.1.17\n\n**Additional context**\nNo issues when using weaviate library directly, so probably an issue with how langchain-weaviate creates the initial schema.\n\n----------\n\n[DudaNogueira (2024-10-16T02:24:58.780Z)]: Can you remove the DEFAULT_VECTORIZER_MODULE altogether?\nAlso, can you copy the docker compose here? Otherwise it’s really copy and paste from the image, as it gets all messed up \nHave you looked into the recipe I pasted?\nIt should give you all the steps to start using Langchain with Weaviate the proper way.\nThanks!\n\n----------\n\n[kihumban (2024-10-17T02:20:20.337Z)]: I removed the DEFAULT_VECTORIZER_MODULE and I am still getting the same error. However, I have worked through the the code in the recipe you shared and that is working ok. The only difference is that the recipe is using Embedded Weaviate rather than stand-alone server as was in my code. I am not sure if that has an impact. I will modify the recipe to try with client = weaviate.connect_to_local().\nThe forum platform does not allow me to copy the docker compose file. Every time I do that it flags the post with the following message.\nScreenshot 2024-10-16 at 10.17.30 PM1076×398 13 KB\n\n----------\n\n[DudaNogueira (2024-10-17T17:40:10.717Z)]: Hi!\nAs long as you have a working weaviate client (connect to embedded/local/cloud) it should work accordingly.\nYou can paste the the docker compose here, like so:\n---\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.27.0\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_API_BASED_MODULES: 'true'\n      CLUSTER_HOSTNAME: 'node1'\nvolumes:\n  weaviate_data:\n...\n\n----------\n\n[kihumban (2024-10-17T18:42:01.197Z)]: I have tried pasting the docker compose here but it does not work. I keep getting the error message I indicated above.\n\n----------\n\n[DudaNogueira (2024-10-17T19:06:37.936Z)]: Oh, I mean, the content of the docker compose file.\nFeel free to reach out to me on our slack. I would love to help you there too!\n\n----------\n\n[kihumban (2024-10-18T01:40:02.693Z)]: I run the langchain-simple-pdf-multitenant.ipynb recipe using local stand-alone server instead of embedded and run into the same error. The only section of the code that changed was the initialization of the client\nclient = weaviate.connect_to_local(\nheaders={\n“X-OpenAi-Api-Key”: os.environ.get(“OPENAI_API_KEY”), # Replace with your Cohere key\n}\n)\nHere is my docker compose:\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.4\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      CLIP_INFERENCE_API: 'http://multi2vec-clip:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_API_BASED_MODULES: 'true'\n      ENABLE_MODULES: 'multi2vec-clip,text2vec-openai,generative-openai'\n      CLUSTER_HOSTNAME: 'node1'\n  multi2vec-clip:\n    image: cr.weaviate.io/semitechnologies/multi2vec-clip:sentence-transformers-clip-ViT-B-32-multilingual-v1\n    environment:\n      ENABLE_CUDA: '0'\nvolumes:\n  weaviate_data:\n...\n\n----------\n\n[kihumban (2024-10-18T01:55:46.898Z)]: Here is the expression and the associated error dump:\ndb = WeaviateVectorStore.from_documents(docs, embeddings, client=client, index_name=“WikipediaLangChainMT”, tenant=“brazil”)\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[11], line 1\n----> 1 db = WeaviateVectorStore.from_documents(docs, embeddings, client=client, index_name=\"WikipediaLangChainMT\", tenant=\"brazil\")\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:835, in VectorStore.from_documents(cls, documents, embedding, **kwargs)\n    833 texts = [d.page_content for d in documents]\n    834 metadatas = [d.metadata for d in documents]\n--> 835 return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_weaviate/vectorstores.py:487, in WeaviateVectorStore.from_texts(cls, texts, embedding, metadatas, tenant, client, index_name, text_key, relevance_score_fn, **kwargs)\n    475 attributes = list(metadatas[0].keys()) if metadatas else None\n    477 weaviate_vector_store = cls(\n    478     client,\n    479     index_name,\n   (...)\n    484     use_multi_tenancy=tenant is not None,\n    485 )\n--> 487 weaviate_vector_store.add_texts(texts, metadatas, tenant=tenant, **kwargs)\n    489 return weaviate_vector_store\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_weaviate/vectorstores.py:167, in WeaviateVectorStore.add_texts(self, texts, metadatas, tenant, **kwargs)\n    164 if self._embedding:\n    165     embeddings = self._embedding.embed_documents(list(texts))\n--> 167 with self._client.batch.dynamic() as batch:\n    168     for i, text in enumerate(texts):\n    169         data_properties = {self._text_key: text}\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/weaviate/collections/batch/client.py:179, in _BatchClientWrapper.dynamic(self, consistency_level)\n    177 self._batch_mode: _BatchMode = _DynamicBatching()\n    178 self._consistency_level = consistency_level\n--> 179 return self.__create_batch_and_reset()\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/weaviate/collections/batch/client.py:135, in _BatchClientWrapper.__create_batch_and_reset(self)\n    133 def __create_batch_and_reset(self) -> _ContextManagerWrapper[_BatchClient]:\n    134     if self._vectorizer_batching is None or not self._vectorizer_batching:\n--> 135         configs = self.__config.list_all(simple=True)\n    137         vectorizer_batching = False\n    138         for config in configs.values():\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/weaviate/collections/collections/sync.py:286, in _Collections.list_all(self, simple)\n    265 def list_all(\n    266     self, simple: bool = True\n    267 ) -> Union[Dict[str, CollectionConfig], Dict[str, CollectionConfigSimple]]:\n    268     \"\"\"List the configurations of the all the collections currently in the Weaviate instance.\n    269 \n    270     Arguments:\n   (...)\n    284             If Weaviate reports a non-OK status.\n    285     \"\"\"\n--> 286     return self.__loop.run_until_complete(self.__collections.list_all, simple)\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/weaviate/event_loop.py:40, in _EventLoop.run_until_complete(self, f, *args, **kwargs)\n     38     raise WeaviateClosedClientError()\n     39 fut = asyncio.run_coroutine_threadsafe(f(*args, **kwargs), self.loop)\n---> 40 return fut.result()\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:456, in Future.result(self, timeout)\n    454     raise CancelledError()\n    455 elif self._state == FINISHED:\n--> 456     return self.__get_result()\n    457 else:\n    458     raise TimeoutError()\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401, in Future.__get_result(self)\n    399 if self._exception:\n    400     try:\n--> 401         raise self._exception\n    402     finally:\n    403         # Break a reference cycle with the exception in self._exception\n    404         self = None\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/weaviate/collections/collections/async_.py:304, in _CollectionsAsync.list_all(self, simple)\n    285 \"\"\"List the configurations of the all the collections currently in the Weaviate instance.\n    286 \n    287 Arguments:\n   (...)\n    301         If Weaviate reports a non-OK status.\n    302 \"\"\"\n    303 _validate_input([_ValidateArgument(expected=[bool], name=\"simple\", value=simple)])\n--> 304 return await self._get_all(simple=simple)\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/weaviate/collections/collections/base.py:76, in _CollectionsBase._get_all(self, simple)\n     74 assert res is not None\n     75 if simple:\n---> 76     return _collection_configs_simple_from_json(res)\n     77 return _collection_configs_from_json(res)\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/weaviate/collections/classes/config_methods.py:327, in _collection_configs_simple_from_json(schema)\n    323 def _collection_configs_simple_from_json(\n    324     schema: Dict[str, Any]\n    325 ) -> Dict[str, _CollectionConfigSimple]:\n    326     return {\n--> 327         schema[\"class\"]: _collection_config_simple_from_json(schema) for schema in schema[\"classes\"]\n    328     }\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/weaviate/collections/classes/config_methods.py:250, in _collection_config_simple_from_json(schema)\n    242 def _collection_config_simple_from_json(schema: Dict[str, Any]) -> _CollectionConfigSimple:\n    243     return _CollectionConfigSimple(\n    244         name=schema[\"class\"],\n    245         description=schema.get(\"description\"),\n    246         generative_config=__get_generative_config(schema),\n    247         properties=_properties_from_config(schema) if schema.get(\"properties\") is not None else [],\n    248         references=_references_from_config(schema) if schema.get(\"properties\") is not None else [],\n    249         reranker_config=__get_rerank_config(schema),\n--> 250         vectorizer_config=__get_vectorizer_config(schema),\n    251         vectorizer=__get_vectorizer(schema),\n    252         vector_config=__get_vector_config(schema, simple=True),\n    253     )\n\nFile /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/weaviate/collections/classes/config_methods.py:88, in __get_vectorizer_config(schema)\n     86 def __get_vectorizer_config(schema: Dict[str, Any]) -> Optional[_VectorizerConfig]:\n     87     if __is_vectorizer_present(schema) is not None and schema.get(\"vectorizer\", \"none\") != \"none\":\n---> 88         vec_config: Dict[str, Any] = schema[\"moduleConfig\"].pop(schema[\"vectorizer\"])\n     89         try:\n     90             vectorizer = Vectorizers(schema[\"vectorizer\"])\n\nKeyError: 'moduleConfig'\n\n----------\n\n[kihumban (2024-10-21T01:48:02.357Z)]: Is this some kind of a bug? It seem it’s looking for a property called “moduleConfig” in the collection object. But when I look at the collection object configuration (below), there is no property “moduleConfig”\n<weaviate.Collection config={\n  \"name\": \"WikipediaLangChainMT\",\n  \"description\": null,\n  \"generative_config\": {\n    \"generative\": \"generative-openai\",\n    \"model\": {}\n  },\n  \"inverted_index_config\": {\n    \"bm25\": {\n      \"b\": 0.75,\n      \"k1\": 1.2\n    },\n    \"cleanup_interval_seconds\": 60,\n    \"index_null_state\": false,\n    \"index_property_length\": false,\n    \"index_timestamps\": false,\n    \"stopwords\": {\n      \"preset\": \"en\",\n      \"additions\": null,\n      \"removals\": null\n    }\n  },\n  \"multi_tenancy_config\": {\n    \"enabled\": true,\n    \"auto_tenant_creation\": true,\n    \"auto_tenant_activation\": true\n  },\n  \"properties\": [],\n  \"references\": [],\n  \"replication_config\": {\n    \"factor\": 1,\n    \"async_enabled\": false\n  },\n  \"reranker_config\": null,\n  \"sharding_config\": null,\n  \"vector_index_config\": {\n    \"quantizer\": null,\n    \"cleanup_interval_seconds\": 300,\n    \"distance_metric\": \"cosine\",\n    \"dynamic_ef_min\": 100,\n    \"dynamic_ef_max\": 500,\n    \"dynamic_ef_factor\": 8,\n    \"ef\": -1,\n    \"ef_construction\": 128,\n    \"flat_search_cutoff\": 40000,\n    \"max_connections\": 32,\n    \"skip\": false,\n    \"vector_cache_max_objects\": 1000000000000\n  },\n  \"vector_index_type\": \"hnsw\",\n  \"vectorizer_config\": {\n    \"vectorizer\": \"text2vec-openai\",\n    \"model\": {\n      \"baseURL\": \"https://api.openai.com\",\n      \"model\": \"ada\"\n    },\n    \"vectorize_collection_name\": true\n  },\n  \"vectorizer\": \"text2vec-openai\",\n  \"vector_config\": null\n}>\n\n----------\n\n[DudaNogueira (2024-10-21T21:30:37.214Z)]: Hi!\nThis example in our recipes uses text2vec-openai and generative-openai\nAnd those modules are enabled:\nENABLE_MODULES: 'multi2vec-clip,text2vec-openai,generative-openai'\nSo it should work. \nhave you restarted your docker so the changes take effect?\nyou can call:\ndocker compose up -d\n\n----------\n\n[kihumban (2024-10-21T22:12:46.425Z)]: I have all those modules enabled in my docker compose as previously indicated. I have restarted the docker several times, the outcome has been consistently the same - KeyError: ‘moduleConfig’.\nBelow is my docker compose at it currently is. I just run the program and  got the same error.\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.4\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      CLIP_INFERENCE_API: 'http://multi2vec-clip:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'multi2vec-clip,text2vec-openai,generative-openai'\n      ENABLE_API_BASED_MODULES: 'true'\n      CLUSTER_HOSTNAME: 'node1'\n  multi2vec-clip:\n    image: cr.weaviate.io/semitechnologies/multi2vec-clip:sentence-transformers-clip-ViT-B-32-multilingual-v1\n    environment:\n      ENABLE_CUDA: '0'\nvolumes:\n  weaviate_data:\n...\n\n----------\n\n[DudaNogueira (2024-10-21T22:23:52.454Z)]: Hi! This is strange.\nI have used your docker compose, and was able to run this:\n\nclient.collections.delete(\"Kihu\")\ncollection = client.collections.create(\n    \"Kihu\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n    generative_config=wvc.config.Configure.Generative.openai(),\n)\ncollection.data.insert({\"text\": \"This is a test\"})\nobj = collection.generate.fetch_objects(single_prompt=\"translate {text} to spanish\", include_vector=True).objects[0]\nprint(\"Generation\", obj.generated)\nprint(\"Generation\", obj.vector)\n\nLet me know if you can run this code.\nThanks!\n\n----------\n\n[DudaNogueira (2024-10-21T22:24:43.663Z)]: Also, you can check what are the installed modules in a server with:\nclient.get_meta().get(\"modules\")\n\n----------\n\n[kihumban (2024-10-22T00:31:02.169Z)]: DudaNogueira:\n\nclient.get_meta().get(\"modules\")\n\n\nthe modules are there. See below.\n{'generative-anthropic': {'documentationHref': 'https://docs.anthropic.com/en/api/getting-started',\n  'name': 'Generative Search - Anthropic'},\n 'generative-anyscale': {'documentationHref': 'https://docs.anyscale.com/endpoints/overview',\n  'name': 'Generative Search - Anyscale'},\n 'generative-aws': {'documentationHref': 'https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html',\n  'name': 'Generative Search - AWS'},\n 'generative-cohere': {'documentationHref': 'https://docs.cohere.com/reference/chat',\n  'name': 'Generative Search - Cohere'},\n 'generative-databricks': {'documentationHref': 'https://docs.databricks.com/en/machine-learning/foundation-models/api-reference.html#completion-task',\n  'name': 'Generative Search - Databricks'},\n 'generative-friendliai': {'documentationHref': 'https://docs.friendli.ai/openapi/create-chat-completions',\n  'name': 'Generative Search - FriendliAI'},\n 'generative-mistral': {'documentationHref': 'https://docs.mistral.ai/api/',\n  'name': 'Generative Search - Mistral'},\n 'generative-octoai': {'documentationHref': 'https://octo.ai/docs/text-gen-solution/getting-started',\n  'name': 'Generative Search - OctoAI'},\n 'generative-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n  'name': 'Generative Search - OpenAI'},\n 'generative-palm': {'documentationHref': 'https://cloud.google.com/vertex-ai/docs/generative-ai/chat/test-chat-prompts',\n  'name': 'Generative Search - Google PaLM'},\n 'multi2vec-palm': {'documentationHref': 'https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings',\n  'name': 'Google PaLM Multimodal Module'},\n 'reranker-cohere': {'documentationHref': 'https://txt.cohere.com/rerank/',\n  'name': 'Reranker - Cohere'},\n 'reranker-voyageai': {'documentationHref': 'https://docs.voyageai.com/reference/reranker-api',\n  'name': 'Reranker - VoyageAI'},\n 'text2vec-aws': {'documentationHref': 'https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html',\n  'name': 'AWS Module'},\n 'text2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/',\n  'name': 'Cohere Module'},\n 'text2vec-databricks': {'documentationHref': 'https://docs.databricks.com/en/machine-learning/foundation-models/api-reference.html#embedding-task',\n  'name': 'Databricks Foundation Models Module - Embeddings'},\n 'text2vec-huggingface': {'documentationHref': 'https://huggingface.co/docs/api-inference/detailed_parameters#feature-extraction-task',\n  'name': 'Hugging Face Module'},\n 'text2vec-jinaai': {'documentationHref': 'https://jina.ai/embeddings/',\n  'name': 'JinaAI Module'},\n 'text2vec-octoai': {'documentationHref': 'https://octo.ai/docs/text-gen-solution/getting-started',\n  'name': 'OctoAI Module'},\n 'text2vec-openai': {'documentationHref': 'https://platform.openai.com/docs/guides/embeddings/what-are-embeddings',\n  'name': 'OpenAI Module'},\n 'text2vec-palm': {'documentationHref': 'https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings',\n  'name': 'Google PaLM Module'},\n 'text2vec-voyageai': {'documentationHref': 'https://docs.voyageai.com/docs/embeddings',\n  'name': 'VoyageAI Module'}}\n\n----------\n\n[DudaNogueira (2024-10-22T13:30:41.659Z)]: were you able to run that code?",
    "date_created": "2024-10-12T20:10:45.132Z",
    "has_accepted_answer": false,
    "title": "KeyError: 'moduleConfig' Error Message",
    "topic_id": 5035
  },
  {
    "user_id": 11655,
    "conversation": "[kathleenb45 (2025-03-21T09:29:14.502Z)]: Description\n\nDatabase has 140k objects of ~1KB size each. I am trying to iterate over all and get the ids. I am using the vector database as a key part of my dataloader, and need to be able to get all ids so that i can randomly split into train/test sets.\nThe queries for getting all objects are very slow – taking 95 seconds for 100k objects, and 101 seconds for 140k objects. This is unscalable because I intend to have 1M objects in the near future.\nAdditionally, I hit the max gprc limits when using pagination at 100k objects, so I am stuck with just the iterator and applying filters myself afterwards.\nHow can I better complete queries like this? Should I be sharding or doing multi-tenancy to reduce the query size to get all objects? Or is there a different way to go through all the objects?\nI’ve tried techniques like reducing the # fields that are indexed, increasing the grpc timeouts, increasing the grpc default limits to get more objects. Nothing is making these queries faster.\nServer Setup Information\n\nWeaviate Server Version: 1.29\nDeployment Method:weaviate docker in EKS\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: 4.11.x\nMultitenancy?: no\nServer setup matched the benchmark for the ANN nearest neighbors, so hopefully it’s well configured.\n\nAny additional Information\n\nFastest query I can create:\ndef _query_once(shard):\n    weaviate_api_key = os.environ[\"WEAVIATE_API_KEY\"]\n    auth_credentials = weaviate.auth.AuthApiKey(api_key=weaviate_api_key)\n    http_forwarded_port = 5000\n    grpc_forwarded_port = 6000\n\n    use_local_host = False\n    http_host = \"localhost\" if use_local_host else \"weaviate.weaviate.svc.cluster.local\"\n    grpc_host = \"localhost\" if use_local_host else \"weaviate-grpc.weaviate.svc.cluster.local\"\n    grpc_port = grpc_forwarded_port if use_local_host else 50051\n    http_port = http_forwarded_port if use_local_host else 80\n    client = weaviate.connect_to_custom(\n        http_host=http_host,\n        http_port=http_port,\n        http_secure=False,\n        grpc_host=grpc_host,\n        grpc_port=grpc_port,\n        grpc_secure=False,\n        auth_credentials=auth_credentials,\n        additional_config=AdditionalConfig(\n            connection=weaviate.config.ConnectionConfig(\n                session_pool_connections=30,\n                session_pool_maxsize=200,\n                session_pool_max_retries=3,\n            ),\n            timeout=weaviate.config.Timeout(query=60, insert=120, init=30),\n        ),\n    )\n    materialized_episodes_db = client.collections.get(db_name)\n\n    offset = shard[0]\n    query_args = shard[1]\n    if offset > len(materialized_episodes_db):\n        return []\n    query_args[\"offset\"] = offset\n    try:\n        data = materialized_episodes_db.query.fetch_objects(**query_args)\n    except Exception as err:\n        print(err)\n        return []\n\n    return data.objects\n\ndef run_map_query(\n    database,\n    tasks: list[str],\n    h5s_after_datetime: datetime | None = None,\n    h5s_before_datetime: datetime | None = None,\n):\n    filter_on_tasks = Filter.any_of(\n        [Filter.by_property(\"task\").equal(task_name) for task_name in tasks]\n    )\n    filter_set = [filter_on_tasks]\n    if h5s_after_datetime is not None:\n        h5s_after_datetime = h5s_after_datetime.replace(tzinfo=timezone.utc)\n        filter_set.append(Filter.by_creation_time().greater_or_equal(h5s_after_datetime))\n    if h5s_before_datetime is not None:\n        h5s_before_datetime = h5s_before_datetime.replace(tzinfo=timezone.utc)\n        filter_set.append(Filter.by_creation_time().less_or_equal(h5s_before_datetime))\n    and_filter = Filter.all_of(filter_set)\n\n\n    print(and_filter)\n    output_vids = []\n    query = {\n        \"return_properties\": [\n            \"unique_id\",\n            \"left_video_s3_url\",\n            \"right_video_s3_url\",\n            \"episode\",\n        ],\n        \"filters\": and_filter,\n        \"limit\": 1000,\n        \"offset\": 0,\n    }\n\n    limit = 1000\n    num_shards = int(len(database) // limit)\n    shard = [(limit * i, query) for i in range(num_shards)]\n    start = time.time()\n    results = list(tqdm(map(_query_once, shard), total=len(shard)))\n    end = time.time()\n    print(len(database), \" in \", end - start)\n\n----------\n\n[DudaNogueira (2025-03-21T13:07:59.640Z)]: hi @kathleenb45 !!\nWelcome to our community \nIn order to fetch all objects, the best way is using the iterator:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nRead all objects | Weaviate\n\n  Weaviate provides the necessary APIs to iterate through all your data. This is useful when you want to manually copy/migrate your data (and vector embeddings) from one place to another.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nfor instance:\ncollection = client.collections.get(\"WineReview\")\n\nfor item in collection.iterator():\n    print(item.uuid, item.properties)\n\nUsing fetch_objects will eventually hit the limit imposed by QUERY_MAXIMUM_RESULTS  environment variable as documented here.\ndepending on the dataset size, you could try increasing that variable and getting all the objects at once. \nI am not sure how that would compare to running the iterator and while not scalable may be worth a try.\nLet me know if this helps!\nThanks!\n\n----------\n\n[kathleenb45 (2025-03-22T02:07:31.634Z)]: Hi Duda,\nThank you for the response! I will try out just increasing the query limit environment variable and see how that goes!\nI’ve tested out the iterator as well, and it does work well and can exceed that grpc limit, however I wish I could apply filters on it similar to the regular fetch_objects queries!\n\n----------\n\n[sebawita (2025-03-25T09:16:14.123Z)]: Hi @kathleenb45,\nIf you are only interested in UUIDs, you can specify which properties you would like to get back, and or even request to not return any properties to make the request smaller, like this:\nIterator\ncollection = client.collections.get(\"WineReview\")\n\nfor item in collection.iterator(return_properties=[\"name\", \"description\"])\n    print(item.uuid, item.properties)\n\nfor item in collection.iterator(return_properties=\"\") #no properties\n    print(item.uuid, item.properties) # item properties will return {}\n\nFetch\nresult = collection.query.fetch_objects(\n    limit=5,\n    return_properties=\"\"\n)",
    "date_created": "2025-03-21T09:29:14.445Z",
    "has_accepted_answer": true,
    "title": "Slow queries to fetch all objects",
    "topic_id": 20155
  },
  {
    "user_id": 1060,
    "conversation": "[abdimussa (2024-12-04T13:09:17.867Z)]: Description\nI wanted to perform a search using creation_time in weaviate, and it requires timestamp index to be added\njobss =jps.get_objects(\n    filters=Filter.by_creation_time().greater_than(filter_time),\n    metadata={'creation_time':True}, limit=80\n    )\n\nWith this error outputted:\nTimestamps must   be indexed to be filterable! Add\n`IndexTimestamps: true` to the   InvertedIndexConfig in JobProfile\"\n\nHow to update the collection definition so that it supports filters on creation_time. I’m using weaviate v4 python client.\nServer Setup Information\n\nWeaviate Server Version: 1.25.3\nDeployment Method: docker\nClient Language and Version: Python and version 4.6.5\n\n----------\n\n[Mohamed_Shahin (2024-12-04T16:38:30.859Z)]: Hi @abdimussa,\nHave you enabled the indexTimestamps?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection definition | Weaviate\n\n  Schema Configuration in Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nExample:\n\nimport weaviate.classes.config as wcc\nimport weaviate.classes as wvc\n\nclient.collections.create(\nname=“Test_time”,\nvectorizer_config=wcc.Configure.Vectorizer.text2vec_openai(),\ninverted_index_config=wcc.Configure.inverted_index(\nindex_timestamps = True\n),\nproperties=[\nwcc.Property(\nname=“question”,\ndata_type=wcc.DataType.TEXT,\ntokenization=wcc.Tokenization.WORD,\n),\nwcc.Property(\nname=“answer”,\ndata_type=wcc.DataType.TEXT,\ntokenization=wcc.Tokenization.FIELD,\n)\n],\n)\n\n----------\n\n[abdimussa (2024-12-04T17:05:52.699Z)]: Hi @Mohamed_Shahin. I haven’t enabled it during the creation of the collection. I want to update the collection currently. Is there a way to do that?\n\n----------\n\n[Mohamed_Shahin (2024-12-05T16:04:33.094Z)]: Good evening @abdimussa,\nYou will need to re-index the collection with:\n\ninverted_index_config=wcc.Configure.inverted_index(\nindex_timestamps=True\n)\n\nindex_timestamps is an immutable parameter that must be initialized at the schema creation.\nFurthermore, I would like to share that we have a mutability list available here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection definition | Weaviate\n\n  Schema Configuration in Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nSome parameters are mutable after you create your collection.\n\n----------\n\n[abdimussa (2024-12-05T17:44:26.775Z)]: Good evening @Mohamed_Shahin, so this means I’ll need to recreate the collection?\n\n----------\n\n[Mohamed_Shahin (2024-12-05T18:25:52.361Z)]: @abdimussa yes that’s correct.\n\n----------\n\n[abdimussa (2024-12-05T19:00:18.392Z)]: @Mohamed_Shahin ok thank you. I’d appreciate it if you can share a resource on how to do that efficiently.\n\n----------\n\n[Mohamed_Shahin (2024-12-05T21:07:12.403Z)]: @abdimussa,\nAbsolutely, I am more than happy to ensure you are well supported. Before sharing some snippets with you to re-use, is there anything specific you’re using or would like to use in your cluster? If so, I can prepare some snippets that cover everything, so you won’t have to face that again.\nOtherwise, please make sure you go through the mutability list to familiarize yourself with what can be re-configured after creation.\nIf you’d like, you can share your schema creation method with me, and I’d be happy to tweak it programmatically for you as well.\n\n----------\n\n[abdimussa (2024-12-06T08:55:21.492Z)]: @Mohamed_Shahin let’s take the below as an example.\nclient = weaviate.connect_to_custom(\n                http_host=valid_url,\n                http_port=\"443\",\n                http_secure=True,\n                grpc_host=valid_url,\n                grpc_port=\"50051\",\n                grpc_secure=True,\n                auth_credentials=auth_config,\n                headers=headers,\n                additional_config=AdditionalConfig(\n                    timeout=Timeout(init=30, query=60, insert=120), \n                ),\n                skip_init_checks=True \n            )\n\nclient.collections.create(\n    \"ArticleMetadata\",\n    properties=[\n        Property(name=\"metadata\", data_type=DataType.TEXT),\n    ],\n    vectorizer_config=wc.Configure.Vectorizer.text2vec_openai(\n                model=\"text-embedding-3-small\",\n            ),\n    generative_config=wc.Configure.Generative.openai(),\n)\n\n\nclient.collections.create(\n    \"Article\",\n    properties=[\n        Property(name=\"title\", data_type=DataType.TEXT),\n        Property(name=\"body\", data_type=DataType.TEXT),\n    ],\n    references=[\n                wc.ReferenceProperty(\n                    name=\"hasMetaData\",\n                    target_collection=\"ArticleMetaData\"\n                )\n            ],        \n    vectorizer_config=wc.Configure.Vectorizer.text2vec_openai(\n                model=\"text-embedding-3-small\",\n            ),\n    generative_config=wc.Configure.Generative.openai(),\n)\n\n----------\n\n[Mohamed_Shahin (2024-12-06T17:30:03.665Z)]: @abdimussa\n\nfrom weaviate.classes.config import Configure\nfrom weaviate.classes.config import Property, DataType, ReferenceProperty, Tokenization\nclient.collections.create(\nname=“Article”,\nvectorizer_config=Configure.Vectorizer.text2vec_openai(model=“text-embedding-3-small”),\ngenerative_config=Configure.Generative.openai(),\ninverted_index_config=Configure.inverted_index(\nindex_timestamps = True\n),\nreplication_config=Configure.replication(factor=3, async_enabled=True),\nproperties=[\nProperty(\nname=“title”,\ndata_type=DataType.TEXT,\ntokenization=Tokenization.WORD,\n),\nProperty(\nname=“body”,\ndata_type=DataType.TEXT,\ntokenization=Tokenization.FIELD,\n)\n],\nreferences=[\nReferenceProperty(\nname=“hasMetaData”,\ntarget_collection=“ArticleMetaData”\n)\n]\n)\n\n----------\n\n[abdimussa (2024-12-12T16:23:47.216Z)]: @Mohamed_Shahin Thank you for your response. However, I wanted to see more on the data migration part from my old collection to the new one where the index_timestamp is set to true. I’m facing issue with how I can migrate the references of each object.\nThe below is a sample code I’ve got:\ndef migrate_data(collection_src:Collection, collection_tgt:Collection):\n\n    with collection_tgt.batch.fixed_size(batch_size=20) as batch:\n        for q in tqdm(collection_src.iterator(include_vector=True,return_references=QueryReference(\n                link_on=\"hasMetaData\",\n                return_properties=[\"metadata\"]\n            ))):\n            batch.add_object(\n                properties=q.properties,\n                vector=q.vector[\"default\"],\n                uuid=q.uuid,\n            )\n            \n\n    return True\n\n----------\n\n[DudaNogueira (2024-12-19T15:42:19.800Z)]: hi @abdimussa !!\nYou can run thru all objects using the iterator api, and then migrate the cross references using this:\nquestions = client.collections.get(\"JeopardyQuestion\")\n\nquestions.data.reference_add(\n    from_uuid=question_obj_id,\n    from_property=\"hasCategory\",\n    to=category_obj_id\n)\n\nLet me know if that helps!\nThanks!\n\n----------\n\n[abdimussa (2024-12-20T12:28:05.510Z)]: @DudaNogueira, thank you, this is helpful.",
    "date_created": "2024-12-04T13:09:17.814Z",
    "has_accepted_answer": true,
    "title": "Filtering based on creation_time requires index_timestamps",
    "topic_id": 9090
  },
  {
    "user_id": 3067,
    "conversation": "[dastankg (2024-12-23T03:03:28.942Z)]: Hello everyone, I need help\nI did everything according to this video and got this error.\nI made a git clone and changed venv added OLLAMA_URL=http://localhost:11434\nOLLAMA_MODEL=llama3.\nСнимок экрана от 2024-12-23 09-02-52845×568 31.6 KB\n\n----------\n\n[DudaNogueira (2024-12-23T13:35:22.939Z)]: Hi @dastankg !!\nWhat video? \nIt looks like there isn’t any documents to search for.\nWere you able to import any documents with success?",
    "date_created": "2024-12-23T03:03:28.897Z",
    "has_accepted_answer": false,
    "title": "Query failed: Query call with protocol GRPC search failed with message",
    "topic_id": 9397
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2025-01-14T18:10:46.320Z)]: Description\nI’m following the migration script to move from a normal cluster to an HA one with the script given:\ndef migrate_data(collection_src, collection_tgt):\n    with collection_tgt.batch.fixed_size(batch_size=100) as batch:\n        for q in tqdm(collection_src.iterator(include_vector=True)):\n            batch.add_object(\n                properties=q.properties,\n                vector=q.vector[\"default\"],\n                uuid=q.uuid\n            )\n    return True\n\nprint('Migrating # of tenants: ', len(tenants_src_list))\n\ni = 0\nfor tenant in tenants_src_list:\n    print('Migrating tenant: ', tenant.name)\n    try:\n        collection_src_tenant = nodes_collection_source.with_tenant(tenant.name)\n        collection_tgt_tenant = nodes_collection_target.with_tenant(tenant.name)\n        migrate_data(collection_src_tenant, collection_tgt_tenant)\n    except Exception as e:\n        print(e)\n        continue\n    i += 1\n    print('Migrated tenants up to # ', i)\n\n\nclient_source.close()\nclient_target.close()\n\nBut for some tenants, I get this error logged of just default\nNo other error message in theprint(e) except just that. I’m not sure if this is anything serious before I go ahead with this. I also sent a support email about this in case our specific node(s) are affected\nServer Setup Information\n\nWeaviate Server Version: Servless\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?: Yes\n\nAny additional Information\n\n----------\n\n[Mohamed_Shahin (2025-01-16T14:44:05.350Z)]: Hey @Tejas_Sharma,\nHave you tried to print out the failed object in a batch then check upon the reason also maybe apply some retry at the end?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Utilize the Python client library to access Weaviate and streamline data processes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nRegards,\nMohamed Shahin,\nWeaviate Support\n\n----------\n\n[Tejas_Sharma (2025-01-17T18:12:15.491Z)]: Hey @Mohamed_Shahin ,\nThanks for the response. I did, but it prints no failed objects and it fails with that error without saying there were any failed objects. There are tenants for which there were failed objects, but for those after I re-run the script, it seems to work.\ndef migrate_data(collection_src, collection_tgt):\nwith collection_tgt.batch.fixed_size(batch_size=100) as batch:  \n  for q in tqdm(collection_src.iterator(include_vector=True)):      \n      batch.add_object(properties=q.properties, vector=q.vector[\"default\"], uuid=q.uuid) \n   if collection_tgt.batch.failed_objects:\n      print('!! FAILED OBJECTS: ') \n         for failed_object in collection_tgt.batch.failed_objects:        \n           print(failed_object) return True\n\nIs this code correct for printing it out?\n\n----------\n\n[Mohamed_Shahin (2025-01-18T16:11:19.786Z)]: Hey @Tejas_Sharma,\nI hope you’re having a great weekend!\nIt might not be the best idea to check failed_objects in real-time during batch processing. It’s often safer to access them after the batch import finishes.\nHere’s an internal example I use when testing batching processes — you might find it helpful. You need to tweak it a little for your specific use case, but it should give you a good idea of how I approach the logic.\ndef batch_upload(client, file_path, collection_name, batch_size=10):\n    \"\"\"\n    Batch upload data from a CSV file into the specified collection.\n    \"\"\"\n    if not client.collections.exists(collection_name):\n        raise Exception(f\"Collection '{collection_name}' does not exist. Cannot insert data.\")\n\n    failed_objects = []\n\n    try:\n        with open(file_path, mode='r', encoding='utf-8') as file:\n            csv_reader = csv.DictReader(file)\n            # Normalize column headers\n            csv_reader.fieldnames = [header.strip().lower() for header in csv_reader.fieldnames]\n\n            with client.batch.fixed_size(batch_size=100, concurrent_requests=2) as batch:\n                for i, row in enumerate(csv_reader):\n                    # Prepare object properties\n                    obj_properties = {\n                        \"company_id\": row.get(\"company_id\", \"\"),\n                        \"last_name\": row.get(\"last_name\", \"\"),\n                        \"first_name\": row.get(\"first_name\", \"\"),\n                        \"job_title\": row.get(\"job_title\", \"\"),\n                        \"email_address\": row.get(\"email_address\", \"\"),\n                        \"country\": row.get(\"country\", \"\"),\n                        \"interaction_notes\": row.get(\"interaction_notes\", \"\"),\n                    }\n                    batch.add_object(\n                        properties=obj_properties,\n                        collection=collection_name\n                    )\n                print(f\"Batch processing completed. {i + 1} objects added.\")\n    except Exception as e:\n        raise Exception(f\"Batch insertion failed: {e}\")\n\n    # Check for failed objects and reason behind to be printed out\n    failed_objects = client.batch.failed_objects\n    if failed_objects:\n        print(f\"Number of failed objects: {len(failed_objects)}\")\n        for i, failed_obj in enumerate(failed_objects, 1):\n            print(f\"Failed object {i}: {failed_obj}\")\n    else:\n        print(f\"All objects successfully inserted into '{collection_name}'.\")\n\nTry that and let me know\nRegards,\nMohamed Shahin,\nWeaviate Support",
    "date_created": "2025-01-14T18:10:46.275Z",
    "has_accepted_answer": false,
    "title": "Getting 'default' error on migration",
    "topic_id": 9753
  },
  {
    "user_id": 3249,
    "conversation": "[becky (2025-01-21T15:52:06.061Z)]: Description\nHi, my team is attempting to migrate Weaviate Cloud data from version 1.25 to a 1.28 cluster. The core code of the migration script is as follows. We are using the Weaviate client v4.\nWhen executing the migration, the following errors occur. We have tried using dynamic batch or fixed-sized batch settings with size=100 and concurrent_request=1, but there are still a large number of errors. After multiple errors, the cluster node will directly disconnect and restart.\nwith collection_tgt.batch.dynamic() as batch:\nfor q in collection_src.iterator(include_vector=True):\nbatch.add_object(\nproperties=q.properties,\nvector=q.vector[“default”],\nuuid=q.uuid\n)\nimage1920×519 237 KB\nWe have 1M objects to migrate. Are there any alternative solutions to perform a safe data migration?\nServer Setup Information\n\nWeaviate Server Version: 1.25 → 1.28\nNumber of Running Nodes: 1\nClient Language and Version: python, weaviate-client v4\nMultitenancy?: No\n\n----------\n\n[Mohamed_Shahin (2025-01-22T11:09:05.978Z)]: Hello @becky,\nWelcome to the community! It’s great to have you here.\nI’ve received your ticket in Support and will follow up with a detailed reply there since you are a cloud customer and our ticketing system differs from the community forum. You could add the following snippet to your code to help identify the reason behind any failures:\n\nfailed_objects = client.batch.failed_objects\nif failed_objects:\nprint(f\"Number of failed objects: {len(failed_objects)}“)\nfor i, failed_obj in enumerate(failed_objects, 1):\nprint(f\"Failed object {i}: {failed_obj}”)\nelse:\nprint(f\"All objects successfully inserted into ‘{collection_name}’.\")\n\nThis code will check for any objects that failed to be inserted and print out the reasons for the failures, helping you pinpoint what might be going wrong.\nRegards,\nMohamed Shahin\nWeaviate Support\n\n----------\n\n[pdp (2025-02-16T13:18:03.399Z)]: I am also experiencing the same issue and frankly I am really annoyed by it. How is this serverless when it basically collapses on the smallest load?\nNot cool!",
    "date_created": "2025-01-21T15:52:06.011Z",
    "has_accepted_answer": false,
    "title": "Migration cause Weaviate Cloud cluster restart all the time",
    "topic_id": 9838
  },
  {
    "user_id": 1195,
    "conversation": "[awolder_cisco (2024-07-12T16:33:57.883Z)]: Description\n\nHi All,\nI am trying to launch the semitechnologies/multi2vec-bind:imagebind docker image on openshift, and having no luck.  Our company policy is that we load images from our own container repo, so I have created a docker file which creates an image from semitechnologies/multi2vec-bind:imagebind and stores that in our own repo.\nbasic docker file:\nFROM semitechnologies/multi2vec-bind:imagebind\nLABEL maintainer=\"myemail@cisco.com\"\nUSER 0\nUSER 1000\nEXPOSE 8080\n\nENV ENABLE_CUDA: ‘0’\nRUN chown -R app:app /app\n(I also tried to give access to User 0 with the following, with no luck)\nRUN chgrp -R 0  /app/ && chmod -R g+rwX  /app/\nI created an openshift deployment, and assigned 4G of memory to test, but when the pod is being created, it resets with CrashLoopBackoff.  The logs output the following:\n/usr/local/lib/python3.11/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be removed in 0.17. Please don’t rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\nwarnings.warn(\n/usr/local/lib/python3.11/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The ‘torchvision.transforms._functional_video’ module is deprecated since 0.12 and will be removed in the future. Please use the ‘torchvision.transforms.functional’ module instead.\nwarnings.warn(\n/usr/local/lib/python3.11/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The ‘torchvision.transforms._transforms_video’ module is deprecated since 0.12 and will be removed in the future. Please use the ‘torchvision.transforms’ module instead.\nwarnings.warn(\nINFO: Started server process [7]\nINFO: Waiting for application startup.\nINFO: Running on CPU\nKilled\nI suspect it is permissions related but have no idea what directories need to have write access.\nAny insights would be appreciated.\nBest Regards\nAndrew\n\n----------\n\n[awolder_cisco (2024-07-12T17:14:15.741Z)]: I actually just got it to work.  After reading some posts about another image, it indicated that the image i am using just needed more memory.  I added 10Gig and it started up fine.\nThanks!\n\n----------\n\n[Mohamed_Shahin (2024-07-12T17:35:03.327Z)]: Hi @awolder_cisco,\nWelcome to our community and it’s great to have you here! Happy Friday!\nI am glad you were able to resolve the problem, fair play to you and thank you for sharing it with us and community!\nHave a lovely weekend!",
    "date_created": "2024-07-12T16:33:57.827Z",
    "has_accepted_answer": true,
    "title": "Semitechnologies/multi2vec-bind:imagebind on openshift",
    "topic_id": 3033
  },
  {
    "user_id": 2477,
    "conversation": "[startde (2024-11-07T11:34:27.211Z)]: Description\nHello everybody. I am stuck with the issue of bringing my own vectors to weaviate cloud. Followed the guide of “batch import”, but didn’t succeed.\nimport weaviate\nfrom weaviate.classes.init import Auth\nfrom dotenv import load_dotenv\nimport weaviate.classes.config as wc\nimport os\nimport weaviate.classes as wvc\nfrom weaviate_test.chroma import chromadb_data\n\nЗагружаем переменные окружения из файла .env\nload_dotenv()\nПолучение переменных окружения с помощью os.getenv()\nweaviate_url = os.getenv(“WEAVIATE_URL”)\nweaviate_api_key = os.getenv(“WEAVIATE_API_KEY”)\nConnect to Weaviate Cloud\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=weaviate_url,\n    auth_credentials=Auth.api_key(weaviate_api_key),\n)\n\nclient.collections.create(\n    name=\"AxiSCADA\",\n    vectorizer_config=wc.Configure.Vectorizer.none(),\n)\n\nAXI_SCADA = list()\ni = 0\nfor i in range (0, len(chromadb_data)):\n    AXI_SCADA.append(wvc.data.DataObject(\n        properties={\n            \"ids\": chromadb_data[i]['ids'][0],\n            \"documents\": chromadb_data[i]['documents'][0],\n            \"section_tag\": chromadb_data[i]['metadatas'][0]['section_tag'],\n            \"urls\": chromadb_data[i]['metadatas'][0]['urls']\n        },\n        vector=chromadb_data[i]['embeddings'][0]\n    ))\n\nprint(AXI_SCADA)\nquestions = client.collections.get(\"AxiSCADA\")\nquestions.data.insert_many(AXI_SCADA)\n\narticles = client.collections.get(\"AxiSCADA\")\narticles_config = articles.config.get()\n\nprint(articles_config)\n\n\nclient.close()\n\nMy code is like that. Embeddings represent “documents” only. I printed out AXI_SCADA and there vectors. But i don’t see them in cloud and i can’t get a vector response. BM25 response works fine.\nServer Setup Information\n\nWeaviate Server Version: weaviate_cloud\n\n----------\n\n[DudaNogueira (2024-11-08T11:58:47.076Z)]: hi @startde !!\nWelcome to our community \nYour code seems right. The only downside is that it is not using Batch, so it will not have the best performance for large ingestion.\nDo you see any error logs while inserting that data?",
    "date_created": "2024-11-07T11:34:27.157Z",
    "has_accepted_answer": false,
    "title": "Issue with bring your own vectors",
    "topic_id": 7487
  },
  {
    "user_id": 1242,
    "conversation": "[arthur_zhang (2024-07-24T08:26:47.472Z)]: I have an object with vectors and properties, and one of the fields in the properties is a location, and I want to use a hybrid search, where the input is a vector, and I want to find something similar to the vector, and there is also a location string, and I want to find something related to the location, can I use a hybrid search?\n\n----------\n\n[sebawita (2024-07-24T09:11:21.908Z)]: Hi @arthur_zhang,\nWelcome to the Weaviate Community.\nSure, you can use the location together with you vector query.\nYou have two options: “filter” and “hybrid”.\nOption 1 - filter\nYou can add a filter condition to any query. In your case, you may want to add a filter that looks for a value in the location property.\nHere is a Python example:\nfrom weaviate.classes.query import Filter\n\ncities = client.collections.get(\"Cities\")\nresponse = cities.query.near_text(\n    query=\"your vector query here\",\n    filters=Filter.by_property(\"location\").like(\"york\"), # will match new york and your\n    limit=3\n)\n\nDocs for reference: near_text with filter, filter page (note, all filter examples can be used with any type of query).\nOption 2 - hybrid\nYou could also use hybrid search and specify separate queries for the keyword search on “location” and for the vector search.\nNormally, the query is used for both the keyword and vector search, but you can also use vector property to define the vector search separately, like this:\nfrom weaviate.classes.query import HybridVector, Move, HybridFusion\n\njeopardy = client.collections.get(\"JeopardyQuestion\")\nresponse = jeopardy.query.hybrid(\n    query=\"york\", # your keyword search here\n    query_properties=[\"location\"], # run the keyword search only on location\n    vector=HybridVector.near_text(\n        query=\"you vector query goes here\",\n    ),\n    limit=5,\n)\n\nHere is a smiliar example in the docs.",
    "date_created": "2024-07-24T08:26:47.346Z",
    "has_accepted_answer": false,
    "title": "[Question] about Hybrid search",
    "topic_id": 3146
  },
  {
    "user_id": 1269,
    "conversation": "[noitsbecky (2024-08-01T02:34:19.612Z)]: Hi\nI’m currently develop a project based on weaviate database, deploying with docker (v1.25.8). Now we want to migrate to AWS cloud service. I found the AWS marketplace link\nAWS Marketplace: Weaviate which shows the latest version is 1.24.8 for Kubernetes Cluster support, i was wondering whether the latest version support for SaaS product the same, or is aligned with newest release?\n(Also, congrats with rapid development! Happy to see more experimental features!)\nThanks\n\n----------\n\n[DudaNogueira (2024-08-01T18:53:30.061Z)]: hi @noitsbecky !! Welcome to our community \nWe are glad you are enjoying Weaviate! We really appreciate it \nI have asked our team about the current AWS Marketplace offering.  We are working on a improved solution, so hopefully that can be available on a time frame that suits you.\nI’ll update it here when I get more information.\nThanks!\n\n----------\n\n[noitsbecky (2024-08-05T01:52:11.506Z)]: Thanks!\nThat’s great news! We are looking forward to integrating batch vectorization and hopefully async client in our project\n\n----------\n\n[DudaNogueira (2024-08-05T19:08:00.049Z)]: Awesome!\nETA for this feature is hopefully this week or mid next week.\nThanks for choosing Weaviate!\n\n----------\n\n[noitsbecky (2024-08-20T00:55:37.709Z)]: Hi!\nMay i ask if there’s any progress here?",
    "date_created": "2024-08-01T02:34:19.567Z",
    "has_accepted_answer": true,
    "title": "The latest version support for AWS product",
    "topic_id": 3239
  },
  {
    "user_id": 837,
    "conversation": "[Guillermo_Ripa (2024-09-05T20:56:24.725Z)]: Description\nIn the docs, there’s a note that says vectors are normalized for cosine similarity, and then we use dot product.\nWouldn’t that mean that the cosine distance ends up being -1 <= distance <= 1? Or do we do 1 - dot(a,b) in the code?\nimage1428×849 112 KB\nI’m asking because we found negative distance using cosine when returning them in metadata.\n\n----------\n\n[DudaNogueira (2024-09-06T20:31:51.279Z)]: hi @Guillermo_Ripa !!\nThat’s an interesting question.\nI will need to ask internally for more context on this.\nI’ll get back with more info. Thanks!\n\n----------\n\n[andrewisplinghoff (2024-09-10T09:57:47.985Z)]: The cosine distance should never be negative, it is defined as 1 - dot(a,b) in the code:\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate/blob/598b4db26ba52c77f7777996ac100f48cd895431/adapters/repos/db/vector/hnsw/distancer/cosine_dist.go#L44\n\n\n\n    \n      \n          func NewCosineDistanceProvider() CosineDistanceProvider {\n          \treturn CosineDistanceProvider{}\n          }\n          \n          func (d CosineDistanceProvider) SingleDist(a, b []float32) (float32, error) {\n          \tif len(a) != len(b) {\n          \t\treturn 0, errors.Wrapf(ErrVectorLength, \"%d vs %d\",\n          \t\t\tlen(a), len(b))\n          \t}\n          \n          \tprod := 1 - dotProductImplementation(a, b)\n          \n          \treturn prod, nil\n          }\n          \n          func (d CosineDistanceProvider) Type() string {\n          \treturn \"cosine-dot\"\n          }\n          \n          func (d CosineDistanceProvider) New(a []float32) Distancer {\n          \treturn &CosineDistance{a: a}\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHere in the tests you can also see the expected distance measures, e.g. opposing vectors lead to cosine distance 2:\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate/blob/598b4db26ba52c77f7777996ac100f48cd895431/adapters/repos/db/vector/hnsw/distancer/cosine_dist_test.go#L66-L68\n\n\n\n    \n      \n          \t\tvec1 := Normalize([]float32{0.1, 0.3, 0.7})\n          \t\tvec2 := Normalize([]float32{-0.1, -0.3, -0.7})\n          \t\texpectedDistance := float32(2)\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nCould you give us an example where there was a negative cosine distance calculated?\n\n----------\n\n[Guillermo_Ripa (2024-09-10T12:40:40.441Z)]: Thanks @DudaNogueira and @andrewisplinghoff for the code snippets! That’s really helpful.\nThe distance was a -1e-5, so I brushed it off as a floating point error. But it got me looking into docs.\nThe code snippet and the unit test puts my doubt to rest. thank you\n\n----------\n\n[DudaNogueira (2024-09-10T13:15:04.851Z)]: Great!! Thanks for jumping in, @andrewisplinghoff !\nThat was the code that our team pointed me to \nThanks!!",
    "date_created": "2024-09-05T20:56:24.671Z",
    "has_accepted_answer": true,
    "title": "Is the cosine distance bound in the docs correct?",
    "topic_id": 3988
  },
  {
    "user_id": 3221,
    "conversation": "[Hao_Zhang (2025-01-14T21:55:28.410Z)]: Description\nThe issue occurs while attempting to insert video data into the Animals collection in Weaviate using the Python client. The UnexpectedStatusCodeError is thrown with the following message:\nObject was not added! Unexpected status code: 500, with response body: {'error': [{'message': 'update vector: send POST request: Post \"http://multi2vec-bind:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)'}]}.\n\nThe error indicates a timeout while making a POST request to the vectorizer service (multi2vec-bind) for vectorization during the insert operation.\nCode that produces the issue:\nanimals = client.collections.get(\"Animals\")\n\nsource = os.listdir(\"./source/video/\")\n\nfor name in source:\n    print(f\"Adding {name}\")\n\n    path = \"./source/video/\" + name\n    item = {\n        \"name\": name,\n        \"path\": path,\n        \"video\": toBase64(path),\n        \"mediaType\": \"video\"\n    }\n\n    # Insert videos one by one\n    animals.data.insert(item)\n\n\nServer Setup Information\n\nWeaviate Server Version: 1.23.7\nDeployment Method: Docker\n\n\nAny Additional Information\n\nLogs: The following error is observed in the Weaviate logs:{\"action\":\"requests_total\",\"api\":\"rest\",\"build_git_commit\":\"6c571ff\",\"build_go_version\":\"go1.22.8\",\"class_name\":\"Animals\",\"error\":\"update vector: send POST request: Post \\\"http://multi2vec-bind:8080/vectorize\\\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\",\"level\":\"error\",\"msg\":\"unexpected error\",\"query_type\":\"objects\",\"time\":\"2025-01-14T21:35:11Z\"}\n\n\nEnvironment Details:\ndocker-compose.yml\n\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:1.23.7\n    ports:\n    - 8080:8080\n    - 50051:50051\n    restart: on-failure:0\n    depends_on:\n      multi2vec-bind:\n        condition: service_healthy    \n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'multi2vec-bind'\n      ENABLE_MODULES: 'multi2vec-bind'\n      BIND_INFERENCE_API: 'http://multi2vec-bind:8080'\n      CLUSTER_HOSTNAME: 'node1'\n  \n  multi2vec-bind:\n    image: semitechnologies/multi2vec-bind:imagebind\n    environment:\n      ENABLE_CUDA: '0'\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/.well-known/ready || exit 1\n      interval: 10s\n      retries: 5\n      start_period: 15s\n      timeout: 3000s\n...\n\n\nPayload Details: Videos are processed one by one and converted to Base64 format before being inserted into the Animals collection.\n\n----------\n\n[Mohamed_Shahin (2025-01-16T10:07:47.562Z)]: Hi @Hao_Zhang,\nWelcome to our community and it’s lovely to have you here.\nTimeout issues can stem from various points, but let’s rule out a few things:\nVideo data is large and more complex than simple text or image data. Consequently, the time required to process and vectorize video files might take a bit. Thus consider increasing the timeout.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nLocal instances | Weaviate\n\n  Follow these steps to connect to a locally hosted Weaviate instance.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIt’s also worth considering allocating more resources if possible.\nBefore making these adjustments, it’s crucial to update your Weaviate instance to version 1.28.2, as you’re currently using version 1.23, which is significantly outdated. There have been many improvements since then, making it challenging to debug on an older version. Upgrading will enhance efficiency, especially since the latest client uses more effective gRPC calls.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\ngRPC | Weaviate\n\n  Integrate gRPC API with Weaviate for efficient data access.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLastly, I would highly recommend using batching\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Utilize the Python client library to access Weaviate and streamline data processes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBest regards,\nMohamed Shahin\nWeaviate Support Engineer",
    "date_created": "2025-01-14T21:55:28.357Z",
    "has_accepted_answer": false,
    "title": "Timeout Issue When Inserting Video Data into Weaviate with Multi2Vec-Bind Vectorizer",
    "topic_id": 9757
  },
  {
    "user_id": 2945,
    "conversation": "[Jeewan (2024-12-02T23:52:47.182Z)]: Description\nHi\nI am running a single Weaviate instance on K8s. Below is the server spec. I am encountering below error very frequently. Also the query time goes up from 100m to 500ms during certain period of the day even though number of queries remains same. Appreciate if your support on this\nServer Setup Information\n\nWeaviate Server Version:  1.26.3\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: python\nMultitenancy?: No\nCpU = 24 vcpus\nMemory = 256G\n\nAny additional Information\nweaviate-0 weaviate {\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"error\",\"msg\":\"Recovered from panic: runtime error: index out of range [2] with length 2, local variables [[]], additional localVars []\\n\",\"panic\":\"runtime error: index out of range [2] with length 2\",\"time\":\"2024-12-02T23:49:00Z\"}\nweaviate-0 weaviate goroutine 3247119061 [running]:\nweaviate-0 weaviate runtime/debug.Stack()\nweaviate-0 weaviate \t/usr/local/go/src/runtime/debug/stack.go:24 +0x5e\nweaviate-0 weaviate runtime/debug.PrintStack()\nweaviate-0 weaviate \t/usr/local/go/src/runtime/debug/stack.go:16 +0x13\nweaviate-0 weaviate github.com/weaviate/weaviate/entities/errors.(*ErrorGroupWrapper).setDeferFunc.func1({0xddf553d320, 0x1, 0x1})\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/entities/errors/error_group_wrapper.go:76 +0x175\nweaviate-0 weaviate panic({0x20565e0?, 0xddf5544738?})\nweaviate-0 weaviate \t/usr/local/go/src/runtime/panic.go:914 +0x21f\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db/vector/hnsw/distancer.CosineDistanceProvider.Step(...)\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/vector/hnsw/distancer/cosine_dist.go:60\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db/vector/compressionhelpers.(*DistanceLookUpTable).LookUp(0xdc9e491d50, {0xd3df43f8c0, 0x20, 0x2923b00?}, 0xc0034b0b40)\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/vector/compressionhelpers/product_quantization.go:97 +0x12d\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db/vector/compressionhelpers.(*ProductQuantizer).Distance(...)\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/vector/compressionhelpers/product_quantization.go:430\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db/vector/compressionhelpers.(*PQDistancer).Distance(0x0?, {0xd3df43f8c0?, 0x51f13c0?, 0x20?})\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/vector/compressionhelpers/product_quantization.go:350 +0x58\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db/vector/compressionhelpers.(*quantizedCompressorDistancer[...]).DistanceToNode(0x2102102102222a52, 0xd44d878918?)\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/vector/compressionhelpers/compression.go:420 +0xb3\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db/vector/hnsw.(*hnsw).distToNode(0xc003f08dc0?, {0x28fa630?, 0xddf5143590?}, 0x16?, {0xdc4af0b400?, 0x100000a20c28830a?, 0xdda46af700?})\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/vector/hnsw/index.go:522 +0x42\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db/vector/hnsw.(*hnsw).knnSearchByVector(0xc003f08dc0, {0xdc4af0b400, 0x300, 0x300}, 0x32, 0xc4bffe9cc0?, {0x0, 0x0})\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/vector/hnsw/search.go:474 +0x1e5\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db/vector/hnsw.(*hnsw).SearchByVector(0xc003f08dc0, {0xdc4af0a800?, 0xd44d878b90?, 0xd44d878d10?}, 0x1223b0a?, {0x0, 0x0})\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/vector/hnsw/search.go:75 +0x2ba\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db.(*IndexQueue).search(0xc0035cd9e0, {0xdc4af0a800?, 0x300, 0x300}, 0xbf800000, 0x32, {0x0?, 0x0?})\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/index_queue.go:546 +0x1f2\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db.(*IndexQueue).SearchByVector(...)\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/index_queue.go:526\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db.(*Shard).ObjectVectorSearch.func2()\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_read.go:437 +0x245\nweaviate-0 weaviate github.com/weaviate/weaviate/adapters/repos/db.(*Shard).ObjectVectorSearch.(*ErrorGroupWrapper).Go.func3()\nweaviate-0 weaviate \t/go/src/github.com/weaviate/weaviate/entities/errors/error_group_wrapper.go:90 +0x97\nweaviate-0 weaviate golang.org/x/sync/errgroup.(*Group).Go.func1()\nweaviate-0 weaviate \t/go/pkg/mod/golang.org/x/sync@v0.7.0/errgroup/errgroup.go:78 +0x56\nweaviate-0 weaviate created by golang.org/x/sync/errgroup.(*Group).Go in goroutine 3247118991\nweaviate-0 weaviate \t/go/pkg/mod/golang.org/x/sync@v0.7.0/errgroup/errgroup.go:75 +0x96\n\n----------\n\n[DudaNogueira (2024-12-03T12:58:28.122Z)]: hi @Jeewan !!\nI suggest you to upgrade to 1.26.latest.\nAs I write, the latest at 1.26 is 1.26.11\nWe always backport critical patches to at least 3 versions.\nLet me know if this is possible and if that fixes those panics.\nTHanks!\n\n----------\n\n[Abdel_Rodriguez (2024-12-04T11:29:55.307Z)]: Hi @Jeewan, could you tell us you PQ configuration? I see there is a problem with the lengths of the centroids in your PQ but it will help me to better understand the problem if I could know your PQ settings.\nThanks for reporting the issue!\nLooking forward to the information.\n\n----------\n\n[Jeewan (2024-12-06T00:33:12.500Z)]: Hi @Abdel_Rodriguez ,\nthanks for response.\nPls find the PQ configuration\n'pq': {'bitCompression': False,\n     'centroids': 256,\n     'enabled': True,\n     'encoder': {'distribution': 'log-normal', 'type': 'kmeans'},\n     'segments': 64,\n     'trainingLimit': 100000}",
    "date_created": "2024-12-02T23:52:47.126Z",
    "has_accepted_answer": false,
    "title": ",\"panic\":\"runtime error: index out of range [2] with length 2\"",
    "topic_id": 9058
  },
  {
    "user_id": 1096,
    "conversation": "[Lakshman_Krishnamurt (2024-10-11T07:36:02.020Z)]: Description\n\nTrtying to pydantic and running into this error\npydantic.errors.PydanticSchemaGenerationError: Unable to generate pydantic-core schema for <class ‘weaviate.client.WeaviateClient’\nIs there any class imports that will resolve this?\nI already have these\nimport weaviate\nimport weaviate.classes as wvc\n\n----------\n\n[DudaNogueira (2024-10-11T20:46:29.834Z)]: hi!\nCan you share the versions of the client you are using?\nI cannot reproduce this.\nThis is the version I am using:\n$ pip freeze | grep weaviate\nweaviate-client==4.8.1\n\n----------\n\n[Lakshman_Krishnamurt (2024-10-12T17:02:24.200Z)]: DudaNogueira:\n\npip freeze | grep weaviate\n\n\nlangchain-weaviate==0.0.3\nweaviate==0.1.0\nweaviate-client==4.8.1\nI worked around by disabling pydantic check for now.  for this class. Not ideal\n\n----------\n\n[Dirk (2024-10-13T07:46:02.821Z)]: Hi, can you please post a full example?",
    "date_created": "2024-10-11T07:36:01.978Z",
    "has_accepted_answer": false,
    "title": "‘weaviate.client.WeaviateClient use with pydantic",
    "topic_id": 4779
  },
  {
    "user_id": 1612,
    "conversation": "[Sumat_Mallick (2024-11-18T10:06:37.831Z)]: Problem Description:\nWe are currently facing challenges with our Weaviate setup on an AWS Ubuntu instance when using version 4 of Weaviate. While our setup works smoothly with Weaviate v3 under the same conditions, v4 encounters issues when connecting to the Weaviate Cloud.\nHere are the details:\n\n\nEnvironment:\n\nInstance: AWS Ubuntu instance.\nGunicorn Workers Tested: sync, gthread, gevent.\nWeaviate Versions:\n\nv3: Works fine under all tested configurations.\nv4: Works with sync and gthread but fails with gevent.\n\n\n\n\n\nError Details:\nWhen using gevent with Weaviate v4, the connection attempt hangs indefinitely at the following line:\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=wcd_url,  # Replace with your Weaviate Cloud URL\n    auth_credentials=Auth.api_key(wcd_api_key),  # Replace with your Weaviate Cloud key\n    headers={'X-OpenAI-Api-key': openai_api_key}  # Replace with your OpenAI API key\n)\n\n\nThe process eventually times out after 120 seconds, and the worker thread is killed with the following error message:[2024-10-09 10:56:37 +0000] [445826] [ERROR] Worker (pid:445830) was sent SIGKILL! Perhaps out of memory?\n\n\n\n\n\nReplication Steps:\n\nCreate a file named vec.py with relevant connection code.\nRun the following command:gunicorn --workers 4 --worker-class gevent --bind 0.0.0.0:8000 --timeout 120 vec:app\n\n\nObserve that with Weaviate v4 and gevent, the connection hangs and fails, while v3 works without any issues.\n\n\n\nAdditional Notes:\n\nThis issue only arises with the gevent worker class in Gunicorn.\nUsing sync or gthread with v4 works as expected.\nThe problem does not seem related to instance memory, as sufficient resources are allocated, and no OOM conditions are observed.\nThe same gevent configuration works for v3 but fails for v4.\n\n----------\n\n[Dirk (2024-12-18T05:45:19.311Z)]: Hello!\nSorry, missed this one!\nCould you either:\n\ntry out our async client (Async API | Weaviate)?\nread these two issues and see if any of the mentioned things work for you?\n\nConnection hang up with gunicorn + uvicorn workers · Issue #1292 · weaviate/weaviate-python-client · GitHub\nProblem upgrading to version higher than 4.6.7 on AWS ECS Cluster · Issue #1309 · weaviate/weaviate-python-client · GitHub\n\n\n\nHope these help",
    "date_created": "2024-11-18T10:06:37.781Z",
    "has_accepted_answer": false,
    "title": "Issue with Connecting to Weaviate Cloud Using gevent Worker Class on AWS Ubuntu Instance",
    "topic_id": 7630
  },
  {
    "user_id": 3578,
    "conversation": "[tapish_22.11 (2025-03-03T06:05:25.723Z)]: I was trying to create a collection with Multi-Tenancy but it is giving the following error.\nWeaviateTimeoutError: The request to Weaviate timed out while awaiting a response. Try adjusting the timeout config for your client. Details: Collection may not have been created properly.\nI followed exact documentation code and even gave the correct collection name and all.\nThis is my code for creating the collection.\nfrom weaviate.classes.config import Configure\npdf_collection = client.collections.create(\nname=“Tapish”,\nmulti_tenancy_config= Configure.multi_tenancy(\nenabled=True,\n)\n)\n\n----------\n\n[Mohamed_Shahin (2025-03-03T09:50:45.020Z)]: Good morning @tapish_22.11,\nHappy Monday!\nCould you please provide more details about your Weaviate configuration and server setup?\nAdditionally, it would be helpful if you could share the script you are using to connect to Weaviate and create the collection.\nBest regards,\nMohamed Shahin\nSupport Engineer\n\n----------\n\n[tapish_22.11 (2025-03-03T10:03:10.820Z)]: Hi @Mohamed_Shahin ,\nThe problem has been solved. Just had to make some changes in the docker file.\nThank You!",
    "date_created": "2025-03-03T06:05:25.666Z",
    "has_accepted_answer": true,
    "title": "Issue in making multi-tenancy Collection in weaviate",
    "topic_id": 10639
  },
  {
    "user_id": 11637,
    "conversation": "[cluel01 (2025-03-20T13:41:31.632Z)]: Hey everyone,\nwe are planning to use Weaviate as our vector db for our internal RAG system. However, as we are building our infrastructure in the Google Cloud, we are struggling with deploying Weaviate as a Cloud Run Service. The problem is that when deploying it as Cloud Run only one port can be exposed per application. All attempts to make it run failed: We have tested to deploy two containers one for REST and one for GRPC while sharing the same volume and then access them via the http_endpoint and grpc_endpoint. This however didn’t work due to concurrency problems. Is there any way to make these things work without adding the complexity of a proxy service? Are we missing out some obvious solutions?\nWe are aware that deploying Weaviate inside Kubernetes (GKE) would be an option, but so far we want to stick to Cloud Run. We are also aware of the existing Weaviate Cloud version, but we want to manage the database ourselves.\nThanks in advance!\n\n----------\n\n[cluel01 (2025-03-20T16:51:42.122Z)]: I managed to get a first workaround by adding a Envoy proxy. However, I now have the same host and port for HTTP and GRPC and the pydantic validation of the connect_to_custom fails because of that. Is there any way to disable this validation? Because apart from that it seems to work.\n\n----------\n\n[DudaNogueira (2025-03-21T13:29:23.012Z)]: Hi @cluel01 !!\nWelcome to our community \nI never seen this being tried, to be honest. So not sure exactly how it plays out.\nBut before the client pydantic issue, can you make sure the grpc port is serving?\nYou can test that with grpcurl:\n# lets test our grpc connection\n❯ wget https://raw.githubusercontent.com/grpc/grpc/master/src/proto/grpc/health/v1/health.proto\n❯ grpcurl -d '{\"service\": \"Weaviate\"}' -proto health.proto grpc.weaviate.mydomain.com:50051 grpc.health.v1.Health/Check\n{\n  \"status\": \"SERVING\"\n}\n\nLet me know if you can share how you did it as I would love to try that too!\nThanks!",
    "date_created": "2025-03-20T13:41:31.578Z",
    "has_accepted_answer": false,
    "title": "How to run containerized Weaviate as Google Cloud Run",
    "topic_id": 20115
  },
  {
    "user_id": 2790,
    "conversation": "[Tibin_Lukose (2025-03-07T07:35:56.660Z)]: Description\nProduction weaviate crashed out of random, not sure what caused though, running docker-compose setup\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: Docker\nMulti Node? Number of Running Nodes: 2 nodes\nClient Language and Version: http-graphql\nMultitenancy: Yes\n\nersion: '3.9'\nservices:\n  weaviate-node-1:\n    networks:\n        - dev\n        - shared\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.6\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_01_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'backup-s3,text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node1'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'\n      BACKUP_S3_BUCKET: 'xx'\n      AWS_ACCESS_KEY_ID: 'xx'\n      AWS_SECRET_ACCESS_KEY: 'xx'\n      AWS_REGION: 'us-east-1'\n      BACKUP_S3_PATH: 'weaviate-backup/'\n  weaviate-node-2:\n    networks:\n        - dev\n        - shared\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.6\n    ports:\n    - 8081:8081\n    - 50052:50052\n    volumes:\n    - weaviate_02_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'backup-s3,text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node2'\n      CLUSTER_GOSSIP_BIND_PORT: '7102'\n      CLUSTER_DATA_BIND_PORT: '7103'\n      CLUSTER_JOIN: 'weaviate-node-1:7100'\n      BACKUP_S3_BUCKET: 'xx'\n      AWS_ACCESS_KEY_ID: 'xx'\n      AWS_SECRET_ACCESS_KEY: 'xx'\n      AWS_REGION: 'us-east-1'\n      BACKUP_S3_PATH: 'weaviate-backup/'\n\nnetworks:\n  dev:\n    driver: \"bridge\"\n  shared:\n    external: true\nvolumes:\n  weaviate_01_data:\n  weaviate_02_data:\n\nAny additional Information\n{“action”:“hnsw_commit_logger_combine_condensed_logs”,“id”:“main”,“input_first”:“/var/lib/weaviate/default/teamQWjneg5YbwZ1/main.hnsw.commitlog.d/1739359455.condensed”,“input_second”:“/var/lib/weaviate/default/teamQWjneg5YbwZ1/main.hnsw.commitlog.d/1741147203.condensed”,“level”:“info”,“msg”:“successfully combined previously condensed commit log files”,“output”:“/var/lib/weaviate/default/teamQWjneg5YbwZ1/main.hnsw.commitlog.d/1739359455”,“time”:“2025-03-06T04:02:01Z”}\n{“action”:“hnsw_commit_logger_combine_condensed_logs”,“id”:“main”,“input_first”:“/var/lib/weaviate/default/teamLkzPdyP7bQro/main.hnsw.commitlog.d/1731038403.condensed”,“input_second”:“/var/lib/weaviate/default/teamLkzPdyP7bQro/main.hnsw.commitlog.d/1741147204.condensed”,“level”:“info”,“msg”:“successfully combined previously condensed commit log files”,“output”:“/var/lib/weaviate/default/teamLkzPdyP7bQro/main.hnsw.commitlog.d/1731038403”,“time”:“2025-03-06T04:02:01Z”}\n{“action”:“hnsw_commit_logger_combine_condensed_logs”,“id”:“main”,“input_first”:“/var/lib/weaviate/default/team37N1aMAaWmpn/main.hnsw.commitlog.d/1721027622.condensed”,“input_second”:“/var/lib/weaviate/default/team37N1aMAaWmpn/main.hnsw.commitlog.d/1741147203.condensed”,“level”:“info”,“msg”:“successfully combined previously condensed commit log files”,“output”:“/var/lib/weaviate/default/team37N1aMAaWmpn/main.hnsw.commitlog.d/1721027622”,“time”:“2025-03-06T04:02:01Z”}\n{“action”:“telemetry_push”,“level”:“info”,“msg”:“telemetry update”,“payload”:“\\u0026{MachineID:30e421f1-2b92-468d-b726-dd2c34a18fd2 Type:UPDATE Version:1.24.6 Modules:backup-s3,generative-cohere,generative-openai,generative-palm,qna-openai,ref2vec-centroid,reranker-cohere,text2vec-cohere,text2vec-huggingface,text2vec-openai,text2vec-palm NumObjects:643377 OS:linux Arch:amd64}”,“time”:“2025-03-06T08:18:09Z”}\n{“level”:“info”,“msg”:“Created shard default_teamxk8mepg2dMyJ in 2.62715ms”,“time”:“2025-03-07T04:00:05Z”}\n{“action”:“hnsw_vector_cache_prefill”,“count”:1000,“index_id”:“main”,“level”:“info”,“limit”:1000000000000,“msg”:“prefilled vector cache”,“time”:“2025-03-07T04:00:05Z”,“took”:83026}\n{“class”:“Default”,“level”:“info”,“msg”:“start uploading files”,“time”:“2025-03-07T04:00:05Z”}\n{“backup_id”:“app-default-250307-040004”,“class”:“Default”,“level”:“info”,“msg”:“release backup”,“time”:“2025-03-07T04:02:09Z”}\n{“class”:“Default”,“level”:“info”,“msg”:“finish uploading files”,“time”:“2025-03-07T04:02:09Z”}\n{“level”:“info”,“msg”:“start uploading meta data”,“time”:“2025-03-07T04:02:09Z”}\n{“level”:“info”,“msg”:“finish uploading meta data”,“time”:“2025-03-07T04:02:10Z”}\n{“action”:“create_backup”,“backup_id”:“app-default-250307-040004”,“level”:“info”,“msg”:“backup completed successfully”,“time”:“2025-03-07T04:02:10Z”}\n{“action”:“startup”,“default_vectorizer_module”:“none”,“level”:“info”,“msg”:“the default vectorizer modules is set to \"none\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer”,“time”:“2025-03-07T07:18:20Z”}\n{“action”:“startup”,“auto_schema_enabled”:true,“level”:“info”,“msg”:“auto schema enabled setting is set to \"true\"”,“time”:“2025-03-07T07:18:20Z”}\n{“level”:“info”,“msg”:“No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true”,“time”:“2025-03-07T07:18:20Z”}\n{“action”:“broadcast_abort_transaction”,“error”:“host \"172.19.0.3:7101\": send http request: Delete \"http://172.19.0.3:7101/schema/transactions/5ba28efc-2f25-43b6-88f0-e2c11a4f6a38\\”: dial tcp 172.19.0.3:7101: connect: connection refused\",“id”:“5ba28efc-2f25-43b6-88f0-e2c11a4f6a38”,“level”:“error”,“msg”:“broadcast tx abort failed”,“time”:“2025-03-07T07:18:20Z”}\n{“action”:“startup”,“error”:“could not load or initialize schema: sync schema with other nodes in the cluster: read schema: open transaction: broadcast open transaction: host \"172.19.0.3:7101\": send http request: Post \"http://172.19.0.3:7101/schema/transactions/\\”: dial tcp 172.19.0.3:7101: connect: connection refused\",“level”:“fatal”,“msg”:“could not initialize schema manager”,“time”:“2025-03-07T07:18:20Z”}\n{“action”:“startup”,“default_vectorizer_module”:“none”,“level”:“info”,“msg”:“the default vectorizer modules is set to \"none\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer”,“time”:“2025-03-07T07:18:21Z”}\n{“action”:“startup”,“auto_schema_enabled”:true,“level”:“info”,“msg”:“auto schema enabled setting is set to \"true\"”,“time”:“2025-03-07T07:18:21Z”}\n{“action”:“memberlist_init”,“error”:“1 error occurred:\\n\\t* Failed to join 172.19.0.3:7100: dial tcp 172.19.0.3:7100: connect: connection refused\\n\\n”,“level”:“error”,“msg”:“memberlist join not successful”,“remote_hostname”:[“weaviate-node-1:7100”],“time”:“2025-03-07T07:18:21Z”}\n{“action”:“startup”,“error”:“join cluster: 1 error occurred:\\n\\t* Failed to join 172.19.0.3:7100: dial tcp 172.19.0.3:7100: connect: connection refused\\n\\n”,“level”:“error”,“msg”:“could not init cluster state”,“time”:“2025-03-07T07:18:21Z”}\n{“action”:“startup”,“default_vectorizer_module”:“none”,“level”:“info”,“msg”:“the default vectorizer modules is set to \"none\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer”,“time”:“2025-03-07T07:18:22Z”}\n{“action”:“startup”,“auto_schema_enabled”:true,“level”:“info”,“msg”:“auto schema enabled setting is set to \"true\"”,“time”:“2025-03-07T07:18:22Z”}\n{“level”:“info”,“msg”:“No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true”,“time”:“2025-03-07T07:18:22Z”}\n{“level”:“warning”,“msg”:“Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.”,“time”:“2025-03-07T07:18:22Z”}\n{“action”:“grpc_startup”,“level”:“info”,“msg”:“grpc server listening at [::]:50051”,“time”:“2025-03-07T07:18:22Z”}\n{“action”:“restapi_management”,“level”:“info”,“msg”:“Serving weaviate at http://[::]:8080”,“time”:“2025-03-07T07:18:22Z”}\n{“action”:“telemetry_push”,“level”:“info”,“msg”:“telemetry started”,“payload”:“\\u0026{MachineID:2c582ae5-789d-447c-9b25-1cc60e5b2bc7 Type:INIT Version:1.24.6 Modules:backup-s3,generative-cohere,generative-openai,generative-palm,qna-openai,ref2vec-centroid,reranker-cohere,text2vec-cohere,text2vec-huggingface,text2vec-openai,text2vec-palm NumObjects:0 OS:linux Arch:amd64}”,“time”:“2025-03-07T07:18:22Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“Default”,“index”:“default”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/objects/segment-1727236802809722618”,“shard”:“team0wMvbmZOdYAl”,“time”:“2025-03-07T07:18:23Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“Default”,“index”:“default”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/property__id/segment-1727236802810307015”,“shard”:“team0wMvbmZOdYAl”,“time”:“2025-03-07T07:18:23Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“Default”,“index”:“default”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/property_docId/segment-1727236802810364796”,“shard”:“team0wMvbmZOdYAl”,“time”:“2025-03-07T07:18:23Z”}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Default\",\"index\":\"default\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/property_text/segment-1727236802810419938\",\"shard\":\"team0wMvbmZOdYAl\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Default\",\"index\":\"default\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/property_correctionId/segment-1727236802810704006\",\"shard\":\"team0wMvbmZOdYAl\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Default\",\"index\":\"default\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/property_text_searchable/segment-1727236802810544466\",\"shard\":\"team0wMvbmZOdYAl\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"level\":\"info\",\"msg\":\"Completed loading shard default_team0wMvbmZOdYAl in 10.048082ms\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-03-07T07:18:23Z\",\"took\":83694}\n\n{\"action\":\"hnsw_commit_logger_combine_condensed_logs\",\"id\":\"main\",\"input_first\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/main.hnsw.commitlog.d/1727236802.condensed\",\"input_second\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/main.hnsw.commitlog.d/1741233604.condensed\",\"level\":\"info\",\"msg\":\"successfully combined previously condensed commit log files\",\"output\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/main.hnsw.commitlog.d/1727236802\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n----------\n\n[Mohamed_Shahin (2025-03-08T20:11:05.932Z)]: Hi @Tibin_Lukose,\nThis error is related to an old panic from back in the day, but the bug has already been resolved besides many other improvements:\n“error”: “could not load or initialize schema: sync schema with other nodes in the cluster: read schema: open transaction: broadcast open transaction.”\nPlease be aware that you’re running a very outdated version of Weaviate, even before the RAFT mechanism was implemented for multi-node clusters.\nYou must upgrade to v1.25.32 post-RAFT, despite the fact that 1.25 is still considered outdated. The latest version of Weaviate is 1.29, so I highly recommend planning an upgrade soon - there are way too many features and great improvements that have been implemented.\nAdditionally, I see that you have only 2 nodes in your cluster. I’d highly recommend reading up on the concept of multi-node clusters. It is generally better to have 3 nodes (an odd number) for replication in Weaviate, rather than 2 nodes (an even number). Here’s why:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCluster Architecture | Weaviate\n\n  This page describes how the nodes or clusters in Weaviate's replication design behave.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nRaft-based cluster like Weaviate, a quorum is needed for the cluster to function properly. With 3 nodes, the quorum is 2, which means the cluster can continue to operate even if one node fails. In contrast, a 2-node cluster requires both nodes to be available to form a quorum, making it less fault-tolerant.\nConsensus resolution: An odd number of nodes makes it easier to resolve conflicts and reach consensus. In a 3-node setup, a quorum can be reached with 2 nodes, providing better fault tolerance. A replication factor of 3 or 5 is commonly used as it provides a good balance between performance and fault tolerance.\nI hope this helps!\nRegards,\nMohamed Shahin\nWeaviate Support Engineer",
    "date_created": "2025-03-07T07:35:56.589Z",
    "has_accepted_answer": false,
    "title": "Production weaviate 24.6 crashed",
    "topic_id": 11686
  },
  {
    "user_id": 3095,
    "conversation": "[DevelMyCry (2024-12-24T10:08:13.633Z)]: Hey Weaviate community! I don’t know how to achieve maximum response time reduction (latency reduction) through Product Quantization.\nThere are two named vectors. The lengths of these vectors are 768 and 1024. I followed the steps on the official site for PQ, but I can’t understand a few points:\n\nIs it possible to specify a different number of segments for each vector when creating collection (for example, on Standalone)? I tried to do this, but I got weaviate log messages (errors) like “inconsistent vector length”…\nWhy does search time with PQ for a dataset size from 1 to 5 million (I haven’t tested on larger datasets yet) is worse than Weaviate instance without quantization?\nWhat is the best way to configure quantization to prioritize fast service response time for storage with more than 20 million vectors? The goal is to gain some processing time advantage compared to regular storage.\n\nP.S. I mostly configure PQ in creation time of collection. I don’t know which option is better, update config or creation with pq. Also I turned on ASYNC_INDEXING. And I tried set segments to 0 (or just set training limit), but don’t understand in which case that helps (test results aren’t OK). Weaviate version 1.25.25\n\n----------\n\n[DudaNogueira (2024-12-26T14:47:14.412Z)]: hi @DevelMyCry !!\nWelcome to our community \n\n\nYes. You can provide the segments, as described here. If you do not specify one, Weaviate will try to figure out the best segments number.\n\n\nNot sure here. Can you provide the code to replicate and the same steps you did? For example, it may take a while for Weaviate to index and compress all data, so maybe if you do queries right after, the response time may be affected.\n\n\nOne of the motivations of replication is to increase QPS. Also, making sure you have fast disks and servers close to the client (same region, for example).\n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[DevelMyCry (2024-12-27T04:53:59.369Z)]: Hi @DudaNogueira!\nMy Configuration and steps:\nServer: Standalone\nCPU LIMIT: 40\nLENGTH OF VECTOR TYPE ONE - 768\nLENGTH OF VECTOR TYPE TWO - 1024\nIndex - HNSW\nCONSISTENCY LEVEL : ONE\ndocker-compose:\nversion: '3.4'\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:1.25.25\n    ports:\n    - 8081:8080\n    - 50052:50051\n    volumes:\n    - ./test_data:/data\n    - ./backups:/tmp/backups\n    restart: on-failure:0\n    environment:\n      TOMBSTONE_DELETION_CONCURRENCY: '4'\n\n      DISABLE_LAZY_LOAD_SHARDS: 'true'\n      HNSW_STARTUP_WAIT_FOR_VECTOR_CACHE: 'true'\n\n      STANDALONE_MODE: 'true'\n      AUTOSCHEMA_ENABLED: 'false'\n      QUERY_MAXIMUM_RESULTS: 10000\n\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/data'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      CLUSTER_HOSTNAME: 'node1'\n      ENABLE_MODULES: 'backup-filesystem,backup-s3'\n      BACKUP_FILESYSTEM_PATH: '/tmp/backups'\n\n      LIMIT_RESOURCES: 'true'\n      ASYNC_INDEXING: 'true'\n\n      LOG_LEVEL: 'debug'\n\n      PROMETHEUS_MONITORING_ENABLED: 'false'\n      GOMAXPROCS: 40\n      GOGC: 90\n      PERSISTENCE_HNSW_MAX_LOG_SIZE: 4GiB\n    deploy:\n      resources:\n        limits:\n          cpus: '40.0'\n\nBlock of code for collection creation:\nclient.collections.create(\n        name=some_name,\n        properties=[\n            weaviate.classes.config.Property(\n                name=SOME_CATEGORY,\n                data_type=weaviate.classes.config.DataType.TEXT\n            ),\n            weaviate.classes.config.Property(\n                name=SOME_PROP,\n                data_type=weaviate.classes.config.DataType.TEXT\n            )\n        ],\n        vectorizer_config=[\n            weaviate.classes.config.Configure.NamedVectors.none(\n                name=WV_VECTOR_TYPE_ONE,\n                vector_index_config=weaviate.classes.config.Configure.VectorIndex.hnsw(\n                    #quantizer=weaviate.classes.config.Configure.VectorIndex.Quantizer.pq(segments=8, training_limit=100000),\n                    distance_metric=weaviate.classes.config.VectorDistances.COSINE,\n                    ef=320,\n                    ef_construction=320,\n                    max_connections=100\n                )\n            ),\n            weaviate.classes.config.Configure.NamedVectors.none(\n                name=WV_VECTOR_TYPE_TWO,\n                vector_index_config=weaviate.classes.config.Configure.VectorIndex.hnsw(\n                    #quantizer=weaviate.classes.config.Configure.VectorIndex.Quantizer.pq(segments=8, training_limit=100000),\n                    distance_metric=weaviate.classes.config.VectorDistances.COSINE,\n                    ef=480,\n                    ef_construction=480,\n                    max_connections=120\n                )\n            )\n        ],\n    )\n\nBlock of search query:\nSEARCH THREADS = 4\nQUERY_TIMEOUT_SEC = 60\ncollection = client.collections.get(SCHEMA)\nif CONSISTENCY_LEVEL:\n     collection =\n     collection.with_consistency_level(CONSISTENCY_LEVEL)\n                query = collection.query.near_vector(\n                    near_vector=vectors[VECTOR],\n                    limit=LIMIT,\n                    filters=Filter.by_property(filter_property).equal(filter_value) if filter_property and filter_value else None,\n                    return_metadata=MetadataQuery(distance=True),\n                    return_properties=properties,\n                    target_vector=VECTOR,\n                )\n\nImporting was through batching (batch size = 5000). After importing, I waited until “queue size” was equal to 0.\nWith the same import and after waiting finish of “queue” in a normal configuration (without compression), the speed is an order of magnitude higher than with compression.\nsearch on 5 million vectors:\n(without any compression)\nimage579×380 35.2 KB\n(segments: 128)\nimage533×166 40.4 KB\nAnd I noticed that with segments=6 results are better than for example segments=128 or 256.  But even with the best segment option (segments=6), the speed is about 2 times slower than without quantization.\n\n----------\n\n[DudaNogueira (2024-12-27T13:45:46.812Z)]: Hi!\nIs there any specific reason to use 1.25.25? Do you get the same results with 1.28.latest?\nAlso, Those different times (148.8 obj/s x 37.58obj/s) are about querying, not importing, right?\nAnother question: why those values for max_connections and ef/ef_construction?\nI will need to grab more info here so I can escalate this with our team.\nAre you able to perform this test on a publicly available dataset?\nThanks!\n\n----------\n\n[DevelMyCry (2024-12-30T05:33:11.222Z)]: Hello!\n\nUsing 1.25.25 is temporary, but I tried 1.27 - results were the same.\nAbout querying (search)\nFor high recall on production (may be to do fix it?)\nI’ll be looking forward for your response.\nIt is important for me to find out from the team what solutions are available in this situation, what I need to pay attention to, and does compression give a speed advantage compared to regular HNSW (with the same ef, ef_construction, max_connections)?",
    "date_created": "2024-12-24T10:08:13.582Z",
    "has_accepted_answer": false,
    "title": "How to determine the optimal number of segments in PQ to reduce requests latency (search)?",
    "topic_id": 9418
  },
  {
    "user_id": 2410,
    "conversation": "[bam (2024-11-13T02:52:10.978Z)]: Description\n11.37 MB pdf file 647 chunks\nUI Error Response:\nImport for NASM's essentials of corrective exercise training ( PDFDrive ).pdf failed: Import for NASM's essentials of corrective exercise training ( PDFDrive ).pdf failed: Batch vectorization failed: Vectorization failed for some batches: 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed'), 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed'), 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed'), 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed'), 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed')\nServer Setup Information\n\nWeaviate Server Version: Docker\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\nScreenshot 2024-11-12 at 20.51.261928×1262 128 KB\nScreenshot 2024-11-12 at 20.51.331966×1242 166 KB\n\nAny additional Information\nDebugger Error Response:\nDebugging File Configuration\n{\n  \"fileID\": \"NASM's essentials of corrective exercise training ( PDFDrive ).pdf\",\n  \"filename\": \"NASM's essentials of corrective exercise training ( PDFDrive ).pdf\",\n  \"extension\": \"pdf\",\n  \"status_report\": {\n    \"STARTING\": {\n      \"fileID\": \"NASM's essentials of corrective exercise training ( PDFDrive ).pdf\",\n      \"status\": \"STARTING\",\n      \"message\": \"Starting Import\",\n      \"took\": 0\n    },\n    \"LOADING\": {\n      \"fileID\": \"NASM's essentials of corrective exercise training ( PDFDrive ).pdf\",\n      \"status\": \"LOADING\",\n      \"message\": \"Loaded NASM's essentials of corrective exercise training ( PDFDrive ).pdf\",\n      \"took\": 14.4\n    },\n    \"CHUNKING\": {\n      \"fileID\": \"NASM's essentials of corrective exercise training ( PDFDrive ).pdf\",\n      \"status\": \"CHUNKING\",\n      \"message\": \"Split NASM's essentials of corrective exercise training ( PDFDrive ).pdf into 647 chunks\",\n      \"took\": 0.31\n    },\n    \"EMBEDDING\": {\n      \"fileID\": \"NASM's essentials of corrective exercise training ( PDFDrive ).pdf\",\n      \"status\": \"EMBEDDING\",\n      \"message\": \"\",\n      \"took\": 0\n    },\n    \"ERROR\": {\n      \"fileID\": \"NASM's essentials of corrective exercise training ( PDFDrive ).pdf\",\n      \"status\": \"ERROR\",\n      \"message\": \"Import for NASM's essentials of corrective exercise training ( PDFDrive ).pdf failed: Import for NASM's essentials of corrective exercise training ( PDFDrive ).pdf failed: Batch vectorization failed: Vectorization failed for some batches: 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed'), 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed'), 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed'), 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed'), 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed')\",\n      \"took\": 0\n    }\n  },\n  \"source\": \"\",\n  \"isURL\": false,\n  \"metadata\": \"\",\n  \"overwrite\": false,\n  \"content\": \"File Content\",\n  \"labels\": [\n    \"Document\"\n  ],\n  \"rag_config\": {\n    \"Reader\": {\n      \"selected\": \"Default\",\n      \"components\": {\n        \"Default\": {\n          \"name\": \"Default\",\n          \"variables\": [],\n          \"library\": [\n            \"pypdf\",\n            \"docx\",\n            \"spacy\"\n          ],\n          \"description\": \"Ingests text, code, PDF, and DOCX files\",\n          \"config\": {},\n          \"type\": \"FILE\",\n          \"available\": true\n        },\n        \"HTML\": {\n          \"name\": \"HTML\",\n          \"variables\": [],\n          \"library\": [\n            \"markdownify\",\n            \"beautifulsoup4\"\n          ],\n          \"description\": \"Downloads and ingests HTML from a URL, with optional recursive fetching.\",\n          \"config\": {\n            \"URLs\": {\n              \"type\": \"multi\",\n              \"value\": \"\",\n              \"description\": \"Add URLs to retrieve data from\",\n              \"values\": []\n            },\n            \"Convert To Markdown\": {\n              \"type\": \"bool\",\n              \"value\": 0,\n              \"description\": \"Should the HTML be converted into markdown?\",\n              \"values\": []\n            },\n            \"Recursive\": {\n              \"type\": \"bool\",\n              \"value\": 0,\n              \"description\": \"Fetch linked pages recursively\",\n              \"values\": []\n            },\n            \"Max Depth\": {\n              \"type\": \"number\",\n              \"value\": 3,\n              \"description\": \"Maximum depth for recursive fetching\",\n              \"values\": []\n            }\n          },\n          \"type\": \"URL\",\n          \"available\": false\n        },\n        \"Git\": {\n          \"name\": \"Git\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Downloads and ingests all files from a GitHub or GitLab Repo.\",\n          \"config\": {\n            \"Platform\": {\n              \"type\": \"dropdown\",\n              \"value\": \"GitHub\",\n              \"description\": \"Select the Git platform\",\n              \"values\": [\n                \"GitHub\",\n                \"GitLab\"\n              ]\n            },\n            \"Owner\": {\n              \"type\": \"text\",\n              \"value\": \"\",\n              \"description\": \"Enter the repo owner (GitHub) or group/user (GitLab)\",\n              \"values\": []\n            },\n            \"Name\": {\n              \"type\": \"text\",\n              \"value\": \"\",\n              \"description\": \"Enter the repo name\",\n              \"values\": []\n            },\n            \"Branch\": {\n              \"type\": \"text\",\n              \"value\": \"main\",\n              \"description\": \"Enter the branch name\",\n              \"values\": []\n            },\n            \"Path\": {\n              \"type\": \"text\",\n              \"value\": \"\",\n              \"description\": \"Enter the path or leave it empty to import all\",\n              \"values\": []\n            },\n            \"Git Token\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your GitHub/GitLab Token here if you haven't set it up as environment variable `GITHUB_TOKEN` or `GITLAB_TOKEN`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"URL\",\n          \"available\": true\n        },\n        \"Unstructured IO\": {\n          \"name\": \"Unstructured IO\",\n          \"variables\": [\n            \"UNSTRUCTURED_API_KEY\"\n          ],\n          \"library\": [],\n          \"description\": \"Uses the Unstructured API to import multiple file types such as plain text and documents\",\n          \"config\": {\n            \"Strategy\": {\n              \"type\": \"dropdown\",\n              \"value\": \"auto\",\n              \"description\": \"Set the extraction strategy\",\n              \"values\": [\n                \"auto\",\n                \"hi_res\",\n                \"ocr_only\",\n                \"fast\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"Set your Unstructured API Key here or set it as an environment variable `UNSTRUCTURED_API_KEY`\",\n              \"values\": []\n            },\n            \"API URL\": {\n              \"type\": \"text\",\n              \"value\": \"https://api.unstructured.io/general/v0/general\",\n              \"description\": \"Set the base URL to the Unstructured API or set it as an environment variable `UNSTRUCTURED_API_URL`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"FILE\",\n          \"available\": false\n        },\n        \"Firecrawl\": {\n          \"name\": \"Firecrawl\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Use Firecrawl to scrape websites and ingest them into Verba\",\n          \"config\": {\n            \"Mode\": {\n              \"type\": \"dropdown\",\n              \"value\": \"Scrape\",\n              \"description\": \"Switch between scraping and crawling. Note that crawling can take some time.\",\n              \"values\": [\n                \"Crawl\",\n                \"Scrape\"\n              ]\n            },\n            \"URLs\": {\n              \"type\": \"multi\",\n              \"value\": \"\",\n              \"description\": \"Add URLs to retrieve data from\",\n              \"values\": []\n            },\n            \"Firecrawl API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your Firecrawl API Key or set it as environment variable `FIRECRAWL_API_KEY`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"URL\",\n          \"available\": true\n        }\n      }\n    },\n    \"Chunker\": {\n      \"selected\": \"Token\",\n      \"components\": {\n        \"Token\": {\n          \"name\": \"Token\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Splits documents based on word tokens\",\n          \"config\": {\n            \"Tokens\": {\n              \"type\": \"number\",\n              \"value\": 250,\n              \"description\": \"Choose how many Token per chunks\",\n              \"values\": []\n            },\n            \"Overlap\": {\n              \"type\": \"number\",\n              \"value\": 50,\n              \"description\": \"Choose how many Tokens should overlap between chunks\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Sentence\": {\n          \"name\": \"Sentence\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Splits documents based on word tokens\",\n          \"config\": {\n            \"Sentences\": {\n              \"type\": \"number\",\n              \"value\": 5,\n              \"description\": \"Choose how many Sentences per chunks\",\n              \"values\": []\n            },\n            \"Overlap\": {\n              \"type\": \"number\",\n              \"value\": 1,\n              \"description\": \"Choose how many Sentences should overlap between chunks\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Recursive\": {\n          \"name\": \"Recursive\",\n          \"variables\": [],\n          \"library\": [\n            \"langchain_text_splitters \"\n          ],\n          \"description\": \"Recursively split documents based on predefined characters using LangChain\",\n          \"config\": {\n            \"Chunk Size\": {\n              \"type\": \"number\",\n              \"value\": 500,\n              \"description\": \"Choose how many characters per chunks\",\n              \"values\": []\n            },\n            \"Overlap\": {\n              \"type\": \"number\",\n              \"value\": 100,\n              \"description\": \"Choose how many characters per chunks\",\n              \"values\": []\n            },\n            \"Seperators\": {\n              \"type\": \"multi\",\n              \"value\": \"\",\n              \"description\": \"Select seperators to split the text\",\n              \"values\": [\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \".\",\n                \",\",\n                \"​\",\n                \"，\",\n                \"、\",\n                \"．\",\n                \"。\",\n                \"\"\n              ]\n            }\n          },\n          \"type\": \"\",\n          \"available\": false\n        },\n        \"Semantic\": {\n          \"name\": \"Semantic\",\n          \"variables\": [],\n          \"library\": [\n            \"sklearn\"\n          ],\n          \"description\": \"Split documents based on semantic similarity or max sentences\",\n          \"config\": {\n            \"Breakpoint Percentile Threshold\": {\n              \"type\": \"number\",\n              \"value\": 80,\n              \"description\": \"Percentile Threshold to split and create a chunk, the lower the more chunks you get\",\n              \"values\": []\n            },\n            \"Max Sentences Per Chunk\": {\n              \"type\": \"number\",\n              \"value\": 20,\n              \"description\": \"Maximum number of sentences per chunk\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"HTML\": {\n          \"name\": \"HTML\",\n          \"variables\": [],\n          \"library\": [\n            \"langchain_text_splitters \"\n          ],\n          \"description\": \"Split documents based on HTML tags using LangChain\",\n          \"config\": {},\n          \"type\": \"\",\n          \"available\": false\n        },\n        \"Markdown\": {\n          \"name\": \"Markdown\",\n          \"variables\": [],\n          \"library\": [\n            \"langchain_text_splitters\"\n          ],\n          \"description\": \"Split documents based on markdown formatting using LangChain\",\n          \"config\": {},\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Code\": {\n          \"name\": \"Code\",\n          \"variables\": [],\n          \"library\": [\n            \"langchain_text_splitters \"\n          ],\n          \"description\": \"Split code based on programming language using LangChain\",\n          \"config\": {\n            \"Language\": {\n              \"type\": \"dropdown\",\n              \"value\": \"python\",\n              \"description\": \"Select programming language\",\n              \"values\": [\n                \"cpp\",\n                \"go\",\n                \"java\",\n                \"kotlin\",\n                \"js\",\n                \"ts\",\n                \"php\",\n                \"proto\",\n                \"python\",\n                \"rst\",\n                \"ruby\",\n                \"rust\",\n                \"scala\",\n                \"swift\",\n                \"markdown\",\n                \"latex\",\n                \"html\",\n                \"sol\",\n                \"csharp\",\n                \"cobol\",\n                \"c\",\n                \"lua\",\n                \"perl\",\n                \"haskell\",\n                \"elixir\"\n              ]\n            },\n            \"Chunk Size\": {\n              \"type\": \"number\",\n              \"value\": 500,\n              \"description\": \"Choose how many characters per chunk\",\n              \"values\": []\n            },\n            \"Chunk Overlap\": {\n              \"type\": \"number\",\n              \"value\": 50,\n              \"description\": \"Choose how many characters overlap between chunks\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": false\n        },\n        \"JSON\": {\n          \"name\": \"JSON\",\n          \"variables\": [],\n          \"library\": [\n            \"langchain_text_splitters \"\n          ],\n          \"description\": \"Split json files using LangChain\",\n          \"config\": {\n            \"Chunk Size\": {\n              \"type\": \"number\",\n              \"value\": 500,\n              \"description\": \"Choose how many characters per chunks\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": false\n        }\n      }\n    },\n    \"Embedder\": {\n      \"selected\": \"Ollama\",\n      \"components\": {\n        \"Ollama\": {\n          \"name\": \"Ollama\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Vectorizes documents and queries using Ollama. If your Ollama instance is not running on http://localhost:11434, you can change the URL by setting the OLLAMA_URL environment variable.\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"snowflake-arctic-embed:latest\",\n              \"description\": \"Select a installed Ollama model from http://localhost:11434. You can change the URL by setting the OLLAMA_URL environment variable. \",\n              \"values\": [\n                \"snowflake-arctic-embed:latest\",\n                \"llama3:latest\",\n                \"codegemma:latest\",\n                \"llama3.2:latest\"\n              ]\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"SentenceTransformers\": {\n          \"name\": \"SentenceTransformers\",\n          \"variables\": [],\n          \"library\": [\n            \"sentence_transformers\"\n          ],\n          \"description\": \"Embeds and retrieves objects using SentenceTransformer\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"all-MiniLM-L6-v2\",\n              \"description\": \"Select an HuggingFace Embedding Model\",\n              \"values\": [\n                \"all-MiniLM-L6-v2\",\n                \"mixedbread-ai/mxbai-embed-large-v1\",\n                \"all-mpnet-base-v2\",\n                \"BAAI/bge-m3\",\n                \"all-MiniLM-L12-v2\",\n                \"paraphrase-MiniLM-L6-v2\"\n              ]\n            }\n          },\n          \"type\": \"\",\n          \"available\": false\n        },\n        \"Weaviate\": {\n          \"name\": \"Weaviate\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Vectorizes documents and queries using Weaviate's In-House Embedding Service.\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"Embedding Service\",\n              \"description\": \"Select a Weaviate Embedding Service Model\",\n              \"values\": [\n                \"Embedding Service\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"Weaviate Embedding Service Key (or set EMBEDDING_SERVICE_KEY env var)\",\n              \"values\": []\n            },\n            \"URL\": {\n              \"type\": \"text\",\n              \"value\": \"\",\n              \"description\": \"Weaviate Embedding Service URL (if different from default)\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"VoyageAI\": {\n          \"name\": \"VoyageAI\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Vectorizes documents and queries using VoyageAI\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"voyage-2\",\n              \"description\": \"Select a VoyageAI Embedding Model\",\n              \"values\": [\n                \"voyage-2\",\n                \"voyage-large-2\",\n                \"voyage-finance-2\",\n                \"voyage-multilingual-2\",\n                \"voyage-law-2\",\n                \"voyage-code-2\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"OpenAI API Key (or set OPENAI_API_KEY env var)\",\n              \"values\": []\n            },\n            \"URL\": {\n              \"type\": \"text\",\n              \"value\": \"https://api.voyageai.com/v1\",\n              \"description\": \"OpenAI API Base URL (if different from default)\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Cohere\": {\n          \"name\": \"Cohere\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Vectorizes documents and queries using Cohere\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"embed-english-v3.0\",\n              \"description\": \"Select a Cohere Embedding Model\",\n              \"values\": [\n                \"embed-english-v3.0\",\n                \"embed-multilingual-v3.0\",\n                \"embed-english-light-v3.0\",\n                \"embed-multilingual-light-v3.0\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your Cohere API Key here or set it as environment variable `COHERE_API_KEY`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"OpenAI\": {\n          \"name\": \"OpenAI\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Vectorizes documents and queries using OpenAI\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"text-embedding-3-small\",\n              \"description\": \"Select an OpenAI Embedding Model\",\n              \"values\": [\n                \"text-embedding-ada-002\",\n                \"text-embedding-3-small\",\n                \"text-embedding-3-large\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"OpenAI API Key (or set OPENAI_API_KEY env var)\",\n              \"values\": []\n            },\n            \"URL\": {\n              \"type\": \"text\",\n              \"value\": \"https://api.openai.com/v1\",\n              \"description\": \"OpenAI API Base URL (if different from default)\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        }\n      }\n    },\n    \"Retriever\": {\n      \"selected\": \"Advanced\",\n      \"components\": {\n        \"Advanced\": {\n          \"name\": \"Advanced\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Retrieve relevant chunks from Weaviate\",\n          \"config\": {\n            \"Suggestion\": {\n              \"type\": \"bool\",\n              \"value\": 1,\n              \"description\": \"Enable Autocomplete Suggestions\",\n              \"values\": []\n            },\n            \"Search Mode\": {\n              \"type\": \"dropdown\",\n              \"value\": \"Hybrid Search\",\n              \"description\": \"Switch between search types.\",\n              \"values\": [\n                \"Hybrid Search\"\n              ]\n            },\n            \"Limit Mode\": {\n              \"type\": \"dropdown\",\n              \"value\": \"Autocut\",\n              \"description\": \"Method for limiting the results. Autocut decides automatically how many chunks to retrieve, while fixed sets a fixed limit.\",\n              \"values\": [\n                \"Autocut\",\n                \"Fixed\"\n              ]\n            },\n            \"Limit/Sensitivity\": {\n              \"type\": \"number\",\n              \"value\": 1,\n              \"description\": \"Value for limiting the results. Value controls Autocut sensitivity and Fixed Size\",\n              \"values\": []\n            },\n            \"Chunk Window\": {\n              \"type\": \"number\",\n              \"value\": 1,\n              \"description\": \"Number of surrounding chunks of retrieved chunks to add to context\",\n              \"values\": []\n            },\n            \"Threshold\": {\n              \"type\": \"number\",\n              \"value\": 80,\n              \"description\": \"Threshold of chunk score to apply window technique (1-100)\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        }\n      }\n    },\n    \"Generator\": {\n      \"selected\": \"Ollama\",\n      \"components\": {\n        \"Ollama\": {\n          \"name\": \"Ollama\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Generate answers using Ollama. If your Ollama instance is not running on http://localhost:11434, you can change the URL by setting the OLLAMA_URL environment variable.\",\n          \"config\": {\n            \"System Message\": {\n              \"type\": \"text\",\n              \"value\": \"You are Fit T Centenarian, a chatbot for Retrieval Augmented Generation (RAG). You will receive a user query and context pieces that have a semantic similarity to that query. Please answer these user queries only with the provided context. Mention documents you used from the context if you use them to reduce hallucination. If the provided documentation does not provide enough information, say so. If the user asks questions about you as a chatbot specifially, answer them naturally. If the answer requires code examples encapsulate them with ```programming-language-name ```. Don't do pseudo-code.\",\n              \"description\": \"System Message\",\n              \"values\": []\n            },\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"llama3.2:latest\",\n              \"description\": \"Select an installed Ollama model from http://localhost:11434.\",\n              \"values\": [\n                \"snowflake-arctic-embed:latest\",\n                \"llama3:latest\",\n                \"codegemma:latest\",\n                \"llama3.2:latest\"\n              ]\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"OpenAI\": {\n          \"name\": \"OpenAI\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Using OpenAI LLM models to generate answers to queries\",\n          \"config\": {\n            \"System Message\": {\n              \"type\": \"text\",\n              \"value\": \"You are Verba, a chatbot for Retrieval Augmented Generation (RAG). You will receive a user query and context pieces that have a semantic similarity to that query. Please answer these user queries only with the provided context. Mention documents you used from the context if you use them to reduce hallucination. If the provided documentation does not provide enough information, say so. If the user asks questions about you as a chatbot specifially, answer them naturally. If the answer requires code examples encapsulate them with ```programming-language-name ```. Don't do pseudo-code.\",\n              \"description\": \"System Message\",\n              \"values\": []\n            },\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"gpt-4o\",\n              \"description\": \"Select an OpenAI Embedding Model\",\n              \"values\": [\n                \"gpt-4o\",\n                \"gpt-3.5-turbo\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your OpenAI API Key here or set it as environment variable `OPENAI_API_KEY`\",\n              \"values\": []\n            },\n            \"URL\": {\n              \"type\": \"text\",\n              \"value\": \"https://api.openai.com/v1\",\n              \"description\": \"You can change the Base URL here if needed\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Anthropic\": {\n          \"name\": \"Anthropic\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Using Anthropic LLM models to generate answers to queries\",\n          \"config\": {\n            \"System Message\": {\n              \"type\": \"text\",\n              \"value\": \"You are Verba, a chatbot for Retrieval Augmented Generation (RAG). You will receive a user query and context pieces that have a semantic similarity to that query. Please answer these user queries only with the provided context. Mention documents you used from the context if you use them to reduce hallucination. If the provided documentation does not provide enough information, say so. If the user asks questions about you as a chatbot specifially, answer them naturally. If the answer requires code examples encapsulate them with ```programming-language-name ```. Don't do pseudo-code.\",\n              \"description\": \"System Message\",\n              \"values\": []\n            },\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"claude-3-5-sonnet-20240620\",\n              \"description\": \"Select an Anthropic Model\",\n              \"values\": [\n                \"claude-3-5-sonnet-20240620\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your Anthropic API Key here or set it as environment variable `ANTHROPIC_API_KEY`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Cohere\": {\n          \"name\": \"Cohere\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Generator using Cohere's command-r-plus model\",\n          \"config\": {\n            \"System Message\": {\n              \"type\": \"text\",\n              \"value\": \"You are Verba, a chatbot for Retrieval Augmented Generation (RAG). You will receive a user query and context pieces that have a semantic similarity to that query. Please answer these user queries only with the provided context. Mention documents you used from the context if you use them to reduce hallucination. If the provided documentation does not provide enough information, say so. If the user asks questions about you as a chatbot specifially, answer them naturally. If the answer requires code examples encapsulate them with ```programming-language-name ```. Don't do pseudo-code.\",\n              \"description\": \"System Message\",\n              \"values\": []\n            },\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"embed-english-v3.0\",\n              \"description\": \"Select a Cohere Embedding Model\",\n              \"values\": [\n                \"embed-english-v3.0\",\n                \"embed-multilingual-v3.0\",\n                \"embed-english-light-v3.0\",\n                \"embed-multilingual-light-v3.0\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your Cohere API Key here or set it as environment variable `COHERE_API_KEY`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        }\n      }\n    }\n  },\n  \"file_size\": 11918470,\n  \"status\": \"ERROR\"\n}\n\n----------\n\n[DudaNogueira (2024-11-13T13:55:12.147Z)]: hi @bam !\nThis error seems to be coming from ollama.\nCan you get something from ollama logs?\n\n----------\n\n[bam (2024-11-14T03:56:27.789Z)]: Idk where to see the logs. I googled it and it says look in the tray. The only option I have is to quit ollama. I’m still searching for the logs.\n\n----------\n\n[DudaNogueira (2024-11-14T13:17:17.849Z)]: In Mac (and probably linux too) it is here:\ntail -n 100  ~/.ollama/logs/server.log\n\n----------\n\n[bam (2024-11-14T20:51:33.310Z)]: I increased the docker memory allocation to 10 GB and trying again.\n\n\n\n DudaNogueira:\n\ntail -n 100  ~/.ollama/logs/server.log\n\n\n\nThank you.\nHere are the logs from that file:\ntime=2024-11-14T15:39:42.076-05:00 level=INFO source=server.go:601 msg=\"llama runner started in 8.17 seconds\"\nllama_model_loader: loaded meta data with 30 key-value pairs and 255 tensors from /Users/bam/.ollama/models/blobs/sha256-dde5aa3fc5ffc17176b5e8bdc82f587b24b2678c6c66101bf7da77af9f7ccdff (version GGUF V3 (latest))\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.type str              = model\nllama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3B Instruct\nllama_model_loader: - kv   3:                           general.finetune str              = Instruct\nllama_model_loader: - kv   4:                           general.basename str              = Llama-3.2\nllama_model_loader: - kv   5:                         general.size_label str              = 3B\nllama_model_loader: - kv   6:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\nllama_model_loader: - kv   7:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\nllama_model_loader: - kv   8:                          llama.block_count u32              = 28\nllama_model_loader: - kv   9:                       llama.context_length u32              = 131072\nllama_model_loader: - kv  10:                     llama.embedding_length u32              = 3072\nllama_model_loader: - kv  11:                  llama.feed_forward_length u32              = 8192\nllama_model_loader: - kv  12:                 llama.attention.head_count u32              = 24\nllama_model_loader: - kv  13:              llama.attention.head_count_kv u32              = 8\nllama_model_loader: - kv  14:                       llama.rope.freq_base f32              = 500000.000000\nllama_model_loader: - kv  15:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  16:                 llama.attention.key_length u32              = 128\nllama_model_loader: - kv  17:               llama.attention.value_length u32              = 128\nllama_model_loader: - kv  18:                          general.file_type u32              = 15\nllama_model_loader: - kv  19:                           llama.vocab_size u32              = 128256\nllama_model_loader: - kv  20:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv  21:                       tokenizer.ggml.model str              = gpt2\nllama_model_loader: - kv  22:                         tokenizer.ggml.pre str              = llama-bpe\nllama_model_loader: - kv  23:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\nllama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\nllama_model_loader: - kv  25:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\nllama_model_loader: - kv  26:                tokenizer.ggml.bos_token_id u32              = 128000\nllama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 128009\nllama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\nllama_model_loader: - kv  29:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   58 tensors\nllama_model_loader: - type q4_K:  168 tensors\nllama_model_loader: - type q6_K:   29 tensors\nllm_load_vocab: special tokens cache size = 256\nllm_load_vocab: token to piece cache size = 0.7999 MB\nllm_load_print_meta: format           = GGUF V3 (latest)\nllm_load_print_meta: arch             = llama\nllm_load_print_meta: vocab type       = BPE\nllm_load_print_meta: n_vocab          = 128256\nllm_load_print_meta: n_merges         = 280147\nllm_load_print_meta: vocab_only       = 1\nllm_load_print_meta: model type       = ?B\nllm_load_print_meta: model ftype      = all F32\nllm_load_print_meta: model params     = 3.21 B\nllm_load_print_meta: model size       = 1.87 GiB (5.01 BPW) \nllm_load_print_meta: general.name     = Llama 3.2 3B Instruct\nllm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\nllm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\nllm_load_print_meta: LF token         = 128 'Ä'\nllm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\nllm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\nllm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\nllm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\nllm_load_print_meta: max token length = 256\nllama_model_load: vocab only - skipping tensors\ntime=2024-11-14T15:39:43.778-05:00 level=WARN source=runner.go:126 msg=\"truncating input prompt\" limit=2048 prompt=6327 numKeep=5\n[GIN] 2024/11/14 - 15:43:05 | 200 |         3m31s |       127.0.0.1 | POST     \"/api/chat\"\n[GIN] 2024/11/14 - 15:44:14 | 200 | 22.751794079s |       127.0.0.1 | POST     \"/api/embed\"\nggml.c:13343: GGML_ASSERT(i01 >= 0 && i01 < ne01) failed\nggml.c:13343: GGML_ASSERT(i01 >= 0 && i01 < ne01) failed\ntime=2024-11-14T15:46:43.252-05:00 level=WARN source=server.go:482 msg=\"llama runner process no longer running\" sys=6 string=\"signal: abort trap\"\ner running\" sys=6 string=\"signal: abort trap\"\ntime=2024-11-14T15:46:43.252-05:00 level=WARN source=server.go:482 msg=\"llama runner process no longer running\" sys=6 string=\"signal: abort trap\"\ntime=2024-11-14T15:46:43.252-05:00 level=WARN source=server.go:482 msg=\"llama runner process no longer running\" sys=6 string=\"signal: abort trap\"\ntime=2024-11-14T15:46:43.252-05:00 level=ERROR source=routes.go:453 msg=\"embedding generation failed\" error=\"do embedding request: Post \\\"http://127.0.0.1:62404/embedding\\\": EOF\"\n[GIN] 2024/11/14 - 15:46:43 | 500 |         2m51s |       127.0.0.1 | POST     \"/api/embed\"\ntime=2024-11-14T15:46:43.257-05:00 level=ERROR source=routes.go:453 msg=\"embedding generation failed\" error=\"llama runner process no longer running: -1 GGML_ASSERT(i01 >= 0 && i01 < ne01) failed\\nggml.c:13343: GGML_ASSERT(i01 >= 0 && i01 < ne01) failed\"\ntime=2024-11-14T15:46:43.258-05:00 level=WARN source=server.go:482 msg=\"llama runner process no longer running\" sys=6 string=\"signal: abort trap\"\n[GIN] 2024/11/14 - 15:46:43 | 500 |         2m52s |       127.0.0.1 | POST     \"/api/embed\"\ntime=2024-11-14T15:46:43.289-05:00 level=ERROR source=routes.go:453 msg=\"embedding generation failed\" error=\"llama runner process no longer running: -1 GGML_ASSERT(i01 >= 0 && i01 < ne01) failed\\nggml.c:13343: GGML_ASSERT(i01 >= 0 && i01 < ne01) failed\"\ntime=2024-11-14T15:46:43.289-05:00 level=WARN source=server.go:482 msg=\"llama runner process no longer running\" sys=6 string=\"signal: abort trap\"\ntime=2024-11-14T15:46:43.289-05:00 level=ERROR source=routes.go:453 msg=\"embedding generation failed\" error=\"llama runner process no longer running: -1 GGML_ASSERT(i01 >= 0 && i01 < ne01) failed\\nggml.c:13343: GGML_ASSERT(i01 >= 0 && i01 < ne01) failed\"\n[GIN] 2024/11/14 - 15:46:43 | 500 |         2m52s |       127.0.0.1 | POST     \"/api/embed\"\n[GIN] 2024/11/14 - 15:46:43 | 500 |         2m52s |       127.0.0.1 | POST     \"/api/embed\"\ntime=2024-11-14T15:46:43.295-05:00 level=ERROR source=routes.go:453 msg=\"embedding generation failed\" error=\"llama runner process no longer running: -1 GGML_ASSERT(i01 >= 0 && i01 < ne01) failed\\nggml.c:13343: GGML_ASSERT(i01 >= 0 && i01 < ne01) failed\"\n[GIN] 2024/11/14 - 15:46:43 | 500 |         2m52s |       127.0.0.1 | POST     \"/api/embed\"\n\n----------\n\n[bam (2024-11-14T23:40:29.237Z)]: I increased the memory allocation to 12 GB and swap to 2GB and the issue persists. It happens on large (>80 mb) and small (< 1mb) pdf files.\n\n----------\n\n[DudaNogueira (2024-11-18T12:58:55.206Z)]: Interesting.\nIt seems ollama is failing to vectorize those files.\nIf you can share those files with me, I can try running that in my machine on a mac m2 pro.\n\n----------\n\n[bam (2024-11-24T22:21:23.323Z)]: Thank you for your help.\nHere’s one of the files with the Import for 5-20-14-Resistance Training Concepts Summary-03.pdf failed: Import for 5-20-14-Resistance Training Concepts Summary-03.pdf failed: Batch vectorization failed: Vectorization failed for some batches: 500, message='Internal Server Error', url=URL('http://localhost:11434/api/embed') error.\nHere’s the file in my drive. You should be able to download it. I wasn’t able to upload a pdf to here.\nBtw, do you know if it’s possible to add metadata and labels to documents already imported into weaviate?\n\n----------\n\n[bam (2024-12-03T02:11:43.328Z)]: Were you able to access the file? Did it give you the same error message.\n\n----------\n\n[DudaNogueira (2024-12-03T12:37:03.748Z)]: hi @bam !!\nSorry, not yet!\nI attended an event las week and couldn’t work the forums that much \nLet me know if this is the steps you have:\n\nspin up weaviate+verba using docker\nspin up ollama (both docker and local)\nimport that file\n\nI will try this today, and will get back here.\n\n----------\n\n[bam (2024-12-03T14:12:37.213Z)]: spin up weaviate in docker\nSpin up verba locally\nspin up ollama locally\nimport that file\n\n----------\n\n[DudaNogueira (2024-12-03T19:23:53.606Z)]: Ok, I will need detailed info on how you have done this.\nI usually run everything from docker.\nI have, on a new env, installed verba:\npip install goldenverba\n\nNow I have set the .env and sourced:\nWEAVIATE_URL_VERBA=http://localhost:8080\nWEAVIATE_API_KEY_VERBA=YOUR-WEAVIATE-API-KEY\n\nand have configure Weaviate properly.\nNow, how are you setting the settings so it connect?\n\n----------\n\n[DudaNogueira (2024-12-03T19:39:36.054Z)]: I was able to import it using Verba and Weaviate in docker, a ollama locally:\n\nverba-1     |  Collected all Batches of 5-20-14-Resistance Training Concepts\nverba-1     | Summary-03.pdf\nverba-1     |  Removing 5-20-14-Resistance Training Concepts Summary-03.pdf from\nverba-1     | BatchManager\nverba-1     |  Found existing Client\nverba-1     |  FileStatus.STARTING | 5-20-14-Resistance Training Concepts\nverba-1     | Summary-03.pdf | Starting Import | 0\nverba-1     |  Loading 5-20-14-Resistance Training Concepts Summary-03.pdf (pdf)\nverba-1     |  FileStatus.LOADING | 5-20-14-Resistance Training Concepts\nverba-1     | Summary-03.pdf | Loaded 5-20-14-Resistance Training Concepts Summary-03.pdf |\nverba-1     | 0.34\nverba-1     |  FileStatus.CHUNKING | 5-20-14-Resistance Training Concepts\nverba-1     | Summary-03.pdf |  | 0\nverba-1     |  FileStatus.CHUNKING | 5-20-14-Resistance Training Concepts\nverba-1     | Summary-03.pdf | Split 5-20-14-Resistance Training Concepts Summary-03.pdf into\nverba-1     | 14 chunks | 0.0\nverba-1     |  FileStatus.EMBEDDING | 5-20-14-Resistance Training Concepts\nverba-1     | Summary-03.pdf |  | 0\nverba-1     |  Vectorizing 14 chunks in 1 batches\nverba-1     | INFO:     127.0.0.1:48002 - “HEAD / HTTP/1.1” 200 OK\nverba-1     |  FileStatus.EMBEDDING | 5-20-14-Resistance Training Concepts\nverba-1     | Summary-03.pdf | Vectorized all chunks | 1.88\nverba-1     |  FileStatus.INGESTING | 5-20-14-Resistance Training Concepts\nverba-1     | Summary-03.pdf |  | 0\nverba-1     |  FileStatus.INGESTING | 5-20-14-Resistance Training Concepts\nverba-1     | Summary-03.pdf | Imported 5-20-14-Resistance Training Concepts Summary-03.pdf\nverba-1     | into Weaviate | 1.91\nverba-1     |  FileStatus.DONE | 5-20-14-Resistance Training Concepts Summary-03.pdf\nverba-1     | | Import for 5-20-14-Resistance Training Concepts Summary-03.pdf completed\nverba-1     | successfully | 1.91\nverba-1     |  FileStatus.INGESTING | 5-20-14-Resistance Training Concepts\nverba-1     | Summary-03.pdf | Imported 5-20-14-Resistance Training Concepts Summary-03.pdf\nverba-1     | and 14 chunks into Weaviate | 2.25\nverba-1     |  FileStatus.DONE | 5-20-14-Resistance Training Concepts Summary-03.pdf\nverba-1     | | Import for 5-20-14-Resistance Training Concepts Summary-03.pdf completed\nverba-1     | successfully | 2.25\n\nI used this docker:\n---\n\nservices:\n  verba:\n    image: semitechnologies/verba\n    ports:\n      - 8000:8000\n    environment:\n      - WEAVIATE_URL_VERBA=http://weaviate:8080\n      - OPENAI_API_KEY=$OPENAI_API_KEY\n      - COHERE_API_KEY=$COHERE_API_KEY\n      - OLLAMA_URL=http://host.docker.internal:11434\n      - OLLAMA_MODEL=$OLLAMA_MODEL\n      - OLLAMA_EMBED_MODEL=$OLLAMA_EMBED_MODEL\n      - UNSTRUCTURED_API_KEY=$UNSTRUCTURED_API_KEY\n      - UNSTRUCTURED_API_URL=$UNSTRUCTURED_API_URL\n      - GITHUB_TOKEN=$GITHUB_TOKEN\n\n    volumes:\n      - ./data:/data/\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8000 || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: semitechnologies/weaviate:1.27.5\n    ports:\n      - 8080:8080\n      - 50051:50051\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n    environment:\n      OPENAI_APIKEY: $OPENAI_API_KEY\n      COHERE_APIKEY: $COHERE_API_KEY\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_API_BASED_MODULES: 'true'\n      CLUSTER_HOSTNAME: 'node1'\n\nvolumes:\n  weaviate_data: {}\n...\n\n----------\n\n[bam (2024-12-04T23:05:25.623Z)]: Are those logs from docker?\nAre you using OpenAI and CoHere?\nDocker File:\nnetworks:\n  local-net:\n    external: true\n    name: local-net  # This is the Docker network that allows access to your local machine\n\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:latest\n    environment:\n      - QUERY_DEFAULTS_LIMIT=20\n      - ENABLE_MODULES=text2vec-verba\n      - VERBA_API_URL=http://host.docker.internal:8000  # Access Verba on local port 8000\n    ports:\n      - \"8080:8080\"  # Expose Weaviate on port 8080\n    networks:\n      - local-net\n\n.env file\nOLLAMA_MODEL=llama3.2:latest\nOLLAMA_EMBED_MODEL=snowflake-arctic-embed\nOLLAMA_URL=http://localhost:11434\nWEAVIATE_PORT=8081\nWEAVIATE_URL_VERBA=http://localhost:8080\n\n----------\n\n[DudaNogueira (2024-12-05T13:18:36.817Z)]: I have used Ollama, selected it from the config",
    "date_created": "2024-11-13T02:52:10.916Z",
    "has_accepted_answer": false,
    "title": "Vectorization failed for some batches: 500, message='Internal Server Error'",
    "topic_id": 7562
  },
  {
    "user_id": 3068,
    "conversation": "[mklobucaric (2024-12-20T13:23:07.873Z)]: Description\nI have created a sanbox in Weaviate Cloud to test functionality before putting the vectorstore in production.  I am testing openai embeddings:\n“text-embedding-3-small” and “text-embedding-3-large”.\nI tried to change dimensions of “text-embedding-3-large” to 256, to see how sould retrieval go, but I got error below. “distance between entrypoint and query node: 256 vs 1536”\nCan I change dimensions in Sandbox? Or do I have to setup something additional when I am doing hybrid or smilarity search?\nThis is my setup:\n    client = weaviate.connect_to_weaviate_cloud(\n        cluster_url=weaviate_url,\n        auth_credentials=Auth.api_key(weaviate_api_key),\n        headers={\"X-OpenAI-Api-Key\": openai_api_key},\n        # headers={\"X-Google-Studio-Api-Key\": google_studio_api_key},\n    )\n\n        vectorizer_config = Configure.Vectorizer.text2vec_openai(\n            model=model,\n            model_version=\"3\",\n            dimensions=dimensions,\n        )\n\n        client.collections.create(\n            name=collection_name,\n            vectorizer_config=vectorizer_config,\n            vector_index_config=Configure.VectorIndex.hnsw(\n                distance_metric=VectorDistances.COSINE\n            ),\n            properties=properties,\n        )\n\nI have changed now everything to model: str = “text-embedding-3-small”, and dimensions: int = 1536, and now retrieval works fine…\nSecond somehow related question: Does, Google’s “text-embedding-004” embedding works in sandbox? I had earlier some trouble setting it up…\nThird question, are this integrations necessary (since this integrations don’t support Google’s embeddings):\n    # integrations = [\n    #     Integrations.openai(\n    #         api_key=openai_api_key,\n    #         requests_per_minute_embeddings=3000,\n    #         tokens_per_minute_embeddings=1000000,\n    #     ),\n    # ]\n    # client.integrations.configure(integrations)\n\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method:  sanbox in Weaviate Cloud\nMulti Node? Number of Running Nodes:  no\nClient Language and Version: Python v4\nMultitenancy?: No\n\nAny additional Information\n\n\"StatusCode.UNKNOWN\\n\\tdetails = “explorer: get class: vector search: object vector search at index …: vector search: knn search: distance between entrypoint and query node: 256 vs 1536: vector lengths don't match”\\n\\tdebug_error_string = \"UNKNOWN:Error received from peer \"\n\n----------\n\n[DudaNogueira (2024-12-20T13:59:55.986Z)]: hi @mklobucaric !!\nWelcome to our community  !!\nThis seems related to this bug we have recently discovered:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Hybrid search falling back to default vectorizer confs when dimensions is set\n    \n\n    \n      \n        opened 08:15PM - 18 Dec 24 UTC\n      \n\n\n      \n        \n          \n          dudanogueira\n        \n      \n    \n\n    \n        \n          bug\n        \n    \n  \n\n\n  \n    ### How to reproduce this bug?\n\nHere is a reproducible code:\n\n```python\nimpor…t os\nimport weaviate\nfrom weaviate import classes as wvc\nimport weaviate.error_msgs\nclient = weaviate.connect_to_local(\n    headers={\n         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\", \"CHANGE_ME\"),\n    }\n)\nprint(f\"Client: {weaviate.__version__}, Server: {client.get_meta().get('version')}\")\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(\n        model=\"text-embedding-3-large\",\n        dimensions=1024,\n        #type_=\"text\",\n        vectorize_collection_name=False\n    ),\n    properties=[\n        wvc.config.Property(\n            name=\"text\",\n            data_type=wvc.config.DataType.TEXT,\n            tokenization=wvc.config.Tokenization.WORD\n        )\n    ]\n)\n\n# Create a single object\nresponse = collection.data.insert(\n    properties={ \"text\": \"COVID-19 has many symptoms.\" }\n)\n\n# objects indeed has 1024 dimensions\nresponse = collection.query.fetch_objects(\n    limit=5,\n    include_vector=True\n)\nfor obj in response.objects:\n    print(\n        f\"fetch_objects: {obj.uuid} ({len(obj.vector['default'])}) | Properties: {obj.properties}\")\n    \n# you can perform a neartext\nresponse = collection.query.near_text(\n    query=\"hybrid query with 1024 dimensions\",\n    #alpha=0.75,\n    limit=5,\n    include_vector=True\n)\nfor obj in response.objects:\n    print(\n        f\"near text query: {obj.uuid} ({len(obj.vector['default'])}) | Properties: {obj.properties}\")\n    \n#but it fails to hybrid\ntry:\n    response = collection.query.hybrid(\n        query=\"hybrid query with 1024 dimensions\",\n        alpha=0.75,\n        limit=5,\n        include_vector=True\n    )\n    for obj in response.objects:\n        print(\n            f\"hybrid query: {obj.uuid} ({len(obj.vector['default'])}) | Properties: {obj.properties}\")\nexcept Exception as e:\n    print(\"ERROR!!!\", e)\n\n# if we close the client\nclient.close()\n\n# and point it to a catch endpoint\nclient = weaviate.connect_to_local(\n    headers={\n         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\", \"CHANGE_ME\"),\n         \"X-OpenAI-BaseUrl\": \"https://webhook.site/beef60de-4d45-4c61-9928-b20fa619f91e\",\n    }\n)\ncollection = client.collections.get(\"Test\")\n\nresponse = collection.query.hybrid(\n    query=\"hybrid query with 1024 dimensions\",\n    #alpha=0.75,\n    limit=5,\n    include_vector=True\n)\nfor obj in response.objects:\n    print(\n        f\"hybrid query: {obj.uuid} ({len(obj.vector['default'])}) | Properties: {obj.properties}\")\n    \n# we get this payload\npayload = {\n  \"input\": [\n    \"hybrid query with 1024 dimensions\"\n  ],\n  \"model\": \"text-embedding-3-small\",\n  \"dimensions\": 1536\n}\n```\n\n### What is the expected behavior?\n\nThe hybrid search should work. It should generate the query vectorization payload as:\n\n```json\n{\n  \"input\": [\n    \"hybrid query with 1024 dimensions\"\n  ],\n  \"model\": \"text-embedding-3-large\",\n  \"dimensions\": 1024\n}\n```\n\n### What is the actual behavior?\n\nThe generated payload to vectorize a hybrid query is passing the wrong model and dimension as the payload:\n\n```json\n{\n  \"input\": [\n    \"hybrid query with 1024 dimensions\"\n  ],\n  \"model\": \"text-embedding-3-small\",\n  \"dimensions\": 1536\n}\n```\n\n### Supporting information\n\nClient: 4.10.2, Server: 1.28.1\n\n### Server Version\n\n1.28.1\n\n### Weaviate Setup\n\nSingle Node\n\n### Nodes count\n\n1\n\n### Code of Conduct\n\n- [X] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nCan you confirm that near_text will work, but the failing query is a hybrid one?\nThanks!\n\n----------\n\n[mklobucaric (2024-12-20T15:16:47.249Z)]: DudaNogueira:\n\nnear_text\n\n\nThank you!\nYes, you are right, nearText works but hybrid not…",
    "date_created": "2024-12-20T13:23:07.814Z",
    "has_accepted_answer": false,
    "title": "Distance between entrypoint and query node",
    "topic_id": 9360
  },
  {
    "user_id": 695,
    "conversation": "[weisisheng (2024-09-23T00:58:49.779Z)]: Running a local docker container.  I’ve got a typescript script (v3) creating a table & adding one toy example.  No matter what I try, when I query on wcs, it is showing no auto vectorization.  I know the openai key is good since I use it in other apps, and I include it both the docker compose and the script itself. The inserted text shows but vectors for each are empty. I’ve cleared the local data in WCS without improvement.\nconst jdCollectionSchema: CollectionConfigCreate = {\n  name: \"JD\",\n  vectorizers: [\n    vectorizer.text2VecOpenAI({\n      name: \"basics\",\n      model: \"text-embedding-3-small\",\n      sourceProperties: [\"basics\"],\n      vectorizeCollectionName: false,\n    }),\n    vectorizer.text2VecOpenAI({\n      name: \"best_practices\",\n      sourceProperties: [\"best_practices\"],\n      vectorizeCollectionName: false,\n    }),\n    vectorizer.text2VecOpenAI({\n      name: \"red_flags\",\n      sourceProperties: [\"red_flags\"],\n      vectorizeCollectionName: false,\n    }),\n  ],\n  properties: [\n    {\n      name: \"basics\",\n      dataType: \"text\",\n      vectorizePropertyName: false,\n      tokenization: tokenization.LOWERCASE,\n    },\n    {\n      name: \"best_practices\",\n      dataType: \"text\",\n      vectorizePropertyName: false,\n      tokenization: tokenization.LOWERCASE,\n    },\n    {\n      name: \"red_flags\",\n      dataType: \"text\",\n      vectorizePropertyName: false,\n      tokenization: tokenization.LOWERCASE,\n    },\n    {\n      name: \"createdAt\",\n      dataType: \"date\",\n    },\n  ],\n};\n\nWhat am I missing?\ndocker image 1.26.4,  dotenv 16.4.5, weaviate-client 3.0.8\n\n----------\n\n[sebawita (2024-09-23T08:18:55.521Z)]: Hi @weisisheng,\nCan you share the code you use to:\n\nconnect (please redact your URLs/API keys),\ninsert data,\nquery?\n\nIn your configuration, you have 3 vectorizers. So, when you query, you need to provide the name of the vector you are searching on, like this:\nconst jd = client.collections.get('JD');\n\nconst result = await myNVCollection.query.nearText('your query', {\n  targetVector: 'basics',\n  limit: 2,\n})\n\n----------\n\n[sebawita (2024-09-23T08:23:32.400Z)]: weisisheng:\n\nwhen I query on wcs, it is showing no auto vectorization.\n…\ndocker image 1.26.4, dotenv 16.4.5, weaviate-client 3.0.8\n\n\nTo be on a safe side.\nDo you run Weaviate with Docker or in Weaviate Cloud?\n\n----------\n\n[weisisheng (2024-09-23T09:44:12.056Z)]: I’ve got one collection which I’ve had on WCS for a few months Completely separate from this new project.\nThe one I am trying to insert is on docker.  I just found the ability to query local from WCS today.\nLet me do some snipping and I will send the rest.\nThanks!\n\n----------\n\n[weisisheng (2024-09-23T09:52:39.916Z)]: connection\n// Connect to local Weaviate database\n  const weaviateClient = await weaviate.connectToLocal({\n    headers: {\n      \"X-Cohere-Api-Key\": process.env.COHERE_API_KEY || \"\",\n      \"X-OpenAI-Api-Key\": process.env.OPENAI_APIKEY || \"\",\n    },\n  });\n  \n  \n  // insert data \n  // Insert the example note into the note collection\n  const jdCollection = weaviateClient.collections.get(\"JD\");\n  await jdCollection.data.insert(exampleJD);\n\n  // query on WCS\n  {\n  Get {\n    JD {\n      basics\n      best_practices\n      red_flags\n      createdAt\n      _additional {\n        vector\n      }\n    }\n  }\n}\n\nresponse\n{\n  \"data\": {\n    \"Get\": {\n      \"JD\": [\n        {\n          \"_additional\": {\n            \"vector\": []\n          },\n          \"basics\":\n...\n\n----------\n\n[weisisheng (2024-09-24T03:08:43.658Z)]: Set up a new openai api key, fixed the process.env reference for a typo,  and narrowed the “vectorization” to one field, still no vectors.\n  vectorizers: [\n    vectorizer.text2VecOpenAI({\n      name: \"basics_vector\",\n      sourceProperties: [\"basics\"],\n      model: \"text-embedding-3-large\",\n      dimensions: 1024,\n    }),\n  ],\n\nquery\n{\n\tGet {\n\t\tJobDescOpenAI {\n\t\t\tbasics\n\t\t\tbest_practices\n\t\t\tred_flags\n\t\t\tcreatedAt\n\t\t\t_additional {\n\t\t\t\tvector\n\t\t\t}\n\t\t}\n\t}\n}\n\nstumped for sure…\nSupport\n\n----------\n\n[weisisheng (2024-09-25T06:59:03.372Z)]: See this post for the answer: Explain _additional vector returned response like i am 5\n\n----------\n\n[malgamves (2024-10-07T10:00:03.052Z)]: Thanks for linking to the fix, the docs team is working on adding more information for that part of the documentation.",
    "date_created": "2024-09-23T00:58:49.729Z",
    "has_accepted_answer": true,
    "title": "[Question] Error: Can't get standard auto vectorization to run?",
    "topic_id": 4254
  },
  {
    "user_id": 1247,
    "conversation": "[Shaunak_Joshi (2024-07-25T00:04:59.307Z)]: Hi I am doing a course on deeplearning.ai called ‘Building Multimodal Search and RAG’. I am running the below code and getting the following error\nCode:\nanimals = client.collections.get(\"Animals\")\n\nsource = os.listdir(\"./source/video/\")\n\nfor name in source:\n    print(f\"Adding {name}\")\n    path = \"./source/video/\" + name    \n\n    # insert videos one by one\n    animals.data.insert({\n        \"name\": name,\n        \"path\": path,\n        \"video\": toBase64(path),\n        \"mediaType\": \"video\"\n    })\n\nError:\n{\"action\":\"requests_total\",\"api\":\"rest\",\"class_name\":\"Animals\",\"error\":\"update vector: connection to Google PaLM failed with status: 400 error: Parameter dimension is not supported with video input.\",\"level\":\"error\",\"msg\":\"unexpected error\",\"query_type\":\"objects\",\"time\":\"2024-07-23T12:41:55Z\"}\n---------------------------------------------------------------------------\nUnexpectedStatusCodeError                 Traceback (most recent call last)\nCell In[8], line 10\n      7 path = \"./source/video/\" + name    \n      9 # insert videos one by one\n---> 10 animals.data.insert({\n     11     \"name\": name,\n     12     \"path\": path,\n     13     \"video\": toBase64(path),\n     14     \"mediaType\": \"video\"\n     15 })\n\nFile /usr/local/lib/python3.11/site-packages/weaviate/collections/data.py:391, in _DataCollection.insert(self, properties, references, uuid, vector)\n    388 if vector is not None:\n    389     weaviate_obj = self.__parse_vector(weaviate_obj, vector)\n--> 391 return self._insert(weaviate_obj)\n\nFile /usr/local/lib/python3.11/site-packages/weaviate/collections/data.py:82, in _Data._insert(self, weaviate_obj)\n     79 path = \"/objects\"\n     81 params, weaviate_obj = self.__apply_context_to_params_and_object({}, weaviate_obj)\n---> 82 self._connection.post(\n     83     path=path,\n     84     weaviate_object=weaviate_obj,\n     85     params=params,\n     86     error_msg=\"Object was not added\",\n     87     status_codes=_ExpectedStatusCodes(ok_in=200, error=\"insert object\"),\n     88 )\n     89 return uuid_package.UUID(weaviate_obj[\"id\"])\n\nFile /usr/local/lib/python3.11/site-packages/weaviate/connect/v4.py:480, in _Connection.post(self, path, weaviate_object, params, error_msg, status_codes)\n    472 def post(\n    473     self,\n    474     path: str,\n   (...)\n    478     status_codes: Optional[_ExpectedStatusCodes] = None,\n    479 ) -> Response:\n--> 480     return self.__send(\n    481         \"POST\",\n    482         url=self.url + self._api_version_path + path,\n    483         weaviate_object=weaviate_object,\n    484         params=params,\n    485         error_msg=error_msg,\n    486         status_codes=status_codes,\n    487     )\n\nFile /usr/local/lib/python3.11/site-packages/weaviate/connect/v4.py:431, in _Connection.__send(self, method, url, error_msg, status_codes, weaviate_object, params)\n    429     res = self._client.send(req)\n    430     if status_codes is not None and res.status_code not in status_codes.ok:\n--> 431         raise UnexpectedStatusCodeError(error_msg, response=res)\n    432     return cast(Response, res)\n    433 except RuntimeError as e:\n\nUnexpectedStatusCodeError: Object was not added! Unexpected status code: 500, with response body: {'error': [{'message': 'update vector: connection to Google PaLM failed with status: 400 error: Parameter dimension is not supported with video input.'}]}.```\n\nEarlier I was adding image object to the same collection it was working fine, the code for collection creation and image object addition is\nfrom weaviate.classes.config import Configure\n\n# Just checking if you ever need to re run it\nif(client.collections.exists(\"Animals\")):\n    client.collections.delete(\"Animals\")\n    \nclient.collections.create(\n    name=\"Animals\",\n    vectorizer_config=Configure.Vectorizer.multi2vec_palm(\n        image_fields=[\"image\"],\n        video_fields=[\"video\"],\n        project_id=\"semi-random-dev\",\n        location=\"us-central1\",\n        model_id=\"multimodalembedding@001\",\n        dimensions=1408,        \n    )\n)\n\n{\"level\":\"info\",\"msg\":\"Created shard animals_wPRveZCpcK2K in 1.110407ms\",\"time\":\"2024-07-24T23:59:00Z\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-07-24T23:59:00Z\",\"took\":82186}\n<weaviate.collections.collection.Collection at 0x7f5a22708d90>\n\nIt would be great if someone can help me out. Thanks!\n\n----------\n\n[DudaNogueira (2024-07-25T18:54:04.891Z)]: Hi @Shaunak_Joshi !!\nWelcome to our community \nPlease, always fill in all the informations we ask in the template as those help us better understand your scenario.\nYou are probably using an outdated version of either the client and the server. Or maybe the model … \nCan you check that?\nthis is how you can get both using python v4 client:\nprint(weaviate.__version__, client.get_meta().get(\"version\"))\nThe error message seems to be coming directly from Google.\nLet me know if this help.\nTHanks!",
    "date_created": "2024-07-25T00:04:59.247Z",
    "has_accepted_answer": false,
    "title": "Error in adding a video object to collection",
    "topic_id": 3163
  },
  {
    "user_id": 2032,
    "conversation": "[Kyle_Xiong (2024-10-24T21:10:53.907Z)]: Description\n\nHello, I’m using Weaviate Cloud for my RAG application and recently ran into this error after upgrading to version 1.26.7 that never occurred using earlier versions:\nWeaviateQueryError: Query call with protocol gRPC failed with message: /weaviate.v1.Weaviate/Search UNKNOWN: extract target vectors: class <class_name> has multiple vectors, but no target vectors were provided\nat /var/task/node_modules/weaviate-client/dist/node/cjs/grpc/searcher.js:43:19\nat process.processTicksAndRejections (node:internal/process/task_queues:95:5)\nat async getKeywords (/var/task/index.js:58:26)\nat async Promise.all (index 0)\nat async exports.handler (/var/task/index.js:166:40)\nMy collection was created using:\ncollection = client.collections.create(\n    name=\"<class_name>\",\n    properties=[\n        wc.Property(name=\"text\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"keywords\", data_type=wc.DataType.TEXT),\n    ],\n    vectorizer_config=[\n        wc.Configure.NamedVectors.text2vec_openai(\n            name=\"text\", source_properties=[\"text\"]\n        ),\n        wc.Configure.NamedVectors.text2vec_openai(\n            name=\"keywords\", source_properties=[\"keywords\"]\n        ),\n    ],\n    generative_config=wvc.config.Configure.Generative.openai()\n)\n\nAfter inserting documents, I can make queries without issue on the Python client using:\nresponse = collection.generate.near_text(\n    query=question,\n    target_vector=\"keywords\",\n    limit=5,\n    grouped_task = \"<task_prompt>\"\n)\n\nHowever, I’m using weaviate-client in Node.js and running into the error above now even though the query worked fine in earlier Weaviate versions. JS usage:\nconst response = await collection.generate.nearText(\n    query, {\n        groupedTask: `<task_prompt>`,\n        limit: 5,\n        targetVector: \"keywords\"\n})\n\nWhen I remove the target_vector keyword from the Python script, I run into a similar error:\nAioRpcError: <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"extract target vectors: class UMMS has multiple vectors, but no target vectors were provided\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"extract target vectors: class UMMS has multiple vectors, but no target vectors were provided\", grpc_status:2, created_time:\"2024-10-24T20:54:53.071755673+00:00\"}\"\n>\n\nI’m not sure how to fix this issue. I’ve upgraded weaviate-client to 3.1.5 and 3.2.0 and still running into this error. Any insight would be helpful, thank you.\nServer Setup Information\n\nWeaviate Server Version: 1.26.7\nDeployment Method: Weaviate Cloud\nMulti Node? Number of Running Nodes:\nClient Language and Version: JavaScript v3.0.9, v3.1.5, v3.2.0\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[tsmith023 (2024-10-25T08:23:56.238Z)]: Hi @Kyle_Xiong, welcome to the community!\nIt looks to me like you are using the .generate.nearText function incorrectly. This is its type signature:\n* @param {string | string[]} query - The query to search for.\n  * @param {GenerateOptions<T>} generate - The available options for performing the generation.\n  * @param {NearTextOptions<T>} [opts] - The available options for performing the near-text search.\n  * @return {GenerateReturn<T>} - The results of the search including the generated data.\n  */\nnearText(\n  query: string | string[],\n  generate: GenerateOptions<T>,\n  opts?: NearTextOptions<T>\n): GenerateReturn<T>;\n\nshowing that it accepts at least two and at most three arguments. The second argument is a required object in which you supply your generative options with the third argument as an optional object in which you supply any of the parameters you would also in the query namespace methods.\nSo for your example, if you try the following then it will work:\nconst response = await collection.generate.nearText(query, {\n  groupedTask: `<task_prompt>`,\n}, {\n  limit: 5,\n  targetVector: \"keywords\"\n})\n\nUsually such an error with the API usage would be caught by the TS compiler. Do you perhaps have it disabled or are you working in JS?\nAlso, I do not understand why your provided query worked with older Weaviate versions but suddenly failer on a newer one. It could be that there was some implicit behaviour on the server that was being activated by the query you were sending that allowed it to succeed!\nI hope this helps, if not then let me know!\n\n----------\n\n[Kyle_Xiong (2024-10-25T14:45:05.826Z)]: Hi Tommy, thanks for the reply! You’re right, I was using the generate API incorrectly - I was using it analogously to query.nearText and didn’t see that the grouped_task keyword belongs in the 2nd object. Not sure why the API call worked in earlier versions either, but glad it’s fixed now. Thanks again!",
    "date_created": "2024-10-24T21:10:53.859Z",
    "has_accepted_answer": false,
    "title": "WeaviateQueryError when using JS/TS client to query named vectors - class has multiple vectors, but no target vectors were provided",
    "topic_id": 5883
  },
  {
    "user_id": 3243,
    "conversation": "[Axel_Straminsky (2025-01-20T20:34:07.653Z)]: Hi, I’m using the Python v4 client, and I have a graphql filter (an example could be something like “{‘where_filter’: {‘path’: [‘KM’], ‘operator’: ‘LessThan’, ‘valueInt’: 200000}}”). I wanted to know if there is a way to automatically convert this filter into a “Filter” object, i.e., a method that takes the graphql query and returns something like “Filter.by_property(“KM”).less_than(200000)”\n\n----------\n\n[DudaNogueira (2025-01-24T20:33:41.216Z)]: hi @Axel_Straminsky !!\nWelcome to our community \nI believe some user have written some parser to generate weaviate python _Filters (I believe it was shared on slack as I did not find it here.)\nnote that you can still do graphql calls using python v4:\nclient.graphql_raw_query()\n\nI understand that there were some implementations generating graphql filters, but unfortunately we doesn’t have some code to convert those \nLet me know if this helps!",
    "date_created": "2025-01-20T20:34:07.602Z",
    "has_accepted_answer": false,
    "title": "[Question] Convert GraphQL query to Filter object",
    "topic_id": 9826
  },
  {
    "user_id": 11544,
    "conversation": "[cyf121232145 (2025-03-18T20:43:59.652Z)]: Description\nI noticed that there is a method called as_retriever in the v3 version, which is integrated into langgraph as a tool, but I can’t find anything similar in v4. The WeaviateVectorStore library that can be integrated as a retriever only supports vector retrieval.\nServer Setup Information\n\nWeaviate Server Version:\nName: weaviate-client\nVersion: 4.11.1\n\nName: langchain-weaviate\nVersion: 0.0.4\n\n----------\n\n[DudaNogueira (2025-03-19T15:00:01.348Z)]: Hi @cyf121232145 !!\nWelcome to our community \nIn the new integration, the similarity search already uses hybrid:\n\n  \n\n      github.com/langchain-ai/langchain-weaviate\n  \n\n  \n    libs/weaviate/langchain_weaviate/vectorstores.py\n\n\n  56c874566\n\n\n\n\n    \n      \n                  # raise an error because weaviate will do a fetch object query\n                  # if both query and vector are None\n                  raise ValueError(\"Either query or vector must be provided.\")\n              else:\n                  vector = self._embedding.embed_query(query)\n          \n          return_uuids = kwargs.pop(\"return_uuids\", False)\n          \n          with self._tenant_context(tenant) as collection:\n              try:\n                  result = collection.query.hybrid(\n                      query=query, vector=vector, limit=k, **kwargs\n                  )\n              except weaviate.exceptions.WeaviateQueryException as e:\n                  raise ValueError(f\"Error during query: {e}\")\n          \n          docs_and_scores: List[Tuple[Document, float]] = []\n          for obj in result.objects:\n              text = obj.properties.pop(self._text_key)\n              filtered_metadata = {\n                  k: v\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNot that, because it passes all kwargs to collection.query.hybrid, you can use any of the parameters as documented here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate\n\n  Hybrid search combines the results of a vector search and a keyword (BM25F) search by fusing the two result sets.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIs this what you are referring to? Sorry, I don’t have much experience with langgraph.\nLet me know if this helps!",
    "date_created": "2025-03-18T20:43:59.599Z",
    "has_accepted_answer": false,
    "title": "Integration of weaviate and langchain, how to use hybrid in v4 like as_retriever in v3",
    "topic_id": 20030
  },
  {
    "user_id": 1890,
    "conversation": "[Lucas_Rothman (2024-10-15T17:55:11.568Z)]: Been using OpenAI embeddings with an embedded Weaviate instance just fine. However, I just launched a local deployment with Docker and I’m now getting the following error:\nweaviate.exceptions.UnexpectedStatusCodeError: Object was not added! \nUnexpected status code: 500, with response body: \n{'error': \n    [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp 162.159.140.245:443: connect: connection refused'}]\n}.\n\nThis is my docker-compose, mostly just copied from the Weaviate website.\n---\nservices:\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - \"8080\"\n      - --scheme\n      - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.6\n    ports:\n      - 8080:8080\n      - 50051:50051\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      PERSISTENCE_DATA_PATH: \"/var/lib/weaviate\"\n      DEFAULT_VECTORIZER_MODULE: \"none\"\n      ENABLE_API_BASED_MODULES: \"true\"\n      CLUSTER_HOSTNAME: \"node1\"\n      ENABLE_MODULES: \"text2vec-openai\"\n\n      # Enables API key authentication.\n      AUTHENTICATION_APIKEY_ENABLED: \"true\"\n\n      # List one or more keys, separated by commas. Each key corresponds to a specific user identity below.\n      AUTHENTICATION_APIKEY_ALLOWED_KEYS: \"[API_KEY]\"\n\n      # List one or more user identities, separated by commas. Each identity corresponds to a specific key above.\n      AUTHENTICATION_APIKEY_USERS: \"[My email]\"\nvolumes:\n  weaviate_data:\n\nIt works fine with embedded Weaviate so it shouldn’t be an issue with the OpenAI API key. Running ping to openai.com in the docker container works so I don’t think it’s an internet connection issue.\nAny help would be appreciated, thanks!\n\n----------\n\n[DudaNogueira (2024-10-15T18:42:27.586Z)]: hi @Lucas_Rothman !!\nWelcome to our community \nIt looks like your Weaviate server cannot communicate with OpenAi for some reason.\nYou can check this by running a wget call directly to open ai like this:\ndocker compose exec -ti weaviate sh -c 'wget --header=\"Content-Type: application/json\" --header=\"Authorization: Bearer '\"$OPENAI_APIKEY\"'\" --post-data='\"'\"'{ \"input\": \"Hey Ho! Weaviate, Go!\", \"model\": \"text-embedding-3-small\" }'\"'\"' --output-document - https://api.openai.com/v1/embeddings'\n\nNote that you should have OPENAI_APIKEY with a valid apikey inside your docker container, or replace it with an actual apikey\n\n----------\n\n[Lucas_Rothman (2024-10-15T18:57:35.105Z)]: DudaNogueira:\n\ndocker compose exec -ti weaviate sh -c 'wget --header=\"Content-Type: application/json\" --header=\"Authorization: Bearer '\"$OPENAI_APIKEY\"'\" --post-data='\"'\"'{ \"input\": \"Hey Ho! Weaviate, Go!\", \"model\": \"text-embedding-3-small\" }'\"'\"' --output-document - https://api.openai.com/v1/embeddings'\n\n\n\nI don’t have the OpenAI key set in my docker env but I’ve set the OpenAI API key in my connection:\nweaviate_client = weaviate.connect_to_local(\n    auth_credentials=Auth.api_key(DOCKER_API_KEY), \n    headers={\"X-OpenAI-Api-Key\": OPENAI_API_KEY}\n)\n\nIs it still required that I set the OpenAI key in the docker container? And if so what is the point of passing the API key in the headers?\nThe call does fail with connection refused when I enter my API key though. Any ideas why this could potentially be happening?\n\n----------\n\n[DudaNogueira (2024-10-16T02:34:25.060Z)]: Hi @Lucas_Rothman !\nIf you pass the environment variable to the server, you no longer need to pass it at client/query time \nNot sure what is happening, but certainly something on your host OS or your network connection may be blocking open ai APIs\nYou will probably be able to run this code in a sandbox in our cloud, for example.\nLet me know if this helps.\nThanks!",
    "date_created": "2024-10-15T17:55:11.525Z",
    "has_accepted_answer": false,
    "title": "Getting connection refused errors with OpenAI embeddings on local",
    "topic_id": 5435
  },
  {
    "user_id": 3139,
    "conversation": "[Rohini_vaidya (2025-01-05T08:09:14.105Z)]: Hi, is there any reference document or guidance on importing multiple vectors from a dictionary into a collection?\nScenario:\nI have a dictionary with key-value pairs in the format string: [vector]. I need to import these vectors into a collection. For example:\nvector = {\n    \"a_vector\": strings_map[row[\"a\"]],\n    \"b_vector\": strings_map[row[\"b\"]],\n    \"c_vector\": strings_map[row[\"c\"]]\n}\n\n\nHere,have a dictionary strings_map with key-value pairs in the format string: [vector]. I’m mapping specific keys (a, b, c) from a row object to corresponding vector values from a strings_map dictionary.\nHow can I efficiently import such vectors into a collection?\n\n----------\n\n[DudaNogueira (2025-01-06T18:02:47.114Z)]: Answer here:\n  \n    \n    \n    Scores for Hybrid search Support\n  \n  \n    hi @Rohini_vaidya !! \nHere is how you can do that: \nvectors = {\n    \"a_vector\": [1,2,3],\n    \"b_vector\": [1,2,3,4],\n    \"c_vector\": [1,2,3,4,5]\n}\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\", \n    vectorizer_config=[\n        wvc.config.Configure.NamedVectors.none(name=\"a_vector\"),\n        wvc.config.Configure.NamedVectors.none(name=\"b_vector\"),\n        wvc.config.Configure.NamedVectors.none(name=\"c_vector\"),\n    ]\n)\ncollection.data.insert(\n    properties=…",
    "date_created": "2025-01-05T08:09:14.060Z",
    "has_accepted_answer": true,
    "title": "Importing multiple vector from a dataframe into the collection",
    "topic_id": 9570
  },
  {
    "user_id": 3052,
    "conversation": "[RamuA (2025-02-24T11:07:02.078Z)]: Description\nI would like to bring your notice and get help to resolve the replication setup issue on Docker container, I have setup the 3 nodes on AWS EC2 machine and installed the docker on top of it\nMy configuration docker compose files like below  I just given node3 config file.\nweaviate-node-3:\ninit: true\ncommand:\n- --host\n- 0.0.0.0\n- --port\n- ‘8080’\n- --scheme\n- http\nimage: cr.weaviate.io/semitechnologies/weaviate:1.28.4\nports:\n- 8080:8080\n- 50051:50051\nrestart: on-failure:0\nvolumes:\n- /data:/data\nenvironment:\nLOG_LEVEL: ‘debug’\nQUERY_DEFAULTS_LIMIT: 25\nPERSISTENCE_DATA_PATH: ‘/data’\nENABLE_MODULES: ‘backup-s3,backup-filesystem’\nBACKUP_S3_BUCKET: ‘your-s3-bucket-name’\nBACKUP_S3_PATH: ‘weaviate-backups’\nBACKUP_FILESYSTEM_PATH: ‘/data/Backups’\nAWS_ACCESS_KEY_ID: ‘your-aws-access-key-id’\nAWS_SECRET_ACCESS_KEY: ‘your-aws-secret-access-key’\nAWS_REGION: ‘your-aws-region’\nENABLE_API_BASED_MODULES: ‘true’\nCLUSTER_HOSTNAME: ‘node3’\nCLUSTER_GOSSIP_BIND_PORT: ‘7104’\nCLUSTER_DATA_BIND_PORT: ‘7105’\nCLUSTER_JOIN: ‘node1IP:7100’\nRAFT_JOIN: ‘10.X.XX.XX:7100,10.X.XX.XX:7100,10.X.XX.XX:7100’\nRAFT_BOOTSTRAP_EXPECT: 3\nAUTHENTICATION_APIKEY_ENABLED: ‘true’\nAUTHENTICATION_APIKEY_ALLOWED_KEYS: ‘’\nAUTHENTICATION_APIKEY_USERS: ‘user’\nWhen I am trying to start the weaviate service all 3 nodes one by one\nI am seeing the below errors.\n{“action”:“memberlist_init”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“error”:“1 error occurred:\\n\\t* Failed to join node1:7100: dial tcp node1:7100: connect: connection refused\\n\\n”,“level”:“error”,“msg”:“memberlist join not successful”,“remote_hostname”:[“node1:7100”],“time”:“2025-02-24T10:42:19Z”}\n{“action”:“bootstrap”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“join_list”:{“node1”:7100,“node2”:7100,“node3”:7100},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2025-02-24T10:32:45Z”}\nServer Setup Information\n\nWeaviate Server Version: 1.28.4\nDeployment Method: \nMulti Node? Number of Running Nodes: 3\nClient Language and Version: python V4\nMultitenancy?:\n\nAny additional Information\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“module offload-s3 is enabled”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“cluster_api_startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“msg”:“serving cluster api on port 7101”,“port”:7101,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“msg”:“start initializing modules”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“reranker-voyageai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“reranker-cohere”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“generative-aws”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-aws”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“multi2vec-cohere”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“multi2vec-voyageai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-jinaai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“generative-octoai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-octoai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“multi2vec-google”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-huggingface”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“reranker-jinaai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“generative-openai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-google”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-openai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“generative-friendliai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“generative-databricks”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“generative-anyscale”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“backup-s3”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-databricks”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-voyageai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-mistral”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-weaviate”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“generative-cohere”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“generative-anthropic”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“backup-filesystem”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-cohere”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“multi2vec-jinaai”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“generative-mistral”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“generative-google”,“msg”:“initialized module”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“multi2vec-jinaai”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-aws”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“multi2vec-cohere”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“multi2vec-voyageai”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-jinaai”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-octoai”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“multi2vec-google”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-huggingface”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-google”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-openai”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-databricks”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-voyageai”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-mistral”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-weaviate”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“module”:“text2vec-cohere”,“msg”:“initialized module extension”,“time”:“2025-02-24T10:32:00Z”}\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“warning”,“msg”:“Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“msg”:“finished initializing modules”,“time”:“2025-02-24T10:32:00Z”}\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“open cluster service”,“servers”:{“node1”:7100,“node2”:7100,“node3”:7100},“time”:“2025-02-24T10:32:00Z”}\n{“address”:“172.18.0.2:8301”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“starting cloud rpc server …”,“time”:“2025-02-24T10:32:00Z”}\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“starting raft sub-system …”,“time”:“2025-02-24T10:32:00Z”}\n{“address”:“172.18.0.2:8300”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“tcp transport”,“tcpMaxPool”:3,“tcpTimeout”:10000000000,“time”:“2025-02-24T10:32:00Z”}\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“loading local db”,“time”:“2025-02-24T10:32:00Z”}\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“local DB successfully loaded”,“time”:“2025-02-24T10:32:00Z”}\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“schema manager loaded”,“n”:0,“time”:“2025-02-24T10:32:00Z”}\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“metadata_only_voters”:false,“msg”:“construct a new raft node”,“name”:“node1”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“raft”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“index”:0,“level”:“info”,“msg”:“initial configuration”,“servers”:“[]”,“time”:“2025-02-24T10:32:00Z”}\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“last_snapshot_index”:0,“last_store_applied_index_on_start”:0,“level”:“info”,“msg”:“raft node constructed”,“raft_applied_index”:0,“raft_last_index”:0,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“raft”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“follower”:{},“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“entering follower state”,“time”:“2025-02-24T10:32:00Z”}\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“hasState”:false,“level”:“info”,“msg”:“raft init”,“time”:“2025-02-24T10:32:00Z”}\n{“action”:“bootstrap”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“join_list”:{“node1”:7100,“node2”:7100,“node3”:7100},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2025-02-24T10:32:01Z”}\n{“action”:“raft”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“warning”,“msg”:“no known peers, aborting election”,“time”:“2025-02-24T10:32:02Z”}\n{“action”:“inverted filter2search migration”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“msg”:“migration skip flag set, skipping migration”,“time”:“2025-02-24T10:32:02Z”}\n{“action”:“inverted filter2search migration”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“msg”:“starting switching fallback mode”,“time”:“2025-02-24T10:32:02Z”}\n{“action”:“inverted filter2search migration”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“debug”,“msg”:“no missing filterable indexes, fallback mode skipped”,“time”:“2025-02-24T10:32:02Z”}\n{“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“configured versions”,“server_version”:“1.28.4”,“time”:“2025-02-24T10:32:02Z”,“version”:“1.28.4”}\n{“action”:“grpc_startup”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“grpc server listening at [::]:50051”,“time”:“2025-02-24T10:32:02Z”}\n{“action”:“restapi_management”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“Serving weaviate at http://[::]:8080”,“time”:“2025-02-24T10:32:02Z”,“version”:“1.28.4”}\n{“action”:“telemetry_push”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“level”:“info”,“msg”:“telemetry started”,“payload”:“\\u0026{MachineID:1e257d0b-a36e-47fd-a45a-1910b1882915 Type:INIT Version:1.28.4 NumObjects:0 OS:linux Arch:amd64 UsedModules:}”,“time”:“2025-02-24T10:32:03Z”}\n{“action”:“bootstrap”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“join_list”:{“node1”:7100,“node2”:7100,“node3”:7100},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2025-02-24T10:32:03Z”}\n{“action”:“bootstrap”,“build_git_commit”:“d4c811b”,“build_go_version”:“go1.22.11”,“build_image_tag”:“v1.28.4”,“build_wv_version”:“1.28.4”,“join_list”:{“node1”:7100,“node2”:7100,“node3”:7100},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2025-02-24T10:32:05Z”}\n\n----------\n\n[RamuA (2025-02-25T11:33:46.054Z)]: Hello @DudaNogueira :\nI still haven’t received any response. While attempting to configure with 3 nodes replication, I observed that all nodes were displaying the same error. Do you have any suggestions on this?\nLog:\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“expect”:3,“got”:{“weaviate-node-3”:“172.18.0.2:8300”},“level”:“debug”,“msg”:“number of candidates lower than bootstrap expect param, stopping notify”,“time”:“2025-02-25T11:27:39Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:39Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:40Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.18.0.2:8300”,“status”:8,“time”:“2025-02-25T11:27:40Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“error”:“could not join a cluster from [172.18.0.2:8300]”,“level”:“warning”,“msg”:“failed to join cluster”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:40Z”,“voter”:true}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“expect”:3,“got”:{“weaviate-node-3”:“172.18.0.2:8300”},“level”:“debug”,“msg”:“number of candidates lower than bootstrap expect param, stopping notify”,“time”:“2025-02-25T11:27:40Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:40Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:41Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.18.0.2:8300”,“status”:8,“time”:“2025-02-25T11:27:41Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“error”:“could not join a cluster from [172.18.0.2:8300]”,“level”:“warning”,“msg”:“failed to join cluster”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:41Z”,“voter”:true}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“expect”:3,“got”:{“weaviate-node-3”:“172.18.0.2:8300”},“level”:“debug”,“msg”:“number of candidates lower than bootstrap expect param, stopping notify”,“time”:“2025-02-25T11:27:41Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:41Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:43Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.18.0.2:8300”,“status”:8,“time”:“2025-02-25T11:27:43Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“error”:“could not join a cluster from [172.18.0.2:8300]”,“level”:“warning”,“msg”:“failed to join cluster”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:43Z”,“voter”:true}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“expect”:3,“got”:{“weaviate-node-3”:“172.18.0.2:8300”},“level”:“debug”,“msg”:“number of candidates lower than bootstrap expect param, stopping notify”,“time”:“2025-02-25T11:27:43Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:43Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:44Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.18.0.2:8300”,“status”:8,“time”:“2025-02-25T11:27:44Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“error”:“could not join a cluster from [172.18.0.2:8300]”,“level”:“warning”,“msg”:“failed to join cluster”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:44Z”,“voter”:true}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“expect”:3,“got”:{“weaviate-node-3”:“172.18.0.2:8300”},“level”:“debug”,“msg”:“number of candidates lower than bootstrap expect param, stopping notify”,“time”:“2025-02-25T11:27:44Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:44Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:45Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.18.0.2:8300”,“status”:8,“time”:“2025-02-25T11:27:45Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“error”:“could not join a cluster from [172.18.0.2:8300]”,“level”:“warning”,“msg”:“failed to join cluster”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:45Z”,“voter”:true}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“expect”:3,“got”:{“weaviate-node-3”:“172.18.0.2:8300”},“level”:“debug”,“msg”:“number of candidates lower than bootstrap expect param, stopping notify”,“time”:“2025-02-25T11:27:45Z”}\n{“action”:“bootstrap”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.18.0.2:8300”],“time”:“2025-02-25T11:27:45Z”}\n\n----------\n\n[DudaNogueira (2025-02-25T18:49:14.899Z)]: hi @RamuA !!\nSorry for the late response here.\nIt seems that nodes are not communicating to each other.\nI have seen some issues like this, but while using docker swarm.\nI will need to escalate this to our team.\nRight now, our recommended way to run multiple node cluster is using Kubernetes:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nKubernetes | Weaviate\n\n  For a tutorial on how to use minikube to deploy Weaviate on Kubernetes, see the Weaviate Academy course, Weaviate on Kubernetes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI will try to experiment with this and docker swarm later this week.\nThanks!",
    "date_created": "2025-02-24T11:07:01.995Z",
    "has_accepted_answer": false,
    "title": "Replication setup on AWS EC2 with Docker container",
    "topic_id": 10524
  },
  {
    "user_id": 1286,
    "conversation": "[Just_Guide7361 (2024-08-07T19:54:19.449Z)]: I am currently building a Q&A interface with Streamlit and Langchain. Our initial vector database was in Pinecone. We have documents about the same topic, but different industries. Pure embedding search is not optimal, as it will match the same concepts across industries. So, we build a simple selector option where users pick their industry, and then ask the question. In pinecone each industry had their own namespace, we then simply filter on this:\nvectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings, namespace=namespace)\nretriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n\nHybrid search with pinecone is not as convenient as with Weaviate, and since we noticed beter performance with hybrid search we are switching to Weaviate. The downside is that filters are not so clear for the Weaviate retriever.\nretriever = WeaviateHybridSearchRetriever(\n        client=client,\n        index_name=WEAVIATE_INDEX_NAME,\n        text_key=\"page_content\",\n        k=5,\n        alpha=0.75,\n        attributes=[\"file_name\", \"industry],\n        create_schema_if_missing=False,\n    )\n\nOur Langchain Chain looks similar to this ( langchain/templates/hybrid-search-weaviate/hybrid_search_weaviate/chain.py at master · langchain-ai/langchain · GitHub ):\n# RAG prompt\ntemplate = \"\"\"Answer the question based only on the following context:\n{context}\nQuestion: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\n# RAG\nmodel = ChatOpenAI()\nchain = (\n    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n    | prompt\n    | model\n    | StrOutputParser()\n)\n\nThe docs do show this:\nretriever.invoke(\n    \"AI integration in society\",\n    where_filter={\n        \"path\": [\"author\"],\n        \"operator\": \"Equal\",\n        \"valueString\": \"Prof. Jonathan K. Sterling\",\n    },\n)\n\n\n  \n      \n\n      python.langchain.com\n  \n\n  \n    \n\nWeaviate Hybrid Search | 🦜️🔗 LangChain\n\n  Weaviate is an open-source vector database.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nDoes anyone know how/where to add the where_filter parameter for Weaviate hybrid search in the Chain?\n\n----------\n\n[DudaNogueira (2024-08-07T19:57:27.547Z)]: hi @Just_Guide7361 !!\nWelcome to our community \nSorry, your topic was stuck on some anti spam check \nWe have a recipe that you will probably benefit here:\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/llm-frameworks/langchain/loading-data at main ·...\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor instance, this is how you can use langchain and filters:\nfrom weaviate import classes as wvc\n# change bellow to get chunks per different files / countries\nsource_file = \"brazil-wikipedia-article-text.pdf\"\n#source_file = \"netherlands-wikipedia-article-text.pdf\"\nwhere_filter = wvc.query.Filter.by_property(\"source\").equal(source_file)\ndocs = db.similarity_search(\"traditional food\", filters=where_filter)\nprint(docs)\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[DudaNogueira (2024-08-07T21:12:55.044Z)]: Hi!\nI have just updated that langchain recipe as it had some deprecations.\nhere is the part you are interested:\nfrom langchain_openai import OpenAI\nfrom langchain.chains import RetrievalQA\n\n# Let's answer some question\n#source_file = \"brazil-wikipedia-article-text.pdf\"\nsource_file = \"netherlands-wikipedia-article-text.pdf\"\nwhere_filter = wvc.query.Filter.by_property(\"source\").equal(source_file)\n\n# we want our retriever to filter the results\nretriever = db.as_retriever(search_kwargs={\"filters\": where_filter})\n\nqa = RetrievalQA.from_chain_type(llm=OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\")),\n                                 chain_type=\"stuff\", \n                                 retriever=retriever, \n                                 chain_type_kwargs=chain_type_kwargs, \n                                 return_source_documents=True)\n                                 \nanswer = qa({\"query\": \"What is the traditional food of this country?\"})\nprint(answer)\n\nWhile this example only uses one operand filter, you can easily add more logic.\nFor example multiple operands:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nConditional filters | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAnd nested filters:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nFilters | Weaviate - Vector Database\n\n  Filters let you include, or exclude, particular objects from your result set based on provided conditions.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHope this helps!\nThanks!\n\n----------\n\n[Just_Guide7361 (2024-08-09T10:41:50.486Z)]: @DudaNogueira thank you for the quick reply. However, using the RetrievalQA is not ideal. As this one is deprecated in newer versions (langchain.chains.retrieval_qa.base.RetrievalQA — 🦜🔗 LangChain 0.2.12).\nThey recommend using create_retrieval_chain (langchain.chains.retrieval.create_retrieval_chain — 🦜🔗 LangChain 0.2.12). Which is using the LCEL principles.\nAre there any plans to update the recipe/examples with this?\n\n----------\n\n[DudaNogueira (2024-08-09T13:03:24.262Z)]: Hi @Just_Guide7361 !!\nThanks for pointing it out!!\nI will take the opportunity and also write a recipe using the multi tenancy feature with langchain.\nhere is a working code using create_retrieval_chain (I will update the recipe later today):\n# ...\nfrom weaviate.classes.query import Filter\n\n# client = weaviate.connect_to_weaviate_cloud(...)\n\nembeddings = OpenAIEmbeddings()\ndb = WeaviateVectorStore.from_documents([], embeddings, client=client, index_name=\"WikipediaLangChain\")\n\nsource_file = \"brazil-wikipedia-article-text.pdf\"\n#source_file = \"netherlands-wikipedia-article-text.pdf\"\nwhere_filter = Filter.by_property(\"source\").equal(source_file)\n\n# we want our retriever to filter the results\nretriever = db.as_retriever(search_kwargs={\"filters\": where_filter})\n\nsystem_prompt = (\n    \"You are an assistant for question-answering tasks. \"\n    \"Use the following pieces of retrieved context to answer \"\n    \"the question. If you don't know the answer, say that you \"\n    \"don't know. Use three sentences maximum and keep the \"\n    \"answer concise.\"\n    \"\\n\\n\"\n    \"{context}\"\n)\n\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", system_prompt),\n        (\"human\", \"{input}\"),\n    ]\n)\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\nquestion_answer_chain = create_stuff_documents_chain(llm, prompt)\nrag_chain = create_retrieval_chain(retriever, question_answer_chain)\n\nresponse = rag_chain.invoke({\"input\": \"What is he traditional food of this country?\"})\nprint(response[\"answer\"])\n\nBy the way, we host a lot of online and in presence webinars and workshops. Check it out: Online Workshops & Events | Weaviate - Vector Database\nThanks and hope you are enjoying your “Weaviate journey”!!\n\n----------\n\n[Just_Guide7361 (2024-08-11T12:52:01.457Z)]: Nevermind fixed it.\nHey, thank you for the quick replies. I have tried your example but sadly it does not work. When initialising the db, I get an “list index out of range error”.\nHere is my code:\nfrom langchain_cohere import CohereEmbeddings\nimport weaviate\nfrom weaviate.classes.init import Auth\nfrom weaviate.classes.query import Filter\n\nembeddings = CohereEmbeddings(model=EMBEDDINGS_MODEL, cohere_api_key=COHERE_API_KEY)\n\nheaders = {\n    \"X-Cohere-Api-Key\": COHERE_API_KEY,\n}\n\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=WEAVIATE_URL,  \n    auth_credentials=Auth.api_key(WEAVIATE_API_KEY), \n    headers=headers,\n)\n\ndb = WeaviateVectorStore.from_documents([], embeddings, client=client, index_name=index_name)\n\nshould become: \n\ndb = WeaviateVectorStore(embeddings= embeddings, client=client, index_name=index_name)\n\nwhere_filter = Filter.by_property(property_to_filter).equal(selected_property_by_user)\nretriever = db.as_retriever(search_kwargs={\"filters\": where_filter, \"alpha\": 0.8})\nretrieved_files = retriever.invoke(user_query)\n\nI’ve inserted my documents as follows:\nembeddings = CohereEmbeddings(\n    model=EMBEDDINGS_MODEL,\n    cohere_api_key=COHERE_API_KEY,\n)\n\ndb = WeaviateVectorStore.from_documents(langchain_document, embeddings, client=client, index_name=index_name)\n\n\n\n\n\nUsing the weaviate client I am able to retrieve documents, when I initialise the db with the langchain_document I am also able to retrieve, but when I initialise it with an empty array it does not work.\nIdeally ofcourse I do not have to pass the langchain_document to the db each time I want to use the weaviate db.\nCan you point out where I am going wrong?\nThanks!\n\n----------\n\n[DudaNogueira (2024-08-13T12:30:03.323Z)]: Hi @Just_Guide7361 !\nI understand you were able to make it work, right?\nLet me know if there is any other blocker we can help you with.\nWe are here to help you on this journey \nThanks!\n\n----------\n\n[DudaNogueira (2024-08-13T12:43:25.749Z)]: Hi again @Just_Guide7361 !!\nI believe this thread is related to the issue you had:\n\n  \n    \n    \n    How to load existing db to similarity search? General\n  \n  \n    weaviate-client==4.7.1 \nlangchain-weaviate==0.0.2 \nlangchain==0.2.11 \nI am able to create a simple example to create a ‘db’ and use that db to do inference in one flow: \nfrom bge import bge_m3_embedding\n\nprint(f'Read in text ...')\nloader = TextLoader('state_of_the_union.txt')\ndocuments = loader.load()\n\nprint('Split text ...')\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)\n\nprint('Load embedding model ...')\nembedding_model =…\n  \n\n\nThanks for sharing the solution!",
    "date_created": "2024-08-07T19:54:19.329Z",
    "has_accepted_answer": false,
    "title": "Langchain WeaviateHybridSearchRetriever with filters?",
    "topic_id": 3296
  },
  {
    "user_id": 30,
    "conversation": "[SomebodySysop (2024-11-08T06:18:56.397Z)]: I need to query my entire database, but it’s too large to return an array variable with all objects.  So, I was wondering if there were a way to execute a query that will return a range of objects.\nSo, let’s say my first query starts from 1 and has a limit of 1000.  Is there a way to start at 1001 to 2000 and so on?\n\n----------\n\n[andrewisplinghoff (2024-11-08T07:17:11.773Z)]: What about the method proposed to read all objects here?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nRead all objects | Weaviate\n\n  Weaviate provides the necessary APIs to iterate through all your data. This is useful when you want to manually copy/migrate your data (and vector embeddings) from one place to another.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor Python Client v3 and Go, these code examples do exactly what you are asking for. There might be no need for the batching anymore when using Python Client v4 as here the example suggests just reading individual objects.\n\n----------\n\n[SomebodySysop (2024-11-08T12:04:38.596Z)]: I think this is the way to go: Search patterns and basics | Weaviate\nI’ve got to store the objects in memory as I retrieve them in order to do some processing on each, so the best way forward for me is to process them in batches – I guess they call their process “pagination”.\n\n----------\n\n[DudaNogueira (2024-11-08T14:03:41.709Z)]: hi @SomebodySysop !\nI believe this will work just fine.\nI did a test, that follows:\nfrom weaviate.classes.config import Configure\n\nclient.collections.delete(\"Test\")\n\ncollection = client.collections.create(\n    \"Test\",\n    vectorizer_config=Configure.Vectorizer.none()\n    # Additional parameters not shown\n)\n\nfor i in range(100):\n    collection.data.insert({\"text\": f\"Object {i}\"})\n\nfor o in collection.query.fetch_objects(limit=10).objects:\n    print(o.properties)\n\nfor o in collection.query.fetch_objects(limit=10, offset=5).objects:\n    print(o.properties)\n\n\nNow I get:\n\n{‘text’: ‘Object 6’}\n{‘text’: ‘Object 4’}\n{‘text’: ‘Object 5’}\n{‘text’: ‘Object 28’}\n{‘text’: ‘Object 56’}\n{‘text’: ‘Object 32’}\n{‘text’: ‘Object 23’}\n{‘text’: ‘Object 97’}\n{‘text’: ‘Object 61’}\n{‘text’: ‘Object 96’}\n\nand with offset 5:\n\n{‘text’: ‘Object 32’}\n{‘text’: ‘Object 23’}\n{‘text’: ‘Object 97’}\n{‘text’: ‘Object 61’}\n{‘text’: ‘Object 96’}\n{‘text’: ‘Object 44’}\n{‘text’: ‘Object 1’}\n{‘text’: ‘Object 29’}\n{‘text’: ‘Object 7’}\n{‘text’: ‘Object 63’}\n\nAnd even if I update that content:\nfor o in collection.query.fetch_objects(limit=100).objects:\n    collection.data.update(uuid=o.uuid, properties={\"text\": o.properties.get(\"text\") + \"update\"})\n\nAlso, the QUERY_MAXIMUM_RESULTS only interference here will be the number of objects returned (limit parameter) so nothing changed",
    "date_created": "2024-11-08T06:18:56.311Z",
    "has_accepted_answer": false,
    "title": "[Question] Is there a way to filter results by range?",
    "topic_id": 7497
  },
  {
    "user_id": 1201,
    "conversation": "[Matthew_Leung (2024-07-24T09:06:26.981Z)]: Hi Team,\nWe would like to upgrade our Weaviate from docker.io/semitechnologies/weaviate:1.19.1 to docker.io/semitechnologies/weaviate:1.22.0 in our EKS environment. Could you please let us know if there will be any impact from this upgrade, or if we can directly change the image?\nThank you.\n\n----------\n\n[DudaNogueira (2024-07-24T13:38:48.958Z)]: hi @mathieu !!\nA good practice is to never skip release versions.\nSo:\n\nBackup \nMigrate first to 1.21.9 (latest 1.21.X as I write)\nWait it start up, and check some logs.\nNow migrate to 1.22.13 (again, latest 1.22.X as I write)\nsame as 3\n…\n\nThere is a second approach, that is migrating your data and reindexing everything.\nThis will not have vectorization costs, as you will bring the vectors with you.\nFor this you spin up a Weaviate cluster on latest version (or use our hosted offerings) and use this guide to migrate the data over.\nThis may be the best approach as you can now compare the differences. But of course, it will depend on the scale of your operation.\nSome things to consider on such a big jump in versions is that you shouldn’t stop in 1.22. There were a lot of improvements since. You can find them here\nin 1.23.7+ we introduced GRPC. So you need to expose this endpoint service to user newer versions of clients. This alone can bring you a 80% of improvement on batches and queries.\nand in 1.25.+ we introduced RAFT, so if you are using multi node deployment, some actions are required\nLet me know if this helps!\nTHanks!\n\n----------\n\n[Matthew_Leung (2024-07-29T02:48:30.568Z)]: @DudaNogueira Thank you for the solution. By the way, can we directly change the Weaviate image version, or do we need to create another Weaviate instance to migrate the data?\n\n----------\n\n[DudaNogueira (2024-07-29T18:30:46.033Z)]: you can change the image tag.\nThe second instance is only if you want to migrate your data directly. For this second approach, you can jump from your current version to latest directly\nThanks!\n\n----------\n\n[Matthew_Leung (2024-08-05T02:18:28.518Z)]: @DudaNogueira Thank you, we have successfully upgraded it.\n\n----------\n\n[DudaNogueira (2024-08-05T19:08:32.436Z)]: That’s awesome @Matthew_Leung !!\nThanks for choosing Weaviate",
    "date_created": "2024-07-24T09:06:26.939Z",
    "has_accepted_answer": true,
    "title": "Weaviate Upgrade Impact Assessment",
    "topic_id": 3149
  },
  {
    "user_id": 2547,
    "conversation": "[mugndhn (2024-11-19T17:58:11.817Z)]: Description\nHello,\nI’m having an issue with the WithinGeoRange operator for geospatial queries in my database.\nHere is the query structure I’m using:\n{\n    'operator': 'WithinGeoRange',\n    'valueGeoRange': {\n        'geoCoordinates': {\n            'latitude': coordinates[\"latitude\"],\n            'longitude': coordinates[\"longitude\"],\n        },\n        'distance': {'max': int(distance)}\n    },\n    'path': ['coordinates']\n}\n\nHere is a sample document in my database:\n{\n    \"properties\": {\n        \"coordinates\": {\n            \"latitude\": 27.160555,\n            \"longitude\": 78.054596\n        },\n        \"productId\": \"66ea\"\n    }\n}\n\nWhen I query using the same latitude and longitude as the document (latitude: 27.160555, longitude: 78.054596) and set the max distance to 1000, I don’t get any results.\nWhat I’ve Tried:\n\nVerified that the coordinates in the query match the document.\nConfirmed that the distance is correctly calculated in meters.\nChecked for typos in the path parameter.\n\nStill, the query doesn’t return the document even though it should fall within the range.\nQuestions:\n\nDoes the WithinGeoRange operator support this type of query, or am I missing something in the implementation?\nIs there a specific distance metric or projection setting I need to configure?\nCould this be related to a bug, or am I misinterpreting how the geospatial query works?\n\nAny help or pointers would be greatly appreciated!\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: Local docker image (http://cr.weaviate.io/semitechnologies/weaviate:1.27.2)\nMulti Node? Number of Running Nodes:\nClient Language and Version: Python Client 3.24.1\nMultitenancy?:\n\n----------\n\n[DudaNogueira (2024-11-20T19:04:22.440Z)]: hi @mugndhn !!\nWelcome to our community  !!\nCan you reproduce this scenario in a python code?\nHere is one that we can use as reference:\n  \n    \n    \n    Distance in meters when using within_geo_range Support\n  \n  \n    hi @jensenbox !! \nThat’s interesting. I don’t believe it does  \nI will poke internally about it and keep you posted. \nI have crafted a small test code for future reference: \nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n    properties=[\n        wvc.config.Property(name=\"city_name\", data_type=wvc.config.DataType.TEXT),\n        wvc.config.Property(name=\"geo\", data_type=wvc.config.DataTyp…\n  \n\n\nThis helps us understand exactly what is the code you are using, with some fictional dataset, etc.\nLEt me know if this helps!\nThanks!\n\n----------\n\n[mugndhn (2024-11-20T23:47:41.447Z)]: hi @DudaNogueira,\nWhile I was putting together the notebook for you, I noticed a typo in the query which was swapping lat and long. We were able to fix it and the geosearch seems to be working now.\nThank you.\n\n----------\n\n[DudaNogueira (2024-11-21T17:34:32.245Z)]: Oh!!\nGlad to hear you were able to solve this.\nThanks for sharing!!",
    "date_created": "2024-11-19T17:58:11.763Z",
    "has_accepted_answer": true,
    "title": "Geosearch WithinGeoRange maxdistance metric not accurate",
    "topic_id": 7707
  },
  {
    "user_id": 611,
    "conversation": "[Bigdwarf43 (2025-01-06T05:42:04.393Z)]: Unable to used Hybrid queries when working with azure-openai embeddings. The query asks for an OPENAI key while the azureopenai key env is set in docker compose. The near_text query works fine though\nweaviate_client_version : 4.10.2\nweaviate_version: 1.28.1\nCollection_definition:\n_CollectionConfig(name='Kip_vid_documents_without_flevy_azure',\n                  description=None,\n                  generative_config=None,\n                  inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75,\n                                                                              k1=1.2),\n                                                             cleanup_interval_seconds=60,\n                                                             index_null_state=False,\n                                                             index_property_length=False,\n                                                             index_timestamps=False,\n                                                             stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>,\n                                                                                        additions=None,\n                                                                                        removals=None)),\n                  multi_tenancy_config=_MultiTenancyConfig(enabled=False,\n                                                           auto_tenant_creation=False,\n                                                           auto_tenant_activation=False),\n                  properties=[_Property(name='data',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.FIELD: 'field'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='segment_id',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='source_url',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='source_name',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='source_tag__metadata',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.FIELD: 'field'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='source_id',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='measurement_approach',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='trend_analysis',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='actionable_tips',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='visualization_suggestions',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='tools_technologies',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='category',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='definition',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='standard_formula',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='risk_warnings',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='integration_points',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='change_impact',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='kpi',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='business_insights',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='diagnostic_questions',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='meta_info',\n                                        description=None,\n                                        data_type=<DataType.TEXT_ARRAY: 'text[]'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='child_url',\n                                        description=None,\n                                        data_type=<DataType.TEXT_ARRAY: 'text[]'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='youtube_url',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='title',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='page_url',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='source_tag__metadatat__metadata',\n                                        description=None,\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.FIELD: 'field'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='organization_name__metadata',\n                                        description='This property was '\n                                                    \"generated by Weaviate's \"\n                                                    'auto-schema feature on '\n                                                    'Thu Dec 12 06:19:46 2024',\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai'),\n                              _Property(name='data_period__metadata',\n                                        description='This property was '\n                                                    \"generated by Weaviate's \"\n                                                    'auto-schema feature on '\n                                                    'Tue Dec 31 12:05:58 2024',\n                                        data_type=<DataType.TEXT: 'text'>,\n                                        index_filterable=True,\n                                        index_range_filters=False,\n                                        index_searchable=True,\n                                        nested_properties=None,\n                                        tokenization=<Tokenization.WORD: 'word'>,\n                                        vectorizer_config=_PropertyVectorizerConfig(skip=False,\n                                                                                    vectorize_property_name=False),\n                                        vectorizer='text2vec-openai')],\n                  references=[],\n                  replication_config=_ReplicationConfig(factor=1,\n                                                        async_enabled=False,\n                                                        deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>),\n                  reranker_config=_RerankerConfig(model={},\n                                                  reranker=<Rerankers.TRANSFORMERS: 'reranker-transformers'>),\n                  sharding_config=_ShardingConfig(virtual_per_physical=128,\n                                                  desired_count=1,\n                                                  actual_count=1,\n                                                  desired_virtual_count=128,\n                                                  actual_virtual_count=128,\n                                                  key='_id',\n                                                  strategy='hash',\n                                                  function='murmur3'),\n                  vector_index_config=_VectorIndexConfigHNSW(quantizer=None,\n                                                             cleanup_interval_seconds=300,\n                                                             distance_metric=<VectorDistances.COSINE: 'cosine'>,\n                                                             dynamic_ef_min=100,\n                                                             dynamic_ef_max=500,\n                                                             dynamic_ef_factor=8,\n                                                             ef=-1,\n                                                             ef_construction=128,\n                                                             filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>,\n                                                             flat_search_cutoff=40000,\n                                                             max_connections=64,\n                                                             skip=False,\n                                                             vector_cache_max_objects=1000000000000),\n                  vector_index_type=<VectorIndexType.HNSW: 'hnsw'>,\n                  vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>,\n                                                      model={'baseURL': 'https://rampp-openai-azure-api.openai.azure.com/',\n                                                             'deploymentId': 'text-embedding-3-small',\n                                                             'model': 'ada',\n                                                             'resourceName': 'text-embedding-3-small'},\n                                                      vectorize_collection_name=False),\n                  vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>,\n                  vector_config=None)\n\n\nQuery:\ndocs = Kip_vid_documents_azure.query.hybrid(\n    query=\"What was the revenue of our company\",\n    alpha=0.7,\n    limit=100,\n)\n\nError:\nWeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"remote client vectorize: API Key: no api key found neither in request header: X-Openai-Api-Key nor in environment variable under OPENAI_APIKEY\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"remote client vectorize: API Key: no api key found neither in request header: X-Openai-Api-Key nor in environment variable under OPENAI_APIKEY\", grpc_status:2, created_time:\"2025-01-06T11:06:12.96562467+05:30\"}\"\n>.\n\n----------\n\n[DudaNogueira (2025-01-23T20:53:15.167Z)]: hi @Bigdwarf43 !!\nSorry for the delay here!!\nare you defining in docker compose AZURE_APIKEY ?\nas per the doc:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nText Embeddings | Weaviate\n\n  Weaviate's integration with Azure OpenAI's APIs allows you to access their models' capabilities directly from Weaviate.\n\n----------\n\n[Bigdwarf43 (2025-03-24T14:07:24.257Z)]: Yes i have, the near_text queries work fine\nI’m on weaviate-client ==  4.10.2 and weaviate == semitechnologies/weaviate:1.28.1\n\n----------\n\n[Bigdwarf43 (2025-03-27T08:28:48.598Z)]: this is my module configuration\n“moduleConfig”: {\n“text2vec-openai”: {\n“baseURL”: “baseUrl”,\n“deploymentId”: “text-embedding-3-small”,\n“model”: “text-embedding-3-small”,\n“resourceName”: “text-embedding-3-small”,\n“vectorizeClassName”: false\n}\n}\n\n----------\n\n[DudaNogueira (2025-03-27T12:02:16.806Z)]: Bigdwarf43:\n\n1.28.1\n\n\nDo you get the same output on newer versions?\nthe newest from this release is Weaviate 1.28.11",
    "date_created": "2025-01-06T05:42:04.329Z",
    "has_accepted_answer": false,
    "title": "Hybrid search raises an API Key error when used with azure-openai",
    "topic_id": 9578
  },
  {
    "user_id": 94,
    "conversation": "[junbetterway (2024-05-10T13:36:09.484Z)]: Description\nIs there a way to perform conditional filter WHERE prop NOT ContainsAny (:excludedValues)?\nAny additional Information\nLet’s say we have a UserProfile vector schema with a property of sourceId for each profile and I wanted to only include results where sourceId is not contains in any :excludeIds (e.g., 1,2,3,4, so on…)\nI just saw this open feature request: [Feature Request] Add \"Not\" operator in filter to support \"Not Like\" etc. in Get queries · Issue #3683 · weaviate/weaviate · GitHub and sadly looks like it has no movements/updates \nAre there any possible workaround to achieve this? Thanks!\n\n----------\n\n[DudaNogueira (2024-05-10T17:42:04.209Z)]: hi @junbetterway !\nAs per our docs:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nConditional filters | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAn operator to invert a filter (e.g. Not Like ... ) is not supported in Weaviate. If you would to see such an operator to be implemented, please let us know by upvoting the issue here.\nThanks!\n\n----------\n\n[junbetterway (2024-05-11T00:55:09.086Z)]: Thanks @DudaNogueira and yeah saw that one already and upvoted it too.\nDo you know if there has been progress about it? We’re really dying to have such as we have this new feature and having this NOT *** (or invert) condition will make it more efficient.\n\n----------\n\n[DudaNogueira (2024-05-12T13:33:56.487Z)]: Not necessarily a progress, but we have recently released the 1.25 version with RAFT that required a lot of effort from our team.\nWith that finished, I believe we’ll have more capacity to tackle those feature requests.\nAlso, I have seen some internal discussions on that exact subject, so hopefully we get a solution for this soon.\n\n----------\n\n[junbetterway (2024-05-13T13:47:15.428Z)]: Thanks @DudaNogueira that’s great to hear.\n\n----------\n\n[Beck (2024-11-30T07:52:40.381Z)]: @DudaNogueira any news about it?\n\n----------\n\n[DudaNogueira (2024-12-02T20:20:20.495Z)]: We have indeed!!\nno ETA, but heard this week from our team about it specific issue, so we should get some updates on the GH issue in the next days.\nThanks and sorry for the delay here  .",
    "date_created": "2024-05-10T13:36:09.426Z",
    "has_accepted_answer": true,
    "title": "Is there a way to perform conditional filter WHERE prop NOT ContainsAny (:excludedValues)?",
    "topic_id": 2260
  },
  {
    "user_id": 1741,
    "conversation": "[wtavares (2024-10-19T21:38:18.985Z)]: Description\nI’m a little bit lost actuality.\nWhen tried the Weaviate Embedder i’m having this error:\nℹ FileStatus.ERROR | xpto.pdf | Import for Por dentro\nMelissa.pdf failed: Import for xpto.pdf failed: Batch\nvectorization failed: Vectorization failed for some batches: 404, message='Not\nFound', url=URL('http://weaviate:8080/v1/embeddings/embed') | 0\n\nMy EMBEDDING_SERVICE_URL and EMBEDDING_SERVICE_KEY are set to my weaviate local server. But… Weaviate does not has the endpoint: /v1/embeddings/embed\nThe README says something about to HuggingFace. But is this the EMBEDDING_SERVICE ?\nHow to setup this?\nI tried with another local Weaviate instance deployed with Locally Hosted Transformers Text Embeddings. But I do not know how to configure.\nIn order to follow with our tests… we arre using the OpenAI Embedder. But I’d like avoid cost with dev and tests.\nServer Setup Information\n\nWeaviate Server Version: 1.24.1\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Verba\nMultitenancy?: No\n\nAny additional Information\nℹ FileStatus.ERROR | xpto.pdf | Import for Por dentro\nMelissa.pdf failed: Import for xpto.pdf failed: Batch\nvectorization failed: Vectorization failed for some batches:\nweaviate/v1/embeddings/embed | 0\n\n----------\n\n[DudaNogueira (2024-10-21T22:00:26.964Z)]: Hi @wtavares !!\nI believe this is a service that we will make available… in the future \nCheck here for being notified when it goes GA:\n\n  \n\n      console.weaviate.cloud\n  \n\n  \n    \n\nWeaviate Cloud | Embedding\n\n  Embedding service\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!\n\n----------\n\n[wtavares (2024-10-22T12:37:08.195Z)]: Exactly Duda! Is a service comming soon.\nBy the way… I’m using OpenAI to this at this momment. But I’d like to avoid costs in DEV.\nCould you explain how to use HuggingFace instead? The README does not explain how to setup a docker with this and also how to configure Verba to use.\nThanks in advance.\nW\n\n----------\n\n[DudaNogueira (2024-10-22T13:32:06.841Z)]: Hummm. Have you tried ollama?\nI believe it will be easier than HF.\n\n----------\n\n[wtavares (2024-10-22T13:45:36.395Z)]: I’m doing exactly this now!\nAny tips about Generation in PT-Br? Or Ollama will do this for me?\nFirst contact with Ollama…\n\n----------\n\n[DudaNogueira (2024-10-24T12:49:51.921Z)]: It will depend on the model you have chosen.\nI have did a quick research, and I don’t think that ollama current available embed models support PT-BR \n\n  \n      \n\n      ollama.com\n  \n\n  \n    \n\nlibrary\n\n  Get up and running with large language models.",
    "date_created": "2024-10-19T21:38:18.932Z",
    "has_accepted_answer": false,
    "title": "Verba: Failing to embed using Weaviate Service",
    "topic_id": 5782
  },
  {
    "user_id": 3257,
    "conversation": "[Tatali (2025-01-23T13:28:53.196Z)]: Description\nSubject: Issue with weaviate.Client in LangChain: ValueError: client should be an instance of weaviate.Client, got <class ‘weaviate.client.WeaviateClient’>\nMessage:\nHi everyone,\nI’ve been working on integrating Weaviate with LangChain to create a retriever for semantic search. However, I’m encountering an issue when trying to use the Weaviate class from LangChain to create a retriever. Here’s the error I’m getting:\nValueError: client should be an instance of weaviate.Client, got <class 'weaviate.client.WeaviateClient'>\nContext\n\nI’m using the following code to connect to Weaviate and create a retriever:\nimport os\nfrom weaviate import connect_to_local\nfrom weaviate.config import AdditionalConfig, Timeout\nfrom langchain.vectorstores import Weaviate\nfrom langchain.embeddings import OpenAIEmbeddings\n\n# Connect to Weaviate\nclient = connect_to_local(\n    headers={\"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\")},\n    additional_config=AdditionalConfig(\n        timeout=Timeout(init=10, query=60, insert=120)\n    )\n)\n\n# Initialize embeddings\nembeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_APIKEY\"))\n\n# Create a Weaviate retriever\nretriever = Weaviate(\n    client=client,\n    index_name=\"EmailQuery\",\n    text_key=[\"subject\", \"beneficiary_email\", \"manager_response\", \"topic\"],\n    embedding=embeddings\n).as_retriever()\n\nHas anyone else encountered this issue when using LangChain with the latest Weaviate client?\nAny additional Information\nlangchain-community== 0.2.11\nlangchain-weaviate==0.0.3\nweaviate-client== 4.8.1\n\n----------\n\n[DudaNogueira (2025-01-23T14:07:21.084Z)]: hi @Tatali !!\nWElcome to our community \nI believe you are using the old Langchain integration.\nCheck here a nice recipe on how to use it:\n\n  \n\n      github.com/weaviate/recipes\n  \n\n  \n    integrations/llm-agent-frameworks/langchain/loading-data/langchain-simple-pdf.ipynb\n\n\n  main\n\n\n\n      {\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Multilanguage RAG filtering by multiple PDFs with Langchain and OpenAi\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 1,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"Note: you may need to restart the kernel to use updated packages.\\n\",\n      \"Requirement already satisfied: langchain-openai in /Users/dudanogueira/dev/weaviate/recipes/.venv/lib/python3.12/site-packages (0.1.21)\\n\",\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!\nTHanks!\n\n----------\n\n[Tatali (2025-01-23T14:37:02.849Z)]: Thanks @DudaNogueira  for you reply.\nI found the correct code to use in the Notebook.\n\n----------\n\n[DudaNogueira (2025-01-23T14:41:38.664Z)]: Awesome!\nYou can check the langchain module for this integration here:\n\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - langchain-ai/langchain-weaviate\n\n    Contribute to langchain-ai/langchain-weaviate development by creating an account on GitHub.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHappy coding!\n\n----------\n\n[Jixy (2025-03-08T05:58:43.770Z)]: Hello ，I just encounterd the same question when trying to use Weaviate with LangChain to cerate a example_selector, but I found that the document you given is lost. Could you pleasae give me some solutions?\n\n----------\n\n[DudaNogueira (2025-03-09T12:19:42.053Z)]: Hi!\nThere was a change in the folder name \nI have edited the link. here is the new place it lives:\n  \n\n      github.com/weaviate/recipes\n  \n\n  \n    integrations/llm-agent-frameworks/langchain/loading-data/langchain-simple-pdf.ipynb\n\n\n  main\n\n\n\n      {\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Multilanguage RAG filtering by multiple PDFs with Langchain and OpenAi\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 1,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"Note: you may need to restart the kernel to use updated packages.\\n\",\n      \"Requirement already satisfied: langchain-openai in /Users/dudanogueira/dev/weaviate/recipes/.venv/lib/python3.12/site-packages (0.1.21)\\n\",\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nOur recipes “may” change folder names that will break links. I’ll try to go around fixing this.\nThanks!",
    "date_created": "2025-01-23T13:28:53.136Z",
    "has_accepted_answer": true,
    "title": "Langchain/Weaviate",
    "topic_id": 9868
  },
  {
    "user_id": 1643,
    "conversation": "[doc97040 (2024-10-06T10:28:05.165Z)]: Hello\nI am super new at this so forgive my errors.     I had first tried to run llama and verba locally on wsl2 and had to many issues. So i moved verba to docker.  could not get that to work until i used the wsl instance ip then verba connected how ever i get these errors.\nHW 5950x 128gb ram primary 1tb m.2  data 2 tb ssd 4090.\nThis is a local Ollama running llama3.1 llama3.1:8b-instruct-fp16 WSL2 ubuntu 24.x\nI have the embed snowflake-arctic-embed:latest\nWindows Desktop Docker yaml file listed below\nError 1  from weaviate log:{“action”:“requests_total”,“api”:“rest”,“build_git_commit”:“353d907”,“build_go_version”:“go1.22.7”,“build_image_tag”:“1.26.5”,“build_wv_version”:“1.26.5”,“class_name”:“VERBA_SUGGESTION”,“error”:“no moduleconfig for class VERBA_SUGGESTION present”,“level”:“error”,“msg”:“unexpected error”,“query_type”:“objects”,“time”:“2024-10-06T10:02:46Z”}\nError 2 on verba page if you summit anything see image:\n Failed to set new RAG Config Object was not added! Unexpected status\ncode: 500, with response body: {‘error’: [{‘message’: ‘no moduleconfig for class\nVERBA_CONFIG present’}]}.\nError 3 when in Verba page and select Docker and then goto settings top right.\nWhen config opens Version Nodes Collections are giving loading animations the whole time. but in the Weaviate docker logs i can see Verba errors so i know its connecting\nScreenshot 2024-10-06 0311252599×647 88.3 KB\n.\nMy Docker Yaml\nversion: '3.8'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.5\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QNA_INFERENCE_API: \"http://qna-transformers:8080\"\n      NER_INFERENCE_API: \"http://ner-transformers:8080\"\n      BIND_INFERENCE_API: 'http://multi2vec-bind:8080'\n      RERANKER_INFERENCE_API: 'http://reranker-transformers:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'multi2vec-bind'\n      ENABLE_MODULES: 'multi2vec-bind,ref2vec-centroid,reranker-transformers,qna-transformers,ner-transformers'\n      CLUSTER_HOSTNAME: 'node1'\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/live || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n\n  ner-transformers:\n    image: cr.weaviate.io/semitechnologies/ner-transformers:dbmdz-bert-large-cased-finetuned-conll03-english\n\n  multi2vec-bind:\n    image: cr.weaviate.io/semitechnologies/multi2vec-bind:imagebind\n    environment:\n      ENABLE_CUDA: '1'\n      NVIDIA_VISIBLE_DEVICES: all\n    deploy:\n      resources:\n        reservations:\n          devices:\n          - capabilities: [gpu]\n\n  qna-transformers:\n    image: cr.weaviate.io/semitechnologies/qna-transformers:bert-large-uncased-whole-word-masking-finetuned-squad\n    environment:\n      ENABLE_CUDA: '1'\n      NVIDIA_VISIBLE_DEVICES: all\n    deploy:\n      resources:\n        reservations:\n          devices:\n          - capabilities: [gpu]\n\n  reranker-transformers:\n    image: cr.weaviate.io/semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2\n    environment:\n      ENABLE_CUDA: '0'\n\n  verba:\n    image: verba-verba\n    ports:\n      - 8000:8000\n    environment:\n      WEAVIATE_URL_VERBA: 'http://weaviate:8080'  # Corrected service name\n      OLLAMA_URL: 'http://172.28.14.23:11434'  # Depending on your Docker environment (localhost or internal)\n    volumes:\n      - ./data:/data/\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://weaviate:8080 || exit 1  # Changed port to 8080\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n\nvolumes:\n  weaviate_data:\n\nScreenshot 2024-10-06 0256431891×949 97.8 KB\n\n----------\n\n[DudaNogueira (2024-11-01T14:52:07.668Z)]: Hi!\nWe have been discussing about running all locally with docker here:\n  \n    \n    \n    Locally running RAG pipeline with Verba and Llama3 with Ollama Support\n  \n  \n    Description\nI tried following the blog post, Locally running RAG pipeline with Verba and Llama3 with Ollama https://weaviate.io/blog/local-llm-with-verba-for-rag, to build locally and it won’t import the pdf. The document is less than 300 kb. \nError message: \n✘ No documents imported 0 of 1 succesful tasks\n FileStatus.ERROR | the-heros-journey-joseph-campbell.pdf | Import for\nthe-heros-journey-joseph-campbell.pdf failed: Import for\nthe-heros-journey-joseph-campbell.pdf failed: Batch vectorizatio…\n  \n\n\nLet me know if you were able to run it.\nThanks!",
    "date_created": "2024-10-06T10:28:05.111Z",
    "has_accepted_answer": false,
    "title": "Local Ollama Verba-Weaviate on docker odd errors when using chat",
    "topic_id": 4446
  },
  {
    "user_id": 3751,
    "conversation": "[Mariem_Sayedi (2025-03-06T08:58:07.502Z)]: how to use open AI API key for free??, i am a student\n\n----------\n\n[DudaNogueira (2025-03-06T13:09:29.449Z)]: Hi @Mariem_Sayedi !\nI am not sure how to get free credits for OpenAi.\nHowever, I could recommend using ollama, where you can locally host your models:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nOllama + Weaviate | Weaviate\n\n  The Ollama library allows you to easily run a wide range of models on your own device. Weaviate seamlessly integrates with the Ollama library, allowing users to leverage compatible models directly from the Weaviate database.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!\nThanks!\n\n----------\n\n[ranvir (2025-03-07T16:03:13.645Z)]: What are you trying to test/develop?",
    "date_created": "2025-03-06T08:58:07.457Z",
    "has_accepted_answer": false,
    "title": "How to use open AI API key for free?, i am a student",
    "topic_id": 10902
  },
  {
    "user_id": 890,
    "conversation": "[pmt1 (2025-01-19T01:49:07.877Z)]: Description\nExperimenting with embedded client using it to query an existing collection created using docker.\nBoth deployment methods use the same server version and clients. The hostname variable on the embedded client is set to 0.0.0.0. The cluster hostname on the docker used to build the collection is set to ‘node1’ - no cluster hostname has been set for the embedded client (not sure if this is possible via variables and may be the source of the problem).\nThe embedded client connects to the collection but throws out the exception error below. Any suggestions on solutions would be appreciated. Thanks!\nServer Setup Information\n\nWeaviate Server Version: 1.26.5\nDeployment Method:  docker + embedded\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: python v4\nMultitenancy?: no\n\nAny additional Information\nError message:\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with: status = StatusCode.UNKNOWN details = “explorer: get class: vector search: object vector search at index docdata: remote shard 5Mo7r7gjuvIl: resolve node name “node1” to host” debug_error_string = “UNKNOWN:Error received from peer {created_time:“2025-01-18T14:55:46.680197+09:00”, grpc_status:2, grpc_message:“explorer: get class: vector search: object vector search at index docdata: remote shard 5Mo7r7gjuvIl: resolve node name \"node1\" to host”}” >.\n\n----------\n\n[pmt1 (2025-01-24T07:25:52.734Z)]: Was able to make some progress on this by explicitly setting environment variables as below. Experimenting continues …\nhostname=“127.0.0.1”,\nadditional_env_vars={\n“CLUSTER_HOSTNAME”: “node1”,\n“RAFT_JOIN”: “node1”,\n“CLUSTER_GOSSIP_BIND_PORT”: “7100”,\n“CLUSTER_DATA_BIND_PORT”: ‘7101’,\n“RAFT_BOOTSTRAP_EXPECT”: ‘1’,\n“ENABLE_TOKENIZER_GSE”: “true”\n\n----------\n\n[DudaNogueira (2025-01-24T20:00:03.720Z)]: hi!\nThanks for sharing.\nAlso one suggestion: if using the Embedded Weaviate, specify the version you want.\nOtherwise it can be used an old one.\nYou can, but should not use “last” as version or the embedded, but it may sometimes get a patch released after the latest.\nAnd finally, note that Embedded is experimental. And there is are some bugs",
    "date_created": "2025-01-19T01:49:07.818Z",
    "has_accepted_answer": true,
    "title": "Node name error on query - using embedded client on an existing collection",
    "topic_id": 9809
  },
  {
    "user_id": 900,
    "conversation": "[P_K (2024-12-29T10:26:00.851Z)]: Description\nI have setup ollama on a GCP server and exposed it as url.  It is accesible through ollama client with AUTH token. Here is sample code:\nfrom ollama import Client\ntry:\n      MODEL_NAME = \"nomic-embed-text:latest\"\n      client = Client(\n        host='https://ollama-inferece-url',\n        headers={'Authorization': AUTH_TOKEN}\n      )\n      text = \"Hello, this is a test sentence.\"\n      response = client.embeddings(\n        model=MODEL_NAME,\n        prompt=text\n      )\n\n      # Extract embeddings from response\n      embedding = response['embedding']\n      print(embedding)\n      print(f\"Single embedding shape: {len(embedding)}\")\n\nexcept Exception as e:\n        print(f\"Error generating: {e}\")\n\nI want to integrate this ollama embeddings with weaviate.  Can you provide some sample code or reference for this?\nServer Setup Information\n\nWeaviate Server Version: 1.28.0\nDeployment Method:docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python 3.8\nMultitenancy?: No\n\n----------\n\n[DudaNogueira (2024-12-29T13:56:33.643Z)]: hi @P_K !!\nWelcome back \nCheck out this recipe:\n  \n\n      github.com\n  \n\n  \n    weaviate/recipes/blob/main/weaviate-features/generative-search/local_rag_using_ollama_integration_using_embedded.ipynb\n\n\n      {\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Local RAG with Ollama and Weaviate\\n\",\n    \"## Using Weaviate integration\\n\",\n    \"\\n\",\n    \"This example shows how to use the text2vec-ollama as well the generative-ollama \"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Setup \\n\",\n    \"1. Download and install Ollama for your operating system: https://ollama.com/download\\n\",\n    \"2. `pip` install the Python library to generate vector embeddings from the model  with `pip install ollama`. (REST API or JavaScript library also available)\"\n   ]\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIt will use ollama to create a RAG locally.\nLet me know if that helps!\n\n----------\n\n[P_K (2024-12-29T16:42:54.725Z)]: Thanks DudaNogueira.\nI have tried this but this works with local ollama embeddings. With the Ollama embedding model hosted on a server, I need to pass in the URL as well as Auth Token for generating embeddings. I unable to find a way to pass in Auth Token to “text2vec-ollama” vectorizer.\nHere is sample curl to access the embedding model from local:\ncurl https://ollama-inference-url/api/embeddings -H \"Authorization: AUTH-TOKEN\" -H \"Content-Type: application/json\" -d '{\"model\": \"nomic-embed-text:latest\", \"prompt\": \"Why is sky blue?\"}'\n\n----------\n\n[DudaNogueira (2024-12-29T18:36:10.621Z)]: Oh, I see. I believe the ollama module was built with the assumption that Ollama will not require an api token \nI have quickly checked that module code and have not found a way to provide an API. I believe this is an interesting feature request.\nI will check on this over the week and make sure we open a feature request if necessary.\nThanks!",
    "date_created": "2024-12-29T10:26:00.802Z",
    "has_accepted_answer": false,
    "title": "Use ollama embeddings hosted on a server using weaviate",
    "topic_id": 9509
  },
  {
    "user_id": 1214,
    "conversation": "[elias.gabriel (2024-10-17T17:25:01.869Z)]: Description\nI have a fairly complicated K8s cluster into which I’m deploying a 3 node weaviate setup. I’m using custom services to underpin the text2vec-transformers and reranker-transfomers modules.\nI want to be able to control my custom module services independently of Weaviate, so that during deployments & upgrades, I can spin up/roll Weaviate before spinning them up alongside my other deployments that actually use Weaviate.\nI’ve noticed that Weaviate will wait for modules to be Ready before becoming Ready itself. Is that something that can be disabled, so that I can spin up my module services later separately?\nServer Setup Information\n\nWeaviate Server Version: 1.26.6\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: N/A\nMultitenancy?: No\n\n----------\n\n[DudaNogueira (2024-10-17T21:02:19.085Z)]: Hi @elias.gabriel !\nThat indeed makes sense.\nAs those modules are locally “bound” they will check for the liveness of the inference model.\nCan you open a feature request here?\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nIssues · weaviate/weaviate\n\n  Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of ...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI could then forward that to our modules team.\nThanks!\n\n----------\n\n[elias.gabriel (2024-10-17T21:49:46.757Z)]: github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Support separately-managed module services\n    \n\n    \n      \n        opened 09:48PM - 17 Oct 24 UTC\n      \n\n\n      \n        \n          \n          thearchitector\n        \n      \n    \n\n    \n        \n          feature request\n        \n    \n  \n\n\n  \n    ### Describe your feature request\n\nI have a fairly complicated K8s cluster into …which I’m deploying a multi-node Weaviate setup. I’m using custom services / deployments to underpin the `text2vec-transformers` and `reranker-transfomers` modules.\n\nI’ve noticed that Weaviate will wait for those pods to be `Ready` before becoming `Ready` itself. It would be useful to be able to disable that, so could control my custom module services independently of Weaviate; during deployments & upgrades, I'd be able to spin up/roll Weaviate before spinning them up alongside my other deployments that actually use Weaviate. Doing would also allow me to better version my custom services, potentially as part of a separate Helm chart, without having to roll Weaviate every time I update them.\n\nSince they'd be managed separately, I could see Weaviate either\n1. coming online, then rejecting requests until the service endpoints ping healthy.\n2. queuing queries until the services come online to process them, or until the request timeout is reached.\n\nThe latter seems like it could integrate really well into the existing `index_queue_*` Prometheus metrics.\n\n### Code of Conduct\n\n- [X] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)",
    "date_created": "2024-10-17T17:25:01.821Z",
    "has_accepted_answer": true,
    "title": "Deploying Weaviate before modules",
    "topic_id": 5732
  },
  {
    "user_id": 1183,
    "conversation": "[Vipul_Maheshwari (2024-07-10T05:43:48.835Z)]: Hey Hi Guys, i am facing so many issues in adding the batch of data during the ingestion part in the weaviate. Tried all the things but there is not a single start to end script which can help me to ingest all the data in the batches…\nI tried skimp with this link : Batch import | Weaviate - Vector Database\nbut nothing seems to be working.\nCan anyone help me with it? I really need it…\n\n----------\n\n[DudaNogueira (2024-07-10T13:31:41.550Z)]: hi @Vipul_Maheshwari !!\nWelcome to our community.\nPlease, when opening a thread, fill in the requested info, like server version, deployment, etc.\nDo you see any error logs? Can you share any code we can reproduce?\nThanks!\n\n----------\n\n[Vipul_Maheshwari (2024-07-11T12:52:27.873Z)]: Hey @DudaNogueira thanks for reverting back.\nFrom the next time, I will make sure to fill the requested info and other details.\nSo I have completed this script for batch ingestion, can you just skim through it fast and let me know if there is any kind of error in it:\nimport numpy as np\nimport logging\nimport time\nimport weaviate\nfrom tqdm import tqdm\nimport weaviate.classes.config as wc\n\n# Constants\nCOLLECTION_NAME = \"weaviate_test_collection_part6\"\nNUM_BATCHES = 10\nVECTORS_PER_BATCH = 100\nVECTOR_SIZE = 1536\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\n\n# Connect to Weaviate\nclient = weaviate.connect_to_embedded()\n\n# Create Weaviate collection\nweaviate_collection = client.collections.create(\n    name=COLLECTION_NAME,\n    properties=[\n        wc.Property(name=\"item\", data_type=wc.DataType.TEXT),\n    ],\n    vectorizer_config=None\n)\n\n# Define the batch generation function\ndef make_batches(num_batches, vectors_per_batch, vector_size):\n    for i in range(num_batches):\n        try:\n            vectors = np.random.rand(vectors_per_batch, vector_size).astype(np.float32)\n            vectors_list = vectors.tolist()\n            items = [str(i * vectors_per_batch + j + 1) for j in range(vectors_per_batch)]\n            batch = list(zip(items, vectors_list))\n            logging.info(f\"Successfully generated batch {i+1}/{num_batches}\")\n            yield batch\n        except Exception as e:\n            logging.error(f\"Error in batch {i+1}: {str(e)}\")\n            raise\n\n# Main processing loop\ntry:\n    total_time = 0.0\n    batch_times = []\n    for _batch_index, _batch in enumerate(tqdm(make_batches(num_batches=NUM_BATCHES,  vectors_per_batch=VECTORS_PER_BATCH, vector_size=VECTOR_SIZE), desc=\"Processing batches\", total=NUM_BATCHES)):\n        ct = 0\n        with weaviate_collection.batch.fixed_size(VECTORS_PER_BATCH) as batch:\n            \n            batch_start_time = time.time()\n            for item, vector in _batch:\n\n                batch.add_object(\n                    properties={\"item\": item},\n                    vector=vector\n                )\n\n                ct += 1\n                \n                # If the number of vectors reached VECTORS_PER_BATCH threshold, it means the batch is injected with the desired number of vectors. (Ingestion of one batch is completed)\n                if ct % VECTORS_PER_BATCH == 0:\n                    duration = time.time() - batch_start_time\n                    batch_times.append(duration)\n                    total_time += duration\n                    print(f\"Processed {ct} vectors in batch {_batch_index + 1} of {NUM_BATCHES} in {duration:.2f}s\")\n    \n    print(f\"Total processing time: {total_time:.2f}s\")\n    print(f\"Average time per batch: {np.mean(batch_times):.2f}s\")\n\nexcept Exception as e:\n    logging.error(f\"An error occurred during processing: {str(e)}\")\n    raise\n\nfinally:\n    pass\n\n----------\n\n[DudaNogueira (2024-07-15T13:22:10.330Z)]: Hi!\nCan you try catching those errors?\nCheck here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate - Vector Database\n\n  Overview\n\n----------\n\n[Vipul_Maheshwari (2024-07-21T07:08:37.691Z)]: Hey Hi! I think I figured it out, can you just confirm if this sounds good to you, Thanks in advance:\nimport numpy as np\nimport logging\nimport time\nimport weaviate\nfrom tqdm import tqdm\nimport weaviate.classes.config as wc\n\n# Constants\nCOLLECTION_NAME = \"weaviate_test_collection_part6\"\nNUM_BATCHES = 10\nVECTORS_PER_BATCH = 100\nVECTOR_SIZE = 1536\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\n# Connect to Weaviate\nclient = weaviate.connect_to_embedded()\n\n# Create Weaviate collection\nweaviate_collection = client.collections.create(\n    name=COLLECTION_NAME,\n    properties=[\n        wc.Property(name=\"item\", data_type=wc.DataType.TEXT),\n    ],\n    vectorizer_config=None\n)\n\n# Define the batch generation function\ndef make_batches(num_batches, vectors_per_batch, vector_size):\n    for i in range(num_batches):\n        try:\n            vectors = np.random.rand(vectors_per_batch, vector_size).astype(np.float32)\n            vectors_list = vectors.tolist()\n            items = [str(i * vectors_per_batch + j + 1) for j in range(vectors_per_batch)]\n            batch = list(zip(items, vectors_list))\n            logging.info(f\"Successfully generated batch {i+1}/{num_batches}\")\n            yield batch\n        except Exception as e:\n            logging.error(f\"Error in batch {i+1}: {str(e)}\")\n            raise\n\n# Main processing loop\ntry:\n    total_time = 0.0\n    batch_times = []\n    for _batch_index, _batch in enumerate(tqdm(make_batches(num_batches=NUM_BATCHES,  vectors_per_batch=VECTORS_PER_BATCH, vector_size=VECTOR_SIZE), desc=\"Processing batches\", total=NUM_BATCHES)):\n        ct = 0\n        with weaviate_collection.batch.fixed_size(VECTORS_PER_BATCH) as batch:\n            \n            batch_start_time = time.time()\n            for item, vector in _batch:\n\n                batch.add_object(\n                    properties={\"item\": item},\n                    vector=vector\n                )\n\n                ct += 1\n                \n                # If the number of vectors reached VECTORS_PER_BATCH threshold, it means the batch is injected with the desired number of vectors. (Ingestion of one batch is completed)\n                if ct % VECTORS_PER_BATCH == 0:\n                    duration = time.time() - batch_start_time\n                    batch_times.append(duration)\n                    total_time += duration\n                    print(f\"Processed {ct} vectors in batch {_batch_index + 1} of {NUM_BATCHES} in {duration:.2f}s\")\n    \n    print(f\"Total processing time: {total_time:.2f}s\")\n    print(f\"Average time per batch: {np.mean(batch_times):.2f}s\")\n\nexcept Exception as e:\n    logging.error(f\"An error occurred during processing: {str(e)}\")\n    raise\n\nfinally:\n    pass\n\n----------\n\n[DudaNogueira (2024-07-23T12:45:09.131Z)]: Hi!\nThis seems fine.\nNow the idea is that you can experiment with different batch sizes.\nHere you can have more info on that:\nhttps://weaviate-python-client.readthedocs.io/en/stable/weaviate.batch.html#module-weaviate.batch.crud_batch\nThanks!\n\n----------\n\n[Vipul_Maheshwari (2024-07-23T13:07:27.932Z)]: Yes! But i wanted to take the VECTORS_PER_ BATCH variables as my go to for deciding the number of batches I want to ingest at a time…\nThanks for putting this through, sorry for the inconvenience! I am just glad you reviewed the snippet and I am good to go…\n\n----------\n\n[DudaNogueira (2024-07-23T13:10:53.329Z)]: That’s ok.\nYou can probably get interesting results with dynamic, as it will adjust the batch size according to what the server reports back, taking into account the current server load.\n\n----------\n\n[Vipul_Maheshwari (2024-07-23T13:29:36.405Z)]: Well to be honest, I am running a benchmark for various DBs to understand the time it takes for the ingestion as well as the bottleneck for the server load…\nSo it would be unfair to change the batch size dynamically\n\n----------\n\n[DudaNogueira (2024-07-23T13:31:18.643Z)]: Fair enough \nYou can also try enabling the ASYNC_INDEXING, so you don’t need to wait for the indexation step.",
    "date_created": "2024-07-10T05:43:48.786Z",
    "has_accepted_answer": true,
    "title": "Not able to ingest the batches of data",
    "topic_id": 2998
  },
  {
    "user_id": 655,
    "conversation": "[alisha_liu (2024-12-16T19:54:05.498Z)]: I am using weaviate typescript v3:\nI have below test code:\nconst itemsIdToDelete = [\n  'c0381cd9-4f9e-4d48-b0e9-33d0e8c3ffa7',\n  'd0fe3dff-3135-4379-92b4-22229db68653'\n]\ndeleteResult = await myCollection.data.deleteMany(\n                  myCollection.filter.byId().containsAny(itemsIdToDelete),\n                  {\n                    dryRun: true,\n                  }\n                );\n\nI got below output:\nINFO    deleteResult {\n  took: 0.0004886100068688393,\n  failed: 0,\n  matches: 0,\n  successful: 0,\n  objects: undefined\n}\n\nI have double check that the object with above id exist in the weaviate collection, screenshot of them:\nimage2398×1056 432 KB\nimage2322×1040 436 KB\n\n----------\n\n[sebawita (2024-12-17T10:44:39.241Z)]: Hi @alisha_liu,\nThat is super strange, I’ve just run a test on a dummy collection.\nFirst I printed 3 UUIDs:\nconst myCollection = client.collections.get('Animals');\nconst res = await myCollection.query.fetchObjects({limit: 3})\n\nfor (const item of res.objects) {\n    console.log(item.uuid)\n}\n\nThen, I took these 3 UUIDs to run the following delete command:\nconst itemsIdToDelete = [\n    \"327e9b13-3ca8-4fdf-867d-5f8326160bc8\",\n    \"4452c466-8e38-421a-b4e6-5ccada98cdf6\",\n    \"548ccd40-acef-4cf2-99d2-afda5e665399\",\n]\n\nconst deleteResult = await myCollection.data.deleteMany(\n    myCollection.filter.byId().containsAny(itemsIdToDelete),\n    {\n        dryRun: true,\n    }\n);\n\nWhich gave me the following response - indicating that it would have deleted 3 objects:\n{\n  \"took\": 0.0006591000128537416,\n  \"failed\": 0,\n  \"matches\": 3,\n  \"successful\": 3\n}\n\nVersions\nCan you share the version of your weaviate-client and the weaviate version?\nYou can check your weaviate version by running:\nconsole.log((await client.getMeta()).version)\n\nCheck object count\nSometimes, it is easy to misspell collection name.\nCan you check that myCollection contains data, like this:\n    const myCollection = client.collections.get('Animals');\n    const overAll = await myCollection.aggregate.overAll()\n    console.log(`Object Count: ${overAll.totalCount}`)\n\nDynamicaly grab uuids\nCan you run the following script, which dynamically grabs 3 UUIDs and then maps them to an array of IDs.\nconst res = await myCollection.query.fetchObjects({limit: 3})\n\nconst itemsIdToDelete = res.objects.map(o => o.uuid)\nconsole.log(`UUIDs to delete:\\n${JSON.stringify(itemsIdToDelete, null, 2)}`)\n\nconst deleteResult = await myCollection.data.deleteMany(\n    myCollection.filter.byId().containsAny(itemsIdToDelete),\n    {\n        dryRun: true,\n    }\n);\n\nconsole.log(JSON.stringify(deleteResult, null, 2))\n\n----------\n\n[alisha_liu (2024-12-17T13:46:28.629Z)]: Hi @sebawita ,\nThank you so much for help me debug the issues.\nMy project environment: node.js (version 22.0.0) typescript (version 5.3.3)\n1 After run this command:console.log((await client.getMeta()).version),\nI got this output: 1.26.0-rc.0\n2 weaviate-client  3.1.4\nBelow is the script you provided and output:\n  const result = await myCollection.aggregate.overAll();\n  const totalCount = result.totalCount;\n  console.log('totalCount',totalCount);\n  const res = await myCollection.query.fetchObjects({ limit: 3 });\n\n  const itemsIdToDelete = res.objects.map((o) => o.uuid);\n  console.log(\n    `UUIDs to delete:\\n${JSON.stringify(itemsIdToDelete, null, 2)}`\n  );\n\n  const testdeleteResult = await myCollection.data.deleteMany(\n    myCollection.filter.byId().containsAny(itemsIdToDelete),\n    {\n      dryRun: true,\n    }\n  );\n\n  console.log(\"testdeleteResult\",JSON.stringify(testdeleteResult, null, 2));\n\nOutput:\nINFO    totalCount 40\n2024-12-17T13:56:47.332Z        bc863d5c-78ed-426c-8b25-7e68b2d28e4a    INFO    UUIDs to delete:\n[\n“016d2780-44d3-409b-8047-d4bddd706705”,\n“0fe66df1-a04e-439c-bcf8-addeabdaef4c”,\n“1006e63e-d1db-402d-9e49-5150eac5339b”\n]\n2024-12-17T13:56:47.354Z        bc863d5c-78ed-426c-8b25-7e68b2d28e4a    INFO    testdeleteResult {\n“took”: 0.0007071029976941645,\n“failed”: 0,\n“matches”: 0,\n“successful”: 0\n}\nMy second test steps and result:\n1Update my weaviate client from 1.26.0-rc.0 to 1.27.1\n2 Update weaviate-client  from 3.1.4 to 3.2.5\n3 execute above function with same collection second time and get same result as above.\nAddition information:\nIf I change collection, and run above code then got the result as expected.\nSeems like the data exist in the problem collection are bad data, but after loading them via Postman, I can not figure out what’s the different with the worked data.",
    "date_created": "2024-12-16T19:54:05.450Z",
    "has_accepted_answer": false,
    "title": "Delete object with id array failed",
    "topic_id": 9265
  },
  {
    "user_id": 956,
    "conversation": "[nik (2024-06-28T09:53:28.193Z)]: Description\nI have written some code that ingests data into weaviate from a postgres or a pandas dataframe. This code relies mostly on methods in weaviate-client (4.6.1). See below for some basics on how it works (this is not a comprehensive working example)\nclass BatchStream:\n    '''\n    a class that allows us to batch-stream\n    data from a postgres db into weaviate.\n    '''\n    type_mapping = {\n        'int': wc.DataType.INT,\n        'str': wc.DataType.TEXT,\n        'float': wc.DataType.NUMBER,\n        'bool': wc.DataType.BOOL,\n        'datetime': wc.DataType.DATE\n    }\n    def __init__(\n            self, \n            client: Client,\n            vectorizer_config: wc.Configure.Vectorizer,\n            generative_config: wc.Configure.Generative,\n            postgres_string: str = 'test',\n            weaviate_batch_size: int = 100,\n            n_workers: int = 4,\n        ) -> None:\n        self.client = client\n        self.vectorizer_config = vectorizer_config\n        self.generative_config = generative_config\n        self.postgres_string = postgres_string\n        self.weaviate_batch_size = weaviate_batch_size\n        self.n_workers = n_workers\n\n        logging.info(\"connecting to postgres db...\")\n        self.engine = create_engine(self.postgres_string)\n        logging.info(\"connected to database\")\n\n\n        def stream_insert_many(\n            self,\n            collection: str,\n            create_collection: bool = True,\n            query: str | None = None,\n            df: pd.DataFrame | None = None,\n            properties: Optional[Union[List[wc.Property], str]] = 'infer') -> None:\n        '''\n        method that streams data retrieved from a \n        postgres query, or a df, into weaviate. \n        '''\n        if df and query:\n            raise ValueError(\"Supply either a dataframe or a sql query, not both.\")\n        \n        if df is None and query is None:\n            raise ValueError(\"Supply either a dataframe or a sql query.\")\n        \n        if properties == 'infer':\n            properties = self._infer_weaviate_properties(df, query)\n\n        if create_collection:\n            coll = self.client.collections.create(\n                name=collection,\n                properties=properties,\n\n                # vectorizer\n                vectorizer_config=self.vectorizer_config,\n                # generative module\n                generative_config=self.generative_config\n            )\n        else:\n            coll = self.client.collections.get(collection)\n\n        insert_obj = []\n        if df is None and query is not None:\n            for chunk in self._sql_query_to_chunked_df(query):\n                insert_obj.extend(chunk.to_dict(orient='records'))\n            \n        else:\n            insert_obj = df.to_dict(orient='records')\n        \n        coll.data.insert_many(insert_obj)\n\nNow, I can easily access this data through weaviate-client, such as count it or run similarity_search on it.\nFor the purpose of building a RAG application, I want to query it via langchain. Langchain seems to be pretty straight-forward, and well integrated with weaviate via the langchain-weaviate package for python. So, following various tutorials, e.g. 1, 2 or 3, I am able to init all the required objects using langchain-weaviate:\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\nfrom langchain_core.messages import HumanMessage\nfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI, OpenAI\nfrom langchain.chains import ChatVectorDBChain\n\nclient = . . .\n\nclient.is_ready()\n>>> True\n\nvectorstore = WeaviateVectorStore(\n    embedding=embeddings,\n    client=client,\n    index_name=\"my_collection\",\n    text_key=\"my_target_key\"\n)\n\nNow, I want to query my collection via the methods on the langchain_weaviate.vectorstores.WeaviateVectorstore. I attempt it like so:\nvectorstore.similarity_search('test')\n\nNow, this returns an empty list [].\nIf instead I run collection.query.near_text() from the weaviate client, I get relevant documents returned.\nHence follows the question:\nHow can I perform queries on a weaviate collection via langchain if data was ingested using the weaviate client library?\nServer Setup Information\n\nWeaviate Server Version: 1.24.13\nDeployment Method: weaviate cloude\nMulti Node? Number of Running Nodes:\nClient Language and Version: Python 3.11.3, client v 4.6.1\nMultitenancy?: No\n\n----------\n\n[DudaNogueira (2024-06-28T12:50:51.958Z)]: Hi @nik !!\nI believe this is an interesting recipe to add here:\n\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/llm-frameworks/langchain at main · weaviate/recipes\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWe are looking for contributors, by the way \nHere is some code I believe can help you:\nPs: used this to install the required libs:\n\n!pip3 install -U weaviate-client langchain-weaviate langchain-openai\n\nfrom weaviate.classes import config\n\n# lets first create our collection and import data\n\nclient.collections.delete(\"MyCollection\")\ncollection = client.collections.create(\n    \"MyCollection\",\n    vectorizer_config=config.Configure.Vectorizer.text2vec_openai(),\n    properties=[\n        config.Property(name=\"text\", data_type=config.DataType.TEXT),\n        config.Property(name=\"source\", data_type=config.DataType.TEXT)\n    ]\n)\n\ncollection.data.insert({\"text\": \"something about cats\", \"source\": \"document1\"})\ncollection.data.insert({\"text\": \"something about tiger\", \"source\": \"document1\"})\ncollection.data.insert({\"text\": \"something about lion\", \"source\": \"document1\"})\n\ncollection.data.insert({\"text\": \"something about dogs\", \"source\": \"document2\"})\ncollection.data.insert({\"text\": \"something about wolf\", \"source\": \"document2\"})\ncollection.data.insert({\"text\": \"something about coyotes\", \"source\": \"document2\"})\n\nNow this is how you would search using Weaviate directly:\ncollection = client.collections.get(\"MyCollection\")\nresponse = collection.query.near_text(query=\"pet animals\")\nfor object in response.objects:\n    print(object.properties)\n\nthis will output something like:\n\n{‘text’: ‘something about dogs’, ‘source’: ‘document2’}\n{‘text’: ‘something about cats’, ‘source’: ‘document1’}\n{‘text’: ‘something about coyotes’, ‘source’: ‘document2’}\n{‘text’: ‘something about lion’, ‘source’: ‘document1’}\n{‘text’: ‘something about tiger’, ‘source’: ‘document1’}\n{‘text’: ‘something about wolf’, ‘source’: ‘document2’}\n\nNow, in order to search using this same data with LangChain, you can:\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\n\nembeddings = OpenAIEmbeddings()\ndb = WeaviateVectorStore.from_documents([], embeddings, client=client, index_name=\"MyCollection\")\n\n# perform a query\ndocs = db.similarity_search(\"pet animals\")\nprint(docs)\n\nAnd this would be the output:\n\n[Document(page_content=‘something about dogs’, metadata={‘source’: ‘document2’}), Document(page_content=‘something about cats’, metadata={‘source’: ‘document1’}), Document(page_content=‘something about coyotes’, metadata={‘source’: ‘document2’}), Document(page_content=‘something about lion’, metadata={‘source’: ‘document1’})]\n\nLet me know if this helps\n\n----------\n\n[nik (2024-06-29T10:43:56.920Z)]: @DudaNogueira , once again thank you very much for helping me out. I’d be happy to share a recipe on filling a weaviate with postgres data once I’ve got my solution to work properly  !\nOut of interest, one more question regarding the behaviour of collection.query.near_text('animal', limit=3):\n\nwhen i run this (in an interactive session) for the first time, it works really well and returns the closest documents.\nbut when i modify the query string, to e.g. ‘football’, i.e. something both semantically and ortographically completely different, it returns exactly the same documents.\nthe only way I can get the ‘correct’ documents for my new query is by re-starting my interactive session.\n\nIs there a workaround for this? Is this the intended behaviour?\nThanks!\n\n----------\n\n[DudaNogueira (2024-07-01T20:47:15.518Z)]: hi @nik !!\nWhat is this interactive session you mentioned? Not sure I follow it \nNote that, on a similarity search, it will always return objects. They may not be close / related to your query. On those cases, the distance will be high, but the objects will still be there.\nSo, for example, if you you only have ten objects, it will always return those 10, but ordered by the closest to farthest to your query.\nIf you could reproduce this interactive with the given example, I would then be able to understand what is happening \nLet me know if this helps\n\n----------\n\n[nik (2024-07-03T17:40:38.693Z)]: hi @DudaNogueira\nthanks for getting back to me. What I meant by ‘interactive’ is that you’re running code either in e.g. ipython or the regular python repl, or jupyter. that is you are typing stuff and getting stuff returned as you go along, rather than having a script or a server/app running.\nin such an example, if you search for something like this:\nresponse = collection.query.near_text('animal', limit=3) then print the results as you would normally, and then run e.g. response = collection.query.near_text('football', limit=3), and then print the objects in response, it will show the same objects as for the animal search (which likely is quite close to what you’re looking for with the first query, but not the second.\nI wonder if this behaviour is expected or a bug; and if there is any way to circumvent it. Thanks!\n\n----------\n\n[DudaNogueira (2024-07-03T18:50:23.231Z)]: Oh, I see.\nI believe this will depend on the objects you have and the query.\nSmall queries (like a single word) may have not enough meaning to change the limited dataset (assuming you don’t have a lot of objects).\nCan you also print the distance for that query?\nsomething like:\nresponse = collection.query.near_text('animal', limit=3, return_metadata=wvc.query.MetadataQuery(distance=True))  \n\nThanks!\n\n----------\n\n[omarsinno (2024-07-11T20:35:09.246Z)]: Hello @DudaNogueira !\nI would like to add on this question, what if the collection was divided into tenants using the weaviate-client.\nCurrently if I run the code as such:\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\nfrom langchain_community.embeddings import OllamaEmbeddings\n\nimport weaviate\n\nclient = weaviate.connect_to_local() \n\nembeddings = OllamaEmbeddings(model = 'mxbai-embed-large')\ndb = WeaviateVectorStore.from_documents(\n    [], \n    embeddings, \n    client=client, \n    index_name=\"Books\"\n)\n\nI get the following error:\n  File \"/home/.../lib/python3.10/site-packages/langchain_weaviate/vectorstores.py\", line 537, in _tenant_context\n    raise ValueError(\"Must use tenant context when multi-tenancy is enabled\")   \nValueError: Must use tenant context when multi-tenancy is enabled\n\nHow can I enable multi-tenancy in this case?\n\n----------\n\n[DudaNogueira (2024-07-15T16:42:19.866Z)]: hi @omarsinno !!\nWelcome to our community!\nWe do have multi tenancy support in Weaviate. Check here the docs:\n\n  \n      \n\n      python.langchain.com\n  \n\n  \n    \n\nWeaviate | 🦜️🔗 LangChain\n\n  This notebook covers how to get started with the Weaviate vector store in LangChain, using the langchain-weaviate package.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nfor instance, the code example:\ndb_with_mt = WeaviateVectorStore.from_documents(\n    docs, embeddings, client=weaviate_client, tenant=\"Foo\"\n)\n\nLet me know if that helps!\nThanks!",
    "date_created": "2024-06-28T09:53:28.124Z",
    "has_accepted_answer": true,
    "title": "How to access/search data ingested through Weaviate client in langchain / langchain-weaviate?",
    "topic_id": 2850
  },
  {
    "user_id": 2495,
    "conversation": "[Oleksandr_Yakovliev (2024-11-11T15:03:39.297Z)]: Description\nI’m trying to initialize client connection to local instance of weavite server from one docker container to another and experiencing next error:\nWeaviateStartUpError: Weaviate startup failed with message: Weaviate failed to startup with message: fetch failed\n\nmeanwhile connection to this local instance is available from Postman (this is the response from http://localhost:8086/v1/meta endpoint):\n{\n    \"grpcMaxMessageSize\": 10485760,\n    \"hostname\": \"http://[::]:8080\",\n    \"modules\": {\n        \"text2vec-openai\": {\n            \"documentationHref\": \"https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\",\n            \"name\": \"OpenAI Module\"\n        }\n    },\n    \"version\": \"1.27.1\"\n}\n\nrunning code example:\nconst client = await weaviate.connectToLocal({\n      host: \"127.0.0.1\",\n      port: 8086,\n      grpcPort: 50051, \n});\n\nDocker config for weaviate service in docker compose file:\nweaviate:\n    command: --host 0.0.0.0 --port '8080' --scheme http\n    container_name: dowow-weaviate\n    image: cr.weaviate.io/semitechnologies/weaviate:1.27.1\n    restart: always\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    networks:\n      dowow:\n        ipv4_address: 172.16.41.55\n    ports:\n    - 8086:8080\n    - 50051:50051\n    - 2112:2112\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'\n      ENABLE_MODULES: 'text2vec-openai'\n      CLUSTER_HOSTNAME: 'node1'\n\nvolumes:\n  weaviate_data:\n    driver: local\n\nServer Setup Information\n\nWeaviate Server Version: 1.27.1\nDeployment Method: docker\nMulti Node? Number of Running Nodes:\nClient Language and Version: TS client v3 (3.2.2)\nMultitenancy?:\n\nHow this can be fixed?\n\n----------\n\n[Oleksandr_Yakovliev (2024-11-11T15:43:04.645Z)]: You may close the topic. I was missing the correct config for host and port between containers\n\n----------\n\n[DudaNogueira (2024-11-11T15:58:18.741Z)]: hi @Oleksandr_Yakovliev !!\nWelcome to our community \nThanks for sharing!",
    "date_created": "2024-11-11T15:03:39.252Z",
    "has_accepted_answer": true,
    "title": "Weavite client connectToLocal failure",
    "topic_id": 7539
  },
  {
    "user_id": 1188,
    "conversation": "[Adityam_Ghosh (2024-07-11T06:28:49.795Z)]: Description\nSo I have a custom linux home server which I have built and I have deployed a weaviate instance using docker. Now I am transfering around 7M records from my mongo instance (which is also running as a docker instance in my current setup) to weaviate using multithreading.\nThe thing is after migrating around 3M records the python script crashes with the following error:\nException: Query call with protocol GRPC batch failed with message recvmsg:Connection reset by peer.\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python v4\nMultitenancy?: No\n\nAny additional Information\nHere’s the complete log:\nweaviate.exceptions.WeaviateBatchError: Query call with protocol GRPC batch failed with message recvmsg:Connection reset by peer.\nTraceback (most recent call last):\n  File \"/home/abc/test/datamigration/.venv/lib/python3.12/site-packages/weaviate/collections/batch/grpc_batch_objects.py\", line 137, in __send_batch\n    res, _ = self._connection.grpc_stub.BatchObjects.with_call(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/abc/test/datamigration/.venv/lib64/python3.12/site-packages/grpc/_channel.py\", line 1198, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/abc/test/datamigration/.venv/lib64/python3.12/site-packages/grpc/_channel.py\", line 1006, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"recvmsg:Connection reset by peer\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-07-11T18:15:30.460550531+12:00\", grpc_status:14, grpc_message:\"recvmsg:Connection reset by peer\"}\"\n>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/abc/test/datamigration/transfer_mongo2weav.py\", line 194, in <module>\n    upload2weaviate(\n  File \"/home/abc/test/datamigration/transfer_mongo2weav.py\", line 39, in upload2weaviate\n    uuids = weaviate_collection.data.insert_many(data)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/abc/test/datamigration/.venv/lib/python3.12/site-packages/weaviate/collections/data.py\", line 410, in insert_many\n    return self._batch_grpc.objects(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/abc/test/datamigration/.venv/lib/python3.12/site-packages/weaviate/collections/batch/grpc_batch_objects.py\", line 97, in objects\n    errors = self.__send_batch(weaviate_objs, timeout=timeout)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/abc/test/datamigration/.venv/lib/python3.12/site-packages/weaviate/collections/batch/grpc_batch_objects.py\", line 151, in __send_batch\n    raise WeaviateBatchError(e.details())  # pyright: ignore\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nweaviate.exceptions.WeaviateBatchError: Query call with protocol GRPC batch failed with message recvmsg:Connection reset by peer.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/abc/test/datamigration/transfer_mongo2weav.py\", line 216, in <module>\n    raise Exception(e)\nException: Query call with protocol GRPC batch failed with message recvmsg:Connection reset by peer.\n\n----------\n\n[Mohamed_Shahin (2024-07-11T09:45:46.319Z)]: Hi @Adityam_Ghosh,\nWelcome to our community! It’s great to have you here.\nI’ve noticed this issue can occur when there’s latency in the connection.\nCan you try adding the skip_init_checks=True flag to your connection call to bypass the initial connection checks? Here’s how you can do it:\nimport weaviate\n\nclient = weaviate.connect_to_local(\n    ...\n    skip_init_checks=True\n)\n\nInitial Connection Checks - If you stop seeing the error, it would likely point to latency issues when checking the port.\n\n----------\n\n[Adityam_Ghosh (2024-07-11T15:10:39.379Z)]: Thanks, but unfortunately this also didn’t work out. I’m thinking, is it because I am trying to upload the data to weaviate using multithreading? Like since it’s receiving a lot of request, the server isn’t able to process all of these at once?\n\n----------\n\n[Mohamed_Shahin (2024-07-12T11:50:38.828Z)]: Happy Friday @Adityam_Ghosh!\nIt’s good point! have you considered running multiple nodes setup then like at least 3?\n\n----------\n\n[Adityam_Ghosh (2024-07-12T13:08:22.185Z)]: Hi @Mohamed_Shahin, thanks for the suggestion. I haven’t thought about this. Will surely try it and post an update regarding this.\n\n----------\n\n[Mohamed_Shahin (2024-07-12T13:34:40.297Z)]: Awesome, and configure the replication factor to 3:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage collections | Weaviate - Vector Database\n\n  Every object in Weaviate belongs to exactly one collection. Use the examples on this page to manage your collections.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAlso, this batch import best practice may add to the code you have\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know how it goes!\nHave a good weekend!\n\n----------\n\n[Adityam_Ghosh (2024-07-12T13:53:01.260Z)]: Thanks mate, you too have a great weekend! Right now, I am trying another configuration where I have just increased the memory limit from 1GB to 4GB and see what happens. And then I will try the solution that you have shared.\n\n----------\n\n[00.lope.naughts (2024-10-17T15:34:12.232Z)]: I have also seen this. for my case, it seems to have something to do with latency of the network connection (to the free weaviate cloud instance).\nclient = weaviate.connect_to_wcs(\n        additional_config=AdditionalConfig(timeout=Timeout(init=30, query=60, insert=120)),\n        # skip_init_checks=True,\n        cluster_url=WCS_URL,\n        auth_credentials=weaviate.auth.AuthApiKey(WCS_API_KEY)\n      )\n\nadding the timeout config seemed to fix the issues (mostly), and I opt not to do the skip init check.\nhowever, it is still happening intermittently. it tends to happen around\ncollection.data.delete_many(…)\nwhere I deleted a lot of stuff. But I haven’t tested enough to be sure. It is definitely intermittent since some jobs will run through fine. And using tenacity on retry didnt seem to help (more debugging there needed).\nbut if you have fixed your problem, and please share. I will detail my setup on another thread if it proves to be very problematic.",
    "date_created": "2024-07-11T06:28:49.744Z",
    "has_accepted_answer": false,
    "title": "Exception: Query call with protocol GRPC batch failed with message recvmsg:Connection reset by peer",
    "topic_id": 3012
  },
  {
    "user_id": 1241,
    "conversation": "[SergeLiatko (2024-07-24T08:34:42.725Z)]: Description\nHi guys,\nI have these type of errors often inside a weaviate docker container:\nexplorer: get class: vectorize params: vectorize params: vectorize params: vectorize move to: vectorize move to: remote client vectorize: send POST request: Post “https://api.openai.com/v1/embeddings”: remote error: tls: bad record MAC (code: 0)\nServer Setup Information\nnetworks:\n    lawxer:\n        name: \"lawxer\"\n        driver: bridge\n\nservices:\n    traefik:\n        image: \"traefik:v3.1\"\n        container_name: \"traefik\"\n        command:\n            - \"--ping=true\"\n            - \"--log.level=DEBUG\"\n            - \"--log.filePath=/var/log/traefik.log\"\n            - \"--log.maxage=2\"\n            - \"--accessLog.filePath=/var/log/access.log\"\n            - \"--api.dashboard=true\"\n            - \"--api.insecure=false\"\n            - \"--providers.docker.endpoint=unix:///var/run/docker.sock\"\n            - \"--providers.docker.exposedbydefault=false\"\n            - \"--providers.docker.useBindPortIP=true\"\n            - \"--entryPoints.web.address=:80\"\n            - \"--entryPoints.web.http.redirections.entryPoint.to=websecure\"\n            - \"--entryPoints.web.http.redirections.entryPoint.scheme=https\"\n            - \"--entryPoints.websecure.address=:443\"\n            - \"--entryPoints.websecure.http.tls.certResolver=myresolver\"\n            - \"--certificatesresolvers.myresolver.acme.tlschallenge=true\"\n            - \"--certificatesresolvers.myresolver.acme.email=EDITED\"\n            - \"--certificatesresolvers.myresolver.acme.storage=/letsencrypt/acme.json\"\n        ports:\n            - \"80:80\"\n            - \"443:443\"\n            - \"8080:8080\"\n        volumes:\n            - \"/var/run/docker.sock:/var/run/docker.sock\"\n            - \"./letsencrypt:/letsencrypt\"\n            - \"./logs/traefik:/var/log\"\n            #- \"./settings/traefik.yml:/etc/traefik/traefik.yml:ro\"\n        labels:\n            - \"traefik.enable=true\"\n            - \"traefik.http.routers.traefik.entrypoints=websecure\"\n            - \"traefik.http.routers.traefik.rule=Host(`apimanager.lawxer.ai`)\"\n            - \"traefik.http.routers.traefik.tls.certresolver=myresolver\"\n            - \"traefik.http.routers.traefik.service=api@internal\"\n            - \"traefik.http.routers.traefik.middlewares=traefik-auth\"\n            - \"traefik.http.middlewares.traefik-auth.basicauth.users=EDITED\"\n        restart: \"unless-stopped\"\n        depends_on:\n            - \"weaviate\"\n            - \"app\"\n        networks:\n            - \"lawxer\"\n        healthcheck:\n            test: [ \"CMD\", \"traefik\", \"healthcheck\", \"--ping\" ]\n            interval: 20s\n            timeout: 5s\n            retries: 2\n            start_period: 20s\n\n    cache:\n        image: \"redis:latest\"\n        container_name: \"cache\"\n        ports:\n            - \"6379:6379\"\n        restart: \"unless-stopped\"\n        networks:\n            - \"lawxer\"\n        labels:\n            - \"traefik.enable=false\"\n            - \"traefik.docker.network=lawxer\"\n            - \"traefik.http.services.cache.loadbalancer.server.port=6379\"\n        command:\n            - \"redis-server\"\n        healthcheck:\n            test: [ \"CMD\", \"redis-cli\", \"--raw\", \"incr\", \"ping\" ]\n            interval: 20s\n            timeout: 5s\n            retries: 2\n\n    weaviate:\n        image: \"cr.weaviate.io/semitechnologies/weaviate:1.25.7\"\n        container_name: \"weaviate\"\n        command:\n            - \"--host\"\n            - \"0.0.0.0\"\n            - \"--port\"\n            - \"8060\"\n            - \"--scheme\"\n            - \"http\"\n        ports:\n            - \"8060:8060\"\n            - \"50051:50051\"\n        volumes:\n            - \"./weaviate:/var/lib/weaviate\"\n        restart: \"unless-stopped\"\n        networks:\n            - \"lawxer\"\n        environment:\n            QUERY_DEFAULTS_LIMIT: 25\n            RECOUNT_PROPERTIES_AT_STARTUP: true\n            AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'false'\n            AUTHENTICATION_APIKEY_ENABLED: 'true'\n            AUTHENTICATION_APIKEY_ALLOWED_KEYS: 'EDITED'\n            AUTHENTICATION_APIKEY_USERS: 'lawxer-app'\n            PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n            DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'\n            ENABLE_MODULES: 'text2vec-openai'\n            ORIGIN: 'https://weaviate.lawxer.loc'\n            CLUSTER_HOSTNAME: 'node1'\n            LOG_LEVEL: 'debug'\n        labels:\n            - \"traefik.enable=true\"\n            - \"traefik.docker.network=lawxer\"\n            - \"traefik.http.services.weaviate.loadbalancer.server.port=8060\"\n            - \"traefik.http.routers.weaviate.entrypoints=websecure\"\n            - \"traefik.http.routers.weaviate.rule=Host(`weaviate.lawxer.ai`)\"\n            - \"traefik.http.routers.weaviate.tls.certresolver=myresolver\"\n        healthcheck:\n            test: wget --no-verbose --tries=3 --spider http://localhost:8060/v1/.well-known/ready || exit 1\n            interval: 20s\n            timeout: 2s\n            retries: 2\n            start_period: 20s\n\n    app:\n        build:\n            context: .\n            dockerfile: Dockerfile\n        image: \"sergeliatko/lawxer-api${BUILD_TAG}\"\n        container_name: \"app\"\n        volumes:\n            - \"./logs:/var/www/logs\"\n            - \"./storage:/var/www/storage\"\n            - \"./settings:/var/www/settings\"\n        ports:\n            - \"9501:9501\"\n        labels:\n            - \"traefik.enable=true\"\n            - \"traefik.docker.network=lawxer\"\n            - \"traefik.http.services.app.loadbalancer.server.port=9501\"\n            - \"traefik.http.routers.app.entrypoints=websecure\"\n            - \"traefik.http.routers.app.rule=Host(`api.lawxer.ai`)\"\n            - \"traefik.http.routers.app.tls.certresolver=myresolver\"\n        depends_on:\n            - \"cache\"\n            - \"weaviate\"\n        restart: \"unless-stopped\"\n        networks:\n            - \"lawxer\"\n        healthcheck:\n            test: [ \"CMD\", \"curl\", \"-f\", \"--head\", \"http://localhost:9501/status\" ]\n            interval: 20s\n            timeout: 5s\n            retries: 2\n            start_period: 20s\n\n\n\nWeaviate Server Version: cr.weaviate.io/semitechnologies/weaviate:1.25.7\nDeployment Method: docker\nMulti Node? Number of Running Nodes: No/1\nClient Language and Version: en curl 8.0.5\nMultitenancy?: no\n\nAny additional Information\nWeaviate logs:\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"created startup context, nothing done so far\",\"startup_time_left\":\"59m59.997979453s\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"action\":\"startup\",\"default_vectorizer_module\":\"text2vec-openai\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"text2vec-openai\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"config loaded\",\"startup_time_left\":\"59m59.997753691s\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"configured OIDC and anonymous access client\",\"startup_time_left\":\"59m59.997721555s\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"initialized schema\",\"startup_time_left\":\"59m59.997704322s\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"startup routine complete\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"start registering modules\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"module\":\"text2vec-openai\",\"msg\":\"enabled module\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"completed registering modules\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"node1\":8300},\"time\":\"2024-07-23T16:10:29Z\"}\n{\"address\":\"192.168.176.3:8301\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"action\":\"cluster_api_startup\",\"level\":\"debug\",\"msg\":\"serving cluster api on port 7947\",\"port\":7947,\"time\":\"2024-07-23T16:10:29Z\"}\n{\"address\":\"192.168.176.3:8300\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-07-23T16:10:29Z\"}\n{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"level\":\"info\",\"msg\":\"database has been successfully loaded\",\"n\":0,\"time\":\"2024-07-23T16:10:29Z\"}\n{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"node1\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"id\":\"2-3-1720451756875\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"starting restore from snapshot\",\"size-in-bytes\":22160,\"time\":\"2024-07-23T16:10:29Z\"}\n{\"level\":\"info\",\"msg\":\"restoring schema from snapshot\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"level\":\"info\",\"msg\":\"successfully restored schema from snapshot\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"last_applied_index\":0,\"last_snapshot_index\":3,\"last_store_log_applied_index\":0,\"level\":\"info\",\"msg\":\"load local db from snapshot\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"index\":\"Element\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-07-23T16:10:29Z\"}\n{\"level\":\"info\",\"msg\":\"successfully reloaded indexes from snapshot\",\"n\":1,\"time\":\"2024-07-23T16:10:30Z\"}\n{\"action\":\"\",\"id\":\"2-3-1720451756875\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"snapshot restore progress\",\"percent-complete\":\"[100.00]%\",\"read-bytes\":22160,\"size-in-bytes\":22160,\"time\":\"2024-07-23T16:10:30Z\"}\n{\"id\":\"2-3-1720451756875\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"restored from snapshot\",\"size-in-bytes\":22160,\"time\":\"2024-07-23T16:10:30Z\"}\n{\"action\":\"raft\",\"index\":4,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:node1 Address:192.168.112.2:8300}]]\",\"time\":\"2024-07-23T16:10:30Z\"}\n{\"last_snapshot_index\":3,\"last_store_applied_index\":3,\"last_store_log_applied_index\":0,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":3,\"raft_last_index\":81,\"time\":\"2024-07-23T16:10:30Z\"}\n{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-07-23T16:10:30Z\"}\n{\"action\":\"hnsw_grow_index\",\"level\":\"debug\",\"msg\":\"index grown from 1000 to 3000, took 11.528µs\\n\",\"new_size\":3000,\"previous_size\":1000,\"time\":\"2024-07-23T16:10:31Z\",\"took\":11528}\n{\"action\":\"hnsw_grow_index\",\"level\":\"debug\",\"msg\":\"index grown from 3000 to 5000, took 11.42µs\\n\",\"new_size\":5000,\"previous_size\":3000,\"time\":\"2024-07-23T16:10:31Z\",\"took\":11420}\n{\"action\":\"hnsw_grow_index\",\"level\":\"debug\",\"msg\":\"index grown from 5000 to 7000, took 16.759µs\\n\",\"new_size\":7000,\"previous_size\":5000,\"time\":\"2024-07-23T16:10:31Z\",\"took\":16759}\n{\"action\":\"hnsw_grow_index\",\"level\":\"debug\",\"msg\":\"index grown from 7000 to 9000, took 18.096µs\\n\",\"new_size\":9000,\"previous_size\":7000,\"time\":\"2024-07-23T16:10:31Z\",\"took\":18096}\n{\"action\":\"hnsw_grow_index\",\"level\":\"debug\",\"msg\":\"index grown from 9000 to 11250, took 32.703µs\\n\",\"new_size\":11250,\"previous_size\":9000,\"time\":\"2024-07-23T16:10:31Z\",\"took\":32703}\n{\"action\":\"hnsw_deserialization\",\"level\":\"debug\",\"msg\":\"hnsw commit logger AddTombstone\",\"ops\":1007,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"hnsw_deserialization\",\"level\":\"debug\",\"msg\":\"hnsw commit logger ClearLinksAtLevel\",\"ops\":1675,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"hnsw_deserialization\",\"level\":\"debug\",\"msg\":\"hnsw commit logger DeleteNode\",\"ops\":1007,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"hnsw_deserialization\",\"level\":\"debug\",\"msg\":\"hnsw commit logger RemoveTombstone\",\"ops\":1007,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"hnsw_deserialization\",\"level\":\"debug\",\"msg\":\"hnsw commit logger SetEntryPointWithMaxLayer\",\"ops\":5,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"hnsw_deserialization\",\"level\":\"debug\",\"msg\":\"hnsw commit logger AddNode\",\"ops\":11243,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"hnsw_deserialization\",\"level\":\"debug\",\"msg\":\"hnsw commit logger ReplaceLinksAtLevel\",\"ops\":15753,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"hnsw_deserialization\",\"level\":\"debug\",\"msg\":\"hnsw commit logger AddLinkAtLevel\",\"ops\":353795,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-07-23T16:10:31Z\",\"wait_for_cache_prefill\":false}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"shard=OSmYvNJv23qO is ready\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"level\":\"info\",\"msg\":\"Completed loading shard element_OSmYvNJv23qO in 117.145438ms\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"load_all_shards\",\"level\":\"debug\",\"msg\":\"finished loading all shards\",\"time\":\"2024-07-23T16:10:31Z\",\"took\":\"1.117810669s\"}\n{\"action\":\"hnsw_vector_cache_prefill_level\",\"count\":1,\"hnsw_level\":3,\"index_id\":\"main\",\"level\":\"debug\",\"msg\":\"prefilled level in vector cache\",\"time\":\"2024-07-23T16:10:31Z\",\"took\":1397273}\n{\"action\":\"hnsw_vector_cache_prefill_level\",\"count\":4,\"hnsw_level\":2,\"index_id\":\"main\",\"level\":\"debug\",\"msg\":\"prefilled level in vector cache\",\"time\":\"2024-07-23T16:10:31Z\",\"took\":1576098}\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [192.168.176.3:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"192.168.176.3:8300\"],\"time\":\"2024-07-23T16:10:31Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"node1\",\"Address\":\"192.168.176.3:8300\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"bootstrap\",\"error\":\"bootstrap only works on new clusters\",\"level\":\"error\",\"msg\":\"could not bootstrapping cluster\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"192.168.176.3:8300\"],\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"hnsw_vector_cache_prefill_level\",\"count\":174,\"hnsw_level\":1,\"index_id\":\"main\",\"level\":\"debug\",\"msg\":\"prefilled level in vector cache\",\"time\":\"2024-07-23T16:10:31Z\",\"took\":28919685}\n{\"action\":\"hnsw_vector_cache_prefill_level\",\"count\":10057,\"hnsw_level\":0,\"index_id\":\"main\",\"level\":\"debug\",\"msg\":\"prefilled level in vector cache\",\"time\":\"2024-07-23T16:10:31Z\",\"took\":284769937}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":13250,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-07-23T16:10:31Z\",\"took\":316856358}\n{\"action\":\"inverted filter2search migration\",\"level\":\"debug\",\"msg\":\"migration skip flag set, skipping migration\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"inverted filter2search migration\",\"level\":\"debug\",\"msg\":\"starting switching fallback mode\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"inverted filter2search migration\",\"level\":\"debug\",\"msg\":\"no missing filterable indexes, fallback mode skipped\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"start initializing modules\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"module\":\"text2vec-openai\",\"msg\":\"initialized module\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"module\":\"text2vec-openai\",\"msg\":\"initialized module extension\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"finished initializing modules\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"graphql_rebuild\",\"level\":\"debug\",\"msg\":\"rebuilding the graphql schema\",\"schema\":{\"Objects\":{\"classes\":[{\"class\":\"Element\",\"description\":\"An element of a legal document.\",\"invertedIndexConfig\":{\"bm25\":{\"b\":0.75,\"k1\":1.2},\"cleanupIntervalSeconds\":60,\"stopwords\":{\"additions\":null,\"preset\":\"en\",\"removals\":null}},\"moduleConfig\":{\"text2vec-openai\":{\"baseURL\":\"https://api.openai.com\",\"model\":\"text-embedding-3-small\",\"type\":\"text\",\"vectorizeClassName\":false}},\"multiTenancyConfig\":{\"autoTenantActivation\":false,\"autoTenantCreation\":false,\"enabled\":false},\"properties\":[{\"dataType\":[\"text\"],\"description\":\"The ID of the legal document this element belongs to.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":true,\"vectorizePropertyName\":false}},\"name\":\"document\",\"tokenization\":\"word\"},{\"dataType\":[\"int\"],\"description\":\"The order of the element within its parent element.\",\"indexFilterable\":true,\"indexSearchable\":false,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"order\"},{\"dataType\":[\"text\"],\"description\":\"The path of the element in the legal document.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":true,\"vectorizePropertyName\":false}},\"name\":\"path\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The path of the parent element in the legal document.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":true,\"vectorizePropertyName\":false}},\"name\":\"parentPath\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The text content of the element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"content\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The title of the element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"title\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The name of the element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"name\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The name of the parent element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"parentName\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The outline of the element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"outline\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The type of the element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":true,\"vectorizePropertyName\":false}},\"name\":\"type\",\"tokenization\":\"word\"}],\"replicationConfig\":{\"factor\":1},\"shardingConfig\":{\"virtualPerPhysical\":128,\"desiredCount\":1,\"actualCount\":1,\"desiredVirtualCount\":128,\"actualVirtualCount\":128,\"key\":\"_id\",\"strategy\":\"hash\",\"function\":\"murmur3\"},\"vectorIndexConfig\":{\"skip\":false,\"cleanupIntervalSeconds\":300,\"maxConnections\":64,\"efConstruction\":128,\"ef\":-1,\"dynamicEfMin\":100,\"dynamicEfMax\":500,\"dynamicEfFactor\":8,\"vectorCacheMaxObjects\":1000000000000,\"flatSearchCutoff\":40000,\"distance\":\"cosine\",\"pq\":{\"enabled\":false,\"bitCompression\":false,\"segments\":0,\"centroids\":256,\"trainingLimit\":100000,\"encoder\":{\"type\":\"kmeans\",\"distribution\":\"log-normal\"}},\"bq\":{\"enabled\":false}},\"vectorIndexType\":\"hnsw\",\"vectorizer\":\"text2vec-openai\"}]}},\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"graphql_rebuild\",\"level\":\"debug\",\"msg\":\"successfully rebuild graphql schema\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"recount\",\"level\":\"info\",\"msg\":\"Recounting properties, this may take a while\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":80,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"raft\",\"id\":\"node1\",\"level\":\"debug\",\"msg\":\"raft voting for self\",\"term\":80,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"raft\",\"level\":\"debug\",\"msg\":\"raft calculated votes needed\",\"needed\":1,\"term\":80,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"raft\",\"from\":\"node1\",\"level\":\"debug\",\"msg\":\"raft vote granted\",\"tally\":1,\"term\":80,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":80,\"time\":\"2024-07-23T16:10:31Z\"}\n{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-07-23T16:10:31Z\"}\n{\"address\":\"192.168.176.3:8300\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-07-23T16:10:32Z\"}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-07-23T16:10:32Z\"}\n{\"action\":\"recount\",\"level\":\"warning\",\"msg\":\"Recounted 10236 objects. Recounting properties complete. Please remove environment variable \\tRECOUNT_PROPERTIES_AT_STARTUP before next startup\",\"time\":\"2024-07-23T16:10:34Z\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-07-23T16:10:34Z\"}\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8060\",\"time\":\"2024-07-23T16:10:34Z\"}\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:1ab20893-e398-4179-82d2-c33abd4f1375 Type:INIT Version:1.25.7 NumObjects:0 OS:linux Arch:amd64 UsedModules:[text2vec-openai]}\",\"time\":\"2024-07-23T16:10:34Z\"}\n{\"action\":\"restapi_request\",\"level\":\"debug\",\"method\":\"GET\",\"msg\":\"received HTTP request\",\"time\":\"2024-07-23T16:10:35Z\",\"url\":{\"Scheme\":\"\",\"Opaque\":\"\",\"User\":null,\"Host\":\"\",\"Path\":\"/v1/schema/Element\",\"RawPath\":\"\",\"OmitHost\":false,\"ForceQuery\":false,\"RawQuery\":\"\",\"Fragment\":\"\",\"RawFragment\":\"\"}}\n{\"level\":\"debug\",\"msg\":\"server.query\",\"time\":\"2024-07-23T16:10:35Z\",\"type\":1}\n{\"action\":\"restapi_request\",\"level\":\"debug\",\"method\":\"GET\",\"msg\":\"received HTTP request\",\"time\":\"2024-07-23T16:10:35Z\",\"url\":{\"Scheme\":\"\",\"Opaque\":\"\",\"User\":null,\"Host\":\"\",\"Path\":\"/v1/schema/Vector\",\"RawPath\":\"\",\"OmitHost\":false,\"ForceQuery\":false,\"RawQuery\":\"\",\"Fragment\":\"\",\"RawFragment\":\"\"}}\n{\"level\":\"debug\",\"msg\":\"server.query\",\"time\":\"2024-07-23T16:10:35Z\",\"type\":1}\n{\"action\":\"restapi_request\",\"level\":\"debug\",\"method\":\"POST\",\"msg\":\"received HTTP request\",\"time\":\"2024-07-23T16:10:35Z\",\"url\":{\"Scheme\":\"\",\"Opaque\":\"\",\"User\":null,\"Host\":\"\",\"Path\":\"/v1/schema\",\"RawPath\":\"\",\"OmitHost\":false,\"ForceQuery\":false,\"RawQuery\":\"\",\"Fragment\":\"\",\"RawFragment\":\"\"}}\n{\"class\":\"Vector\",\"level\":\"debug\",\"msg\":\"server.execute\",\"time\":\"2024-07-23T16:10:35Z\",\"type\":1}\n{\"level\":\"debug\",\"log_index\":83,\"log_name\":\"LogCommand\",\"log_type\":0,\"msg\":\"apply fsm store command\",\"time\":\"2024-07-23T16:10:35Z\"}\n{\"cmd_class\":\"Vector\",\"cmd_schema_only\":false,\"cmd_type\":1,\"cmd_type_name\":\"TYPE_ADD_CLASS\",\"level\":\"debug\",\"log_index\":83,\"log_name\":\"LogCommand\",\"log_type\":0,\"msg\":\"server.apply\",\"time\":\"2024-07-23T16:10:35Z\"}\n{\"action\":\"graphql_rebuild\",\"level\":\"debug\",\"msg\":\"rebuilding the graphql schema\",\"schema\":{\"Objects\":{\"classes\":[{\"class\":\"Element\",\"description\":\"An element of a legal document.\",\"invertedIndexConfig\":{\"bm25\":{\"b\":0.75,\"k1\":1.2},\"cleanupIntervalSeconds\":60,\"stopwords\":{\"additions\":null,\"preset\":\"en\",\"removals\":null}},\"moduleConfig\":{\"text2vec-openai\":{\"baseURL\":\"https://api.openai.com\",\"model\":\"text-embedding-3-small\",\"type\":\"text\",\"vectorizeClassName\":false}},\"multiTenancyConfig\":{\"autoTenantActivation\":false,\"autoTenantCreation\":false,\"enabled\":false},\"properties\":[{\"dataType\":[\"text\"],\"description\":\"The ID of the legal document this element belongs to.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":true,\"vectorizePropertyName\":false}},\"name\":\"document\",\"tokenization\":\"word\"},{\"dataType\":[\"int\"],\"description\":\"The order of the element within its parent element.\",\"indexFilterable\":true,\"indexSearchable\":false,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"order\"},{\"dataType\":[\"text\"],\"description\":\"The path of the element in the legal document.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":true,\"vectorizePropertyName\":false}},\"name\":\"path\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The path of the parent element in the legal document.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":true,\"vectorizePropertyName\":false}},\"name\":\"parentPath\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The text content of the element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"content\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The title of the element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"title\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The name of the element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"name\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The name of the parent element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"parentName\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The outline of the element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"outline\",\"tokenization\":\"word\"},{\"dataType\":[\"text\"],\"description\":\"The type of the element.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":true,\"vectorizePropertyName\":false}},\"name\":\"type\",\"tokenization\":\"word\"}],\"replicationConfig\":{\"factor\":1},\"shardingConfig\":{\"virtualPerPhysical\":128,\"desiredCount\":1,\"actualCount\":1,\"desiredVirtualCount\":128,\"actualVirtualCount\":128,\"key\":\"_id\",\"strategy\":\"hash\",\"function\":\"murmur3\"},\"vectorIndexConfig\":{\"skip\":false,\"cleanupIntervalSeconds\":300,\"maxConnections\":64,\"efConstruction\":128,\"ef\":-1,\"dynamicEfMin\":100,\"dynamicEfMax\":500,\"dynamicEfFactor\":8,\"vectorCacheMaxObjects\":1000000000000,\"flatSearchCutoff\":40000,\"distance\":\"cosine\",\"pq\":{\"enabled\":false,\"bitCompression\":false,\"segments\":0,\"centroids\":256,\"trainingLimit\":100000,\"encoder\":{\"type\":\"kmeans\",\"distribution\":\"log-normal\"}},\"bq\":{\"enabled\":false}},\"vectorIndexType\":\"hnsw\",\"vectorizer\":\"text2vec-openai\"},{\"class\":\"Vector\",\"description\":\"A vector of a string.\",\"invertedIndexConfig\":{\"bm25\":{\"b\":0.75,\"k1\":1.2},\"cleanupIntervalSeconds\":60,\"stopwords\":{\"additions\":null,\"preset\":\"en\",\"removals\":null}},\"moduleConfig\":{\"text2vec-openai\":{\"baseURL\":\"https://api.openai.com\",\"model\":\"text-embedding-3-small\",\"type\":\"text\",\"vectorizeClassName\":false}},\"multiTenancyConfig\":{\"autoTenantActivation\":false,\"autoTenantCreation\":false,\"enabled\":false},\"properties\":[{\"dataType\":[\"text\"],\"description\":\"The content value of the string.\",\"indexFilterable\":true,\"indexSearchable\":true,\"moduleConfig\":{\"text2vec-openai\":{\"skip\":false,\"vectorizePropertyName\":false}},\"name\":\"value\",\"tokenization\":\"word\"}],\"replicationConfig\":{\"factor\":1},\"shardingConfig\":{\"virtualPerPhysical\":128,\"desiredCount\":1,\"actualCount\":1,\"desiredVirtualCount\":128,\"actualVirtualCount\":128,\"key\":\"_id\",\"strategy\":\"hash\",\"function\":\"murmur3\"},\"vectorIndexConfig\":{\"skip\":false,\"cleanupIntervalSeconds\":300,\"maxConnections\":64,\"efConstruction\":128,\"ef\":-1,\"dynamicEfMin\":100,\"dynamicEfMax\":500,\"dynamicEfFactor\":8,\"vectorCacheMaxObjects\":1000000000000,\"flatSearchCutoff\":40000,\"distance\":\"cosine\",\"pq\":{\"enabled\":false,\"bitCompression\":false,\"segments\":0,\"centroids\":256,\"trainingLimit\":100000,\"encoder\":{\"type\":\"kmeans\",\"distribution\":\"log-normal\"}},\"bq\":{\"enabled\":false}},\"vectorIndexType\":\"hnsw\",\"vectorizer\":\"text2vec-openai\"}]}},\"time\":\"2024-07-23T16:10:35Z\"}\n{\"action\":\"graphql_rebuild\",\"level\":\"debug\",\"msg\":\"successfully rebuild graphql schema\",\"time\":\"2024-07-23T16:10:35Z\"}\n{\"level\":\"warning\",\"msg\":\"prop len tracker file /var/lib/weaviate/vector/LkXsmhPzfkEj/proplengths does not exist, creating new tracker\",\"time\":\"2024-07-23T16:10:36Z\"}\n{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-07-23T16:10:36Z\",\"wait_for_cache_prefill\":false}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"shard=LkXsmhPzfkEj is ready\",\"time\":\"2024-07-23T16:10:36Z\"}\n{\"level\":\"info\",\"msg\":\"Created shard vector_LkXsmhPzfkEj in 1.241324ms\",\"time\":\"2024-07-23T16:10:36Z\"}\n{\"action\":\"load_all_shards\",\"level\":\"debug\",\"msg\":\"finished loading all shards\",\"time\":\"2024-07-23T16:10:36Z\",\"took\":\"1.00201509s\"}\n{\"action\":\"hnsw_vector_cache_prefill_level\",\"count\":0,\"hnsw_level\":0,\"index_id\":\"main\",\"level\":\"debug\",\"msg\":\"prefilled level in vector cache\",\"time\":\"2024-07-23T16:10:36Z\",\"took\":110475}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-07-23T16:10:36Z\",\"took\":159470}\n\n\nThe query example:\n{\n  Get {\n    Element(\n      nearText: {\n        concepts: [\"Does the contract specify the duration?\"],\n        moveTo: {\n          concepts: [\"duration of the contract\",\"this document validity has a duration of\"],\n          force: 0.63\n        },\n        certainty: 0.689\n      },\n      where: {\n        path: [\"document\"],\n        operator: Equal,\n        valueText: \"absdef-16354621354\"\n      },\n      autocut: 3,\n      limit: 15,\n    ) {\n      content,\n      title,\n      name,\n      outline,\n      path,\n      parentPath,\n      parentName,\n      document,\n      order,\n      type,\n      _additional {\n        id,\n        certainty\n      }\n    }\n  }\n}\n\nThe errors appear at about 5% of queries\nIs there any way to point me into the right direction to debug this thing?\n\n----------\n\n[DudaNogueira (2024-07-24T13:11:08.160Z)]: hi @SergeLiatko !!\nWelcome to our community  !!\nLogs point to something on OpenAi side while vectorizing the moveTo.\nThe error appearing on 5% of the queries too, as this may be a load balancer delivering that request to a faulty node.\nI am afraid there isn’t much we can do from Weaviate’s perspective. \nOne thing to explore is if Azure OpenAi can get you better results.\nLet me know if this helps\nThanks!\n\n----------\n\n[SergeLiatko (2024-07-24T14:57:00.345Z)]: @DudaNogueira\nHi, thanks for the update. I’ve spent a week fighting with this and finally ended up with a custom retry strategy for this (at least in 1-3 extra attempts the vectorization works).\nIf the delays will pose a problem in the future, I’ll move to your cloud services (already using it in another project, never had issues)\nThank you for your help.\n\n----------\n\n[DudaNogueira (2024-07-24T21:05:41.176Z)]: Great! Thanks for using Weaviate",
    "date_created": "2024-07-24T08:34:42.569Z",
    "has_accepted_answer": true,
    "title": "Random SSL/TLS Errors while vectorizing strings inside docker container",
    "topic_id": 3148
  },
  {
    "user_id": 1630,
    "conversation": "[Sik819 (2024-11-27T08:52:40.648Z)]: Hi Weaviate Community,\nI am currently working with the multi2vec-clip module to perform hybrid text+image searches.\nI have a class called Dog that includes the following properties:\n\nbreed\ncolor\ndescription\nA one-to-many cross-reference to a collection called Image.\n\nThe Image class has an encodedImage property that stores the blob data of the image.\nNow,\n\n\nHow can I perform a hybrid search that includes the breed, color, and description properties from the Dog class and the cross-referenced encodedImage property from the Image class?\n\n\nCan a search be performed directly on cross-referenced properties, or would it have been better to store the encodedImage property within the Dog class itself?\n\n\nBelow is the code so far:\n\n    var hybridSearch *graphql.HybridArgumentBuilder\n    var nearImage *graphql.NearImageArgumentBuilder\n\n\n    textQuery := searchQuery.Breed + \" \" + searchQuery.Color + \" \" + searchQuery.Description\n\n    // handle image input searches\n    if searchQuery.Image != nil && searchQuery.Image.EncodedImage != nil {\n        // Base64 encode the image\n        encodedImage := base64.StdEncoding.EncodeToString(searchQuery.Image.EncodedImage)\n\n        nearImage = db.Client.GraphQL().NearImageArgBuilder().\n            WithImage(encodedImage).\n            WithDistance(0.7)\n    }\n\n\n    hybridSearch = db.Client.GraphQL().HybridArgumentBuilder().\n        WithQuery(textQuery).\n        WithAlpha(0.5) \n\n    // GraphQL query\n    fields := []graphql.Field{\n        {Name: \"breed\"},\n        {Name: \"color\"},\n        {Name: \"description\"},\n        {Name: \"_additional\", Fields: []graphql.Field{\n            {Name: \"certainty\"},\n        }},\n        {Name: \"images\", Fields: []graphql.Field{\n            {Name: \"encodedImage\"},\n        }},\n    }\n\n    result, err := db.Client.GraphQL().Get().\n        WithClassName(\"Dog\"). // Search can only be done on Dog? How about its cross referenced Image collection?\n        WithNearImage(nearImage).\n        WithHybrid(hybridSearch).\n        WithFields(fields...).\n        Do(context.Background())\n\n----------\n\n[sebawita (2024-11-27T14:08:57.757Z)]: Hi @Sik819, welcome to the community.\n\n\n\n Sik819:\n\nHow can I perform a hybrid search that includes the breed, color, and description properties from the Dog class and the cross-referenced encodedImage property from the Image class?\n\n\nUnfortunately, you can’t query two separate collections with a single query.\nCross references allow you to pull referenced data from another collection, but the query elements (both for vector and keyword search) happens on the queried collection.\n\n\n\n Sik819:\n\nCan a search be performed directly on cross-referenced properties, or would it have been better to store the encodedImage property within the Dog class itself?\n\n\nNo, and yes. You need to bring both the image and the other properties into the same class.\nSide note\nBtw. clip allows you to vectorize text (i.e. breed, color) and images.\nMeaning your vector queries will work across the concepts in both text and image properties.\nHowever, please note that Clip is not as powerful when it comes to text search, as you would expect from other embedding models that are specialised on working with text.\nIt might still work for what you need it to be, but there might be limitations\n\n----------\n\n[Sik819 (2024-12-05T20:03:03.589Z)]: Thanks, @sebawita!\n\n\n\n sebawita:\n\nNo, and yes. You need to bring both the image and the other properties into the same class.\n\n\nI tried bringing the encodedImage property into the Dog class, but it seems arrays for base64 blob properties aren’t supported. Is there any alternative way to store multiple images within the same class?\n\n\n\n sebawita:\n\nHowever, please note that Clip is not as powerful when it comes to text search, as you would expect from other embedding models that are specialised on working with text.\n\n\nGiven the limitations with CLIP and the challenge of storing multiple images (if no workaround is available), would it make more sense to perform two separate searches—one for text and one for images—and then manually combine and analyze the results?\n\n----------\n\n[sebawita (2024-12-06T17:31:27.108Z)]: Sik819:\n\n\n\n\n sebawita:\n\nNo, and yes. You need to bring both the image and the other properties into the same class.\n\n\nI tried bringing the encodedImage property into the Dog class, but it seems arrays for base64 blob properties aren’t supported. Is there any alternative way to store multiple images within the same class?\n\n\nYou are correct, you can’t provide an array of images.\n(warning! I haven’t tried this, so this might not work  )\nHowever, you could use a trick to map images to multiple properties. Like this:\nclient.collections.create(\n    name=\"MyCollection\",\n    vectorizer_config=Configure.Vectorizer.multi2vec_clip(\n        text_fields=[\"text\"],\n        image_fields=[\"image1\", \"image2\", \"image3\"],\n    ),\n    properties=[\n        Property(name=\"text\", data_type=DataType.TEXT),\n        Property(name=\"image1\", data_type=DataType.BLOB),\n        Property(name=\"image2\", data_type=DataType.BLOB),\n        Property(name=\"image3\", data_type=DataType.BLOB)\n    ]\n)\n\nThen, when you insert an object, you can move the base64 images from the array to each property.\nNote, with this approach, you will get one vector embedding that is an average of all images.\nIf you need a separate vector embedding per image, then you need to use named vectors:\nclient.collections.create(\n    name=\"MyCollection\",\n    vectorizer_config=[\n        Configure.NamedVectors.multi2vec_clip(\n            name=\"first_vector\",\n            text_fields=[\"text\"],\n            image_fields=[\"image1\"],\n        ),\n        Configure.NamedVectors.multi2vec_clip(\n            name=\"second_vector\",\n            text_fields=[\"text\"],\n            image_fields=[\"image2\"],\n        ),\n        # ...\n    ],\n    properties=[\n        Property(name=\"text\", data_type=DataType.TEXT),\n        Property(name=\"image1\", data_type=DataType.BLOB),\n        Property(name=\"image2\", data_type=DataType.BLOB),\n        Property(name=\"image3\", data_type=DataType.BLOB)\n    ]\n)\n\n\n\n\n Sik819:\n\nGiven the limitations with CLIP and the challenge of storing multiple images (if no workaround is available), would it make more sense to perform two separate searches—one for text and one for images—and then manually combine and analyze the results?\n\n\nYes, that could work. You could use the named vectors approach.\nThen, have one named-vector for your images and another named-vector for your text properties.",
    "date_created": "2024-11-27T08:52:40.600Z",
    "has_accepted_answer": false,
    "title": "[Docs] Image+text hybrid search on cross references",
    "topic_id": 8545
  },
  {
    "user_id": 1279,
    "conversation": "[Zhenghua_Liu (2024-10-09T01:48:30.513Z)]: \"I’m looking for a solution to set a global replication factor for vector indexes. The official documentation only mentions specifying this parameter when creating a vector index. I’m using an open-source software where vector indexes are created dynamically without specifying this parameter, and the database already has many vector indexes. Is there a way to add a global parameter and automatically replicate the existing vector indexes to match the desired replication factor?\nReplication Document\n\n----------\n\n[Zhenghua_Liu (2024-10-09T01:51:29.756Z)]: The request load isn’t heavy. Currently, there’s only a single node, which isn’t robust for production use. I’m looking for a way to ensure high availability for Weaviate, not focused on high throughput.\n\n----------\n\n[DudaNogueira (2024-10-10T07:15:28.748Z)]: hi @Zhenghua_Liu !!\nWelcome to our community \nThank you very much! I have just realized that we do indeed have this feature, however it was undocumented \nthe environment variable you want is:\nREPLICATION_MINIMUM_FACTOR \nOnce you set this for your cluster, it will always specify that value as the replication factor, unless you explicitly specify while creating a collection.\nI will work on adding this to our docs.\nThanks a lot for asking this\n\n----------\n\n[Zhenghua_Liu (2024-10-21T03:31:35.587Z)]: I really appreciate the clarification about REPLICATION_MINIMUM_FACTOR. I do have a follow-up question: If I set this value to 2 and then add a new Weaviate node to the cluster, will the existing collections automatically replicate to the new node?\n\n----------\n\n[DudaNogueira (2024-10-21T21:35:23.418Z)]: hi @Zhenghua_Liu !!\nIt will not. Only new collections or tenants.\nThis feature is in our roadmap, and we call it dynamic scaling. With it you will be able to move shards around, helping this kind of scenario or when you want for example to drain a note.\nLet me know if this helps!\nThanks!",
    "date_created": "2024-10-09T01:48:30.461Z",
    "has_accepted_answer": true,
    "title": "[Question] A way to set global replcation factor?",
    "topic_id": 4483
  },
  {
    "user_id": 1155,
    "conversation": "[pon_raj (2024-07-10T22:37:47.134Z)]: Hi,\nPlease help to arrive the right weaviate client v4 sytnax for the below v3 client query statement.\nV3 client query statement:\nclass_name = “Yoga”\nresponse = (\nclient.query\n.get(class_name, [“document”])\n.with_near_text({‘concepts’ : [“Mahayana Buddhism”]})\n.do()\n)\nprint(response[‘data’][‘Get’][class_name][0][‘document’])\n“Yoga” is the classification, and “document” is the property. I am trying to text match “Mahayana Buddhism”\nIt was working with v3 client but after v4 upgrade, I am unable to get the right query statement.\nHow do I get this working with v4 client?\nThanks.\n\n----------\n\n[Mohamed_Shahin (2024-07-11T10:27:10.492Z)]: Hi @pon_raj, I hope you having a nice day!\nTo perform near_text search with Python Client v4, please use:\n\nyoga = client.collections.get(“Yoga”)\nresponse = yoga.query.near_text(\nquery=“Mahayana Buddhism”,\nreturn_metadata=MetadataQuery(distance=True)\n)\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nVector similarity search | Weaviate - Vector Database\n\n  Vector search returns the objects with most similar vectors to that of the query.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI hope this helps, have a nice week!\n\n----------\n\n[pon_raj (2024-07-11T15:11:57.398Z)]: Thank you for the help with v4 syntax.  It works but response has objects no matter what I query. For an example, if I query non-existing text such as “abcaslkhas”, it returns objects.\nDo I need to add any additional attributes to the query so that it returns objects ony if the query string exists?\nThanks.\n\n----------\n\n[Mohamed_Shahin (2024-07-12T11:47:47.945Z)]: Happy Friday @pon_raj !\nSo the  Near Text  operator is to find objects with the nearest vector to an input text.\nIndeed you could insert some unrelated text and still retrieve an object because it vectorize the query input and it tries to find ‘ANN’ approximate nearest neighbor for vector-search queries.\nThe following operator can explain the distance in such search and shall return a far distance value:\n\n  _additional {\n    distance\n  }   \n\n\nSee here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAdditional properties (metadata) | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHowever from what I understood you are trying to achieve, then I would highly recommend you → Hybrid Search which is the key to your case because Hybrid search results can favor the keyword component, the vector component or mix of both.\n\nUse alpha operator of 1 is a pure vector search or;\nAn alpha of 0 is a pure keyword search or;\nPlay with the value to lean more towards keyword or vector component!\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate - Vector Database\n\n  Hybrid search combines the results of a vector search and a keyword (BM25F) search by fusing the two result sets.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI hope this helps\n\n----------\n\n[pon_raj (2024-07-15T12:05:33.863Z)]: Thank you for the helpful advice.",
    "date_created": "2024-07-10T22:37:47.087Z",
    "has_accepted_answer": true,
    "title": "Help to get the right syntax for query statement - from v3 client to v4 client",
    "topic_id": 3008
  },
  {
    "user_id": 1226,
    "conversation": "[swetag (2024-07-22T04:19:23.871Z)]: Hi,\n\nI batch uploaded around 20k objects and backed them up in s3, worked fine. I can see the backup json file and node1 folder in s3.\nMoments later I deleted all the data and then batch uploaded them again which worked fine but this time while creating backups I am seeing a lot of this messages in my logs:\n“HTTP Request: GET http://------:8080/v1/backups/s3/{backup_id}\"HTTP/1.1 200 OK\"”.\nwhen I see weaviate logs, there are alot of this kind of logging:\n“action”: “backup_status”;  “level”: “info”; “msg”: “”,\nbut before these logs I got following logs in my record (in sequence):\n\n“action”: “lsm_memtable_flush”;  “error”: “flush: unlinkat /var/lib/weaviate/test/{index_name}/w8G6ci6OWwEL/lsm/property__id/segment-1721615078510284041.scratch.d: directory not empty”\n\"“action”: “lsm_memtable_flush”;   “error”: “flush: unlinkat /var/lib/weaviate/test/{index_name}/w8G6ci6OWwEL/lsm/property_title_searchable/segment-1721615075238438328.scratch.d: directory not empty”\n“action”: “lsm_compaction”; “error”: “write index: unlinkat /var/lib/weaviate/test/{index_name}/w8G6ci6OWwEL/lsm/property_annotations_id_searchable/segment-1721615076605784103.dbcompaction.scratch.d: directory not empty”;\n“action”: “lsm_compaction”; “error”: “write index: clean up previous scratch space: unlinkat /var/lib/weaviate/test/{index_name}/w8G6ci6OWwEL/lsm/property_annotations_id_searchable/segment-1721615076605784103.dbcompaction.scratch.d/.nfs3f46fabddd01f71200000009: device or resource busy”,\n“action”: “lsm_compaction”; “error”: “write indices: unlinkat /var/lib/weaviate/test/{index_name}/w8G6ci6OWwEL/lsm/objects/segment-1721615326755105246.dbcompaction.scratch.d: directory not empty”\n“action”: “lsm_memtable_flush”; “error”: “flush: unlinkat /var/lib/weaviate/test/{index_name}/w8G6ci6OWwEL/lsm/property_collections/segment-1721615316392568869.scratch.d: directory not empty”,\n“action”: “lsm_memtable_flush”;  “error”: “flush: unlinkat /var/lib/weaviate/test/{index_name}/w8G6ci6OWwEL/lsm/property_url_searchable/segment-1721615317703263522.scratch.d: directory not empty”\nAfter around 15 mins (having same messages/logs) My server is timed out and restarted. So the backup never completed.\nServer Setup Information\n\nWeaviate Server Version: weaviate:1.25.6\nDeployment Method:  docker\nClient Language and Version: python 3.10.9, weaviate-client: 4.6.5\n\nEnvironment variables:\nQUERY_DEFAULTS_LIMIT: 25\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: ‘true’\nPERSISTENCE_DATA_PATH: ‘/var/lib/weaviate’\nDEFAULT_VECTORIZER_MODULE: ‘none’\nENABLE_MODULES: ‘backup-filesystem,backup-s3’\nCLUSTER_HOSTNAME: ‘node1’\nQUERY_MAXIMUM_RESULTS: 1000000\nDISK_USE_READONLY_PERCENTAGE: 100\nDISABLE_TELEMETRY: true\nDISABLE_LAZY_LOAD_SHARDS: true\nCould you please guide me in how to resolve this issue? TIA.\n\n----------\n\n[DudaNogueira (2024-07-23T21:44:23.363Z)]: hi @swetag !!\nWelcome to our community \nNice! This looks like one of our chaos pipelines \nHow have you deleted those objects in step 2?\nWhen you delete the entire collection, it’s simpler, as no object deletion calculation is needed.\nIf you delete the objects itself, it will generate tombstones, and then a whole new cycle is triggered.\nThis seems related to this issue:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Backup gets stuck and Weaviate as well\n    \n\n    \n      \n        opened 11:38AM - 26 Jun 24 UTC\n      \n\n\n      \n        \n          \n          phlegx\n        \n      \n    \n\n    \n        \n          bug\n        \n    \n  \n\n\n  \n    ### How to reproduce this bug?\n\nInstall Weaviate in version 1.25.5 with latest… Helm chart on a bare metal cluster as a single instance and run the backup script below and the weaviate helm settings also see below.\n\n### What is the expected behavior?\n\nBackup should not be stuck in state STARTED forever,.\n\n### What is the actual behavior?\n\nOn our very small data (roughly 7k objects) in one of our Weaviate test instances, the Backup seems to get stuck for hours. We experience this in a single test instance, as well as also in our cluster test instance.\n\nAfter starting the backup and noticing that it is never finishing, in Weaviate we get this continuous output, as we check every 10 seconds for the status\n\n\n```\n│ 2024-06-26T07:54:43.157558168Z weaviate {\"action\":\"backup_status\",\"backend\":\"backup-s3\",\"backup_id\":\"2024-06-26_01-00-14\",\"level\":\" │\n│ info\",\"msg\":\"\",\"time\":\"2024-06-26T07:54:43Z\",\"took\":31544}                                                                          │\n│ 2024-06-26T07:54:53.185646557Z weaviate {\"action\":\"backup_status\",\"backend\":\"backup-s3\",\"backup_id\":\"2024-06-26_01-00-14\",\"level\":\" │\n│ info\",\"msg\":\"\",\"time\":\"2024-06-26T07:54:53Z\",\"took\":25112}                                                                          │\n│ 2024-06-26T07:55:03.224599217Z weaviate {\"action\":\"backup_status\",\"backend\":\"backup-s3\",\"backup_id\":\"2024-06-26_01-00-14\",\"level\":\" │\n│ info\",\"msg\":\"\",\"time\":\"2024-06-26T07:55:03Z\",\"took\":23890}                                                                          │\n│ 2024-06-26T07:55:13.258652773Z weaviate {\"action\":\"backup_status\",\"backend\":\"backup-s3\",\"backup_id\":\"2024-06-26_01-00-14\",\"level\":\" │\n│ info\",\"msg\":\"\",\"time\":\"2024-06-26T07:55:13Z\",\"took\":25426}                                                                          │\n│ 2024-06-26T07:55:23.290172417Z weaviate {\"action\":\"backup_status\",\"backend\":\"backup-s3\",\"backup_id\":\"2024-06-26_01-00-14\",\"level\":\" │\n│ info\",\"msg\":\"\",\"time\":\"2024-06-26T07:55:23Z\",\"took\":22835}                                                                          │\n│ 2024-06-26T07:55:33.332576022Z weaviate {\"action\":\"backup_status\",\"backend\":\"backup-s3\",\"backup_id\":\"2024-06-26_01-00-14\",\"level\":\" │\n│ info\",\"msg\":\"\",\"time\":\"2024-06-26T07:55:33Z\",\"took\":25835}\n```\n\nManually checking with curl what the status of the backup is indeed still shows us the Backup is stuck in state STARTED:\n\n```\ncurl --silent --fail --show-error -H 'Content-Type: application/json' -H \"Authorization: Bearer $AUTHENTICATION_APIKEY_ALLOWED_KEYS\n\" \"http://weaviate.weaviate.svc.cluster.local/v1/backups/backup-s3/2024-06-26_01-00-14\"\n```\n\n`{\"backend\":\"backup-s3\",\"id\":\"2024-06-26_01-00-14\",\"path\":\"s3://xxxxx-weaviate-backups/staging/2024-06-26_01-00-14\",\"status\":\"STARTED\"}`\n\nI then stop/delete the kubernetes cronjob resp. job and restart it. The curl command that executes the job then gives back 422 error:\n\n`curl: (22) The requested URL returned error: 422`\n\nOn weaviate side in the logs we get this info:\n                                                                          │\n```\n│ 2024-06-26T07:57:17.896867926Z weaviate {\"action\":\"try_backup\",\"backend\":\"s3\",\"backup_id\":\"2024-06-26_07-57-12\",\"level\":\"error\",\"ms │\n│ g\":\"backup 2024-06-26_01-00-14 already in progress\",\"time\":\"2024-06-26T07:57:17Z\",\"took\":128102813}    \n\n```\n\nAfter restarting Weaviate the backup seems to be  again working and it is fast as well (SEEMS NOT TO BE THE CASE IN LATEST 1.25.5, there it gets stuck immediately again). However after some time we see the same behaviour. Then again only a restart of weaviate is helping.\n\n\n\n### Supporting information\n\n\nBackup script\n\n```\n    # Prerequisites\n    backup_id=$(date +%Y-%m-%d_%H-%M-%S)\n    KEEP_BACKUPS_COUNT=\"${KEEP_BACKUPS_COUNT:=10}\"\n\n    # Backup\n    json=$(printf '{ \"id\": \"%s\" }' \"$backup_id\")\n\n    curl --silent --fail --show-error -X POST \\\n        -H 'Content-Type: application/json' \\\n        -H \"Authorization: Bearer $API_KEY\" \\\n        \"http://weaviate.weaviate.svc.cluster.local/v1/backups/s3\" -d \"$json\"\n\n    state=\"\"\n\n    printf \"Waiting for backup to finish\"\n    while [[ \"$state\" != \"SUCCESS\" ]]; do\n        sleep 10\n        printf \".\"\n        state=$(curl --silent --fail --show-error -H 'Content-Type: application/json' -H \"Authorization: Bearer $API_KEY\" \"http://weaviate.weaviate.svc.cluster.local/v1/backups/backup-s3/$backup_id\" | jq -r \".status\")\n        if [[ \"$state\" == \"FAILED\" ]]; then\n            echo \"Backup failed\"\n            exit 1\n        fi\n\n    done\n    printf \"\\n\"\n```\n\nHelm Config:\n\n```\nbackups:\n  s3:\n    enabled: true\n    envconfig:\n      BACKUP_S3_BUCKET: xxxxx-weaviate-backups\n      AWS_REGION: eu-central-1\n\nauthentication:\n  anonymous_access:\n    enabled: false\n  oidc:\n    enabled: false\n\nauthorization:\n  admin_list:\n    enabled: false\n    users:\n    %{~ for user in admin_users ~}\n    - ${user}\n    %{ endfor }\n    read_only_users:\n    %{~ for user in readonly_users ~}\n    - ${user}\n    %{ endfor }\n\n# NOTE: 524288 is default value on Weaviate. Elasticsearch value is 262144\n# So for now we can simply set the value to 524288 on both sides.\n# Setting this here even if default value is used to make sure it is and known.\ninitContainers:\n  sysctlInitContainer:\n    enabled: true\n    sysctVmMaxMapCount: 524288\n\naffinity:\n  nodeAffinity:\n    requiredDuringSchedulingIgnoredDuringExecution:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: deploy/weaviate\n          operator: In\n          values:\n          - \"true\"\n\nenv:\n  ##########################\n  # API Keys with ENV Vars #\n  ##########################\n  # If using ENV Vars to set up API Keys make sure to have `authentication.apikey` block commented out\n  # to avoid any future changes. ENV Vars has priority over the config above `authentication.apikey`.\n  # If using `authentication.apikey `the below ENV Vars will be used because they have priority,\n  # so comment them out to avoid any future changes.\n  # Enables API key authentication. If it is set to 'false' the AUTHENTICATION_APIKEY_ALLOWED_KEYS\n  # and AUTHENTICATION_APIKEY_USERS will not have any effect.\n  AUTHENTICATION_APIKEY_ENABLED: 'true'\n\n  # Expose metrics on port 2112 for Prometheus to scrape\n  PROMETHEUS_MONITORING_ENABLED: true\n\n  # List one or more keys, separated by commas. Each key corresponds to a specific user identity below.\n  # If you want to use a kubernetes secret for the API Keys comment out this Variable and use the one in `envSecrets` below\n  # AUTHENTICATION_APIKEY_ALLOWED_KEYS: 'jane-secret-key,ian-secret-key'  (plain text)\n\n  # List one or more user identities, separated by commas. You can have only one User for all the keys or one user per key.\n  # The User/s can be a simple name or an email, no matter if it exists or not.\n  # NOTE: Make sure to add the users to the authorization above overwise they will not be allowed to interact with Weaviate.\n  # AUTHENTICATION_APIKEY_USERS: ''\n\n  LOG_LEVEL: info\n\nenvSecrets:\n  # create a Kubernetes secret with AUTHENTICATION_APIKEY_ALLOWED_KEYS key and its respective value\n  # NOTE: set from set block in main.tf\n  AUTHENTICATION_APIKEY_ALLOWED_KEYS: weaviate\n\nservice:\n  type: ClusterIP\n\ngrpcService:\n  enabled: false\n\nresources:\n  requests:\n    cpu: 1m\n    memory: 100Mi\n  limits:\n    memory: ${memory}Gi\n\nannotations:\n  ad.datadoghq.com/weaviate.checks: |\n    {\n      \"weaviate\": {\n        \"init_config\": {},\n        \"instances\": [\n          {\n            \"openmetrics_endpoint\": \"http://%%host%%:2112/metrics\",\n            \"weaviate_api_endpoint\": \"http://%%host%%:8080\",\n            \"headers\": {\"Authorization\": \"Bearer ${api_key}\"}\n          }\n        ]\n      }\n    }\n\n\n```\n\n\n\n### Server Version\n\n1.25.5\n\n### Code of Conduct\n\n- [X] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nCan you confirm this issue persists in 1.25.8?\nThanks!\n\n----------\n\n[swetag (2024-07-24T06:21:18.904Z)]: Hey @DudaNogueira , thanks for your response.\n\nI catch the uuids of the objects by running a conditional search operation and in this scenario the uuid of all the objects(around 27k) are returned but this need not be the case always. So i can not delete the collection and have to delete the objects only. Anyway, after that I run delete operation with this code:\n\ncollection.data.delete_many(where=Filter.by_id().contains_any(uuids_batch))\nwhere each batch has 5k uuids. and this code is inside a for loop over all the uuid batches.\nAfter around 5 sec, the function returns from the delete operation and starts the indexing.\n\nThe issue persists in 1.25.8 as well.\n\nWhat should I do to resolve this issue?",
    "date_created": "2024-07-22T04:19:23.810Z",
    "has_accepted_answer": false,
    "title": "Weaviate not backing up for a long time",
    "topic_id": 3116
  },
  {
    "user_id": 807,
    "conversation": "[adithya.ch (2024-04-22T03:32:17.320Z)]: Hi Team,\nSeeing below error when we try to upgrade weaviate cluster(changing the image tag version) or perform scaling(changing the replicas value).\n{\"deprecation\":{\"apiType\":\"Configuration\",\"id\":\"config-files\",\"locations\":[\"--config-file=\\\"\\\"\"],\"mitigation\":\"Configure Weaviate using environment variables.\",\"msg\":\"use of deprecated command line argument --config-file\",\"sinceTime\":\"2020-09-08T09:46:00.000Z\",\"sinceVersion\":\"0.22.16\",\"status\":\"deprecated\"},\"level\":\"warning\",\"msg\":\"use of deprecated command line argument --config-file\",\"time\":\"2024-04-22T03:18:12Z\"}\n{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-04-22T03:18:12Z\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-04-22T03:18:12Z\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-04-22T03:18:12Z\"}\n{\"action\":\"broadcast_abort_transaction\",\"error\":\"host \\\"****:7001\\\": unexpected status code 401: \",\"id\":\"97fec38d-b981-40db-a038-7b70e72595f0\",\"level\":\"error\",\"msg\":\"broadcast tx abort failed\",\"time\":\"2024-04-22T03:18:12Z\"}\n{\"action\":\"startup\",\"error\":\"could not load or initialize schema: sync schema with other nodes in the cluster: read schema: open transaction: broadcast open transaction: host \\\"****:7001\\\": unexpected status code 401 ()\",\"level\":\"fatal\",\"msg\":\"could not initialize schema manager\",\"time\":\"2024-04-22T03:18:12Z\"}\n\nNew controller is getting created automatically and trying to perform the operation in rolling fashion.\nBut pods doesn’t come up because of above errors.\nNote ***\nWhen i completely delete the Statefulset, weaviate scaling or upgrade  works fine !! But we are looking for rolling update. Let me know if any changes to values.yaml to be done .\nRegards,\nAdithya\n\n----------\n\n[DudaNogueira (2024-04-22T12:43:11.520Z)]: hi @adithya.ch ! I have changed the category of this thread to Support\nThis happens both when you upgrade and try to scale? No sure I understood this part.\nCan you reproduce this on a test environment?\nWhat versions are you upgrading from and to?\nI assume you are just change the version or the replicas in the values of our helm chart, right?\nLet me know those info so we figure this out.\nThanks!\n\n----------\n\n[adithya.ch (2024-04-22T13:10:18.532Z)]: Hello @DudaNogueira\nyes, we are seeing the same error while we upgrade or while we try to scale.\nWe just changed the image tag version from 1.24.3 to 1.24.10 for upgrade. and replicas parameter from 3 to 5 for scaling.\nI am testing all the above actions in test k8s cluster.\nError\nBack-off restarting failed container weaviate in pod weaviate-5_vector(a4619704-4d70-4951-9afc-995601ad0045)\n{\"action\":\"broadcast_abort_transaction\",\"error\":\"host \\\"10.36.6.100:7001\\\": unexpected status code 401: \",\"id\":\"6b95cb70-2d84-45c3-acd7-bfd6a17c3b55\",\"level\":\"error\",\"msg\":\"broadcast tx abort failed\",\"time\":\"2024-04-22T13:08:48Z\"}\n{\"action\":\"startup\",\"error\":\"could not load or initialize schema: sync schema with other nodes in the cluster: read schema: open transaction: broadcast open transaction: host \\\"*****:7001\\\": unexpected status code 401 ()\",\"level\":\"fatal\",\"msg\":\"could not initialize schema manager\",\"time\":\"2024-04-22T13:08:48Z\"}\nRegards,\nAdithya\n\n----------\n\n[adithya.ch (2024-04-22T13:32:04.000Z)]: Also node status doesn’t show the newly added nodes.\n\n\n\nnodes_status = client.cluster.get_nodes_status()\nprint(nodes_status)\n[{‘batchStats’: {‘queueLength’: 0, ‘ratePerSecond’: 0}, ‘gitHash’: ‘86660ba’, ‘name’: ‘weaviate-0’, ‘shards’: None, ‘status’: ‘HEALTHY’, ‘version’: ‘1.24.10’}, {‘batchStats’: {‘queueLength’: 0, ‘ratePerSecond’: 0}, ‘gitHash’: ‘86660ba’, ‘name’: ‘weaviate-1’, ‘shards’: None, ‘status’: ‘HEALTHY’, ‘version’: ‘1.24.10’}, {‘batchStats’: {‘queueLength’: 0, ‘ratePerSecond’: 0}, ‘gitHash’: ‘86660ba’, ‘name’: ‘weaviate-2’, ‘shards’: None, ‘status’: ‘HEALTHY’, ‘version’: ‘1.24.10’}, {‘batchStats’: {‘queueLength’: 0, ‘ratePerSecond’: 0}, ‘gitHash’: ‘86660ba’, ‘name’: ‘weaviate-3’, ‘shards’: None, ‘status’: ‘HEALTHY’, ‘version’: ‘1.24.10’}, {‘batchStats’: {‘queueLength’: 0, ‘ratePerSecond’: 0}, ‘gitHash’: ‘86660ba’, ‘name’: ‘weaviate-4’, ‘shards’: None, ‘status’: ‘HEALTHY’, ‘version’: ‘1.24.10’}]\n\n\n\nHere i have changed replicas from 5 to 7\nIdeally weaviate-5 and weaviate-6 should be showing unhealthy from the above command.\nRegards,\nAdithya\n\n----------\n\n[adithya.ch (2024-04-23T16:23:36.818Z)]: Hello @DudaNogueira\nAny suggestions on how to fix the issue. I see multiple old posts with same error nut don’t see the solution.\nRegards,\nAdithya\n\n----------\n\n[adithya.ch (2024-04-24T19:51:28.084Z)]: Hi @DudaNogueira , Let me know if there us any update on the above mentioned issue\nThank you\n\n----------\n\n[DudaNogueira (2024-04-29T16:54:00.446Z)]: hi @adithya.ch !\nDoes it persist?\nNot sure how to fix this.\nCan you provide some step by step to reproduce? Then I can try to achieve this situation myself and explore more.\nThanks!\n\n----------\n\n[adithya.ch (2024-04-29T19:00:40.010Z)]: Hello @DudaNogueira\nYes, still the issue exists.\nIt’s similar to Rolling Update Not Working\nWe use ArgoCD to deploy the resouces in Openshift cluster and we deployed using helm chart after changing the variables in the values.yaml file for vertical/horizontal scaling.\n\nDownloaded the helm chart (templates / chart.yaml / values.yaml)\n\nin gitops config\ntargetRevision: develop\napplicationConfig:\npath: vector-rcdn\nname: vector-rcdn\nnamespace: vector\nhelm:\nvalueFiles:\n- values.yaml\nreleaseName: weaviate-helm-rcdn\nbased on this config ArgoCD deploying the code changes to k8s cluster.\nChanged the value of replicas for horizontal scaling.\nAttached the list of steps with errors.\nimage1192×1480 129 KB\nimage1192×1306 202 KB\nimage1192×1434 149 KB\nimage1192×602 37.8 KB\nRegards,\nAdithya\n\n----------\n\n[andrii (2024-08-28T08:56:26.613Z)]: Hey @adithya.ch , @DudaNogueira !\nNot sure I can add any new context to this issue, but basically having the exact same problem, also using ArgoCD and Weaviate Helm chart and rolling update enabled.\nWhen I do any change to the helm chart values that triggers new deployment, weaviate goes into infinite crashloop. It can only recover with manual intervention - killing all (2 in my case) weaviate pods manually helps.\nDid anyone manage to solve this?\nBest regards,\nAndrii\n\n----------\n\n[DudaNogueira (2024-08-28T20:34:39.376Z)]: hi @andrii !\nIs this a new deployment using the helm chart or a migrated from before 1.25 one?\nThere is some changes that is about this:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\n1.25 (For Kubernetes users) | Weaviate\n\n  Assumptions & requirements\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.\n\n----------\n\n[andrii (2024-09-02T10:05:29.431Z)]: Thanks @DudaNogueira !\nI have updated to weaviate 1.26.3 and chart version 17.1.1, increased the replicas to 3.\nI am still having an issue with multiple replicas. Here is an example:\nI have weaviate-0 (leader), weaviate-1 and weaviate-2 (followers) pods.\nWhen kubernetes kills weaviate-2 to move to another node, weaviate-2 fails to join the cluster. I am seeing this in the leader’s logs:\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"could not resolve server id weaviate-2\",\"fallback\":\"10.0.174.130:8300\",\"id\":\"weaviate-2\",\"level\":\"warning\",\"msg\":\"raft-net unable to get address for server, using fallback address\",\"time\":\"2024-09-02T09:57:46Z\"}\n{\"action\":\"raft\",\"backoff time\":500000000,\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"dial tcp 10.0.173.129:8300: connect: connection refused\",\"level\":\"error\",\"msg\":\"raft failed to heartbeat to\",\"peer\":\"10.0.174.130:8300\",\"time\":\"2024-09-02T09:59:35Z\"}\n\nThis can be resolved by deleting and recreating the stateful set.\nAppreciate any feedback\nBest regards\n\n----------\n\n[andrii (2024-09-02T11:07:13.832Z)]: Here is the list of RAFT_ and CLUSTER_ related env variables that the chart set for the stateful set, is there anything missing that I need to add manually?\n\n            - name: CLUSTER_DATA_BIND_PORT\n              value: '7001'\n            - name: CLUSTER_GOSSIP_BIND_PORT\n              value: '7000'\n            - name: RAFT_JOIN\n              value: 'weaviate-0,weaviate-1,weaviate-2'\n            - name: RAFT_BOOTSTRAP_EXPECT\n              value: '3'\n            - name: CLUSTER_JOIN\n              value: weaviate-headless.flux-k8s.svc.cluster.local.\n\n----------\n\n[DudaNogueira (2024-09-02T14:04:06.821Z)]: andrii:\n\n10.0.173.129\n\n\nHi! His this ip actually pointing to a node?\nIt seems it is not able to connect to that\n\n----------\n\n[andrii (2024-09-05T09:26:51.086Z)]: Hey @DudaNogueira,\nSorry for going silent, and thank you for your assistance. At the risk of sounding a bit ridiculous, I can no longer reproduce the issue. I’m not sure why it happened in the first place or why it stopped, but everything seems fine now.\n\n----------\n\n[DudaNogueira (2024-09-05T13:30:46.175Z)]: Oh, glad to hear that, @andrii !!\nIn case you run at any other issues, we’ll be here to help you \nThanks!\n\n----------\n\n[andrii (2024-09-05T17:27:41.456Z)]: There is now what looks like a different issue, caused by the same process of  replacing one pod out of the cluster.\nStill same setup: 3 replicas, collection has a replication factor of 3 and async replication enabled. When pod weaviate-1 got replaced, it now has this message in logs:\n{\"action\":\"async_replication\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"class_name\":\"AndriiTest\",\"hashbeat_iteration\":51,\"level\":\"warning\",\"msg\":\"hashbeat iteration failed: collecting differences: \\\"10.0.198.209:7001\\\": status code: 401, error: \",\"shard_name\":\"554JMVbS6e2m\",\"time\":\"2024-09-05T17:25:51Z\"}\n\n\nWhen I try to call v1/cluster/statistics endpoint I am getting this error back:\n{\n    \"error\": [\n        {\n            \"message\": \"node: weaviate-1: unexpected status code 401 ()\"\n        }\n    ]\n}\n\nRestarting the ReplicaSet helps, but it seems to not be able to recover on its own",
    "date_created": "2024-04-22T03:32:17.255Z",
    "has_accepted_answer": false,
    "title": "Horizontal Scaling or Upgrade issue - Weaviate cluster",
    "topic_id": 2081
  },
  {
    "user_id": 2560,
    "conversation": "[Guillaume (2024-11-21T10:32:21.515Z)]: Description\nHello,\nWe are using a Weaviate instance 1.26.3 in an Azure Container App and connected to an NFS Azure file share for persistence. It contains almost 1M elements.\nWe got errors trying to restore different backups (around 7GB) on the instance like this one :\n{\"msg\":\"failed to load shard: Unable to load shard TKgQUlWgvhID: init prop \\\"doc_author\\\": null index: init disk segments: init segment segment-1730278936414135887.db: mmap file: invalid argument\",\"shard_name\":\"TKgQUlWgvhID\"}\n\nAs I understood, it seems there are some corrupted files in our data.\nI researched errors in Azure logs and I found some errors occured during the day like this one which seems to be linked to the backup restore error :\n{\"action\":\"lsm_memtable_flush\",\"error\":\"flush: unlinkat /var/lib/weaviate/<indexName>/TKgQUlWgvhID/lsm/property_doc_author_nullState/segment-1730278936414135887.scratch.d: directory not empty\",\"index\":\"<indexName>\",\"level\":\"error\",\"msg\":\"flush and switch failed\",\"path\":\"/var/lib/weaviate/<indexName>/TKgQUlWgvhID/lsm/property_doc_author_nullState\",\"shard\":\"TKgQUlWgvhID\"}\n\nWe got also other “lsm_memtable_flush” errors on other properties and also “lsm_compaction” errors like this one :\n{\"action\":\"lsm_compaction\",\"error\":\"write index: unlinkat /var/lib/weaviate/<indexName>/TKgQUlWgvhID/lsm/property_scope_value_searchable/segment-1730280309487972970.dbcompaction.scratch.d: directory not empty\",\"index\":\"<indexName>\",\"level\":\"error\",\"msg\":\"compaction failed\",\"path\":\"/var/lib/weaviate/<indexName>/TKgQUlWgvhID/lsm/property_scope_value_searchable\",\"shard\":\"TKgQUlWgvhID\"}\n\nIt seems to me that Weaviate tried to perform maintenance operation like delete some files, failed and corrupted these files.\nDid someone already encountered these errors and know how to resolve them ?\nServer Setup Information\n\nWeaviate Server Version: 1.26.3\nDeployment Method: docker\nMulti Node? No   Number of Running Nodes: 1\nClient Language and Version:\nMultitenancy?: No\n\n----------\n\n[DudaNogueira (2024-11-26T20:31:55.249Z)]: hi @Guillaume !!\nAre you trying to restore to the same version?\n\n----------\n\n[Guillaume (2024-11-27T10:29:00.815Z)]: Hi @DudaNogueira,\nBackups comes from a weaviate 1.26.3.\nWe have two environments, one with weaviate 1.26.3, one with weaviate 1.26.6.\nBackup from October 29th restores correctly on both environments.\nBackups from October 30th and later fail on restore on both environments.\nI made a new try to restore the backup from October 30th on environment using weaviate 1.26.3 to be sure and I got this error :\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"init shard \\\"<indexName>_TKgQUlWgvhID\\\": init shard \\\"<indexName>_TKgQUlWgvhID\\\": init prop \\\"other_infos\\\": null index: init disk segments: init segment segment-1730279432907267231.db: mmap file: invalid argument\",\"level\":\"error\",\"msg\":\"Unable to load shard TKgQUlWgvhID: init shard \\\"<indexName>_TKgQUlWgvhID\\\": init shard \\\"<indexName>_TKgQUlWgvhID\\\": init prop \\\"other_infos\\\": null index: init disk segments: init segment segment-1730279432907267231.db: mmap file: invalid argument\",\"time\":\"2024-11-27T09:42:04Z\"}\n\n{\"action\":\"load_shard\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"error\",\"msg\":\"failed to load shard: Unable to load shard TKgQUlWgvhID: init shard \\\"<indexName>_TKgQUlWgvhID\\\": init shard \\\"<indexName>_TKgQUlWgvhID\\\": init prop \\\"other_infos\\\": null index: init disk segments: init segment segment-1730279432907267231.db: mmap file: invalid argument\",\"shard_name\":\"TKgQUlWgvhID\",\"time\":\"2024-11-27T09:42:04Z\"}\n\nAlso found this error the day of the backup, I don’t know if it’s relevant but it is the same segment :\n{\"action\":\"lsm_memtable_flush\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"class\":\"<indexName>\",\"error\":\"flush: unlinkat /var/lib/weaviate/<indexName>/TKgQUlWgvhID/lsm/property_ver_current_version_nullState/segment-1730279432907267231.scratch.d: directory not empty\",\"index\":\"<indexName>\",\"level\":\"error\",\"msg\":\"flush and switch failed\",\"path\":\"/var/lib/weaviate/<indexName>/TKgQUlWgvhID/lsm/property_ver_current_version_nullState\",\"shard\":\"TKgQUlWgvhID\",\"time\":\"2024-10-30T09:11:34Z\"}",
    "date_created": "2024-11-21T10:32:21.453Z",
    "has_accepted_answer": false,
    "title": "Error restoring backup and file corruption",
    "topic_id": 7751
  },
  {
    "user_id": 611,
    "conversation": "[Bigdwarf43 (2024-08-12T06:34:49.074Z)]: Description\nWhen creating a new collection with an existing collection’s config, the newly created collection does not retain the original collection’s properties\nScreenshot from 2024-08-12 12-01-391154×607 56.2 KB\nServer Setup Information\n\nWeaviate Server Version: weaviate:1.24.22\n\n----------\n\n[DudaNogueira (2024-08-12T18:52:52.203Z)]: hi @Bigdwarf43 !!\nThank you very much. Nice catch!\nThis is a reproducible bug \nhere is how I have reproduced it:\nclient.collections.delete([\"Test\", \"NewTest\"])\ncollection = client.collections.create(\"Test\",\n    properties=[\n        wvc.config.Property(\n            name=\"field_tokenizer\",\n            data_type=wvc.config.DataType.TEXT,\n            tokenization=wvc.config.Tokenization.FIELD\n        )\n    ]\n)\n\n# extract the collection config dict\nschema_dict = collection.config.get().to_dict()\ndefined_tokenizer = schema_dict.get(\"properties\")[0].get(\"tokenizer\")\nassert defined_tokenizer == \"field\"\n\n# create a new collection\nmodified_schema_dict = schema_dict\nmodified_schema_dict[\"class\"] = \"NewTest\"\nnew_collection = client.collections.create_from_dict(modified_schema_dict)\nnew_tokenizer = new_collection.config.get().properties[0].tokenization.value\nassert defined_tokenizer == new_tokenizer\n\nI will escalate this ASAP.\nThanks!\n\n----------\n\n[DudaNogueira (2024-08-12T19:42:05.591Z)]: hi @Bigdwarf43 !!\nWe have a PR already!\n\n  \n\n      github.com/weaviate/weaviate-python-client\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      property.to_dict() with tokenizer instead of tokenization\n    \n\n    \n      \n        opened 07:34PM - 12 Aug 24 UTC\n      \n\n\n      \n        \n          \n          dudanogueira\n        \n      \n    \n\n    \n    \n  \n\n\n  \n    When exporting the collection config using `to_dict`, the `tokenization` paramet…er is defined as `tokenizer`. \n\nThis causes a wrong parameter name to be generated, and when using `creating_from_dict` with this dict, it doesn't have a  tokenization, and fall backs to default (word) when used with `create_from_dict`.\n\nthis affects 4.7.1. [Here is the line to change](https://github.com/weaviate/weaviate-python-client/blob/5482164c2732db8ea9ce66b1c4743a4c2140b8ac/weaviate/collections/classes/config.py#L1223)\n\nCode to test:\n\n```python\nimport weaviate\nfrom weaviate import classes as wvc\nclient = weaviate.connect_to_local()\n    \nprint(weaviate.__version__, client.get_meta().get(\"version\"))\n\nclient.collections.delete([\"Test\", \"NewTest\"])\ncollection = client.collections.create(\"Test\",\n    properties=[\n        wvc.config.Property(\n            name=\"field_tokenizer\",\n            data_type=wvc.config.DataType.TEXT,\n            tokenization=wvc.config.Tokenization.FIELD\n        )\n    ]\n)\n\n# extract the collection config dict\nschema_dict = collection.config.get().to_dict()\ndefined_tokenizer = schema_dict.get(\"properties\")[0].get(\"tokenizer\")\nassert defined_tokenizer == \"field\"\n\n# create a new collection\nmodified_schema_dict = schema_dict\n# change it to a new name\nmodified_schema_dict[\"class\"] = \"NewTest\"\nnew_collection = client.collections.create_from_dict(modified_schema_dict)\nnew_tokenizer = new_collection.config.get().properties[0].tokenization.value\nprint(\"new tokenizer\", new_tokenizer)\nassert new_tokenizer == \"field\"\n```\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWe should see a new version of the client with this issue fixed soon.\nThanks!",
    "date_created": "2024-08-12T06:34:49.022Z",
    "has_accepted_answer": false,
    "title": "Client.collections.create_from_config reverts to default config",
    "topic_id": 3333
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-12-18T23:35:59.794Z)]: Description\nLet’s say something bad happens and that I need to do a backup of my cluster hosted on the Weaviate cloud.\nWhat are the capabilities here? I saw on another post that Weaviate has covered, but it’s free stressful to not know exactly how we are covered.\nCouldn’t find any documentation on this.\nParticularly, the questions were:\n\nIn MongoDB, I can backup to a specific time period as regular backups at intervals are done. Is this possible?\nIs there a self-serve way to do backup?\nCan I export my Weaviate instance and store it myself as well?\n\nServer Setup Information\n\nWeaviate Server Version: Weaviate Cloud Hosted\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?: Yes\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-12-19T19:17:07.571Z)]: hi @Tejas_Sharma !!\nAll hosted clusters in our cloud have a backup bucket already configured.\nThis means that, at any time, you can create or restore from your own backups, on top of the automated backups we do from our side.\nThose “ad-hoc” backups can be store up to 1 month.\nHere is an example code in python v4 client for that, using a real serverless cluster in our cloud:\nclient.collections.delete(\"Collection1\")\ncollection = client.collections.create(\"Collection1\")\ncollection.data.insert({\"name\": \"John\"})\ncollection.data.insert({\"name\": \"Mary\"})\nprint(\"Collection1 exists?\", client.collections.exists(\"Collection1\"))\nprint(\"Collection1 total count\", collection.aggregate.over_all())\nbackup_task = client.backup.create(backup_id=\"super-cool-backup-id\", backend=\"gcs\", include_collections=[\"Collection1\"], wait_for_completion=True)\nprint(\"Backup task\", backup_task)\nclient.collections.delete(\"Collection1\")\nprint(\"Collection1 deleted!\")\nprint(\"Collection1 exists?\", client.collections.exists(\"Collection1\"))\nrestore_task = client.backup.restore(backup_id=\"super-cool-backup-id\", backend=\"gcs\", include_collections=\"Collection1\", wait_for_completion=True)\nprint(\"Collection1 restore task\", restore_task)\nprint(\"Collection1 exists?\", client.collections.exists(\"Collection1\"))\nprint(\"Collection1 total count\", collection.aggregate.over_all())\n\nI got this as the output:\nCollection1 exists? True\nCollection1 total count AggregateReturn(properties={}, total_count=2)\nBackup task error=None status=<BackupStatus.SUCCESS: 'SUCCESS'> path='gs://weaviate-wcs-prod-cust-us-west3-workloads-backups/69e14018-8f2c-4361-bf79-0953902372b3/super-cool-backup-id' backup_id='super-cool-backup-id' collections=['Collection1']\nCollection1 deleted!\nCollection1 exists? False\nCollection1 restore task error=None status=<BackupStatus.SUCCESS: 'SUCCESS'> path='gs://weaviate-wcs-prod-cust-us-west3-workloads-backups/69e14018-8f2c-4361-bf79-0953902372b3/super-cool-backup-id' backup_id='super-cool-backup-id' collections=['Collection1']\nCollection1 exists? True\nCollection1 total count AggregateReturn(properties={}, total_count=2)\n\nWe do not provide a feature in our console to export your backup. \nHowever, If you ever need a copy of your backups for testing or in case you want take your vectors elsewhere - hope that’s not the case!!  - you can always reach out to our super friendly support line at:\n  \n\n      console.weaviate.cloud\n  \n\n  \n    \n\nWeaviate Cloud\n\n  Weaviate Cloud\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this answer your questions!\nThanks!\n\n----------\n\n[Tejas_Sharma (2024-12-19T20:51:56.086Z)]: Thanks Duda, so from Python code I can do a backup at any time. Is there any docs link?\nOh and no migration at all, super happy with Weaviate but this is just something on the back of our minds at the team in case an emergency happens — planning before hand!\n\n----------\n\n[DudaNogueira (2024-12-19T21:16:20.166Z)]: Glad to hear that!\nHere are the docs about backup:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBackups | Weaviate\n\n  Weaviate's Backup feature is designed to work natively with cloud technology. Most notably, it allows:\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIf you need direct access to the backup bucket, then the Bring Your Own Cloud offering is a way to go\nLet me know if that helps!\nThanks!\n\n----------\n\n[filip.s (2025-02-25T16:22:57.062Z)]: Hi @DudaNogueira\nI’m experiencing significant challenges creating backups on my paid Weaviate Cloud serverless cluster using Azure storage. Despite my best efforts following the available documentation, I haven’t been able to create a working implementation.\nSpecifically, I’m unable to determine how to properly pass the Azure Storage Account connection string and container name parameters to the Weaviate Cloud backup API. The documentation doesn’t seem to provide clear examples for this use case.\nHere’s the code I’ve attempted to use:\nimport weaviate\nimport os\nimport datetime\nimport argparse\nfrom weaviate.backup import BackupStorage\n\n\nwcd_url = \"https://123abc.c1.europe-west3.gcp.weaviate.cloud\"\nwcd_api_key = \"key..123\"\nazure_connection_string=\"DefaultEndpointsProtocol=https;AccountName=...\",\nazure_container=\"weaviate-backups\"\n\n\n# Generate backup ID with timestamp\ntimestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\nbackup_id = f\"backup-{timestamp}\"\n\n# Connect to Weaviate\nprint(f\"Connecting to Weaviate at {wcd_url}\")\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=wcd_url,\n    auth_credentials=weaviate.auth.Auth.api_key(wcd_api_key)\n)\n\ntry:\n    print(f\"Starting backup with ID: {backup_id}\")\n    \n    # The most basic create call with just the required parameters\n    backup_config = {\n        \"backend\": BackupStorage.AZURE,\n        \"azure\": {\n            \"container\": azure_container,\n            \"connection_string\": azure_connection_string\n        }\n    }\n    \n    # Start backup process\n    print(f\"Starting backup with ID: {backup_id}\")\n    client.backup.create(\n        backup_id=backup_id,\n        **backup_config\n    )\n    \n    print(f\"Backup initiated: {backup}\")\n    \n    # Get initial status\n    status = client.backup.get_status(backup_id)\n    print(f\"Initial status: {status}\")\n    \nexcept Exception as e:\n    print(f\"Error: {str(e)}\")\nfinally:\n    client.close()\n    print(\"Connection closed\")\n\n----------\n\n[DudaNogueira (2025-02-25T18:45:33.402Z)]: hi @filip.s !!\nAll clusters hosted in our cloud already have the backup buckets configured, and the backups are triggered daily by our platform.\nYou can check the module user for your cluster with:\nclient.get_meta()\n\nOn top of the automatic backups we provide, you can also trigger a new backup at anytime passing the backend used in your cluster.\nNote: We do not expose those backups in our console.\nFor any issues with a hosted cluster, the best place to ask for help is Weaviate Cloud\nThanks!\n\n----------\n\n[filip.s (2025-02-26T11:00:08.594Z)]: Thanks for your answer.\nIt is great you’re doing backups, but I feel I am missing enough control over it in order to feel confident that I am covered when something happens.\nI would like to use example of a SQL database in Azure. In Azure portal, I can see list of my regular backups and I can trigger restore by few clicks. I feel that I am in control.\nCorrect my if I’m wrong, but I don’t see such option at Weaviate.\nWhat is the process in situation when there is some kind of data loss (caused by whatever - hacking incident, our client app error, etc.), I want to see what backups are there in Weaviate, and trigger a restore?\nThanks for your help\n\n----------\n\n[DudaNogueira (2025-02-26T13:49:14.485Z)]: hi @filip.s !\nYou are right. We do not expose the backups you have available in your cluster hosted in our cloud.\nHowever, you can always reach out to our support team, and we’ll send you the ids of the backup we currently have, either created by us or by you.\nWith those ids, you can restore your data at anytime using client.backup.restore.\nLet me know if that helps!\nThanks!\n\n----------\n\n[filip.s (2025-02-26T14:54:11.585Z)]: Thanks @DudaNogueira , it is clearer for me now.\nIn case of incidents, reaching out to Weaviate support may end up taking too long (I assume you guys don’t work 24/7).\nIs there any reason why you decided not to expose cloud backups with your customers?\nI can also do backups manually, using the functionality in your python library  that saves backups to Azure Storage Account. However, I just want able to make it work based on your documentation nor I found any workable examples online. Would you mind sharing a simple script that works?\nThanks for your help.\n\n----------\n\n[DudaNogueira (2025-02-26T17:46:31.324Z)]: hi @filip.s !\nOur support team covers all timezones.\nHere you can find more information on response time for our support levels according to the severity level:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nSupport levels | Weaviate\n\n  Weaviate Cloud (WCD) offers multiple levels of support. You have the flexibility to choose the level of support that you need.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI don’t believe there is any specific reason for the backups not being exposed other than it was not yet implemented.\nI have asked internally about this feature.\n\nI can also do backups manually, using the functionality in your python library that saves backups to Azure Storage Account. However, I just want able to make it work based on your documentation nor I found any workable examples online. Would you mind sharing a simple script that works?\n\nYou can’t do that, actually. The backup module is configured at the cluster level. So you can only perform backups to where it is already configured in your cluster.\nYou can migrate your data over to a new cluster, or store it locally, using this migration guide:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Learn how to migrate data within Weaviate for easy data handling.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNote that we also have BYOC (Bring your Own Cloud) offering where you can customize some of the configurations while still counting with our services.\nLet me know if that helps!\nThanks!",
    "date_created": "2024-12-18T23:35:59.751Z",
    "has_accepted_answer": true,
    "title": "Weaviate Cloud Hosting Backups",
    "topic_id": 9306
  },
  {
    "user_id": 3520,
    "conversation": "[dourillon (2025-02-21T22:06:41.748Z)]: Description\nUsing this requirements.txt file and pip install -r requirements.txt:\nanthropic\npython-dotenv\nweaviate-client\n\nWith the following .env file:\n# weaviate\nWCD_URL=<your_wcd_url>\nWCD_API_KEY=<your_wcd_key>\n\n# openai\nOPENAI_API_KEY=<your_openai_key>\n\n# anthropic\nANTHROPIC_API_KEY=<your_anthropic_key>\n\nRun the following python script:\nimport os\n\nfrom dotenv import load_dotenv\nfrom weaviate import WeaviateClient, connect_to_weaviate_cloud\nfrom weaviate.classes.config import Configure\nfrom weaviate.classes.init import Auth\n\nload_dotenv()\n\n\ndef get_client() -> WeaviateClient:\n    \"\"\"Get a weaviate cloud client instance, using WCD_URL, WCD_API_KEY, and OPENAI_API_KEY\n    environment variables.\n\n    **Important:** Note that it is the responsibility of the caller to close the client.\n\n    Returns:\n        WeaviateClient: A configured weaviate cloud client\n    \"\"\"\n    return connect_to_weaviate_cloud(\n        cluster_url=os.environ[\"WCD_URL\"],\n        auth_credentials=Auth.api_key(os.environ[\"WCD_API_KEY\"]),\n        headers={\n            \"X-Anthropic-Api-Key\": os.environ[\"ANTHROPIC_API_KEY\"],\n            \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"],\n        },\n    )\n\n\nif __name__ == \"__main__\":\n\n\n    with get_client() as client:\n\n        print(\"Creating collection...\")\n        collection_name = \"test_collection\"\n        collection = client.collections.create(\n            name=collection_name,\n            vectorizer_config=Configure.Vectorizer.text2vec_openai(\n            ),\n            generative_config=Configure.Generative.anthropic(\n                # model=\"claude-3-5-sonnet-20240620\",\n                model=\"claude-3-5-sonnet-20241022\",\n                max_tokens=1024,\n            ),\n        )\n\n        print(\"Adding chunk to collection...\")\n        with collection.batch.dynamic() as batch:\n            batch.add_object({\"text\": \"Most dogs have 4 legs... except those that were amputated.\"})\n        print(f\"Nb of chunks in collection: {collection.aggregate.over_all().total_count}\")\n\n        print(\"Call generate...\")\n        query = \"How many legs does a dog have? Answer as a pirate would.\"\n        print(f\"\\tQuery: {query}\")\n        response = collection.generate.near_text(\n            query=\"dog\",\n            limit=1,\n            grouped_task=query,\n        )\n        print(f\"\\tRetrieved chunk: {response.objects[0].properties['text']}\")\n        print(f\"\\tAnswer: {response.generated}\")\n\n        print(\"Delete collection...\")\n        client.collections.delete(collection_name)\n\nYou should get the following error:\nCreating collection...\nAdding chunk to collection...\nNb of chunks in collection: 1\nCall generate...\n\tQuery: How many legs does a dog have? Answer as a pirate would.\nTraceback (most recent call last):\n  File \"/Users/dtourillon/TouriLogica/Kwerty/dev/weaviate-generate-issue/weaviate-issue-venv/lib/python3.12/site-packages/weaviate/collections/grpc/query.py\", line 478, in __call\n    res = await _Retry(4).with_exponential_backoff(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dtourillon/TouriLogica/Kwerty/dev/weaviate-generate-issue/weaviate-issue-venv/lib/python3.12/site-packages/weaviate/collections/grpc/retry.py\", line 31, in with_exponential_backoff\n    raise e\n  File \"/Users/dtourillon/TouriLogica/Kwerty/dev/weaviate-generate-issue/weaviate-issue-venv/lib/python3.12/site-packages/weaviate/collections/grpc/retry.py\", line 28, in with_exponential_backoff\n    return await f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dtourillon/TouriLogica/Kwerty/dev/weaviate-generate-issue/weaviate-issue-venv/lib/python3.12/site-packages/grpc/aio/_call.py\", line 327, in __await__\n    raise _create_rpc_error(\ngrpc.aio._call.AioRpcError: <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Anthropic API error: invalid_request_error - max_tokens: must be greater than or equal to 1\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-02-21T16:55:50.85583-05:00\", grpc_status:2, grpc_message:\"Anthropic API error: invalid_request_error - max_tokens: must be greater than or equal to 1\"}\"\n>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/dtourillon/TouriLogica/Kwerty/dev/weaviate-generate-issue/weaviate_generate_issue_main.py\", line 56, in <module>\n    response = collection.generate.near_text(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dtourillon/TouriLogica/Kwerty/dev/weaviate-generate-issue/weaviate-issue-venv/lib/python3.12/site-packages/weaviate/syncify.py\", line 23, in sync_method\n    return _EventLoopSingleton.get_instance().run_until_complete(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dtourillon/TouriLogica/Kwerty/dev/weaviate-generate-issue/weaviate-issue-venv/lib/python3.12/site-packages/weaviate/event_loop.py\", line 42, in run_until_complete\n    return fut.result()\n           ^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 456, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/dtourillon/TouriLogica/Kwerty/dev/weaviate-generate-issue/weaviate-issue-venv/lib/python3.12/site-packages/weaviate/collections/queries/near_text/generate.py\", line 101, in near_text\n    res = await self._query.near_text(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dtourillon/TouriLogica/Kwerty/dev/weaviate-generate-issue/weaviate-issue-venv/lib/python3.12/site-packages/weaviate/collections/grpc/query.py\", line 490, in __call\n    raise WeaviateQueryError(str(e), \"GRPC search\")  # pyright: ignore\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Anthropic API error: invalid_request_error - max_tokens: must be greater than or equal to 1\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-02-21T16:55:50.85583-05:00\", grpc_status:2, grpc_message:\"Anthropic API error: invalid_request_error - max_tokens: must be greater than or equal to 1\"}\"\n>.\n\nAny additional Information\nThe script above:\n\n… works using claude-3-5-sonnet-20240620, the second last available Claude 3.5 sonnet model\n… raises “Anthropic API error: invalid_request_error - max_tokens: must be greater than or equal to 1” using claude-3-5-sonnet-20241022, the latest Claude 3.5 Sonnet model… despite max_tokens being set to 1024…\n\n----------\n\n[DudaNogueira (2025-02-24T13:41:31.765Z)]: hi @dourillon !!\nWelcome to our community!\nI was not able to reproduce this.\nI tried with both models.\nHere is a running version on python notebook:\nimport os\n\nfrom dotenv import load_dotenv\nfrom weaviate import WeaviateClient, connect_to_weaviate_cloud, connect_to_local\nfrom weaviate.classes.config import Configure\nfrom weaviate.classes.init import Auth\n\nload_dotenv()\n\n\ndef get_client() -> WeaviateClient:\n    \"\"\"Get a weaviate cloud client instance, using WCD_URL, WCD_API_KEY, and OPENAI_API_KEY\n    environment variables.\n\n    **Important:** Note that it is the responsibility of the caller to close the client.\n\n    Returns:\n        WeaviateClient: A configured weaviate cloud client\n    \"\"\"\n    return connect_to_local(\n        headers={\n            \"X-Anthropic-Api-Key\": os.environ[\"ANTHROPIC_API_KEY\"],\n            \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"],\n        },\n    )\n\nwith get_client() as client:\n\n    collection_name = \"test_collection\"\n    print(\"Delete collection...\")\n    client.collections.delete(collection_name)    \n    print(\"Creating collection...\")\n    collection = client.collections.create(\n        name=collection_name,\n        vectorizer_config=Configure.Vectorizer.text2vec_openai(\n        ),\n        generative_config=Configure.Generative.anthropic(\n            #model=\"claude-3-5-sonnet-20240620\",\n            model=\"claude-3-5-sonnet-20241022\",\n            max_tokens=1024,\n        ),\n    )\n\n    print(\"Adding chunk to collection...\")\n    with collection.batch.dynamic() as batch:\n        batch.add_object({\"text\": \"Most dogs have 4 legs... except those that were amputated.\"})\n    print(f\"Nb of chunks in collection: {collection.aggregate.over_all().total_count}\")\n\n    print(\"Call generate...\")\n    query = \"How many legs does a dog have? Answer as a pirate would.\"\n    print(f\"\\tQuery: {query}\")\n    response = collection.generate.near_text(\n        query=\"dog\",\n        limit=1,\n        grouped_task=query,\n    )\n    print(f\"\\tRetrieved chunk: {response.objects[0].properties['text']}\")\n    print(f\"\\tAnswer: {response.generated}\")\n\n----------\n\n[dourillon (2025-02-24T14:56:54.581Z)]: Hi @DudaNogueira\nThanks for trying to reproduce, and sorry you were not able to.\nI am new to weaviate, so the problem may very well be on my side. Apologies if that’s the case…\nI tried running your notebook on my side, and just as you have, I was able to run it with both versions on Claude 3.5 models… At least, we are seeing the same! \nHowever, I can still consistently reproduce the initial reported issue on my side, so where do we go from here?\n\nI notice that I am using connect_to_weaviate_cloud while your notebook uses connect_to_local… could “weaviate cloud” vs. “weaviate local” make a difference? Is this something you could try on your side?\nI am creating a python venv, then activating it, then pip install -r requirements.txt, then running my script with python at command line… Any additional info you’d need that could explain the issue I’m seeing? Would it help if I report the packages I’m using with pip freeze ?\n\nCheers,\nDominique\n\n----------\n\n[DudaNogueira (2025-02-24T15:27:18.059Z)]: Hi!\nthe connect_to_local will connect to a Weaviate instance running locally in docker.\nThis may be an issue Anthropic side:\nAnthropic API error: invalid_request_error - max_tokens: must be greater than or equal to 1\n\n----------\n\n[dourillon (2025-02-24T15:36:15.102Z)]: the connect_to_local will connect to a Weaviate instance running locally in docker.\n\nAgreed, but why do I get a different behavior using local vs could weaviate? And cloud weaviate is what I’ll use in prod.\n\nThis may be an issue Anthropic side:\nAnthropic API error: invalid_request_error - max_tokens: must be greater than or equal to 1\n\nAgreed, it could be on Anthropic side… but it could also be on weaviate side since I set max_tokens=1024 when setting the generative config in weaviate when creating a weaviate collection, no?\n\n----------\n\n[DudaNogueira (2025-02-27T18:26:58.736Z)]: hi @dourillon !\nI got the same result both running locally and running on ou cloud.\nI this outcome consistent?\n\n----------\n\n[dourillon (2025-02-28T14:19:27.887Z)]: Hi @DudaNogueira\nSorry you cannot seem to be able to reproduce.\nYes, in my case, the results is consistent for the past week.\nIn case it helps, here’s the result of pip freeze in my venv:\nannotated-types==0.7.0\nanthropic==0.46.0\nanyio==4.8.0\nappnope==0.1.4\nasttokens==3.0.0\nAuthlib==1.3.1\ncertifi==2025.1.31\ncffi==1.17.1\ncomm==0.2.2\ncryptography==44.0.1\ndebugpy==1.8.12\ndecorator==5.2.1\ndistro==1.9.0\ndocx2txt==0.8\nexecuting==2.2.0\ngrpcio==1.70.0\ngrpcio-health-checking==1.70.0\ngrpcio-tools==1.70.0\nh11==0.14.0\nhttpcore==1.0.7\nhttpx==0.28.1\nidna==3.10\nipykernel==6.29.5\nipython==8.32.0\njedi==0.19.2\njiter==0.8.2\njupyter_client==8.6.3\njupyter_core==5.7.2\nmatplotlib-inline==0.1.7\nnest-asyncio==1.6.0\npackaging==24.2\nparso==0.8.4\npexpect==4.9.0\nplatformdirs==4.3.6\nprompt_toolkit==3.0.50\nprotobuf==5.29.3\npsutil==7.0.0\nptyprocess==0.7.0\npure_eval==0.2.3\npycparser==2.22\npydantic==2.10.6\npydantic_core==2.27.2\nPygments==2.19.1\npypandoc==1.15\npython-dateutil==2.9.0.post0\npython-dotenv==1.0.1\npyzmq==26.2.1\nsetuptools==75.8.0\nsix==1.17.0\nsniffio==1.3.1\nstack-data==0.6.3\ntornado==6.4.2\ntraitlets==5.14.3\ntyping_extensions==4.12.2\nvalidators==0.34.0\nwcwidth==0.2.13\nweaviate-client==4.11.0\n\nApart from maybe using different lib versions, not sure I can think of other reasons for you not seeing the issue consistently and me seeing it consistently?!\n\n----------\n\n[DudaNogueira (2025-02-28T14:52:05.662Z)]: As you are running in our cloud, can you open a support ticket as described in Weaviate Cloud?\nThen I can access that cluster and try something with my key to see if I can replicate it.\nThanks!\n\n----------\n\n[dourillon (2025-02-28T15:21:17.496Z)]: Hi @DudaNogueira\nSure, I see this\nSupport\nFor support of your cluster hosted on Weaviate Cloud, please send an e-mail to support@weaviate.io\n\nSo I will send an email to support@weaviate.io pointing to this conversation.\nThanks for your support!\n\n----------\n\n[dourillon (2025-02-28T15:26:40.080Z)]: Done, email just sent to support@weaviate.io.\n\n----------\n\n[dourillon (2025-02-28T15:34:26.799Z)]: Confused as to where to ask my questions initially, I had also asked it there: collection.generate.near_text using claude-3-5-sonnet-20241022 raises Anthropic API error: invalid_request_error - max_tokens: must be greater than or equal to 1 · Issue #7331 · weaviate/weaviate · GitHub\nSomeone was able to reproduce and commented:\nThanks for the information! @dtourillon\n\nI am able to replicate this issue on v1.28.4. However, it does not exist on v1.28.5 so must have been fixed in a recent PR. Are you able to update your Weaviate cluster to v1.28.5 or above?\n\nSo I will give it a try…\n\n----------\n\n[dourillon (2025-02-28T15:53:19.831Z)]: To close the loop: upgrading my weaviate cluster to v1.28.6 appears to have fixed the issue I was seeing!\n\n----------\n\n[DudaNogueira (2025-02-28T17:54:43.678Z)]: Glad to hear that, and thanks for sharing @dourillon !!",
    "date_created": "2025-02-21T22:06:41.691Z",
    "has_accepted_answer": true,
    "title": "Collection.generate.near_text using claude-3-5-sonnet-20241022 raises Anthropic API error: invalid_request_error - max_tokens: must be greater than or equal to 1",
    "topic_id": 10499
  },
  {
    "user_id": 2045,
    "conversation": "[Muhammad_Ashir (2024-10-25T11:27:07.490Z)]: Description\nHi there I am trying to generate some vector embeddings via Mistral AI but I am having few issues first of all I was getting 429 issue on object insertion i fixed it by limiting the number of request per seconds now I am getting this :\nerrors: text too long for vectorization. Tokens for text: 10440, max tokens per batch: 8192, ApiKey absolute token limit: 1000000’\nclient.collections.create(\n    \"Embeddings\",\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_mistral(\n            name=\"filecontent\",\n            source_properties=[\"filecontent\"],\n            model=\"mistral-embed\"\n        )\n    ],\n    # Additional parameters not shown\n)\n\nfor row in rows:\n      original_name = row.OriginalName\n      full_text = row.FullText\n    \n    # Create object directly\n      data_row = {\n        \"filename\": original_name,\n        \"filecontent\": full_text\n      }\n      print(f\"Passing file : {original_name}\")\n      collection = client.collections.get(\"Embeddings\")\n      with collection.batch.rate_limit(requests_per_minute=30) as batch:\n          obj_uuid = generate_uuid5(data_row)\n          batch.add_object(\n            properties=data_row  )\n      \n      if len(collection.batch.failed_objects) > 0:\n          print(collection.batch.failed_objects)\n      time.sleep(30)\n    cursor.close()\n    connection.close()\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-10-25T15:06:47.946Z)]: hi @Muhammad_Ashir !\nWelcome to our community \nWhat is the version you are using both for server and client?\nCan you paste the entire traceback?\nThis message can happen if you pass a too big of content  from a object to be indexed.\n\n----------\n\n[Muhammad_Ashir (2024-10-28T12:48:30.874Z)]: Hi @DudaNogueira I am using the cloud version Weaviate\nDatabase version : 1.26.6\nfor server is there any solution how I can handle big content I am already using batch import and limited request with sleep time to handle the mistral api limits is there any way to limit the token\n\n----------\n\n[Muhammad_Ashir (2024-10-28T12:54:41.695Z)]: Passing file : AccountTransactionsf.pdf\n{‘message’: ‘Failed to send 1 objects in a batch of 1. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\n[ErrorObject(message=“WeaviateInsertManyAllFailedError(‘Every object failed during insertion. Here is the set of all errors: text too long for vectorization. Tokens for text: 10440, max tokens per batch: 8192, ApiKey absolute token limit: 1000000’)”, object_=_BatchObject(collection=‘ECMEmbeddings’, vector=None, uuid=‘4e512aff-441d-4dbd-b31b-69f5c2e69aa1’, properties={‘filename’: ‘AccountTransactionsf.pdf’, ‘filecontent’: ‘my content is large here’ }, tenant=None, references=None, index=0, retry_count=0), original_uuid=None)]\n\n----------\n\n[Dirk (2024-10-28T13:02:10.037Z)]: Hey, How big is your input text? You can have a look here https://platform.openai.com/tokenizer\n\n----------\n\n[Muhammad_Ashir (2024-10-28T13:03:14.898Z)]: Hi @Dirk  its\nTokens:8,230\nCharacters:18316\nWe do have some very large files expected to be having tokens more than 50,000\n\n----------\n\n[Dirk (2024-10-28T13:33:18.564Z)]: Mistral has a hard limit of 8192 tokens. You cannot have any texts that are larger that should be vectorized by mistral.\nHave a look into chunking to work around that: A brief introduction to chunking | Weaviate\n\n----------\n\n[Muhammad_Ashir (2024-10-31T12:01:18.466Z)]: chunk_collection_definition = {\n    \"class\": \"DEmbeddings\",\n    \"vectorizer\": \"text2vec-mistral\",\n    \"moduleConfig\": {\n        \"generative-mistral\": {}\n    },\n    \"properties\": [\n        {\n            \"name\": \"chunk\",\n            \"dataType\": [\"text\"],\n        },\n        {\n            \"name\": \"filename\",\n            \"dataType\": [\"text\"],\n        },\n        {\n            \"name\": \"chunking_strategy\",\n            \"dataType\": [\"text\"],\n            \"tokenization\": \"field\",\n        }\n    ]\n}\n\n\nclient.schema.create_class(chunk_collection_definition)\n\nI have tried this but it says that not schema inside client one more thing right now I am using this\n# client.collections.create(\n#     \"DEmbeddings\",\n#     vectorizer_config=[\n#         Configure.NamedVectors.text2vec_mistral(\n#             name=\"filecontent\",\n#             source_properties=[\"filecontent\"],\n#             model=\"mistral-embed\",\n#         )\n#     ],\n#     # Additional parameters not shown\n# )\n\nis there any way to define the chunking thing?\n\n----------\n\n[DudaNogueira (2024-10-31T12:56:05.904Z)]: hi @Muhammad_Ashir !\nYou need to chunk your content before ingesting to the Database.\n\n----------\n\n[Muhammad_Ashir (2024-10-31T13:00:46.330Z)]: I got you but I am concered about fetching because the techniques you have mentioned on documentation I am following that if I save it as chunk then in case of search I have to fetch the other chunks as well and I am just trying to follow that : Example part 1 - Chunking | Weaviate\n\n----------\n\n[DudaNogueira (2024-10-31T20:16:36.663Z)]: hi @Muhammad_Ashir !\nNot sure I understood.\nIf you chunk your document, in let’s say, 3 chunks, you will get only the chunk that is closest to your query.\n\n----------\n\n[Muhammad_Ashir (2024-11-01T11:11:32.185Z)]: Hi @DudaNogueira that’s not my case here What i want if I have three chunks and my search is nearest to the one of the chunks then i wanna get all those three chunks\nWe are working on a file base system so if we lets say have a large files we converted it into three chunks that is : a,b,c\nNow if my query matches with b then I have to fetch the whole files to do some thing on that, and in your example even this thing has been explained that if you convert object into the chunks on match you will get the whole object but I am not sure about the tokenization because the method in documentation mentioned is not working for me as I have pasted code above as well.\nI am following this Example part 1 - Chunking | Weaviate can you have look and let me know please\n\n----------\n\n[DudaNogueira (2024-11-01T12:50:46.109Z)]: Tokenization and Chunking are different things.\nTokenization is about how an object property will be tokenized to be indexed.\nLet’s say you have a property url, that is set up to tokenization word (the default).\nwhen you create an object with the value, for example, google.com Weaviate will tokenize this value per word. This means that you will end up with both google and com\nNow when you do a filter in Weaviate, by property url EqualTo google.com you will not find that object, because it doesn’t have a google.com token, but google and com.\nIf you set the tokenization to field, then Weaviate will treat the whole value as a single token. Now you can search only for EqualTo google.com.\nNow, chunking, is how you will separate a big corpus of text into smaller ones. Weaviate will not do that for your.\nYou need to chunk it before ingesting to the database. So instead of chunking 1 big corpus, you chunk it up in smaller ones, and each of that chunk will be an object in Weaviate.\nNow, when you do a hybrid search, you will leverage both the vector and those tokens indexed as word and field, in order to get the best possible search.\nIn your case, you could for example group the results per different documents, and pass it over to the front end. If the user requests (or you can do it beforehand), you load up the surrounding chunks of that document so you can present it to the user.\nI believe Verba does something similar: GitHub - weaviate/Verba: Retrieval Augmented Generation (RAG) chatbot powered by Weaviate\nLet me know if this helps",
    "date_created": "2024-10-25T11:27:07.438Z",
    "has_accepted_answer": false,
    "title": "Errors: text too long for vectorization. Tokens for text: 10440, max tokens per batch: 8192, ApiKey absolute token limit: 1000000'",
    "topic_id": 5918
  },
  {
    "user_id": 3108,
    "conversation": "[laban48707 (2024-12-26T11:21:59.397Z)]: Hey guys… \nI am new to Weaviate and am working on a project that involves storing and querying a dataset with complex relationships. My dataset includes entities such as “Products,” “Customers,” and “Orders,” where:\n\nEach order is linked to a customer and one or more products.\nProducts have various attributes, including categories and tags.\nCustomers can have multiple attributes, like preferences and past order history.\n\nI want to design the schema in a way that allows for efficient querying, such as:\n\nFinding customers who have purchased products with specific tags or categories.\nAnalyzing trends in product orders based on customer preferences.\nRecommending products based on a customer’s order history.\n\nI check this: https://forum.weaviate.io/t/setting-preference-on-properties salesforcedeveloper But I have not found any solution. Could anyone guide me about this? Could someone provide advice or examples on how to structure such a schema in Weaviate? Are there specific strategies or pitfalls I should be aware of when modeling these types of relationships?\nThanks in advance!\nRespected community member!",
    "date_created": "2024-12-26T11:21:59.346Z",
    "has_accepted_answer": false,
    "title": "Guidance on Schema Design for Complex Data Relationships",
    "topic_id": 9454
  },
  {
    "user_id": 1273,
    "conversation": "[longspearfish (2024-09-05T15:33:55.522Z)]: Description\nHi community! I tried to do aggregation with group by, and was looking for some examples on grouping by on multiple properties of a collection. However, I could only find examples where it groups by one property at a time, such as the one below -\ntry:\n    collection = client.collections.get(\"Article\")\n    response = collection.aggregate.over_all(\n        group_by=GroupByAggregate(prop=\"inPublication\"),\n        total_count=True,\n        return_metrics=wvc.query.Metrics(\"wordCount\").integer(mean=True)\n    )\n\n    for g in response.groups:\n        print(g.total_count)\n        print(g.properties)\n        print(g.grouped_by)\n\nfinally:\n    client.close()\n\nI wonder if it is possible for us to do group_by with multiple properties?\nServer Setup Information\n\nWeaviate Server Version: 1.25.11\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python 4.5.7\nMultitenancy?:  No\n\n----------\n\n[DudaNogueira (2024-09-05T18:28:47.331Z)]: hi @longspearfish!! Hope you are having a lovely week!\nYou can only group by one property at a time. \nCheck here a related issue/question on that:\n  \n\n      github.com/weaviate/weaviate-python-client\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      GroupBy does not group under multiple properties\n    \n\n    \n      \n        opened 05:20PM - 08 Jun 23 UTC\n      \n\n        \n          closed 10:02AM - 07 Jul 23 UTC\n        \n\n      \n        \n          \n          aledelunap\n        \n      \n    \n\n    \n    \n  \n\n\n  \n    When passing a list of properties (containing more than one) to `with_group_by()…` the query execution results in an error. For example, with the final query being:\n\n```\n{Get{Class(nearText: {concepts: [\"credit card\"]} groupBy:{path:[\"product_group\",\"product_name\"], groups:3, objectsPerGroup:2}){_additional {\n        group {\n          hits{\n            section_title\n            information_type\n            content\n            _additional {\n                  id\n                }\n          }\n        }\n       id }}}}\n```\n\nThe execution returns the following error:\n\n```\n{'data': {'Get': {'Class': None}},\n 'errors': [{'locations': [{'column': 6, 'line': 1}],\n   'message': \"explorer: get class: vector search: object vector search at index Index: shard Index_: no such prop with name '' found in class 'Class' in the schema. Check your schema files for which properties in this class are available: unrecognized property: \",\n   'path': ['Get', 'Class']}]}\n```\n\nIt works well when passing a single property, but crashes when adding multiple.\n\nThe function docstring states the following: \n```\nproperties: List[str]\n    Properties to group by\n```\nMeaning it should support multiple properties.\n\nAm I missing something in how to correctly use `with_group_by()`?\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!",
    "date_created": "2024-09-05T15:33:55.471Z",
    "has_accepted_answer": false,
    "title": "Aggregation over multiple properties in python",
    "topic_id": 3987
  },
  {
    "user_id": 3216,
    "conversation": "[srbk95 (2025-01-14T13:34:46.184Z)]: Description\nHi,\nI’ve noticed that when using the text2vec-contextionary, one can add custom words or abbreviations (referred to as “concepts”) through the v1/modules/text2vec-contextionary/extensions/ endpoint. However, I am not utilizing the Contextionary model in my implementation.\nI am already using Hybrid Search. Hence, the only solution I’ve identified is to fine-tune the embedding model I’m using to better capture the context and meaning of these abbreviations. While this approach seems promising, I’m wondering if there are any alternative methods or best practices within Weaviate that could help with this issue.\nHas anyone faced a similar challenge or found effective ways to handle abbreviations in their embeddings without relying on Contextionary? Any insights or suggestions would be greatly appreciated!\n\n----------\n\n[DudaNogueira (2025-01-27T21:48:17.533Z)]: hi @srbk95 !!\nWelcome to our community \nSorry for the delay here.\nThat’s an interesting question.\nThe text2vec-contextionary is really not being used according to some stats we have, so I don’t think that’s an interesting path to follow.\nfine tuning your model may be a long and expensive path.\nOne alternative way I can think of is to create your own collection of abbreviations. Before performing the hybrid search, you will search that abbreviation collection and add the most relevant abbreviations to the prompt. \nAnother alternative is to add those abbreviations before ingesting the content…\nAny way, let me know if you were able to come with some alternatives.\nThanks!",
    "date_created": "2025-01-14T13:34:46.125Z",
    "has_accepted_answer": false,
    "title": "How to best handle domain specific acronyms/abbreviations?",
    "topic_id": 9746
  },
  {
    "user_id": 511,
    "conversation": "[shadowlin (2024-03-06T10:37:39.631Z)]: Description\nIf use or operator to combine filter for many times there will be a error like below happens:\nweaviate/collections/grpc/query.py\", line 572, in __create_request\n    return search_get_pb2.SearchRequest(\ngoogle.protobuf.message.DecodeError: Error parsing message\n\ncode to reproduce is  kinda like below:\n    filters = Filter.by_property(\"code\").contains_any(\"1\")\n    count = 1\n\n    for code in range(500):\n        count += 1\n        filters |= Filter.by_property(\"code\").contains_any(str(code))\n\nServer Setup Information\n\nWeaviate Server Version: 1.24.1\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: python 4.5.1\n\nAny additional Information\nnone\n\n----------\n\n[DudaNogueira (2024-03-06T21:12:56.928Z)]: Hi!\nThis is interesting.\nI will try to come up with a notebook as it will be interesting to explore on dynamic filter building with the new pyv4.\nThanks for pointing out. I will get back to you soon.\n\n----------\n\n[DudaNogueira (2024-10-10T07:29:42.558Z)]: hi!\nSorry for the delay here \nI believe the error here is that the filter may be too big",
    "date_created": "2024-03-06T10:37:39.564Z",
    "has_accepted_answer": false,
    "title": "Error when use or operator to combine more than certain number of filters",
    "topic_id": 1636
  },
  {
    "user_id": 2981,
    "conversation": "[skuski (2024-12-07T14:38:40.228Z)]: Description\nI’m a fan of Verba and would like a way to handle upload, update, and error-handling of such tasks programmatically with a python script interacting directly with the weaviate docker at 8080, instead of via verba webui. Is there a way to make a light-weight wrapper around goldenverba/components/manager.py to do that please?\nThanks!\nServer Setup Information\n\nWeaviate Server Version: 1.27\nDeployment Method: docker compose\nMulti Node? Number of Running Nodes: single\nClient Language and Version: python3.12\nMultitenancy?: no\n\nAny additional Information\n\n----------\n\n[Edward_Schmuhl (2024-12-09T13:34:26.614Z)]: Hey! Thanks for your message \nUnfortunately, there’s no good way to handle Verba’s functionality programmatically right now. However, we’re planning on building a user-friendly endpoint that serves Verba through an API. This would allow you to handle all your stuff programmatically and also allow other frontend’s to use Verba’s functionality. I’ll let you know once we finish it\n\n----------\n\n[skuski (2024-12-10T07:36:11.470Z)]: Oh i see. Yeah API would be good too. Can’t wait to get to use it! Thx!\n\n----------\n\n[lindon (2025-01-14T15:20:51.441Z)]: I’m also interested in a programatic way to manage documents connected to verba. Specifically, I want the ability to set metadata fields for my documents (labels, link, etc.). I have a few hundred files (small) and it’s time consuming to manually label them all.",
    "date_created": "2024-12-07T14:38:40.169Z",
    "has_accepted_answer": true,
    "title": "[Verba] programmatic management of weaviate db",
    "topic_id": 9137
  },
  {
    "user_id": 893,
    "conversation": "[chua0332 (2024-05-07T01:30:43.665Z)]: Hey there,\nI am new to weaviate, and I just created an account. However, they were supposed to send a confirmation email to me. It has being a day, but I still gotten nothing. I have checked my spam folder, nothing over there too. Not sure if this is the right place to ask?\nRegards,\nEugene\n\n----------\n\n[chua0332 (2024-05-07T06:53:48.986Z)]: the confirmation email finally came -\n\n----------\n\n[DudaNogueira (2024-05-07T21:26:28.974Z)]: Hi @chua0332 !\nSorry for the inconvenience.\nGlad it sorted out!\nIf you face any other issues, let us know.\nWe are here to help!\nThanks!\n\n----------\n\n[obscur0x (2024-11-23T21:05:06.993Z)]: I’m currently having this issue. With a google email it works fine but with a proton email it takes hours to arrive and by the time I check it’s expired.\n\n----------\n\n[DudaNogueira (2024-11-25T18:56:16.623Z)]: hi @obscur0x !!\nWelcome to our community.\nSorry to hear that.\nLet me know if this is still the case. I saw other issue internally, but it was due to an error in our delivery email system.\nthanks!",
    "date_created": "2024-05-07T01:30:43.606Z",
    "has_accepted_answer": true,
    "title": "Confirmation email to create WCS",
    "topic_id": 2217
  },
  {
    "user_id": 2559,
    "conversation": "[David_Mane (2024-11-26T11:58:44.064Z)]: Description\nWe have the backup s3 module enabled and after some daily backup the memory usage increases, and it doesn’t release memory anymore. We already set env variable GOMEMLIMIT: 4GiB, but it seems no have any effect. We have only one collection with shard of 3 and replication of 2.\nFurthermore, we attach you a screenshoot of 7 days of Pod memory:\nCaptura de pantalla 2024-11-26 a las 12.29.021831×805 91.5 KB\nThese are environment variables set in pods:\nAWS_FORCE_PATH_STYLE : false\nBACKUP_S3_BUCKET : weaviate-backups\nBACKUP_S3_ENDPOINT : *******\nBACKUP_S3_USE_SSL : false\nCLUSTER_DATA_BIND_PORT : 7001\nCLUSTER_GOSSIP_BIND_PORT : 7000\nCLUSTER_JOIN : weaviate-headless.prod.svc.cluster.local.\nDEFAULT_VECTORIZER_MODULE : none\nENABLE_MODULES : backup-s3\nGOGC : 100\nGOMEMLIMIT : 4GiB\nPERSISTENCE_DATA_PATH : /var/lib/weaviate\nPROMETHEUS_MONITORING_ENABLED : true\nPROMETHEUS_MONITORING_GROUP : false\nQUERY_MAXIMUM_RESULTS : 100000\nRAFT_BOOTSTRAP_EXPECT : 3\nRAFT_BOOTSTRAP_TIMEOUT : 600\nRAFT_JOIN : weaviate-0,weaviate-1,weaviate-2\nREINDEX_VECTOR_DIMENSIONS_AT_STARTUP : false\nTRACK_VECTOR_DIMENSIONS : true\n\nServer Setup Information\n\nWeaviate Server Version: 1.27.0\nDeployment Method: K8S\nMulti Node? Number of Running Nodes: 3\nClient Language and Version:  Python V3\nMultitenancy?: disabled\n\nAny additional Information\nAnd the schema configuration:\n{\n  \"class\": \"Books\",\n  \"invertedIndexConfig\": {\n    \"bm25\": {\n      \"b\": 0.75,\n      \"k1\": 1.2\n    },\n    \"cleanupIntervalSeconds\": 60,\n    \"stopwords\": {\n      \"additions\": null,\n      \"preset\": \"en\",\n      \"removals\": null\n    }\n  },\n  \"multiTenancyConfig\": {\n    \"autoTenantActivation\": false,\n    \"autoTenantCreation\": false,\n    \"enabled\": false\n  },\n  \"properties\": [\n    {\n      \"dataType\": [\n        \"text\"\n      ],\n      \"indexFilterable\": true,\n      \"indexRangeFilters\": false,\n      \"indexSearchable\": true,\n      \"name\": \"text\",\n      \"tokenization\": \"word\"\n    },\n    {\n      \"dataType\": [\n        \"number\"\n      ],\n      \"indexFilterable\": true,\n      \"indexRangeFilters\": false,\n      \"indexSearchable\": false,\n      \"name\": \"bookId\"\n    }\n  ],\n  \"replicationConfig\": {\n    \"asyncEnabled\": false,\n    \"deletionStrategy\": \"DeleteOnConflict\",\n    \"factor\": 2\n  },\n  \"shardingConfig\": {\n    \"actualCount\": 3,\n    \"actualVirtualCount\": 384,\n    \"desiredCount\": 3,\n    \"desiredVirtualCount\": 384,\n    \"function\": \"murmur3\",\n    \"key\": \"_id\",\n    \"strategy\": \"hash\",\n    \"virtualPerPhysical\": 128\n  },\n  \"vectorIndexConfig\": {\n    \"bq\": {\n      \"enabled\": false\n    },\n    \"cleanupIntervalSeconds\": 300,\n    \"distance\": \"cosine\",\n    \"dynamicEfFactor\": 8,\n    \"dynamicEfMax\": 500,\n    \"dynamicEfMin\": 100,\n    \"ef\": -1,\n    \"efConstruction\": 128,\n    \"filterStrategy\": \"sweeping\",\n    \"flatSearchCutoff\": 40000,\n    \"maxConnections\": 32,\n    \"pq\": {\n      \"bitCompression\": false,\n      \"centroids\": 256,\n      \"enabled\": false,\n      \"encoder\": {\n        \"distribution\": \"log-normal\",\n        \"type\": \"kmeans\"\n      },\n      \"segments\": 0,\n      \"trainingLimit\": 100000\n    },\n    \"skip\": false,\n    \"sq\": {\n      \"enabled\": false,\n      \"rescoreLimit\": 20,\n      \"trainingLimit\": 100000\n    },\n    \"vectorCacheMaxObjects\": 1000000000000\n  },\n  \"vectorIndexType\": \"hnsw\",\n  \"vectorizer\": \"none\"\n}\n\n----------\n\n[DudaNogueira (2024-11-26T19:39:06.875Z)]: hi @David_Mane !!\nWelcome to our community \nThere is an open issue on that, and our team has it on it’s radar:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Memory increases on each backup\n    \n\n    \n      \n        opened 02:45PM - 05 Sep 24 UTC\n      \n\n\n      \n        \n          \n          adrianrico-cy\n        \n      \n    \n\n    \n        \n          bug\n        \n    \n  \n\n\n  \n    ### How to reproduce this bug?\n\nRun a backup and when it's going to finish it ra…ises the memory usage and sticks on that.\n\n### What is the expected behavior?\n\nNot to increment memory on each backup performed.\n\n### What is the actual behavior?\n\nEach time a backup is run the memory increases.\n\n### Supporting information\n\n_No response_\n\n### Server Version\n\n1.26.3\n\n### Code of Conduct\n\n- [X] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nOne options to mitigate this is to tweak the cpuPercentage.\nLet me know if this helps!\n\n----------\n\n[David_Mane (2024-11-27T06:34:44.520Z)]: Hi @DudaNogueira ,\nThank you for the quick response and for confirming that the issue is on the team’s radar. I’ll look into tweaking the cpuPercentage setting as a mitigation and see if it improves the situation.\nI appreciate the support and will keep an eye on updates regarding this issue. Thanks again for the suggestion!",
    "date_created": "2024-11-26T11:58:44.008Z",
    "has_accepted_answer": false,
    "title": "Memory Leak with S3 backup module: Memory Usage Remains High After Backups",
    "topic_id": 8315
  },
  {
    "user_id": 3146,
    "conversation": "[Bohdan_Klishchov (2025-01-04T19:16:58.405Z)]: My collections:\n            \"Short\",\n            properties=[\n                Property(\n                    name=ShortProps.ID.value,\n                    data_type=DataType.INT,\n                    description=\"Unique identifier for the short.\",\n                    skip_vectorization=True,\n                ),\n                Property(\n                    name=ShortProps.HASH_NAME.value,\n                    data_type=DataType.TEXT,\n                    description=\"Unique content hash name for the short.\",\n                    skip_vectorization=True,\n                ),\n                Property(\n                    name=ShortProps.DESCRIPTION.value,\n                    data_type=DataType.TEXT,\n                    description=\"Short description of the content.\",\n                ),\n                Property(\n                    name=ShortProps.CATEGORY.value,\n                    data_type=DataType.TEXT,\n                    description=\"Category of the short.\",\n                ),\n                Property(\n                    name=ShortProps.CONTENT.value,\n                    data_type=DataType.BLOB,\n                    description=\"Content of the short (e.g., video, image).\"\n                ),\n            ],\n            vectorizer_config=[\n                # Set a named vector\n                Configure.NamedVectors.multi2vec_bind(\n                    name=\"shorts_vec\",\n                    text_fields=[\n                        Multi2VecField(name=ShortProps.DESCRIPTION.value, weight=0.3),\n                        Multi2VecField(name=ShortProps.CATEGORY.value, weight=0.2),\n                    ],\n                    # video_fields=[\n                    #     Multi2VecField(name=ShortProps.CONTENT.value, weight=0.5),\n                    # ],\n                ),\n            ],\n        )\n\n        await cls.client.collections.create(\n            \"UserInteractions\",\n            properties=[\n                Property(\n                    name=UserInteractionsProps.ID.value,\n                    data_type=DataType.INT,\n                    description=\"Unique identifier for the user.\"\n                ),\n            ],\n            references=[\n                ReferenceProperty(\n                    name=UserInteractionsProps.LIKED_SHORTS.value,\n                    target_collection=\"Short\",\n                    description=\"Short which liked by current user\",\n                ),\n            ],\n            vectorizer_config=[\n                Configure.NamedVectors.ref2vec_centroid(\n                    name=\"liked_vector\",\n                    reference_properties=[\n                        UserInteractionsProps.LIKED_SHORTS.value,\n                    ],\n                ),\n            ],\n        )\n\nI tried add cross-references like this:\nasync def create_interaction(\n        self,\n        user_interactions_uuid: UUID,\n        short_uuid: UUID,\n        interaction_type: InteractionType,\n    ) -> None:\n        await self.collection.data.reference_add(\n            from_uuid=user_interactions_uuid,\n            from_property=interaction_type_property[interaction_type.value],\n            to=short_uuid\n        )\n\nbut got object with empty vector:\nObject(uuid=_WeaviateUUIDInt('ede63ad5-ae6b-4041-be34-1db9864177c7'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'object_id': 2}, references={'liked_shorts': <weaviate.collections.classes.internal._CrossReference object at 0x75f4bf33ae10>}, vector={'liked_vector': []}, collection='UserInteractions')\n\n----------\n\n[DudaNogueira (2025-01-06T14:08:34.954Z)]: hi @Bohdan_Klishchov !!\nWelcome to our community \nCan you share a full running code? This has proven more efficient to discover this kind of issue as sometimes the issue is on underlying code that is not share \nHere we have a set of recipes here, that can serve as base for this:\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate/recipes: This repository shares end-to-end notebooks on how...\n\n    This repository shares end-to-end notebooks on how to use various Weaviate features and integrations!\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI have searched, and there isn’t a recipe for ref2vec-centroid \nMaybe we can create one \nThanks!\n\n----------\n\n[Bohdan_Klishchov (2025-01-06T15:31:26.917Z)]: hello @DudaNogueira\nI simplified my code:\nimport asyncio\n\nimport weaviate\nfrom weaviate.classes.config import Configure\nfrom weaviate.client import WeaviateAsyncClient\nfrom weaviate.collections.classes.grpc import QueryReference\nfrom weaviate.collections.classes.config_vectorizers import Multi2VecField\nfrom weaviate.collections.classes.config import Property, DataType, ReferenceProperty\n\nfrom core.settings import get_settings\n\nsettings = get_settings()\n\n\nasync def init_collections(client: WeaviateAsyncClient):\n\n    if await client.collections.exists('Short'):\n        return\n    if await client.collections.exists('UserInteractions'):\n        return\n    await client.collections.create(\n        \"Short\",\n        properties=[\n            Property(\n                name='object_id',\n                data_type=DataType.INT,\n                description=\"Unique identifier for the short.\",\n                skip_vectorization=True,\n            ),\n            Property(\n                name='description',\n                data_type=DataType.TEXT,\n                description=\"Short description of the content.\",\n            ),\n            Property(\n                name='category',\n                data_type=DataType.TEXT,\n                description=\"Category of the short.\",\n            ),\n        ],\n        vectorizer_config=[\n            # Set a named vector\n            Configure.NamedVectors.multi2vec_bind(\n                name=\"shorts_vec\",\n                text_fields=[\n                    Multi2VecField(name='description', weight=0.6),\n                    Multi2VecField(name='category', weight=0.4),\n                ]\n            ),\n        ],\n    )\n\n    await client.collections.create(\n        \"UserInteractions\",\n        properties=[\n            Property(\n                name='object_id',\n                data_type=DataType.INT,\n                description=\"Unique identifier for the user.\"\n            ),\n        ],\n        references=[\n            ReferenceProperty(\n                name='liked_shorts',\n                target_collection=\"Short\",\n                description=\"Short which liked by current user\",\n            ),\n        ],\n        vectorizer_config=Configure.Vectorizer.ref2vec_centroid(\n            reference_properties=[\n                'liked_shorts'\n            ]\n        ),\n    )\n\n\nasync def main():\n    client: WeaviateAsyncClient = weaviate.use_async_with_local(\n        host=settings.WEAVIATE_HOST,\n        port=settings.WEAVIATE_PORT,\n        skip_init_checks=True\n    )\n    await client.connect()\n    try:\n        await init_collections(client=client)\n\n        short_collection = client.collections.get('Short')\n        user_collection = client.collections.get('UserInteractions')\n\n        short_uuid = await short_collection.data.insert(properties={\n            'object_id': 1,\n            'description': 'description1',\n            'category': 'category1'\n        }, uuid=uuid.uuid4())\n        print(f'created short: {short_uuid}')\n\n        user_uuid = await user_collection.data.insert(properties={'object_id': 1}, uuid=uuid.uuid4())\n        print(f'created user: {user_uuid}')\n\n        # creating cross-reference\n        await user_collection.data.reference_add(\n            from_uuid=user_uuid,\n            from_property='liked_shorts',\n            to=short_uuid\n        )\n\n        resp = await user_collection.query.fetch_object_by_id(\n            uuid=user_uuid,\n            include_vector=True,\n            return_references=QueryReference(\n                link_on='liked_shorts',\n                return_properties=[\"object_id\"],\n            ),\n        )\n\n        print(resp)\n\n    finally:\n        await client.close()\n\nif __name__ == '__main__':\n    asyncio.run(main())\n\ngot this output:\ncreated short: 09e06d77-a1f6-4274-b0ae-485f532322fd\ncreated user: 0c6ff736-ef4a-45e9-9e34-93ff67a53dfe\nObjectSingleReturn(uuid=_WeaviateUUIDInt('0c6ff736-ef4a-45e9-9e34-93ff67a53dfe'), metadata=MetadataSingleObjectReturn(creation_time=datetime.datetime(2025, 1, 6, 15, 20, 12, 837000, tzinfo=datetime.timezone.utc), last_update_time=datetime.datetime(2025, 1, 6, 15, 20, 12, 840000, tzinfo=datetime.timezone.utc), is_consistent=None), properties={'object_id': 1}, references={'liked_shorts': <weaviate.collections.classes.internal._CrossReference object at 0x7c28da11e610>}, vector={}, collection='UserInteractions')\n\n\ni use python 3.11 and weaviate-client 4.9.6\nfor me asynchronicity is important, so I can’t downgrade to the old 3rd client, where it is not supported, even if there are more examples\nthank you for your reply\np.s. I’m working on a recommendation system",
    "date_created": "2025-01-04T19:16:58.328Z",
    "has_accepted_answer": false,
    "title": "Empty vector when adding cross references (ref2vec-centroid)",
    "topic_id": 9564
  },
  {
    "user_id": 1573,
    "conversation": "[Rajan_Kumar_Soni (2024-09-22T23:49:52.410Z)]: how to configure corporate modified base url of openAI in weaviate client\n\n----------\n\n[sebawita (2024-09-23T08:35:52.918Z)]: Hi Rajan,\nOpenAI\nTo access corporate hosted service by OpenAI,\nYou can do it with base_url in the vectorizer configuration (see docs for all config options)\nWith classic vectorizer\nfrom weaviate.classes.config import Configure\n\nclient.collections.create(\n    name=\"DemoCollection\",\n\n    vectorizer_config=Configure.Vectorizer.text2vec_openai(\n        model=\"text-embedding-3-small\",\n        base_url=\"<custom_openai_url>\",\n    ),\n)\n\nWith named vectorizer\nfrom weaviate.classes.config import Configure\n\nclient.collections.create(\n    \"DemoCollection\",\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_openai(\n            name=\"title_vector\",\n            source_properties=[\"title\", \"description\"], # properties to vectorize\n            model=\"text-embedding-3-small\",\n            base_url=\"<custom_openai_url>\",\n        )\n    ],\n)\n\nAzure\nIf your OpenAI models are hosted on Azure.\nThen your code should look like this (see docs):\nWith classic vectorizer\nfrom weaviate.classes.config import Configure\n\nclient.collections.create(\n    name=\"DemoCollection\",\n\n    vectorizer_config=Configure.Vectorizer.text2vec_azure_openai(\n            deployment_id=\"text-embedding-3-small\",\n\n            resource_name=\"<azure-resource-name>\", \n            base_url=\"<custom_openai_url>\",\n    ),\n)\n\nWith named vectorizer\nfrom weaviate.classes.config import Configure\n\nclient.collections.create(\n    \"DemoCollection\",\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_azure_openai(\n            name=\"title_vector\",\n            source_properties=[\"title\", \"description\"], # properties to vectorize\n            deployment_id=\"text-embedding-3-small\",\n\n            resource_name=\"<azure-resource-name>\", \n            base_url=\"<custom_openai_url>\",\n        )\n    ],\n)\n\n----------\n\n[DudaNogueira (2024-09-23T08:44:26.582Z)]: hi @Rajan_Kumar_Soni !!\nWelcome to our community!\nAlso notice that you can set this value at query time too, like so:\nclient = weaviate.connect_to_local(\n    headers={\n        \"X-OpenAI-BaseURL\": \"http://your-custom-openai-endpoint.com\"\n    }\n)",
    "date_created": "2024-09-22T23:49:52.368Z",
    "has_accepted_answer": false,
    "title": "How to configure corporate modified base url of openAI in weaviate client",
    "topic_id": 4253
  },
  {
    "user_id": 11726,
    "conversation": "[Zen_Tang (2025-03-22T23:21:40.260Z)]: Query Latency\nHi folks!\nI’m using Weaviate on the cloud, and I’m getting query latencies like this… does anyone have anything they suggest to do?\nimage1384×984 152 KB\nI mostly just stuck with the “bare minimum” (Ie, tutorial level) to see what would happen!\n\nMy collection is just a bunch of text jfk_files/jfk_text at main · amasad/jfk_files · GitHub\nI generated summaries of each of the text items (~1000 tokens for each doc)\nI just used default embeddings (openai 1536-dimensional one)\nThere’s only ~1000 documents (~2-3k if i break them up into chunks)\n\nDebugging details\nCluster size & region\n\nSandbox cluster (I tried US East and US West), and it didn’t really make a difference\nI upgraded to “Serverless” but that didn’t seem to improve it either\n\nThings I tried\n\nSwitch to “Flat” indexing (vector_index_config=Configure.VectorIndex.flat(),) – the latency is about the same though\n\nCollection Config\nCollection found: <weaviate.Collection config={\n  \"name\": \"DocSummaries7_hnsw\",\n  \"description\": null,\n  \"generative_config\": null,\n  \"inverted_index_config\": {\n    \"bm25\": {\n      \"b\": 0.75,\n      \"k1\": 1.2\n    },\n    \"cleanup_interval_seconds\": 60,\n    \"index_null_state\": false,\n    \"index_property_length\": false,\n    \"index_timestamps\": false,\n    \"stopwords\": {\n      \"preset\": \"en\",\n      \"additions\": null,\n      \"removals\": null\n    }\n  },\n  \"multi_tenancy_config\": {\n    \"enabled\": false,\n    \"auto_tenant_creation\": false,\n    \"auto_tenant_activation\": false\n  },\n  \"properties\": [\n    {\n      \"name\": \"title\",\n      \"description\": null,\n      \"data_type\": \"text\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": true,\n      \"nested_properties\": null,\n      \"tokenization\": \"word\",\n      \"vectorizer_config\": {\n        \"skip\": false,\n        \"vectorize_property_name\": true\n      },\n      \"vectorizer\": \"text2vec-openai\",\n      \"vectorizer_configs\": null\n    },\n    {\n      \"name\": \"content\",\n      \"description\": null,\n      \"data_type\": \"text\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": true,\n      \"nested_properties\": null,\n      \"tokenization\": \"word\",\n      \"vectorizer_config\": {\n        \"skip\": false,\n        \"vectorize_property_name\": true\n      },\n      \"vectorizer\": \"text2vec-openai\",\n      \"vectorizer_configs\": null\n    }\n  ],\n  \"references\": [],\n  \"replication_config\": {\n    \"factor\": 1,\n    \"async_enabled\": false,\n    \"deletion_strategy\": \"NoAutomatedResolution\"\n  },\n  \"reranker_config\": null,\n  \"sharding_config\": {\n    \"virtual_per_physical\": 128,\n    \"desired_count\": 1,\n    \"actual_count\": 1,\n    \"desired_virtual_count\": 128,\n    \"actual_virtual_count\": 128,\n    \"key\": \"_id\",\n    \"strategy\": \"hash\",\n    \"function\": \"murmur3\"\n  },\n  \"vector_index_config\": {\n    \"multi_vector\": null,\n    \"quantizer\": null,\n    \"cleanup_interval_seconds\": 300,\n    \"distance_metric\": \"cosine\",\n    \"dynamic_ef_min\": 100,\n    \"dynamic_ef_max\": 500,\n    \"dynamic_ef_factor\": 8,\n    \"ef\": -1,\n    \"ef_construction\": 128,\n    \"filter_strategy\": \"sweeping\",\n    \"flat_search_cutoff\": 40000,\n    \"max_connections\": 32,\n    \"skip\": false,\n    \"vector_cache_max_objects\": 1000000000000\n  },\n  \"vector_index_type\": \"hnsw\",\n  \"vectorizer_config\": {\n    \"vectorizer\": \"text2vec-openai\",\n    \"model\": {\n      \"baseURL\": \"https://api.openai.com\",\n      \"isAzure\": false,\n      \"model\": \"text-embedding-3-small\"\n    },\n    \"vectorize_collection_name\": true\n  },\n  \"vectorizer\": \"text2vec-openai\",\n  \"vector_config\": null\n}>\n\nI tried to keep it as simple as possible:\nself.client.collections.create(\n      name,\n      vectorizer_config=Configure.Vectorizer.text2vec_openai(),\n      # vector_index_config=Configure.VectorIndex.flat(),\n      properties=[  # properties configuration is optional\n      Property(name=\"title\", data_type=DataType.TEXT),\n      Property(name=\"content\", data_type=DataType.TEXT),\n     ],\n)\n\nOther tags:\nslow, semantic search, hybrid search\n\n----------\n\n[Joe (2025-03-24T16:08:05.583Z)]: Hey Zen,\nHappy to help here!   There are definitely some unknowns I’d like to clarify:\n\n\nCould you provide a snippet of the query being used? (I imagine if it’s just tutorial level stuff we shouldn’t see spikes in latency like this)\n\n\nHow are you hosting your function,  is it a cloud function or are you running it locally?  ( If it’s a cloud function what region is it hosted in, and if it’s locally can you confirm where you are connecting from?)\n\n\nYou also mentioned that you tried this on both sandboxes and a Serverless cluster,  I’d love to doublecheck that cluster but I don’t want to share any sensitive info openly on our forum.    Would you be able to create a ticket with our support by emailing these details to Support@weaviate.io?  We can then continue this conversation in that ticket, and any public solution I can post back here if needed!\nRegards,\nJoe\n\n----------\n\n[Zen_Tang (2025-03-24T17:21:57.806Z)]: Hi Joe!\nI’m just running it locally on my computer.\nMy query code looks like this!\n@timer_decorator\ndef semantic_search(self, query, limit=10):\n    response = self.collection.query.near_text(\n        query=query,\n        limit=limit,\n        # return_metadata=MetadataQuery(distance=True, score=True),\n    )\n    return response\n\n----------\n\n[Zen_Tang (2025-03-24T17:25:18.000Z)]: Hi Joe!\nThanks for helping! Here’s the details!\nEndpoint: https://9p6vscwpqlgxuawurcupaq.c0.us-east1.gcp.weaviate.cloud\nCollection name: DocSummaries7_flat/DocSummaries7_hnsw\nimage.png2816×1884 395 KB",
    "date_created": "2025-03-22T23:21:40.208Z",
    "has_accepted_answer": false,
    "title": "Help me fix this 500ms latency for vector search!",
    "topic_id": 20218
  },
  {
    "user_id": 8921,
    "conversation": "[Daniel_Engelhardt (2025-03-09T09:44:56.883Z)]: Hi!\nI tried to leverage the full RAG-functionality of weaviate-cloud. I could not get any results with the JS-SDK, using my anthropic API-key in the respective header. Instead I received the following Error:\nWeaviateQueryError: Query call with protocol gRPC failed with message: /weaviate.v1.Weaviate/Search UNKNOWN: explorer: get class: concurrentTargetVectorSearch): explorer: get class: extend: extend generate: client not found, empty provider\n    at <anonymous> (/xxx/node_modules/.pnpm/weaviate-client@3.4.0_encoding@0.1.13/node_modules/weaviate-client/dist/node/esm/grpc/searcher.js:46:19)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n\nApart from that I could easily perform embeddings and hybrid search, so RAG seems the culprit here. I tried both, the REST and the grpc Endpoint, because the documentation does not clarify which one to use. Using the grpc endpoint resulted in this error:\nWeaviateStartUpError: Weaviate startup failed with message: Weaviate failed to startup with message: The request to Weaviate failed with status code: 415 and message:\n    at <anonymous> (/xxx/node_modules/.pnpm/weaviate-client@3.4.0_encoding@0.1.13/node_modules/weaviate-client/dist/node/esm/connection/helpers.js:52:11)\n\nCan somebody tell me what’s going on here?\nThank you!\n\n----------\n\n[malgamves (2025-03-09T10:02:09.709Z)]: Hey there, could you share snippets of your connection function (with headers included) and the code that produces these errors? What Weaviate and JS client version are you using?\n\n----------\n\n[Daniel_Engelhardt (2025-03-09T10:25:57.458Z)]: Hi,\nclient version: 3.4.0,\nweaviate cloud database version(sandbox): 1.29.0,\nI connect with this call:\n this.client = await weaviate.connectToWeaviateCloud(this.url, {\n authCredentials: 'XYZ',\n      headers: {\n        'X-Anthropic-Api-Key':\n          'XXX',\n      },\n    });\n\nthe throwing code looks like this:\nconst results = await this.client.collections\n      .get('collection')\n      .withTenant('tenantX');.generate.nearText(\n      'query',\n      {\n        groupedTask: 'xxx',\n      },\n      {\n        limit: 10,\n      },\n    );\n\nThank you for looking into this!\n\n----------\n\n[malgamves (2025-03-10T09:49:32.016Z)]: From the error you have, it looks like you might have misconfigured your collection.\nDid you include the generative anthropic module or a vectorizer module??\nThe snippet you shared (minus the “;” before generate) worked for me with this collection configuration.\nawait client.collections.create({\n      name: 'Collection',\n      // Define your vectorizer and Anthropic generative model\n      vectorizers: weaviate.configure.vectorizer.text2VecOpenAI({\n        sourceProperties: ['title','text']\n      }),\n      generative: weaviate.configure.generative.anthropic(),\n      multiTenancy: weaviate.configure.multiTenancy({enabled: true, autoTenantCreation: true})\n    });\n\nLet me know if any of these fix the issue for you.\n\n----------\n\n[Daniel_Engelhardt (2025-03-10T10:27:36.417Z)]: Sorry for the ;! That’s just a typo originating in me trying to generalise my code for this thread.\nThe  vectorizers-property was configured as suggested by you, but I actually missed that I have to configure my collection to use a generative model too. My bad, thank you very much for bringing that up.\nMaybe a more prominent hint on collection-configuration in the Rag Documentation and a more verbose ErrorMessage would improve the DX here!\n\n----------\n\n[malgamves (2025-03-10T14:53:07.501Z)]: I figured, i only pointed it (;) out incase that was an error waiting to happen \nHappy it worked, thanks for the feedback on the docs, we do have a drop down pointing users to a page that details the required config for RAG, do you think we could do more to make it more obvious?\n\n----------\n\n[Daniel_Engelhardt (2025-03-11T07:24:37.538Z)]: Maybe just pin a minimal collection config on top with all properties that are required for RAG.\nBut an error message stating that the collection misses a generative AI model would be most helpful.\nThank you",
    "date_created": "2025-03-09T09:44:56.834Z",
    "has_accepted_answer": true,
    "title": "RAG not working with Anthropic Key and JS-SDK",
    "topic_id": 17146
  },
  {
    "user_id": 615,
    "conversation": "[D3x (2024-02-23T04:33:24.164Z)]: @DudaNogueira I thought I would create a new thread for this issue rather than hijacking New OpenAI Embedding Models - #21 by SomebodySysop\nThe problem statement is that once a weaviate server is configured with an OpenAI vectorizer using the new model of text-embedding-3-large and dimensions of 1024, hybrid queries fails with a vector search: vector lengths don't match: 1024 vs 3072 error message upon a server reboot.\nI was able to replicate this issue on codesandbox. This is using Weaviate v1.23.10 and python client 4.4.4.\nSteps to reproduce\n\nhttps://codesandbox.io/p/sandbox/interesting-morse-hgvggd\nSign-in using SSO of choice\nOpen up setup.py and query.py and update line 16 with an OpenAI API Key.  As this is being done codesandbox will “seamlessly fork” to your own private sandbox. If the URL does not change, you may have to go back to the dashboard CodeSandbox, go to My drafts, and open the newly created sandbox.\nGo to top left corner and select the “Restart Devbox” option. This should trigger sandbox initialization. Wait for container to be started and the pip -r requirements.txt job to complete.\nOpen up a new terminal in the center bottom pane.\nRun the following in sequence:\n\n\n\ndocker compose down -v\n\n\ndocker compose up -d\n\n\npython setup.py\n\n\npython query.py\nNote the following:\n\nsetup.py creates a collection and inserts a single object\nThe single object we stored in weaviate has a vector length of 1024, indicating vectorizer is working properly\nWe can fetch that object from weaviate, confirming that the inserted object is persisted\nWe can hybrid query from weaviate\n\n\n\n\nNow run:\n\n\ndocker compose restart\npython query.py\n\nAll we’ve done here is restart the weaviate container. Notice now that we can still fetch the inserted object (see output above the exception output), but now hybrid query fails with a vector length not matching error.\n\n----------\n\n[DudaNogueira (2024-02-23T12:21:24.534Z)]: Hi @D3x !\nThanks for reporting.\nI will try to reproduce this on my end and get back to you!\n\n----------\n\n[D3x (2024-02-27T21:50:08.257Z)]: Hi @DudaNogueira were you able to reproduce this given the instructions?\n\n----------\n\n[DudaNogueira (2024-02-28T13:17:16.584Z)]: Hi! Sorry, I couldn’t get to it yet.\nhave you tried running this locally?\nThose sandboxes usually has a lot of limitations that may affect it, so removing that component may give us a hint if the issue is on there on in the server.\n\n----------\n\n[D3x (2024-02-29T04:07:41.007Z)]: @DudaNogueira yes this is reproducible locally.\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nGitHub - d3xtemp/weaviate-issue\n\n  Contribute to d3xtemp/weaviate-issue development by creating an account on GitHub.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThe same behaviors as I noted above persists. A simple server restart makes hybrid queries fail which seems like a fairly serious problem. Would appreciate your team’s attention on this asap.\n\n----------\n\n[DudaNogueira (2024-03-04T16:41:23.439Z)]: Hi D3x!\nSorry for the delay here.\nI was not able to reproduce this:\n❯ python3 setup.py\nUUID for new object created: 117a7993-a2aa-4847-9bd2-f69cbdac1160\nfetch_objects: 117a7993-a2aa-4847-9bd2-f69cbdac1160 (1024) | Properties: {‘text’: ‘Some data’}\nhybrid query: 117a7993-a2aa-4847-9bd2-f69cbdac1160 (1024) | Properties: {‘text’: ‘Some data’}\n❯ python3 query.py\nfetch_objects: 117a7993-a2aa-4847-9bd2-f69cbdac1160 (1024) | Properties: {‘text’: ‘Some data’}\nhybrid query: 117a7993-a2aa-4847-9bd2-f69cbdac1160 (1024) | Properties: {‘text’: ‘Some data’}\nCould we connect in Slack so I can take a closer look?\nThanks!\n\n----------\n\n[D3x (2024-12-17T23:41:40.430Z)]: Hi @DudaNogueira\nI’ve recently looked into upgrading our local setup to 1.28 but when validating it failed the same Hybrid Query issue again.  I recall it was resolved with your help on Slack, but I’m unable to view older messages to verify.\nI’ve refreshed the demo repo to reproduce the issue: GitHub - d3xtemp/weaviate-issue.  The local weaviate instance was initialized exactly as specified in the Weaviate docs Docker | Weaviate.  Also, the issue now does not require a server restart to be demonstrated.\nAgain, a quick explanation of the issue is that I’ve used OpenAI’s text-embedding-3-large embedding model with a dimension of 1024 to create a collection.  When I simply fetch objects from this collection, I can verify that these objects have a vector length of 1024 as expected.  However, when I attempt hybrid queries against this collection, I receive the error message below.\nError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n        status = StatusCode.UNKNOWN\n        details = \"explorer: get class: vector search: object vector search at index mycollection: shard mycollection_66Yf5V7XYzHQ: vector search: knn search: distance between entrypoint and query node: 1024 vs 1536: vector lengths don't match\"\n        debug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"explorer: get class: vector search: object vector search at index mycollection: shard mycollection_66Yf5V7XYzHQ: vector search: knn search: distance between entrypoint and query node: 1024 vs 1536: vector lengths don\\'t match\", grpc_status:2, created_time:\"2024-12-17T15:29:04.353870673-08:00\"}\"\n\nYour help to confirm this issue and orchestrate a fix is appreciated.\n\n----------\n\n[DudaNogueira (2024-12-17T23:45:57.160Z)]: hi @D3x !!\nWelcome back \nYou probably have your vectors stored with one dimensionality, and have the vectorizer of your collection configured to use different one.\nYou can get the collection configuration and check that:\ncollection.config.get().vectorizer_config\n\nThe solution here is to create a second collection (or on a different server), specifying the exact model and dimensions of your vectorized data, and migrate your data over.\nThere is a fairly easy migration guide here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Learn how to migrate data within Weaviate for easy data handling.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.\nThanks!\n\n----------\n\n[D3x (2024-12-18T00:23:34.513Z)]: Hi @DudaNogueira , I’m unclear what you’re suggesting.\nThe repo I provided you demonstrates the problem in a fresh instance of weaviate, creates a collection from scratch, inserts a few records, and then attempts to hybrid query.  No migration of data is needed to demonstrate the issue.\nIn weaviate-issue/setup.py at 7a9bfdd08791a33daad96c074c7fc2e90779c9a5 · d3xtemp/weaviate-issue · GitHub I’ve configured the vectorizer simply and yes with one dimensionality only.  In this simple case, shouldn’t I be able be hybrid query without issue whenever I use a reference to that same collection (i.e. client.collections.get(collection_name).query.hybrid())?\n\n----------\n\n[DudaNogueira (2024-12-18T14:11:32.965Z)]: Oh Right! sorry! completely missed the repo\nThis is indeed a  bug\n\nfor some reason, in this scenario, it is using the default module configuration.\nThis is the payload it will send:\nclient = weaviate.connect_to_local(\n    headers={\n         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\", \"CHANGE_ME\"),\n         \"X-OpenAI-BaseUrl\": \"https://webhook.site/beef60de-4d45-4c61-9928-b20fa619f91e\",\n    }\n)\ncollection = client.collections.get(\"Test\")\n\nresponse = collection.query.hybrid(\n    query=\"hybrid query with 1024 dimensions\",\n    alpha=0.75,\n    limit=5,\n    include_vector=True\n)\nfor obj in response.objects:\n    print(\n        f\"hybrid query: {obj.uuid} ({len(obj.vector['default'])}) | Properties: {obj.properties}\")\n    \n# we get this payload\npayload = {\n  \"input\": [\n    \"hybrid query with 1024 dimensions\"\n  ],\n  \"model\": \"text-embedding-3-small\",\n  \"dimensions\": 1536\n}\n\nI have raised it internally.\nThanks you very much  for raising this here.\n\n----------\n\n[D3x (2024-12-18T17:09:27.553Z)]: Thanks for confirming the issue!\nAssuming that we have no visibility into the status of the internal issues, I would appreciate it if you can provide an update when it’s resolved and which upcoming versions would contain the fix. We are eager to stay on top of the releases.\n\n----------\n\n[DudaNogueira (2024-12-18T19:15:04.046Z)]: Sure. Our team is already looking into this.\nAs soon as they confirm, I’ll open a github issue so we can keep track of it.\nI’ll update it here.\nThanks!\n\n----------\n\n[DudaNogueira (2024-12-18T20:16:26.035Z)]: hi @D3x !!\nThe issue is this one:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Hybrid search falling back to default vectorizer confs when dimensions is set\n    \n\n    \n      \n        opened 08:15PM - 18 Dec 24 UTC\n      \n\n\n      \n        \n          \n          dudanogueira\n        \n      \n    \n\n    \n        \n          bug\n        \n    \n  \n\n\n  \n    ### How to reproduce this bug?\n\nHere is a reproducible code:\n\n```python\nimpor…t os\nimport weaviate\nfrom weaviate import classes as wvc\nimport weaviate.error_msgs\nclient = weaviate.connect_to_local(\n    headers={\n         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\", \"CHANGE_ME\"),\n    }\n)\nprint(f\"Client: {weaviate.__version__}, Server: {client.get_meta().get('version')}\")\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(\n        model=\"text-embedding-3-large\",\n        dimensions=1024,\n        #type_=\"text\",\n        vectorize_collection_name=False\n    ),\n    properties=[\n        wvc.config.Property(\n            name=\"text\",\n            data_type=wvc.config.DataType.TEXT,\n            tokenization=wvc.config.Tokenization.WORD\n        )\n    ]\n)\n\n# Create a single object\nresponse = collection.data.insert(\n    properties={ \"text\": \"COVID-19 has many symptoms.\" }\n)\n\n# objects indeed has 1024 dimensions\nresponse = collection.query.fetch_objects(\n    limit=5,\n    include_vector=True\n)\nfor obj in response.objects:\n    print(\n        f\"fetch_objects: {obj.uuid} ({len(obj.vector['default'])}) | Properties: {obj.properties}\")\n    \n# you can perform a neartext\nresponse = collection.query.near_text(\n    query=\"hybrid query with 1024 dimensions\",\n    #alpha=0.75,\n    limit=5,\n    include_vector=True\n)\nfor obj in response.objects:\n    print(\n        f\"near text query: {obj.uuid} ({len(obj.vector['default'])}) | Properties: {obj.properties}\")\n    \n#but it fails to hybrid\ntry:\n    response = collection.query.hybrid(\n        query=\"hybrid query with 1024 dimensions\",\n        alpha=0.75,\n        limit=5,\n        include_vector=True\n    )\n    for obj in response.objects:\n        print(\n            f\"hybrid query: {obj.uuid} ({len(obj.vector['default'])}) | Properties: {obj.properties}\")\nexcept Exception as e:\n    print(\"ERROR!!!\", e)\n\n# if we close the client\nclient.close()\n\n# and point it to a catch endpoint\nclient = weaviate.connect_to_local(\n    headers={\n         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\", \"CHANGE_ME\"),\n         \"X-OpenAI-BaseUrl\": \"https://webhook.site/beef60de-4d45-4c61-9928-b20fa619f91e\",\n    }\n)\ncollection = client.collections.get(\"Test\")\n\nresponse = collection.query.hybrid(\n    query=\"hybrid query with 1024 dimensions\",\n    #alpha=0.75,\n    limit=5,\n    include_vector=True\n)\nfor obj in response.objects:\n    print(\n        f\"hybrid query: {obj.uuid} ({len(obj.vector['default'])}) | Properties: {obj.properties}\")\n    \n# we get this payload\npayload = {\n  \"input\": [\n    \"hybrid query with 1024 dimensions\"\n  ],\n  \"model\": \"text-embedding-3-small\",\n  \"dimensions\": 1536\n}\n```\n\n### What is the expected behavior?\n\nThe hybrid search should work. It should generate the query vectorization payload as:\n\n```json\n{\n  \"input\": [\n    \"hybrid query with 1024 dimensions\"\n  ],\n  \"model\": \"text-embedding-3-large\",\n  \"dimensions\": 1024\n}\n```\n\n### What is the actual behavior?\n\nThe generated payload to vectorize a hybrid query is passing the wrong model and dimension as the payload:\n\n```json\n{\n  \"input\": [\n    \"hybrid query with 1024 dimensions\"\n  ],\n  \"model\": \"text-embedding-3-small\",\n  \"dimensions\": 1536\n}\n```\n\n### Supporting information\n\nClient: 4.10.2, Server: 1.28.1\n\n### Server Version\n\n1.28.1\n\n### Weaviate Setup\n\nSingle Node\n\n### Nodes count\n\n1\n\n### Code of Conduct\n\n- [X] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n\n----------\n\n[franciscoracosta (2025-01-08T11:30:14.976Z)]: Any updates on this? Issue seems to be on server version 1.28 and in weaviate cloud it’s not possible to select a prior version\n\n----------\n\n[Jose-Coutinho_cmore (2025-01-08T11:31:48.450Z)]: Hello @DudaNogueira,\nWhat is the status or the bug fix?\nWe are attempting to deploy our application using the paid serverless option, but the server version is locked to 1.28.2 (we can’t use the 1.27.0 we used to test locally) and are therefore unable to deploy anything!!\nPlease let me know if you have any suggestion to go around this issue, even if its temporary.\n\n----------\n\n[DudaNogueira (2025-01-08T13:58:23.508Z)]: hi there @Jose-Coutinho_cmore !! Welcome to our community \nThis seems like a popular issue \nI have pinged our team again so we can prio this.\nThanks!",
    "date_created": "2024-02-23T04:33:24.114Z",
    "has_accepted_answer": false,
    "title": "Hybrid Queries on new OpenAI Embedding Models failing server restart",
    "topic_id": 1551
  },
  {
    "user_id": 2699,
    "conversation": "[jaehyoyoo (2024-11-26T05:15:48.329Z)]: Hi, I have a question about vectorCacheMaxObjects. It seems that the memory held by weaviate can be controlled by vectorCacheMaxObjects. Is this a queue-like structure where vectors are updated in the most recent order? Also, I’m curious about the process of which vectors are prioritized in memory when the weaviate server is rebooted.\nI’m also curious about how weaviate’s memory is driven, because once it reach the maximum memory limit set in kubernetes, it won’t be able to create any more caches, and I’m wondering how weaviate behaves in that case.\nAnd finally, if \bI want to limit the maximum size of memory that the weaviate server can hold to 24 gigabytes (not by the number of vectors), I’m wondering if there are other arguments I could utilize.\n\n----------\n\n[DudaNogueira (2024-11-26T20:05:56.938Z)]: hi @jaehyoyoo !!\nWelcome to our community \nConsidering our docs on that subject, indeed vectorCacheMaxObjects has a direct impact on memory usage.\nIf you have more objects than vectorCacheMaxObjects, a disk lookup will be necessary, making your database less performant.\nWhen you restart, Weaviate will fill in that cache, so following searches will be faster. Whenever that cache fills up, Weaviate will drop it, and start replacing it as requested.\nIf you want to control the memory Weaviate uses at the memory level, you need to change the value of GOMEMLIMIT, as described here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nEnvironment variables | Weaviate\n\n  To configure Weaviate in a Docker or a Kubernetes deployment, set these environment variables\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWe have this nice article that do a deep dive into GOMEMLIMIT in Weaviate:GOMEMLIMIT is a game changer for high-memory applications | Weaviate\nLet me know if this helps!\nThanks!",
    "date_created": "2024-11-26T05:15:48.287Z",
    "has_accepted_answer": false,
    "title": "[Question] About vectorCacheMaxObjects mechanism",
    "topic_id": 8235
  },
  {
    "user_id": 2464,
    "conversation": "[accorrea1-stf (2024-11-05T15:04:14.808Z)]: Description\nI’m geting an unexpected result running a near_vector search on my Weaviate database.\nThe database contains 570 objects.\nRunning a near vector query, using limit 3, I receive 3 wrong objects, the lowest distance being 0.6878337.\nRunning the exact same query without the limit parameter, the result is 100 objects, and the lowest distance is 0.5604408.\nIt seem’s that the query does not search on the full database. Is this the behavior of the limit parameter? Even without it, we can expect the query to use all the nodes or the 100 internal limit can also be an issue?\nServer Setup Information\n\nWeaviate Server Version: 1.24.9 deployed, on my dev machine I can reproduce the issue on versions 1.23.16, 1.24.26, 1.25.24, 1.26.8 and 1.27.1\nDeployment Method: docker\nClient Language and Version: python client 4.7.1 and direct graphQL query using the REST API\nMultitenancy?: no\n\n----------\n\n[Mohamed_Shahin (2024-11-05T16:28:26.766Z)]: @accorrea1-stf,\nWelcome to our community! It’s great to have you here.\nI wonder about the HNSW configuration in your cluster. Have you explored the ef operator? A higher ef value results in a more extensive search, enhancing accuracy.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nVector Indexing | Weaviate\n\n  Vector indexing is a key component of vector databases. It can help to significantly increase the speed of the search process of similarity search with only a minimal tradeoff in search accuracy (HNSW index), or efficiently store many subsets of data...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBy increasing the ef value, you improve the accuracy of your searches. I would suggest trying out a few fixed values such as 100, 250, 500, and 1000. My hope is that by setting it to one of these higher values, you will achieve more consistent results, as the graph for the vector index will be explored more exhaustively.\nHere’s some code to help you achieve this:\nfrom weaviate.classes.config import Reconfigure\n\ncollection.config.update(\n\nvector_index_config=Reconfigure().VectorIndex.hnsw(ef=512)\n\n)\n\nBest regards,\nMohamed Shahin\nWeaviate Support\n\n----------\n\n[accorrea1-stf (2024-11-05T17:34:08.528Z)]: Thank you for your answer Mohamed!\nI’m going to do some tests increasing the ef value.\nOur current config is:\n{'cleanupIntervalSeconds': 300,\n  'distanceMetric': 'cosine',\n  'dynamicEfMin': 100,\n  'dynamicEfMax': 500,\n  'dynamicEfFactor': 8,\n  'ef': -1,\n  'efConstruction': 128,\n  'filterStrategy': 'sweeping',\n  'flatSearchCutoff': 40000,\n  'maxConnections': 64,\n  'skip': False,\n  'vectorCacheMaxObjects': 1000000000000}\n\n----------\n\n[Mohamed_Shahin (2024-11-06T08:42:10.983Z)]: @accorrea1-stf Awesome, let me know how it goes.",
    "date_created": "2024-11-05T15:04:14.757Z",
    "has_accepted_answer": false,
    "title": "Limit parameter change results of near_vector query",
    "topic_id": 7458
  },
  {
    "user_id": 2546,
    "conversation": "[Daniele_Longo (2024-11-19T15:49:37.362Z)]: Hello,\nI’m running a local instance of Weaviate using Docker, and everything seems to be functioning well. When I use the Python client to update collections, it works without issues. However, when I attempt to perform updates via GraphQL, I receive the following error: “schema is not configured for migration.”\nCould you help me understand why this is happening and how to resolve it?\nThank you!\n\n----------\n\n[DudaNogueira (2024-11-20T18:56:58.871Z)]: hi @Daniele_Longo !!\nWelcome to our community \nYou cannot update objects with graphql. We only expose graphql for reading/querying\nFor updating objects, you need to use our REST endpoints. For example, this is the one you need to update an object:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nWeaviate\n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNote that while GRAPHQL and REST APIs are convenient, whenever you need more performance, for operations like batch updating, inserting, querying, etc, we suggest using the client, as it leverages GRPC and delivers a lot more performance.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nUpdate objects | Weaviate\n\n  Weaviate allows partial or complete object updates.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Daniele_Longo (2024-11-22T08:59:05.235Z)]: Hi @DudaNogueira ,\nThank you for the answer, isn’t there a console for local instances to query and manipulate data faster, right?\n\n----------\n\n[DudaNogueira (2024-11-22T13:19:42.479Z)]: hi @Daniele_Longo !\nWe used to allow our console to add locally hosted clusters, so the browser would connect to your locally hosted Weaviate instance.\nUnfortunately we had to limit this feature to our cloud hosted only clusters, as this could potentially be exploited.\nHowever, you can still use any api client, like insomnia or postman to get the same graphql autocomplete functionality.\nHere is how It looks like in insomnia:\nimage2200×1218 318 KB\nyou can also import our openapi specs to use the rest endpoints:\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate/blob/main/openapi-specs/schema.json\n\n\n      {\n  \"basePath\": \"/v1\",\n  \"consumes\": [\n    \"application/yaml\",\n    \"application/json\"\n  ],\n  \"definitions\": {\n    \"Role\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"name\": {\n          \"type\": \"string\",\n          \"description\": \"role name\"\n        },\n        \"permissions\" : {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"object\",\n            \"description\": \"list of permissions (level, action, resource)\",\n            \"$ref\": \"#/definitions/Permission\"\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\n\n----------\n\n[Daniele_Longo (2024-11-25T09:05:37.233Z)]: Dear @DudaNogueira ,\nThank you for the answer!",
    "date_created": "2024-11-19T15:49:37.315Z",
    "has_accepted_answer": true,
    "title": "Weaviate local instance graphql Update \"schema is not configured for migration\"",
    "topic_id": 7705
  },
  {
    "user_id": 807,
    "conversation": "[adithya.ch (2024-09-10T02:48:58.099Z)]: I am trying to access verba 2.0 version with weaviate cluster 1.26.3 version.\nexport WEAVIATE_API_KEY_VERBA=“pwd”\nexport OLLAMA_EMBED_MODEL=llama3.1\nexport OLLAMA_MODEL=llama3.1\nexport WEAVIATE_URL_VERBA=https://:6383\nexport OLLAMA_URL=http://ollama-url:2300\nError :\nhttps://::6383 with Auth\n✘ Couldn’t connect to Weaviate, check your URL/API KEY: Invalid port:\n‘6383:443’\n✘ Failed to connect to Weaviate Couldn’t connect to Weaviate, check\nyour URL/API KEY: Invalid port: ‘6383:443’\nINFO:     10.82.204.17:65400 - “POST /api/connect HTTP/1.1” 400 Bad Request\nimage3380×1454 214 KB\nnote : It was working fine with verba 1.0 version !!\nPlease let me know how to fix this issue ?\n\n----------\n\n[DudaNogueira (2024-09-10T14:29:16.802Z)]: Hi @adithya.ch !\nIf you are using it locally, hosting using the embeddedm you need to choose local.\nThis option will work for Weaviate hosted in our cloud.\n\n----------\n\n[adithya.ch (2024-09-10T14:47:04.240Z)]: Hi @DudaNogueira ,\nWe hosted weaviate cluster locally on our kubernetes cluster.\nIt was working fine with v1.0 ? Was there any process/breaking changes with V2.0 disabling access to self hosted weaviate cluster ?\nRegards,\nAdithya\n\n----------\n\n[DudaNogueira (2024-09-10T18:16:42.359Z)]: Right now the new Verba 2.0 will give you three options to connect:\n\nLocal (Embedded, will spin a Weaviate instance)\nWeaviate (will allow you to provide URL and API KEY to connect to our cloud)\nDocker. will use connect_to_local. It expects a host named weaviate at http port 8080 and grpc port 50051.\n\nAs you are using K8s, you will need provide Verba pod a way to connect to your K8s Weaviate instance having those exact informations.",
    "date_created": "2024-09-10T02:48:58.050Z",
    "has_accepted_answer": false,
    "title": "Unable to connect to self-hosted weaviate clusters through verba 2.0 version",
    "topic_id": 4050
  },
  {
    "user_id": 656,
    "conversation": "[viethungluu (2024-07-19T03:37:31.142Z)]: Description\nIm ingesting data using LangChain WeaviateVectorStore.from_documents() function. After successfully inserted ~600K of objects (embedding length 1536), I start getting the following error\nweaviate.exceptions.UnexpectedStatusCodeError: Collection may not exist.! Unexpected status code: 503, with response body: None.\nI tried to enable async indexing, and sent a Cluster Scale request. But the error still happens.\n\nServer Setup Information\n\nWeaviate Server Version: 1.25.7\nDeployment Method: Weaviate cloud\nMulti Node? Number of Running Nodes: Single node\nClient Language and Version: Python V4\nMultitenancy?:\n\nAny additional Information\nNA\n\n----------\n\n[DudaNogueira (2024-07-19T13:41:36.947Z)]: Hi!\nAs this is hosted with us, please, can you send an email to support@weaviate.io so we can give a look at those logs?\nIn this situation, we should take a look at the server logs to try understanding what is happening.\nThanks!",
    "date_created": "2024-07-19T03:37:31.088Z",
    "has_accepted_answer": false,
    "title": "Getting UnexpectedStatusCodeError: Collection may not exist.!",
    "topic_id": 3095
  },
  {
    "user_id": 3164,
    "conversation": "[Min (2025-01-09T03:53:31.131Z)]: Please understand that my questions may be very basic.\nIf I build and operate a service using a specific embedding model (vectorizer) such as multi2vec-bind, and need to change the embedding model for some reasons (due to new better model or custom model), how can I update the vectorizer model while it’s in service?\nAlso, in the case above, will all the data stored in the DB become useless? (Is it necessary to vectorize everything again?)\nThank you.\n\n----------\n\n[DudaNogueira (2025-01-10T11:16:28.642Z)]: hi @Min !!\nYou got it right.\nYou cannot change the vectorizer without vectorizing all your data using the new vectorizer.\nNote that the vectorizer is a non mutable configuration of your collection:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection definition | Weaviate\n\n  Schema Configuration in Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nSo what you’ll need to do is to create a new collection with the configurations you want, and copy your data over so it triggers a new vectorization.\nWe have a nice example here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Learn how to migrate data within Weaviate for easy data handling.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!\nTHanks!",
    "date_created": "2025-01-09T03:53:31.076Z",
    "has_accepted_answer": true,
    "title": "Can vectorizer embedding model be changed while in service?",
    "topic_id": 9642
  },
  {
    "user_id": 1555,
    "conversation": "[Rishi_Prakash (2024-10-06T11:48:53.457Z)]: I want to store embedding separately for two fields. For example, I am creating a schema like this\n           skills = self.client.collections.create(\n                name=self.collection_name,\n                vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_azure_openai(\n                    deployment_id=\"text-embedding-ada-002\",\n                    resource_name=\"\",\n                    vectorize_collection_name=True\n                ),\n                properties=[\n                    wvc.config.Property(\n                        name=\"skill_name\",\n                        data_type=wvc.config.DataType.TEXT,\n                        vectorize_property_name=True\n                    ),\n                    wvc.config.Property(\n                        name=\"description\",\n                        data_type=wvc.config.DataType.TEXT,\n                        vectorize_property_name=True\n                    ),\n                    wvc.config.Property(\n                        name=\"etldatetime\",\n                        data_type=wvc.config.DataType.TEXT,\n                        skip_vectorization=True\n                    ),\n                ]\n            )\n\nnow i want skill_name and description embedding to be created separately,\nshare me the query for it, also how to search from the collection similarly, Thanks\n\n----------\n\n[DudaNogueira (2024-10-06T17:39:56.468Z)]: hi @Rishi_Prakash !!\nThis is a named vector (multi vector) use case.\nWhen you define a single vectorizer, just like you have done, Weavaite will concatenate all “vectorizable” properties.\nNow, if you want to create vectors for specific properties (single o multiple properties), you should define different named vectors, as stated here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMultiple vectors | Weaviate\n\n  [comment] multi-vector-support dot mdx )\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nwith that said, this is how you collection should be created:\nclient.collections.delete(\"Test\")\nskills = client.collections.create(\n                name=\"Test\",\n                vectorizer_config=[\n                    wvc.config.Configure.NamedVectors.text2vec_openai(\n                        name=\"skill_vector\", vectorize_collection_name=True,\n                        source_properties=[\"skill_name\", \"etldatetime\"]\n                    ),\n                    wvc.config.Configure.NamedVectors.text2vec_openai(\n                        name=\"description_vector\", vectorize_collection_name=True,\n                        source_properties=[\"description\"]\n                    )                    \n                ],\n                properties=[\n                    wvc.config.Property(\n                        name=\"skill_name\",\n                        data_type=wvc.config.DataType.TEXT,\n                        vectorize_property_name=True\n                    ),\n                    wvc.config.Property(\n                        name=\"description\",\n                        data_type=wvc.config.DataType.TEXT,\n                        vectorize_property_name=True\n                    ),\n                    wvc.config.Property(\n                        name=\"etldatetime\",\n                        data_type=wvc.config.DataType.TEXT,\n                        skip_vectorization=True\n                    ),\n                ]\n            )\nskills.data.insert({\"skill_name\": \"this is a skill\", \"description\": \"This is a skill desc\", \"etldatetime\": \"some etldatetime\"})\n\nnote that you will get now two vectors, as below:\no = skills.query.fetch_objects(include_vector=True).objects[0]\no.vector.keys()\n\nOutput:\n\ndict_keys([‘skill_vector’, ‘description_vector’])\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-10-06T11:48:53.407Z",
    "has_accepted_answer": true,
    "title": "How to create vector embedding for multiple fields",
    "topic_id": 4447
  },
  {
    "user_id": 1604,
    "conversation": "[ZzzWii (2024-09-27T06:11:03.739Z)]: Description\nuse the following code to request:\nfilters=wvc.query.Filter.by_property('knowledge_name').equal('QA')\ncollection=client.collection.get(Flies)\ncollection.query.fetch_object(filters=filters,limit=1)\n\nReturns： QueryReturn（object=）\ncollection.query.fetch_object(filters=filters,limit=2)\n\nReturns： one data.\nMy expectation is that when limit=1, one data should also be returned\nServer Setup Information\n\nWeaviate Server Version: weaviate1.23.7\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 3\nClient Language and Version:4.4.1\nMultitenancy:no\n\nAny additional Information\nI checked the server logs and found no relevant logs.\nI think the problem is on the server side, because when I use the crul request, when limit=1, the feedback result is still empty\n\n----------\n\n[Mohamed_Shahin (2024-09-27T12:11:38.046Z)]: Hello @ZzzWii,\nWelcome to our community, and it’s lovely to have you here.\nYour understanding is correct—the limit here should return one object. However, I see you have filters, which could be a case where the filter conditions don’t match any data.\nI’m not sure about your data and schema, so it’s difficult to tell for sure.\nI would suggest testing by applying the filter without the limit to ensure the filter is working against the data.\nRegards,\nMohamed Shahin\nWeaviate Support",
    "date_created": "2024-09-27T06:11:03.686Z",
    "has_accepted_answer": false,
    "title": "Expected: fetch_object with limit=1 returns one data object. Actual: Returns empty",
    "topic_id": 4348
  },
  {
    "user_id": 1143,
    "conversation": "[andrewisplinghoff (2024-07-01T13:38:53.976Z)]: Description\nWe are seeing our single Weaviate pod repeatedly fail during startup with the fatal error “could not open cloud meta store”. It seems to depend on how much data is in the database if the Pod manages to successfully start up after multiple restarts. What can be the reason for this error? There is only one single Weaviate pod in our Kubernetes cluster, so there is not even any need for  any communication to occur between pods. Is there any way to disable the “join cluster” logic as long as there is only one Pod? RAFT_BOOTSTRAP_EXPECT is set to 1 already, so I would expect the system to know there is not any other pods running?\nServer Setup Information\n\nWeaviate Server Version: 1.25.5\nDeployment Method: k8s using Helm\nMulti Node? Number of Running Nodes: 1\nMultitenancy?: no\n\nAny additional Information\nBootstrap related logs:\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [10.130.37.168:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"10.130.37.168:8300\"],\"time\":\"2024-07-01T11:06:49Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"weaviate-0\",\"Address\":\"10.130.37.168:8300\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-07-01T11:06:49Z\"}\n{\"action\":\"bootstrap\",\"error\":\"bootstrap only works on new clusters\",\"level\":\"error\",\"msg\":\"could not bootstrapping cluster\",\"time\":\"2024-07-01T11:06:49Z\"}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"10.130.37.168:8300\"],\"time\":\"2024-07-01T11:06:49Z\"}\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [10.130.37.168:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"10.130.37.168:8300\"],\"time\":\"2024-07-01T11:08:18Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"error\":\"rpc error: code = DeadlineExceeded desc = context deadline exceeded\",\"level\":\"error\",\"msg\":\"notify all peers\",\"servers\":[\"10.130.37.168:8300\"],\"time\":\"2024-07-01T11:08:18Z\"}\n{\"action\":\"startup\",\"error\":\"bootstrap: context deadline exceeded\",\"level\":\"fatal\",\"msg\":\"could not open cloud meta store\",\"time\":\"2024-07-01T11:08:18Z\"}\n\nEnvironment variables of the StatefulSet:\n- name: AUTHENTICATION_APIKEY_ENABLED\n  value: 'true'\n- name: AUTHENTICATION_APIKEY_USERS\n  value: 'api-key-user-readOnly,api-key-user-admin'\n- name: AUTHORIZATION_ADMINLIST_ENABLED\n  value: 'true'\n- name: AUTHORIZATION_ADMINLIST_READONLY_USERS\n  value: api-key-user-readOnly\n- name: AUTHORIZATION_ADMINLIST_USERS\n  value: api-key-user-admin\n- name: AUTOSCHEMA_ENABLED\n  value: 'false'\n- name: CLUSTER_DATA_BIND_PORT\n  value: '7001'\n- name: CLUSTER_GOSSIP_BIND_PORT\n  value: '7000'\n- name: DISABLE_TELEMETRY\n  value: 'true'\n- name: GOGC\n  value: '100'\n- name: LIMIT_RESOURCES\n  value: 'true'\n- name: LOG_LEVEL\n  value: debug\n- name: PROMETHEUS_MONITORING_ENABLED\n  value: 'true'\n- name: PROMETHEUS_MONITORING_GROUP\n  value: 'false'\n- name: PROMETHEUS_MONITORING_PORT\n  value: '9091'\n- name: QUERY_MAXIMUM_RESULTS\n  value: '100000'\n- name: REINDEX_VECTOR_DIMENSIONS_AT_STARTUP\n  value: 'false'\n- name: TIKTOKEN_CACHE_DIR\n  value: /weaviate-backups/tiktoken_cache\n- name: TRACK_VECTOR_DIMENSIONS\n  value: 'false'\n- name: AUTHENTICATION_APIKEY_ALLOWED_KEYS\n  valueFrom:\n    secretKeyRef:\n      name: weaviate-api-keys\n      key: AUTHENTICATION_APIKEY_ALLOWED_KEYS\n- name: CLUSTER_BASIC_AUTH_USERNAME\n  valueFrom:\n    secretKeyRef:\n      name: weaviate-cluster-api-basic-auth\n      key: username\n- name: CLUSTER_BASIC_AUTH_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      name: weaviate-cluster-api-basic-auth\n      key: password\n- name: STANDALONE_MODE\n  value: 'true'\n- name: PERSISTENCE_DATA_PATH\n  value: /var/lib/weaviate\n- name: DEFAULT_VECTORIZER_MODULE\n  value: none\n- name: ENABLE_MODULES\n  value: 'text2vec-openai,backup-filesystem'\n- name: RAFT_JOIN\n  value: weaviate-0\n- name: RAFT_BOOTSTRAP_EXPECT\n  value: '1'\n- name: BACKUP_FILESYSTEM_PATH\n  value: /weaviate-backups\n- name: CLUSTER_JOIN\n  value: weaviate-headless.015461-skaios-dev.svc.cluster.local.\n\n----------\n\n[DudaNogueira (2024-07-03T19:08:35.901Z)]: hi @andrewisplinghoff !!\nWelcome to our community!\nThat’s strange.\nHave you upgrade this cluster or was it a clear install at 1.25.5?\n\n----------\n\n[andrewisplinghoff (2024-07-04T00:37:04.139Z)]: Hi @DudaNogueira,\nwe upgraded from 1.24.x. This error only started occurring with 1.25.x, what makes sense I guess because the RAFT algorithm is new in 1.25.x.\n\n----------\n\n[DudaNogueira (2024-07-05T18:52:31.054Z)]: Oh, on that case, have you followed this migration guide?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\n1.25 (For Kubernetes users) | Weaviate - Vector Database\n\n  Assumptions & requirements\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nSorry for the delay \nI believe this may be related.\nOtherwise, I will need to escalate this internally. I have seen some similar log errors, but that was usually for multi node clusters.\n\n----------\n\n[andrewisplinghoff (2024-07-08T12:16:25.818Z)]: Yes, we followed the migration instructions.\n\n----------\n\n[andrewisplinghoff (2024-07-10T18:50:55.216Z)]: Have there been any fixes related to this in 1.25.7? The Pod directly came up with the data it was failing with earlier (maybe we just got lucky though).\n\n----------\n\n[andrewisplinghoff (2024-07-11T14:51:17.262Z)]: Looks like we just got lucky yesterday. Today the pod again failed the first time with the “could not open cloud meta store” error when using 1.25.7, but at least it worked after one restart.\n\n----------\n\n[DudaNogueira (2024-07-15T16:37:46.370Z)]: Hi, sorry! I was out of office those days.\nHave it fixed with the new version? Not sure I understood.\nUpgrading fixed it, but it failed again and was back with a restart?\n\n----------\n\n[andrewisplinghoff (2024-07-15T16:50:59.828Z)]: No, it’s not fixed. The error also happened with the latest version. After it happened, the Pod got restarted and in the second try, it came up successfully. Looks like some sort of race condition to me.\n\n----------\n\n[DudaNogueira (2024-07-15T19:59:48.166Z)]: Ok, can you open a Github issue with that?\nI will escalate it with out team.\nTHanks!\n\n----------\n\n[andrewisplinghoff (2024-07-16T09:32:17.227Z)]: Thanks & done: “could not open cloud meta store” error during Weaviate Startup using one node · Issue #5362 · weaviate/weaviate (github.com)",
    "date_created": "2024-07-01T13:38:53.910Z",
    "has_accepted_answer": false,
    "title": "Fatal error during Weaviate 1.25 startup: could not open cloud meta store",
    "topic_id": 2888
  },
  {
    "user_id": 504,
    "conversation": "[Jegadeesh (2024-02-25T08:36:51.172Z)]: I got an exception while batch inserting:\nweaviate.exceptions.WeaviateInsertManyAllFailedError: Every object failed during insertion. Here is the set of all errors: update inverted indices: put inverted indices props: no bucket for prop 'length' found\n\nI got the following exception for some more properties too.\nupdate inverted indices: put inverted indices props: no bucket for prop 'name' found\n\nBut the count of objects in the collection is incremented even after this exception “WeaviateInsertManyAllFailedError”.\nHow to resolve this issue and why is this issue? Thanks in advance\n\n----------\n\n[DudaNogueira (2024-02-25T10:56:57.153Z)]: Hi!\nCan you consistently reproduce this error?\nIf you could, sharing the code that led to it would help understand what were the steps that led to it.\nLet me know if this helps!\n\n----------\n\n[Jegadeesh (2024-02-25T11:24:07.578Z)]: I followed the similar approach for creating data objects and batch inserting the data.\nfor i in range(5):\n       properties = {\"question\": f\"Test Question {i+1}\"}\n      data_object = wvc.data.DataObject(\n            properties=properties,\n            vector = vectors\n        )\n       data_objects.append(data_object)\n\ncollection.data.insert_many(data_objects)\n\nSeeing the total number of objects increased in the collection, when I tried fetching the objects using a filter by property names, I am facing the following exception\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message explorer: list class: search: object search at index <collection_name>: local shard object search <collection_name_5xxxxx>: fetch doc ids for prop/value pair: nested query: nested child 0: nested query: nested child 2: bucket for prop <property_name> not found - is it indexed?.\nBut when I read all the objects in the collection, I can get the objects in the result.\nfor item in collection.iterator(include_vector=True):\n        print(item.uuid, item.properties,item.vector)\n\n----------\n\n[andrewisplinghoff (2024-09-05T11:38:09.545Z)]: We also ran into this error this week, querying Weaviate was not possible anymore, the error from the Weaviate log was as follows:\n{\"action\":\"hybrid\",\"build_git_commit\":\"unknown\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"unknown\",\"build_wv_version\":\"1.25.11\",\"error\":\"explorer: get class: vector search: object vector search at index pagenode_v4: shard pagenode_v4_Lly8mf7irQs5: build inverted filter allow list: fetch doc ids for prop/value pair: nested query: nested child 0: bucket for prop req_permissions_nullState not found - is it indexed?\",\"level\":\"error\",\"msg\":\"denseSearch failed\",\"time\":\"2024-09-04T08:33:27Z\"}\n\nInterestingly, also backups were not possible anymore, with the following error messages (error actually occurred while backing up another collection than the one that shows the error while querying):\n{\"action\":\"create_backup\",\"backup_id\":\"2024-09-04-page_v4\",\"build_git_commit\":\"unknown\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"unknown\",\"build_wv_version\":\"1.25.11\",\"level\":\"error\",\"msg\":\"upload backup class Page_v4 descriptor: list shard WiRWeiVpM70X files: node name: failed to execute query: could not get shard owner: shard not found: \\u003cnil\\u003e\",\"time\":\"2024-09-04T08:50:29Z\"}\n{\"action\":\"create\",\"backup_id\":\"2024-09-04-page_v4\",\"build_git_commit\":\"unknown\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"unknown\",\"build_wv_version\":\"1.25.11\",\"level\":\"error\",\"msg\":\"coordinator: backup class Page_v4 descriptor: list shard WiRWeiVpM70X files: node name: failed to execute query: could not get shard owner: shard not found\",\"time\":\"2024-09-04T08:50:31Z\"}\n\nA restart of Weaviate fixed these issues, just wanted to let you guys know as these problems seem to be in some way interconnected as they occurred at the same time for us.\n\n----------\n\n[DudaNogueira (2024-09-05T13:29:53.165Z)]: hi @andrewisplinghoff !\nWhat is the version you are running?\nTHanks!\n\n----------\n\n[andrewisplinghoff (2024-09-05T13:41:13.942Z)]: This was on Weaviate 1.25.11 (it’s part of the log messages btw).\n\n----------\n\n[Martinus (2024-09-24T08:10:08.392Z)]: @andrewisplinghoff  We are facing the same issue while doing backups. Currently running a  single 1.26.3 instance\n[\n  \"{\\\"action\\\":\\\"create\\\",\\\"backup_id\\\":\\\"2024-09-24_07-39-58\\\",\\\"build_git_commit\\\":\\\"9a4ea6d\\\",\\\"build_go_version\\\":\\\"go1.21.13\\\",\\\"build_image_tag\\\":\\\"1.26.3\\\",\\\"build_wv_version\\\":\\\"1.26.3\\\",\\\"level\\\":\\\"error\\\",\\\"msg\\\":\\\"coordinator: backup class Conversation__ae962c75_0b00_40c4_931d_0ad7ef85c011 descriptor: list shard QUXngs1oL2UQ files: node name: failed to execute query: could not get shard owner: shard not found\\\",\\\"time\\\":\\\"2024-09-24T07:40:26Z\\\"}\"\n]\n\nIt seems the class is corrupted. Sometimes it helps restarting Weaviate, but last time we had to delete the classes, only then we were able to backup again.\nAny ideas how this can happen? Is this a Weaviate bug perhaps?\n\n----------\n\n[DudaNogueira (2024-09-25T11:05:31.598Z)]: this seems to be a collection corrupted indeed.\nIf you can read this collection, can you reindex it on a new collection and then remove the old one?\nThis could solve this issue as the new index shouldn’t be corrupted.",
    "date_created": "2024-02-25T08:36:51.125Z",
    "has_accepted_answer": false,
    "title": "Update inverted indices: put inverted indices props:no bucket for prop '<property_name>' found",
    "topic_id": 1564
  },
  {
    "user_id": 1521,
    "conversation": "[td55 (2024-09-10T22:42:37.993Z)]: Description - error message:\nFailed to connect to Weaviate Collection may not have been created properly.! Unexpected status code: 422, with response body: {‘error’: [{‘message’: ‘class already exists: found similar class “VERBA_Config”’}]}.\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: local on Mac, Ollama running llama3:70B on port 11434\n\nAny additional Information\ninstalled from source, previously tried pip3 install with same result\n\n----------\n\n[DudaNogueira (2024-09-11T17:06:49.668Z)]: hi @td55 !! Welcome to our community  !!\nIt looks like there is already a VERBA_Config collection, but it shouldn’t try creating it again.\nWhat is the Verba version you are running?\n\n----------\n\n[td55 (2024-09-11T17:56:10.415Z)]: Thanks,  using Github latest, also tried a clean install with pip3 - same result\n\n----------\n\n[Roman (2024-09-12T08:06:30.501Z)]: Temp Fix:\nGo to ‘goldenverba/components/managers.py:146’\nChange ‘self.config_collection_name = “VERBA_CONFIG”’ to custom name\nInstance attribute config_collection_name of goldenverba. components. managers. WeaviateManager config_collection_name: str = “VERBA_CONFIG”\n\n----------\n\n[td55 (2024-09-12T12:57:22.514Z)]: That worked, thanks.  Let me know if I can help with testing.\n\n----------\n\n[DudaNogueira (2024-09-12T13:23:19.504Z)]: What could also work is removing all content from your local persistence path, if using local deployment",
    "date_created": "2024-09-10T22:42:37.943Z",
    "has_accepted_answer": false,
    "title": "Problem starting Verba using Ollama on Mac",
    "topic_id": 4098
  },
  {
    "user_id": 1236,
    "conversation": "[ctindel (2024-07-25T16:17:06.978Z)]: I am running docker image cr.weaviate.io/semitechnologies/weaviate:1.25.8 and seeing this panic while loading data:\ngoroutine 2297272 [running]:\nruntime/debug.Stack()\n/usr/local/go/src/runtime/debug/stack.go:24 +0x64\nruntime/debug.PrintStack()\n/usr/local/go/src/runtime/debug/stack.go:16 +0x1c\ngithub.com/weaviate/weaviate/entities/errors.GoWrapperWithBlock.func1.1()\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:48 +0x170\npanic({0x144eb00?, 0x405a5f9380?})\n/usr/local/go/src/runtime/panic.go:914 +0x218\ngithub.com/weaviate/weaviate/usecases/modules.reVectorize({0x1bca2f0, 0x4053bd38c0}, {0x1bcd700?, 0x405a520200?}, {0xf70be1628158?, 0x4003aad110?}, 0x40538d74d0, 0x4053c41550, {0x0, 0x0, …}, …)\n/go/src/github.com/weaviate/weaviate/usecases/modules/compare.go:126 +0xc14\ngithub.com/weaviate/weaviate/usecases/modules.(*Provider).batchUpdateVector(0x4002b7dd60, {0x1bca2f0, 0x4053bd38c0}, {0x4053050800?, 0x3e8, 0x500}, 0x4053c41550, 0x9?, {0x0, 0x0}, …)\n/go/src/github.com/weaviate/weaviate/usecases/modules/vectorizer.go:203 +0x3a8\ngithub.com/weaviate/weaviate/usecases/modules.(*Provider).BatchUpdateVector(0x4002b7dd60, {0x1bca2f0?, 0x4053bd38c0}, 0x4053c41550, {0x4053050800, 0x3e8, 0x500}, 0x405a580610, {0x1be1b48, 0x40038d0f80})\n/go/src/github.com/weaviate/weaviate/usecases/modules/vectorizer.go:111 +0x240\ngithub.com/weaviate/weaviate/usecases/objects.(*BatchManager).validateAndGetVector(0x4002caf880, {0x1bca2f0, 0x4053bd38c0}, 0x402ff19a68?, {0x4053426000, 0x3e8, 0x402ff19ad8?}, 0x0)\n/go/src/github.com/weaviate/weaviate/usecases/objects/batch_add.go:159 +0x8e8\ngithub.com/weaviate/weaviate/usecases/objects.(*BatchManager).AddObjects(0x4002caf880, {0x1bca2f0, 0x404ab01f80}, 0x41b04c0?, {0x4053426000, 0x3e8, 0x3e8}, {0x404ab018f0?, 0x1ba4020?, 0x41b04c0?}, …)\n/go/src/github.com/weaviate/weaviate/usecases/objects/batch_add.go:56 +0x2a0\ngithub.com/weaviate/weaviate/adapters/handlers/grpc/v1.(*Service).batchObjects(0x4002ca1580, {0x1bca2f0, 0x404ab01f80}, 0x404ade5720)\n/go/src/github.com/weaviate/weaviate/adapters/handlers/grpc/v1/service.go:150 +0x2b4\ngithub.com/weaviate/weaviate/adapters/handlers/grpc/v1.(*Service).BatchObjects.func1()\n/go/src/github.com/weaviate/weaviate/adapters/handlers/grpc/v1/service.go:131 +0x3c\ngithub.com/weaviate/weaviate/entities/errors.GoWrapperWithBlock.func1()\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:53 +0x74\ncreated by github.com/weaviate/weaviate/entities/errors.GoWrapperWithBlock in goroutine 2297271\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:42 +0xa4\n{“level”:“error”,“msg”:“Recovered from panic: interface conversion: interface {} is interface {}, not string”,“time”:“2024-07-25T16:12:59Z”}\n\n----------\n\n[DudaNogueira (2024-07-25T18:36:34.775Z)]: hi @ctindel !!\nI have just faced this exact same error recently.\nAre you by any chance updating an object and not passing a TEXT_ARRAY?\nhere is a code I was able to run and reproduce and get this error message:\n\nimport weaviate\nfrom weaviate.util import generate_uuid5\nfrom weaviate import classes as wvc\nclient = weaviate.connect_to_local()\n\nprint(weaviate.__version__, client.get_meta().get(\"version\"))\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    properties=[\n        wvc.config.Property(\n            name=\"tags\", data_type=wvc.config.DataType.TEXT_ARRAY),\n        wvc.config.Property(\n            name=\"title\", data_type=wvc.config.DataType.TEXT),\n        wvc.config.Property(name=\"authorized\",\n                            data_type=wvc.config.DataType.BOOL)\n    ],\n    vectorizer_config=[\n        wvc.config.Configure.NamedVectors.text2vec_openai(\n            name=\"title_vector\",\n            source_properties=[\"title\"],\n        ),\n        wvc.config.Configure.NamedVectors.text2vec_openai(\n            name=\"tags_vector\",\n            source_properties=[\"tags\"],\n        ),\n    ]\n)\n\ncollection.data.insert({\"tags\": [], \"authorized\": False, },\n                       uuid=generate_uuid5(\"example2\"))\n# this will fail:\ncollection.data.update(\n    properties={\n        \"authorized\": True,\n        #\"tags\": [] # specifying it null will work\n    }, uuid=generate_uuid5(\"example2\"))\n#\n# ERROR: UnexpectedStatusCodeError: Object was not updated.! Unexpected status code: 500, with response body: {'error': [{'message': 'msg:merge and vectorize code:500 err:panic occurred: interface conversion: interface {} is []interface {}, not []string'}]}.\n#\n\n----------\n\n[ctindel (2024-07-25T19:24:38.480Z)]: Yes! There was a case where I was omitting the text array field from the object!\nWill it be OK to pass an empty array instead of a null value?\n\n----------\n\n[DudaNogueira (2024-07-25T20:35:47.720Z)]: null or the value you want.\nAnd that’s a problem \nNow for for every property update you do, you have to pass all TEXT_ARRAY with it’s values.\n\n----------\n\n[Dirk (2024-07-26T07:53:26.309Z)]: semitechnologies/weaviate:preview-fix-updating-object-with-empty-list-c604412\nthis should fix the panic (latest 1.25+a fix)",
    "date_created": "2024-07-25T16:17:06.932Z",
    "has_accepted_answer": true,
    "title": "Panic with 1.25.8",
    "topic_id": 3170
  },
  {
    "user_id": 1541,
    "conversation": "[fabriziof64 (2024-09-14T20:13:17.126Z)]: I’m trying to use (on Windows) the docker image of weaviate 1.26.0 to get vector embedding local to my computer, but when vectorization should occur I get the error ‘failed with status: 429 error: Rate limit reached. Please log in or use a HF access token’.\nThis is the docker-compose.yml:\nversion: ‘3.4’\nservices:\nweaviate:\nimage: semitechnologies/weaviate:1.26.0\nports:\n- “9090:8080”\nenvironment:\nQUERY_DEFAULTS_LIMIT: 100\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: ‘true’\nENABLE_MODULES: ‘text2vec-huggingface’  # Enable Hugging Face module\nHUGGINGFACE_INFERENCE_MODEL: ‘sentence-transformers/all-MiniLM-L6-v2’\nDEFAULT_VECTORIZER_MODULE: text2vec-huggingface\nHUGGINGFACE_INFERENCE_API: ‘local’\nPERSISTENCE_DATA_PATH: “/var/lib/weaviate”  # Inside the container\nIt seems that it is not possibile to use local vectorization, but only remote (which implies sending text to HuggingFace). Is it correct? What is the meaning of HUGGINGFACE_INFERENCE_API: ‘local’? Thanks!\n\n----------\n\n[DudaNogueira (2024-09-16T18:09:43.313Z)]: hi @fabriziof64 !!\nWelcome to our community \nThis message usually comes from the vectorizer service.\nChanging HUGGINGFACE_INFERENCE_API will set the url to where Weaviate will look for Hugging face inference service.\nIf you want to run transformers locally, check this option:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nText Embeddings | Weaviate\n\n  Weaviate's integration with the Hugging Face Transformers library allows you to access their models' capabilities directly from Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAlso, you can run models using ollama:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nText Embeddings | Weaviate\n\n  Weaviate's integration with Ollama's models allows you to access their models' capabilities directly from Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-09-14T20:13:17.074Z",
    "has_accepted_answer": false,
    "title": "Local Hugginface vector embedding",
    "topic_id": 4160
  },
  {
    "user_id": 1264,
    "conversation": "[Cobyboss (2024-08-22T20:19:13.715Z)]: ErrorObject(message=’WeaviateBatchError(\\‘Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.RESOURCE_EXHAUSTED\\n\\tdetails = “CLIENT: Sent message larger than max (146965530 vs. 104858000)“\\n\\tdebug_error_string = “UNKNOWN:Error received from peer {created_time:“2024-08-22T13:03:51.442771-07:00”, grpc_status:8, grpc_message:“CLIENT: Sent message larger than max (146965530 vs. 104858000)“}”\\n>.\\‘)’,\nI am trying to vectorize images from Google Cloud Platform with Weaviate but am getting RESOURCE_EXHAUSTED errors. I am using the multimodal model for this. When I was testing this on the Sandbox it worked completely fine, but now it is not working on the serverless cluster. Is it that the image sizes are too big (confusing because it worked on the Sandbox) and if so, how should I workaround this? I tried to vectorize 100 images: 72 worked 28 failed with that error above.\nI am using 1.25.10 and the code is below:\nimage_b64 = url_to_base64(src_obj[\"image_url\"])\n        weaviate_obj = {\n            \"image\": image_b64,\n            \"image_url\": src_obj[\"image_url\"],\n            \"image_name\": src_obj[\"image_name\"],\n            \"source\": src_obj[\"source\"],\n        }\n        obj_uuid = src_obj[\"uuid\"] if src_obj[\"uuid\"] else generate_uuid5(weaviate_obj)\n\n        batch.add_object(\n            properties=weaviate_obj,\n            uuid = obj_uuid\n            # vector=vector  # Optionally provide a pre-obtained vector\n        )\n\n----------\n\n[DudaNogueira (2024-08-22T21:11:57.486Z)]: hi @Cobyboss !\nFor all clusters hosted in our cloud, the best place for support is opening a support ticket. Check the Support Link inside your console dashboard for details.\nThis error message indicates that the size of the payload was too big to be handled.\nHow are you configuring your batch size? What batch sizes have you tried?\nhere is an example:\nwith collection.batch.fixed_size(batch_size=10, concurrent_requests=2) as batch:\n    for data_row in objects:\n        batch.add_object(\n            properties=data_row,\n            uuid=generate_uuid5(data_row.get(\"reference_id\"))\n        )\n\nLet me know if this helps!\n\n----------\n\n[bobvanluijt (2025-01-20T17:50:39.688Z)]: I run into the same thing (the object send to the DB is too large). It’s solved in the next release: Increase default GRPC_MAX_MESSAGE_SIZE limit to 100MB by antas-marcin · Pull Request #6966 · weaviate/weaviate · GitHub",
    "date_created": "2024-08-22T20:19:13.665Z",
    "has_accepted_answer": true,
    "title": "GRPC Resource Exhausted Error",
    "topic_id": 3436
  },
  {
    "user_id": 917,
    "conversation": "[henry_m (2024-10-18T08:03:39.505Z)]: Description\n\nI’m exploring keyword search using BM25.\nFrom Multiple keywords using BM25 I see that multiple words can be supplied. However we’re handling Chinese text:\n>>> collection.query.bm25(\"水痘是怎樣形成的？\")\nQueryReturn(objects=[])\n>>> collection.query.bm25(\"水痘\")\nQueryReturn(objects=[Object(uuid=...),Object(uuid=...),Object(uuid=...)])\n>>> collection.query.bm25(\"水 痘 是 怎 樣 形 成 的 ？\")\nQueryReturn(objects=[])\n>>> collection.query.bm25(\"水痘 是 怎 樣 形 成 的 ？\")\nQueryReturn(objects=[Object(uuid=...),Object(uuid=...),Object(uuid=...)])\n\nCan weaviate expose the underlying BM25 tokenizer so that CJK texts are handled properly?\nServer Setup Information\n\nWeaviate Server Version: 1.25.2\nDeployment Method: docker (semitechnologies/weaviate:1.25.2)\nMulti Node? Number of Running Nodes: 1\n\nAny additional Information\n\n----------\n\n[Dirk (2024-10-18T08:12:09.835Z)]: Hello!\nWe have special tokenizers for chinese+japanese and korean \nPlease have a look here: Collection schema | Weaviate",
    "date_created": "2024-10-18T08:03:39.459Z",
    "has_accepted_answer": false,
    "title": "BM25 CJK (Chinese, Japanese, Korean) Support",
    "topic_id": 5762
  },
  {
    "user_id": 805,
    "conversation": "[mmoya (2024-07-29T18:55:32.655Z)]: Description\nhello, we were running into the following issue when trying to read from one of our classes\n{\n    \"error\": [\n        {\n            \"message\": \"msg:search index documenttextchunk256 code:500 err:local shard object search documenttextchunk256_CHVDD95kgRmJ: memory pressure: cannot load shard: not enough memory mappings\"\n        }\n    ]\n}\n\nit’s not clear on what was causing this issue. We ended up deleting the class and that seemed to resolve the issue short term but we obviously wouldn’t want this to reoccur in the future\nAny insight on what caused the issue above?\nServer Setup Information\n\nWeaviate Server Version:  1.21.8\nDeployment Method: k8s\nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\n----------\n\n[DudaNogueira (2024-07-29T19:50:38.220Z)]: hi @mmoya !!\nWhat are the resource metrics reading for this cluster?\nIt may be needing more memory. \nAlso,  note that 1.21.8 is a fairly old version and a lot has changed since it.\nWe strongly suggest upgrading it to latest versions.\nThanks!\n\n----------\n\n[mmoya (2024-07-29T19:52:23.729Z)]: thank you for the reply. This wasn’t a cluster or version related related issue because we were able to read/write othe classes in this weaviate instance. This issue was isolated to this specific class and I’d get that error even if I did GET https://[OUR_SERVER_NAME]/v1/objects?class=DocumentTextChunk256&limit=1\n\n----------\n\n[mmoya (2024-07-29T20:01:52.213Z)]: I noticed that\n\nWeaviate also uses memory-mapped files for data stored on disks. Memory-mapped files are efficient, but disk storage is much slower than in-memory storage.\n\nIs there a way to alter this? We’re currently using EFS for storage and if I had to guess by the error itself, it’s most likely tied to Weaviate’s memory mapping\n\n----------\n\n[mmoya (2024-07-29T20:05:44.697Z)]: is there a way to implement a vector cache based on some type of recency or incorporate some type TTL related to weaviate’s in memory usage?\nAlternatively, is there a way to autoscale memory for an hnsw index dynamically?\n\n----------\n\n[DudaNogueira (2024-07-29T20:11:07.835Z)]: Oh, I see.\nLooks like Weaviate is having a hard time loading this specific collection shard into memory.\nAFAIK you cannot disable it, as it’s how it is used to load data from disk to memory.\nWhile this may not be tied to a version, newever versions for sure has a lot of improvements that may solve this.\n\nis there a way to implement a vector cache based on some type of recency or incorporate some type TTL related to weaviate’s in memory usage?\n\nYou can try reducing vectorCacheMaxObjects  as described here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nResource Planning | Weaviate - Vector Database\n\n  Weaviate scales well for large projects. Smaller projects, less than 1M objects, do not require resource planning. For medium and large-scale projects, you should plan how to get the best performance from your resources. While you design you system,...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.\nThanks!\n\n----------\n\n[mmoya (2024-07-29T20:12:59.460Z)]: how could I autoscale memory allocated to an index? Or alternatively, is there a way to incorporate some type of TTL around data stored in memory?\n\n----------\n\n[mmoya (2024-07-29T20:17:33.857Z)]: I see, how does the vectorCacheMaxObjects work? Is it based on recency? Thus if I set it to 100,000 will it store the most recent 100,000 vectors and anything thereafter would need to be read from disk?\nThen, once it reaches 100,000 it restarts the cache?\n\n----------\n\n[DudaNogueira (2024-07-29T20:18:34.189Z)]: hi!\nAutoscaling would be something to be done at the k8s or docker level \nas per TTL, if you are using multitenancy, there is a new feature where you can load and offload from memory on a per tenant basis:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMulti-tenancy operations | Weaviate - Vector Database\n\n  Multi-tenancy provides data isolation. Each tenant is stored on a separate shard. Data stored in one tenant is not visible to another tenant. If your application serves many different users, multi-tenancy keeps their data private and makes database...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor now, you can activate and deactivate. So if this applies for your usecase, let’s say a user logs out from your system, you can offload that tenant.\nFuture versions will allow a time to auto offload the tenant, considering it’s last activity.\nSo, whenever a new query comes in for a deactivated tenant, Weaviate will load it on demand.\nLet me know if this helps.\nThanks!\n\n----------\n\n[mmoya (2024-07-29T20:56:31.544Z)]: thank you, I think I’ll give setting the vectorCacheMaxObjects a try. I’m assuming this is something that is set upon class creation rather than something I change via the manifest/server correct? If so, I’m assuming it’s defined via client.schema.create_class(some_dict) where some_dict[\"vectorIndexConfig\"][\"vectorCacheMaxObjects\"] = 100000?\nhttps://weaviate-python-client.readthedocs.io/en/v3.2.2/weaviate.schema.html#module-weaviate.schema\n\n----------\n\n[antas-marcin (2024-07-30T11:36:57.580Z)]: mmoya:\n\nnot enough memory mappings\n\n\nThis error tells that you are hitting Operating Systems open files limit.\nThis setting is OS specific setting and can be increased. Our helm charts are updating this setting already (look here). If you already have this OS setting applied then you can switch to PERSISTENCE_LSM_ACCESS_STRATEGY=pread with this Weaviate setting this error should go away.\n\n----------\n\n[mmoya (2024-09-06T14:04:31.601Z)]: thank you for the reply. We tried considering PERSISTENCE_LSM_ACCESS_STRATEGY=pread but now we’re getting\n\n{“error”:“init shard \"documenttextchunk256_SsFs8E1E78j2\": init shard \"documenttextchunk256_SsFs8E1E78j2\": init per property indices: init properties on shard ‘documenttextchunk256_SsFs8E1E78j2’: create property\n‘embedding’ value index on shard ‘documenttextchunk256_SsFs8E1E78j2’: init disk segments: init segment segment-1724189418098378082.db: mmap file: invalid argument”,“level”:“error”,“msg”:“Unable to load shard SsFs8\nE1E78j2: init shard \"documenttextchunk256_SsFs8E1E78j2\": init shard \"documenttextchunk256_SsFs8E1E78j2\": init per property indices: init properties on shard ‘documenttextchunk256_SsFs8E1E78j2’: create property\n‘embedding’ value index on shard ‘documenttextchunk256_SsFs8E1E78j2’: init disk segments: init segment segment-1724189418098378082.db: mmap file: invalid argument”,“time”:“2024-09-06T14:06:11Z”}\n\n----------\n\n[VasylHerman (2024-11-19T17:23:07.888Z)]: Hi,\nI get the same error\nerror: Could not save the document Query call with protocol gRPC failed with message: /weaviate.v1.Weaviate/Search UNKNOWN: explorer: list class: search: object search at index policydoc: LazyLoadShard::preventShutdown: memory pressure: cannot load shard: not enough memory mappings WeaviateQueryError: Query call with protocol gRPC failed with message: /weaviate.v1.Weaviate/Search UNKNOWN: explorer: list class: search: object search at index policydoc: LazyLoadShard::preventShutdown: memory pressure: cannot load shard: not enough memory mappings\n\nRunnung in docker compose:\nservices:\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '80'\n      - --scheme\n      - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.5\n    ports:\n      - \"80:80\"\n      - \"50051:50051\"\n      - \"2112:2112\"\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: always\n    environment:\n      PROMETHEUS_MONITORING_ENABLED: 'true'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-aws,text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node1'\n      ASYNC_INDEXING: 'true'\n      PERSISTENCE_LSM_ACCESS_STRATEGY: pread\n\nOn the host sysctl vm.max_map_count is set vm.max_map_count = 1572864\nOn the host sudo cat /proc/*/maps | wc -l shows 744592\nLinux ip-10-1-10-208 6.8.0-1018-aws #19~22.04.1-Ubuntu SMP Wed Oct  9 17:10:38 UTC 2024 aarch64 aarch64 aarch64 GNU/Linux\nPlease help to address.",
    "date_created": "2024-07-29T18:55:32.595Z",
    "has_accepted_answer": true,
    "title": "Error: not enough memory mappings",
    "topic_id": 3215
  },
  {
    "user_id": 1496,
    "conversation": "[Deepak_Pachiannan (2024-09-07T16:45:55.422Z)]: Hi everyone,\nI’ve been trying to set up the Ollama Llama3 model locally using Docker, but I’m running into connection issues. I’ve installed Weaviate and set up the Ollama embedders, but it’s showing “Couldn’t connect to Ollama at http://localhost:11434” (see screenshot below).\nSetup details:\n\nWeaviate Chatbot installed via Docker\nOllama Llama3 instance running locally\nWeaviate is set to connect to Ollama on localhost:11434\n\nWhat I’ve tried:\n\nVerified that Docker is running and Ollama instance is installed.\nConfirmed that http://localhost:11434 is the correct URL.\nScreenshot 2024-09-07 2121572878×1632 214 KB\n\n----------\n\n[DudaNogueira (2024-09-07T16:50:56.231Z)]: hi @Deepak_Pachiannan !!\nWelcome to our community  !!\nWhen you run Weaviate as a docker container, from it’s perspective localhost will point to Weaviate itself, not Ollama.\nSetting Ollama endpoint as localhost will only work if you run Verba from python directly.\nYou need to change ollama’s endpoint to the host machine, as stated here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\ntext2vec-ollama | Weaviate\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWhen you set the ollama endpoint to http://host.docker.internal:11434, Weaviate will try to reach ollama at the docker host at port 11434.\nLet me know if this helps!\nThanks!",
    "date_created": "2024-09-07T16:45:55.370Z",
    "has_accepted_answer": false,
    "title": "Issue Connecting to Ollama Llama3 Instance in Docker – Need Help",
    "topic_id": 4006
  },
  {
    "user_id": 1414,
    "conversation": "[vrano (2024-09-25T11:08:40.300Z)]: Hello,\nI’m using Go to ingest my data into a Weaviate database with two collections connected by a reference. I need to keep track of failed batches effectively, and my current approach relies on the WithObjects function. It is supposed to return an object ID for each object in the return type, but I get that field as well as the class field as empty\n[\n    {\n        Object: {\n            Additional: map[]\n            Class: \n            CreationTimeUnix: 0\n            ID: \n            LastUpdateTimeUnix: 0\n            Properties: <nil>\n            Tenant: \n            Vector: []\n            VectorWeights: <nil>\n            Vectors: map[]\n        }\n        Deprecations: []\n        Result: 0xc0006fc8e0\n    },\n    {\n        Object: {\n            Additional: map[]\n            Class: \n            CreationTimeUnix: 0\n            ID: \n            LastUpdateTimeUnix: 0\n            Properties: <nil>\n            Tenant: \n            Vector: []\n            VectorWeights: <nil>\n            Vectors: map[]\n        }\n        Deprecations: []\n        Result: 0xc0006fc8f0\n    }\n]\n\n----------\n\n[DudaNogueira (2024-09-30T15:07:54.621Z)]: hi @vrano !!\nCan you share the the code you are using?\nTHanks!",
    "date_created": "2024-09-25T11:08:40.254Z",
    "has_accepted_answer": false,
    "title": "Empty fields in WithObjects response in Go",
    "topic_id": 4311
  },
  {
    "user_id": 495,
    "conversation": "[sri-postgres-cassand (2024-09-11T21:04:55.224Z)]: Description\n\nI am trying to configure OIDC and would like what is the SCHEME option that I need to choose . SCHEME can take either HTTP or HTTPS for tls . Below is the error I am getting . Please let me know if someone had got the below issue and how was it resolved.\n{“code”:401,“message”:“anonymous access not enabled, please provide an auth scheme such as OIDC”}\nBelow are the parameters that I had passed to weaviate\nType=simple\nUser=weaviate\nGroup=dba\nWorkingDirectory=/etc/weaviatedb\nEnvironment=AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=false\nEnvironment=AUTHENTICATION_OIDC_ENABLED=true\nEnvironment=AUTHENTICATION_OIDC_CLIENT_ID=*******\nEnvironment=AUTHENTICATION_OIDC_ISSUER= ******\nEnvironment=AUTHENTICATION_OIDC_USERNAME_CLAIM=*****\n#Environment=AUTHENTICATION_OIDC_SKIP_CLIENT_ID_CHECK=false\nEnvironment=AUTHENTICATION_OIDC_SCOPES='’\nEnvironment=AUTHORIZATION_ADMINLIST_ENABLED=true\nEnvironment=AUTHORIZATION_ADMINLIST_USERS=\nEnvironment=HOME=/home/weaviate\nEnvironment=PERSISTENCE_DATA_PATH=/data\nEnvironment=AUTHORIZATION_ADMINLIST_ENABLED=true\nEnvironment=AUTHORIZATION_ADMINLIST_USERS=******\nEnvironment=PROMETHEUS_MONITORING_ENABLED=true\nEnvironment=LOG_LEVEL=debug\nExecStart=/etc/weaviatedb/weaviate --tls-host=******* --tls-port=8181 --scheme=https --tls-certificate=/etc/weaviatedb/certs/weaviate.cer.pem --tls-key=/etc/weaviatedb/certs/weaviate.key.pem\nStandardError=append:/weaviate/logs/weaviate.log\nServer Setup Information\n\nWeaviate Server Version: 1.25.13\nDeployment Method:  binary\nMulti Node? Number of Running Nodes: 1\nClient Language and Version:\nMultitenancy?:  no\n\nAny additional Information\n\n----------\n\n[Dirk (2024-09-12T05:47:27.147Z)]: HI, here is a working example: weaviate-python-client/ci/docker-compose-wcs.yml at main · weaviate/weaviate-python-client · GitHub",
    "date_created": "2024-09-11T21:04:55.163Z",
    "has_accepted_answer": false,
    "title": "OIDC Configuration issue",
    "topic_id": 4114
  },
  {
    "user_id": 9150,
    "conversation": "[dreamerwhite (2025-03-09T23:35:41.594Z)]: Description\nhelp!\nI’m deploying weaviate on three machine with docker.\nI got the error on both master node and client node.\nthe error is ：\n{“level”:“warning”,“msg”:\" memberlist: Got ping for unexpected node ‘node2’ from=59.70.88.221:7100\",“time”:“2025-03-09T14:51:16Z”}\n{“level”:“warning”,“msg”:\" memberlist: Got ping for unexpected node node2 from=59.70.88.221:34518\",“time”:“2025-03-09T14:51:16Z”}\n{“level”:“error”,“msg”:\" memberlist: Failed fallback TCP ping: EOF\",“time”:“2025-03-09T14:51:16Z”}\n{“level”:“info”,“msg”:\" memberlist: Suspect node2 has failed, no acks received\",“time”:“2025-03-09T14:51:17Z”}\n{“level”:“warning”,“msg”:\" memberlist: Got ping for unexpected node ‘node2’ from=59.70.88.221:7100\",“time”:“2025-03-09T14:51:17Z”}\n{“level”:“warning”,“msg”:\" memberlist: Got ping for unexpected node node2 from=59.70.88.221:32924\",“time”:“2025-03-09T14:51:17Z”}\n{“level”:“error”,“msg”:\" memberlist: Failed fallback TCP ping: EOF\",“time”:“2025-03-09T14:51:17Z”}\n{“level”:“info”,“msg”:\" memberlist: Suspect node2 has failed, no acks received\",“time”:“2025-03-09T14:51:19Z”}\n{“level”:“warning”,“msg”:\" memberlist: Got ping for unexpected node ‘node2’ from=59.70.88.221:7100\",“time”:“2025-03-09T14:51:20Z”}\n{“level”:“warning”,“msg”:\" memberlist: Got ping for unexpected node node2 from=59.70.88.221:32932\",“time”:“2025-03-09T14:51:20Z”}\n{“level”:“error”,“msg”:\" memberlist: Failed fallback TCP ping: EOF\",“time”:“2025-03-09T14:51:20Z”}\n{“level”:“info”,“msg”:\" memberlist: Marking node2 as failed, suspect timeout reached (0 peer confirmations)“,“time”:“2025-03-09T14:51:21Z”}\n{“level”:“info”,“msg”:” memberlist: Suspect node2 has failed, no acks received\",“time”:“2025-03-09T14:51:23Z”}\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 3\nClient Language and Version:python\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2025-03-10T12:31:50.234Z)]: hi!\nIt seems that they are not able to communicate with each other.\nThe recommended way for multi node cluster is using  our helm charts\nBy the way, why 1.26.1?\nWe suggest always running the latest versions or at least, in your case. 1.26.latest (as I write, 1.26.17)\nLet me know if that helps!\nThanks!",
    "date_created": "2025-03-09T23:35:41.533Z",
    "has_accepted_answer": false,
    "title": "memberlist: Got ping for unexpected node node1 from=59.70.88.222:60544\"",
    "topic_id": 17635
  },
  {
    "user_id": 1214,
    "conversation": "[elias.gabriel (2024-07-17T21:22:10.148Z)]: Description\ni’m seeing some weird behavior with the latest weaviate version running on kubernetes, where cycling pods results in one of the replicas (i have 3) reporting failures (one of them has already been updated and is running, the other has not been terminated/updated yet, and this one erroring is reporting the below). has anyone seen this before?\nAs far as I can tell, the replica that is failing is not the main replica.\nI also observed similar behavior with the simple docker compose setup after docker compose up, then ctrl+c, then docker compose up again.\nthe last line in the log below about data restoration the only thing that the node is logging, about every 10s.\nThis did not happen on 1.25.1, and only started happening once I tried to update my cluster to 1.25.7.\nServer Setup Information\n\nWeaviate Server Version: 1.25.7\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python, V3\nMultitenancy?: No\n\nAny additional Information\n{\"action\":\"graphql_rebuild\",\"error\":\"Could not build GraphQL schema, because: runtime error: invalid memory address or nil pointer dereference at goroutine 108 [running]:\\nruntime/debug.Stack()\\n\\t/usr/local/go/src/runtime/debug/stack.go:24 +0x5e\\ngithub.com/weaviate/weaviate/adapters/handlers/graphql.buildGraphqlSchema.func1.1()\\n\\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/schema.go:105 +0x3d\\npanic({0x19dfea0?, 0x471ccc0?})\\n\\t/usr/local/go/src/runtime/panic.go:914 +0x21f\\ngithub.com/weaviate/weaviate/modules/reranker-transformers.(*ReRankerModule).AdditionalProperties(0xc002a157e0?)\\n\\t/go/src/github.com/weaviate/weaviate/modules/reranker-transformers/module.go:92 +0x16\\ngithub.com/weaviate/weaviate/usecases/modules.(*Provider).GetAdditionalFields(0xc003c1a3c0, 0xc0027dcf20)\\n\\t/go/src/github.com/weaviate/weaviate/usecases/modules/modules.go:493 +0x204\\ngithub.com/weaviate/weaviate/adapters/handlers/graphql/local/get.(*classBuilder).additionalFields(0xc002b77d40, 0xc0030440f0?, 0xc0027dcf20)\\n\\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/local/get/class_builder.go:169 +0x6df\\ngithub.com/weaviate/weaviate/adapters/handlers/graphql/local/get.(*classBuilder).classObject.func1()\\n\\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/local/get/class_builder.go:143 +0x469\\ngithub.com/tailor-inc/graphql.(*Object).Fields(0xc0027e0960)\\n\\t/go/pkg/mod/github.com/tailor-inc/graphql@v0.2.1/definition.go:452 +0x63\\ngithub.com/tailor-inc/graphql.typeMapReducer(0xc002a15df0?, 0xc00302dc80, {0x216c020, 0xc0027e0960?})\\n\\t/go/pkg/mod/github.com/tailor-inc/graphql@v0.2.1/schema.go:333 +0x405\\ngithub.com/tailor-inc/graphql.typeMapReducer(0xc0027e0a50?, 0xc00302dc80, {0x216bfb0, 0xc002b20c60?})\\n\\t/go/pkg/mod/github.com/tailor-inc/graphql@v0.2.1/schema.go:281 +0xc7\\ngithub.com/tailor-inc/graphql.typeMapReducer(0xc0027e0e10?, 0xc00302dc80, {0x216c020, 0xc0027e0a50?})\\n\\t/go/pkg/mod/github.com/tailor-inc/graphql@v0.2.1/schema.go:344 +0x7f8\\ngithub.com/tailor-inc/graphql.typeMapReducer(0xc0027250c0?, 0xc00302dc80, {0x216c020, 0xc0027e0e10?})\\n\\t/go/pkg/mod/github.com/tailor-inc/graphql@v0.2.1/schema.go:344 +0x7f8\\ngithub.com/tailor-inc/graphql.NewSchema({0xc0027e0e10, 0x0, 0x0, {0x0, 0x0, 0x0}, {0x0, 0x0, 0x0}, {0x0, ...}})\\n\\t/go/pkg/mod/github.com/tailor-inc/graphql@v0.2.1/schema.go:104 +0x5bf\\ngithub.com/weaviate/weaviate/adapters/handlers/graphql.buildGraphqlSchema.func1(0xc002a16918, 0xc002a16938, {{0x1ce2ebe, 0xb}, {0x0, 0x0}, {0x1a01900, 0xc00302dc50}, 0x0, {0x1d047c0, ...}, ...})\\n\\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/schema.go:109 +0xfc\\ngithub.com/weaviate/weaviate/adapters/handlers/graphql.buildGraphqlSchema(_, {_, _}, {{0x0, 0x0}, 0x0, {0x64}, 0x186a0, 0x186a0, {{0x0, ...}}, ...}, ...)\\n\\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/schema.go:112 +0x188\\ngithub.com/weaviate/weaviate/adapters/handlers/graphql.Build(_, {_, _}, {_, _}, {{0x0, 0x0}, 0x0, {0x64}, 0x186a0, ...}, ...)\\n\\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/schema.go:57 +0x205\\ngithub.com/weaviate/weaviate/adapters/handlers/rest.rebuildGraphQL({_}, {_, _}, {{0x0, 0x0}, 0x0, {0x64}, 0x186a0, 0x186a0, {{0x0, ...}}, ...}, ...)\\n\\t/go/src/github.com/weaviate/weaviate/adapters/handlers/rest/configure_server.go:70 +0xe5\\ngithub.com/weaviate/weaviate/adapters/handlers/rest.MakeAppState.makeUpdateSchemaCall.func6({0xc003c05b00?})\\n\\t/go/src/github.com/weaviate/weaviate/adapters/handlers/rest/configure_server.go:52 +0xde\\ngithub.com/weaviate/weaviate/usecases/schema.(*executor).TriggerSchemaUpdateCallbacks(0xc003cb56c0)\\n\\t/go/src/github.com/weaviate/weaviate/usecases/schema/executor.go:242 +0x14f\\ngithub.com/weaviate/weaviate/cluster/schema.(*SchemaManager).apply(0xc003c05b30, {{0xc002ce3633, 0xe}, 0xc002b20c40, 0xc002b390e0, 0x1, 0x1})\\n\\t/go/src/github.com/weaviate/weaviate/cluster/schema/manager.go:360 +0x287\\ngithub.com/weaviate/weaviate/cluster/schema.(*SchemaManager).AddClass(0xc003c05b30, 0xc003c037a0, {0xc003b03790, 0xa}, 0x1)\\n\\t/go/src/github.com/weaviate/weaviate/cluster/schema/manager.go:143 +0x369\\ngithub.com/weaviate/weaviate/cluster.(*Store).Apply.func2()\\n\\t/go/src/github.com/weaviate/weaviate/cluster/store_apply.go:140 +0x37\\ngithub.com/weaviate/weaviate/cluster.(*Store).Apply.func12()\\n\\t/go/src/github.com/weaviate/weaviate/cluster/store_apply.go:205 +0x23\\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1()\\n\\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:34 +0x62\\ncreated by github.com/weaviate/weaviate/entities/errors.GoWrapper in goroutine 44\\n\\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:25 +0x79\\n\",\"level\":\"error\",\"msg\":\"could not (re)build graphql provider\",\"time\":\"2024-07-17T16:18:16Z\"}\n{\"level\":\"error\",\"msg\":\"Recovered from panic: runtime error: invalid memory address or nil pointer dereference\",\"time\":\"2024-07-17T16:18:16Z\"}\ngoroutine 109 [running]:\nruntime/debug.Stack()\n\t/usr/local/go/src/runtime/debug/stack.go:24 +0x5e\nruntime/debug.PrintStack()\n\t/usr/local/go/src/runtime/debug/stack.go:16 +0x13\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1.1()\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:30 +0x110\npanic({0x19dfea0?, 0x471ccc0?})\n\t/usr/local/go/src/runtime/panic.go:914 +0x21f\ngithub.com/weaviate/weaviate/modules/text2vec-transformers.(*TransformersModule).Arguments(0xc0029dbc90?)\n\t/go/src/github.com/weaviate/weaviate/modules/text2vec-transformers/nearText.go:26 +0x16\ngithub.com/weaviate/weaviate/usecases/modules.(*Provider).GetArguments(0xc003c1a3c0, 0xc0027dd130)\n\t/go/src/github.com/weaviate/weaviate/usecases/modules/modules.go:356 +0x204\ngithub.com/weaviate/weaviate/adapters/handlers/graphql/local/get.buildGetClassField(0x412ba5?, 0xc0027dd130, {0x2170b20?, 0xc003c1a3c0}, 0xc0029dbf20?)\n\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/local/get/class_builder_fields.go:242 +0x769\ngithub.com/weaviate/weaviate/adapters/handlers/graphql/local/get.(*classBuilder).classField(0xc002d05680, 0xc0027dd130, 0xc003044930?)\n\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/local/get/class_builder.go:102 +0xde\ngithub.com/weaviate/weaviate/adapters/handlers/graphql/local/get.(*classBuilder).kinds(0xc000126a98?, 0xc002d05640)\n\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/local/get/class_builder.go:83 +0x21c\ngithub.com/weaviate/weaviate/adapters/handlers/graphql/local/get.(*classBuilder).objects(...)\n\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/local/get/class_builder.go:65\ngithub.com/weaviate/weaviate/adapters/handlers/graphql/local/get.Build(0xc000126a98, {0x2182d10?, 0xc003af2480?}, {0x2170b20?, 0xc003c1a3c0?})\n\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/local/get/get.go:47 +0x5d\ngithub.com/weaviate/weaviate/adapters/handlers/graphql/local.Build(_, {_, _}, {{0x0, 0x0}, 0x0, {0x64}, 0x186a0, 0x186a0, {{0x0, ...}}, ...}, ...)\n\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/local/local.go:29 +0x4c\ngithub.com/weaviate/weaviate/adapters/handlers/graphql.buildGraphqlSchema(_, {_, _}, {{0x0, 0x0}, 0x0, {0x64}, 0x186a0, 0x186a0, {{0x0, ...}}, ...}, ...)\n\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/schema.go:87 +0x87\ngithub.com/weaviate/weaviate/adapters/handlers/graphql.Build(_, {_, _}, {_, _}, {{0x0, 0x0}, 0x0, {0x64}, 0x186a0, ...}, ...)\n\t/go/src/github.com/weaviate/weaviate/adapters/handlers/graphql/schema.go:57 +0x205\ngithub.com/weaviate/weaviate/adapters/handlers/rest.rebuildGraphQL({_}, {_, _}, {{0x0, 0x0}, 0x0, {0x64}, 0x186a0, 0x186a0, {{0x0, ...}}, ...}, ...)\n\t/go/src/github.com/weaviate/weaviate/adapters/handlers/rest/configure_server.go:70 +0xe5\ngithub.com/weaviate/weaviate/adapters/handlers/rest.MakeAppState.makeUpdateSchemaCall.func6({0xc003c05b00?})\n\t/go/src/github.com/weaviate/weaviate/adapters/handlers/rest/configure_server.go:52 +0xde\ngithub.com/weaviate/weaviate/usecases/schema.(*executor).TriggerSchemaUpdateCallbacks(0xc003cb56c0)\n\t/go/src/github.com/weaviate/weaviate/usecases/schema/executor.go:242 +0x14f\ngithub.com/weaviate/weaviate/cluster/schema.(*SchemaManager).apply(0xc003c05b30, {{0xc002ce3633, 0xe}, 0xc002b218c0, 0xc002b391a0, 0x1, 0x1})\n\t/go/src/github.com/weaviate/weaviate/cluster/schema/manager.go:360 +0x287\ngithub.com/weaviate/weaviate/cluster/schema.(*SchemaManager).AddClass(0xc003c05b30, 0xc003c039e0, {0xc003b03790, 0xa}, 0x1)\n\t/go/src/github.com/weaviate/weaviate/cluster/schema/manager.go:143 +0x369\ngithub.com/weaviate/weaviate/cluster.(*Store).Apply.func2()\n\t/go/src/github.com/weaviate/weaviate/cluster/store_apply.go:140 +0x37\ngithub.com/weaviate/weaviate/cluster.(*Store).Apply.func12()\n\t/go/src/github.com/weaviate/weaviate/cluster/store_apply.go:205 +0x23\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1()\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:34 +0x62\ncreated by github.com/weaviate/weaviate/entities/errors.GoWrapper in goroutine 44\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:25 +0x79\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-07-17T16:18:16Z\"}\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2024-07-17T16:18:16Z\"}\n{\"address\":\"10.0.4.169:8300\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-07-17T16:18:17Z\"}\n{\"level\":\"info\",\"msg\":\"waiting for database to be restored\",\"time\":\"2024-07-17T16:18:24Z\"}\n{\"level\":\"info\",\"msg\":\"waiting for database to be restored\",\"time\":\"2024-07-17T16:18:34Z\"}\n\n----------\n\n[DudaNogueira (2024-07-31T20:56:53.888Z)]: hi @elias.gabriel !!\nWelcome to our community \nSorry! Missed this message. \nJust discovered some messages that went under my radar \nDo you still face this issue?\nSome questions: Have you deployed this using our helm chart?\nWas this cluster ben upgraded from previous versions to 1.25.x?\nHave you seen this migration guide?\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\n1.25 (For Kubernetes users) | Weaviate - Vector Database\n\n  Assumptions & requirements\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!\n\n----------\n\n[elias.gabriel (2024-08-02T18:11:31.395Z)]: I chatted with someone (@Dirk ?) on Slack, and we determined this to be the result of a bug. Releasing and updating to 1.25.8 resolved the issue.\n\n----------\n\n[DudaNogueira (2024-08-02T20:26:25.835Z)]: thanks for sharing!!",
    "date_created": "2024-07-17T21:22:10.081Z",
    "has_accepted_answer": true,
    "title": "GraphQL rebuild error after rolling one or more replicas",
    "topic_id": 3079
  },
  {
    "user_id": 2478,
    "conversation": "[Sudharshan (2024-11-11T10:37:16.136Z)]: Description\nA backup was taken from a multi-node Docker environment using S3 storage, then restored to a Kubernetes environment deployed with Helm and configured with three replicas.\nServer Setup Information\n\nWeaviate Server Version: semitechnologies/weaviate:1.23.7(Docker), semitechnologies/weaviate:1.27.2(K8s)\nDeployment Method: docker & k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python\nMultitenancy: Nil\n\nAny additional Information\nTaking the backup records from weaviate docker running environment and stored the data backups on S3 Bucket.\nLogs from K8s Deployment\n{“action”:“try_restore”,“backend”:“s3”,“backup_id”:“first-backup”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“level”:“error”,“msg”:“cannot resolve hostname for \"node1\"”,“time”:“2024-11-11T10:29:59Z”,“took”:6559398683}\nK8s Deployment Data Backups Restoring1524×115 11.5 KB\nEncountered issues while attempting to change the hostname and pod settings in a Kubernetes deployment, using both Helm and the YAML configuration file.\n\n----------\n\n[DudaNogueira (2024-11-11T21:44:23.297Z)]: hi @Sudharshan !!\nWelcome to our community \nThis is an interesting thing to try and write an article. \nI believe that the issue here is the different cluster hostname.\nwhile in docker, your node hostname were node1, in your k8s it is different.\nDepending on the size of your dataset, you can also migrate the data over.\nI will play around more with this and poke around internally to see if we can come up with some guide o how to restore on that scenario.\nThanks!\n\n----------\n\n[Sudharshan (2024-11-12T06:31:59.497Z)]: K8s Deployment using Helm\nProvide a reference link for deploying Weaviate on Kubernetes using Helm.\nMade changes to the replicas in the values.yaml file and updated the S3 backup configuration with the bucket details and AWS keys. Additionally, attempted to modify the naming convention for the pod but encountered issues preventing the pod service from starting.\n[Tested using a single-node cluster for validation purposes only…] \nkubectl describe pod/node-0 -n weaviate\n\nPod Status for Naming Changes1532×375 33 KB\nLog for K8s Pod\n\n{“action”:“bootstrap”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“join_list”:{“weaviate-0”:8300},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2024-11-12T06:23:32Z”}\n{“action”:“bootstrap”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“join_list”:{“weaviate-0”:8300},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2024-11-12T06:23:34Z”}\n{“action”:“bootstrap”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“join_list”:{“weaviate-0”:8300},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2024-11-12T06:23:35Z”}\n{“action”:“bootstrap”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“join_list”:{“weaviate-0”:8300},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2024-11-12T06:23:36Z”}\n{“action”:“bootstrap”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“join_list”:{“weaviate-0”:8300},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2024-11-12T06:23:38Z”}\n{“action”:“bootstrap”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“join_list”:{“weaviate-0”:8300},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2024-11-12T06:23:39Z”}\n{“action”:“bootstrap”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“join_list”:{“weaviate-0”:8300},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2024-11-12T06:23:40Z”}\n{“action”:“bootstrap”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“join_list”:{“weaviate-0”:8300},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2024-11-12T06:23:42Z”}\n{“action”:“bootstrap”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“join_list”:{“weaviate-0”:8300},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2024-11-12T06:23:43Z”}\n{“action”:“bootstrap”,“build_git_commit”:“64457c2”,“build_go_version”:“go1.22.9”,“build_image_tag”:“v1.27.2”,“build_wv_version”:“1.27.2”,“join_list”:{“weaviate-0”:8300},“level”:“warning”,“msg”:“unable to resolve any node address to join”,“time”:“2024-11-12T06:23:44Z”}\n\nIs there a way to migrate data from a Docker environment to a Kubernetes environment in Weaviate?\nThanks\n\n----------\n\n[DudaNogueira (2024-11-12T19:21:04.765Z)]: well, if you don’t want to move your data, and is ok with actually mgirating it (copying from source and inserting to target), you can use this migration guide:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Learn how to migrate data within Weaviate for easy data handling.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIf course, it would be interesting to tame this store from different deployments, but that can take some time",
    "date_created": "2024-11-11T10:37:16.079Z",
    "has_accepted_answer": false,
    "title": "Docker to K8s Backups using s3",
    "topic_id": 7533
  },
  {
    "user_id": 513,
    "conversation": "[rjalex (2024-10-22T15:32:58.399Z)]: I have objects with a text title and kicker properties. I will use my own bge-m3 vectorizer. What is the difference between these two styles of using them in the retrieval phase?\nvectorizer_config=[\n            wvc.config.Configure.NamedVectors.none(source_properties=[\"title\",\"kicker\"],name=\"title_bge-m3\")]\n\nor just do a title+’ '+kicker and vectorize this single field?\nThanks\n\n----------\n\n[DudaNogueira (2024-10-24T13:00:21.849Z)]: Ciao @rjalex !\nYou mean passing a list of NamedVectors to vectrorizer_config instead of the usual  wvc.config.Configure.Vectorizer?\nIf that’s the case, you could get the same result of wvc.config.Configure.Vectorizer if you name your NamedVector as “default”.\nNamedVectors is more flexible/easier to configure, IMO, as you can specify at the namedvector definition the properties that will be used, instead of defining  at the property.\nSo, at the end, you can define that single named vector. Now that you have named it as title_bge_m3 you will need to specify it while retrieving (target_vector) and when inserting the object with the vector, you will need to pass it as a dict:\ncollection.data.insert(\n    {\"text\": \"This is a test\"},\n    vector={\n        \"title_bge-m3\": [1,2,3,4]\n    }\n)\n\n----------\n\n[rjalex (2024-10-24T13:21:04.418Z)]: Muiro obrigado @DudaNogueira",
    "date_created": "2024-10-22T15:32:58.357Z",
    "has_accepted_answer": true,
    "title": "Help wrapping my head on two named vectors configs",
    "topic_id": 5844
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-11-27T08:58:49.247Z)]: If a record already exists, then inserting it will cause a 422 error. However, I’m confused on how to handle this error as it emits an “UnexpectedStatusCodeError”\nIn this Python code, how can I specifically catch record already exists errors?  I tried checking the docs, but couldn’t find how to catch this one as I wish to not raise an exception when it occurs\ntry:\n\t\ttenant_collection = get_tenant_collection(tenant_name)\n\t\t\n\t\tuniqueid = tenant_collection.data.insert(\n\t\t\tvector=record.vector,\n\t\t\tproperties=record.properties,\n\t\t\tuuid=record.uniqueid\n\t\t)\n\n\t\treturn uniqueid\n\texcept:\n\t\t# if already exists, wil throw 422 error\n\t\tprint('Error in insert record')\n\t\ttraceback.print_exc()\n\t\traise Exception(\"Failed to insert record\")\n\n----------\n\n[DudaNogueira (2024-12-03T13:11:55.747Z)]: hi! @Tejas_Sharma !!!\nSorry, missed this message (last week was crazy).\nIndeed this specific error get only a hint of what happened at the error message, and not raising a specific error.\nI have questioned it with our team.\nThe best route here is to open a feature request at GitHub - weaviate/weaviate-python-client: A python native client for easy interaction with a Weaviate instance.\nThanks!",
    "date_created": "2024-11-27T08:58:49.197Z",
    "has_accepted_answer": false,
    "title": "How to handle record already exists insert error",
    "topic_id": 8546
  },
  {
    "user_id": 839,
    "conversation": "[Tomas (2024-04-18T10:49:18.738Z)]: Hi,\nwe are storing non-English texts in WSC. Since the Stopwords Preset for an inverted index (BM25) is set to None, there is a lot of search for high occurrence keywords happening. And the keyword search gets compromised.\nWe can replicate it for English texts and demonstrate it a on the Quickstart Tutorial in Weviate Docs (Quickstart Tutorial | Weaviate - Vector Database). Using the same code and the same data (10 entries from a TV quiz show “Jeopardy!” with properties ‘category’, ‘question’, ‘answer’) and searching via BM25 for a query “the science is” gives you as a result 6 entries with the same score 0.35819104313850403.\nOnce you set Stopwords Preset to None in the collection definition (and allow for a search for high occurrence words), it starts giving you as a result more entries than there are in the original dataset (i. e. more than 10), meaning it starts giving you duplicate entries with different scores. To make things worse, the result is very different every time you make a fresh import of the dataset (aplies to both insert_many() and batch import).\nAn example result in full (returns 14 objects, 4 duplicates - answers: DNA, Liver, Antelope, species):\n0.6708551645278931\n, BM25F_is_frequency:1, BM25F_is_propLength:14, BM25F_science_frequency:1, BM25F_science_propLength:1\n{'answer': 'wire', 'question': 'A metal that is ductile can be pulled into this while cold & under pressure', 'category': 'SCIENCE'}\n\n0.5260506272315979\n, BM25F_is_frequency:1, BM25F_is_propLength:10, BM25F_the_frequency:1, BM25F_the_propLength:3\n{'answer': 'the diamondback rattler', 'question': 'Heaviest of all poisonous snakes is this North American rattlesnake', 'category': 'ANIMALS'}\n\n0.4687879681587219\n, BM25F_science_propLength:1, BM25F_the_frequency:2, BM25F_the_propLength:14, BM25F_science_frequency:1\n{'answer': 'the atmosphere', 'question': 'Changes in the tropospheric layer of this are what gives us weather', 'category': 'SCIENCE'}\n\n0.35819104313850403\n, BM25F_science_frequency:1, BM25F_science_propLength:1\n{'answer': 'Sound barrier', 'question': 'In 70-degree air, a plane traveling at about 1,130 feet per second breaks it', 'category': 'SCIENCE'}\n\n0.35819104313850403\n, BM25F_the_frequency:2, BM25F_the_propLength:15, BM25F_science_frequency:1, BM25F_science_propLength:1\n{'answer': 'DNA', 'question': 'In 1953 Watson & Crick built a model of the molecular structure of this, the gene-carrying substance', 'category': 'SCIENCE'}\n\n0.35819104313850403\n, BM25F_science_propLength:1, BM25F_the_frequency:1, BM25F_the_propLength:18, BM25F_science_frequency:1\n{'answer': 'species', 'question': \"2000 news: the Gunnison sage grouse isn't just another northern sage grouse, but a new one of this classification\", 'category': 'SCIENCE'}\n\n0.35819104313850403\n, BM25F_science_frequency:1, BM25F_science_propLength:1, BM25F_the_frequency:1, BM25F_the_propLength:12\n{'answer': 'Liver', 'question': 'This organ removes excess glucose from the blood & stores it as glycogen', 'category': 'SCIENCE'}\n\n0.31266409158706665\n, BM25F_is_propLength:14, BM25F_the_frequency:2, BM25F_the_propLength:14, BM25F_is_frequency:1\n{'answer': 'Antelope', 'question': 'Weighing around a ton, the eland is the largest species of this animal in Africa', 'category': 'ANIMALS'}\n\n0.1350332498550415\n, BM25F_the_frequency:2, BM25F_the_propLength:9\n{'answer': 'Elephant', 'question': \"It's the only living mammal in the order Proboseidea\", 'category': 'ANIMALS'}\n\n0.11059693247079849\n, BM25F_is_propLength:14, BM25F_the_frequency:2, BM25F_the_propLength:14, BM25F_is_frequency:1\n{'answer': 'Antelope', 'question': 'Weighing around a ton, the eland is the largest species of this animal in Africa', 'category': 'ANIMALS'}\n\n0.10673391073942184\n, BM25F_the_frequency:2, BM25F_the_propLength:15, BM25F_science_frequency:1, BM25F_science_propLength:1\n{'answer': 'DNA', 'question': 'In 1953 Watson & Crick built a model of the molecular structure of this, the gene-carrying substance', 'category': 'SCIENCE'}\n\n0.09976458549499512\n, BM25F_the_frequency:2, BM25F_the_propLength:17\n{'answer': 'the nose or snout', 'question': 'The gavial looks very much like a crocodile except for this bodily feature', 'category': 'ANIMALS'}\n\n0.07754258811473846\n, BM25F_the_propLength:12, BM25F_science_frequency:1, BM25F_science_propLength:1, BM25F_the_frequency:1\n{'answer': 'Liver', 'question': 'This organ removes excess glucose from the blood & stores it as glycogen', 'category': 'SCIENCE'}\n\n0.05944186821579933\n, BM25F_the_frequency:1, BM25F_the_propLength:18, BM25F_science_frequency:1, BM25F_science_propLength:1\n{'answer': 'species', 'question': \"2000 news: the Gunnison sage grouse isn't just another northern sage grouse, but a new one of this classification\", 'category': 'SCIENCE'}\n\nExample results of 3 different imports of the same dataset:\n\n\n\n\nAnswer + score\nAnswer + score\nAnswer + score\n\n\n\n\n‘wire’ - 0.6708551645278931\n‘wire’ - 0.6708551645278931\n‘wire’ - 0.6708551645278931\n\n\n‘the diamondback rattler’ - 0.5260506272315979\n‘the diamondback rattler’ - 0.5260506272315979\n‘the diamondback rattler’ - 0.5260506272315979\n\n\n‘the atmosphere’ - 0.4687879681587219\n‘the atmosphere’ - 0.4687879681587219\n‘the atmosphere’ - 0.4687879681587219\n\n\n‘Antelope’ - 0.42326104640960693\n‘DNA’ - 0.35819104313850403\n‘Liver’ - 0.4357336163520813\n\n\n‘species’ - 0.41763290762901306\n‘Liver’ - 0.35819104313850403\n‘Sound barrier’ - 0.35819104313850403\n\n\n‘DNA’ - 0.35819104313850403\n‘Sound barrier’ - 0.35819104313850403\n‘species’ - 0.35819104313850403\n\n\n‘Liver’ - 0.35819104313850403\n‘species’ - 0.35819104313850403\n‘DNA’ - 0.35819104313850403\n\n\n‘Sound barrier’ - 0.35819104313850403\n‘Antelope’ - 0.31266409158706665\n‘Antelope’ - 0.31266409158706665\n\n\n‘Elephant’ - 0.1350332498550415\n‘Elephant’ - 0.1350332498550415\n‘Elephant’ - 0.1350332498550415\n\n\n‘DNA’ - 0.10673391073942184\n‘Antelope’ - 0.11059693247079849\n‘Antelope’ - 0.11059693247079849\n\n\n‘the nose or snout’ - 0.09976458549499512\n‘DNA’ - 0.10673391073942184\n‘DNA’ - 0.10673391073942184\n\n\n‘Liver’ - 0.07754258811473846\n‘the nose or snout’ - 0.09976458549499512\n‘the nose or snout’ - 0.09976458549499512\n\n\n\n‘Liver’ - 0.07754258811473846\n‘species’ - 0.05944186821579933\n\n\n\n‘species’ - 0.05944186821579933\n\n\n\n\n\n\n\n\n12 results (2 duplicates)\n14 results (4 duplicates)\n13 results (3 duplicates)\n\n\n\nWhen you dig deeper into the details you can find that when you query separate properties (i. e. ‘category’, ‘question’, ‘answer’) via query_properties parametr of bm25(), the results have consistent scores for each import and no duplicates occur. So the BM25 search itself works but the algorithm which fuses the score of each property into a score of the whole object is broken.\nAlso we don’t think there is a problem with Stopwords Preset itself. More likely the problem lays in a keyword search for words with a high occurrence which is only hidden by Stopwords Preset set to EN.\nThe same problem occurs with larger datasets, the small dataset was chosen for brevity.\nIt might seem as a small bug but it prohibits any production use for non-English texts and any domain specific texts containing a high frequency of same words which are not defined as stopwords (e. g. legal texts).\n\nWeaviate Server Version: 1.24.8\nDeployment Method: WSC\nClient Language and Version: Python weaviate-client 4.5.5\n\nCode used:\nimport weaviate\nimport weaviate.classes as wvc\nimport os\nimport requests\nimport json\n\nclient = weaviate.connect_to_wcs(\n    cluster_url=os.getenv(\"WCS_URL\"),\n    auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WCS_API_KEY\")),\n    headers={\n        # Replace with your inference API key\n        \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY\"]\n    }\n)\n\ntry:\n    # ===== define collection =====\n    questions = client.collections.create(\n        name=\"Question\",\n        # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n        # Ensure the `generative-openai` module is used for generative queries\n        generative_config=wvc.config.Configure.Generative.openai(),\n        inverted_index_config=wvc.config.Configure.inverted_index(\n            stopwords_preset=wvc.config.StopwordsPreset.NONE,\n        ),\n    )\n\n    # ===== import data =====\n    resp = requests.get(\n        'https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json')\n    data = json.loads(resp.text)  # Load data\n\n    question_objs = list()\n    for i, d in enumerate(data):\n        question_objs.append({\n            \"answer\": d[\"Answer\"],\n            \"question\": d[\"Question\"],\n            \"category\": d[\"Category\"],\n        })\n\n    questions = client.collections.get(\"Question\")\n    questions.data.insert_many(question_objs)\n\n    response = questions.query.bm25(\n        query=\"the science is\",\n        return_metadata=wvc.query.MetadataQuery(score=True),\n    )\n\n    for obj in response.objects:\n        print(obj.metadata.score)\n        print(obj.metadata.explain_score)\n        print(obj.properties)\n        print()\n\nfinally:\n    client.close()  # Close client gracefully\n\n----------\n\n[DudaNogueira (2024-04-18T14:29:46.403Z)]: hi @Tomas !! Welcome to our community! \nNice catch. Looks like a bug indeed. I was also able to reproduce it on my end.\nThanks a lot for this finding and awesome report! \nDo you mind opening an issue in our github?\nI can also do it, if you can’t.\nThanks again!\n\n----------\n\n[DudaNogueira (2024-04-19T19:05:16.573Z)]: by the way, the issue was created. Thanks a lot.\nLink for reference: Duplicate and inconsistent results of BM25 search · Issue #4719 · weaviate/weaviate · GitHub\n\n----------\n\n[Tomas (2024-08-11T12:53:04.395Z)]: As I can see no one was even assigned to this problem\n\n----------\n\n[DudaNogueira (2024-08-12T21:37:11.623Z)]: hi @Tomas !\nSorry for the delay.\nUnfortunately our team had “laser focus” on some implementation delivered in 1.25 and 1.26\nAs those are now released, we’ll have a sprint to deal with all those kind of issues, as well as reviewing bounties, etc.\nThanks for your patience!\n\n----------\n\n[Neil (2024-10-02T18:19:11.230Z)]: Hi @DudaNogueira, I think your team is doing a great job on following up.\nI was curious is there a plan to work on this issue before end of calendar year?\nAlso, will testing for duplicative + inconsistent results be also tested for hybrid alongside BM25 results during this bug fix?\n\n----------\n\n[Dirk (2024-10-04T09:45:52.704Z)]: There has been a fix in the latest version for BM25 - could you have a look if it still happens for you?\nIf yes - could you provide an example for us to reproduce it?",
    "date_created": "2024-04-18T10:49:18.635Z",
    "has_accepted_answer": true,
    "title": "BUG - Duplicate and inconsistent results of BM25 search",
    "topic_id": 2065
  },
  {
    "user_id": 900,
    "conversation": "[P_K (2025-01-24T08:36:33.311Z)]: I want to create a single collection with 2 tenants: tenant1, tenant2\nI need to use openai embeddings for tenant1 and ollama embeddings for tenant 2.\nDoes existing Weaviate support setting different vectorizer for tenants ?\n\n----------\n\n[Mohamed_Shahin (2025-01-24T11:42:25.297Z)]: Hello @P_K,\nThat’s actually a great idea for a future feature! Please make sure to log it as a new feature request here\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nweaviate/weaviate\n\n  Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of ...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nUnfortunately, if you’re looking to use different vectorizers, you can leverage multi-vector (named vector) functionality, but this only applies to properties within a collection.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMultiple vectors | Weaviate\n\n  [comment] multi-vector-support dot mdx )\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nwhich I thought might give you an idea or potential workaround for your use case.\nAlso, I wanted to highlight an awesome new feature in our documentation—Weaviate Docs AI. You can ask it any questions, and it’ll guide you through the information\nimage725×448 29 KB\nI hope this helps, and feel free to reach out if you have any further questions!\nBest regards,\nMohamed Shahin\nWeaviate Support Engineer",
    "date_created": "2025-01-24T08:36:33.260Z",
    "has_accepted_answer": true,
    "title": "Can we use different vectorizers for different tenants in multi-tenant collection?",
    "topic_id": 9880
  },
  {
    "user_id": 94,
    "conversation": "[junbetterway (2024-08-06T06:33:47.989Z)]: Description\nGetting “nested query: nested clause at pos 1: invalid search term, only stopwords provided. Stopwords can be configured in class.invertedIndexConfig.stopwords” when conditional filter has an input of single or double quotes\nServer Setup Information\n\nWeaviate Server Version: 1.23.7\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version:\nMultitenancy?: No\n\nAny additional Information\nBasically, we have this one free text input → “skills” which uses containsAny operator filter and since its free text, users can input whatever they can, however we noticed that if users tried to enter single (') or double quotes (\") then the vector database gives us the error mentioned above.\nWe’re seeing one quick solution is to add the single and double quotes to the stopwords → additions, however, can you give me a sample REST/CURL command to achieve this where I just need to modify invertedIndexConfig at runtime without the need to recreate the collection, else if not possible, then do we have a better solution for it?\nPlease see below sample schema snippet of class Profile:\n      \"class\": \"Profile\",\n      \"vectorizer\": \"text2vec-transformers\",\n      \"invertedIndexConfig\": {\n        \"indexNullState\": true,\n        \"indexTimestamps\": true,\n        \"stopwords\": {\n          \"preset\": \"en\",\n          \"additions\": null,\n          \"removals\": [\"it\"]\n        }\n      },\n      \"properties\": [\n        ...\n        ... REMOVED FOR BREVITY\n          {\n            \"name\": \"skills\",\n            \"description\": \"Profile tags to showcase their skills, tech tools, etc.\",\n            \"dataType\": [\n              \"text[]\"\n            ],\n            \"moduleConfig\": {\n              \"text2vec-transformers\": {\n                \"skip\": false,\n                \"vectorizePropertyName\": false\n              }\n            }\n          }\n        },\n\n----------\n\n[DudaNogueira (2024-08-07T17:26:23.138Z)]: hi @junbetterway  !! Long time no see \nI was not able to reproduce this on 1.26.1 nor on 1.23.7\nPlease, check if my code is what you are doing:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n    properties=[\n        wvc.config.Property(\n            name=\"name\", data_type=wvc.config.DataType.TEXT\n        ),        \n        wvc.config.Property(\n            name=\"skills\", data_type=wvc.config.DataType.TEXT_ARRAY\n        ),\n    ],\n    inverted_index_config=wvc.config.Configure.inverted_index(\n        stopwords_removals=[\"it\"],\n        stopwords_preset=wvc.config.StopwordsPreset.EN\n    )\n)\ncollection.data.insert({\"name\": \"skill set 1\", \"skills\": [\"account\", \"hr\", \"sales\"]})\ncollection.data.insert({\"name\": \"skill set 2\", \"skills\": [\"engineering\", \"sales\", \"finance\"]})\ncollection.data.insert({\"name\": \"skill set 3\", \"skills\": [\"it\", \"training\", \"other\"]})\ncollection.data.insert({\"name\": \"skill set 3\", \"skills\": [\"'it'\", \"training\", \"other\"]})\n\nNow I can search:\nfor o in collection.query.fetch_objects(\n    filters=wvc.query.Filter.by_property(\"skills\").contains_any([\"it\"])\n).objects:\n    print(o.properties)\n\nthose are the versions used:\nprint(weaviate.__version__, \"/\", client.get_meta().get(\"version\"))\n# client version / server version\n>>> 4.7.1 / 1.26.1\n\nLet me know what we can do in this code to try replicating this issue.\nTHanks!\n\n----------\n\n[junbetterway (2024-08-08T05:04:10.244Z)]: Yeah long time no post indeed! \nAnyways, yes looks like it gonna work but what if you try to search single or double quotes? (Not a python dev so not sure how you will search for a single quote in below code)\nfor o in collection.query.fetch_objects(\n    filters=wvc.query.Filter.by_property(\"skills\").contains_any([\" \\' \"])\n).objects:\n    print(o.properties)",
    "date_created": "2024-08-06T06:33:47.937Z",
    "has_accepted_answer": false,
    "title": "Getting “nested query: nested clause at pos 1: invalid search term, only stopwords provided. Stopwords can be configured in class.invertedIndexConfig.stopwords” when conditional filter has an input of single or double quotes",
    "topic_id": 3271
  },
  {
    "user_id": 2462,
    "conversation": "[Tuana (2024-11-11T14:38:23.038Z)]: Hey hey, starting to document what I find/experience so I figured I can also add them to the forum.\nI’m doing the 101 academy course which has lots of references to various dataclasses and methods naturally. However, various dataclasses that one might want to look up in documentation and read through the reference are missing in the docs.\nThere seems to have been this page in the past which still appears in the search: Python | Weaviate\nBut that’s no longer live (I think).\nSo tldr, 3 bits of feedback:\n\nHaving a docs page with a reference to the various dataclasses and what they are for/their init variables etc would be SUPER useful\nIf this page exists, there seems to be a problem with the discoverability\nWe should start linking to the docs reference pages for methods/classes mentioned in the Academy courses\n\n----------\n\n[DudaNogueira (2024-11-11T16:09:40.928Z)]: hi @Tuana !! Welcome to Weaviate (again hehehe) and to our forums \nIs this what you are looking for?\nhttps://weaviate-python-client.readthedocs.io/en/stable/genindex.html\nI see a link to it from here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Utilize the Python client library to access Weaviate and streamline data processes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor example, if you want to learn all about the connect_to_custom method\nLet me know if that helps!\n\n----------\n\n[Tuana (2024-11-13T09:35:23.500Z)]: Hey Duda, I suppose that is what I’m looking for. Where in that page did you link to this? It’s quite difficult to discover I would say. Also not easy to navigate to the reference you need when you get there. I was looking for MetadataQuery for example.\nMaybe I can raise this with the DevRel team…? Wdyt?\n\n----------\n\n[DudaNogueira (2024-11-13T13:49:24.697Z)]: It is linked from here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Utilize the Python client library to access Weaviate and streamline data processes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nand also from the python client repo as well:\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nGitHub - weaviate/weaviate-python-client: A python native client for easy...\n\n  A python native client for easy interaction with a Weaviate instance. - weaviate/weaviate-python-client\n\n----------\n\n[DudaNogueira (2024-11-13T13:51:06.028Z)]: Indeed we could link it from more places",
    "date_created": "2024-11-11T14:38:22.984Z",
    "has_accepted_answer": false,
    "title": "[Docs] Python Dataclasses missing",
    "topic_id": 7537
  },
  {
    "user_id": 3052,
    "conversation": "[RamuA (2025-01-23T08:58:06.323Z)]: Dear Weaviate Team,\nI am really excited to work with Weaviate DB, and I would like to learn about the features of using the Python client for Weaviate version 4.\nCan we use a command-line interface (CLI) to connect to Weaviate DB, similar to how we use MongoDB shell or MySQL command prompt?\nWhat are the future plans for making the database more user-friendly?\nIs it possible to take backups and restore the database using the Python client for Weaviate DB?\nI would also like to create users and manage their access levels. Do you have any documentation for these steps?\nThanks\nRamu A\n\n----------\n\n[Mohamed_Shahin (2025-01-23T10:47:54.823Z)]: Hello @RamuA,\nI hope you’re having a great week!\nWe’re always happy to support you and ensure you’re enjoying your experience with Weaviate.\nHave you had a chance to check out our Weaviate-CLI? It’s exactly what you’re looking for. We’re continually improving it, and since it’s open source, you’re welcome to contribute to it if you’d like:\n\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate/weaviate-cli: CLI tool for Weaviate\n\n    CLI tool for Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAdditionally, in our Cloud offering, we provide a UI where you can interact with the database directly with awesome tools and Weaviate Lap Apps. You can try it out in a Sandbox to see the UI.\nAs for backups, you can indeed create and manage backups using the Python Client:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBackups | Weaviate\n\n  Weaviate's Backup feature is designed to work natively with cloud technology. Most notably, it allows:\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYou can also perform backups using the CLI tool.\nFor detailed information about Authorization and Access Levels, refer to this:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAuthorization & RBAC | Weaviate\n\n  Authentication and authorization are closely related concepts, and sometimes abbreviated as AuthN and AuthZ. Authentication (AuthN) is the process of verifying the identity of a user, while authorization (AuthZ) is the process of determining what...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI hope this helps! Let me know if you have any other questions.\nRegards,\nMohamed Shahin\nWeaviate Support",
    "date_created": "2025-01-23T08:58:06.275Z",
    "has_accepted_answer": true,
    "title": "Play around Python client for Weaviate version 4",
    "topic_id": 9862
  },
  {
    "user_id": 3139,
    "conversation": "[Rohini_vaidya (2025-01-02T17:16:48.820Z)]: Hi, I am trying to perform a hybrid search with alpha=0.5 and am getting responses, but I would like to validate the search process. To do so, I printed the scores from the metadata. However, I observed that for every document in the results, the score is the same, i.e., 0.5.\nHere is my code snippet:\nresponse = collection.query.hybrid(\n    query=\"my query\",\n    query_properties=[\"test\"],\n    alpha=0.5,\n    fusion_type=HybridFusion.RELATIVE_SCORE,\n    \n    return_metadata=MetadataQuery(score=True, explain_score=True),\n    limit=5,\n)\n\nfor o in response.objects:\n    print(o.properties)\n    print(o.metadata.score,o.metadata.explain_score)\n\nExample Output:\n\nDocument 1 Result:\nHybrid (Result Set keyword, bm25) Document 854678e5-af01-4658-b55f-0427c0544a32:\nOriginal score: 15.578449, Normalized score: 0.5\nDocument 2 Result:\nHybrid (Result Set vector, hybridVector) Document d745302e-84a6-42d9-bee1-5b104be285e3:\nOriginal score: 0.7183615, Normalized score: 0.5\n\nObservations:\n\nWhen alpha=0.5, the normalized scores for all documents are the same (0.5), irrespective of the query type.\nWhen experimenting with alpha:\n\n\nAt alpha=0 (pure keyword search), the scores differ for each document.\nAt alpha=1 (pure vector search), the normalized scores are again the same for all documents.\n\nQuery: Am I missing something in my implementation or understanding of the hybrid search process? Could you provide any suggestions or clarifications on this behavior?\n\n----------\n\n[DudaNogueira (2025-01-02T17:55:50.110Z)]: hi @Rohini_vaidya !!\nHow many objects are there?\nWhat I am finding weird is that looks like there is no vector distance for Document1 \nthe keyword,bm25 score will only be accounted if the object has indeed any of the query tokens.\nHowever, the vector distance should always be present.\nFor example:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\"Test\", vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai())\ncollection.data.insert({\"text\": \"a beautiful dog\"})\ncollection.data.insert({\"text\": \"a nice cat\"})\n\nr = collection.query.hybrid(query=\"cat\", return_metadata=wvc.query.MetadataQuery(score=True, explain_score=True), alpha=0.5)\nfor o in r.objects:\n    print(\"#*10\")\n    print(o.properties)\n    print(o.metadata.explain_score)\n\nand this is the output:\n\n##########\n{‘text’: ‘a nice cat’}\nHybrid (Result Set keyword,bm25) Document 2b19e024-5261-46d3-85ae-5110806d081c: original score 0.3150669, normalized score: 0.5 -\nHybrid (Result Set vector,hybridVector) Document 2b19e024-5261-46d3-85ae-5110806d081c: original score 0.4917053, normalized score: 0.5\n##########\n{‘text’: ‘a beautiful dog’}\nHybrid (Result Set vector,hybridVector) Document 34a189b1-4fd5-4b4f-8e77-23e9e2ea2def: original score 0.32074285, normalized score: 0\n\nLet me know if you can provide a dataset where this is reproducible.\nThanks!\n\n----------\n\n[Rohini_vaidya (2025-01-03T04:00:39.024Z)]: Thank you, @DudaNogueira.\nI have a total of three objects in my dataset, but I’m unable to share the dataset itself. When I tested the example you provided, it returned the correct results.\nNow, I’m a bit confused about why this discrepancy is occurring in my case. Could you help to clarify?\n\n----------\n\n[DudaNogueira (2025-01-03T13:59:36.775Z)]: Feel free to reach out to me in our public slack.\nWe could then do a screen sharing session so I can take a closer look.\nI am assuming you are using latest version on server, right?\n\n----------\n\n[Rohini_vaidya (2025-01-04T05:47:16.023Z)]: Thank you, @DudaNogueira.\nCould you please provide a reference document or guidance on importing multiple vectors from a dictionary into a collection?\nScenario:\nI have a dictionary with key-value pairs in the format string: [vector]. I need to import these vectors into a collection. For example:\nvector = {\n    \"a_vector\": strings_map[row[\"a\"]],\n    \"b_vector\": strings_map[row[\"b\"]],\n    \"c_vector\": strings_map[row[\"c\"]]\n}\n\n\nHere,have a dictionary strings_map with key-value pairs in the format string: [vector]. I’m mapping specific keys (a, b, c) from a row object to corresponding vector values from a strings_map dictionary.\nHow can I efficiently import such vectors into a collection?\n\n----------\n\n[DudaNogueira (2025-01-06T14:00:31.886Z)]: hi @Rohini_vaidya !!\nHere is how you can do that:\nvectors = {\n    \"a_vector\": [1,2,3],\n    \"b_vector\": [1,2,3,4],\n    \"c_vector\": [1,2,3,4,5]\n}\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\", \n    vectorizer_config=[\n        wvc.config.Configure.NamedVectors.none(name=\"a_vector\"),\n        wvc.config.Configure.NamedVectors.none(name=\"b_vector\"),\n        wvc.config.Configure.NamedVectors.none(name=\"c_vector\"),\n    ]\n)\ncollection.data.insert(\n    properties={\"text\": \"music for running\", \"brand\": \"Bosch\"},\n    vector=vectors\n)\n\nnow you can get your objects:\nquery = collection.query.fetch_objects(include_vector=True)\nprint(query.objects[0].properties)\nprint(query.objects[0].vector)\n\n# outputs:\n# {'text': 'music for running', 'brand': 'Bosch'}\n# {'a_vector': [1.0, 2.0, 3.0], 'b_vector': [1.0, 2.0, 3.0, 4.0], 'c_vector': [1.0, 2.0, 3.0, 4.0, 5.0]}\n\nYou can also search using near_vector:\nquery = collection.query.near_vector(\n    near_vector=[5,4,3,2,1], include_vector=True, target_vector=\"c_vector\", return_metadata=wvc.query.MetadataQuery(distance=True)\n)\nprint(query.objects[0].properties)\nprint(query.objects[0].vector)\nprint(query.objects[0].metadata.distance)\n\n# outputs:\n# {'text': 'music for running', 'brand': 'Bosch'}\n# {'c_vector': [1.0, 2.0, 3.0, 4.0, 5.0], 'a_vector': [1.0, 2.0, 3.0], 'b_vector': [1.0, 2.0, 3.0, 4.0]}\n# 0.3636362552642822\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Rohini_vaidya (2025-01-06T16:19:21.484Z)]: Thank you, @DudaNogueira.\nThis works for me.",
    "date_created": "2025-01-02T17:16:48.755Z",
    "has_accepted_answer": false,
    "title": "Scores for Hybrid search",
    "topic_id": 9544
  },
  {
    "user_id": 695,
    "conversation": "[weisisheng (2025-01-22T03:38:02.968Z)]: Description\n\nUsing WCS, SST, and Hono, this example works:  Building AI Search APIs with Hono.js | Weaviate\nBut when I try to connect to my pre-existing collections and do a simple vector search< i get the error “{“error”: “Metadata key ‘x-openai-api-key’ doesn’t end with ‘-bin’, thus it must have string value”}”\nServer Setup Information\n\nWeaviate Server Version: 1.28.x\nDeployment Method: WCS\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: weaviate-client: 3.3.4\nMultitenancy?: no\n\nAny additional Information\n\n----------\n\n[weisisheng (2025-01-22T03:52:53.691Z)]: Something to do with dotenv library I believe.  Now failing to find api key in .env.\nSwitched from this “const openaiKey = process.env.OPENAI_API_KEY as string;” to \"const openaiKey = process.env.OPENAI_API_KEY || “”;\n\n----------\n\n[weisisheng (2025-01-22T04:33:07.972Z)]: Sigh, deprecated api key…\n\n----------\n\n[Mohamed_Shahin (2025-01-22T11:10:25.146Z)]: @weisisheng thank you for letting us know the reason! I am glad to hear you got it resolved.",
    "date_created": "2025-01-22T03:38:02.916Z",
    "has_accepted_answer": true,
    "title": "Weird openaikey reference error I've never seen before (and can't find online)",
    "topic_id": 9845
  },
  {
    "user_id": 1615,
    "conversation": "[blue-j (2024-10-01T05:48:48.562Z)]: Description\n\nI’ve been told by GPT-4o that to change the distance metric for a collection, you have to back up all your data and metadata, delete the old schema and data, implement the new schema with the different distance metric, and reimport the data.  Is this blasphemy true??  GPT-4o seems to be up to speed on v3 API mainly, so maybe that is the cause of the misinformation?  - J\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-10-01T08:40:20.214Z)]: hi @blue-j !!\nWelcome to our community \nIndeed, this is true. \nThere are some collection properties that are mutable, but some are not.\nWe have a list of this mutability here.\nThe reasoning behind this is that there is a lot of computation that goes behind while ingesting and building the index using the distance metric.\nChanging the distance metric means that all those calculation will get “lost” and need to be done again.\nWe are working on implementing a way to reindex your data, that will allow some of those options to be mutable. For large datasets that will mean a huge increase on resource usage, so we are figuring out the best way to implement that.\nMigrating your data to a new collection on a different cluster or event a second collection at the same cluster is fairly easy. Here is a guide on how to do that: Migrate data | Weaviate\nWe understand that someone coming from a “regular” database this is a “blasphemy” (hahaha) but you need to understand that a Vector database will not only store the data and create some inverted index. There is a lot of other computation going on.\nLet me know if this helps!\n\n----------\n\n[blue-j (2024-10-01T21:52:12.836Z)]: Thanks for the warm welcome!  I totally understand.  This is tough stuff!  And thank you for the guidance.  : )\n\nJ",
    "date_created": "2024-10-01T05:48:48.516Z",
    "has_accepted_answer": true,
    "title": "Changing Distance Metric for a Collection",
    "topic_id": 4377
  },
  {
    "user_id": 2505,
    "conversation": "[Crazydarkman113 (2024-11-14T21:18:09.305Z)]: I am trying to upload my csv files to weaviate after creating sandbox account. Don’t see any option for upload. My other choice is through Python which I never used. What are my options?\n\n----------\n\n[DudaNogueira (2024-11-14T21:46:41.728Z)]: hi @Crazydarkman113 !!\nWelcome to our community \nWeaviate is a Database. So you will need other tools in order to load a csv file.\nOne option is to leverage frameworks like Langchain.\nHere, for example, we have a python recipe that will do exactly that, but for PDF files:\n\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/llm-frameworks/langchain/loading-data at main ·...\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNow, in order to load up CSV files, you can use langchain for that, as documented here:\n  \n      \n\n      python.langchain.com\n  \n\n  \n    \n\nCSV | 🦜️🔗 LangChain\n\n  A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThis, of course, will require some python coding.\nLet me know if I can help on that.\nWe host weekly office hours where we can eventually tackle this and guide you thru this journey.\nThanks!",
    "date_created": "2024-11-14T21:18:09.261Z",
    "has_accepted_answer": false,
    "title": "Uploading CSV files to Weaviate",
    "topic_id": 7575
  },
  {
    "user_id": 1273,
    "conversation": "[longspearfish (2024-08-01T13:21:53.600Z)]: Description\nHi community! I tried to get the total_count of a collection, with filters on some property with type date.\ncollection.aggregate.over_all(\n    filters = Filter.by_property('published_date').greater_or_equal('2020-01-01T00:00:00Z')\n).total_count\n\nHowever, the following error message came up.\nWeaviateQueryError: Query call with protocol GQL Aggregate failed with message Error in GraphQL response: [\n  {\n    \"locations\": [\n      {\n        \"column\": 12,\n        \"line\": 1\n      }\n    ],\n    \"message\": \"invalid 'where' filter: data type filter cannot use \\\"valueText\\\" on type \\\"date\\\", use \\\"valueDate\\\" instead\",\n    \"path\": [\n      \"Aggregate\",\n      \"Mycollection\"\n    ]\n  }\n], for the following query: {Aggregate{Mycollection(where: {path: [\"published_date\"] operator: GreaterThanEqual valueText: \"2020-01-01T00:00:00Z\"} ){meta{count}}}}.\n\nDoes someone encounter the same problem? Is there a way around?\nServer Setup Information\n\nWeaviate Server Version: 1.23.14\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python 4.5.7\nMultitenancy?: No\n\n----------\n\n[DudaNogueira (2024-08-01T19:20:13.586Z)]: hi @longspearfish !!\nWelcome to our community! \nThis is a  bug in the python client.\nEdit: Not really…\nthis is because whatever you pass as the comparison argument, the client will infer the data type to pass it over to Weaviate.\nSo when you pass a date using string, it will use valueText instead of valueDate.\nHence the error code:\ncannot use \\\"valueText\\\" on type \\\"date\\\", use \\\"valueDate\\\" instead\"\n\nHere is the client code for this\nSo you need to pass a python date object.\nthis will work:\nfrom datetime import datetime\ntimestamp = \"2020-01-01T00:00:00Z\"\ndt = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%SZ\")\ncollection.aggregate.over_all(\n    filters = Filter.by_property('published_date').greater_or_equal(dt)\n).total_count\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[longspearfish (2024-08-04T16:43:44.995Z)]: Yes it works! Thanks so much!",
    "date_created": "2024-08-01T13:21:53.548Z",
    "has_accepted_answer": true,
    "title": "Total_count not working with filters on date values",
    "topic_id": 3247
  },
  {
    "user_id": 1714,
    "conversation": "[Adi_Sra_Ga (2024-10-11T07:30:52.606Z)]: Hello folks,\nwe are trying to validate and see if Weaviate DB  is a perfect match for our use case scenarios.\nOur datasets are pretty big,  datasets may range from 100 Million to couple of billion vectors generated in few hours. with higher dimensions >768\nHence local storage is not feasible for us  at this scale.\nHence I  have couple of questions that i seek help from the community.\n\nCan we use an S3 or MinIO type of object storage endpoints as  persistent storage directory with Weaviate (like Milvus for reference) ?\n\n(or)\n\nI read about EKS somewhere in the documentation . Hence  could we use NFS based options for persistent storage  for the k8s cluster deployments .\n\nWhich one is recommended for performance and data consistency ?\nAlso how Weavieate behave if we use the NFS as PERSISTENCE_DATA_PATH when i deploy multiple replicas  ?  How are the reads and writes are load balanced. ?\nWill all the pods write to the same NFS data path. (e.x: My Persistent data path is set to  “/mnt/weavieatedb/data/”)   or do we need to configure, each pod should be pointed to separate data folder. ?\nPod0  ==>  (“/mnt/weavieatedb/data_0/”)\nPod1 ==> (“/mnt/weavieatedb/data_1/”)\nPodN. ==> (“/mnt/weavieatedb/data_n/”)\nWe have huge NFS share (NFS share is presented from a storage box) . Hence performance and throughput should not be a concern.\n\nCan we use one PVC created out of the NFS share and present it to values.yaml when  deploying via helm chart\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: wv-storage\n  namespace: wvdb  # Match the namespace\nspec:\n  accessModes:\n    - ReadWriteMany\n  storageClassName: \"\"\n  resources:\n    requests:\n      storage: 500Gi\n  volumeName: wv-nfs-pv\n\nand my Persistent volume is this:\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: wv-nfs-pv\nspec:\n  capacity:\n    storage: 500Gi\n  accessModes:\n    - ReadWriteMany\n  nfs:\n    path: /wvdb  # Path on NFS server\n    server: mystorageserver  # NFS server IP\n\nIn my values.yaml:\nstorage:\nfullnameOverride: “wv-storage”\nsize: 500Gi\nstorageClassName: “”\nWhen i deploy the helm chart . I coud only see one pod . Is Weaviate not a distributed architecture o\nEvery 2.0s: kubectl get pods -n wvdb                                                                                                                                                 sn1-r6515-h01-05: Fri Oct 11 07:36:39 2024\n\nNAME         READY   STATUS    RESTARTS   AGE\nweaviate-0   1/1     Running   0          100s\n\n----------\n\n[DudaNogueira (2024-10-11T20:44:30.607Z)]: hi @Adi_Sra_Ga !\nAs long as Weaviate can write to the persistent path, it should work. I am not sure NFS will deliver the best performance.\nFor this mount of objects, I strongly suggest you contacting our sales team so we can arrange a call with our team on how to better architect a solution for you.\nEach replica should have it’s own PERSISTENE_DATA_PATH.\nYou can use your own PVC. Check here for more info on that.\nIn order to run multiple nodes while deploying with our oficial helm, you will need to change the replicas definition in your values.yml (here the link).\nLet me know if this helps!\nThanks!\n\n----------\n\n[Adi_Sra_Ga (2024-10-12T04:28:43.298Z)]: Hi @DudaNogueira ,\nThanks for the reply , Is S3 bucket or any object based storage buckets are supported if i use that as  PERSISTENT DATA  endpoints.  I can only see the configurations for backup in S3 ?\n\n----------\n\n[DudaNogueira (2024-10-14T23:06:32.160Z)]: Hi!\nThose are only suggested to be used for the backup storage, not the PERSISTENT_DATA, as Weaviate needs quick read/write to that PATH.",
    "date_created": "2024-10-11T07:30:52.557Z",
    "has_accepted_answer": false,
    "title": "[STORAGE][LARGER DATASETS] Can we use the NFS for PERSISTENT_DATA?",
    "topic_id": 4777
  },
  {
    "user_id": 1035,
    "conversation": "[JK_Rider (2024-08-29T12:54:28.698Z)]: Description\nWhen inserting a large number of objects(> 1M total vectors) with a batch insert I’ve been intermittently getting\nthe error.\n{‘message’: ‘Failed to send x objects in a batch of x. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\nInsertion Code:\nwith self.collection.batch.fixed_size(batch_size=300)as batch:\nfor i, data_row in enumerate(property_rows):\nbatch.add_object(\nproperties=data_row,\nvector={\n“title_vector”: title_vectors[i],\n“body_vector”: body_vectors[i],\n“keywords_vector”: keyword_vectors[i],\n},\nuuid=generate_uuid5(data_row[‘ext_id’])\n)\nConnection Code:\nself.client = weaviate.connect_to_wcs(\ncluster_url=URL,\nauth_credentials=weaviate.auth.AuthApiKey(APIKEY),\nadditional_config=AdditionalConfig(\nconnection=ConnectionConfig(\nsession_pool_connections=30,\nsession_pool_maxsize=200,\nsession_pool_max_retries=3,\n),\ntimeout=Timeout(init=1440, query=1440, insert=1440)  # Values in seconds\n)\n)\nErrors:\nWeaviateBatchError(‘Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.UNAVAILABLE\\n\\tdetails = “Received http2 header with status: 502”\\n\\tdebug_error_string = “UNKNOWN:Error received from peer {created_time:“2024-08-29T08:31:03.197046647+00:00”, grpc_status:14, grpc_message:“Received http2 header with status: 502”}”\\n>.’)\nWeaviateBatchError(‘Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.UNAVAILABLE\\n\\tdetails = “recvmsg:Connection reset by peer”\\n\\tdebug_error_string = “UNKNOWN:Error received from peer {created_time:“2024-08-28T23:03:28.550055837+00:00”, grpc_status:14, grpc_message:“recvmsg:Connection reset by peer”}”\\n>.’)\n<AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.UNAVAILABLE\\n\\tdetails = “sendmsg: Broken pipe (32)”\\n\\tdebug_error_string = “UNKNOWN:Error received from peer {created_time:“2024-08-28T18:23:59.686140478+00:00”, grpc_status:14, grpc_message:“sendmsg: Broken pipe (32)”}”\\n>\nServer Setup Information\n\nWeaviate Server Version: 1.25.10\nDeployment Method: Weaviate Serverless Cloud\nMulti Node? Number of Running Nodes:\nClient Language and Version: Python v4  Client\nMultitenancy?: No\n\nAny Additional Information\nNo vectorizer is being used, objects are being sent with preloaded embeddings. There are multiple-named vectors in this collection.\nAsynchronous Indexing is Enabled\n\n----------\n\n[Mohamed_Shahin (2024-08-29T15:23:41.680Z)]: Hi @JK_Rider, how are you?\nThank you very much for the details. I see you have opened a support ticket with us as well.\nI will investigate and get back to you there.\nRegards,\nMohamed\n\n----------\n\n[Mohamed_Shahin (2024-08-29T15:51:05.241Z)]: Hi @JK_Rider,\nI’ve reached out to you over the Supprt Channel. Let’s take it from there.\nHave a good evening!\n\n----------\n\n[JK_Rider (2024-08-29T15:56:49.002Z)]: Thank you @Mohamed_Shahin for the fast response. I’ve responded on the support ticket.",
    "date_created": "2024-08-29T12:54:28.635Z",
    "has_accepted_answer": false,
    "title": "Weaviate Cloud Serverless - Batch Insert 502 Server Side errors with v4 client",
    "topic_id": 3909
  },
  {
    "user_id": 207,
    "conversation": "[duplaja (2023-08-01T23:18:10.649Z)]: Hello! I’m currently using the generative-openai module to query my data (vectorizing with text2vec-openai), with the Python client library.\nWhen I create my schema / class, I’m specifying a particular OpenAI model ( gpt-3.5-turbo ).\nIs there a way when querying to override that on a per-query basis? (to gpt-4, for example)?\nOr, barring that, is there a way to change the model on the class? I tried modifying the class, but it said that that it was immutable.\nI’d like to be able to do some queries with each, depending on the query, without having to have two instances of the data.\nThank you!\n\n----------\n\n[sebawita (2023-08-08T11:12:47.418Z)]: Hi Dan, welcome to the community.\nThis was something I had on my mind for a little while.\nThe bad news\nUnfortunately, this is not possible at this moment.\nThe good news\nBut we can do something about it. \nI’ve created a GitHub issue, if we get enough votes for it, we can get it implemented \nIn other words, please upvote it  to get the ball rolling.\n\n----------\n\n[duplaja (2023-08-09T21:23:25.274Z)]: Thank you! I didn’t think I was overlooking anything, but wanted to make sure. I also wanted to make sure I wasn’t (unnecessarily) duplicating my stored data.\nI’ve put a thumbs up on the GitHub Issue. Hopefully something that can be implemented!\n\n----------\n\n[DudaNogueira (2024-12-10T13:28:46.734Z)]: hi! Coming from the future \nThis is now implemented:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage collections | Weaviate\n\n  Every object in Weaviate belongs to exactly one collection. Use the examples on this page to manage your collections.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor example in python:\ncollection.config.update(\n    generative_config=Reconfigure.Generative.cohere()  # Update the generative module\n)\n\nThanks!",
    "date_created": "2023-08-01T23:18:10.597Z",
    "has_accepted_answer": true,
    "title": "Change OpenAI Generative Model for Existing Classes",
    "topic_id": 442
  },
  {
    "user_id": 1040,
    "conversation": "[jaydcrowe1989 (2024-10-24T14:07:55.638Z)]: Hi,\nI am using docker on a webserver and I want it to maintain the same volume and not create a new one each time I upload a new image and deploy that. How can I do this please?\nJay\n\n----------\n\n[DudaNogueira (2024-10-24T18:40:49.004Z)]: hi! Not sure I understood you question.\nCan you elaborate or give some examples?\nThanks!\n\n----------\n\n[jaydcrowe1989 (2024-10-24T18:54:00.169Z)]: Sorry. So when i am using weaviate verba on my local pc, deploying via docker, it works as expected creating one volume. When i make front end changes and deploy a new build it continues to use the same volume and my data is maintained. When i then deploy it to docker on a webserver, everytime i update the build it creates a new volume and a does not continue to use the same volume. So i lose my data.",
    "date_created": "2024-10-24T14:07:55.595Z",
    "has_accepted_answer": false,
    "title": "Docker on webserver - maintain same volume when using new image",
    "topic_id": 5865
  },
  {
    "user_id": 3240,
    "conversation": "[PaulJPhilp (2025-01-19T20:51:34.341Z)]: I have been trying to get weaviate and ollama working together on my local machine.  I have yet to get weaviate to successfully connect to ollama at all.  Does anyone any tips?\nHere is my docker-compose.yml file:\nversion: \"3.7\"\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2\n    ports:\n      - 8080:8080\n      - 50051:50051\n    environment:\n      ENABLE_MODULES: text2vec-ollama\n      OLLAMA_URL: http://ollama:11434\n      TEXT2VEC_OLLAMA_BASE_URL: http://ollama:11434\n      TEXT2VEC_OLLAMA_MODEL: nomic-embed-text\n      WEAVIATE_HOST: 0.0.0.0\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: true\n      PERSISTENCE_DATA_PATH: /var/lib/weaviate\n      DEFAULT_VECTORIZER_MODULE: text2vec-ollama\n      CLUSTER_HOSTNAME: node1\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    depends_on:\n      - ollama\n\n  ollama:\n    image: ollama/ollama:latest\n    ports:\n      - 11434:11434\n    volumes:\n      - ollama_data:/root/.ollama\n\nvolumes:\n  weaviate_data:\n  ollama_data:\n\nAnd the error I get when doing an insert:\n} else {\n318 |         return Promise.reject(new WeaviateUnexpectedStatusCodeError(res.status, err));\n^\nWeaviateUnexpectedStatusCodeError: The request to Weaviate failed with status code: 500 and message: {“error”:[{“message”:“vectorize target vector default: update vector: send POST request: Post \"http://localhost:11434/api/embed\\”: dial tcp [::1]:11434: connect: connection refused\"}]}\ncode: 500,\n\n----------\n\n[DudaNogueira (2025-01-24T19:50:59.763Z)]: hi @PaulJPhilp !!\nWelcome to our community \nThere isn’t a variables such as TEXT2VEC_OLLAMA_BASE_URL or TEXT2VEC_OLLAMA_MODEL\nDo you remember where you saw those?\nThat configuration is defined per collection, as documented here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nText Embeddings | Weaviate\n\n  Ollama Embedding Provider\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIn your case, you will need to use:\napi_endpoint=\"http://ollama:11434\",\n\nLet me know if that helps!\n\n----------\n\n[CalebMontgomery (2025-02-04T06:01:45.971Z)]: Thank you so much for sharing it helped me.",
    "date_created": "2025-01-19T20:51:34.293Z",
    "has_accepted_answer": true,
    "title": "[Question] Getting Weaviate and Ollama working together running locally",
    "topic_id": 9818
  },
  {
    "user_id": 448,
    "conversation": "[jan.strunk (2024-08-21T23:57:52.995Z)]: Description\nI have three hierarchical collections:\nCorpus ← Document ← Chunk\nChunks refer to the document they belong to using cross-references, documents refer to the corpus they belong to using cross-references.\nI have recently come across the rare phenomenon that Aggregate queries, which we use to keep track of how many chunks are in a document and how many documents are in a corpus etc. return a larger number of objects using meta count than Get queries actually getting those objects. (Nota bene the limit for the maximum number of objects to get is definitely higher than both numbers so that it should have no influence.)\nExample queries:\n\n\nAggregate query returns a count of 68 objects\n\nquery: {Aggregate{Chunk(where: {path: [\"document\", \"Document\", \"id\"] operator: Equal valueText: \"3154c57d-9a70-415d-b3fe-480562d25c01\"} limit: 1100 ){meta {count}}}}\nresult: {\"data\": {\"Aggregate\": {\"Chunk\": [{\"meta\": {\"count\": 68}}]}}\n\n\n\nGet query return 63 Chunk objects\n\nquery: {Get{Chunk(where: {path: [\"document\", \"Document\", \"id\"] operator: Equal valueText: \"3154c57d-9a70-415d-b3fe-480562d25c01\"} limit: 1100 ){_additional {id}}}}\nresult:\n\n\n\n{\n    \"data\": {\n        \"Get\": {\n            \"Chunk\": [\n                {\n                    \"_additional\": {\n                        \"id\": \"1e1b6df2-c6dc-4aa4-8837-5781ebe04a23\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"85d23a48-c468-4422-aa24-1bea7294d3a8\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"a1a8c958-0199-4c1d-84b5-6fc023293003\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"4b3206c0-e8b4-417a-8466-964d946dcc7e\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"1fe3a960-cb7a-4a24-aaa4-33c87084b95f\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"c9aeb5cd-5618-4083-ba9b-7870934b4eac\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"26b3947d-22c0-4fe3-8037-c4f6f894b368\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"cab382b0-87f6-4d88-9554-c16a4c1ec1c9\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"574871d8-251e-49f0-92e8-a12ac126bff4\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"d96ba70b-1aef-4a50-9a83-2a4a1f267770\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"63eb0974-b18d-4224-a8ce-9fbb17aee6e7\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"226dc976-42f9-4362-8451-b270a03d5eae\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"61563590-39b1-4175-a716-894f10fc27bb\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"eacce4fc-f100-4f31-92e1-d56585107a38\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"3f6227b0-7415-4450-b0c3-9110e9a4ee37\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"4978d106-f70c-44ee-a73a-26dd3848e243\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"9c9e2ab8-ed31-4c89-b8bc-275485e70007\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"28fedc62-164c-43d9-8e9c-99e4e8e0d101\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"e8a29452-584c-4298-9bc8-64b81eeda7c6\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"b9a6adb5-55b5-4d6a-8fe3-cd587862ab71\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"fdbc016a-1c7b-448b-9593-3da2353e70d6\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"302ca135-02d4-4387-9e6c-45197e5360e3\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"e78e6758-d877-4210-b11d-8424381a9c7a\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"24c9b423-5c3e-42ac-bf16-35eb0a2b600f\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"3ab58cc5-47f4-4e95-9438-241ea6c0b6f0\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"c90c1aea-b68a-4918-b783-fad086266599\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"5642fc62-8a85-46c0-a2b0-de0b0edfe870\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"f6142f9b-d6e4-4b6a-8c35-17ef737f2336\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"0669522e-ebe8-4ed0-963a-f5204a2e793b\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"4f96f6e3-e0b0-4f22-b81d-4eba34521ab0\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"2ab46511-bb43-43ac-8c33-92ff054c561d\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"e55ac626-6c76-431f-9dd8-0fbb652e73dd\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"8efb0cdf-fc3f-4907-b7ce-9dfb632aac03\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"feebf499-d048-429f-b5cf-efaacaddba5d\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"a79188ca-cc7c-4161-a8b5-5c8cedfdb23c\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"fad39570-1131-40a7-863b-d561542f47c8\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"48811b2a-e9f3-4fe3-b89e-387d52f3d5e9\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"827080f6-019b-4f1c-b0da-d62fe8321d3d\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"8c0f8f4e-7127-46a9-bb27-6d78f53998c3\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"9c2102be-f376-46b6-8a38-b395dc782608\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"63c18dc8-ec58-4516-b784-468387c15c67\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"6330175f-de7f-4f10-8b18-de9a4bfdb45e\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"94d8feac-4e9f-40df-8d02-f9f9a961d5fe\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"7eefe892-27ed-4137-a833-e0df1e1eaafe\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"8c5cb0f6-2834-4c06-88c2-cd719edd9f29\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"3035ec04-dc4d-4941-8311-3940876af9d0\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"a02db6e1-ce4d-4a50-9522-b6cf0b904106\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"0e972e82-4d74-4470-8132-cc4b28fb1055\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"ecaef2f9-8671-4bbf-9f21-88e59aa50e18\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"efe30d68-fa3b-455c-a740-5e012f8edb28\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"6c7c96ee-e9de-45e6-8e8d-c13da731382a\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"ea3ec993-43fc-43e4-a038-ad83d6a3be43\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"c6cd581c-b831-4263-8128-6a048773c9ad\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"bda917ac-bae2-469f-9a3d-428a0b6c477a\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"7624105f-072f-4d71-ae29-63b497dd1a4e\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"635aac1d-b0d1-4ee3-8b6f-f2c69c1ac220\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"62a8f35f-c713-4b60-8e87-26bf1440a9a5\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"60a8cd09-7955-443f-981d-f5d9b6a07b36\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"5482791b-1af8-4d3e-b37c-d854445759e6\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"b8c595cd-0002-4505-b5db-c0eeb604fe5a\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"f28771dd-db46-4b04-995b-ee11e43c8bf3\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"dba63357-42d4-402a-bfe4-211d96dd9d05\"\n                    }\n                },\n                {\n                    \"_additional\": {\n                        \"id\": \"537dd764-c989-4efa-a2e3-08840a0f3d27\"\n                    }\n                }\n            ]\n        }\n    }\n}\n\nIs there any good explanation for this kind of phenomenon? Or could this be a bug? I would be very thankful for any hints… Thank you very much!\nServer Setup Information\n\nWeaviate Server Version: 1.24.3\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python v3\nMultitenancy?: no\n\nAny additional Information\nNone\n\n----------\n\n[DudaNogueira (2024-08-29T19:20:53.945Z)]: hi @jan.strunk !!\nSorry for the delay here, missed this one \nIs this a big dataset?\nDo you think we could reindex it on a second cluster and check if this still persists?\nWas all that data added at 1.24.3 or you migrated it at some point?\nAnd finally, what client version you are using? have you tried the latest python v3 client?\nThanks!",
    "date_created": "2024-08-21T23:57:52.905Z",
    "has_accepted_answer": false,
    "title": "Inconsistent numbers of objects using Get and Aggregate",
    "topic_id": 3427
  },
  {
    "user_id": 434,
    "conversation": "[A_S (2024-11-11T16:22:32.915Z)]: Tested on the newest weaviate server version.\nCould you help with explaining how the scoring works?\nWe are getting hybrid search score results from weaviate. We extract them as follows:\nif explain_score is not None:\nvector_score_pattern = r’Result Set vector.?original score (\\d+.\\d+)’\nkeyword_score_pattern = r’Result Set keyword.?original score (\\d+.\\d+)’\n                vector_score_match = re.search(vector_score_pattern, explain_score)\n                keyword_score_match = re.search(keyword_score_pattern, explain_score)\n\n                try:\n                    vector_score = float(vector_score_match.group(1))\n                except AttributeError:\n                    vector_score = 0.0\n                    alpha = 0.0\n                try:\n                    keyword_score = float(keyword_score_match.group(1))\n                except AttributeError:\n                    keyword_score = 0.0\n                    alpha = 1.0\n\nWe had to build in these fallbacks because we still get scores from weaviate very unreliably. For 80% we receive NaN as keyword score value for whatever reason…\nSo, we decided to rely mostly on vector score, since we should be getting it more or less reliably…\nWe ask in German “What does a cat look like?” and get following results:\n[(0.31066078, ‘\\nHybrid (Result Set keyword,bm25) Document e160ac1e-22c4-4eeb-8cff-27f064011aab: original score NaN, normalized score: NaN - \\nHybrid (Result Set vector,hybridVector) Document e160ac1e-22c4-4eeb-8cff-27f064011aab: original score 0.31066078, normalized score: 0.23898673’, Chunk(id=‘e160ac1e-22c4-4eeb-8cff-27f064011aab’, text=‘Hunde beim Tierarzt    Bei der ersten Behandlung wird dein Welpe gründlich untersucht und der Tierarzt wird  mit dir die Impfung besprechen. Detaillierte Angaben zu früheren Behandlungen, die  dein Züchter oder das Tierheim eventuell veranlasst haben, sind sinnvoll. Ihr werdet  euch über häuﬁge Probleme wie Würmer und Flöhe unterhalten, einschließlich deren  Behandlung und Vorbeugung (erste Informationen solltest du schon vom Züchter oder  Tierheim/AuKangstation erhalten haben), sowie über Mikrochips, Kastrationen und alle  Fragen, die du bezüglich der Gesundheitsversorgung von Welpen hast. Möglicherweise  sind auch Fütterung, Bewegung und Pﬂege ein Thema.       Darüber hinaus gibt es hier einige Informationen zur Niederschlagsmenge:’, metadata=ChunkMetadata(etc)\nThis is the best matching chunk for some reason (even though it talks about dogs). At the same time we have a chunk about a cat: “Das Bild zeigt eine weiße Katze, die ruhig auf dem Boden liegt. Auffällig sind ihre heterochromen Augen, eines ist blau und das andere gelb. Die Umgebung ist schlicht gehalten, mit einem hellen Vorhang im Hintergrund, der einen minimalistischen und sauberen Wohnraum andeutet. Die Katze schaut leicht zur Seite und wirkt aufmerksam und interessiert.” This receives a vector score of only 0.18 for some reason…\nAre we doing something wrong? Should we not use hybrid score if not working with English? Or should we just not use hybrid scoring at all to get reliable results?\n\n----------\n\n[DudaNogueira (2024-11-12T18:24:22.562Z)]: hi @A_S !!\nThe best way to analyze this is with a working code so we can make sure we are at the same page.\nI was not able to reproduce the NAN issue. Can you provide some code for that?\nHere is some code:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n    properties=[\n        wvc.config.Property(name=\"text\", data_type=wvc.config.DataType.TEXT)\n    ]\n)\ncollection.data.insert_many(\n    objects=[\n        {\"text\": \"What does a cat look like?\"},\n        {\"text\": \"What is the sound of a dog?\"},\n        {\"text\": \"What time is it?\"},\n    ]\n)\n\nNow if I perform a hybrid search:\nquery = collection.query.hybrid(\n    return_metadata=wvc.query.MetadataQuery(score=True, explain_score=True),\n    query=\"dog\",\n    limit=2\n)\nfor i in query.objects:\n    print(\"#\"*10)\n    print(i.properties)\n    print(i.metadata.score)\n    print(i.metadata.explain_score)\n\nI will get:\n\n##########\n{‘text’: ‘What is the sound of a dog?’}\n1.0\nHybrid (Result Set keyword,bm25) Document e3e1cab9-e8d4-4a31-a157-df0f3fbb5d76: original score 0.4815891, normalized score: 0.3 -\nHybrid (Result Set vector,hybridVector) Document e3e1cab9-e8d4-4a31-a157-df0f3fbb5d76: original score 0.41238725, normalized score: 0.7\n##########\n{‘text’: ‘What does a cat look like?’}\n0.37308037281036377\nHybrid (Result Set vector,hybridVector) Document dd8bec05-b9d3-457a-b67a-56f92b3c16f3: original score 0.27121615, normalized score: 0.37308037\n\nIf I do the same query, now using bm25:\nquery = collection.query.bm25(\n    return_metadata=wvc.query.MetadataQuery(score=True, explain_score=True),\n    query=\"dog\"\n)\nfor i in query.objects:\n    print(\"#\"*10)\n    print(i.properties)\n    print(i.metadata.score)\n    print(i.metadata.explain_score)\n\nI get:\n\n##########\n{‘text’: ‘What is the sound of a dog?’}\n0.48158910870552063\n, BM25F_dog_frequency:1, BM25F_dog_propLength:7\n\nNow if we get back to our explain score, this is the score equivalent to the bm25 0.4815891, normalized score: 0.3\nIf I perform a near_text, I will get the distance:\nquery = collection.query.near_text(\n    return_metadata=wvc.query.MetadataQuery(distance=True),\n    query=\"dog\",\n    limit=1\n)\nfor i in query.objects:\n    print(\"#\"*10)\n    print(i.properties)\n    print(i.metadata.distance)\n\noutput:\n\n##########\n{‘text’: ‘What is the sound of a dog?’}\n0.5876127481460571\n\nNow if we get back to our explain score, this is the distance equivalent to the near_text 0.41238725, normalized score: 0.7\nSo those two (score and distance) metrics are fused to combine a single score for the hybrid search.\nYou can learn more on those algorithms here:\n  \n      \n\n      weaviate.io – 29 Aug 23\n  \n\n  \n    \n\nUnlocking the Power of Hybrid Search - A Deep Dive into Weaviate's Fusion...\n\n  How hybrid search works, and under the hood of Weaviate's fusion algorithms.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps.",
    "date_created": "2024-11-11T16:22:32.863Z",
    "has_accepted_answer": false,
    "title": "Hybrid similarity scoring is so weird - it doesn't make any sense",
    "topic_id": 7540
  },
  {
    "user_id": 2486,
    "conversation": "[taigofranca (2024-11-08T21:17:44.291Z)]: Description\nI have the following code:\nimport weaviate\nfrom weaviate.classes.config import Configure\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_aws import BedrockEmbeddings\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\n\nheaders = {\n    \"X-AWS-Access-Key\": \"my_access_key\",\n    \"X-AWS-Secret-Key\": \"my_secret_key\",\n}\n\nclient = weaviate.connect_to_local(headers=headers)\n\ntry:\n\n    print('Client is ready? ', client.is_ready())\n\n    client.collections.delete(\"MPVirtual\")\n\n    client.collections.create(\n        \"MPVirtual\",\n        vectorizer_config=Configure.NamedVectors.text2vec_aws(\n            name=\"MPVirtual\",\n            region=\"sa-east-1\",\n            service=\"bedrock\",\n            model=\"amazon.titan-embed-text-v2:0\"\n        ),\n        generative_config=Configure.Generative.aws(\n            region=\"sa-east-1\",\n            service=\"bedrock\",\n            model=\"amazon.titan-text-express-v1\"\n        )\n    )\n\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n    embeddings = BedrockEmbeddings()\n\n    loader = PyPDFLoader(\"my_pdf_file.pdf\", extract_images=False)\n    docs = loader.load_and_split(text_splitter)\n    print(f\"GOT {len(docs)} docs for PDF\")\n\n    db = WeaviateVectorStore.from_documents(docs, embeddings, client=client, index_name=\"MPVirtual\")\n\n    collection = client.collections.get(\"MPVirtual\")\n\n    response = collection.aggregate.over_all(total_count=True)\n    print(response)\n\n    response = collection.aggregate.over_all(group_by=\"source\")\n    for group in response.groups:\n        print(group.grouped_by.value, group.total_count)\n\n    object = collection.query.fetch_objects(limit=1).objects[0]\n    print(object.properties.keys())\n\nfinally:\n    client.close()\n\nWhen I run the script, the following error occurs:\n\nClient is ready?  True\nGOT 66 docs for PDF\nERROR:root:Error raised by inference endpoint: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.\nTraceback (most recent call last):\n  File \"/my_folder/IA/mpvirtual/teste.py\", line 44, in <module>\n    db = WeaviateVectorStore.from_documents(docs, embeddings, client=client, index_name=\"MPVirtual\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/my_folder/IA/mpvirtual/.venv/lib/python3.11/site-packages/langchain_core/vectorstores/base.py\", line 852, in from_documents\n    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/my_folder/IA/mpvirtual/.venv/lib/python3.11/site-packages/langchain_weaviate/vectorstores.py\", line 487, in from_texts\n    weaviate_vector_store.add_texts(texts, metadatas, tenant=tenant, **kwargs)\n  File \"/my_folder/IA/mpvirtual/.venv/lib/python3.11/site-packages/langchain_weaviate/vectorstores.py\", line 165, in add_texts\n    embeddings = self._embedding.embed_documents(list(texts))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/my_folder/IA/mpvirtual/.venv/lib/python3.11/site-packages/langchain_aws/embeddings/bedrock.py\", line 178, in embed_documents\n    response = self._embedding_func(text)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/my_folder/IA/mpvirtual/.venv/lib/python3.11/site-packages/langchain_aws/embeddings/bedrock.py\", line 159, in _embedding_func\n    raise e\n  File \"/my_folder/IA/mpvirtual/.venv/lib/python3.11/site-packages/langchain_aws/embeddings/bedrock.py\", line 144, in _embedding_func\n    response = self.client.invoke_model(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/my_folder/IA/mpvirtual/.venv/lib/python3.11/site-packages/botocore/client.py\", line 569, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/my_folder/IA/mpvirtual/.venv/lib/python3.11/site-packages/botocore/client.py\", line 1023, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.\n\nI copied the names of the models from this link:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAWS + Weaviate | Weaviate\n\n  AWS offers a wide range of models for natural language processing and generation. Weaviate seamlessly integrates with AWS's APIs, allowing users to leverage AWS's models directly within the Weaviate database.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThe user has the necessary accesses.\nI really believe I’m doing something wrong. Can you help me solve this problem? I’m just starting out in this world of vector banks, RAG and GenIA.\nServer Setup Information\n\nWeaviate Server Version: 1.27.0\nDeployment Method: Local\nMulti Node? No\nClient Language and Version: Python 3.11\nMultitenancy? No\n\n----------\n\n[DudaNogueira (2024-11-10T12:07:37.567Z)]: Oi @taigofranca !!\nWelcome to our community \nI believe that the issue here is that by default, BedrockEmbeddings from langchain will grab the credentials from ~/.aws/credentials, while Weaviate will accept those in headers.\nSo now you need to make sure that you pass a working langchain embeddings object, like so:\nfrom langchain_aws import BedrockEmbeddings\nembeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", credentials_profile_name=\"my_cool_aws_profile\")\nresult = embeddings.embed_query(\"This is a test\")\nprint(result)\n\nI was able to run a basic insert/generate with this code, but this will only Weaviate, and rely on the credentials you pass at the client instantiation\nfrom weaviate.classes.config import Configure\n\nclient.collections.delete(\"DemoCollection\")\n\ncollection = client.collections.create(\n    \"DemoCollection\",\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_aws(\n            name=\"title_vector\",\n            region=\"sa-east-1\",\n            source_properties=[\"title\"],\n            service=\"bedrock\",\n            model=\"amazon.titan-embed-text-v2:0\",\n        )\n    ],\n    generative_config=Configure.Generative.aws(\n        region=\"sa-east-1\",\n        service=\"bedrock\",\n        model=\"amazon.titan-text-express-v1\"\n    )    \n)\n\ncollection.data.insert({\"title\": \"This is a test\"})\nobj = collection.generate.fetch_objects(\n    include_vector=True, \n    limit=1, \n    single_prompt=\"Translate {title} to Portuguese\"\n).objects[0]\nprint(obj.generated)\nprint(len(obj.vector.get(\"title_vector\")))\n\nLet me know if this helps!\n\n----------\n\n[taigofranca (2024-11-11T15:27:32.328Z)]: Oi @DudaNogueira !!\nYour suggestion worked. I just had to indicate the region, as I changed from the Titan model to the Cohere model.\nembeddings = BedrockEmbeddings(model_id=\"cohere.embed-multilingual-v3\", credentials_profile_name=\"avenger_thor_profile\", region_name=\"us-east-1\")\n\nThanks for your help.\nHugs.",
    "date_created": "2024-11-08T21:17:44.236Z",
    "has_accepted_answer": true,
    "title": "AWS Bedrock invalid template issue",
    "topic_id": 7515
  },
  {
    "user_id": 1327,
    "conversation": "[jhc (2024-08-21T09:28:41.229Z)]: I used to query a collection with …query.with_where(filter) with python client v3,\nwhere filter was a formal conditional filter like\n{\n“operator”: “And”,\n“operands”: [\n{“path”: [“color”], “operator”: “Equal”, “valueText”: “grau”},\n{“path”: [“price”], “operator”: “LessThanEqual”, “valueNumber”: 300},\n],\n}\nlooks like that this is not possible anymore with python client v4 (or deprecated at least), is it?\nthat is unfortunate, as I am building the filter like above and translating it to the new Filter methods or build a string from it to call  directly via http is cumbersome.\n\n----------\n\n[DudaNogueira (2024-08-21T12:25:44.157Z)]: hi @jhc !!\nWelcome to our community \nThis is certainly possible.\nhere is how:\nimport weaviate\nclient = weaviate.connect_to_local()\nfrom weaviate.classes.query import Filter\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(name=\"Test\")\ncollection.data.insert({\"color\": \"grau\", \"price\": 300})\ncollection.data.insert({\"color\": \"grau\", \"price\": 400})\ncollection.data.insert({\"color\": \"grau\", \"price\": 100})\ncollection.data.insert({\"color\": \"bope\", \"price\": 400})\ncollection.data.insert({\"color\": \"bope\", \"price\": 200})\n\n# now we filter\n\nquery = collection.query.fetch_objects(\n    filters=(\n        Filter.by_property(\"color\").equal(\"grau\") & \n        Filter.by_property(\"price\").less_or_equal(300)\n    )\n)\nfor object in query.objects:\n    print(object.properties)\n\n\nFor more information on filters, check this doc:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nFilters | Weaviate - Vector Database\n\n  Filters let you include, or exclude, particular objects from your result set based on provided conditions.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[jhc (2024-08-21T16:25:34.364Z)]: Thanks,\nbut sorry I haven’t made myself clear enaugh. I’m aware that I can build filters as you outlined above, e.g. constructing a filter with subsequently making use of Filter.by_property.\nbut I have a hugh complex filter as a python structure as I explained, that I could previously (in v3) put into query.with_where(formal_filter).\nBut with_where does not exist anymore, and there is no substitute.\nOr am I missing something?\n\n----------\n\n[DudaNogueira (2024-08-21T18:19:45.229Z)]: Hi @jhc !!\nNo worries. I think I got you covered.\nIs this what you are looking for?\nGiven this dataset:\nimport weaviate\nclient = weaviate.connect_to_local()\nfrom weaviate.classes.query import Filter\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(name=\"Test\")\ncollection.data.insert({\"color\": \"grau\", \"price\": 300, \"location\": \"Brazil\"})\ncollection.data.insert({\"color\": \"grau\", \"price\": 400, \"location\": \"Netherlands\"})\ncollection.data.insert({\"color\": \"grau\", \"price\": 100, \"location\": \"Netherlands\"})\ncollection.data.insert({\"color\": \"bope\", \"price\": 400, \"location\": \"Egypt\"})\ncollection.data.insert({\"color\": \"bope\", \"price\": 200, \"location\": \"Egypt\"})\n\n\nyou can have optional filters added to a base filter, for example:\nfilter_by_location = True\nlocation = \"Brazil\"\n\n# now we filter\n#base filter\nfilters=(\n    Filter.by_property(\"color\").equal(\"grau\") & \n    Filter.by_property(\"price\").less_or_equal(300)\n)\n\nif filter_by_location:\n    filters = filters & Filter.by_property(\"location\").equal(location)\n\nquery = collection.query.fetch_objects(\n    filters=filters\n)\n\nfor object in query.objects:\n    print(object.properties)\n\nNote that you can also do more complex logic, using nested filters.\nLike in this example:\nresponse = jeopardy.query.fetch_objects(\n    filters=Filter.by_property(\"answer\").like(\"*bird*\") &\n            (Filter.by_property(\"points\").greater_than(700) | Filter.by_property(\"points\").less_than(300)),\n    limit=3\n)\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[jhc (2024-08-22T14:23:23.075Z)]: Let me try once more.\nIn python client v3, I could query weaviate with a filter that consists of python data structures, e.g.\nfilter_in_python_data_structures  = {‘operator’: ‘And’, ‘operands’: [{‘path’: [‘price’], ‘operator’: ‘LessThanEqual’, ‘valueNumber’: 300}, {‘path’: [‘color’], ‘operator’: ‘Equal’, ‘valueText’: ‘schwarz’}, {‘path’: [‘available_sizes’], ‘operator’: ‘Like’, ‘valueText’: ‘44’}, {‘path’: [‘categories’], ‘operator’: ‘Like’, ‘valueText’: ‘Schuhe’}, {‘path’: [‘material’], ‘operator’: ‘Like’, ‘valueText’: ‘Leder’}, {‘path’: [‘brand’], ‘operator’: ‘Equal’, ‘valueText’: ‘Nike’}, {‘path’: [‘certifications’], ‘operator’: ‘Like’, ‘valueText’: ‘Öko-Tex Standard 100’}, {‘path’: [‘condition’], ‘operator’: ‘Equal’, ‘valueText’: ‘neu’}] … }\nThis filter is long and complex. It is build by another module.\nIn python client v3, I could query weaviate with directly using this filter:\nclient.query.get(collection, return_properties).with_where(filter_in_python_data_structures)\nBut, in  python client v4, there is no “with_where” method anymore. I found the methods you indicated, but they would not accept something like filter_in_python_data_structures.\nInstead, that is my understanding, I need to build a filter by myself with Filter.by_property etc.\nBut, I don’t like to do that, as would need to write first a wrapper to transform filter_in_python_data_structures to something that is accepted by collection.query.fetch_objects( filters=…) .\nBefore doing that, I would rather translate filter_in_python_data_structures to a valid graphQL string and call weaviate without making use of the python client.\nMy hope is, that I have overlooked something, and that there is a way to still query as it was possible in python client v3. Or, if not, maybe, you are planning to extend the functionality of python client v4 in this way.\n\n----------\n\n[DudaNogueira (2024-08-22T14:54:48.459Z)]: Oh, I see.\nIndeed you will need to generate a v4 python filter as it will not support a v3 filter.\nThis new client uses GRPC, while the v3 uses Graphql with REST.\nSo all the underlying apis the python v4 client communicate are different. Because of that, I don’t believe that there will be a support for v3 filters syntax in v4.\nLet me know if this helps.\nThanks!\n\n----------\n\n[jhc (2024-08-23T07:21:08.879Z)]: ok, thanks.\nI have to stick with v3 filters. I’m check what comes closest to this v3 filter. I’m getting from you that it will be the REST interface. Maybe taking over the implementation of v3 of how to translate a v3 filter to what is required by REST.\n\n----------\n\n[Guillermo_Ripa (2024-08-23T13:28:30.292Z)]: Hi @jhc !\nI had a similar thing where I came from one filter definition, and I had to move into v4 Filters.\nI think something along this line could help translate filters from v3 to v4:\nfrom weaviate.classes.query import Filter\nfrom weaviate.collections.classes.filters import _Filters, _FilterByProperty\n\n\nV3_TO_V4_OPERATORS = {\n    \"Equal\": \"equal\",\n    \"NotEqual\": \"not_equal\",\n    \"GreaterThan\": \"greater_than\",\n    \"LessThan\": \"less_than\",\n    \"LessThanEqual\": \"less_or_equal\",\n    \"GreaterThanEqual\": \"greater_or_equal\",\n    # TODO: Add other operators here\n}\n\nfilters = []\nfilter_: _Filters\nfilter_by_property: _FilterByProperty\nfor v3_filter in filters:\n    filter_by_property = Filter.by_property(v3_filter[\"path\"])\n    operator = V3_TO_V4_OPERATORS[v3_filter[\"type\"]]\n    filter_ = getattr(filter_by_property, operator)(v3_filter[\"valueText\"]) # TODO: You will need to extend this value* to more types.\n    filters.append(filter_)\n\nfilters = Filter.all_of(filters)\n\nHope it helps!\n\n----------\n\n[DudaNogueira (2024-08-23T16:14:05.004Z)]: What can probably help you on this situation is to build the graphql query in v3 client and execute it in pyv4.\nin v3 instead of calling the .do() you can call .build() and get the graphql string.\nIn pyv4 you can call it like so:\nclient = weaviate.connect_to_local()    \nclient.graphql_raw_query(query.build())\n\nLet me know if this helps.\n\n----------\n\n[DudaNogueira (2024-08-23T16:18:11.498Z)]: hi @Guillermo_Ripa !!\nNice! Thanks for sharing.\nOnce thing to consider is that all_of will:\n\nCombine all filters in the input list with an AND operator.\n\nSo if you have some OR logic, you will need to adapt and use any_of instead.",
    "date_created": "2024-08-21T09:28:41.167Z",
    "has_accepted_answer": false,
    "title": "Conditional filter with python client v4",
    "topic_id": 3413
  },
  {
    "user_id": 2410,
    "conversation": "[bam (2024-10-30T09:34:47.869Z)]: Description\nI tried following the blog post, Locally running RAG pipeline with Verba and Llama3 with Ollama https://weaviate.io/blog/local-llm-with-verba-for-rag, to build locally and it won’t import the pdf. The document is less than 300 kb.\nError message:\n✘ No documents imported 0 of 1 succesful tasks\nℹ FileStatus.ERROR | the-heros-journey-joseph-campbell.pdf | Import for\nthe-heros-journey-joseph-campbell.pdf failed: Import for\nthe-heros-journey-joseph-campbell.pdf failed: Batch vectorization failed:\nVectorization failed for some batches: 500, message='Internal Server Error',\nurl=URL('http://localhost:11434/api/embed') | 0\n\nServer Setup Information\nI followed the embed path of the blog post on a macbook pro. Locally running RAG pipeline with Verba and Llama3 with Ollama. I can get Ollama to work locally.\n\nWeaviate Server Version:\nDeployment Method: embed\nMulti Node? Number of Running Nodes:\nClient Language and Version: python\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-10-30T12:51:45.081Z)]: Hi @bam !!\nWelcome to our community \nI have just built and run Verba using Ollama to test the newer version.\nI noticed that while we have recently implemented a public docker image, it doesn’t have the arm platform images yet.\nSo first I cloned the repo, built the image, and used this docker compose to spin it that same image up.\nConsidering the error message you pasted, it looks like the OLLAMA_URL is pointing to localhost. I tried to reproduce this error, but got a different one:\nverba-1     | ✘ No documents imported 0 of 1 succesful tasks\nverba-1     | ℹ FileStatus.ERROR | netherlands-wikipedia-article-text.pdf | Import\nverba-1     | for netherlands-wikipedia-article-text.pdf failed: Import for\nverba-1     | netherlands-wikipedia-article-text.pdf failed: Batch vectorization failed:\nverba-1     | Vectorization failed for some batches: Cannot connect to host localhost:11434\nverba-1     | ssl:default [Connection refused] | 0\n\nAre you running ollama locally? If that’s the case, you should set the OLLAMA_URL accordingly:\n---\n\nservices:\n  verba:\n    image: verba-verba\n    ports:\n      - 8000:8000\n    environment:\n      - WEAVIATE_URL_VERBA=http://weaviate:8080\n      - OPENAI_API_KEY=$OPENAI_API_KEY\n      - COHERE_API_KEY=$COHERE_API_KEY\n      - OLLAMA_URL=http://host.docker.internal:11434\n      - OLLAMA_MODEL=llama3.1\n      - OLLAMA_EMBED_MODEL=mxbai-embed-large\n      - UNSTRUCTURED_API_KEY=$UNSTRUCTURED_API_KEY\n      - UNSTRUCTURED_API_URL=https://api.unstructured.io/general/v0/general\n      #- GITHUB_TOKEN=$GITHUB_TOKEN\n\n    volumes:\n      - ./data:/data/\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8000 || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: semitechnologies/weaviate:1.25.10\n    ports:\n      - 8080:8080\n      - 3000:8080\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n    environment:\n      OPENAI_APIKEY: $OPENAI_API_KEY\n      COHERE_APIKEY: $COHERE_API_KEY\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'e'\n      CLUSTER_HOSTNAME: 'node1'\n\nvolumes:\n  weaviate_data: {}\n...\n\n\nLet me know if that helps!\nThanks!\n\n----------\n\n[bam (2024-10-30T23:32:03.189Z)]: Thank you for the quick response.\nScreenshot 2024-10-30 at 18.11.471498×480 47.4 KB\nWhat does your file structure look like?\nI didn’t use Docker to launch Weaviate. I used the embedded path because the blog post said it would be the easiest. That’s my directory structure and the only file I added was the .env copied from the blogpost.\nI ran docker pull semitechnologies/verba in my terminal.\nThen tried running docker compose up using the file/commands you shared and got a different error.\n✘ weaviate Error context canceled                                                                 1.3s\n ✘ verba Error    pull access denied for verba-verba, repository does not exist or...              1.3s\nError response from daemon: pull access denied for verba-verba, repository does not exist or may require 'docker login'\n\nI confirmed that I’m logged in. I check stackoverflow for his error and it sights mispellings are a cause. Tho’ I didn’t change anything in the commands.\nThank you. I’ll keep tinkering with it tonight.\n\n----------\n\n[bam (2024-10-31T02:53:29.761Z)]: I think defining the schema will solve my problem.\nerror message:\nlocalhost:8080/v1/schema\nScreenshot 2024-10-30 at 21.59.25766×298 17.6 KB\n\n----------\n\n[DudaNogueira (2024-10-31T12:44:48.610Z)]: I believe docker is the easiest way \nOnce you know how to play around with, it gets really easy to run apps. Also, you get a more production ready deployment, considering that embedded is still marked as experimental.\nthe verba-verba image I have used is the one I have built myself, in my mac. You can build it by cloning Verba’s repo and running\ndocker compose build\nI have sent a PR to enable Verba to have linux/arm64 support, so it will work on Mac.\nFor now, you can try using the image I have built, so your docker-compose can be:\n---\n\nservices:\n  verba:\n    image: dudanogueira/verba\n    ports:\n      - 8000:8000\n    environment:\n      - WEAVIATE_URL_VERBA=http://weaviate:8080\n      - OPENAI_API_KEY=$OPENAI_API_KEY\n      - COHERE_API_KEY=$COHERE_API_KEY\n      - OLLAMA_URL=http://host.docker.internal:11434\n      - OLLAMA_MODEL=llama3.1\n      - OLLAMA_EMBED_MODEL=mxbai-embed-large\n      - UNSTRUCTURED_API_KEY=$UNSTRUCTURED_API_KEY\n      - UNSTRUCTURED_API_URL=https://api.unstructured.io/general/v0/general\n      #- GITHUB_TOKEN=$GITHUB_TOKEN\n\n    volumes:\n      - ./data:/data/\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8000 || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: semitechnologies/weaviate:1.25.10\n    ports:\n      - 8080:8080\n      - 3000:8080\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n    environment:\n      OPENAI_APIKEY: $OPENAI_API_KEY\n      COHERE_APIKEY: $COHERE_API_KEY\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'e'\n      CLUSTER_HOSTNAME: 'node1'\n\nvolumes:\n  weaviate_data: {}\n...\n\nLet me know if you are okey running it with docker (don’t worry, I can help you on this) or if you want to keep running with weaviate embedded .\n\n----------\n\n[bam (2024-11-03T18:16:16.305Z)]: How would I set this up without Cohere? I read their TOC and it requires giving them permission to use your data. My goal is to use this locally/offline and not expose my data to 3rd parties.\nI need help creating a schema and importing my data. I got the docker container running locally.\n\n----------\n\n[bam (2024-11-03T21:48:20.925Z)]: Screenshot 2024-11-03 at 16.33.471920×892 179 KB\nI have Verba, Weaviate, and Ollama running in the same image. Ollama keeps restarting. Verba says it’s connected to Ollama on port 11434 only when Ollama is started outside of the docker image.\nI’m getting this error in docker using a refactored docker compose file now:\nINFO:     Started reloader process [1] using WatchFiles\n2024-11-03 16:31:31 verba-1     | ℹ Couldn't connect to Ollama http://host.docker.internal:11434\n2024-11-03 16:31:31 verba-1     | ℹ Couldn't connect to Ollama http://host.docker.internal:11434\n2024-11-03 16:31:31 verba-1     | ℹ Couldn't connect to Groq (https://api.groq.com/openai/v1/)\n\nI made a few changes to the docker file:\nservices:\n  ollama:\n    image: ollama/ollama\n    command: ollama run llama3.2\n    ports:\n      - 11434:11434\n    restart: on-failure\n\n  verba:\n    image: dudanogueira/verba\n    ports:\n      - 8000:8000\n    environment:\n      - WEAVIATE_URL_VERBA=http://weaviate:8080\n      - OLLAMA_URL=http://host.docker.internal:11434\n      - OLLAMA_MODEL=llama3.2\n      - OLLAMA_EMBED_MODEL=mxbai-embed-large\n      #- GITHUB_TOKEN=$GITHUB_TOKEN\n\n    volumes:\n      - ./data:/data/\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8000 || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: semitechnologies/weaviate:1.25.10\n    ports:\n      - 8080:8080\n      - 3000:8080\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'e'\n      CLUSTER_HOSTNAME: 'node1'\n\nvolumes:\n  weaviate_data: {}\n\n----------\n\n[Kieran_Sears (2024-11-04T12:25:25.640Z)]: what are the logs for ollama? docker logs ollama to find out why it’s restarting?\nyou’ll probably want to link a volume to ollama as well otherwise you go through the hassle of needing to manually pull a model each time you start it up. I’ve got an example here which also has a few other bells and whistles that work for my machine (see ollama dockerhub for GPU details):\nvolumes:\n  ollama_data:\n    driver: local\n\nservices:\n  ollama:\n    container_name: ollama\n    hostname: ollama\n    image: ollama/ollama:0.3.9\n    deploy:\n      resources:\n        reservations:\n          devices:\n          - driver: nvidia\n            capabilities: [\"gpu\"]\n            count: all\n    volumes:\n      - ollama_data:/root/.ollama\n    restart: always\n    ports:\n      - 11434:11434\n    healthcheck:\n      test: ollama list || exit 1\n      interval: 10s\n      timeout: 5s\n      retries: 3\n      start_period: 10s\n\nHave you tried OLLAMA_URL=http://ollama:11434 for your verba services environment variables? I’ve found that I don’t need host.docker.internal if I’m running ollama as part of docker compose, only if it’s externally being fired up with something like docker run ollama\n\n----------\n\n[bam (2024-11-05T20:52:27.076Z)]: Thank you. I tried to use your docker compose file and got the following\nerror:\nGracefully stopping... (press Ctrl+C again to force)\nError response from daemon: could not select device driver \"nvidia\" with capabilities: [[gpu]]\n\nScreenshot 2024-11-05 at 15.50.531398×114 27.5 KB\nI think the issue is loading the schema. I don’t have a schema yet.\n\n----------\n\n[Kieran_Sears (2024-11-06T09:32:49.195Z)]: Just checking, did you follow the instructions in the link posted “ollama dockerhub for GPU details”? Maybe you don’t have an Nvidia card or didn’t install the Nvidia Container Toolkit?\n\n----------\n\n[bam (2024-11-12T21:27:59.418Z)]: I was able to get it to work, not the way I wanted but it works.\nI open weaviate db in a docker image, run ollama locally, and verba locally using the pip install goldenverba then verba start.\nHere’s my docker-compose file\"\n\nnetworks:\n  local-net:\n    external: true\n    name: local-net  # This is the Docker network that allows access to your local machine\n\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:latest\n    environment:\n      - QUERY_DEFAULTS_LIMIT=20\n      - ENABLE_MODULES=text2vec-verba\n      - VERBA_API_URL=http://host.docker.internal:8000  # Access Verba on local port 8000\n    ports:\n      - \"8080:8080\"  # Expose Weaviate on port 8080\n    networks:\n      - local-net\n\n----------\n\n[DudaNogueira (2024-11-13T17:31:47.492Z)]: Oh, nice!\nThanks for sharing!\nI have also noticed ollama performing better when running directly on host instead of docker.\nFor one dataset it was importing in host, but not on docker.\nI run mac, without GPU, so this may also affect it somehow.",
    "date_created": "2024-10-30T09:34:47.810Z",
    "has_accepted_answer": true,
    "title": "Locally running RAG pipeline with Verba and Llama3 with Ollama",
    "topic_id": 7324
  },
  {
    "user_id": 2474,
    "conversation": "[afstkla (2025-02-20T07:11:24.111Z)]: Description\nDue to a bug in our update handling, instead of updating objects, we actually created new ones without deleting the old ones for a while. We noticed this a few days ago and have solved the issue since.\nThis situation resulted in having 160GB of data from Weaviate (according to df), which didnt seem to make our Weaviate very happy in our 120GB RAM server.\nThen, we ran a script, removing all objects that should have been deleted. For some reason, the over-all file size increased from 160GB to 185GB, causing the resource issues to become even bigger.\nIs this expected and just a matter of time until it actually deletes objects? Is there a way to speed up that deletion?\nServer Setup Information\n\nWeaviate Version: 1.28.2\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: python v3\nMultitenancy?:  nope\n\nAny additional Information\nSetup is quite normal, but we’ve noticed this issue due to our AWS costs getting significant overnight, due to what seems like weaviate constantly swapping objects in and out of our EFS\nWe did a quick calculation based on our raw object size, and we expect about 30GB to be a realistic number. We’re not sure how much overhead weaviate adds, but if we’d store the objects raw on disk, we expect about 30GB in total\n\n----------\n\n[DudaNogueira (2025-02-20T16:21:18.099Z)]: hi @afstkla !!\nThe disk usage should be freed as the compaction goes.\nCan you confirm to me if the disk has not reduced even 1 day after the object deletion?\nThanks!\n\n----------\n\n[afstkla (2025-02-21T08:36:06.576Z)]: Hi @DudaNogueira , no, even though we ran the cleanup script Tuesday night (CET), this morning (48+hrs later) it’s still at 184.3 (which is ± the same as when I made this post).\nI’ve already tried re-running our deletion script again, and it doesn’t find any objects anymore that we’ve deleted, nor new objects to delete since the last run (we used Python v3’s client.data_object.delete(<uuid>, \"WeaviateDocumentChunk\"). So we’re quite at a loss here. Anything you can propose to fix it (or even debug it? We don’t see any weird logs (other than the fact that our service is clearly struggling, probably due to the significant storage)\n(Can’t upload more than 1 image, so trying it like this. Terminal info from our prod instance, AWS logs from ± the past hr in DEBUG mode)\nimage1920×1080 196 KB\n\n----------\n\n[DudaNogueira (2025-02-25T19:22:03.501Z)]: hi @afstkla !!\nI will be investigating this further to escalate with our team.\nI will get back here when I get more info.\nThanks!\n\n----------\n\n[afstkla (2025-02-26T07:01:36.752Z)]: Hi @DudaNogueira , thanks!\nReason this initially spiked our worries was that we suddenly had an insane increase in spend on AWS due to our EFS volume suddenly being bombarded with read requests (which triggered our investigation & our data purge).\nSince yesterday we’ve moved our Weaviate away from ECS/EFS, which made things cool off cost wise. So the urgency on our side is slightly less, but maybe this context helps you figure out what’s up.\n\n----------\n\n[DudaNogueira (2025-02-26T14:27:23.706Z)]: Thanks for sharing!\nWe did some investigations, and it indeed seems to have room for improvements:\n\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Space not being freed up on Weaviate's instances after deleting objects\n    \n\n    \n      \n        opened 11:10AM - 26 Feb 25 UTC\n      \n\n\n      \n        \n          \n          jfrancoa\n        \n      \n    \n\n    \n        \n          bug\n        \n    \n  \n\n\n  \n    ### How to reproduce this bug?\n\nIt was observed, after bringing up a 3 node clus…ter (either using the Weaviate process or running on K8s), that after deleting 99,999 objects in a collection with 100,000 objects, the disk space was not being returned and around 600MB were still being used.\n\nFirst, checkout `stable/v1.29` branch from the weaviate repo.\nTo run the cluster with 3 nodes, make sure to start contextionary first:\n```\ncd weaviate\ndocker compose -f docker-compose-test.yml up -d contextionary\n```\nRemove any /data-weaviate-* folder to ensure we start from clean state:\n```\nrm -rf data-weaviate-*\n```\n\nIn three different terminals run the Weaviate server:\n```\n./tools/dev/run_dev_server.sh\n```\n\n```\n./tools/dev/run_dev_server.sh second-node\n```\n\n```\n./tools/dev/run_dev_server.sh third-node\n```\n\nIn a fourth terminal we will use `weaviate-cli` (`brew install weaviate-cli`) to create collections and data:\n* Create a collection\n```\nweaviate-cli create collection\n```\n* Add objects to it:\n```\nweaviate-cli create data --limit 100000 --randomize\n```\n* Once the data is created, check the disk space:\n```\ndu -sh data-weaviate-*\n551M\tdata-weaviate-0\n532M\tdata-weaviate-1\n565M\tdata-weaviate-2\n```\n\nTo check the compaction status we are using the script [analyze_segments](https://github.com/weaviate/tools/tree/main/analyze_segments_python) from the tools repository.\n* We can confirm that compaction also takes place:\n* Weaviate-0\n```\npython analize_segments.py --collection Movies --weaviate-data ~/repos/weaviate/data-weaviate-0/\n\nShard: 9W6QpOz0ynuW\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-0/movies/9W6QpOz0ynuW/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740563284000080000.db          16.26 MB               0\nsegment-1740563258736910000.db          39.82 MB               1\n\nShard: Ms7orVnsKwbD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-0/movies/Ms7orVnsKwbD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740563296363253000.db          75.47 MB               2\n\nShard: M4XHkh1kd0dD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-0/movies/M4XHkh1kd0dD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740563285052783000.db          15.22 MB               0\nsegment-1740563259624060000.db          39.41 MB               1\n```\n\n* Weaviate-1\n```\npython analize_segments.py --collection Movies --weaviate-data ~/repos/weaviate/data-weaviate-1/\n\nShard: 9W6QpOz0ynuW\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-1/movies/9W6QpOz0ynuW/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740563283880589000.db          16.26 MB               0\nsegment-1740563258679799000.db          39.82 MB               1\n\nShard: Ms7orVnsKwbD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-1/movies/Ms7orVnsKwbD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740563296366529000.db          75.47 MB               2\n\nShard: M4XHkh1kd0dD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-1/movies/M4XHkh1kd0dD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740563284812753000.db          15.22 MB               0\nsegment-1740563259617401000.db          39.41 MB               1\n```\n\n* Weaviate-2\n```\npython analize_segments.py --collection Movies --weaviate-data ~/repos/weaviate/data-weaviate-2/\n\nShard: 9W6QpOz0ynuW\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-2/movies/9W6QpOz0ynuW/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740563283841454000.db          16.41 MB               0\nsegment-1740563258605321000.db          39.68 MB               1\n\nShard: Ms7orVnsKwbD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-2/movies/Ms7orVnsKwbD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740563296330709000.db          75.47 MB               2\n\nShard: M4XHkh1kd0dD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-2/movies/M4XHkh1kd0dD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740563284808913000.db          15.22 MB               0\nsegment-1740563259725768000.db          39.41 MB               1\n```\n\nNow, we go ahead and delete 99999 objects:\n```\nfor i in {1..9}; do weaviate-cli delete data --limit 10000; done; weaviate-cli  delete data --limit 9999\n```\n\nWe then wait for few minutes and check again the space and compaction state (waited several minutes):\n* Number objects:\n```\nweaviate-cli  get collection\n\nCollections:\n+------------+--------------+---------+---------+--------------+----------------------+------------------------------------+\n| Collection | Multitenancy | Tenants | Objects | Repl. Factor | Vector Index         | Vectorizer                         |\n+------------+--------------+---------+---------+--------------+----------------------+------------------------------------+\n| Movies     | False        | 0       | 1       | 3            | VectorIndexType.HNSW | Vectorizers.TEXT2VEC_CONTEXTIONARY |\n+------------+--------------+---------+---------+--------------+----------------------+------------------------------------+\n\nTotal: 1 collections\n```\n\n* Space:\n```\ndu -sh data-weaviate-*\n281M\tdata-weaviate-0\n263M\tdata-weaviate-1\n296M\tdata-weaviate-2\n```\n\n* Compaction:\n* Weaviate-0\n```\npython analize_segments.py --collection Movies --weaviate-data ~/repos/weaviate/data-weaviate-0/\n\nShard: 9W6QpOz0ynuW\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-0/movies/9W6QpOz0ynuW/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740566723304811000.db           3.00 MB               1\nsegment-1740563346169834000.db          36.30 MB               2\n\nShard: Ms7orVnsKwbD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-0/movies/Ms7orVnsKwbD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740566723147105000.db           1.63 MB               0\nsegment-1740566659497672000.db           4.94 MB               1\nsegment-1740563296363253000.db          75.47 MB               2\n\nShard: M4XHkh1kd0dD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-0/movies/M4XHkh1kd0dD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740566721615392000.db           2.92 MB               1\nsegment-1740563350274105000.db          35.35 MB               2\n```\n* Weaviate-1\n```\npython analize_segments.py --collection Movies --weaviate-data ~/repos/weaviate/data-weaviate-1/\n\nShard: 9W6QpOz0ynuW\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-1/movies/9W6QpOz0ynuW/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740566723074944000.db           3.00 MB               1\nsegment-1740563345858732000.db          36.30 MB               2\n\nShard: Ms7orVnsKwbD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-1/movies/Ms7orVnsKwbD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740566723985045000.db           1.62 MB               0\nsegment-1740566661162546000.db           4.95 MB               1\nsegment-1740563296366529000.db          75.47 MB               2\n\nShard: M4XHkh1kd0dD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-1/movies/M4XHkh1kd0dD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740566721494229000.db           2.92 MB               1\nsegment-1740563350011833000.db          35.36 MB               2\n```\n* Weaviate-2\n```\npython analize_segments.py --collection Movies --weaviate-data ~/repos/weaviate/data-weaviate-2/\n\nShard: 9W6QpOz0ynuW\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-2/movies/9W6QpOz0ynuW/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740566723962036000.db           2.99 MB               1\nsegment-1740563346128610000.db          36.24 MB               2\n\nShard: Ms7orVnsKwbD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-2/movies/Ms7orVnsKwbD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740566722349008000.db           1.64 MB               0\nsegment-1740566658605196000.db           4.94 MB               1\nsegment-1740563296330709000.db          75.47 MB               2\n\nShard: M4XHkh1kd0dD\nPath: /Users/jfrancoa/repos/weaviate/data-weaviate-2/movies/M4XHkh1kd0dD/lsm/objects\n\nSEGMENT                                     SIZE           LEVEL\nsegment-1740566722465873000.db           2.91 MB               1\nsegment-1740563350173759000.db          35.28 MB               2\n```\n\nAttached you can see a graph obtained also from the same test (not this specific execution reported though)\n\n![Image](https://github.com/user-attachments/assets/6cab4b3b-c92c-4914-8d04-95cbe616d19d)\n\n### What is the expected behavior?\n\nAfter the objects get deleted the space should be given back, mostly when there is only 1 single object\n\n### What is the actual behavior?\n\nWeaviate is not returning back the disk space used from storing objects\n\n### Supporting information\n\n_No response_\n\n### Server Version\n\n1.29.0\n\n### Weaviate Setup\n\nMulti-Node Cluster\n\n### Nodes count\n\n3\n\n### Code of Conduct\n\n- [x] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWe may be able to adjust some configs to free that space faster and improve it.\nThanks for reporting!\n\n----------\n\n[afstkla (2025-02-26T17:38:22.188Z)]: Thanks, I’ve subscribed to the issue to get updates.\nAs we’re running a workload with a lot of deletions & creations (we update a lot of our documents daily / weekly), is it expected that the impact due to this bug are also bigger?\nIn our case we went from ±160GB in disk size before the deletion, to ±185GB in disk size after the deletion (also, for some reason, it seems that our issues actually got worse after the deletion), and it’s been at that 185GB for a week.\n\n----------\n\n[DudaNogueira (2025-02-27T17:38:44.829Z)]: afstkla:\n\nSince yesterday we’ve moved our Weaviate away from ECS/EFS, which made things cool off cost wise. So the urgency on our side is slightly less, but maybe this context helps you figure out what’s up.\n\n\nIndeed, EFS is not recommended.\nOu team is analyzing this kind of scenario (lots of deletions). We may be able to improve configurations like PERSISTENCE_LSM_SEGMENTS_CLEANUP_INTERVAL_HOURS that will speed up the cleaning/merging of segments after deletion.\nThanks!",
    "date_created": "2025-02-20T07:11:24.059Z",
    "has_accepted_answer": false,
    "title": "Volume and objects size going up instead of down after removing >50% of objects",
    "topic_id": 10473
  },
  {
    "user_id": 2974,
    "conversation": "[ReverseHobo (2024-12-09T10:26:30.881Z)]: Hello, I would like to know if there are any good options or strategies for “penalizing” objects based on how common a specific TEXT property is among the results.\nMy collection consists of c.a. 35 000 objects, each object represents a statistical dataset. Each object has a “label” property, which is the title of the dataset used to generate the vector.\nEach object also has a “provider_id” property, which is the name of the organization that provided the dataset. There are about 15 different providers in the collection.\nMy problem is that when I query (hybrid or semantic) for a dataset, the results are often dominated by datasets from the same provider. Often these have very similar titles, so the results are not very diverse.\nI would like to know if there is a way to penalize objects based on how common the “provider_id” is among the results.\nMy idea would be to add a weight of some kind, so that if the first result provider is “A” → then the next result with provider “A” would have a penalty of 0.9 and then the next 0.9^2, and so on.\nIs there a way to do this in Weaviate? Or do you have any other suggestions on how to approach this problem?\n\nMy weaviate cluster is a serverless Weaviate Cloud instance.\nI use the python client to query the Weaviate instance.\n\nThank you in advance!\nHere is the schema of the collection:\n{\n    \"invertedIndexConfig\": {\n        \"bm25\": {\"b\": 0.75, \"k1\": 1.2},\n        \"cleanupIntervalSeconds\": 60,\n        \"indexNullState\": false,\n        \"indexPropertyLength\": false,\n        \"indexTimestamps\": false,\n        \"stopwords\": {\"preset\": \"en\"},\n    },\n    \"multiTenancyConfig\": {\n        \"enabled\": false,\n        \"autoTenantCreation\": false,\n        \"autoTenantActivation\": false,\n    },\n    \"properties\": [\n        {\n            \"name\": \"dataset_id\",\n            \"description\": \"The id of the dataset.\",\n            \"dataType\": [\"int\"],\n            \"indexFilterable\": false,\n            \"indexSearchable\": false,\n            \"indexRangeFilters\": false,\n            \"tokenization\": null,\n            \"moduleConfig\": {\"none\": {}},\n        },\n        {\n            \"name\": \"provider_id\",\n            \"description\": \"The provider id of the table.\",\n            \"dataType\": [\"text\"],\n            \"indexFilterable\": true,\n            \"indexSearchable\": true,\n            \"indexRangeFilters\": false,\n            \"tokenization\": \"word\",\n            \"moduleConfig\": {\"none\": {}},\n        },\n        {\n            \"name\": \"label\",\n            \"description\": \"The title of the table.\",\n            \"dataType\": [\"text\"],\n            \"indexFilterable\": true,\n            \"indexSearchable\": true,\n            \"indexRangeFilters\": false,\n            \"tokenization\": \"word\",\n            \"moduleConfig\": {\"none\": {}},\n        },\n        {\n            \"name\": \"dimensions\",\n            \"description\": \"The dimension/variable names for the table.\",\n            \"dataType\": [\"text[]\"],\n            \"indexFilterable\": true,\n            \"indexSearchable\": true,\n            \"indexRangeFilters\": false,\n            \"tokenization\": \"word\",\n            \"moduleConfig\": {\"none\": {}},\n        },\n        {\n            \"name\": \"uuid\",\n            \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Dec  6 20:58:14 2024\",\n            \"dataType\": [\"uuid\"],\n            \"indexFilterable\": true,\n            \"indexSearchable\": false,\n            \"indexRangeFilters\": false,\n            \"tokenization\": null,\n            \"moduleConfig\": {\"none\": {}},\n        },\n    ],\n    \"replicationConfig\": {\n        \"factor\": 1,\n        \"asyncEnabled\": false,\n        \"deletionStrategy\": \"NoAutomatedResolution\",\n    },\n    \"shardingConfig\": {\n        \"virtualPerPhysical\": 128,\n        \"desiredCount\": 1,\n        \"actualCount\": 1,\n        \"desiredVirtualCount\": 128,\n        \"actualVirtualCount\": 128,\n        \"key\": \"_id\",\n        \"strategy\": \"hash\",\n        \"function\": \"murmur3\",\n    },\n    \"vectorConfig\": {\n        \"default\": {\n            \"vectorizer\": {\n                \"text2vec-openai\": {\n                    \"baseURL\": \"https://api.openai.com\",\n                    \"dimensions\": 3072,\n                    \"model\": \"text-embedding-3-large\",\n                    \"vectorizeClassName\": true,\n                    \"properties\": null,\n                }\n            },\n            \"vectorIndexConfig\": {\n                \"cleanupIntervalSeconds\": 300,\n                \"distanceMetric\": \"cosine\",\n                \"dynamicEfMin\": 100,\n                \"dynamicEfMax\": 500,\n                \"dynamicEfFactor\": 8,\n                \"ef\": -1,\n                \"efConstruction\": 128,\n                \"filterStrategy\": \"sweeping\",\n                \"flatSearchCutoff\": 40000,\n                \"maxConnections\": 32,\n                \"skip\": false,\n                \"vectorCacheMaxObjects\": 1000000000000,\n            },\n            \"vectorIndexType\": \"hnsw\",\n        }\n    },\n    \"class\": \"Datasets\",\n    \"moduleConfig\": {\"reranker-cohere\": {\"model\": \"rerank-v3.5\"}},\n}\n\n----------\n\n[DudaNogueira (2024-12-09T19:08:45.942Z)]: hi @ReverseHobo !!\nWelcome to our community \nI know that bm25 will consider if a token is common to all objects, and take that into consideration.\nAlso, maybe you could group the query by provider_id, so you can manage the different results per provider and post process this after.\nLet me know if this helps!\nThanks!\n\n----------\n\n[ReverseHobo (2024-12-09T22:51:16.554Z)]: Yeah thanks, grouping by provider_id was the solution!",
    "date_created": "2024-12-09T10:26:30.830Z",
    "has_accepted_answer": true,
    "title": "Penalizing Frequent Property Values in Vector/Hybrid Search",
    "topic_id": 9164
  },
  {
    "user_id": 655,
    "conversation": "[alisha_liu (2024-12-09T22:40:24.481Z)]: Description\nI know in python v4 version we can do it like this:\ncollection.data.delete_many(\n    where=(\n        wvc.query.Filter.by_property(\"document_name\").equal(\"my_document\") &\n        wvc.query.Filter.by_property(\"document_type\").equal(\"xml\") &\n        wvc.query.Filter.by_property(\"source\").equal(\"source1\")\n    )\n)\n\nbut how to do the same things in typescript v3 version?\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-12-10T00:37:08.711Z)]: hi @alisha_liu !!\nThis is how you can filter with multiple conditions in our typescript client\nSo the syntax for deleteMany is similar, you can just pass a Filters.and, like so:\n    // delete many with multiple conditions\n    const query =  await collection.data.deleteMany(\n        Filters.and(\n            collection.filter.byProperty('category').equal('places'),\n            collection.filter.byProperty('answer').equal('Brazil')\n          )\n    )\n\nLet me know if that helps!\nThanks!",
    "date_created": "2024-12-09T22:40:24.428Z",
    "has_accepted_answer": true,
    "title": "Anyone used many WHERE filters in deleteMany function via typescript v3",
    "topic_id": 9171
  },
  {
    "user_id": 1408,
    "conversation": "[sandeep_gajula (2024-11-11T10:33:20.159Z)]: I am facing an issue with deleting and retrieving data when I have applied where filter.\nI want to delete only the name test, but it is deleting the test and test limi properties/data objects  I have in my weaviate. I don’t want this to happen.\nHere, if you observe that the display or get function deviates from retrieving results based on semantic search, but I need to extract search results. For example, for a test, I need only matches of the test, not the test limi, etc.\nMy query::\ncheck_query = f\"“”\n{{\nGet {{\n{class_name}(\nwhere: {{\npath: [“name”],\noperator: Equal,\nvalueString: “{name}”\n}}\n) {{\nname\n_additional {{\nid\n}}\n}}\n}}\n}}\n“”\"\nresponse = client.query.raw(check_query)\nprint(“Response from Weaviate:”, response)\ndelete_query = {\n“operator”: “Equal”,\n“path”: [“name”],\n“valueString”: name,\n}\nx= client.batch.delete_objects(\nclass_name=class_name,\nwhere=delete_query\n)\nprint(x)\nResponse from Weaviate:  {‘data’: {‘Get’: {‘Issue’: [{‘_additional’: {‘id’: ‘a5fff400-df0f-4320-8134-036ae28c4891’}, ‘name’: ‘test limi’}, {‘_additional’: {‘id’: ‘9cb804bc-8375-4dfe-bf4d-f30402780386’}, ‘name’: ‘test’}]}}}\nDelete query response :\n{‘dryRun’: False, ‘match’: {‘class’: ‘Issue’, ‘where’: {‘operands’: None, ‘operator’: ‘Equal’, ‘path’: [‘name’], ‘valueString’: ‘test’}}, ‘output’: ‘minimal’, ‘results’: {‘failed’: 0, ‘limit’: 10000, ‘matches’: 2, ‘objects’: None, ‘successful’: 2}}\nSuccessfully deleted 4 exact matches for client name ‘test’\nSupport\nResolve this issue if anyone aware of\nI am using docker version of weavaite and my tokenizer for this property is whitespace\n\n----------\n\n[DudaNogueira (2024-11-11T21:47:54.950Z)]: Hi!\nWhat is the server version?\nYou property probably has the tokenization of the property name set to field.\nThis means that My Cool Test will become three tokens: my cool test, and now if you search for some objects that has cool it will find all objects that has this token.\nCheck here for a comprehensive doc on Tokenization in Weaviate:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nOverview of tokenization | Weaviate\n\n  Tokenization is the process of breaking text into smaller units, called tokens. This is an important step that impacts how text is processed in a variety of contexts.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYou may want to set the tokenization to field to avoid this scenario.\nLet me know if that helps!\nThanks!\n\n----------\n\n[sandeep_gajula (2024-11-12T03:08:55.552Z)]: No, I have used “white space”  tokenization in my schema while creating a class.\nAnd I am using python client v3\n\n----------\n\n[DudaNogueira (2024-11-12T19:19:32.336Z)]: That best thing here is to create some python code, if possible in pyv4, so we can try to reproduce the issue you are facing.\nCan you share a code for this?\nThanks!",
    "date_created": "2024-11-11T10:33:20.101Z",
    "has_accepted_answer": false,
    "title": "Issues facing while performing CRUD operations",
    "topic_id": 7532
  },
  {
    "user_id": 1492,
    "conversation": "[aliaksei-kharlap (2024-09-06T15:00:23.364Z)]: I didn’t find any record that the WeaviateHybridSearchRetriever supports working with WeaviateAsyncClient or any records on how to work, can you give me some information? I am trying to rewrite sync app to async\nAlso i need the same information about WeaviateVectorStore\n\n----------\n\n[DudaNogueira (2024-09-06T20:41:18.183Z)]: hi @aliaksei-kharlap !!\nIs this using Langchain?\nIf that’s the case, I don’t think this is supported yet \nBut that’s something interesting to try and implement.\n\n----------\n\n[aliaksei-kharlap (2024-09-08T06:48:30.217Z)]: Yes, i use Langchain",
    "date_created": "2024-09-06T15:00:23.163Z",
    "has_accepted_answer": false,
    "title": "WeaviateHybridSearchRetriever with WeaviateAsyncClient",
    "topic_id": 3995
  },
  {
    "user_id": 3685,
    "conversation": "[Volvo (2025-03-04T14:38:20.714Z)]: I’m building a chatbot that uses Weaviate and t2v-transformers for vectorizing my knowledge base. My way of sends batches like this:\nvar batchResponse = await _httpClient.PostAsync($\"{_weaviateUrl}/v1/batch/objects\", batchContent);\nEach batch contains 50 objects, runs with 5 parallel processes, and each object includes about 12 sentences. Most batches succeed, but occasionally I run into this error:\n\nt2v-transformers-1       | INFO:     172.21.0.4:55808 - “POST /vectors HTTP/1.1” 200 OK\nweaviate-1               | {“build_git_commit”:“584532a”, … “error”:“write tcp 172.21.0.4:8080->172.21.0.1:33884: i/o timeout”, “hint”:“Either try increasing the server-side timeout using e.g. ‘–write-timeout=600s’ …”}\n\nThe error suggests increasing the server-side timeout using --write-timeout=600s. When I added that to my Weaviate Docker configuration, the container started to reload repeatedly with errors about missing TLS certificates. To resolve the TLS issue, I generated certificates with OpenSSL, mapped them into the container, and configured Weaviate to use them.\nHere’s my current Docker Compose configuration for Weaviate and t2v-transformers:\nweaviate:\n  image: cr.weaviate.io/semitechnologies/weaviate:1.26.4\n  restart: unless-stopped\n  ports:\n    - 8080:8080\n    - 50051:50051\n  volumes:\n    - /var/beyond_weaviate_data:/data\n    - ./certs:/certs \n  command: [\n      \"/app/weaviate\",\n      \"--write-timeout=600s\",\n      \"--tls-certificate=/certs/cert.pem\", \n      \"--tls-key=/certs/key.pem\"          \n    ]\n  environment:\n    QUERY_DEFAULTS_LIMIT: 100\n    AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n    PERSISTENCE_DATA_PATH: \"/data\"\n    DEFAULT_VECTORIZER_MODULE: text2vec-transformers\n    ENABLE_MODULES: text2vec-transformers\n    TRANSFORMERS_INFERENCE_API: http://t2v-transformers:8080\n    CLUSTER_HOSTNAME: 'node1'\n    BATCH_TIMEOUT: 300\n\nt2v-transformers:\n  image: cr.weaviate.io/semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1\n  restart: unless-stopped\n  environment:\n    ENABLE_CUDA: 0\n    USE_SENTENCE_TRANSFORMERS_MULTI_PROCESS: \"true\"\n    ENABLE_CACHE: \"true\"\n\nAfter adding the certificate parameters, the container stopped reloading, but now my application cannot connect. I get connection errors in my .NET client similar to:\nat System.Net.Http.HttpConnection.<SendAsync>d__57.MoveNext()\n...\nat NLP_LLMEngine.Services.WeaviateVectorizationService.<CreateCollectionIfNotExistsAsync>d__11.MoveNext() in ...\\WeaviateVectorizationService.cs:line 70\n\nWeaviate logs show that the transformer remote inference service is not ready (connection refused on t2v-transformers:8080). And thats how i get connectivity issues and timeout errors.\nMy Question\nHow can I safely add a server-side write timeout (e.g., --write-timeout=600s) for batch vectorization without causing TLS certificate issues or container restarts? And if the tls is needed in my case is there a way to configure Weaviate to use the specified TLS certificate and key without interfering with communication between Weaviate and t2v-transformers?\nAny help to handle these issues would be greatly appreciated. I’m fairly new to vector databases and Weaviate, so any help would be great, thanks in advance.\n\n----------\n\n[Mohamed_Shahin (2025-03-05T09:11:21.324Z)]: Hey @Volvo\nIt’s great to have you in our community!\nHave you tried to reduce the parallel processes to 1 or 2, or limit it to 100 objects at a time. It’s also worth checking that your network latency is good.\nI’d also suggest ensuring the resources are sufficient in your cluster. Also, try increasing the connection timeout for Weaviate, especially for inserts:\n\nadditional_config=AdditionalConfig(\ntimeout=Timeout(init=30, query=240, insert=240),\n)\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nLocal instances | Weaviate\n\n  Follow these steps to connect to a locally hosted Weaviate instance.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nRegarding TLS configuration, please see the following example from my colleague @DudaNogueira regarding SSL/TLS\n\n  \n    \n    \n    Does Weaviate support SSL out of the box? Support\n  \n  \n    hi @lakshminarayana ! Welcome to our community. \nOur documentation usually doesn’t cover the SSL/TLS side of the deployment for two main reasons: \n1 - Usually, self deployments will not expose Weaviate directly. Their applications will be exposed. but not Weaviate. \n2 - Whenever there is a reason to expose Weaviate under a SSL/TLS connection, one can use a variety of reverse proxies, load balancers and so on. \nI have crafted here a gist on how to deploy Weaviate, with a single node, using docker…\n  \n\n\nRegards,\nMohamed Shahin\nSupport Engineer\n\n----------\n\n[Volvo (2025-03-05T09:38:36.403Z)]: Hi @Mohamed_Shahin ,thanks for replying!\nI have tried reducing parallelism to 2 and increasing the batch size from 50 to 100, like so:\n\"WeaviateSettings\": {\n  \"Host\": \"127.0.0.1\",\n  \"Port\": 8080,\n  \"GrpcPort\": 50051,\n  \"BatchChunkSize\": 100,\n  \"MaxParallelBatches\": 2,\n  \"SentencesPerObject\": 12\n}\n\nHowever, I am still facing the same issue with this error in my Weaviate console:\nweaviate-1 | {\"build_git_commit\":\"584532a\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.4\",\"build_wv_version\":\"1.26.4\",\"description\":\"An I/O timeout occurs when the request takes longer than the specified server-side timeout.\",\"error\":\"write tcp 172.21.0.5:8080-\\u003e172.21.0.1:35834: i/o timeout\",\"hint\":\"Either try increasing the server-side timeout using e.g. '--write-timeout=600s' as a command line flag when starting Weaviate, or try sending a computationally cheaper request, for example by reducing a batch size, reducing a limit, using less complex filters, etc. Note that this error is only thrown if client-side and server-side timeouts are not in sync, more precisely if the client-side timeout is longer than the server side timeout.\",\"level\":\"error\",\"method\":\"POST\",\"msg\":\"i/o timeout\",\"path\":{\"Scheme\":\"\",\"Opaque\":\"\",\"User\":null,\"Host\":\"\",\"Path\":\"/v1/batch/objects\",\"RawPath\":\"\",\"OmitHost\":false,\"ForceQuery\":false,\"RawQuery\":\"\",\"Fragment\":\"\",\"RawFragment\":\"\"},\"time\":\"2025-03-05T09:29:35Z\"}\n\nMy Setup:\nI am using .NET and hosting Weaviate locally on Docker with the following configuration:\nweaviate:\n  image: cr.weaviate.io/semitechnologies/weaviate:1.26.4\n  restart: unless-stopped\n  ports:\n    - 8080:8080\n    - 50051:50051\n  volumes:\n      - /var/beyond_weaviate_data:/data\n  environment:\n    QUERY_DEFAULTS_LIMIT: 100\n    AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n    PERSISTENCE_DATA_PATH: \"/data\"\n    DEFAULT_VECTORIZER_MODULE: text2vec-transformers\n    ENABLE_MODULES: text2vec-transformers\n    TRANSFORMERS_INFERENCE_API: http://t2v-transformers:8080\n    CLUSTER_HOSTNAME: 'node1'\n    BATCH_TIMEOUT: 300\n\nt2v-transformers:\n  image: cr.weaviate.io/semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1\n  restart: unless-stopped\n  environment:\n    ENABLE_CUDA: 0  \n    USE_SENTENCE_TRANSFORMERS_MULTI_PROCESS: \"true\"\n    ENABLE_CACHE: \"true\"\n\nWhat I Tried:\nI have attempted to add --write-timeout=600s to my Docker setup. However, after doing so, I am facing another issue: Weaviate keeps reloading.\nThe error I receive is:\nweaviate-1 | {\"action\":\"restapi_management\",\"build_git_commit\":\"584532a\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.4\",\"build_wv_version\":\"1.26.4\",\"docker_image_tag\":\"1.26.4\",\"level\":\"info\",\"msg\":\"the required flags `--tls-certificate` and `--tls-key` were not specified\",\"time\":\"2025-03-05T09:34:07Z\"}\nweaviate-1 exited with code 0\n\nI’d appreciate any guidance on resolving this issue, because I’m unsure of what am I doing wrong and how should my docker look like\n\n----------\n\n[DudaNogueira (2025-03-13T15:11:10.017Z)]: Hi!\nCan you try increasing the value of MODULES_CLIENT_TIMEOUT?\nYou can get more info on this here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nEnvironment variables | Weaviate\n\n  To configure Weaviate in a Docker or a Kubernetes deployment, set these environment variables",
    "date_created": "2025-03-04T14:38:20.630Z",
    "has_accepted_answer": false,
    "title": "Write Timeout for Batch Vectorization in Docker – TLS & Container Restart Issues",
    "topic_id": 10737
  },
  {
    "user_id": 2020,
    "conversation": "[akerkau (2024-10-22T14:51:49.765Z)]: Description\nWith Weaviate 1.23.7, I configured S3 backup in the Helm chart. The S3 endpoint is a local service (on a NetApp SAN) that’s available via https on port 8443 and with a self-signed certificate.\nThe inevitable happens:\n# curl -X POST -H \"Content-Type: application/json\" -d '{ \"id\": \"test-backup\", \"include\": [\"TEST_01\"] }' http://10.43.186.32:80/v1/backups/s3\n{\"error\":[{\"message\":\"check if backup \\\"test-backup\\\" exists at \\\"s3://[…internal_bucketname…]/test-backup\\\": get object 'test-backup/backup_config.json': Get \\\"https://[…internal_host_fqdn…]:8443/[…internal_bucketname…]/?location=\\\": tls: failed to verify certificate: x509: certificate relies on legacy Common Name field, use SANs instead\"}]}\n\nCan I somehow disable TLS verification or add the self-signed certificate as trusted? The docs only mention disabling TLS altogether which the endpoint doesn’t allow it seems.\nServer Setup Information\n\nWeaviate Server Version: 1.23.7\nDeployment Method: k8s with Helm\nMulti Node? Number of Running Nodes: 2\nClient Language and Version: curl 7.61.1\nMultitenancy?: no\n\nAny additional Information\nThe backup-specific part of the values.yaml for Helm:\nbackups:\n  filesystem:\n    enabled: false\n\n  s3:\n    enabled: true\n\n    envconfig:\n      BACKUP_S3_BUCKET: […internal_bucketname…]\n      BACKUP_S3_ENDPOINT: […internal_host_fqdn…]:8443\n      # BACKUP_S3_USE_SSL: true\n\n    envSecrets:\n      AWS_ACCESS_KEY_ID: weaviate-s3-backup\n      AWS_SECRET_ACCESS_KEY: weaviate-s3-backup\n\n  gcs:\n    enabled: false\n\n  azure:\n    enabled: false\n\n----------\n\n[akerkau (2024-10-23T13:16:05.794Z)]: tl;dr: The self-signed certificate needs subjectAltNames and the environment variable SSL_CERT_FILE allows an override for the truststore.\nI continued investigating and found out that the specific self-signed certificate has issues: Golang > 1.17 doesn’t support certificates not defining SANs. With a modified self-signed certificate, the error message looks like this:\n{\"error\":[{\"message\":\"check if backup \\\"test-backup\\\" exists at \\\"s3://[…internal_bucketname…]/test-backup\\\": get object 'test-backup/backup_config.json': Get \\\"https://[…internal_host_fqdn…]:8443/[…internal_bucketname…]/?location=\\\": tls: failed to verify certificate: x509: certificate signed by unknown authority\"}]}\n\nThen I found the Golang-specific environment variable SSL_CERT_FILE and added a custom truststore file as follows:\n$ vi values.yaml\n[…]\nenv:\n  # Add a custom truststore including the self-signed certificate\n  SSL_CERT_FILE: /tls/custom-truststore.crt\n[…]\nextraVolumeMounts:\n- name: custom-truststore\n  mountPath: /tls\n\nextraVolumes:\n- name: custom-truststore\n  configMap:\n    name: weaviate-custom-truststore\n[…]\n\nThe referenced ConfigMap contains the complete /etc/ssl/certs/ca-certificates.crt from the image plus my self-signed certificate.\nIt’s working now:\n{\"backend\":\"s3\",\"classes\":[\"TEST_01\"],\"id\":\"test-backup\",\"path\":\"s3://[…internal_bucketname…]/test-backup\",\"status\":\"STARTED\"}\n\n----------\n\n[Mohamed_Shahin (2024-10-24T09:11:55.696Z)]: Hi @akerkau,\nWelcome to our community! It’s great to have you here.\nI’m glad to hear you managed to solve the issue, and I appreciate you sharing the solution for us and other members who may face the same challenge.\nWishing you a lovely week ahead!",
    "date_created": "2024-10-22T14:51:49.715Z",
    "has_accepted_answer": true,
    "title": "S3 backup \"failed to verify certificate\"",
    "topic_id": 5841
  },
  {
    "user_id": 2431,
    "conversation": "[cw257900 (2024-11-10T07:04:50.500Z)]: When I use connect_to_local, I can tell chunks inserted properly : one file has 10; other pdf has 15. When I switch to use embeded, it stuck with 20, seems last file over-written the fist file. How to avoid this?\n2024-11-10 00:57:04,305 - INFO -  === utils.py counts per file\n{\n“/Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf”: 10,\n“/Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what-is-a-constitution-primer.pdf”: 15\n}\n\n----------\n\n[DudaNogueira (2024-11-10T11:17:46.036Z)]: hi @cw257900 !\nAre you sure you are running the same version on both scenarios?\nWhat is the version you are running?\nIs the code and data used sharable?\nThanks!\n\n----------\n\n[cw257900 (2024-11-11T01:16:43.489Z)]: it’s all from same code base, in vector_store.py file, I can switch between embeded and local while the rest code stays the same\n\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - cw257900/fastapi_onazure\n\n    Contribute to cw257900/fastapi_onazure development by creating an account on GitHub.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nCode is open in git\n\n----------\n\n[cw257900 (2024-11-11T01:17:50.140Z)]: local client works perfect. when i use connected_to_embeded; length of response are always 20 after new file being uploaded;\n\n----------\n\n[cw257900 (2024-11-11T20:46:58.169Z)]: This is the collection I print out:  {‘classes’: [{‘class’: ‘PDF_COLLECTION’, ‘invertedIndexConfig’: {‘bm25’: {‘b’: 0.75, ‘k1’: 1.2}, ‘cleanupIntervalSeconds’: 60, ‘indexNullState’: True, ‘indexPropertyLength’: True, ‘indexTimestamps’: True, ‘stopwords’: {‘additions’: None, ‘preset’: ‘en’, ‘removals’: None}}, ‘moduleConfig’: {‘generative-cohere’: {}, ‘text2vec-openai’: {‘baseURL’: ‘https://api.openai.com’, ‘model’: ‘ada’, ‘vectorizeClassName’: True}}, ‘multiTenancyConfig’: {‘autoTenantActivation’: False, ‘autoTenantCreation’: False, ‘enabled’: False}, ‘properties’: [{‘dataType’: [‘text’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: True, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘page_content’, ‘tokenization’: ‘word’}, {‘dataType’: [‘int’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: False, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘page_number’}, {‘dataType’: [‘text’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: True, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘source’, ‘tokenization’: ‘word’}, {‘dataType’: [‘date’], ‘description’: “This property was generated by Weaviate’s auto-schema feature on Sun Nov 10 23:44:25 2024”, ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: False, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: False}}, ‘name’: ‘uploadDate’}], ‘replicationConfig’: {‘asyncEnabled’: False, ‘deletionStrategy’: ‘DeleteOnConflict’, ‘factor’: 1}, ‘shardingConfig’: {‘actualCount’: 1, ‘actualVirtualCount’: 128, ‘desiredCount’: 1, ‘desiredVirtualCount’: 128, ‘function’: ‘murmur3’, ‘key’: ‘_id’, ‘strategy’: ‘hash’, ‘virtualPerPhysical’: 128}, ‘vectorIndexConfig’: {‘bq’: {‘enabled’: True}, ‘cleanupIntervalSeconds’: 300, ‘distance’: ‘cosine’, ‘dynamicEfFactor’: 8, ‘dynamicEfMax’: 500, ‘dynamicEfMin’: 100, ‘ef’: -1, ‘efConstruction’: 128, ‘filterStrategy’: ‘sweeping’, ‘flatSearchCutoff’: 40000, ‘maxConnections’: 32, ‘pq’: {‘bitCompression’: False, ‘centroids’: 256, ‘enabled’: False, ‘encoder’: {‘distribution’: ‘log-normal’, ‘type’: ‘kmeans’}, ‘segments’: 0, ‘trainingLimit’: 100000}, ‘skip’: False, ‘sq’: {‘enabled’: False, ‘rescoreLimit’: 20, ‘trainingLimit’: 100000}, ‘vectorCacheMaxObjects’: 1000000000000}, ‘vectorIndexType’: ‘hnsw’, ‘vectorizer’: ‘text2vec-openai’}]}\n\n----------\n\n[DudaNogueira (2024-11-12T18:58:02.509Z)]: Embedded will spawn a weaviate instance from the python client code. So a lot can happen there \nWhat you mean length of response?\n\n----------\n\n[cw257900 (2024-11-12T19:58:10.441Z)]: collection = client.collections.get(class_name)\nresponse = collection.query.fetch_objects()\nobject_cnts = len(response.objects)\nIt shows 20 when I load first file; 15 when I upload 2nd file. After both files are done, cnts is always 20 even after I tried to upload a 3rd file.\nWeaviate version is 3.4\nI can hardly find any documentation on how to trouble shoot issue like this.\nI did dump all objects to local file; and found some chunks from 1st file are missing file_counts = Counter()\nall_files= get_all_filenames(pdf_file_path)\nfor filename in all_files:\ncount = sum(1 for o in response.objects if o.properties.get(“source”) == filename)\nfile_counts[filename] = count\nlogging.info(f\" === utils.py counts per file \\n {json.dumps(file_counts, indent=2)}\")\n\n# Define the path to save the JSON file\noutput_file_path = \"temp.txt\"  # Update with your desired path\n\nwith open(output_file_path, \"w\") as f:\n    for i, o in enumerate(response.objects, start=1):\n        f.write(f\"Object {i} properties:\\n\")\n        # Access only the properties dictionary of each object\n        for key, value in o.properties.items():\n            f.write(f\"  {key}: {value}\\n\")\n        f.write(\"\\n\")  # Separate objects by a newline\n\n\nreturn object_cnts\n\n----------\n\n[DudaNogueira (2024-11-13T15:06:00.861Z)]: Ok, can you share some code I can reproduce this?\nIf possible, separated from the project.\nWeaviate current version is 1.27.2, if you are running with Embedded, you can specify a version there.\nLet me know if this helps!\n\n----------\n\n[cw257900 (2024-11-13T17:17:00.000Z)]: I shared entire project. Code in calling create are the same for embedded and use_local_connection.\nimport os\nimport sys\nimport weaviate\nfrom weaviate import WeaviateClient\nfrom weaviate.classes.init import Auth\nfrom weaviate.connect import ConnectionParams\nimport weaviate\nfrom weaviate.embedded import EmbeddedOptions\nAdd the parent directory (or wherever “with_pinecone” is located) to the Python path\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(file), ‘…’)))\nfrom configs import configs\nimport logging\nConfigure logging for development\nlogging.basicConfig(\nformat=‘%(asctime)s - %(levelname)s - %(message)s’,\nlevel=logging.INFO, # Changed from WARNING to INFO\nhandlers=[\nlogging.StreamHandler() # This ensures output to console\n]\n)\nos.environ[‘OPENAI_API_KEY’]=configs.OPENAI_API_KEY\nFunction to create and return a Weaviate client object\ndef create_client():\nheaders = {“X-OpenAI-Api-Key”: configs.OPENAI_API_KEY}\nInitialize connection params\n“”\"\nconnection_params = ConnectionParams(\nhttp={“host”: WEAVIATE_HOST, “port”: WEAVIATE_HTTP_PORT, “secure”: False, “additional_headers”: headers},\ngrpc={“host”: WEAVIATE_HOST, “port”: WEAVIATE_GRPC_PORT, “secure”: False}\n)\n“”\"\n#client = weaviate.connect_to_local( headers = {“X-OpenAI-Api-Key”: configs.OPENAI_API_KEY})\n“”\"\nclient = weaviate.use_async_with_embedded (\nversion=“1.26.1”,\nheaders={“X-OpenAI-Api-Key”: OPENAI_API_KEY},\nport=8079,\ngrpc_port=50051,\n)\n“”\"\nclient = weaviate.connect_to_embedded(\nversion=“latest”,\npersistence_data_path=configs.WEAVIATE_PERSISTENCE_PATH,\nheaders= headers,\nenvironment_variables={\n“ENABLE_MODULES”: “text2vec-openai,text2vec-cohere,text2vec-huggingface,ref2vec-centroid,generative-openai,qna-openai”,\n}\n)\nlogging.info (\" === vectore_stores.py - embeded client initated {}\".format(client))\nreturn client\ndef close_client(client):\nif client:\nclient.close()\nprint(“Weaviate client closed.”)\nif name == “main”:\nclient = create_client()\nprint (client)\nif not client.collections.exists(“Test”):\ncollection = client.collections.create(“Test”)\nelse:\ncollection = client.collections.get(“Test”)\ncollection.data.insert({“text”: \"this is a test \" })\nprint (collection)\nclient.close()\n\n----------\n\n[DudaNogueira (2024-11-13T17:36:35.781Z)]: The code is not formatted. I was not able to run it.\nCan you for example create a google collab?\nOne thing I noticed, is that you seem to be instantiating two embedded, use_async_with_embedded and connect_to_embedded, also, try using the latest version (not the latest word, but for now 1.27.3)\n\n----------\n\n[cw257900 (2024-11-13T17:48:52.000Z)]: The code for aysnc is commented out. I’ll try to create a google collab . thanks\n\n----------\n\n[cw257900 (2024-11-13T17:49:43.000Z)]: will try 1.27.3 as well. thanks\n\n----------\n\n[cw257900 (2024-11-13T22:35:27.849Z)]: Here is the log; shows first file has 18 chucks loaded; 2nd has 10. When final counts the object, it shows 20 2024-11-13 16:32:09,935 - INFO -\n=== file_path: /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf\nchunking_recursiveCharacterTextSplitter.py: file is being chunked:  /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“warning”,“msg”:“prop len tracker file weaviate_data/pdf_collection/Ib2JkZKYAJpm/proplengths does not exist, creating new tracker”,“time”:“2024-11-13T16:32:10-06:00”}\n{“action”:“hnsw_prefill_cache_async”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“not waiting for vector cache prefill, running in background”,“time”:“2024-11-13T16:32:10-06:00”,“wait_for_cache_prefill”:false}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Created shard pdf_collection_Ib2JkZKYAJpm in 3.017834ms”,“time”:“2024-11-13T16:32:10-06:00”}\n2024-11-13 16:32:10,833 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 0 - Chunk 0\n2024-11-13 16:32:11,310 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 1 - Chunk 1\n2024-11-13 16:32:11,640 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 2 - Chunk 2\n2024-11-13 16:32:12,396 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 3 - Chunk 3\n2024-11-13 16:32:12,842 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 4 - Chunk 4\n2024-11-13 16:32:13,188 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 5 - Chunk 5\n2024-11-13 16:32:13,701 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 6 - Chunk 6\n2024-11-13 16:32:14,206 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 7 - Chunk 7\n2024-11-13 16:32:14,969 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 8 - Chunk 8\n{“action”:“hnsw_compressed_vector_cache_prefill_progress”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“elapsed_total”:5000034500,“level”:“info”,“loaded”:0,“msg”:“loaded 0 vectors in 5s, current rate is 0 vectors/s, total rate is 0 vectors/s”,“rate_per_second”:0,“time”:“2024-11-13T16:32:15-06:00”,“total_rate_per_second”:0}\n2024-11-13 16:32:15,531 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 9 - Chunk 9\n2024-11-13 16:32:15,951 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 10 - Chunk 10\n2024-11-13 16:32:16,424 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 11 - Chunk 11\n2024-11-13 16:32:16,754 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 12 - Chunk 12\n2024-11-13 16:32:16,976 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 13 - Chunk 13\n2024-11-13 16:32:17,388 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 14 - Chunk 14\n2024-11-13 16:32:17,832 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 15 - Chunk 15\n2024-11-13 16:32:18,164 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 16 - Chunk 16\n2024-11-13 16:32:19,974 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 17 - Chunk 17\n{“action”:“hnsw_compressed_vector_cache_prefill_progress”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“elapsed_total”:10000003084,“level”:“info”,“loaded”:0,“msg”:“loaded 0 vectors in 10s, current rate is 0 vectors/s, total rate is 0 vectors/s”,“rate_per_second”:0,“time”:“2024-11-13T16:32:20-06:00”,“total_rate_per_second”:0}\n2024-11-13 16:32:20,372 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 18 - Chunk 18\n2024-11-13 16:32:20 - All chunks inserted for /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf\n2024-11-13 16:32:20,373 - INFO -\nDocument /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf Processing Status:\n{\n“status”: true,\n“message”: ,\n“error”: \n}\n2024-11-13 16:32:20,373 - INFO -\n=== file_path: /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf\nchunking_recursiveCharacterTextSplitter.py: file is being chunked:  /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf\n2024-11-13 16:32:20,745 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 0 - Chunk 0\n2024-11-13 16:32:21,027 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 1 - Chunk 1\n2024-11-13 16:32:21,489 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 2 - Chunk 2\n2024-11-13 16:32:22,146 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 3 - Chunk 3\n2024-11-13 16:32:22,590 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 4 - Chunk 4\n2024-11-13 16:32:22,965 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 5 - Chunk 5\n2024-11-13 16:32:23,338 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 6 - Chunk 6\n2024-11-13 16:32:23,568 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 7 - Chunk 7\n2024-11-13 16:32:23,940 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 8 - Chunk 8\n2024-11-13 16:32:24,390 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 9 - Chunk 9\n2024-11-13 16:32:24,672 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 10 - Chunk 10\n2024-11-13 16:32:24,971 - INFO - HTTP Request: POST http://localhost:8079/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 11 - Chunk 11\n2024-11-13 16:32:24 - All chunks inserted for /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf\n2024-11-13 16:32:24,972 - INFO -\nDocument /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf Processing Status:\n{\n“status”: true,\n“message”: ,\n“error”: \n}\n2024-11-13 16:32:24,972 - INFO -  === utils.py url:  http://localhost:8079/v1/objects/\n2024-11-13 16:32:24,978 - INFO -  === utils.py\n{‘classes’: [{‘class’: ‘PDF_COLLECTION’, ‘invertedIndexConfig’: {‘bm25’: {‘b’: 0.75, ‘k1’: 1.2}, ‘cleanupIntervalSeconds’: 60, ‘indexNullState’: True, ‘indexPropertyLength’: True, ‘indexTimestamps’: True, ‘stopwords’: {‘additions’: None, ‘preset’: ‘en’, ‘removals’: None}}, ‘moduleConfig’: {‘generative-cohere’: {}, ‘text2vec-openai’: {‘baseURL’: ‘https://api.openai.com’, ‘model’: ‘text-embedding-3-small’, ‘vectorizeClassName’: True}}, ‘multiTenancyConfig’: {‘autoTenantActivation’: False, ‘autoTenantCreation’: False, ‘enabled’: False}, ‘properties’: [{‘dataType’: [‘text’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: True, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘page_content’, ‘tokenization’: ‘word’}, {‘dataType’: [‘int’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: False, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘page_number’}, {‘dataType’: [‘text’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: True, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘source’, ‘tokenization’: ‘word’}], ‘replicationConfig’: {‘asyncEnabled’: False, ‘deletionStrategy’: ‘DeleteOnConflict’, ‘factor’: 1}, ‘shardingConfig’: {‘actualCount’: 1, ‘actualVirtualCount’: 128, ‘desiredCount’: 1, ‘desiredVirtualCount’: 128, ‘function’: ‘murmur3’, ‘key’: ‘_id’, ‘strategy’: ‘hash’, ‘virtualPerPhysical’: 128}, ‘vectorIndexConfig’: {‘bq’: {‘enabled’: True}, ‘cleanupIntervalSeconds’: 300, ‘distance’: ‘cosine’, ‘dynamicEfFactor’: 8, ‘dynamicEfMax’: 500, ‘dynamicEfMin’: 100, ‘ef’: -1, ‘efConstruction’: 128, ‘filterStrategy’: ‘sweeping’, ‘flatSearchCutoff’: 40000, ‘maxConnections’: 32, ‘pq’: {‘bitCompression’: False, ‘centroids’: 256, ‘enabled’: False, ‘encoder’: {‘distribution’: ‘log-normal’, ‘type’: ‘kmeans’}, ‘segments’: 0, ‘trainingLimit’: 100000}, ‘skip’: False, ‘sq’: {‘enabled’: False, ‘rescoreLimit’: 20, ‘trainingLimit’: 100000}, ‘vectorCacheMaxObjects’: 1000000000000}, ‘vectorIndexType’: ‘hnsw’, ‘vectorizer’: ‘text2vec-openai’}]}\n2024-11-13 16:32:24,984 - INFO -\n=== utils.py total objects 20 in PDF_COLLECTION\n2024-11-13 16:32:24,984 - INFO -  === utils.py counts per file\n{\n“/Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf”: 11,\n“/Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf”: 9\n}\n{‘status’: True, ‘message’: [‘20 already in http://localhost:8079/v1/objects/’], ‘error’: }\n2024-11-13 16:32:24,985 - INFO -  === *created.py - url:  http://localhost:8079/v1/objects/\n2024-11-13 16:32:24,985 - INFO -  === *created.py - object_count: 20\n2024-11-13 16:32:24,985 - INFO -\nDocument Processing Status: for /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data\n{\n“status”: true,\n“message”: [\n“20 already in http://localhost:8079/v1/objects/”\n],\n“error”: \n}\n{“action”:“restapi_management”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Shutting down… “,“time”:“2024-11-13T16:32:24-06:00”,“version”:“1.27.3”}\n{“action”:“restapi_management”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Stopped serving weaviate at http://127.0.0.1:8079”,“time”:“2024-11-13T16:32:24-06:00”,“version”:“1.27.3”}\n{“action”:“hnsw_compressed_vector_cache_prefill_progress”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“elapsed_total”:15000027792,“level”:“info”,“loaded”:0,“msg”:“loaded 0 vectors in 15s, current rate is 0 vectors/s, total rate is 0 vectors/s”,“rate_per_second”:0,“time”:“2024-11-13T16:32:25-06:00”,“total_rate_per_second”:0}\n{“action”:“telemetry_push”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“telemetry terminated”,“payload”:”\\u0026{MachineID:857f2ecf-d343-4a0c-8023-8363be41eafc Type:TERMINATE Version:1.27.3 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[generative-cohere text2vec-openai]}”,“time”:“2024-11-13T16:32:25-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“closing raft FSM store …”,“time”:“2024-11-13T16:32:25-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“shutting down raft sub-system …”,“time”:“2024-11-13T16:32:25-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“transferring leadership to another server”,“time”:“2024-11-13T16:32:25-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“error”:“cannot find peer”,“level”:“error”,“msg”:“transferring leadership”,“time”:“2024-11-13T16:32:25-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“closing raft-net …”,“time”:“2024-11-13T16:32:25-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“closing log store …”,“time”:“2024-11-13T16:32:25-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“closing data store …”,“time”:“2024-11-13T16:32:25-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“closing loaded database …”,“time”:“2024-11-13T16:32:25-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“closing raft-rpc client …”,“time”:“2024-11-13T16:32:25-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“closing raft-rpc server …”,“time”:“2024-11-13T16:32:25-06:00”}\n(.venv) connie.wang@Connies-MacBook-Pro-M3 fastapi_onazure % python app/rag/with_weaviate/utils/utils.py\n2024-11-13 16:32:40,122 - INFO -  === configs.py - blob_name for azure: rag/data/constitution.pdf\n2024-11-13 16:32:40,122 - INFO -  === configs.py - pdf_file_path : /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data\n2024-11-13 16:32:40,127 - INFO - Started /Users/connie.wang/.cache/weaviate-embedded: process ID 17425\n{“action”:“startup”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“default_vectorizer_module”:“none”,“level”:“info”,“msg”:“the default vectorizer modules is set to \"none\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer”,“time”:“2024-11-13T16:32:40-06:00”}\n{“action”:“startup”,“auto_schema_enabled”:true,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“auto schema enabled setting is set to \"true\"”,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true”,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“module offload-s3 is enabled”,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“warning”,“msg”:“Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.”,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“open cluster service”,“servers”:{“Embedded_at_8079”:51416},“time”:“2024-11-13T16:32:40-06:00”}\n{“address”:“192.168.1.44:51417”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“starting cloud rpc server …”,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“starting raft sub-system …”,“time”:“2024-11-13T16:32:40-06:00”}\n{“address”:“192.168.1.44:51416”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“tcp transport”,“tcpMaxPool”:3,“tcpTimeout”:10000000000,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“loading local db”,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“local DB successfully loaded”,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“schema manager loaded”,“n”:0,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“metadata_only_voters”:false,“msg”:“construct a new raft node”,“name”:“Embedded_at_8079”,“time”:“2024-11-13T16:32:40-06:00”}\n{“action”:“raft”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“index”:61,“level”:“info”,“msg”:“initial configuration”,“servers”:“[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.1.44:51277}]]”,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“last_snapshot_index”:0,“last_store_applied_index_on_start”:62,“level”:“info”,“msg”:“raft node constructed”,“raft_applied_index”:0,“raft_last_index”:62,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“hasState”:true,“level”:“info”,“msg”:“raft init”,“time”:“2024-11-13T16:32:40-06:00”}\n{“action”:“raft”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“follower”:{},“index”:61,“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“entering follower state”,“servers”:“[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.1.44:51277}]]”,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“192.168.1.44:51416”],“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“192.168.1.44:51416”,“status”:8,“time”:“2024-11-13T16:32:40-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“192.168.1.44:51416”],“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“192.168.1.44:51416”,“status”:8,“time”:“2024-11-13T16:32:41-06:00”}\n{“action”:“raft”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“follower”:{},“index”:61,“last-leader-addr”:“”,“last-leader-id”:“”,“leader-address”:“”,“leader-id”:“”,“level”:“warning”,“msg”:“heartbeat timeout reached, starting election”,“servers”:“[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.1.44:51277}]]”,“time”:“2024-11-13T16:32:41-06:00”}\n{“action”:“raft”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“follower”:{},“index”:61,“last-leader-addr”:“”,“last-leader-id”:“”,“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“entering candidate state”,“node”:{},“servers”:“[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.1.44:51277}]]”,“term”:29,“time”:“2024-11-13T16:32:41-06:00”}\n{“action”:“raft”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“follower”:{},“from”:“Embedded_at_8079”,“id”:“Embedded_at_8079”,“index”:61,“last-leader-addr”:“”,“last-leader-id”:“”,“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“pre-vote successful, starting election”,“needed”:1,“node”:{},“refused”:0,“servers”:“[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.1.44:51277}]]”,“tally”:1,“term”:29,“time”:“2024-11-13T16:32:41-06:00”,“votesNeeded”:1}\n{“action”:“raft”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“follower”:{},“from”:“Embedded_at_8079”,“id”:“Embedded_at_8079”,“index”:61,“last-leader-addr”:“”,“last-leader-id”:“”,“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“election won”,“needed”:1,“node”:{},“refused”:0,“servers”:“[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.1.44:51277}]]”,“tally”:1,“term”:29,“time”:“2024-11-13T16:32:41-06:00”,“votesNeeded”:1}\n{“action”:“raft”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“follower”:{},“from”:“Embedded_at_8079”,“id”:“Embedded_at_8079”,“index”:61,“last-leader-addr”:“”,“last-leader-id”:“”,“leader”:{},“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“entering leader state”,“needed”:1,“node”:{},“refused”:0,“servers”:“[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.1.44:51277}]]”,“tally”:1,“term”:29,“time”:“2024-11-13T16:32:41-06:00”,“votesNeeded”:1}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Schema catching up: applying log entry: [7/62]”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Schema catching up: applying log entry: [8/62]”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Schema catching up: applying log entry: [19/62]”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Schema catching up: applying log entry: [22/62]”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Schema catching up: applying log entry: [23/62]”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Schema catching up: applying log entry: [24/62]”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Schema catching up: applying log entry: [57/62]”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Schema catching up: applying log entry: [62/62]”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“last_store_log_applied_index”:62,“level”:“info”,“log_index”:62,“log_name”:“LogCommand”,“log_type”:0,“msg”:“reloading local DB as RAFT and local DB are now caught up”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“reload local db: update schema …”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“index”:“PDF_COLLECTION”,“level”:“info”,“msg”:“reload local index”,“time”:“2024-11-13T16:32:41-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“configured versions”,“server_version”:“1.27.3”,“time”:“2024-11-13T16:32:42-06:00”,“version”:“1.27.3”}\n{“action”:“grpc_startup”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“grpc server listening at [::]:50050”,“time”:“2024-11-13T16:32:42-06:00”}\n{“address”:“192.168.1.44:51416”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“current Leader”,“time”:“2024-11-13T16:32:42-06:00”}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“192.168.1.44:51416”],“time”:“2024-11-13T16:32:42-06:00”}\n{“action”:“raft”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“command”:0,“follower”:{},“from”:“Embedded_at_8079”,“id”:“Embedded_at_8079”,“index”:61,“last-leader-addr”:“”,“last-leader-id”:“”,“leader”:{},“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“updating configuration”,“needed”:1,“node”:{},“refused”:0,“server-addr”:“192.168.1.44:51416”,“server-id”:“Embedded_at_8079”,“servers”:“[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.1.44:51416}]]”,“tally”:1,“term”:29,“time”:“2024-11-13T16:32:42-06:00”,“votesNeeded”:1}\n{“action”:“restapi_management”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Serving weaviate at http://127.0.0.1:8079”,“time”:“2024-11-13T16:32:42-06:00”,“version”:“1.27.3”}\n2024-11-13 16:32:42,325 - INFO - HTTP Request: GET http://localhost:8079/v1/.well-known/openid-configuration “HTTP/1.1 404 Not Found”\n2024-11-13 16:32:42,336 - INFO - HTTP Request: GET http://localhost:8079/v1/meta “HTTP/1.1 200 OK”\n2024-11-13 16:32:42,337 - INFO - HTTP Request: GET http://localhost:8079/v1/.well-known/ready “HTTP/1.1 200 OK”\n2024-11-13 16:32:42,440 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json “HTTP/1.1 200 OK”\n2024-11-13 16:32:42,468 - INFO -  === vectore_stores.py - embeded client initated <weaviate.client.WeaviateClient object at 0x1040461e0>\n2024-11-13 16:32:42,468 - INFO -  === utils.py url:  http://localhost:8079/v1/objects/\n2024-11-13 16:32:42,472 - INFO -  === utils.py\n{‘classes’: [{‘class’: ‘PDF_COLLECTION’, ‘invertedIndexConfig’: {‘bm25’: {‘b’: 0.75, ‘k1’: 1.2}, ‘cleanupIntervalSeconds’: 60, ‘indexNullState’: True, ‘indexPropertyLength’: True, ‘indexTimestamps’: True, ‘stopwords’: {‘additions’: None, ‘preset’: ‘en’, ‘removals’: None}}, ‘moduleConfig’: {‘generative-cohere’: {}, ‘text2vec-openai’: {‘baseURL’: ‘https://api.openai.com’, ‘model’: ‘text-embedding-3-small’, ‘vectorizeClassName’: True}}, ‘multiTenancyConfig’: {‘autoTenantActivation’: False, ‘autoTenantCreation’: False, ‘enabled’: False}, ‘properties’: [{‘dataType’: [‘text’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: True, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘page_content’, ‘tokenization’: ‘word’}, {‘dataType’: [‘int’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: False, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘page_number’}, {‘dataType’: [‘text’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: True, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘source’, ‘tokenization’: ‘word’}], ‘replicationConfig’: {‘asyncEnabled’: False, ‘deletionStrategy’: ‘DeleteOnConflict’, ‘factor’: 1}, ‘shardingConfig’: {‘actualCount’: 1, ‘actualVirtualCount’: 128, ‘desiredCount’: 1, ‘desiredVirtualCount’: 128, ‘function’: ‘murmur3’, ‘key’: ‘_id’, ‘strategy’: ‘hash’, ‘virtualPerPhysical’: 128}, ‘vectorIndexConfig’: {‘bq’: {‘enabled’: True}, ‘cleanupIntervalSeconds’: 300, ‘distance’: ‘cosine’, ‘dynamicEfFactor’: 8, ‘dynamicEfMax’: 500, ‘dynamicEfMin’: 100, ‘ef’: -1, ‘efConstruction’: 128, ‘filterStrategy’: ‘sweeping’, ‘flatSearchCutoff’: 40000, ‘maxConnections’: 32, ‘pq’: {‘bitCompression’: False, ‘centroids’: 256, ‘enabled’: False, ‘encoder’: {‘distribution’: ‘log-normal’, ‘type’: ‘kmeans’}, ‘segments’: 0, ‘trainingLimit’: 100000}, ‘skip’: False, ‘sq’: {‘enabled’: False, ‘rescoreLimit’: 20, ‘trainingLimit’: 100000}, ‘vectorCacheMaxObjects’: 1000000000000}, ‘vectorIndexType’: ‘hnsw’, ‘vectorizer’: ‘text2vec-openai’}]}\n{“action”:“hnsw_prefill_cache_async”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“not waiting for vector cache prefill, running in background”,“time”:“2024-11-13T16:32:42-06:00”,“wait_for_cache_prefill”:false}\n{“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“level”:“info”,“msg”:“Completed loading shard pdf_collection_Ib2JkZKYAJpm in 5.526791ms”,“time”:“2024-11-13T16:32:42-06:00”}\n{“action”:“hnsw_compressed_vector_cache_prefill”,“build_git_commit”:“4258bdfc2”,“build_go_version”:“go1.23.3”,“build_image_tag”:“HEAD”,“build_wv_version”:“1.27.3”,“count”:31,“level”:“info”,“maxID”:30,“msg”:“prefilled compressed vector cache”,“time”:“2024-11-13T16:32:42-06:00”,“took”:344667}\n2024-11-13 16:32:42,480 - INFO -\n=== utils.py total objects 20 in PDF_COLLECTION\n2024-11-13 16:32:42,481 - INFO -  === utils.py counts per file\n{\n“/Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf”: 11,\n“/Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf”: 9\n}\n\n----------\n\n[cw257900 (2024-11-13T22:45:02.300Z)]: here is same code, by switching to local connection; the counts of object is 25 iner fastapi_onazure-t2v-transformers-1  Started                                                                                                               0.2s\n Container fastapi_onazure-contextionary-1     Started                                                                                                               0.2s\n Container fastapi_onazure-weaviate-1          Started                                                                                                               0.3s\n(.venv) connie.wang@Connies-MacBook-Pro-M3 fastapi_onazure % python app/rag/with_weaviate/*create.py\n2024-11-13 16:43:35,687 - INFO -  === configs.py - blob_name for azure: rag/data/constitution.pdf\n2024-11-13 16:43:35,688 - INFO -  === configs.py - pdf_file_path : /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data\n2024-11-13 16:43:36,087 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings “HTTP/1.1 200 OK”\n== 0.1. embeddings initiated from embedding_openai.py: text-embedding-ada-002  and dimension: 1536\n2024-11-13 16:43:36,125 - INFO - HTTP Request: GET http://localhost:8080/v1/.well-known/openid-configuration “HTTP/1.1 404 Not Found”\n2024-11-13 16:43:36,148 - INFO - HTTP Request: GET http://localhost:8080/v1/meta “HTTP/1.1 200 OK”\n2024-11-13 16:43:36,243 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json “HTTP/1.1 200 OK”\n2024-11-13 16:43:36,273 - INFO -  === vectore_stores.py - embeded client initated <weaviate.client.WeaviateClient object at 0x30057cb90>\n2024-11-13 16:43:36,276 - INFO - HTTP Request: GET http://localhost:8080/v1/schema/PDF_COLLECTION “HTTP/1.1 404 Not Found”\n2024-11-13 16:43:36,279 - INFO - HTTP Request: GET http://localhost:8080/v1/schema/PDF_COLLECTION “HTTP/1.1 404 Not Found”\n2024-11-13 16:43:36,452 - INFO - HTTP Request: POST http://localhost:8080/v1/schema “HTTP/1.1 200 OK”\n2024-11-13 16:43:36,456 - INFO -\n=== file_path: /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/.DS_Store\n2024-11-13 16:43:36,456 - INFO -\nDocument /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/.DS_Store Processing Status:\n{\n“status”: true,\n“message”: ,\n“error”: \n}\n2024-11-13 16:43:36,456 - INFO -\n=== file_path: /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf\nchunking_recursiveCharacterTextSplitter.py: file is being chunked:  /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf\n2024-11-13 16:43:37,267 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 0 - Chunk 0\n2024-11-13 16:43:37,523 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 1 - Chunk 1\n2024-11-13 16:43:37,909 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 2 - Chunk 2\n2024-11-13 16:43:38,386 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 3 - Chunk 3\n2024-11-13 16:43:38,785 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 4 - Chunk 4\n2024-11-13 16:43:39,070 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 5 - Chunk 5\n2024-11-13 16:43:39,445 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 6 - Chunk 6\n2024-11-13 16:43:40,080 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 7 - Chunk 7\n2024-11-13 16:43:40,446 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 8 - Chunk 8\n2024-11-13 16:43:40,799 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 9 - Chunk 9\n2024-11-13 16:43:41,220 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 10 - Chunk 10\n2024-11-13 16:43:41,776 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 11 - Chunk 11\n2024-11-13 16:43:42,107 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 12 - Chunk 12\n2024-11-13 16:43:42,344 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 13 - Chunk 13\n2024-11-13 16:43:42,607 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 14 - Chunk 14\n2024-11-13 16:43:43,177 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 15 - Chunk 15\n2024-11-13 16:43:43,409 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 16 - Chunk 16\n2024-11-13 16:43:43,935 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 17 - Chunk 17\n2024-11-13 16:43:44,466 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 18 - Chunk 18\n2024-11-13 16:43:44 - All chunks inserted for /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf\n2024-11-13 16:43:44,468 - INFO -\nDocument /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf Processing Status:\n{\n“status”: true,\n“message”: ,\n“error”: \n}\n2024-11-13 16:43:44,468 - INFO -\n=== file_path: /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf\nchunking_recursiveCharacterTextSplitter.py: file is being chunked:  /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf\n2024-11-13 16:43:44,761 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 0 - Chunk 0\n2024-11-13 16:43:45,217 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 1 - Chunk 1\n2024-11-13 16:43:45,741 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 2 - Chunk 2\n2024-11-13 16:43:46,267 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 3 - Chunk 3\n2024-11-13 16:43:46,606 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 4 - Chunk 4\n2024-11-13 16:43:47,222 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 5 - Chunk 5\n2024-11-13 16:43:47,746 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 6 - Chunk 6\n2024-11-13 16:43:48,216 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 7 - Chunk 7\n2024-11-13 16:43:48,458 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 8 - Chunk 8\n2024-11-13 16:43:48,934 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 9 - Chunk 9\n2024-11-13 16:43:49,185 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 10 - Chunk 10\n2024-11-13 16:43:49,495 - INFO - HTTP Request: POST http://localhost:8080/v1/objects “HTTP/1.1 200 OK”\nInserted: Page 11 - Chunk 11\n2024-11-13 16:43:49 - All chunks inserted for /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf\n2024-11-13 16:43:49,497 - INFO -\nDocument /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf Processing Status:\n{\n“status”: true,\n“message”: ,\n“error”: \n}\n2024-11-13 16:43:49,498 - INFO -  === utils.py url:  http://localhost:8080/v1/objects/\n2024-11-13 16:43:49,509 - INFO -  === utils.py\n{‘classes’: [{‘class’: ‘PDF_COLLECTION’, ‘invertedIndexConfig’: {‘bm25’: {‘b’: 0.75, ‘k1’: 1.2}, ‘cleanupIntervalSeconds’: 60, ‘indexNullState’: True, ‘indexPropertyLength’: True, ‘indexTimestamps’: True, ‘stopwords’: {‘additions’: None, ‘preset’: ‘en’, ‘removals’: None}}, ‘moduleConfig’: {‘generative-cohere’: {}, ‘text2vec-openai’: {‘baseURL’: ‘https://api.openai.com’, ‘model’: ‘ada’, ‘vectorizeClassName’: True}}, ‘multiTenancyConfig’: {‘autoTenantActivation’: False, ‘autoTenantCreation’: False, ‘enabled’: False}, ‘properties’: [{‘dataType’: [‘text’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: True, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘page_content’, ‘tokenization’: ‘word’}, {‘dataType’: [‘int’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: False, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘page_number’}, {‘dataType’: [‘text’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: True, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘source’, ‘tokenization’: ‘word’}], ‘replicationConfig’: {‘asyncEnabled’: False, ‘deletionStrategy’: ‘DeleteOnConflict’, ‘factor’: 1}, ‘shardingConfig’: {‘actualCount’: 1, ‘actualVirtualCount’: 128, ‘desiredCount’: 1, ‘desiredVirtualCount’: 128, ‘function’: ‘murmur3’, ‘key’: ‘_id’, ‘strategy’: ‘hash’, ‘virtualPerPhysical’: 128}, ‘vectorIndexConfig’: {‘bq’: {‘enabled’: True}, ‘cleanupIntervalSeconds’: 300, ‘distance’: ‘cosine’, ‘dynamicEfFactor’: 8, ‘dynamicEfMax’: 500, ‘dynamicEfMin’: 100, ‘ef’: -1, ‘efConstruction’: 128, ‘filterStrategy’: ‘sweeping’, ‘flatSearchCutoff’: 40000, ‘maxConnections’: 32, ‘pq’: {‘bitCompression’: False, ‘centroids’: 256, ‘enabled’: False, ‘encoder’: {‘distribution’: ‘log-normal’, ‘type’: ‘kmeans’}, ‘segments’: 0, ‘trainingLimit’: 100000}, ‘skip’: False, ‘sq’: {‘enabled’: False, ‘rescoreLimit’: 20, ‘trainingLimit’: 100000}, ‘vectorCacheMaxObjects’: 1000000000000}, ‘vectorIndexType’: ‘hnsw’, ‘vectorizer’: ‘text2vec-openai’}]}\n2024-11-13 16:43:49,520 - INFO -\n=== utils.py total objects 25 in PDF_COLLECTION\n2024-11-13 16:43:49,520 - INFO -  === utils.py counts per file\n{\n“/Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf”: 14,\n“/Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf”: 11\n}\n{‘status’: True, ‘message’: [‘25 already in http://localhost:8080/v1/objects/’], ‘error’: }\n2024-11-13 16:43:49,521 - INFO -  === *created.py - url:  http://localhost:8080/v1/objects/\n2024-11-13 16:43:49,521 - INFO -  === *created.py - object_count: 25\n2024-11-13 16:43:49,521 - INFO -\nDocument Processing Status: for /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data\n{\n“status”: true,\n“message”: [\n“25 already in http://localhost:8080/v1/objects/”\n],\n“error”: \n}\n(.venv) connie.wang@Connies-MacBook-Pro-M3 fastapi_onazure % python app/rag/with_weaviate/utils/utils.py\n2024-11-13 16:44:09,454 - INFO -  === configs.py - blob_name for azure: rag/data/constitution.pdf\n2024-11-13 16:44:09,454 - INFO -  === configs.py - pdf_file_path : /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data\n2024-11-13 16:44:09,465 - INFO - HTTP Request: GET http://localhost:8080/v1/.well-known/openid-configuration “HTTP/1.1 404 Not Found”\n2024-11-13 16:44:09,479 - INFO - HTTP Request: GET http://localhost:8080/v1/meta “HTTP/1.1 200 OK”\n2024-11-13 16:44:09,571 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json “HTTP/1.1 200 OK”\n2024-11-13 16:44:09,597 - INFO -  === vectore_stores.py - embeded client initated <weaviate.client.WeaviateClient object at 0x107d5a0c0>\n2024-11-13 16:44:09,597 - INFO -  === utils.py url:  http://localhost:8080/v1/objects/\n2024-11-13 16:44:09,603 - INFO -  === utils.py\n{‘classes’: [{‘class’: ‘PDF_COLLECTION’, ‘invertedIndexConfig’: {‘bm25’: {‘b’: 0.75, ‘k1’: 1.2}, ‘cleanupIntervalSeconds’: 60, ‘indexNullState’: True, ‘indexPropertyLength’: True, ‘indexTimestamps’: True, ‘stopwords’: {‘additions’: None, ‘preset’: ‘en’, ‘removals’: None}}, ‘moduleConfig’: {‘generative-cohere’: {}, ‘text2vec-openai’: {‘baseURL’: ‘https://api.openai.com’, ‘model’: ‘ada’, ‘vectorizeClassName’: True}}, ‘multiTenancyConfig’: {‘autoTenantActivation’: False, ‘autoTenantCreation’: False, ‘enabled’: False}, ‘properties’: [{‘dataType’: [‘text’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: True, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘page_content’, ‘tokenization’: ‘word’}, {‘dataType’: [‘int’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: False, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘page_number’}, {‘dataType’: [‘text’], ‘indexFilterable’: True, ‘indexRangeFilters’: False, ‘indexSearchable’: True, ‘moduleConfig’: {‘text2vec-openai’: {‘skip’: False, ‘vectorizePropertyName’: True}}, ‘name’: ‘source’, ‘tokenization’: ‘word’}], ‘replicationConfig’: {‘asyncEnabled’: False, ‘deletionStrategy’: ‘DeleteOnConflict’, ‘factor’: 1}, ‘shardingConfig’: {‘actualCount’: 1, ‘actualVirtualCount’: 128, ‘desiredCount’: 1, ‘desiredVirtualCount’: 128, ‘function’: ‘murmur3’, ‘key’: ‘_id’, ‘strategy’: ‘hash’, ‘virtualPerPhysical’: 128}, ‘vectorIndexConfig’: {‘bq’: {‘enabled’: True}, ‘cleanupIntervalSeconds’: 300, ‘distance’: ‘cosine’, ‘dynamicEfFactor’: 8, ‘dynamicEfMax’: 500, ‘dynamicEfMin’: 100, ‘ef’: -1, ‘efConstruction’: 128, ‘filterStrategy’: ‘sweeping’, ‘flatSearchCutoff’: 40000, ‘maxConnections’: 32, ‘pq’: {‘bitCompression’: False, ‘centroids’: 256, ‘enabled’: False, ‘encoder’: {‘distribution’: ‘log-normal’, ‘type’: ‘kmeans’}, ‘segments’: 0, ‘trainingLimit’: 100000}, ‘skip’: False, ‘sq’: {‘enabled’: False, ‘rescoreLimit’: 20, ‘trainingLimit’: 100000}, ‘vectorCacheMaxObjects’: 1000000000000}, ‘vectorIndexType’: ‘hnsw’, ‘vectorizer’: ‘text2vec-openai’}]}\n2024-11-13 16:44:09,609 - INFO -\n=== utils.py total objects 25 in PDF_COLLECTION\n2024-11-13 16:44:09,609 - INFO -  === utils.py counts per file\n{\n“/Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/constitution.pdf”: 14,\n“/Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/rag/with_weaviate/data/what_is_a_constitution.pdf”: 11\n}\n\n----------\n\n[DudaNogueira (2024-11-14T13:06:09.160Z)]: cw257900:\n\n2024-11-13 16:43:36,276 - INFO - HTTP Request: GET http://localhost:8080/v1/schema/PDF_COLLECTION “HTTP/1.1 404 Not Found”\n2024-11-13 16:43:36,279 - INFO - HTTP Request: GET http://localhost:8080/v1/schema/PDF_COLLECTION “HTTP/1.1 404 Not Found”\n\n\nThose are the only thing close to an error I could see.\nBut this is probably the first run, checking if the collection exists.\nHow can I run this myself? Can you share the dataset with step by step?",
    "date_created": "2024-11-10T07:04:50.455Z",
    "has_accepted_answer": false,
    "title": "Embeded weaviate with objects stuck at 20; connect_to_local shows thousands objects",
    "topic_id": 7522
  },
  {
    "user_id": 1278,
    "conversation": "[vk_Cheung (2024-08-07T15:57:35.702Z)]: Description\nWhen I use hybrid query with rerank, and will get a error of context deadline exceeded. But if I use near_text or bm25 query with rerank, it work fine . My code is as follow\ncollection = weaviate_client.collections.get(index_name)\nresponse = collection.query.hybird(\n                query=query,\n                limit=10,\n                filters=Filter.by_property(\"key\").not_equal(to_int(key)),\n                rerank=Rerank(prop=\"text\", query=query),\n                return_metadata=MetadataQuery(score=True, explain_score=True),\n                alpha=0.75,\n                fusion_type=HybridFusion.RELATIVE_SCORE,\n)\n\nAnd the exception info is:\nQuery call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"explorer: get class: extend: extend rerank: error ranking with cohere: send POST request: Post \"http://reranker-transformers:8080/rerank\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-08-07T23:37:00.889730113+08:00\", grpc_status:2, grpc_message:\"explorer: get class: extend: extend rerank: error ranking with cohere: send POST request: Post \\\"http://reranker-transformers:8080/rerank\\\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\"}\"\n>.\n\nIf I set rerank as None, it will work fine. And use rerank with near_text or bm25, will also work file.\nThe reranker is build with reranker-transformers, which version is v1.1.1, and the model is BAAI/bge-reranker-large.\nServer Setup Information\n\nWeaviate Server Version:\n\nversion: \"3.4\"\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:1.25.10\n    ports:\n      - \"8088:8080\"\n      - \"50051:50051\"\n    volumes:\n      - ./data:/var/lib/weaviate\n    restart: on-failure:0\n    networks:\n      - weaviate_default\n    environment:\n      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'\n      RERANKER_INFERENCE_API: 'http://reranker-transformers:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'\n      ENABLE_MODULES: 'text2vec-transformers,reranker-transformers'\n      CLUSTER_HOSTNAME: 'node1'\n  t2v-transformers:\n    image: semitechnologies/transformers-inference:baai-bge-m3-onnx\n    networks:\n      - weaviate_default\n    environment:\n      ENABLE_CUDA: 0 # set to 1 to enable\n  reranker-transformers:\n    build:\n      context: reranker-transformers-1.1.1\n      dockerfile: Dockerfile\n      args:\n        HF_ENDPOINT: \"https://hf-mirror.com\"\n        MODEL_NAME: \"BAAI/bge-reranker-large\"\n    image: weaviate-reranker-transformers:latest\n    networks:\n      - weaviate_default\n    environment:\n      ENABLE_CUDA: '0'\nnetworks:\n  weaviate_default:\n    driver: bridge\n\n\nDeployment Method: docker\nClient Language and Version: Python, with weaviate-client==4.7.1\n\n----------\n\n[DudaNogueira (2024-08-07T19:45:41.110Z)]: hi @vk_Cheung !!\nCan you inspect the object that you get from both queries?\nYou are probably getting bigger objects, that is now taking its toll on the reranker service, leading to a probable timeout.\nIs this query taking a long time? If this is a timeout thing, this is the env. var that will control the module client timeout\nMODULES_CLIENT_TIMEOUT  it’s default is 50s\nYou can try increasing the timeout?\nHowever… whenever you see yourself tweaking Weaviate timeout default values, you should first look at the resources you have available at your Weaviate cluster.\nLet me know if this helps.\nThanks!",
    "date_created": "2024-08-07T15:57:35.653Z",
    "has_accepted_answer": false,
    "title": "Hybrid query with rerank， get context deadline exceeded ERROr",
    "topic_id": 3292
  },
  {
    "user_id": 2872,
    "conversation": "[Davit_Makharashvili (2024-11-28T14:06:41.438Z)]: Hi. i’m trying to save data into collection and then read similar data with near_text function. but after insert data into collection metadata object is null. is it normal?\n def __init__(self):\n        self.client = weaviate.use_async_with_weaviate_cloud(\n            cluster_url=\"---\", \n            auth_credentials=Auth.api_key(\"---\"),  \n            headers={'X-OpenAI-Api-key': \"----\"}  # \n        )\n\n async def create_collection(self, collection_name: str, properties, vectorizer_config=None):\n        async with self.client:\n            try:\n                if vectorizer_config is None:\n                    vectorizer_config = weaviate.classes.config.Configure.Vectorizer.text2vec_openai()\n                \n                if not await self.client.collections.exists(collection_name):\n                    await self.client.collections.create(\n                        name=collection_name,\n                        vectorizer_config=vectorizer_config,\n                        properties=properties\n                    )\n                    print(f\"Collection '{collection_name}' created successfully!\")\n                else:\n                    print(f\"Collection '{collection_name}' already exists.\")\n            except Exception as e:\n                print(f\"Error creating collection: {e}\")\n\nasync def upload_data(self, collection_name: str, data, uuid_property: str):\n        async with self.client:\n            try:\n                collection = self.client.collections.get(collection_name)\n                for item in data:\n                    item_dict = item.model_dump()\n\n                    # Validate that the uuid_property exists\n                    if uuid_property not in item_dict:\n                        raise ValueError(f\"Missing UUID property '{uuid_property}' in data: {item_dict}\")\n\n                    which_uuid = item_dict[uuid_property]\n\n                    # Check if the object already exists\n                    if await collection.data.exists(which_uuid):\n                        print(f\"Updating existing object with UUID: {which_uuid}\")\n                        await collection.data.update(\n                            uuid=which_uuid,\n                            properties=item_dict\n                        )\n                    else:\n                        print(f\"Inserting new object with UUID: {which_uuid}\")\n                        await collection.data.insert(\n                            properties=item_dict,\n                            uuid=which_uuid,\n                        )\n\n            except Exception as e:\n                print(f\"Error uploading data: {e}\")\n\nasync def get_data_by_query(self, collection_name: str, content: str, limit: int = 10):\n        async with self.client:\n            collection = self.client.collections.get(collection_name)\n            result = await collection.query.near_text(\n                query=content,\n                limit=limit,\n                \n            )\n            return result\n\nresult from get_data_by_query\n{\n    \"objects\": [\n        {\n            \"uuid\": \"3b7a8252-e44c-4ab9-b94b-f99b62716a2c\",\n            \"metadata\": {\n                \"creation_time\": null,\n                \"last_update_time\": null,\n                \"distance\": null,\n                \"certainty\": null,\n                \"score\": null,\n                \"explain_score\": null,\n                \"is_consistent\": null,\n                \"rerank_score\": null\n            },\n            \"properties\": {\n                \"session_uuid\": \"3b7a8252-e44c-4ab9-b94b-f99b62716a2c\",\n                \"summary\": \"hello world\",\n                \"brand_id\": 1234\n            },\n            \"references\": null,\n            \"vector\": {},\n            \"collection\": \"SummaryCollection\"\n        }\n    ]\n}\n\n----------\n\n[DudaNogueira (2024-11-28T20:39:38.852Z)]: hi @Davit_Makharashvili !!\nWelcome to our community \nThis is the expected result. As documented here, you need to explicitly request the metadata to be returned.\nSo the query need to be:\ncollection.query.near_text(query=content,\n    limit=limit,\n    return_metadata=wvc.query.MetadataQuery(distance=True)        \n)\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-11-28T14:06:41.384Z",
    "has_accepted_answer": false,
    "title": "Metadata is empty",
    "topic_id": 8825
  },
  {
    "user_id": 848,
    "conversation": "[sanjeev1678 (2024-09-26T13:05:54.829Z)]: Hello Team\nI am getting this error, when I am running weaviate backup(.create) method.\nThe block list may not contain more than 50,000 blocks.\\nERROR CODE: BlockListTooLong\\n--------------------------------------------------------------------------------\\n\\ufeff<?xml version=\"1.0\" encoding=\"utf-8\"?>BlockListTooLongThe block list may not contain more than 50,000 blocks.\nI’ve been experimenting with the chunk_size and compressionLevel parameters in the backup configuration to address this issue.\nPlease find my code.\nresult = client.backup.create(\nbackup_id=\"weaviate-backup_20240902600000_3\",\nbackend='azure',\nwait_for_completion=False,\nconfig=BackupConfigCreate(chunk_size=\"256\"),\ninclude_collections = ['demotesting']\n)\n\nGiven the size of the dataset, I suspect that the error is related to the number of data blocks generated during the backup process. To reduce the total number of blocks, I increase the chunk size, but still giving the same error.\nPlease let me know how I can fix this issue\n\nWeaviate Server Version:\nDeployment Method: Kubernetes\nNumber of Running Nodes: One node\nWeaviate Version: 1.25.0\nbackup-azure\nweaviate python client: 4.6.5\n\n----------\n\n[DudaNogueira (2024-09-30T14:59:22.923Z)]: Hi @sanjeev1678 !!\nI believe this is a bug \nHave you tried a different module, for example, backup-s3?\nI will create an issue on this after I get some word from our team.\nThanks!\n\n----------\n\n[DudaNogueira (2024-09-30T15:13:26.938Z)]: @sanjeev1678 !!\nAlso, can you try that with the latest version?\nWe had some changes on modules that have bumped some dependencies and may have fixed this.\nTHanks!\n\n----------\n\n[sanjeev1678 (2024-10-01T07:21:27.644Z)]: Hello @DudaNogueira\nIn the meantime, I encountered multiple issue with the backup in Azure.\nError message:\n“upload stream \"weaviate-backup/weaviate-0/doc/chunk-1\": Put \"\\weaviate-backup_20240902600000%2Fweaviate-0%2Fdoc%2Fchunk-1?blockid=5oN5xDQLTMVIhoP8%2F5nf8gAALL0AAAAAAAAAAAAA%3D%3D\\u0026comp=block\": dial tcp 20.60.128.132:443: connect: connection refused”\nAdditionally, there’s another issue:\n“backup class industryintel descriptor: cannot create new backup, backup ‘weaviate-backup_20240902600000’ is not yet released, this means its contents have not yet been fully copied to its destination, try again later”\nI was expecting these to be resolved in newer versions of Weaviate.\n\n----------\n\n[DudaNogueira (2024-10-01T08:08:27.285Z)]: hi, sorry, are those logs from the latest version?\nIt was not clear if that you have updated it after the 1.25.0 version\n\n----------\n\n[sanjeev1678 (2024-10-01T08:20:20.958Z)]: Hello @DudaNogueira\nYes, this is the logs from the latest version after updated to 1.25.0 version.\n\n----------\n\n[DudaNogueira (2024-10-01T08:29:59.694Z)]: Oh, the latest version is 1.26.5, not 1.25 \nThe changes I mentioned landed in latest 1.26.X version (not sure exactly which, so 1.26.5 is the best option)\n\n----------\n\n[sanjeev1678 (2024-10-01T08:45:25.369Z)]: I understand, but will the issue with “backup not released yet” be resolved in the latest release?\nA recurring issue we’re facing is that whenever a previous backup fails for any reason, this “backup release not yet” error appears for all subsequent backups.\nThis is a significant problem because once this issue occurs, entire backup pipeline stops functioning. It’s strange, and we should have some form of exception-handling mechanism to address and resolve this issue.\nThe error message we receive is:\n“cannot create new backup, backup ‘weaviate-backup_20240902600000’ is not yet released.”\n\n----------\n\n[DudaNogueira (2024-10-01T09:24:02.388Z)]: Hi @sanjeev1678 !\nThe new 1.26.5 version implements a new cancel backup endpoint:\n\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n\n\n\n    \n      \n    \n\n  \n\n\n\n      \n        backport : add backup cancel endpoint\n      \n\n    \n      weaviate:stable/v1.24 ← weaviate:backup-cancel-1.24\n    \n\n      \n        \n          opened 03:01PM - 10 Sep 24 UTC\n        \n\n        \n          \n            \n            moogacs\n          \n        \n\n        \n          \n            +1558\n            -34\n          \n        \n      \n  \n\n\n  \n    ### What's being changed:\nthis PR backports backup cancel endpoint PRs\n - http…s://github.com/weaviate/weaviate/pull/5639\n-  https://github.com/weaviate/weaviate/pull/5736\n\n### Review checklist\n\n- [ ] Documentation has been updated, if necessary. Link to changed documentation:\n- [x] Chaos pipeline run or not necessary. Link to pipeline: https://github.com/weaviate/weaviate-chaos-engineering/actions/runs/10798058707\n- [ ] All new code is covered by tests where it is reasonable.\n- [ ] Performance tests have been run or not necessary.\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nPreviously you could solve this by restarting Weaviate server, that will reset all backup processes.\nThis is not yet implemented on new client version, but you call this API directly.\nhere is the part of the openapi spec for that:\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate/blob/faf123a410d73b7408a5b3a601609f3646c78bee/openapi-specs/schema.json#L4956\n\n\n\n    \n      \n                }\n              },\n              \"500\": {\n                \"description\": \"An error has occurred while trying to fulfill the request. Most likely the ErrorResponse will contain more information about the error.\",\n                \"schema\": {\n                  \"$ref\": \"#/definitions/ErrorResponse\"\n                }\n              }\n            }\n          },\n          \"delete\": {\n            \"description\": \"Cancel created backup with specified ID\",\n            \"operationId\": \"backups.cancel\",\n            \"x-serviceIds\": [\n              \"weaviate.local.backup\"\n            ],\n            \"tags\": [\n              \"backups\"\n            ],\n            \"parameters\": [\n              {\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYou need to do a DELETE call to this endpoint:\n\nGET/backups/{backend}/{id}\n\nLet me know if this helps!\n\n----------\n\n[DudaNogueira (2024-10-01T09:46:39.317Z)]: Hi! By the way the legend @jphwang   just updated our docs with that:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nWeaviate",
    "date_created": "2024-09-26T13:05:54.785Z",
    "has_accepted_answer": false,
    "title": "Backup Issue Weaviate",
    "topic_id": 4341
  },
  {
    "user_id": 3185,
    "conversation": "[AnnTade (2025-01-20T15:24:57.534Z)]: Hello everyone. I need some help regarding the following issue\nI have a weaviate instance that doesn’t support gRPC (i cannot use weaviate client version 4 on it). I have an S3 bucket that acts as a backup for the mentioned weaviate instance. Now I have created a weaviate cluster that has 3 weaviate instances on openstack. The idea is to use them as shards and shard based on id\nMy question is - Is there a way to load / import data from S3 into the weaviate instance? If so, is there a way to import the data into weaviate shards from S3?\nAny help or resource is appreciated, or a link to relevant part of documentation!\nThank you so much in advance!\n\n----------\n\n[DudaNogueira (2025-01-24T20:38:43.873Z)]: hi @AnnTade !!\nGreat question. If I understood it correctly, you want to now use a multi node cluster, and have your data in a single node cluster.\nIn those cases, you cannot use the backup/restore functions. That’s because, upon restoring at target, the collection in the new cluster will still have the very same configurations you had in souce.\nThere is a feature in our roadmap that will make it possible using dynamic scaling.\nBut for now, you will need to create the target collection, define the replication factor accordingly, and migrate your data to this new cluster.\nWe have a fairly simple migration guide available here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Learn how to migrate data within Weaviate for easy data handling.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2025-01-20T15:24:57.482Z",
    "has_accepted_answer": false,
    "title": "Data replication Weaviate",
    "topic_id": 9823
  },
  {
    "user_id": 643,
    "conversation": "[garcia.e (2025-01-23T13:05:19.776Z)]: Hi\nI’m trying to transfer the data from a docker desktop to a docker engine.\nWe’re using the weaviate 1.25.0\nFirts of all we’re taking all the data from the volume of the docker desktop container, creating a .tar file.\nThen we create the containers inside the docker engine using the docker compose up.\nThen we restore the data from the old volume to the new one using wsl commands.\nOnce we’re done, we look into the volume and there is all the schemas and data stored, but when I try to access to the data using the url  v1/objects, its empty.\nWhat are we doing wrong? How can I transfer all the data to my docker engine container.\nRegards\n\n----------\n\n[DudaNogueira (2025-01-24T19:39:48.158Z)]: hi @garcia.e !!\nWelcome to our community \nHere are suggested steps to move backups around:\n\nspin a target cluster, with the very same version used in source cluster\nconfigure the same s3/gcp/azure bucket on both servers, as per the backup module docs.\ncreate a backup in source cluster\ncheck if the backup was indeed generated in the bucket\nrestore the same backup in target cluster\nupgrade target cluster. Don’t skip releases: upgrade to 1.26.latest, restart. Then 1.27.latest, restart. And finally 1.28.latest\n\nThis is important to make sure that any migrations that were created between 1.25.current and 1.28.latest are run.\nbecause those clusters share the backup bucket, they can backup and restore between each other. You need to only use the same id when creating the backup.\nNote that if you have a single node cluster, and want to restore the backup on a multi node cluster, this approach will not work.\nIn that case, you need to migrate your data. Migrating your data is different, because when you insert the objects, all the calculations will be computed again and the data will be replicated as per the new configuration.\nFor that case, you can spin a target cluster (and here it can already be in the latest version ), and use the migration guide to move your data over:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Learn how to migrate data within Weaviate for easy data handling.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNote that, migrating your data will consume some resource, so depending on the size of your dataset, you will need to allocate the resources accordingly.\nLet me know if that helps!",
    "date_created": "2025-01-23T13:05:19.729Z",
    "has_accepted_answer": false,
    "title": "Trying to restore data from docker desktop to a docker engine",
    "topic_id": 9863
  },
  {
    "user_id": 3052,
    "conversation": "[RamuA (2024-12-19T02:52:48.130Z)]: I am seeking detailed information and documentation on installing and configuring Weaviate DB on AWS EC2 instances with three replication nodes. Specifically, I need the best configuration methods and minimum requirement details (OS, CPU, RAM, and volume size). Additionally, I would like to know the available options for monitoring the cluster and performing backup/restore administrative activities. If you provide these details, I will begin preparing to implement them on AWS.\"\n\n----------\n\n[DudaNogueira (2024-12-19T19:29:40.627Z)]: Hi @RamuA !!\nWelcome to our community \nThe best - and recommended - way to deploy a Weaviate multi node cluster is using our oficial helm chart and kubernetes:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nKubernetes | Weaviate\n\n  For a tutorial on how to use minikube to deploy Weaviate on Kubernetes, see the Weaviate Academy course, Weaviate on Kubernetes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nOS, CPU, RAM, and volume size will depend on your usage, specially how many dimensions you plan on storing. For this, we have a comprehensive resource planning documentation here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nResource Planning | Weaviate\n\n  Weaviate scales well for large projects. Smaller projects, less than 1M objects, do not require resource planning. For medium and large-scale projects, you should plan how to get the best performance from your resources. While you design you system,...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor observing your cluster, you can use prometheus and grafana, as explained on this blog post:\n  \n      \n\n      weaviate.io – 28 Mar 23\n  \n\n  \n    \n\nMonitoring Weaviate in Production | Weaviate\n\n  Learn about how to monitor Weaviate in production and observe key metrics.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this answer your questions!\nTHanks!\n\n----------\n\n[RamuA (2024-12-28T06:19:48.048Z)]: DudaNogueira:\n\nMonitoring Weaviate in Production | Weaviate\n\n\nHello @DudaNogueira,\nThank you for your response. Could you please share the minimum requirements for instances to build a Weaviate development cluster with replication configuration? Additionally, should we use Kubernetes or Docker containers for this setup?\nI also have a few more questions:\n\nHow will it integrate with IDP (Azure)?\nWhat are the steps to restore from an AWS S3 bucket, and how can we encrypt the backups stored in S3?\nHow can we block outgoing traffic?\nHow can we restrict client-based access behind a VPN and use Nginx as a proxy?\nWhat metrics are needed to measure the database performance?\n\nThank you for your assistance.\n\n----------\n\n[RamuA (2025-01-09T05:02:29.869Z)]: DudaNogueira:\n\nThe best - and recommended - way to deploy a Weaviate multi node cluster is using our oficial helm chart and kubernetes:\n\n\n@DudaNogueira : Could you please provide an update on my response above? We need to implement the three environments in our projects and are waiting for your response to choose the best implementation.\n\n----------\n\n[DudaNogueira (2025-01-10T11:23:53.002Z)]: hi!!\nSome of those questions are not Weaviate related \nHere we have some content on Observability in prod:\n  \n      \n\n      weaviate.io – 28 Mar 23\n  \n\n  \n    \n\nMonitoring Weaviate in Production | Weaviate\n\n  Learn about how to monitor Weaviate in production and observe key metrics.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nand here is how to use the backup/restore capabilities of Weaviate:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBackups | Weaviate\n\n  Weaviate's Backup feature is designed to work natively with cloud technology. Most notably, it allows:\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps. Those are the two questions that are Weaviate related. The other ones are specific to where you are running.\nTHanks!",
    "date_created": "2024-12-19T02:52:48.054Z",
    "has_accepted_answer": false,
    "title": "To setup Weaviate on the EC2 instances with 3 nodes",
    "topic_id": 9309
  },
  {
    "user_id": 3323,
    "conversation": "[violin1443 (2025-03-21T21:55:15.877Z)]: Hi! I’d like to implement a query with an inverter (“not” filter) to one of the multiple conditional filters in a collection.query.near_text search.\nHere are the details with a made-up example: in collection “Test”, I would like to run a near text query for movies that EITHER 1) have DirectorA as its movie_director OR 2) do NOT have Horror in its tags.\nIn case it’s helpful with getting started, here is the code that would exactly so except for having “do have Horror in its tags” instead, adapted from what @DudaNogueira graciously shared last time for my previous question on a similar topic.\nimport weaviate\nfrom weaviate import classes as wvc\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=[\n        wvc.config.Configure.NamedVectors.text2vec_openai(name=\"default\")\n    ],\n    inverted_index_config=wvc.config.Configure.inverted_index(\n        index_null_state=True,\n        index_property_length=True\n    ),\n    properties=[\n        wvc.config.Property(name=\"movie_description\", data_type=wvc.config.DataType.TEXT),\n        wvc.config.Property(name=\"movie_tags\", data_type=wvc.config.DataType.TEXT_ARRAY),\n        wvc.config.Property(name=\"movie_director\", data_type=wvc.config.DataType.TEXT),\n    ]\n)\ncollection = client.collections.get(\"Test\")\ncollection.data.insert_many([\n    { \"movie_description\": \"Move desc 1. No tag\", \"movie_director\": \"DirectorB\"},\n    { \"movie_description\": \"Move desc 2. One Tag\", \"movie_tags\": [\"Drama\"], \"movie_director\": \"DirectorA\"},\n    { \"movie_description\": \"Move desc 3. Two Tags\", \"movie_tags\": [\"Crime\", \"Horror\"], \"movie_director\": \"DirectorB\"},\n    { \"movie_description\": \"Move desc 4. OverLap tags\", \"movie_tags\": [\"Horror\", \"Action\"], \"movie_director\": \"DirectorA\"},\n])\n\nfilters = (wvc.query.Filter.by_property(\"movie_tags\").contains_any([\"Horror\"]) |\n           wvc.query.Filter.by_property(\"movie_director\").equal(\"DirectorA\")\n          )\n\nquery = collection.query.near_text(\n    query=\"some movie\",\n    filters= filters\n)\nfor o in query.objects:\n    print(o.properties)\n\nI am aware that the “Not” operator is not implemented, although based on this thread it seems like it might be included soon in a new release? Meanwhile, I wonder what is the best way as of now to implement the “do not have” filter? I assume there might be a way to do so with client.graphql_raw_query and GraphQL, but I don’t have any experience with the language, so any guidance (sample code for a not filter, documentations, etc.) is highly appreciated.\nThank you!",
    "date_created": "2025-03-21T21:55:15.821Z",
    "has_accepted_answer": false,
    "title": "Workaround for \"Not\" operator in conditional filters when querying",
    "topic_id": 20176
  },
  {
    "user_id": 3100,
    "conversation": "[ziemo (2024-12-25T11:42:57.125Z)]: Hi guys! \nI noticed a strange but important issue (bug?) with cosine similarity in Weaviate. I’m using external SentenceTransformer for vectorization, and when I compare cosine similarity obtained with ScikitLearn - it’s strangely completely different.\nSince I want to be precise I will past my code with both texts where I noticed the difference (they are in polish, but for those who doesn’t know → first text is the right answer),  hopefully it’s still be pleasant to read \nSentence Transformer vectorizer:\nmodel = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n\nMy text query and 2 texts to compare:\nquery = \"jakie są kary w kodeksie karnym?\"\n\ntext1 = \"kodeks karny. Start. Kary. 32. Katalog kar. Karami są:1)grzywna;2)ograniczenie wolności;3)pozbawienie wolności;4)(uchylony);5)dożywotnie pozbawienie wolności.\"\n\ntext2 = \"\"\"kodeks karny skarbowy. Część ogólna. Przestępstwa skarbowe. 22. Kary oraz środki karne i zabezpieczające. § 1.Karami za przestępstwa skarbowe są:1)kara grzywny w stawkach dziennych;2)kara ograniczenia wolności;3)kara pozbawienia wolności.\n§ 2.Środkami karnymi są:1)dobrowolne poddanie się odpowiedzialności;2)przepadek przedmiotów;3)ściągnięcie równowartości pieniężnej przepadku przedmiotów;4)przepadek korzyści majątkowej;4a)ściągnięcie równowartości pieniężnej przepadku korzyści majątkowej;5)zakaz prowadzenia określonej działalności gospodarczej, wykonywania określonego zawodu lub zajmowania określonego stanowiska;6)podanie wyroku do publicznej wiadomości;7)pozbawienie praw publicznych;8)środki związane z poddaniem sprawcy próbie:a)warunkowe umorzenie postępowania karnego,b)warunkowe zawieszenie wykonania kary,c)warunkowe zwolnienie.\n§ 3.Środkami zabezpieczającymi są:1)elektroniczna kontrola miejsca pobytu;2)terapia;3)terapia uzależnień;4)pobyt w zakładzie psychiatrycznym;5)przepadek przedmiotów;6)zakazy wymienione w § 2 pkt 5.\"\"\"\n\nScikitLearn cosine implementation:\nquery_embedding = model.encode(query)\nsentence1_embedding = model.encode(ss1)\nsentence2_embedding = model.encode(ss2)\n\n# Compute cosine similarity\nsimilarity = cosine_similarity([query_embedding], [sentence1_embedding])\nprint(\"Text 1 Score:\", similarity[0][0])\n# score: 0.28450348362745925\n\nsimilarity = cosine_similarity([query_embedding], [sentence2_embedding])\nprint(\"Text 2 Score:\", similarity[0][0])\n# score: 0.5143749261108472\n\nScikitLearn results are:\n\nfor the text 1: 0.28450348362745925\nfor the text 2: 0.5143749261108472\n\nAs you can see SciKit cosine silimarity correctly distinguishes first text as more similar than the second one.\nWeaviate: collection creation\nvector_index_config = Configure.VectorIndex.hnsw(\n    distance_metric=VectorDistances.COSINE\n)\n\ncollection = client.collections.create(collection_name,\n                                       vector_index_config=vector_index_config, \n                                       vectorizer_config=Configure.Vectorizer.none())\n\nWeaviate: batch adding\nembeddings = model.encode(query).tolist()\nwith collection.batch.dynamic() as batch:\n    for vector, data_row in zip(embeddings, docs):\n        obj_uuid = generate_uuid5(data_row)\n        batch.add_object(\n            properties=data_row,\n            uuid=obj_uuid,\n            vector=vector\n)\n\nWeaviate: near vector search\nfrom weaviate.collections.classes.grpc import MetadataQuery\n\nvector = vectorizer.model.encode(search_query).tolist()\n\nresults = obj.collection.query.near_vector(\n    near_vector=vector, \n    limit=2,\n    return_metadata=MetadataQuery(distance=True, certainty=True))\n\nfor rr in results.objects:\n    print(rr.metadata.distance)\n    print(rr.properties['content'])\n\nWeaviate results are:\n\nfor the text 1: 0.7154964208602905\nfor the text 2: 0.4856252074241638\n\nfor testing I have only those 2 objects in the database.\nI also checked if stored vectors are the same with:\nweaviate_vec = (obj.collection.query.fetch_object_by_id('id_of_first_object', include_vector=True).vector['default'])\n\nnp.sum(np.array(weaviate_vec) - np.array(sentence1_embedding))\n# 0\n\nand they are.\nDo anyone has any idea what’s might going on? I will be very appreciate of your help",
    "date_created": "2024-12-25T11:42:57.057Z",
    "has_accepted_answer": false,
    "title": "Cosine similarity differs between ScikitLearn and Weaviate for SentenceTransformer vectors",
    "topic_id": 9429
  },
  {
    "user_id": 702,
    "conversation": "[fenglizzz (2024-03-15T06:01:40.704Z)]: Description\nHi, I am using docker compose to deploy Weaviate on two machines.  The first machine’s docker compose yml file is:\nservices:\n  weaviate-node-1:\n    init: true\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.2\n    ports:\n    - 8080:8080\n    - 7100:7100\n    - 7101:7101\n    - 50051:50051\n    restart: on-failure:0\n    volumes:\n      - ./data-node-1:/var/lib/weaviate\n    environment:\n      LOG_LEVEL: 'debug'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      CLUSTER_HOSTNAME: 'node1'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'\n    networks:\n      - weaviate\nnetworks:\n  weaviate:\n    attachable: true\n\nThe second machine docker compose file is:\nservices:\n  weaviate-node-2:\n    init: true\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8081'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.2\n    ports:\n    - 8081:8080\n    - 7102:7102\n    - 7103:7103\n    - 50052:50051\n    restart: on-failure:0\n    volumes:\n      - ./data-node-2:/var/lib/weaviate\n    environment:\n      LOG_LEVEL: 'debug'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      CLUSTER_HOSTNAME: 'node2'\n      CLUSTER_GOSSIP_BIND_PORT: '7102'\n      CLUSTER_DATA_BIND_PORT: '7103'\n      CLUSTER_JOIN: '10.12.226.225:7100'\n    networks:\n      - weaviate\nnetworks:\n  weaviate:\n    attachable: true\n\nafter I ran docker compose up and I got the error as shown in the following logs.\nThe log from node 1:\n[+] Running 2/1\n ✔ Network weaviate_testing_weaviate             Created                                                                                                    0.2s \n ✔ Container weaviate_testing-weaviate-node-1-1  Created                                                                                                    0.0s \nAttaching to weaviate-node-1-1\nweaviate-node-1-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"created startup context, nothing done so far\",\"startup_time_left\":\"59m59.997886965s\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"config loaded\",\"startup_time_left\":\"59m59.997070446s\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"configured OIDC and anonymous access client\",\"startup_time_left\":\"59m59.997044326s\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"initialized schema\",\"startup_time_left\":\"59m59.997008365s\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"startup routine complete\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"start registering modules\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"completed registering modules\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup_cluster_schema_sync\",\"level\":\"debug\",\"msg\":\"Only node in the cluster at this point. No schema sync necessary.\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"inverted filter2search migration\",\"level\":\"debug\",\"msg\":\"migration skip flag set, skipping migration\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"cluster_api_startup\",\"level\":\"debug\",\"msg\":\"serving cluster api on port 7101\",\"port\":7101,\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"inverted filter2search migration\",\"level\":\"debug\",\"msg\":\"starting switching fallback mode\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"inverted filter2search migration\",\"level\":\"debug\",\"msg\":\"no missing filterable indexes, fallback mode skipped\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"start initializing modules\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"finished initializing modules\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"graphql_rebuild\",\"level\":\"debug\",\"msg\":\"rebuilding the graphql schema\",\"schema\":{\"Objects\":{\"classes\":[]}},\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2024-03-15T05:43:29Z\"}\nweaviate-node-1-1  | {\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:cd3080db-13b9-4357-8015-9fefbebf3de3 Type:INIT Version:1.24.2 Modules: NumObjects:0 OS:linux Arch:amd64}\",\"time\":\"2024-03-15T05:43:30Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=10.12.226.153:60154\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-03-15T05:44:10Z\"}\nweaviate-node-1-1  | {\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-03-15T05:44:11Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-03-15T05:44:12Z\"}\nweaviate-node-1-1  | {\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-03-15T05:44:14Z\"}\nweaviate-node-1-1  | {\"level\":\"info\",\"msg\":\" memberlist: Marking node2 as failed, suspect timeout reached (0 peer confirmations)\",\"time\":\"2024-03-15T05:44:15Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-03-15T05:44:15Z\"}\nweaviate-node-1-1  | {\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-03-15T05:44:18Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=10.12.226.153:53962\",\"time\":\"2024-03-15T05:44:40Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=10.12.226.153:34830\",\"time\":\"2024-03-15T05:45:12Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-03-15T05:45:14Z\"}\nweaviate-node-1-1  | {\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-03-15T05:45:18Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-03-15T05:45:19Z\"}\nweaviate-node-1-1  | {\"level\":\"info\",\"msg\":\" memberlist: Marking node2 as failed, suspect timeout reached (0 peer confirmations)\",\"time\":\"2024-03-15T05:45:22Z\"}\nweaviate-node-1-1  | {\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-03-15T05:45:24Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=10.12.226.153:32960\",\"time\":\"2024-03-15T05:45:44Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=10.12.226.153:56040\",\"time\":\"2024-03-15T05:46:16Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-03-15T05:46:17Z\"}\nweaviate-node-1-1  | {\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-03-15T05:46:23Z\"}\nweaviate-node-1-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-03-15T05:46:24Z\"}\n\nThe log from node 2:\n[+] Running 2/1\n ✔ Network weaviate_testing_weaviate             Created                                                                                                    0.2s \n ✔ Container weaviate_testing-weaviate-node-2-1  Created                                                                                                    0.0s \nAttaching to weaviate-node-2-1\nweaviate-node-2-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"created startup context, nothing done so far\",\"startup_time_left\":\"59m59.997878536s\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"config loaded\",\"startup_time_left\":\"59m59.997113417s\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"configured OIDC and anonymous access client\",\"startup_time_left\":\"59m59.997089937s\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"initialized schema\",\"startup_time_left\":\"59m59.997072807s\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Initiating push/pull sync with:  10.12.226.225:7100\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"startup routine complete\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"start registering modules\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"completed registering modules\",\"time\":\"2024-03-15T05:44:08Z\"}\nweaviate-node-2-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node1 (timeout reached)\",\"time\":\"2024-03-15T05:44:09Z\"}\nweaviate-node-2-1  | {\"level\":\"info\",\"msg\":\" memberlist: Suspect node1 has failed, no acks received\",\"time\":\"2024-03-15T05:44:10Z\"}\nweaviate-node-2-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node1 (timeout reached)\",\"time\":\"2024-03-15T05:44:11Z\"}\nweaviate-node-2-1  | {\"level\":\"info\",\"msg\":\" memberlist: Suspect node1 has failed, no acks received\",\"time\":\"2024-03-15T05:44:13Z\"}\nweaviate-node-2-1  | {\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node1 (timeout reached)\",\"time\":\"2024-03-15T05:44:13Z\"}\nweaviate-node-2-1  | {\"level\":\"info\",\"msg\":\" memberlist: Marking node1 as failed, suspect timeout reached (0 peer confirmations)\",\"time\":\"2024-03-15T05:44:14Z\"}\nweaviate-node-2-1  | {\"level\":\"info\",\"msg\":\" memberlist: Suspect node1 has failed, no acks received\",\"time\":\"2024-03-15T05:44:16Z\"}\nweaviate-node-2-1  | {\"action\":\"startup\",\"error\":\"could not load or initialize schema: sync schema with other nodes in the cluster: read schema: open transaction: broadcast open transaction: host \\\"172.31.0.2:7101\\\": send http request: Post \\\"http://172.31.0.2:7101/schema/transactions/\\\": context deadline exceeded\",\"level\":\"fatal\",\"msg\":\"could not initialize schema manager\",\"time\":\"2024-03-15T05:44:38Z\"}\nweaviate-node-2-1 exited with code 0\n\nAnd I have tried your suggestion here Can only Docker Compose be used for multi node deployment?, but still got same issues.\nI have tested the communication between the two nodes and they can connect with each other through TCP and UDP.\nDo you have any clue why this is happening and suggestion on how to resolve this? Thanks very much!\n\n----------\n\n[DudaNogueira (2024-03-15T12:54:34.467Z)]: Hi @fenglizzz !! Welcome to our community \nIt’s not a good idea to reference the CLUSTER_JOIN by IPs (or any container to container connection inside docker/k8s to be fair), as those will eventually change down the road, or maybe even after a reboot.\nHere are some steps to get this party going. \nFirst, let’s create a docker attachable network:\ndocker network create --attachable weaviate\n\nNow, using the latest docker compose, and using this doc to adjust it to a multi node setup, a came up with those two files:\ndocker-compose-0.yaml\n---\nversion: '3.4'\nservices:\n  weaviate-0:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.3\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - ./data-node0:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node0'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'      \n    networks:\n      - weaviate\n\nnetworks:\n  weaviate:\n    attachable: true\n...\n\nlet’s first run it and check everything\ndocker compose -f docker-compose-0.yaml\n\nand check if our founder node is up:\n❯ curl localhost:8080/v1/nodes\n{\"nodes\":[{\"batchStats\":{\"queueLength\":0,\"ratePerSecond\":0},\"gitHash\":\"7e5d3aa\",\"name\":\"node0\",\"shards\":null,\"status\":\"HEALTHY\",\"version\":\"1.24.3\"}]}\n\nnow, let’s spin up the second node, node1 \nhere is the docker-compose-1.yaml\n---\nversion: '3.4'\nservices:\n  weaviate-1:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.3\n    ports:\n    - 8081:8080\n    - 50052:50051\n    volumes:\n    - ./data-node1:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node1'\n      CLUSTER_GOSSIP_BIND_PORT: '7102'\n      CLUSTER_DATA_BIND_PORT: '7103'\n      CLUSTER_JOIN: 'weaviate-0:7100'\n    networks:\n      - weaviate\n\nnetworks:\n  weaviate:\n    attachable: true\n...\n\nThe only differences:\n\nService name\nPort mappings (so they don’t conflict)\nFolder for mounting data\nCLUSTER_HOSTNAME\nNode1 has CLUSTER_JOIN pointing to the reachable hostname of Node0\n\nNow, you can spin the second node:\ndocker compose -f docker-compose-0.yaml up -d\n\nAnd now check the status of your cluster:\n❯ curl localhost:8080/v1/nodes\n{\n   \"nodes\":[\n      {\n         \"batchStats\":{\n            \"queueLength\":0,\n            \"ratePerSecond\":0\n         },\n         \"gitHash\":\"7e5d3aa\",\n         \"name\":\"node0\",\n         \"shards\":null,\n         \"status\":\"HEALTHY\",\n         \"version\":\"1.24.3\"\n      },\n      {\n         \"batchStats\":{\n            \"queueLength\":0,\n            \"ratePerSecond\":0\n         },\n         \"gitHash\":\"7e5d3aa\",\n         \"name\":\"node1\",\n         \"shards\":null,\n         \"status\":\"HEALTHY\",\n         \"version\":\"1.24.3\"\n      }\n   ]\n}\n\nLet me know if this helps!\nAnd don’t forget to check out events page!\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nEvents & Webinars | Weaviate - Vector Database\n\n  Join us at conferences, meetups, webinars or workshops\n\n----------\n\n[fenglizzz (2024-03-18T01:55:46.324Z)]: DudaNogueira:\n\nnetworks:\n  weaviate:\n    attachable: true\n\n\n\nHI thanks very much for the detailed steps. I followed exactly as what you said here. But when I run on the second node. There is one error with\"action\":“cluster_attempt_join”,“error”:“lookup weaviate-0 on 127.0.0.11:53: no such host”,“level”:“warning”,“msg”:\"specified hostname to join cluster cannot be resolved. The log on the second node is shown as following.\n{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-03-18T01:33:51Z\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-03-18T01:33:51Z\"}\n{\"action\":\"cluster_attempt_join\",\"error\":\"lookup weaviate-0 on 127.0.0.11:53: no such host\",\"level\":\"warning\",\"msg\":\"specified hostname to join cluster cannot be resolved. This is fineif this is the first node of a new cluster, but problematic otherwise.\",\"remote_hostname\":\"weaviate-0:7100\",\"time\":\"2024-03-18T01:33:51Z\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-03-18T01:33:51Z\"}\n{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-03-18T01:33:51Z\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-03-18T01:33:51Z\"}\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2024-03-18T01:33:51Z\"}\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:fbfc895b-e0b2-4d44-b191-dfb5965fbdea Type:INIT Version:1.24.3 Modules:generative-cohere,generative-openai,generative-palm,qna-openai,ref2vec-centroid,reranker-cohere,text2vec-cohere,text2vec-huggingface,text2vec-openai,text2vec-palm NumObjects:0 OS:linux Arch:amd64}\",\"time\":\"2024-03-18T01:33:52Z\"}\n\n----------\n\n[fenglizzz (2024-03-18T03:17:42.107Z)]: since these are running on to different nodes. How does it know which node that weaviate-0 is running on if we just use the ‘weaviate-0’ instead of IP please?\n\n----------\n\n[DudaNogueira (2024-03-18T13:00:33.659Z)]: Hi @fenglizzz !\nit will infer from the service name.\nEvery container in a docker network will use it’s service name as the hostname, as well as projectname-container-[1-NN]\nproject name, if not defined, will be the folder where it runs.\nso for example, if you run those docker compose in a folder called feng, the second hostname you could use are:\n\nfeng-weaviate-0-1\nfeng-weaviate-1-1\n\nBefore running those, can completely remove that stack?\nyou can do it with:\nWARNING: this command removes everything from the stack, including docker volumes. As this docker compose volumes are binded to a folder, it will not delete it.\ndocker compose down -v\n\nLet me know if this works.\nTHanks!\n\n----------\n\n[fenglizzz (2024-03-18T14:01:09.035Z)]: HI thanks very much for the response. I am running under the folder weaviate_testing. The first node is started as:\n[+] Running 2/1\n ✔ Network weaviate_testing_weaviate        Created                                                                                                         0.2s \n ✔ Container weaviate_testing-weaviate-0-1  Created                                                                                                         0.0s \nAttaching to weaviate-0-1\nweaviate-0-1  | {\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-03-18T13:54:12Z\"}\nweaviate-0-1  | {\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-03-18T13:54:12Z\"}\nweaviate-0-1  | {\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-03-18T13:54:12Z\"}\nweaviate-0-1  | {\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-03-18T13:54:12Z\"}\nweaviate-0-1  | {\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2024-03-18T13:54:12Z\"}\nweaviate-0-1  | {\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:e140af08-5a21-45dc-a643-99c87d0865a6 Type:INIT Version:1.24.3 Modules: NumObjects:0 OS:linux Arch:amd64}\",\"time\":\"2024-03-18T13:54:13Z\"}\n\n\nso the hostname should be ‘weaviate_testing-weaviate-0-1’ right? Then in the second node’s compose file I set\n CLUSTER_JOIN: 'weaviate_testing-weaviate-0-1:7100'\n\nbut after run compose up, I still got the following error:\n[+] Running 2/1\n ✔ Network weaviate_testing_weaviate        Created                                                                                                         0.2s \n ✔ Container weaviate_testing-weaviate-1-1  Created                                                                                                         0.0s \nAttaching to weaviate-1-1\nweaviate-1-1  | {\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-03-18T13:55:06Z\"}\nweaviate-1-1  | {\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-03-18T13:55:06Z\"}\nweaviate-1-1  | {\"action\":\"cluster_attempt_join\",\"error\":\"lookup weaviate_testing-weaviate-0-1 on 127.0.0.11:53: no such host\",\"level\":\"warning\",\"msg\":\"specified hostname to join cluster cannot be resolved. This is fineif this is the first node of a new cluster, but problematic otherwise.\",\"remote_hostname\":\"weaviate_testing-weaviate-0-1:7100\",\"time\":\"2024-03-18T13:55:06Z\"}\nweaviate-1-1  | {\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-03-18T13:55:06Z\"}\nweaviate-1-1  | {\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-03-18T13:55:06Z\"}\nweaviate-1-1  | {\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2024-03-18T13:55:06Z\"}\nweaviate-1-1  | {\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:e43c6368-fdfb-4006-bebb-61d907771ccd Type:INIT Version:1.24.3 Modules: NumObjects:0 OS:linux Arch:amd64}\",\"time\":\"2024-03-18T13:55:07Z\"}\n\n----------\n\n[DudaNogueira (2024-03-18T17:47:20.164Z)]: After spinning the first node, can you read the node status?\ncurl localhost:8080/v1/nodes\n\none thing to try is to clearing everything (including the network) and start over:\ndocker compose -f docker-compose-0.yaml -f docker-compose-1.yaml down -v\ndocker network rm weaviate\nrm -rf data-node0 data-node1\n\nNow, create again\ndocker network create --attachable weaviate\ndocker compose -f docker-compose-0.yaml -f docker-compose-1.yaml up -d\n\nThis is how you can check the connectivity from one node to another:\ndocker compose -f docker-compose-0.yaml exec -ti weaviate-0 wget -qO - http://weaviate-1:8080/v1/nodes\n\nYou are running a wget from within the container weaviate-o, pointing to weaviate-1.\nLet me know if this helps, and feel free to ping me on our lack if you need further assistance.\nTHanks!\n\n----------\n\n[Ashok_Raja (2024-03-18T19:54:36.320Z)]: @DudaNogueira,\nIf I’m not wrong, you are sharing the steps to spawn multiple weaviate nodes in one and the same physical machines, attach them to a common docker network and establish the cluster network.\nBut the issue lies, say, in spawning three weaviate nodes in three physical machines (one node per machine) and then trying to establish the cluster network. Thats where we face the following issue:\n\n{“action”:“cluster_attempt_join”,“error”:“lookup weaviate_testing-weaviate-0-1 on 127.0.0.11:53: no such host”,“level”:“warning”,“msg”:“specified hostname to join cluster cannot be resolved. This is fine if this is the first node of a new cluster, but problematic otherwise.”,“remote_hostname”:“weaviate_testing-weaviate-0-1:7100”,“time”:“2024-03-18T13:55:06Z”}\n\nRequesting your assistance in this regard.\n\n----------\n\n[DudaNogueira (2024-03-18T21:37:21.180Z)]: Hi @Ashok_Raja ! Welcome to our community \nOh… That’s indeed different.\nSorry @fenglizzz !! I totally missed the “two machines” on the beginning \nThat’s definitely some connectivity issues between this machines.\nAnd yes, on that case the IP address will be needed. Sorry again @fenglizzz  \none thing you could do to test the connectivity:\ndocker compose exec -ti weaviate sh\napk add busybox-extras\ntelnet ip-of-the-other-machine:7100\n\nLet me know if this helps.\n\n----------\n\n[jasper2077 (2024-11-20T06:40:12.688Z)]: Hello, I’m currently facing the same issue. Have you managed to resolve it",
    "date_created": "2024-03-15T06:01:40.621Z",
    "has_accepted_answer": false,
    "title": "Docker Compose with multi node deployment issue",
    "topic_id": 1720
  },
  {
    "user_id": 1487,
    "conversation": "[comportment (2024-09-03T15:20:22.299Z)]: Hello, the docker-compose configurator no longer shows up at Docker | Weaviate, I’ve tried on Chrome (normal and incognito) and Safari to no avail.\nThe developer console shows some potentially relevant errors: “Failed to load resource: net::ERR_CONNECTION_CLOSED” when issuing a get request to https://configuration.weaviate.io/v2/parameters/\nThe attached screenshot shows what I see: an empty “Configurator” section. Has it been moved, or am I just missing something?\nThanks!\nScreenshot 2024-09-03 at 11.18.032210×729 143 KB\n\n----------\n\n[DudaNogueira (2024-09-03T18:01:19.638Z)]: hi @comportment !! Welcome to our community \nThank you a lot for pointing it out!\nIndeed this service was out.\nWe have restored it and should be working now as expected.\nThanks!",
    "date_created": "2024-09-03T15:20:22.252Z",
    "has_accepted_answer": true,
    "title": "Docker Compose Configurator Missing in Install Guide",
    "topic_id": 3970
  },
  {
    "user_id": 753,
    "conversation": "[rhuang (2024-12-20T07:59:12.243Z)]: There are two parameters in the ConnectionConfig:\nsession_pool_connections\nsession_pool_maxsize\nI have the following questions:\n\nsession_pool_connections = 20, does it mean the application can have maximum 20 connections to the weaviate at the same time?\nWhat does it mean to set session_pool_maxsize = 100?\nIf the application has 5 threads, and session_pool_connections = 20, what does it mean to each thread?\n\nconn_config = ConnectionConfig(session_pool_connections=20,session_pool_maxsize=20)\n\nconfig_ = Config(connection_config=conn_config)\n\nclient = weaviate.Client(ip,additional_config=config)\n\nWith the setup, how do we get a connection from the pool?\nAny help is appreciated.\nThank you,\nRobert\n\n----------\n\n[DudaNogueira (2024-12-20T13:54:39.923Z)]: Hi!\nNot sure where you got those informations.\nYou also seem to be using the python v3 client, that is now considered deprecated:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nLegacy (v3) API (DEPRECATED) | Weaviate\n\n  This document relates to the legacy v3 client and API.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nDo you have any hard requirement to use that version?\nThanks!\n\n----------\n\n[rhuang (2024-12-20T16:20:34.192Z)]: @DudaNogueira sorry for the confusion. I just copied the code from the other post in the forum.\nWe still have the same thing in v4 but it is in weaviate.config.AdditionalConfig, right?\nI am trying to understand how to use connection pool in weaviate.\n\n----------\n\n[rhuang (2024-12-20T16:24:59.596Z)]: @DudaNogueira I have an other question.\nIf there are 5 threads in the application, and each thread uses weaviate.connect_to_custom to create a weaviate instance.\nDo they share the same connection? Or each one is an individual connection to the weaviate?\n\n----------\n\n[DudaNogueira (2024-12-20T22:08:30.839Z)]: Hi!\nAFAIK, they will open 5 different GRPC connections.\nIf you are dealing with ingestion, you can also increase the number of concurrent_requests in batch.\nLet me know if this helps!\nthanks!\n\n----------\n\n[rhuang (2024-12-20T22:24:51.655Z)]: @DudaNogueira I want to know the meaning of these two parameters:\nsession_pool_connections\nsession_pool_maxsize\n\n----------\n\n[DudaNogueira (2024-12-20T23:25:17.786Z)]: rhuang:\n\nsession_pool_connections\nsession_pool_maxsize\n\n\nThose parameters are passed here to httpx:\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate-python-client/blob/07c9f0ede2bdc817a626d8c02bb9aec9d72311f6/weaviate/connect/v4.py#L223\n\n\n\n    \n      \n          \n          def set_integrations(self, integrations_config: List[_IntegrationConfig]) -> None:\n              for integration in integrations_config:\n                  self._headers.update(integration._to_header())\n                  self.__additional_headers.update(integration._to_header())\n          \n          def _make_mounts(self) -> Dict[str, AsyncHTTPTransport]:\n              return {\n                  f\"{key}://\" if key == \"http\" or key == \"https\" else key: AsyncHTTPTransport(\n                      limits=Limits(\n                          max_connections=self.__connection_config.session_pool_maxsize,\n                          max_keepalive_connections=self.__connection_config.session_pool_connections,\n                      ),\n                      proxy=Proxy(url=proxy),\n                      retries=self.__connection_config.session_pool_max_retries,\n                      trust_env=self.__trust_env,\n                  )\n                  for key, proxy in self._proxies.items()\n                  if key != \"grpc\"\n              }\n          \n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAnd in httpx page we have this:\n  \n      \n\n      python-httpx.org\n  \n\n  \n    \n\nResource Limits - HTTPX\n\n  A next-generation HTTP client for Python.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n\nmax_keepalive_connections, number of allowable keep-alive connections, or None to always allow.\nmax_connections, maximum number of allowable connections, or None for no limits.\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-12-20T07:59:12.187Z",
    "has_accepted_answer": false,
    "title": "Connection pool",
    "topic_id": 9356
  },
  {
    "user_id": 813,
    "conversation": "[djjeffr (2024-09-25T13:38:59.219Z)]: Description\nVersion of pytorch used in modules doesn’t support Nvidia sm90 driver. The version of pytorch used in vector modules only support Nvidia sm86 or older drivers.\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\nPython error saying version of pytorch doesn’t support sm90 driver.\nI see PyTorch 2.0.1 being used has no support for sm_90:\nTorch: 2.0.1+cu121\nTorch: [‘sm_50’, ‘sm_60’, ‘sm_70’, ‘sm_75’, ‘sm_80’, ‘sm_86’]\n\nI see PyTorch 2.1.0 has sm_90:\nTorch: 2.1.0+cu121\nTorch: [‘sm_50’, ‘sm_60’, ‘sm_70’, ‘sm_75’, ‘sm_80’, ‘sm_86’, ‘sm_90’]\n\nYou can check on this with:\nprint(torch.version)\nprint(torch.cuda.get_arch_list())\nProblem is modules contain complied code using pytorch 2.0.1, it will need to be re-complied for pytorch 2.1\n\n----------\n\n[djjeffr (2024-09-27T17:58:42.450Z)]: djjeffr:\n\nTorch: 2.0.1+cu121\n\n\nShould be ```\nTorch: 2.0.1+cu117\n\n----------\n\n[djjeffr (2025-01-17T15:30:49.215Z)]: Hi, is any work being done to update the weaviate modules to use a new version of Pytorch to support the Nvidia gpu using the sm_90 driver.",
    "date_created": "2024-09-25T13:38:59.170Z",
    "has_accepted_answer": false,
    "title": "Version of pytorch used in modules doesn't support Nvidia sm90 driver",
    "topic_id": 4320
  },
  {
    "user_id": 225,
    "conversation": "[Vishal_Chaudhary (2023-08-07T11:10:07.230Z)]: Hi everyone,\nI am working on weaviate docker container which was deployed on EC2 instance. It was running until now, But suddenly I am not able to access weaviate docker container using port 8080. So, I checked EC2 logs but no error. After that I access EC2 instance to check the docker container status but docker container is running fine and also checked logs of weaviate container but no error has been found, So please anyone help me out with this ?\n\n----------\n\n[DudaNogueira (2023-08-07T19:20:58.818Z)]: hi @Vishal_Chaudhary ! Welcome to our community \nif you run:\nnetstat -tanu | grep 8080\ncan you see the port marked as “listening”?\nAlso, try restarting your weaviate instance with:\ndocker compose restart weaviate  (assuming your service is named weaviate)\nand keep a look on that log output:\ndocker compose logs -f --tail 100\nif you see something like:\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2023-08-07T19:15:02Z\"}\nIt’s probably safe to assume that this is something “up”, maybe a security policy configuration in Amazon’s EC2 or at your Linux server, like a firewall/ufw.\nLet me know if this helps\n\n----------\n\n[Amir_Sohail (2024-08-30T07:54:42.274Z)]: Hi @Vishal_Chaudhary could you share the way you deploy container on EC2?",
    "date_created": "2023-08-07T11:10:07.178Z",
    "has_accepted_answer": false,
    "title": "Weaviate Docker Container not working on EC2 instance",
    "topic_id": 481
  },
  {
    "user_id": 1262,
    "conversation": "[shaheen (2024-07-31T07:55:44.715Z)]: I am using python 3.11 and weaviate client 3.25 version.\nOn trying to connect with weaviate I get this below error.\n\\weaviate\\connect\\connection.py\", line 657, in wait_for_weaviate\nraise WeaviateStartUpError(\nweaviate.exceptions.WeaviateStartUpError: Weaviate did not start up in 5 seconds. Either the Weaviate URL (url) is wrong or Weaviate did not start up in the interval given in 'startup_period\n\n----------\n\n[Mohamed_Shahin (2024-07-31T11:57:01.997Z)]: Hello @shaheen,\nWelcome to our community! It’s great to have you here \nCan you share the code you’re using to connect? This issue is usually related to connectivity or an incorrect URL.\n\n----------\n\n[shaheen (2024-07-31T12:42:44.936Z)]: weaviate_client = weaviate.Client(\nurl=settings.weaviate_url,\nauth_client_secret=weaviate.auth.AuthApiKey(api_key=settings.weaviate_api_key),\nadditional_headers={\n“X-Azure-Api-Key”: settings.openai_api_key_us_east,\n“X-OpenAI-BaseURL”: settings.azure_openai_endpoint,\n},\ntimeout_config=(300, 300),\nstartup_period=30\n)\n\n----------\n\n[Mohamed_Shahin (2024-07-31T14:44:52.935Z)]: Thank you so much for details.\nCould you please try with the following and let me know:\n\nclient = weaviate.Client(\nurl=“”,\nauth_client_secret=weaviate.AuthApiKey(\n“”),\nadditional_headers={\n“X-Azure-Api-Key”: “”}\n)\n\nHere is another example in our docs:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nLocal instances | Weaviate - Vector Database\n\n  Follow these steps to connect to a locally hosted Weaviate instance.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI recommend you to upgrade and use Weaviate Client v4 to benefits from the new features and gRPC\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate - Vector Database\n\n  Overview\n\n----------\n\n[shaheen (2024-08-01T01:42:50.227Z)]: Hey, It still gives same error.\n\n----------\n\n[DudaNogueira (2024-08-29T19:34:21.889Z)]: hi @shaheen !!\nWhere you able to solve this?\nLet us know if you need further assistance.\nThanks!",
    "date_created": "2024-07-31T07:55:44.667Z",
    "has_accepted_answer": false,
    "title": "Weaviate didn't startup",
    "topic_id": 3228
  },
  {
    "user_id": 3019,
    "conversation": "[fcaldas (2024-12-15T22:55:09.956Z)]: Description\nHi,\nI am trying to use Weaviate with the Azure OpenAI service. I have a gpt-4o model deployed there.\nI am connecting to the weaviate docker container like this:\nself.client = weaviate.connect_to_custom(\n            http_host=self.config.weaviate_host,\n            http_port=self.config.weaviate_port,\n            http_secure=False,\n            grpc_host=self.config.weaviate_host,\n            grpc_port=self.config.weaviate_grpc_port,\n            grpc_secure=False,\n            headers={\n                \"X-Azure-Api-Key\": self.config.azure_openai_key,\n                \"X-Azure-Client-Value\": self.resource_name\n            }\n        )\n\nMy docker compose is as follows:\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.27.8\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_API_BASED_MODULES: 'true'\n      CLUSTER_HOSTNAME: 'node1'\n      ENABLE_MODULES: 'text2vec-azure-openai'\n      AZURE_OPENAI_ENDPOINT: 'https://*****instance.openai.azure.com'\n      AZURE_OPENAI_API_KEY: '****'\nvolumes:\n  weaviate_data:\n\nI am creating the collection like this:\ndef _create_collection(self, resource_name: str):\n        \"\"\"Create the Weaviate collection if it doesn't exist.\"\"\"\n        try:\n            try:\n                collection = self.client.collections.get(self.collection_name)\n                logging.info(f\"Using existing collection: {self.collection_name}\")\n            except weaviate.exceptions.WeaviateQueryError:\n                # Collection doesn't exist, create it\n                collection = self.client.collections.create(\n                    name=self.collection_name,\n                    vectorizer_config=weaviate.classes.config.Configure.Vectorizer.text2vec_azure_openai(\n                        vectorizer=\"text2vec-azure-openai\",\n                        resource_name=resource_name,\n                        deployment_id=self.config.azure_openai_deployment\n                    ),\n                    properties=[\n                        weaviate.classes.properties.Property(\n                            name=\"content\",\n                            data_type=weaviate.classes.datatypes.DataType.TEXT,\n                            description=\"The chunk content\",\n                            vectorize=True\n                        ),\n                        weaviate.classes.properties.Property(\n                            name=\"doc_id\",\n                            data_type=weaviate.classes.datatypes.DataType.TEXT,\n                            description=\"Document identifier\"\n                        ),\n                        weaviate.classes.properties.Property(\n                            name=\"chunk_id\",\n                            data_type=weaviate.classes.datatypes.DataType.INT,\n                            description=\"Chunk number within document\"\n                        ),\n                        weaviate.classes.properties.Property(\n                            name=\"source\",\n                            data_type=weaviate.classes.datatypes.DataType.TEXT,\n                            description=\"Document source\"\n                        ),\n                        weaviate.classes.properties.Property(\n                            name=\"last_updated\",\n                            data_type=weaviate.classes.datatypes.DataType.DATE,\n                            description=\"Last update timestamp\"\n                        ),\n                        weaviate.classes.properties.Property(\n                            name=\"content_hash\",\n                            data_type=weaviate.classes.datatypes.DataType.TEXT,\n                            description=\"Hash of document content\"\n                        ),\n                        weaviate.classes.properties.Property(\n                            name=\"file_path\",\n                            data_type=weaviate.classes.datatypes.DataType.TEXT,\n                            description=\"Original file path\"\n                        )\n                    ]\n                )\n                logging.info(f\"Created new collection: {self.collection_name}\")\n                \n        except Exception as e:\n            logging.error(f\"Error creating collection: {str(e)}\")\n            raise\n\nAnd ingesting documents:\ndef ingest_document(self, content: str, source: str, file_path: str = None) -> str:\n        \"\"\"Ingest a document into Weaviate.\"\"\"\n        try:\n            doc_id = self._generate_doc_id(content, source)\n            content_hash = hashlib.md5(content.encode()).hexdigest()\n            \n            # Get collection\n            collection = self.client.collections.get(self.collection_name)\n            \n            # Delete existing chunks if document exists\n            try:\n                where_filter = {\n                    \"path\": [\"doc_id\"],\n                    \"operator\": \"Equal\",\n                    \"valueString\": doc_id\n                }\n                collection.data.delete_many(where_filter)\n            except Exception as e:\n                logging.warning(f\"Error deleting existing chunks: {str(e)}\")\n\n            # Create new chunks\n            chunks = self._chunk_document(content)\n            current_time = datetime.now(timezone.utc).isoformat()\n            \n            # Prepare objects for batch import\n            objects = []\n            for i, chunk in enumerate(chunks):\n                properties = {\n                    \"content\": chunk,\n                    \"doc_id\": doc_id,\n                    \"chunk_id\": i,\n                    \"source\": source,\n                    \"last_updated\": current_time,\n                    \"content_hash\": content_hash\n                }\n                \n                if file_path:\n                    properties[\"file_path\"] = file_path\n                    \n                objects.append(properties)\n\n            # Import all chunks in a single batch\n            if objects:\n                collection.data.insert_many(objects)\n\n            return doc_id\n            \n        except Exception as e:\n            logging.error(f\"Error ingesting document: {str(e)}\")\n            raise\n\nAnd, yet, I am getting the following error:\n2024-12-16 09:45:34,854 - ERROR - Error processing C:\\Projects\\Qualification Toolbox\\backend\\documents\\technical qualification-v30-20241202_045512.pdf: Every object failed during insertion. Here is the set of all errors: API Key: no api key found neither in request header: X-Openai-Api-Key nor in environment variable under OPENAI_APIKEY\nProcessing existing documents: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 12.53it/s] \n2024-12-16 09:45:34,872 - ERROR - Error querying similar chunks: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n        status = StatusCode.UNKNOWN\n        details = \"explorer: get class: concurrentTargetVectorSearch): explorer: get class: vectorize search vector: vectorize params: vectorize params: vectorize keywords: remote client vectorize: API Key: no api key found neither in request header: X-Openai-Api-Key nor in environment variable under OPENAI_APIKEY\"\n        debug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-12-15T22:45:34.8592749+00:00\", grpc_status:2, grpc_message:\"explorer: get class: concurrentTargetVectorSearch): explorer: get class: vectorize search vector: vectorize params: vectorize params: vectorize keywords: remote client vectorize: API Key: no api key found neither in request header: X-Openai-Api-Key nor in environment variable under OPENAI_APIKEY\"}\"\n>.\n\nWhy am I being asked to provide a OPENAI_APIKEY  ?\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: official docker image\nMulti Node? Number of Running Nodes:\nClient Language and Version: EN, weaviate-client==4.9.6\nMultitenancy?: No\n\n----------\n\n[sebawita (2024-12-16T10:34:32.015Z)]: Hi @fcaldas,\nCan you try to provide the base_url when you define the vectorizer:\nLike this:\nclient.collections.create(\n    name=\"Jeopardy\",\n\n    vectorizer_config=Configure.Vectorizer.text2vec_azure_openai(\n        deployment_id=\"text-embedding-3-small\", # OpenAI model\n        resource_name=AZURE_RESOURCE_NAME,\n        base_url=AZURE_BASE_URL\n    ),\n)\n\nremove vectorizer\nBtw. There is no vectorizer property in text2vec_azure_openai()\n\n\n\n fcaldas:\n\nvectorizer_config=weaviate.classes.config.Configure.Vectorizer.text2vec_azure_openai(\n      # vectorizer=\"text2vec-azure-openai\", # <== this should be removed\n      resource_name=resource_name,\n      deployment_id=self.config.azure_openai_deployment\n),\n\n\n\nHere are available properties:\nimage896×308 29.6 KB\n\n----------\n\n[fcaldas (2024-12-17T03:22:37.817Z)]: Thank you!\nThat makes sense. I ended up finding out that I don’t have access to the Azure OpenAI Embedding model in my Azure OpenAI subscription, so I had to change directions and use  sentence-transformers/all-MiniLM-L6-v2 instead.\nSo I am creating the collection like this:\ndef _create_new_collection(self):\n        \"\"\"Create a new collection with proper configuration.\"\"\"\n        return self.client.collections.create(\n            name=self.collection_name,\n            vectorizer_config=weaviate.classes.config.Configure.Vectorizer.none(),\n            vector_index_config=weaviate.classes.config.Configure.VectorIndex.hnsw(\n                distance_metric=weaviate.classes.config.VectorDistances.COSINE,\n                vector_cache_max_objects=1000000,\n                max_connections=64,\n                ef_construction=128,\n                ef=100,\n                dynamic_ef_min=100,\n                dynamic_ef_max=500,\n                dynamic_ef_factor=8,\n                flat_search_cutoff=40000,\n                cleanup_interval_seconds=300\n            ),\n            properties=[\n                weaviate.classes.config.Property(\n                    name=\"content\",\n                    data_type=weaviate.classes.config.DataType.TEXT,\n                    description=\"The chunk content\",\n                    vectorize=True\n                ),\n                weaviate.classes.config.Property(\n                    name=\"documentId\",\n                    data_type=weaviate.classes.config.DataType.TEXT,\n                    description=\"Document identifier\"\n                ),\n                weaviate.classes.config.Property(\n                    name=\"chunkId\",\n                    data_type=weaviate.classes.config.DataType.INT,\n                    description=\"Chunk number within document\"\n                ),\n                weaviate.classes.config.Property(\n                    name=\"source\",\n                    data_type=weaviate.classes.config.DataType.TEXT,\n                    description=\"Document source\"\n                ),\n                weaviate.classes.config.Property(\n                    name=\"lastUpdated\",\n                    data_type=weaviate.classes.config.DataType.DATE,\n                    description=\"Last update timestamp\"\n                ),\n                weaviate.classes.config.Property(\n                    name=\"contentHash\",\n                    data_type=weaviate.classes.config.DataType.TEXT,\n                    description=\"Hash of document content\"\n                ),\n                weaviate.classes.config.Property(\n                    name=\"filePath\",\n                    data_type=weaviate.classes.config.DataType.TEXT,\n                    description=\"Original file path\"\n                )\n            ]\n        )\n\nAnd ingesting the documents like this:\ndef ingest_document(self, content: str, source: str, file_path: str = None) -> str:\n        \"\"\"Ingest a document into Weaviate.\"\"\"\n        try:\n            doc_id = self._generate_doc_id(content, source)\n            content_hash = hashlib.md5(content.encode()).hexdigest()\n            \n            # Get collection\n            collection = self.client.collections.get(self.collection_name)\n            \n            # Delete existing chunks if document exists\n            try:\n                collection.data.delete_many(\n                    where={\n                        \"path\": [\"documentId\"],\n                        \"operator\": \"Equal\",\n                        \"valueString\": doc_id\n                    }\n                )\n                logging.info(f\"Deleted existing chunks for document {doc_id}\")\n            except Exception as e:\n                if \"not found\" not in str(e).lower():\n                    logging.warning(f\"Error deleting existing chunks: {str(e)}\")\n\n            # Create new chunks\n            chunks = self._chunk_document(content)\n            current_time = datetime.now(timezone.utc).isoformat()\n            \n            # Prepare objects for batch import\n            objects_to_create = []\n            for i, chunk in enumerate(chunks):\n                # Generate vector for the chunk\n                vector = self._generate_embedding(chunk)\n                \n                properties = {\n                    \"content\": chunk,\n                    \"documentId\": doc_id,\n                    \"chunkId\": i,\n                    \"source\": source,\n                    \"lastUpdated\": current_time,\n                    \"contentHash\": content_hash\n                }\n                \n                if file_path:\n                    properties[\"filePath\"] = file_path\n                    \n                # Create object with vector\n                objects_to_create.append({\n                    \"properties\": properties,\n                    \"vector\": vector\n                })\n\n            # Import objects in batches\n            batch_size = 100\n            for i in range(0, len(objects_to_create), batch_size):\n                batch = objects_to_create[i:i + batch_size]\n                try:\n                    # Use batch import\n                    with collection.batch.dynamic() as batch_writer:\n                        for obj in batch:\n                            batch_writer.add_object(\n                                properties=obj[\"properties\"],\n                                vector=obj[\"vector\"]\n                            )\n                    logging.info(f\"Successfully inserted batch of {len(batch)} chunks for document {doc_id}\")\n                except Exception as e:\n                    logging.error(f\"Error inserting batch: {str(e)}\")\n                    raise\n\n            return doc_id\n\nThis all works, I am able to connect to weaviate, ingest the documents in batches and trigger my prompt with the relevant chunks to Azure OpenAI.\nBut, with that said, the answers I am getting from Azure OpenAI are pretty average and it doesn’t look like it’s considering the knowledge from my internal documents that i’ve passed in as relevant chunks, so this is now where I need to figure out what’s going on.\nCheers\n\n----------\n\n[sebawita (2024-12-17T12:42:33.243Z)]: Can you share an example of how you query your data?\nThis might help us figure out if you could change something about your queries.\n\n----------\n\n[sebawita (2024-12-17T13:15:23.178Z)]: By the way, most Wednesdays we run Office Hours, during which you can ask questions and get help from our experts. Which could help you get this solved \nYou can register here, and we will send you a calendar invite with link to the meeting \nAlso, we run other workshops and other events, you can learn more here",
    "date_created": "2024-12-15T22:55:09.898Z",
    "has_accepted_answer": false,
    "title": "I want to use Azure OpenAI but being asked to provide an OPENAI_APIKEY?",
    "topic_id": 9242
  },
  {
    "user_id": 1517,
    "conversation": "[johtani (2024-09-10T13:26:42.973Z)]: I got an error using Python API v4 example with AI Studio on the\nDocument.\nI can run following vectorizer_config.\n    client.collections.create(\n        name=collection_name,\n        vectorizer_config=[\n            Configure.NamedVectors.text2vec_palm(\n                name=\"title_vector\", \n                source_properties=[\"title\"],\n                model_id=\"text-embedding-004\",\n                api_endpoint=\"generativelanguage.googleapis.com\",\n                project_id=\"\"\n            )\n        ],\n\nI think there are 2 problems.\n\nThe project_id is REQUIRED on Python Client.\nDefault api_endpoint is Vertex AI for text2vec_palm on Server side.\n\nWhat do you  think?\n\n----------\n\n[DudaNogueira (2024-09-11T17:08:18.655Z)]: hi @johtani !!\nWelcome to our community \nThanks for pointing it out.\nWe’ll look into it.\nThanks!",
    "date_created": "2024-09-10T13:26:42.922Z",
    "has_accepted_answer": false,
    "title": "[Docs] Wrong example google embeddings AI Studio Python example",
    "topic_id": 4088
  },
  {
    "user_id": 1493,
    "conversation": "[Anton (2024-09-08T10:08:40.384Z)]: Description\nI’ve deployed the latest Weaviate helm chart (v17.2.1) in our k8s cluster. I’m trying to run it in a single-node configuration. During a startup error message is displayed in logs:\n“error”:“could not join a cluster from [172.16.10.120:8300]”\nBut after that Weaviate seems to start:\nServing weaviate at http://[::]:8080\nUnfortunately shortly after that the server fails with the following error messages:\n“error”:“cannot find peer”,“level”:“error”,“msg”:“transferring leadership”\nSince this is a single-node application there’re no peers, the process fails and a node restarts.\nServer Setup Information\n\nWeaviate Server Version: 1.26.3\nDeployment Method: k8s\nMulti Node? Number of Running Nodes:  1\nClient Language and Version: Python 3.12\nMultitenancy?: Yes\n\nAny additional Information\nI’m running Weaviate with default configuration. And any help will be much appreciated.\n\n----------\n\n[Mohamed_Shahin (2024-09-09T12:35:56.879Z)]: Hey @Anton,\nWelcome to our community! It’s great to have you with us.\nI understand you’re seeing RAFT-related error logs. To explain, RAFT implementation is designed for fault tolerance in multi-node clusters. In a single-node setup, RAFT doesn’t have peers to elect as leader or followers, so when it can’t find peers, leadership transfer can’t proceed, which is why you’re seeing those logs.\nHave you noticed any other errors aside from RAFT?\nWhile these RAFT errors are being logged, in some cases, the leadership failure messages might not cause critical issues, and Weaviate can still function as expected for single nodes.\nA 3-node setup is generally recommended for more stability with RAFT, especially in production environments, but a single-node setup should still work fine in non-critical deployments. If you’re planning to expand or increase fault tolerance later on, a multi-node cluster will give you better stability.\nCould you share more details or the entire log stack with us? Additionally, are there any other errors from the node’s events?\nkubectl describe pod weaviate-0\n\nLooking forward to helping you resolve this!\n\n----------\n\n[Anton (2024-09-09T21:15:50.673Z)]: Mohamed_Shahin:\n\nkubectl describe pod weaviate-0\n\n\n\nHey @Mohamed_Shahin ,\nThank you for getting back to me. The following is Weaviate pod’s description:\nName:             weaviate-0\nNamespace:        infra\nPriority:         0\nService Account:  default\nNode:             gke-main-default-87b2c456-jgm8/10.128.0.71\nStart Time:       Sun, 08 Sep 2024 12:36:56 +0300\nLabels:           app=weaviate\n                  app.kubernetes.io/managed-by=Helm\n                  app.kubernetes.io/name=weaviate\n                  apps.kubernetes.io/pod-index=0\n                  controller-revision-hash=weaviate-7bccb69488\n                  statefulset.kubernetes.io/pod-name=weaviate-0\nAnnotations:      checksum/config: 7355a42cca09eb72943a4bf637082e7f5b24197d19d2f851109b01875a53fba4\nStatus:           Running\nIP:               172.16.10.52\nIPs:\n  IP:           172.16.10.52\nControlled By:  StatefulSet/weaviate\nInit Containers:\n  configure-sysctl:\n    Container ID:  containerd://23be7241f52d8a01cc168f0d9776b50c49dcdc0fe26345be6a128ce0eed50d4a\n    Image:         docker.io/alpine:latest\n    Image ID:      docker.io/library/alpine@sha256:0a4eaa0eecf5f8c050e5bba433f58c052be7587ee8af3e8b3910ef9ab5fbe9f5\n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sysctl\n      -w\n      vm.max_map_count=524288\n      vm.overcommit_memory=1\n    State:          Terminated\n      Reason:       Completed\n      Exit Code:    0\n      Started:      Mon, 09 Sep 2024 23:59:47 +0300\n      Finished:     Mon, 09 Sep 2024 23:59:47 +0300\n    Ready:          True\n    Restart Count:  333\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-tlbt6 (ro)\nContainers:\n  weaviate:\n    Container ID:  containerd://e410a14a74e5b68552ae0d7a3272fa28faa99f372436da3e462f84c1a5fa5c4b\n    Image:         cr.weaviate.io/semitechnologies/weaviate:1.26.3\n    Image ID:      cr.weaviate.io/semitechnologies/weaviate@sha256:ef1fe73f1918a1a4d52187b738f8fbc795f6a1d0cd4d5d6d0706a3ae5a50a03e\n    Ports:         8080/TCP, 50051/TCP\n    Host Ports:    0/TCP, 0/TCP\n    Command:\n      /bin/weaviate\n    Args:\n      --host\n      0.0.0.0\n      --port\n      8080\n      --scheme\n      http\n      --config-file\n      /weaviate-config/conf.yaml\n      --read-timeout=60s\n      --write-timeout=60s\n    State:          Waiting\n      Reason:       CrashLoopBackOff\n    Last State:     Terminated\n      Reason:       Completed\n      Exit Code:    0\n      Started:      Mon, 09 Sep 2024 23:58:16 +0300\n      Finished:     Mon, 09 Sep 2024 23:59:46 +0300\n    Ready:          False\n    Restart Count:  338\n    Liveness:       http-get http://:8080/v1/.well-known/live delay=900s timeout=3s period=10s #success=1 #failure=30\n    Readiness:      http-get http://:8080/v1/.well-known/ready delay=3s timeout=3s period=10s #success=1 #failure=3\n    Environment:\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED:  true\n      CLUSTER_DATA_BIND_PORT:                   7001\n      CLUSTER_DATA_PORT:                        \n      CLUSTER_GOSSIP_BIND_PORT:                 7000\n      CLUSTER_GOSSIP_PORT:                      \n      CLUSTER_HOST:                             \n      CLUSTER_IN_LOCALHOST:                     false\n      DISABLE_TELEMETRY:                        true\n      ENABLE_CLUSTER:                           false\n      GOGC:                                     100\n      LOG_LEVEL:                                debug\n      PROMETHEUS_MONITORING_ENABLED:            false\n      PROMETHEUS_MONITORING_GROUP:              false\n      QUERY_MAXIMUM_RESULTS:                    100000\n      REINDEX_VECTOR_DIMENSIONS_AT_STARTUP:     false\n      TRACK_VECTOR_DIMENSIONS:                  false\n      CLUSTER_BASIC_AUTH_USERNAME:              <set to the key 'username' in secret 'weaviate-cluster-api-basic-auth'>  Optional: false\n      CLUSTER_BASIC_AUTH_PASSWORD:              <set to the key 'password' in secret 'weaviate-cluster-api-basic-auth'>  Optional: false\n      PERSISTENCE_DATA_PATH:                    /var/lib/weaviate\n      DEFAULT_VECTORIZER_MODULE:                none\n      RAFT_JOIN:                                weaviate-0\n      RAFT_BOOTSTRAP_EXPECT:                    1\n      CLUSTER_JOIN:                             weaviate-headless.infra.svc.cluster.local.\n    Mounts:\n      /var/lib/weaviate from weaviate-data (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-tlbt6 (ro)\n      /weaviate-config from weaviate-config (rw)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       False \n  ContainersReady             False \n  PodScheduled                True \nVolumes:\n  weaviate-data:\n    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)\n    ClaimName:  weaviate-data-weaviate-0\n    ReadOnly:   false\n  weaviate-config:\n    Type:      ConfigMap (a volume populated by a ConfigMap)\n    Name:      weaviate-config\n    Optional:  false\n  kube-api-access-tlbt6:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type     Reason   Age                    From     Message\n  ----     ------   ----                   ----     -------\n  Normal   Killing  7m59s (x338 over 35h)  kubelet  Stopping container weaviate\n  Warning  BackOff  4m1s (x8205 over 35h)  kubelet  Back-off restarting failed container weaviate in pod weaviate-0_infra(1eb740cc-e11f-40b2-b30a-ebbcc771716d)\n\nAnd the full log:\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"created startup context, nothing done so far\",\"startup_time_left\":\"59m59.998618881s\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"config_load\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"config_file_path\":\"/weaviate-config/conf.yaml\",\"level\":\"info\",\"msg\":\"Usage of the weaviate.conf.json file is deprecated and will be removed in the future. Please use environment variables.\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"deprecation\":{\"apiType\":\"Configuration\",\"id\":\"config-files\",\"locations\":[\"--config-file=\\\"\\\"\"],\"mitigation\":\"Configure Weaviate using environment variables.\",\"msg\":\"use of deprecated command line argument --config-file\",\"sinceTime\":\"2020-09-08T09:46:00.000Z\",\"sinceVersion\":\"0.22.16\",\"status\":\"deprecated\"},\"level\":\"warning\",\"msg\":\"use of deprecated command line argument --config-file\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"config loaded\",\"startup_time_left\":\"59m59.998157221s\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"configured OIDC and anonymous access client\",\"startup_time_left\":\"59m59.998140071s\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"initialized schema\",\"startup_time_left\":\"59m59.998120461s\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\" memberlist: Initiating push/pull sync with:  172.16.10.52:7000\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=172.16.10.52:46836\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"startup routine complete\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"start registering modules\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"completed registering modules\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"module offload-s3 is not enabled\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"cluster_api_startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"serving cluster api on port 7001\",\"port\":7001,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"start initializing modules\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"finished initializing modules\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"weaviate-0\":8300},\"time\":\"2024-09-09T21:04:49Z\"}\n{\"address\":\"172.16.10.52:8301\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"address\":\"172.16.10.52:8300\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"weaviate-0\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":\"1449-1452-1725915496176\",\"last-index\":1452,\"last-term\":1449,\"level\":\"info\",\"msg\":\"starting restore from snapshot\",\"size-in-bytes\":78,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"restoring schema from snapshot\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"successfully restored schema from snapshot\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"graphql_rebuild\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"rebuilding the graphql schema\",\"schema\":{\"Objects\":{\"classes\":[]}},\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"last_applied_index\":1452,\"last_snapshot_index\":1452,\"last_store_log_applied_index\":1452,\"level\":\"info\",\"msg\":\"successfully reloaded indexes from snapshot\",\"n\":0,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":\"1449-1452-1725915496176\",\"last-index\":1452,\"last-term\":1449,\"level\":\"info\",\"msg\":\"snapshot restore progress\",\"percent-complete\":\"[100.00]%\",\"read-bytes\":78,\"size-in-bytes\":78,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":\"1449-1452-1725915496176\",\"last-index\":1452,\"last-term\":1449,\"level\":\"info\",\"msg\":\"restored from snapshot\",\"size-in-bytes\":78,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"index\":1,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:weaviate-0 Address:172.16.10.51:8301}]]\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"raft_cluster_recovery\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"existed_single_cluster_node\":{\"Suffrage\":0,\"ID\":\"weaviate-0\",\"Address\":\"172.16.10.51:8301\"},\"level\":\"info\",\"msg\":\"perform cluster recovery\",\"new_single_cluster_node\":{\"Suffrage\":0,\"ID\":\"weaviate-0\",\"Address\":\"172.16.10.52:8301\"},\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"restoring schema from snapshot\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"successfully restored schema from snapshot\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"graphql_rebuild\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"rebuilding the graphql schema\",\"schema\":{\"Objects\":{\"classes\":[]}},\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"last_applied_index\":1452,\"last_snapshot_index\":1452,\"last_store_log_applied_index\":1452,\"level\":\"info\",\"msg\":\"successfully reloaded indexes from snapshot\",\"n\":0,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":\"1449-1452-1725915496176\",\"last-index\":1452,\"last-term\":1449,\"level\":\"info\",\"msg\":\"snapshot restore progress\",\"percent-complete\":\"[100.00]%\",\"read-bytes\":78,\"size-in-bytes\":78,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"persisting snapshot\",\"time\":\"2024-09-09T21:04:49Z\"}\n2024-09-09T21:04:49.184Z [INFO]  snapshot: creating new snapshot: path=/var/lib/weaviate/raft/snapshots/1450-1453-1725915889184.tmp\n2024-09-09T21:04:49.194Z [INFO]  snapshot: reaping snapshot: path=/var/lib/weaviate/raft/snapshots/1447-1450-1725914796170\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":\"1450-1453-1725915889184\",\"last-index\":1453,\"last-term\":1450,\"level\":\"info\",\"msg\":\"starting restore from snapshot\",\"size-in-bytes\":78,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"restoring schema from snapshot\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"successfully restored schema from snapshot\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"graphql_rebuild\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"rebuilding the graphql schema\",\"schema\":{\"Objects\":{\"classes\":[]}},\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"last_applied_index\":1452,\"last_snapshot_index\":1453,\"last_store_log_applied_index\":1452,\"level\":\"info\",\"msg\":\"successfully reloaded indexes from snapshot\",\"n\":0,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":\"1450-1453-1725915889184\",\"last-index\":1453,\"last-term\":1450,\"level\":\"info\",\"msg\":\"snapshot restore progress\",\"percent-complete\":\"[100.00]%\",\"read-bytes\":78,\"size-in-bytes\":78,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":\"1450-1453-1725915889184\",\"last-index\":1453,\"last-term\":1450,\"level\":\"info\",\"msg\":\"restored from snapshot\",\"size-in-bytes\":78,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"index\":1,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:weaviate-0 Address:172.16.10.52:8301}]]\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-09-09T21:04:49Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"last_snapshot_index\":1453,\"last_store_applied_index_on_start\":1452,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":1453,\"raft_last_index\":1453,\"time\":\"2024-09-09T21:04:49Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-09-09T21:04:50Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":1451,\"time\":\"2024-09-09T21:04:50Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":\"weaviate-0\",\"level\":\"debug\",\"msg\":\"raft voting for self\",\"term\":1451,\"time\":\"2024-09-09T21:04:50Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"raft calculated votes needed\",\"needed\":1,\"term\":1451,\"time\":\"2024-09-09T21:04:50Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"from\":\"weaviate-0\",\"level\":\"debug\",\"msg\":\"raft vote granted\",\"tally\":1,\"term\":1451,\"time\":\"2024-09-09T21:04:50Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":1451,\"time\":\"2024-09-09T21:04:50Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-09-09T21:04:50Z\"}\n{\"action\":\"bootstrap\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"action\":\"inverted filter2search migration\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"migration skip flag set, skipping migration\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"action\":\"inverted filter2search migration\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"starting switching fallback mode\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"action\":\"inverted filter2search migration\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"no missing filterable indexes, fallback mode skipped\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"docker_image_tag\":\"1.26.3\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.3\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"action\":\"grpc_startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"address\":\"172.16.10.52:8300\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"starting migration from old schema\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"legacy schema is empty, nothing to migrate\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"migration from the old schema has been successfully completed\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"action\":\"restapi_management\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"docker_image_tag\":\"1.26.3\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2024-09-09T21:04:51Z\"}\n{\"action\":\"restapi_management\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"docker_image_tag\":\"1.26.3\",\"level\":\"info\",\"msg\":\"Shutting down... \",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"action\":\"restapi_management\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"docker_image_tag\":\"1.26.3\",\"level\":\"info\",\"msg\":\"Stopped serving weaviate at http://[::]:8080\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing raft FSM store ...\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"shutting down raft sub-system ...\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"transferring leadership to another server\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"action\":\"raft\",\"address\":null,\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":null,\"level\":\"debug\",\"msg\":\"raft starting leadership transfer\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"raft cannot find peer\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"cannot find peer\",\"level\":\"error\",\"msg\":\"transferring leadership\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing raft-net ...\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing log store ...\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing data store ...\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing loaded database ...\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing raft-rpc client ...\",\"time\":\"2024-09-09T21:06:12Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing raft-rpc server ...\",\"time\":\"2024-09-09T21:06:12Z\"}\n\nPlease let me know if you need any additional information and thanks for the help.\n\n----------\n\n[Mohamed_Shahin (2024-09-11T15:30:30.818Z)]: Hey @Anton,\nCould you please provide us with the .yaml file? I’d like to try reproducing the issue.\nAlso, is this a fresh installation, or are you editing the config and restarting the node?\n\n----------\n\n[Anton (2024-09-11T22:31:47.725Z)]: Hey @Mohamed_Shahin ,\nIn terms of configuration, we’ve deployed the latest (17.2.1) Weaviate helm chart to our k8s cluster (v1.29) running in GCP. The installation is fresh and the following is a configuration:\n  replicas: 3\n  env:\n    LOG_LEVEL: 'debug'\n\nCurrently in  three-node configuration the following is the full log of one of the replicas between crashes:\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"created startup context, nothing done so far\",\"startup_time_left\":\"59m59.99858618s\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"config_load\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"config_file_path\":\"/weaviate-config/conf.yaml\",\"level\":\"info\",\"msg\":\"Usage of the weaviate.conf.json file is deprecated and will be removed in the future. Please use environment variables.\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"deprecation\":{\"apiType\":\"Configuration\",\"id\":\"config-files\",\"locations\":[\"--config-file=\\\"\\\"\"],\"mitigation\":\"Configure Weaviate using environment variables.\",\"msg\":\"use of deprecated command line argument --config-file\",\"sinceTime\":\"2020-09-08T09:46:00.000Z\",\"sinceVersion\":\"0.22.16\",\"status\":\"deprecated\"},\"level\":\"warning\",\"msg\":\"use of deprecated command line argument --config-file\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"config loaded\",\"startup_time_left\":\"59m59.99818449s\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"configured OIDC and anonymous access client\",\"startup_time_left\":\"59m59.99815745s\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"initialized schema\",\"startup_time_left\":\"59m59.99814683s\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\" memberlist: Failed to join 172.16.17.159:7000: dial tcp 172.16.17.159:7000: connect: connection refused\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\" memberlist: Failed to join 172.16.4.116:7000: dial tcp 172.16.4.116:7000: connect: connection refused\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\" memberlist: Initiating push/pull sync with:  172.16.9.130:7000\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=172.16.9.130:41992\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"startup routine complete\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"start registering modules\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"completed registering modules\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"module offload-s3 is not enabled\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"start initializing modules\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"finished initializing modules\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"cluster_api_startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"serving cluster api on port 7001\",\"port\":7001,\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"weaviate-0\":8300,\"weaviate-1\":8300,\"weaviate-2\":8300},\"time\":\"2024-09-11T22:28:05Z\"}\n{\"address\":\"172.16.9.130:8301\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"address\":\"172.16.9.130:8300\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"weaviate-1\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"index\":340,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:weaviate-0 Address:172.16.4.110:8300} {Suffrage:Voter ID:weaviate-2 Address:172.16.17.144:8300} {Suffrage:Voter ID:weaviate-1 Address:172.16.9.51:8300}]]\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"last_snapshot_index\":0,\"last_store_applied_index_on_start\":0,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":346,\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-09-11T22:28:05Z\"}\n{\"action\":\"bootstrap\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"could not join a cluster from [172.16.9.130:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"172.16.9.130:8300\"],\"time\":\"2024-09-11T22:28:06Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"expect\":3,\"got\":{\"weaviate-1\":\"172.16.9.130:8300\"},\"level\":\"debug\",\"msg\":\"number of candidates lower than bootstrap expect param, stopping notify\",\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"bootstrap\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"172.16.9.130:8300\"],\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":7112,\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"raft\",\"address\":\"172.16.4.110:8300\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"from\":\"weaviate-0\",\"level\":\"debug\",\"msg\":\"raft asking for vote\",\"term\":7112,\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"raft\",\"address\":\"172.16.17.144:8300\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"from\":\"weaviate-2\",\"level\":\"debug\",\"msg\":\"raft asking for vote\",\"term\":7112,\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":\"weaviate-1\",\"level\":\"debug\",\"msg\":\"raft voting for self\",\"term\":7112,\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"could not resolve server id weaviate-0\",\"fallback\":\"172.16.4.110:8300\",\"id\":\"weaviate-0\",\"level\":\"warning\",\"msg\":\"raft-net unable to get address for server, using fallback address\",\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"could not resolve server id weaviate-2\",\"fallback\":\"172.16.17.144:8300\",\"id\":\"weaviate-2\",\"level\":\"warning\",\"msg\":\"raft-net unable to get address for server, using fallback address\",\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"raft calculated votes needed\",\"needed\":2,\"term\":7112,\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"from\":\"weaviate-1\",\"level\":\"debug\",\"msg\":\"raft vote granted\",\"tally\":1,\"term\":7112,\"time\":\"2024-09-11T22:28:06Z\"}\n{\"action\":\"inverted filter2search migration\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"migration skip flag set, skipping migration\",\"time\":\"2024-09-11T22:28:07Z\"}\n{\"action\":\"inverted filter2search migration\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"starting switching fallback mode\",\"time\":\"2024-09-11T22:28:07Z\"}\n{\"action\":\"inverted filter2search migration\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"no missing filterable indexes, fallback mode skipped\",\"time\":\"2024-09-11T22:28:07Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"docker_image_tag\":\"1.26.3\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.3\",\"time\":\"2024-09-11T22:28:07Z\"}\n{\"action\":\"grpc_startup\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-09-11T22:28:07Z\"}\n{\"action\":\"restapi_management\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"docker_image_tag\":\"1.26.3\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2024-09-11T22:28:07Z\"}\n{\"action\":\"bootstrap\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"could not join a cluster from [172.16.9.130:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"172.16.9.130:8300\"],\"time\":\"2024-09-11T22:28:07Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"expect\":3,\"got\":{\"weaviate-1\":\"172.16.9.130:8300\"},\"level\":\"debug\",\"msg\":\"number of candidates lower than bootstrap expect param, stopping notify\",\"time\":\"2024-09-11T22:28:07Z\"}\n{\"action\":\"bootstrap\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"172.16.9.130:8300\"],\"time\":\"2024-09-11T22:28:07Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=172.16.4.116:42192\",\"time\":\"2024-09-11T22:28:07Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"warning\",\"msg\":\"raft Election timeout reached, restarting election\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":7113,\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"address\":\"172.16.4.110:8300\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"from\":\"weaviate-0\",\"level\":\"debug\",\"msg\":\"raft asking for vote\",\"term\":7113,\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"address\":\"172.16.17.144:8300\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"from\":\"weaviate-2\",\"level\":\"debug\",\"msg\":\"raft asking for vote\",\"term\":7113,\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":\"weaviate-1\",\"level\":\"debug\",\"msg\":\"raft voting for self\",\"term\":7113,\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"could not resolve server id weaviate-2\",\"fallback\":\"172.16.17.144:8300\",\"id\":\"weaviate-2\",\"level\":\"warning\",\"msg\":\"raft-net unable to get address for server, using fallback address\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"msg\":\"raft calculated votes needed\",\"needed\":2,\"term\":7113,\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"from\":\"weaviate-1\",\"level\":\"debug\",\"msg\":\"raft vote granted\",\"tally\":1,\"term\":7113,\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"from\":\"weaviate-0\",\"level\":\"debug\",\"msg\":\"raft vote granted\",\"tally\":2,\"term\":7113,\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":2,\"term\":7113,\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"raft added peer, starting replication\",\"peer\":\"weaviate-0\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"raft added peer, starting replication\",\"peer\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"could not resolve server id weaviate-2\",\"fallback\":\"172.16.17.144:8300\",\"id\":\"weaviate-2\",\"level\":\"warning\",\"msg\":\"raft-net unable to get address for server, using fallback address\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"warning\",\"msg\":\"raft appendEntries rejected, sending older logs\",\"next\":346,\"peer\":{\"Suffrage\":0,\"ID\":\"weaviate-0\",\"Address\":\"172.16.4.110:8300\"},\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"raft pipelining replication\",\"peer\":{\"Suffrage\":0,\"ID\":\"weaviate-0\",\"Address\":\"172.16.4.110:8300\"},\"time\":\"2024-09-11T22:28:08Z\"}\n{\"address\":\"172.16.9.130:8300\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"starting migration from old schema\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"legacy schema is empty, nothing to migrate\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"migration from the old schema has been successfully completed\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"could not resolve server id weaviate-2\",\"fallback\":\"172.16.17.144:8300\",\"id\":\"weaviate-2\",\"level\":\"warning\",\"msg\":\"raft-net unable to get address for server, using fallback address\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":501887355,\"level\":\"warning\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"bootstrap\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-09-11T22:28:08Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":970415071,\"level\":\"warning\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:09Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":1415676468,\"level\":\"warning\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:09Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":1849860337,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:09Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":2298746284,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:10Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":2734670652,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:10Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":3233415067,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:11Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":3716153072,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:11Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":4190246908,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:12Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":4684010383,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:12Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":5120811571,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:13Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":5592213807,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:13Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":6086457392,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:14Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":6563357968,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:14Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"fields.time\":7028038025,\"level\":\"debug\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-09-11T22:28:15Z\"}\n{\"action\":\"restapi_management\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"docker_image_tag\":\"1.26.3\",\"level\":\"info\",\"msg\":\"Shutting down... \",\"time\":\"2024-09-11T22:28:15Z\"}\n{\"action\":\"restapi_management\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"docker_image_tag\":\"1.26.3\",\"level\":\"info\",\"msg\":\"Stopped serving weaviate at http://[::]:8080\",\"time\":\"2024-09-11T22:28:15Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing raft FSM store ...\",\"time\":\"2024-09-11T22:28:15Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"shutting down raft sub-system ...\",\"time\":\"2024-09-11T22:28:15Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"transferring leadership to another server\",\"time\":\"2024-09-11T22:28:15Z\"}\n{\"action\":\"raft\",\"address\":null,\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"id\":null,\"level\":\"debug\",\"msg\":\"raft starting leadership transfer\",\"time\":\"2024-09-11T22:28:15Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"successfully transferred leadership to another server\",\"time\":\"2024-09-11T22:28:15Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"raft aborting pipeline replication\",\"peer\":{\"Suffrage\":0,\"ID\":\"weaviate-0\",\"Address\":\"172.16.4.110:8300\"},\"time\":\"2024-09-11T22:28:15Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"local-address\":\"172.16.9.130:8300\",\"msg\":\"raft-net accepted connection\",\"remote-address\":\"172.16.4.116:46818\",\"time\":\"2024-09-11T22:28:15Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"dial tcp 172.16.4.110:8300: i/o timeout\",\"level\":\"error\",\"msg\":\"raft failed to make requestVote RPC\",\"target\":{\"Suffrage\":0,\"ID\":\"weaviate-0\",\"Address\":\"172.16.4.110:8300\"},\"term\":7112,\"time\":\"2024-09-11T22:28:16Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"dial tcp 172.16.17.144:8300: i/o timeout\",\"level\":\"error\",\"msg\":\"raft failed to make requestVote RPC\",\"target\":{\"Suffrage\":0,\"ID\":\"weaviate-2\",\"Address\":\"172.16.17.144:8300\"},\"term\":7112,\"time\":\"2024-09-11T22:28:16Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"local-address\":\"172.16.9.130:8300\",\"msg\":\"raft-net accepted connection\",\"remote-address\":\"172.16.4.116:46832\",\"time\":\"2024-09-11T22:28:17Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"dial tcp 172.16.17.144:8300: i/o timeout\",\"level\":\"error\",\"msg\":\"raft failed to make requestVote RPC\",\"target\":{\"Suffrage\":0,\"ID\":\"weaviate-2\",\"Address\":\"172.16.17.144:8300\"},\"term\":7113,\"time\":\"2024-09-11T22:28:18Z\"}\n{\"action\":\"raft\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"dial tcp 172.16.17.144:8300: i/o timeout\",\"level\":\"error\",\"msg\":\"raft failed to appendEntries to\",\"peer\":{\"Suffrage\":0,\"ID\":\"weaviate-2\",\"Address\":\"172.16.17.144:8300\"},\"time\":\"2024-09-11T22:28:18Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"debug\",\"local-address\":\"172.16.9.130:8300\",\"msg\":\"raft-net accepted connection\",\"remote-address\":\"172.16.4.116:46846\",\"time\":\"2024-09-11T22:28:18Z\"}\n{\"action\":\"raft\",\"backoff time\":10000000,\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"dial tcp 172.16.17.144:8300: i/o timeout\",\"level\":\"error\",\"msg\":\"raft failed to heartbeat to\",\"peer\":\"172.16.17.144:8300\",\"time\":\"2024-09-11T22:28:18Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"transport shutdown\",\"level\":\"error\",\"msg\":\"raft-net failed to decode incoming command\",\"time\":\"2024-09-11T22:28:18Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing raft-net ...\",\"time\":\"2024-09-11T22:28:18Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing log store ...\",\"time\":\"2024-09-11T22:28:18Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"transport shutdown\",\"level\":\"error\",\"msg\":\"raft-net failed to decode incoming command\",\"time\":\"2024-09-11T22:28:18Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing data store ...\",\"time\":\"2024-09-11T22:28:18Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing loaded database ...\",\"time\":\"2024-09-11T22:28:18Z\"}\n{\"action\":\"raft-net\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"error\":\"transport shutdown\",\"level\":\"error\",\"msg\":\"raft-net failed to decode incoming command\",\"time\":\"2024-09-11T22:28:18Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing raft-rpc client ...\",\"time\":\"2024-09-11T22:28:18Z\"}\n{\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"level\":\"info\",\"msg\":\"closing raft-rpc server ...\",\"time\":\"2024-09-11T22:28:18Z\"}\n\nThanks for the help, mate!\n\n----------\n\n[Mohamed_Shahin (2024-09-20T09:27:47.577Z)]: Hey @Anton ,\nI’ve attempted the same deployment, and everything worked fine on my end! I wonder if it’s specific to your GCP.\nIs the issue still happening? Try deleting the pod and initializing it again to see if that resolves it.\nCheck the logs for this pod:\n\n\n\n Mohamed_Shahin:\n\nkubectl describe pod weaviate-2\n\n----------\n\n[Anton (2024-09-23T07:51:36.766Z)]: Hey @Mohamed_Shahin ,\nI agree that it looks like the issue is related to our infrastructure configuration. I’m going to look into this with our DevOps team. For now we’re going forward with testing an Enterprise Cloud solution and will revisit VPC deployment at a later stage.\nThank you for your help!",
    "date_created": "2024-09-08T10:08:40.332Z",
    "has_accepted_answer": true,
    "title": "Single-node in k8s deployment issue",
    "topic_id": 4018
  },
  {
    "user_id": 9593,
    "conversation": "[ryansamu5 (2025-03-11T09:08:36.980Z)]: Description\nSeems like weaviate is not initializing properly. I’m unable to create a class as noted by the transaction-entry container log stated below Error creating schema class: status code: 422, error: {\"error\":[{\"message\":\"leader not found\"}]}\nWeaviate is supposed be run as a single-node but it looks like it’s trying to join a cluster and look for a leader which there is none because I only have one instance using docker compose\nIs there a way to force it to run as a single-node? Is something wrong with my configuration?\nAlso note that I’m using AWS EFS as my volume\nServer Setup Information\n\nWeaviate Server Version: 1.29.0\nDeployment Method: AWS EC2 t2.micro as Docker host, Docker version 28.0.1, build 068a01e\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: go version go1.23.2 linux/amd64\nMultitenancy?: no sure, probably not\n\nAny additional Information\ndocker-compose.yml\nservices:\n  knomor-gateway:\n    build: ./knomor-gateway\n    container_name: knomor-gateway\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    networks:\n      - knomor-network\n\n  transaction-entry:\n    build: ./transaction-entry\n    container_name: transaction-entry\n    networks:\n      - knomor-network\n    expose:\n      - \"9030\"\n    depends_on:\n      - weaviate\n\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.29.0\n    container_name: weaviate\n    networks:\n      - knomor-network\n    expose:\n      - \"8080\"\n      - \"50051\"\n    volumes:\n      - /mnt/knomor-efs:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: \"true\"\n      PERSISTENCE_DATA_PATH: \"/var/lib/weaviate\"\n      ENABLE_MODULES: \"text2vec-openai\"\n      RAFT_JOIN: \"weaviate-0\"\n      RAFT_BOOTSTRAP_EXPECT: 1\n      LIMIT_RESOURCES: true\n      OPENAI_API_KEY: <api-key>\n\nnetworks:\n  knomor-network:\n    driver: bridge\n\nmain.go\nfunc main() {\n\tctx := context.Background()\n\n\t// init godotenv\n\terr := godotenv.Load()\n\tif err != nil {\n\t\tlog.Fatal(\"Error loading .env file\")\n\t}\n\n\t// init db\n\tvar dbURL string\n\tif os.Getenv(\"DATABASE_URL\") != \"\" {\n\t\tdbURL = os.Getenv(\"DATABASE_URL\")\n\t} else {\n\t\tlog.Fatal(\"Error: No DATABASE_URL environment variable found: main.go: run() -> os.Getenv(\\\"DATABASE_URL\\\")\")\n\t}\n\n\tdbpool, err := pgxpool.New(ctx, dbURL)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Unable to create connection pool: %v\\n; main.go: run() -> pgxpool.New()\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer dbpool.Close()\n\n\tqueries := db.New(dbpool)\n\n\t// init weaviate db\n\tcfg := weaviate.Config{\n\t\tHost:   \"weaviate:8080\",\n\t\tScheme: \"http\",\n\t}\n\n\tclient, err := weaviate.NewClient(cfg)\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n\n\t// Check the weaviate db connection\n\tready, err := client.Misc().ReadyChecker().Do(context.Background())\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfmt.Println(\"vector store is ready: \", ready)\n\n\t// Log weaviate configuration meta data\n\tmeta, err := client.Misc().MetaGetter().Do(context.Background())\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfmt.Println(\"weaviate config mata data: \", meta)\n\n\t// Check if POPULATE_WEAVIATE mode is enabled in the .env file\n\tif os.Getenv(\"POPULATE_WEAVIATE\") == \"true\" {\n\t\tstandalones.PopulateWeaviate(ctx, queries, client)\n\t\treturn\n\t}\n        ...\n}\n\npopulateWeaviate.go\nfunc PopulateWeaviate(ctx context.Context, queries *db.Queries, client *weaviate.Client) {\n\t// Define the schema for our class.\n\tclassObj := &models.Class{\n\t\tClass: \"LabeledTransaction\",\n\t\tVectorConfig: map[string]models.VectorConfig{\n\t\t\t\"description_vector\": {\n\t\t\t\tVectorizer: map[string]interface{}{\n\t\t\t\t\t\"text2vec-openai\": map[string]interface{}{\n\t\t\t\t\t\t\"sourceProperties\": []string{\"description\"},\n\t\t\t\t\t\t\"model\":            \"text-embedding-3-small\",\n\t\t\t\t\t\t\"dimensions\":       1536, // Optional (e.g. 1536, 512) for text-embedding-3-small\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tVectorIndexType: \"hnsw\",\n\t\t\t},\n\t\t},\n\t\tProperties: []*models.Property{\n\t\t\t{\n\t\t\t\tDataType: []string{\"text\"},\n\t\t\t\tName:     \"description\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tDataType: []string{\"string[]\"},\n\t\t\t\tName:     \"labels\",\n\t\t\t},\n\t\t},\n\t}\n\n\terr := client.Schema().ClassCreator().WithClass(classObj).Do(ctx)\n\tif err != nil {\n\t\tfmt.Println(\"Error creating schema class:\", err)\n\t\treturn\n\t} else {\n\t\tfmt.Println(\"Weaviate schema created successfully.\")\n\t}\n        ....\n}\n\ntransaction-entry container logs:\nvector store is ready:  false\nweaviate config mata data:  &{http://[::]:8080 map[text2vec-openai:map[documentationHref:https://platform.openai.com/docs/guides/embeddings/what-are-embeddings name:OpenAI Module]] 1.29.0}\nError creating schema class: status code: 422, error: {“error”:[{“message”:“leader not found”}]}\nweaviate container logs:\n{“action”:“startup”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“error”:“could not join raft join list: context deadline exceeded. Weaviate detected this node to have state stored. If the DB is still loading up we will hit this timeout. You can try increasing/setting RAFT_BOOTSTRAP_TIMEOUT env variable to a higher value.”,“level”:“fatal”,“msg”:“could not open cloud meta store”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“warning”,“log_level_env”:“”,“msg”:“log level not recognized, defaulting to info”,“time”:“2025-03-11T08:39:34Z”}\n{“action”:“startup”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“Feature flag LD integration disabled: could not locate WEAVIATE_LD_API_KEY env variable”,“time”:“2025-03-11T08:39:34Z”}\n{“action”:“startup”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“default_vectorizer_module”:“none”,“level”:“info”,“msg”:“the default vectorizer modules is set to \"none\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer”,“time”:“2025-03-11T08:39:34Z”}\n{“action”:“startup”,“auto_schema_enabled”:true,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“auto schema enabled setting is set to \"true\"”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“Limiting resources: memory: 80%, cores: all but one”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“limit”:0,“msg”:“Set memory limit”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“module offload-s3 is enabled”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“flag_key”:“collection-retrieval-strategy”,“level”:“info”,“msg”:“feature flag instantiated”,“time”:“2025-03-11T08:39:34Z”,“tool”:“feature_flag”,“value”:“LeaderOnly”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“warning”,“msg”:“Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“open cluster service”,“servers”:{“weaviate-0”:8300},“time”:“2025-03-11T08:39:34Z”}\n{“address”:“172.18.0.5:8301”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“starting cloud rpc server …”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“starting raft sub-system …”,“time”:“2025-03-11T08:39:34Z”}\n{“address”:“172.18.0.5:8300”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“tcp transport”,“tcpMaxPool”:3,“tcpTimeout”:10000000000,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“loading local db”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“local DB successfully loaded”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“schema manager loaded”,“n”:0,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“metadata_only_voters”:false,“msg”:“construct a new raft node”,“name”:“4eafcef84a52”,“time”:“2025-03-11T08:39:34Z”}\n{“action”:“raft”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“index”:1,“level”:“info”,“msg”:“initial configuration”,“servers”:“[[{Suffrage:Voter ID:4fec3d6ddd53 Address:172.18.0.7:8300}]]”,“time”:“2025-03-11T08:39:34Z”}\n{“action”:“raft”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“follower”:{},“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“entering follower state”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“last_snapshot_index”:0,“last_store_applied_index_on_start”:0,“level”:“info”,“msg”:“raft node constructed”,“raft_applied_index”:0,“raft_last_index”:2,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“hasState”:true,“level”:“info”,“msg”:“raft init”,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:,“time”:“2025-03-11T08:39:34Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:,“time”:“2025-03-11T08:39:35Z”}\n{“action”:“raft”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“warning”,“msg”:“heartbeat timeout reached, not part of a stable configuration or a non-voter, not triggering a leader election”,“time”:“2025-03-11T08:39:36Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“configured versions”,“server_version”:“1.29.0”,“time”:“2025-03-11T08:39:36Z”,“version”:“1.29.0”}\n{“action”:“grpc_startup”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“grpc server listening at [::]:50051”,“time”:“2025-03-11T08:39:36Z”}\n{“action”:“restapi_management”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“Serving weaviate at http://[::]:8080”,“time”:“2025-03-11T08:39:36Z”,“version”:“1.29.0”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:,“time”:“2025-03-11T08:39:36Z”}\n{“action”:“telemetry_push”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“telemetry started”,“payload”:“\\u0026{MachineID:b5e46904-afeb-4d66-b4a4-81326cc7e437 Type:INIT Version:1.29.0 ObjectsCount:0 OS:linux Arch:amd64 UsedModules: CollectionsCount:0}”,“time”:“2025-03-11T08:39:37Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:,“time”:“2025-03-11T08:39:37Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:,“time”:“2025-03-11T08:39:38Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:,“time”:“2025-03-11T08:39:39Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:,“time”:“2025-03-11T08:39:40Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:,“time”:“2025-03-11T08:39:41Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:,“time”:“2025-03-11T08:39:42Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:,“time”:“2025-03-11T08:39:43Z”}\n\n----------\n\n[Mohamed_Shahin (2025-03-11T12:35:33.518Z)]: Hey @ryansamu5,\nIt’s lovely to have you here in our community, and I’m looking forward to seeing you with us!\nSince this is a single-node cluster, can you remove the RAFT env from your Docker setup and retry?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nDocker | Weaviate\n\n  Weaviate supports deployment with Docker.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nRAFT_JOIN: \"weaviate-0\"\nRAFT_BOOTSTRAP_EXPECT: 1\n\nAdditionally, you can add:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nDocker | Weaviate\n\n  Weaviate supports deployment with Docker.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nCLUSTER_HOSTNAME: 'node1'\n\nLet me know if that helps.\nRegards,\nMohamed Shahin\nWeaviate Support\n\n----------\n\n[ryansamu5 (2025-03-11T18:39:03.366Z)]: Mohamed_Shahin:\n\nCLUSTER_HOSTNAME: 'node1'\n\n\nAfter the changes it’s still seeming to locate a leader and my program still exits due to this error.\ndocker-compose.yml:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.29.0\n    container_name: weaviate\n    networks:\n      - knomor-network\n    expose:\n      - \"8080\"\n      - \"50051\"\n    volumes:\n      - /mnt/knomor-efs:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: \"true\"\n      PERSISTENCE_DATA_PATH: \"/var/lib/weaviate\"\n      ENABLE_MODULES: \"text2vec-openai\"\n      LIMIT_RESOURCES: true\n      CLUSTER_HOSTNAME: \"node1\"\n      OPENAI_API_KEY: <api-key>\n\ntransaction-entry container logs:\nvector store is ready:  false\nweaviate config mata data:  &{http://[::]:8080 map[text2vec-openai:map[documentationHref:https://platform.openai.com/docs/guides/embeddings/what-are-embeddings name:OpenAI Module]] 1.29.0}\nError creating schema class: status code: 422, error: {“error”:[{“message”:“leader not found”}]}\nweaviate container logs:\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“warning”,“log_level_env”:“”,“msg”:“log level not recognized, defaulting to info”,“time”:“2025-03-11T18:29:14Z”}\n{“action”:“startup”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“Feature flag LD integration disabled: could not locate WEAVIATE_LD_API_KEY env variable”,“time”:“2025-03-11T18:29:14Z”}\n{“action”:“startup”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“default_vectorizer_module”:“none”,“level”:“info”,“msg”:“the default vectorizer modules is set to \"none\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer”,“time”:“2025-03-11T18:29:14Z”}\n{“action”:“startup”,“auto_schema_enabled”:true,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“auto schema enabled setting is set to \"true\"”,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“Limiting resources: memory: 80%, cores: all but one”,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“limit”:0,“msg”:“Set memory limit”,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“module offload-s3 is enabled”,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“flag_key”:“collection-retrieval-strategy”,“level”:“info”,“msg”:“feature flag instantiated”,“time”:“2025-03-11T18:29:14Z”,“tool”:“feature_flag”,“value”:“LeaderOnly”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“warning”,“msg”:“Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.”,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“open cluster service”,“servers”:{“node1”:8300},“time”:“2025-03-11T18:29:14Z”}\n{“address”:“172.18.0.5:8301”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“starting cloud rpc server …”,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“starting raft sub-system …”,“time”:“2025-03-11T18:29:14Z”}\n{“address”:“172.18.0.5:8300”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“tcp transport”,“tcpMaxPool”:3,“tcpTimeout”:10000000000,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“loading local db”,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“local DB successfully loaded”,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“schema manager loaded”,“n”:0,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“metadata_only_voters”:false,“msg”:“construct a new raft node”,“name”:“node1”,“time”:“2025-03-11T18:29:14Z”}\n{“action”:“raft”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“index”:1,“level”:“info”,“msg”:“initial configuration”,“servers”:“[[{Suffrage:Voter ID:4fec3d6ddd53 Address:172.18.0.7:8300}]]”,“time”:“2025-03-11T18:29:14Z”}\n{“action”:“raft”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“follower”:{},“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“entering follower state”,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“last_snapshot_index”:0,“last_store_applied_index_on_start”:0,“level”:“info”,“msg”:“raft node constructed”,“raft_applied_index”:0,“raft_last_index”:2,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“hasState”:true,“level”:“info”,“msg”:“raft init”,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.18.0.5:8300”],“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.18.0.5:8300”,“status”:8,“time”:“2025-03-11T18:29:14Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.18.0.5:8300”],“time”:“2025-03-11T18:29:15Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.18.0.5:8300”,“status”:8,“time”:“2025-03-11T18:29:15Z”}\n{“action”:“raft”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“warning”,“msg”:“heartbeat timeout reached, not part of a stable configuration or a non-voter, not triggering a leader election”,“time”:“2025-03-11T18:29:15Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“configured versions”,“server_version”:“1.29.0”,“time”:“2025-03-11T18:29:16Z”,“version”:“1.29.0”}\n{“action”:“grpc_startup”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“grpc server listening at [::]:50051”,“time”:“2025-03-11T18:29:16Z”}\n{“action”:“restapi_management”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“Serving weaviate at http://[::]:8080”,“time”:“2025-03-11T18:29:16Z”,“version”:“1.29.0”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.18.0.5:8300”],“time”:“2025-03-11T18:29:16Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.18.0.5:8300”,“status”:8,“time”:“2025-03-11T18:29:16Z”}\n{“action”:“telemetry_push”,“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“telemetry started”,“payload”:“\\u0026{MachineID:f791d4ec-1dda-432b-83e8-39b1011e41bc Type:INIT Version:1.29.0 ObjectsCount:0 OS:linux Arch:amd64 UsedModules: CollectionsCount:0}”,“time”:“2025-03-11T18:29:17Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.18.0.5:8300”],“time”:“2025-03-11T18:29:17Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.18.0.5:8300”,“status”:8,“time”:“2025-03-11T18:29:17Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“172.18.0.5:8300”],“time”:“2025-03-11T18:29:18Z”}\n{“build_git_commit”:“35d800d”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.29.0”,“build_wv_version”:“1.29.0”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“172.18.0.5:8300”,“status”:8,“time”:“2025-03-11T18:29:18Z”}\n\n----------\n\n[DudaNogueira (2025-03-13T12:11:44.290Z)]: hi @ryansamu5 !\nCan you try this docker compose?\nNote: I removed the network, changed the volumes to a local folder, and mapped the ports 8080 and 50051 and passed OPENAI_API_KEY as and ENV VAR.:\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.29.0\n    container_name: weaviate\n    #networks:\n    #  - knomor-network\n    expose:\n      - \"8080\"\n      - \"50051\"\n    ports:\n      - 8080:8080\n      - 50051:50051\n    volumes:\n      - ./data/:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: \"true\"\n      PERSISTENCE_DATA_PATH: \"/var/lib/weaviate\"\n      ENABLE_MODULES: \"text2vec-openai\"\n      LIMIT_RESOURCES: true\n      CLUSTER_HOSTNAME: \"node1\"\n      OPENAI_API_KEY: $OPENAI_API_KEY",
    "date_created": "2025-03-11T09:08:36.901Z",
    "has_accepted_answer": false,
    "title": "How can I force weaviate to run(recognize?) as a single node?",
    "topic_id": 18417
  },
  {
    "user_id": 1040,
    "conversation": "[jaydcrowe1989 (2024-10-24T12:52:57.186Z)]: Hi, I have managed to customise the response for when there is no information related to question but I was wanting to log what the user asked that generated this kind of response. So then I know what information is missing that the user is requesting. How would I do this and where?\n\n----------\n\n[DudaNogueira (2024-11-01T14:41:52.119Z)]: hi @jaydcrowe1989 !!\nSorry! I missed this one here too \nNot sure I understood your question.\nCan you provide some code examples or elaborate more on this?",
    "date_created": "2024-10-24T12:52:57.133Z",
    "has_accepted_answer": false,
    "title": "Log null responses",
    "topic_id": 5864
  },
  {
    "user_id": 2509,
    "conversation": "[gadey_karthik (2024-11-15T12:00:17.025Z)]: Description\nI have weaviate running in an VM but i need another weaviate for Production.Created snapsot and spiined a VM after spiing containers are getting spinned but my old data is present but when i am querying from post i am getting 404 and when i hit http://:8080/v1/.well-known/ready i am getting 503 below is the log error\nServer Setup Information\n\nWeaviate Server Version:1.26.1\nDeployment Method: Docker-compose.yml\nMulti Node? Number of Running Nodes: Single node\nClient Language and Version:\nMultitenancy?:\nBelow is my Compose file\n\nversion: '3.4'\n\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.1\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    environment:\n      LOG_LEVEL: trace\n      QUERY_SLOW_LOG_ENABLED: 'true'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n    ports:\n      - 8080:8080\n      - 50051:50051\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n\n  prometheus:\n    image: prom/prometheus:latest\n    volumes:\n      - ./prometheus:/etc/prometheus/\n      - ./data/prometheus:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--web.console.libraries=/usr/share/prometheus/console_libraries'\n      - '--web.console.templates=/usr/share/prometheus/consoles'\n    ports:\n      - 9090:9090\n\n  grafana:\n    image: grafana/grafana\n    ports:\n      - 3000:3000\n    volumes:\n      - ./grafana/grafana.ini:/etc/grafana/grafana.ini\n      - ./grafana/datasource.yml:/etc/grafana/provisioning/datasources/prometheus.yml\n      - ./grafana/dashboard_provider.yml:/etc/grafana/provisioning/dashboards/dashboards.yml\n      - ./grafana/dashboards:/var/lib/grafana/dashboards\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n\nvolumes:\n  weaviate_data:\n\nAny additional Information\n{“action”:“bootstrap”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:16Z”}\n{“level”:“warning”,“msg”:“raft heartbeat timeout reached, not part of a stable configuration or a non-voter, not triggering a leader election”,“time”:“2024-11-15T11:30:16Z”}\n{“action”:“inverted filter2search migration”,“level”:“debug”,“msg”:“migration skip flag set, skipping migration”,“time”:“2024-11-15T11:30:16Z”}\n{“action”:“inverted filter2search migration”,“level”:“debug”,“msg”:“starting switching fallback mode”,“time”:“2024-11-15T11:30:16Z”}\n{“action”:“inverted filter2search migration”,“level”:“debug”,“msg”:“no missing filterable indexes, fallback mode skipped”,“time”:“2024-11-15T11:30:16Z”}\n{“docker_image_tag”:“1.26.1”,“level”:“info”,“msg”:“configured versions”,“server_version”:“1.26.1”,“time”:“2024-11-15T11:30:16Z”}\n{“action”:“grpc_startup”,“level”:“info”,“msg”:“grpc server listening at [::]:50051”,“time”:“2024-11-15T11:30:16Z”}\n{“action”:“restapi_management”,“docker_image_tag”:“1.26.1”,“level”:“info”,“msg”:“Serving weaviate at http://[::]:8080”,“time”:“2024-11-15T11:30:16Z”}\n{“action”:“telemetry_push”,“level”:“info”,“msg”:“telemetry started”,“payload”:“\\u0026{MachineID:cbf6157a-efb6-46aa-b51b-1cb2af875756 Type:INIT Version:1.26.1 NumObjects:0 OS:linux Arch:amd64 UsedModules:}”,“time”:“2024-11-15T11:30:16Z”}\n{“action”:“bootstrap”,“error”:“could not join a cluster from [172.21.0.4:8300]”,“level”:“warning”,“msg”:“failed to join cluster, will notify next if voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:17Z”,“voter”:true}\n{“action”:“bootstrap”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:17Z”}\n{“action”:“bootstrap”,“error”:“could not join a cluster from [172.21.0.4:8300]”,“level”:“warning”,“msg”:“failed to join cluster, will notify next if voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:19Z”,“voter”:true}\n{“action”:“bootstrap”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:19Z”}\n{“action”:“bootstrap”,“error”:“could not join a cluster from [172.21.0.4:8300]”,“level”:“warning”,“msg”:“failed to join cluster, will notify next if voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:21Z”,“voter”:true}\n{“action”:“bootstrap”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:21Z”}\n{“action”:“bootstrap”,“error”:“could not join a cluster from [172.21.0.4:8300]”,“level”:“warning”,“msg”:“failed to join cluster, will notify next if voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:22Z”,“voter”:true}\n{“action”:“bootstrap”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:22Z”}\n{“action”:“bootstrap”,“error”:“could not join a cluster from [172.21.0.4:8300]”,“level”:“warning”,“msg”:“failed to join cluster, will notify next if voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:24Z”,“voter”:true}\n{“action”:“bootstrap”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:24Z”}\n{“action”:“bootstrap”,“error”:“could not join a cluster from [172.21.0.4:8300]”,“level”:“warning”,“msg”:“failed to join cluster, will notify next if voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:26Z”,“voter”:true}\n{“action”:“bootstrap”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:26Z”}\n{“action”:“bootstrap”,“error”:“could not join a cluster from [172.21.0.4:8300]”,“level”:“warning”,“msg”:“failed to join cluster, will notify next if voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:27Z”,“voter”:true}\n{“action”:“bootstrap”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:27Z”}\n{“action”:“bootstrap”,“error”:“could not join a cluster from [172.21.0.4:8300]”,“level”:“warning”,“msg”:“failed to join cluster, will notify next if voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:29Z”,“voter”:true}\n{“action”:“bootstrap”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:29Z”}\n{“action”:“bootstrap”,“error”:“could not join a cluster from [172.21.0.4:8300]”,“level”:“warning”,“msg”:“failed to join cluster, will notify next if voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:31Z”,“voter”:true}\n{“action”:“bootstrap”,“level”:“info”,“msg”:“notified peers this node is ready to join as voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:31Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-11-15T11:30:32Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“action”:“bootstrap”,“error”:“could not join a cluster from [172.21.0.4:8300]”,“level”:“warning”,“msg”:“failed to join cluster, will notify next if voter”,“servers”:[“172.21.0.4:8300”],“time”:“2024-11-15T11:30:32Z”,“voter”:true}\n\n----------\n\n[DudaNogueira (2024-11-18T12:56:50.261Z)]: hi @gadey_karthik !!\nNot sure I understood the sequence you described.\nBut consider that you can run two weaviates at the same VM (running on different ports) or you can run two separate VMs, each one with different IPs.\nThe logs you shared indicate that this node is trying to join a non existent cluster \nDo you see the same output if using 1.26.latest or 1.27.latest?",
    "date_created": "2024-11-15T12:00:16.965Z",
    "has_accepted_answer": false,
    "title": "Single Weaviate unable to connect",
    "topic_id": 7588
  },
  {
    "user_id": 2022,
    "conversation": "[Ahmed_Mahmoud (2024-10-22T23:18:25.004Z)]: Hello Weaviate Support Team,\nI’m encountering an issue when inserting data into a multi-node Weaviate cluster using Spark. I am successfully able to insert data into other tables, but when I attempt to insert data into the Ebright table, I receive the following error:\nWeaviateErrorMessage(message=local index \"Ebright\" not found: deadline exceeded for waiting for update: version got=3 want=108, throwable=null)\n\n\nThe error occurs when writing batches of data using the following Spark job:\nspark = SparkSession.getActiveSession()\ndf = spark.createDataFrame(documents)\ndf.write.format(\"io.weaviate.spark.Weaviate\") \\\n    .option(\"batchSize\", 200) \\\n    .option(\"scheme\", \"http\") \\\n    .option(\"host\", weaviate_url) \\\n    .option(\"grpc:host\", \"10.2.0.13:50051\") \\\n    .option(\"grpc:secured\", \"false\") \\\n    .option(\"className\", weaviate_table_name) \\\n    .mode(\"append\").save()\n\nThe schema for the Ebright table is as follows:\nproperties = [\n    Property(name=\"chunk\", data_type=DataType.TEXT, vectorize_property_name=False),\n    Property(name=\"chunk_id\", data_type=DataType.INT, vectorize_property_name=False),\n    Property(name=\"chunk_unique_id\", data_type=DataType.TEXT, vectorize_property_name=False),\n    Property(name=\"abs_url\", data_type=DataType.TEXT, vectorize_property_name=False, skip_vectorization=True),\n    Property(name=\"file_name\", data_type=DataType.TEXT, vectorize_property_name=False, skip_vectorization=True),\n    Property(name=\"server_relative_url\", data_type=DataType.TEXT, vectorize_property_name=False, skip_vectorization=True),\n    Property(name=\"topic\", data_type=DataType.TEXT, vectorize_property_name=False, skip_vectorization=True),\n    Property(name=\"time_created\", data_type=DataType.DATE, vectorize_property_name=False, skip_vectorization=True),\n    Property(name=\"time_lastmodified\", data_type=DataType.DATE, vectorize_property_name=False, skip_vectorization=True),\n    Property(name=\"unique_id\", data_type=DataType.TEXT, vectorize_property_name=False, skip_vectorization=True),\n]\n\n\nCluster Setup:\n\n3-node cluster.\nUsing Weaviate version 1.26.6.\nSpark for batch data insertion.\nWeaviate Python client 4.9.0.\n\nI can see the collection exists already, so its strange that the error says index not found:\ntest_col = client.collections.get(\"Ebright\")\nprint(test_col)\n\n<weaviate.Collection config={\n  \"name\": \"Ebright\",\n  \"description\": null,\n  \"generative_config\": null,\n  \"inverted_index_config\": {\n    \"bm25\": {\n      \"b\": 0.75,\n      \"k1\": 1.2\n    },\n    \"cleanup_interval_seconds\": 60,\n    \"index_null_state\": false,\n    \"index_property_length\": false,\n    \"index_timestamps\": false,\n    \"stopwords\": {\n      \"preset\": \"en\",\n      \"additions\": null,\n      \"removals\": null\n    }\n  },\n  \"multi_tenancy_config\": {\n    \"enabled\": false,\n    \"auto_tenant_creation\": false,\n    \"auto_tenant_activation\": false\n  },\n  \"properties\": [\n    {\n      \"name\": \"chunk\",\n      \"description\": null,\n      \"data_type\": \"text\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": true,\n      \"nested_properties\": null,\n      \"tokenization\": \"word\",\n      \"vectorizer_config\": {\n        \"skip\": false,\n        \"vectorize_property_name\": false\n      },\n      \"vectorizer\": \"text2vec-transformers\"\n    },\n    {\n      \"name\": \"chunk_id\",\n      \"description\": null,\n      \"data_type\": \"int\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": false,\n      \"nested_properties\": null,\n      \"tokenization\": null,\n      \"vectorizer_config\": {\n        \"skip\": false,\n        \"vectorize_property_name\": false\n      },\n      \"vectorizer\": \"text2vec-transformers\"\n    },\n    {\n      \"name\": \"chunk_unique_id\",\n      \"description\": null,\n      \"data_type\": \"text\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": true,\n      \"nested_properties\": null,\n      \"tokenization\": \"word\",\n      \"vectorizer_config\": {\n        \"skip\": false,\n        \"vectorize_property_name\": false\n      },\n      \"vectorizer\": \"text2vec-transformers\"\n    },\n    {\n      \"name\": \"abs_url\",\n      \"description\": null,\n      \"data_type\": \"text\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": true,\n      \"nested_properties\": null,\n      \"tokenization\": \"word\",\n      \"vectorizer_config\": {\n        \"skip\": true,\n        \"vectorize_property_name\": false\n      },\n      \"vectorizer\": \"text2vec-transformers\"\n    },\n    {\n      \"name\": \"file_name\",\n      \"description\": null,\n      \"data_type\": \"text\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": true,\n      \"nested_properties\": null,\n      \"tokenization\": \"word\",\n      \"vectorizer_config\": {\n        \"skip\": true,\n        \"vectorize_property_name\": false\n      },\n      \"vectorizer\": \"text2vec-transformers\"\n    },\n    {\n      \"name\": \"server_relative_url\",\n      \"description\": null,\n      \"data_type\": \"text\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": true,\n      \"nested_properties\": null,\n      \"tokenization\": \"word\",\n      \"vectorizer_config\": {\n        \"skip\": true,\n        \"vectorize_property_name\": false\n      },\n      \"vectorizer\": \"text2vec-transformers\"\n    },\n    {\n      \"name\": \"topic\",\n      \"description\": null,\n      \"data_type\": \"text\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": true,\n      \"nested_properties\": null,\n      \"tokenization\": \"word\",\n      \"vectorizer_config\": {\n        \"skip\": true,\n        \"vectorize_property_name\": false\n      },\n      \"vectorizer\": \"text2vec-transformers\"\n    },\n    {\n      \"name\": \"time_created\",\n      \"description\": null,\n      \"data_type\": \"date\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": false,\n      \"nested_properties\": null,\n      \"tokenization\": null,\n      \"vectorizer_config\": {\n        \"skip\": true,\n        \"vectorize_property_name\": false\n      },\n      \"vectorizer\": \"text2vec-transformers\"\n    },\n    {\n      \"name\": \"time_lastmodified\",\n      \"description\": null,\n      \"data_type\": \"date\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": false,\n      \"nested_properties\": null,\n      \"tokenization\": null,\n      \"vectorizer_config\": {\n        \"skip\": true,\n        \"vectorize_property_name\": false\n      },\n      \"vectorizer\": \"text2vec-transformers\"\n    },\n    {\n      \"name\": \"unique_id\",\n      \"description\": null,\n      \"data_type\": \"text\",\n      \"index_filterable\": true,\n      \"index_range_filters\": false,\n      \"index_searchable\": true,\n      \"nested_properties\": null,\n      \"tokenization\": \"word\",\n      \"vectorizer_config\": {\n        \"skip\": true,\n        \"vectorize_property_name\": false\n      },\n      \"vectorizer\": \"text2vec-transformers\"\n    }\n  ],\n  \"references\": [],\n  \"replication_config\": {\n    \"factor\": 1,\n    \"async_enabled\": false,\n    \"deletion_strategy\": \"NoAutomatedResolution\"\n  },\n  \"reranker_config\": null,\n  \"sharding_config\": {\n    \"virtual_per_physical\": 128,\n    \"desired_count\": 3,\n    \"actual_count\": 3,\n    \"desired_virtual_count\": 384,\n    \"actual_virtual_count\": 384,\n    \"key\": \"_id\",\n    \"strategy\": \"hash\",\n    \"function\": \"murmur3\"\n  },\n  \"vector_index_config\": {\n    \"quantizer\": null,\n    \"cleanup_interval_seconds\": 300,\n    \"distance_metric\": \"cosine\",\n    \"dynamic_ef_min\": 100,\n    \"dynamic_ef_max\": 500,\n    \"dynamic_ef_factor\": 8,\n    \"ef\": -1,\n    \"ef_construction\": 128,\n    \"filter_strategy\": \"sweeping\",\n    \"flat_search_cutoff\": 40000,\n    \"max_connections\": 32,\n    \"skip\": false,\n    \"vector_cache_max_objects\": 1000000000000\n  },\n  \"vector_index_type\": \"hnsw\",\n  \"vectorizer_config\": {\n    \"vectorizer\": \"text2vec-transformers\",\n    \"model\": {\n      \"poolingStrategy\": \"masked_mean\"\n    },\n    \"vectorize_collection_name\": false\n  },\n  \"vectorizer\": \"text2vec-transformers\",\n  \"vector_config\": null\n}>\n\n\nCould you please help me diagnose this issue or provide suggestions on how to resolve the index update problem? Is there any specific configuration or tuning required for multi-node cluster setups in this context?\nThank you in advance!\n\n----------\n\n[DudaNogueira (2024-11-01T14:44:33.581Z)]: hi @Ahmed_Mahmoud !!\nSorry for the delay here.\nWere you able to solve this?\nCan you correctly insert directly into Weaviate with one of our clients?\nThat would be interesting to try first.\nAlso, can you check if all 3 nodes are healthy at the nodes api?",
    "date_created": "2024-10-22T23:18:24.946Z",
    "has_accepted_answer": false,
    "title": "[Question] Issue with Data Insertion using spark in Weaviate Cluster",
    "topic_id": 5848
  },
  {
    "user_id": 3013,
    "conversation": "[riturajraman (2024-12-16T08:32:32.570Z)]: Hi Team,\nI am getting the following Errors while writing object to weaviate.\n\nError: 'WeaviateBatchError(‘Query call with protocol GRPC batch failed with message CLIENT: Sent message larger than max (296704410 vs. 104858000).’)\nError: 'WeaviateBatchError(‘Query call with protocol GRPC batch failed with message Deadline Exceeded.’)\nError: 'WeaviateBatchError(‘Query call with protocol GRPC batch failed with message GOAWAY received; Error code: 1; Debug Text: [p]DATA: stream idle.’)\n\nThe following error occours when the batch size is set to >=100.\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: Kubernetes\nNumber of Running Nodes: One node\nWeaviate Version: 1.25.0\nweaviate python client: 4.6.5\n\n----------\n\n[DudaNogueira (2024-12-16T13:28:36.808Z)]: hi @riturajraman !!\nWelcome to our community \nThis will happen if the amount of data you have per object, combined in a batch of X objects, is greater than GRPC_MAX_MESSAGE_SIZE.\nIf you inspect the server logs, you should see a tip that your need to increase this environment variable.\nIncreasing this number should result in bigger batches being allowed.\nLet me know if that helps!\nThanks!\n\n----------\n\n[riturajraman (2024-12-17T11:58:02.284Z)]: Hi @DudaNogueira\nThankyou for the clarification.\nCan you please clarifiy the other two, the deadline exceed and goaway received error one or it is also related to the same GRPC_MAX_MESSAGE_SIZE?\n\n----------\n\n[riturajraman (2025-01-02T09:27:19.428Z)]: Hi @DudaNogueira\nAfter reducing the batch size, I am getting the Error: 'WeaviateBatchError(‘Query call with protocol GRPC batch failed with message Deadline Exceeded.’) and Error ‘Sent message larger than max’ is no more reflecting which was earlier an issue.\nWhat could be the resolution.\n\n----------\n\n[DudaNogueira (2025-01-02T17:58:16.559Z)]: hi!\nYou can either increase the environment variable GRPC_MAX_MESSAGE_SIZE , as described here\nor reduce the batch size further.\nThe problem here is that your objects, combined by the batch size, are bigger than the default GRPC max message.\nLet me know if that helps!\nThanks!",
    "date_created": "2024-12-16T08:32:32.525Z",
    "has_accepted_answer": false,
    "title": "Error: 'WeaviateBatchError('Query call with protocol GRPC batch failed with message <>)",
    "topic_id": 9248
  },
  {
    "user_id": 1309,
    "conversation": "[bbbbb (2024-08-14T20:01:34.143Z)]: Description\n\nI’m having trouble setting up multi-node deployments using docker-compose on different machines. I have two servers server_1 and server_2 and I’m trying to run 2 instances on server_1 and 1 on server_2. No matter how I set it up, nodes on server_1 and server_2 cannot join a cluster together. All traffic between the servers is allowed.\nserver_1 docker-compose\nservices:\n  weaviate-1:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '9090'\n    - --scheme\n    - http\n   image: cr.weaviate.io/semitechnologies/weaviate:`1.26.1`\n  ports:\n    - 9090:9090\n    - 7100:7100/tcp\n    - 7100:7100/udp\n    - 7101:7101/tcp\n    - 7101:7101/udp\n    - 50051:50051/tcp\n    - 50051:50051/udp\n    - 8300:8300/tcp\n    - 8300:8300/udp\n    - 8301:8301/tcp\n    - 8301:8301/udp\n   environment:\n      CLUSTER_HOSTNAME: 'server_1_1'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'\n      RAFT_JOIN: 'HOSTNAME_1:8300,HOSTNAME_1:8302,HOSTNAME_2:8300'\n      RAFT_BOOTSTRAP_EXPECT: 3\n weaviate-2:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '9090'\n    - --scheme\n    - http\n   image: cr.weaviate.io/semitechnologies/weaviate:`1.26.1`\n  ports:\n    - 9091:9090\n    - 7102:7102/tcp\n    - 7102:7102/udp\n    - 7103:7103/tcp\n    - 7103:7103/udp\n    - 50052:50051/tcp\n    - 50052:50051/udp\n    - 8302:8302/tcp\n    - 8302:8302/udp\n    - 8303:8303/tcp\n    - 8303:8303/udp\n   environment:\n      CLUSTER_HOSTNAME: 'server_1_2'\n      CLUSTER_JOIN: 'HOSTNAME_1:7100'\n      CLUSTER_GOSSIP_BIND_PORT: '7102'\n      CLUSTER_DATA_BIND_PORT: '7103'\n      RAFT_PORT: '8302'\n      RAFT_INTERNAL_RPC_PORT: '8303'\n      RAFT_JOIN: 'HOSTNAME_1:8300,HOSTNAME_1:8302,HOSTNAME_2:8300'\n      RAFT_BOOTSTRAP_EXPECT: 3\n\n\nand for server_2\nservices:\n  weaviate-1:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '9090'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.1\n    ports:\n    - 9090:9090\n    - 7100:7100/tcp\n    - 7100:7100/udp\n    - 7101:7101/tcp\n    - 7101:7101/udp\n    - 50051:50051/tcp\n    - 50051:50051/udp\n    - 8300:8300/tcp\n    - 8300:8300/udp\n    - 8301:8301/tcp\n    - 8301:8301/udp\n    restart: on-failure:0\n    environment:\n      CLUSTER_HOSTNAME: 'server_2'\n      CLUSTER_JOIN: 'HOSTNAME_1:7100'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'\n      RAFT_JOIN: 'HOSTNAME_1:8300,HOSTNAME_1:8302,HOSTNAME_2:8300'\n      RAFT_BOOTSTRAP_EXPECT: 3\n\nI’ve tried numerous RAFT_JOIN configs with the CLUSTER_HOSTNAME’s, or the hostnames of server_1 and server_2 with the ports. In the first case, server_1 services don’t join server_2’s cluster, and server_2 doesn’t join server_1s.\n{\"level\":\"info\",\"msg\":\" memberlist: Suspect server_2 has failed, no acks received\",\"time\":\"2024-08-13T23:29:46Z\"}\nIn the second case, there’s connection problems between the two services on server_1. Any insight into how to set this up, or examples?\nThe documentation for this doesn’t include port 8300 / Raft port info at all, and seems to lack a nice example of multi node configurations with docker-compose on different machines.\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method: docker-compose\nMulti Node? Number of Running Nodes: 3 on 2 servers\nClient Language and Version: Python\nMultitenancy?: Not atm\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-08-15T18:22:49.074Z)]: Hi!\nThis is an unusual way of deploying. I have seen some users with this similar deployment requirement.\nCan you elaborate better on the reasoning for this?\nK8s is a better way to manage multi nodes, and is way more battle proofed.\nAlternatively, it would be easier to deploy in Docker Swarm.\nother than that, I would try leaving all service name, hostname and node name the same, and working with extra hosts to make sure the host/node is resolving into the corresponding IP.\nBut this is far from the optimal way to deploy a production cluster\n\n----------\n\n[jasper2077 (2024-11-29T08:55:21.780Z)]: Hello, I’m currently facing the same issue. Have you figured out how to solve the error?",
    "date_created": "2024-08-14T20:01:34.089Z",
    "has_accepted_answer": false,
    "title": "Multi node docker-compose deployment on multiple machines",
    "topic_id": 3352
  },
  {
    "user_id": 323,
    "conversation": "[Dharanish (2024-03-25T08:18:19.882Z)]: Hi , configured batch on\nclient.batch.configure(batch_size=100,dynamic=True,consistency_level=“ALL”,connection_error_retries=3,num_workers=2)\nperform batch insertion and getting exception\nUnexpectedStatusCodeException: batch response! Unexpected status code: 500, with response body: {‘error’: [{‘message’: ‘batch objects: &fmt.wrapError{msg:“cannot process batch: not enough memory”, err:(*errors.errorString)(0xc00004c020)}’}]}.\nWeaviate version :1.23.11\nDeployment type: Kubernetes cluster\nPython client : 3.24.2\navailable memory per container: 4GB\n\n----------\n\n[DudaNogueira (2024-03-25T10:38:51.337Z)]: hi @Dharanish !\nCan you try using the new python v4 client?\nAlso, does the server has enough memory considering the amount of objects to be ingested?\nAnd finally, does it happens if you reduce the batch size?\nIf you try to the python v4 client, I suggest using the dynamic batch size, so Weaviate server can adjust the batch size while communicating with the client.\nThanks!\n\n----------\n\n[Dharanish (2024-08-08T10:28:05.861Z)]: Hi @DudaNogueira , My cluster has enough memory and batch size is 20 and using client 4.5.7, still getting this error\n\n----------\n\n[DudaNogueira (2024-08-08T14:31:33.706Z)]: This is the origin of this error:\n\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate/blob/6fd24322f15ecf46d40e1e35754b524fe96e61f5/adapters/repos/db/batch.go#L39\n\n\n\n    \n      \n          \toriginalIndex []int\n          }\n          \n          func (db *DB) BatchPutObjects(ctx context.Context, objs objects.BatchObjects,\n          \trepl *additional.ReplicationProperties, schemaVersion uint64,\n          ) (objects.BatchObjects, error) {\n          \tobjectByClass := make(map[string]batchQueue)\n          \tindexByClass := make(map[string]*Index)\n          \n          \tif err := db.memMonitor.CheckAlloc(estimateBatchMemory(objs)); err != nil {\n          \t\tdb.logger.WithError(err).Errorf(\"memory pressure: cannot process batch\")\n          \t\treturn nil, fmt.Errorf(\"cannot process batch: %w\", err)\n          \t}\n          \n          \tfor _, item := range objs {\n          \t\tif item.Err != nil {\n          \t\t\t// item has a validation error or another reason to ignore\n          \t\t\tcontinue\n          \t\t}\n          \t\tqueue := objectByClass[item.Object.Class]\n          \t\tqueue.objects = append(queue.objects, storobj.FromObject(item.Object, item.Object.Vector, item.Object.Vectors))\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIt may be hitting the limits while ingesting.\nDoes it also happen if you reduce the size of the batch or increase the memory?\nAlso, have you tried this on recent version?\n\n----------\n\n[bharath97 (2024-12-11T13:00:58.163Z)]: Hi @DudaNogueira , @Dharanish ,\nI’ve also seen the same issue today.\nRunning weaviate: 1.24.11\nRestarting the weaviate service has resolved this(temporarily  I guess).\n\n----------\n\n[DudaNogueira (2024-12-11T20:15:55.259Z)]: hi @bharath97 !!\nIn order to mitigate this, some recommendations would be upgrading to latest version (a lot have improved from from 1.24 to 1.28). Also, we need to be aware that while ingesting data with vectors, Weaviate will also index that data, while write it accordingly. For example, Weaviate 1.28 version, that was just released, had some interesting improvements on ASYNC_INDEXING\nSo allocating more memory so the ingestion can happen smoothly is an option.\nAnother route here is to enable ASYNC_INDEXING. This will allow Weaviate to “take it’s time” to index everything and will also make the ingestion process quicker, as it will not perform the indexing right away, but asynchronously.\nLet me know if that helps!\nTHanks!\n\n----------\n\n[bharath97 (2024-12-12T05:45:52.137Z)]: Hey @DudaNogueira ,\nThanks for responding to this.\nLet me try setting the ASYNC_INDEXING config to true and see if this improved as I see it’s available from 1.22.\nIf not, I’ll try upgrading to 1.28.\nThanks!\n\n----------\n\n[bharath97 (2024-12-16T11:27:09.457Z)]: Hello @DudaNogueira,\nI have set the ASYNC_INDEXING to true and also upgraded weaviate to 1.28, however the issue still seems to persist.\nCan you help please?\nFYI - my client version is: 3.24.1 (Python SDK)\nSome logs from weaviate that could be of any help:\ncannot load vector into cache due to memory pressure\nfind and connect neighbors: at level 0: search layer at level 0: calculate distance between candidate and query: not enough memory\n\n----------\n\n[DudaNogueira (2024-12-16T13:53:25.384Z)]: It is best to use the python version 4+.\nAlso, do you have any observability on this server?\nWhat is the memory and cpu allocated? have you done something as documented here?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nResource Planning | Weaviate\n\n  Weaviate scales well for large projects. Smaller projects, less than 1M objects, do not require resource planning. For medium and large-scale projects, you should plan how to get the best performance from your resources. While you design you system,...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nPs: it is best to open a new thread, so we can answer it from there.\nThanks!",
    "date_created": "2024-03-25T08:18:19.825Z",
    "has_accepted_answer": true,
    "title": "Cannot process batch: not enough memory",
    "topic_id": 1810
  },
  {
    "user_id": 680,
    "conversation": "[Gene_Mc (2024-05-06T21:15:52.712Z)]: Description\nTrying to understand what is actually happening with the combination of\nrerank with HybridFusion.RELATIVE_SCORE.\nHybridFusion.RELATIVE_SCORE documentation says:\n“To mitigate this effect, Weaviate automatically performs a search with a higher limit (100) and then trims the results down to the requested limit.”\nIf I specify a limit in the search query:\nresponse = collection.query.hybrid(\n    query=instring,\n    alpha=0.6, #proportion of vector search 1.0 = 100% vector\n    return_metadata=wvc.query.MetadataQuery(\n                    score=True,\n                    distance=True,\n                    explain_score=True),\n    fusion_type=HybridFusion.RELATIVE_SCORE,\n    limit=8,\n    rerank=Rerank(\n        prop=\"search_text\",\n        query=instring\n    ),\n)\n\nThe code above works fine and returns both the normalized hybridFusion normalized scores and the rerank scores.\nDoes the rerank “rerank” only the limit=8 documents, or does it rerank the 100 initial documents retrieved by HybridFusion.RELATIVE_SCORE behind the scenes?\nI’d prefer a wider rerank, just unclear on what this combination does…\nIf I want to rerank the top 50 documents, I guess I could start with limit=50 then trim the result to the final top 8?\nServer Setup Information\n\nWeaviate Server Version: 1.24.1\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: python 4.5.5\n\nAny additional Information\nall above\n\n----------\n\n[DudaNogueira (2024-05-06T21:57:26.652Z)]: hi @Gene_Mc !!\nWeaviate will do a 2 phase process. It will first perform the search you requested (hybrid, near vector, etc), and subsequently it will pass over those objects to the reranker module to get them resorted.\nSo on your case, it will only perform the rerank over the 8 objects, as your limited for your query.\nfrom:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nReranking | Weaviate - Vector Database\n\n  Reranking seeks to improve search relevance by reordering the result set returned by a retriever with a different model.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Gene_Mc (2024-05-07T22:22:48.084Z)]: Hi @DudaNogueira\nThis answer does help me understand, so I’ve gone the route of returning 100 documents then plucking the top N for my RAG application.\n        response = collection.query.hybrid(\n            query=instring,\n            alpha=0.6, #proportion of vector search 1.0 = 100% vector\n            return_metadata=wvc.query.MetadataQuery(\n                score=True,\n                explain_score=True,\n                ),\n            limit=100,\n            fusion_type=HybridFusion.RELATIVE_SCORE,\n            rerank=Rerank(\n                prop=\"page_content\",\n                query=instring\n            ),\n        )\n\nThis combination works pretty well… maybe too well? Now I wish I had an easy way to add back some diversity and/or eliminate redundancy… I’ll keep reading…\nthank you for your help!\n\n----------\n\n[DudaNogueira (2024-05-08T00:16:51.150Z)]: That’s great, @Gene_Mc !!\nLet us know if you have any other doubts along your journey learning those cool technology \nJust be aware that with more objects being passed to rerank, costs will be higher \nWe are here to help!\nThanks!",
    "date_created": "2024-05-06T21:15:52.638Z",
    "has_accepted_answer": true,
    "title": "Rerank with HybridFusion.RELATIVE_SCORE - How many are ranked?",
    "topic_id": 2212
  },
  {
    "user_id": 3052,
    "conversation": "[RamuA (2025-01-13T04:18:32.580Z)]: Description\nWhat is the best way to use the Weaviate client for Weaviate hosted on an EC2 machine?\n\nDo we have the option to use GraphiQL?\nWhere can I download the package and install it on an Ubuntu machine or macOS?\nI don’t see any option to download the GraphiQL software in the WCD portal.\n\n----------\n\n[Sam_Joel (2025-01-15T15:04:09.488Z)]: I dont think weaviate has any OS native client libraries. There are language specific client libraries like in python, js, go etc.\n\n----------\n\n[Mohamed_Shahin (2025-01-16T09:29:04.876Z)]: Hi @RamuA,\nHere is a list of the client libraries we have as tools for Weaviate database:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nReference - Client Libraries | Weaviate\n\n  Explore Weaviate client libraries to integrate Weaviate into your tech stack.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAs @Sam_Joel mentioned, each client is language-specific.\nBest,\nMohamed Shahin\nWeaviate Support",
    "date_created": "2025-01-13T04:18:32.525Z",
    "has_accepted_answer": true,
    "title": "Client tool for Weaviate DB",
    "topic_id": 9695
  },
  {
    "user_id": 3198,
    "conversation": "[kumaran14 (2025-01-12T20:07:03.070Z)]: Description\n\n\nimport weaviate\nimport os\nimport weaviate.classes as wvc\nimport weaviate.classes.config as wc\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain.schema import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_ollama import ChatOllama\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\n\nweaviate_client = weaviate.connect_to_local()\n\n\nweaviate_client.collections.create(\n    name=\"DataStored\",\n    properties=[\n        wc.Property(name=\"text\", data_type=wc.DataType.TEXT_ARRAY),\n        \n    ],\n    # Define the vectorizer module (none, as we will add our own vectors)\n    vectorizer_config=wc.Configure.Vectorizer.none(),\n    generative_config=wc.Configure.Generative.mistral()\n    \n)\n\ndb = WeaviateVectorStore(\n    client=weaviate_client,\n    index_name=\"DataStored\",  # Your existing class name\n    text_key=\"text\",  # The field containing your text data\n    embedding=embed\n)\n\n\ntemplate = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: {question}\nContext: {context}\nAnswer:\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\n\nllm = ChatOllama(\n    model=\"mistral:latest\",\n    temperature=0,\n    num_predict = 256\n    # other params...\n)\n\n\nrag_chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nrag_chain.invoke(\"What is the use case\")\n\nSo when I run this code I get an error stating:\nValidationError: 1 validation error for Document\npage_content\n  Input should be a valid string [type=string_type, input_value=['Changes in visionLow bl...it'], input_type=list]\n\nwhen I change the column/feature to a DataType.TEXT I don’t get any error and the RAG retrieval works perfectly fine, My question is why LangChain’s Document and retrieval systems are designed to work with text and not text_array ?\n\n----------\n\n[Mohamed_Shahin (2025-01-14T14:24:43.100Z)]: Hi @kumaran14,\nIt’s lovely to have you here—welcome to the community!\nLangChain’s Document class is designed to handle individual text entries, with the page_content attribute specifically expecting a single string (str).\nhttps://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html\nThis design choice aligns with the framework’s focus on processing and analyzing individual documents or text segments efficiently.\nWhen integrating with Weaviate, if your data is stored as a TEXT_ARRAY, it doesn’t directly match the expected input type for LangChain’s Document class. This mismatch lead to validation errors, as the system anticipates a single string rather than an array.\nRegards,\nMohamed Shahin,\nWeaviate Support Engineer\n\n----------\n\n[kumaran14 (2025-01-26T17:40:22.402Z)]: Thanks for the info @Mohamed_Shahin",
    "date_created": "2025-01-12T20:07:03.022Z",
    "has_accepted_answer": true,
    "title": "Using DataType.TEXT_ARRAY as a datatype for a feature/column causes problems with LangChain's Document and retrieval systems",
    "topic_id": 9694
  },
  {
    "user_id": 1252,
    "conversation": "[tadejkrivec (2024-07-26T10:46:30.770Z)]: Description\nWe migrated a collection from WCS to an on-premise server. The number of items is around ~ 5kk. The migration was obtained by copying the items from one instance to another, along with the vector embeddings. The settings of the Weaviate instance (and collection/schemas) are identical. The only difference being a minor version of the Weaviate instance (on-premise is 1.24.4, WCS is currently 1.24.1).\nThe benchmark queries used to test the migration show different performance between the instances. When doing a top 10 search the results are different. E.g., a specific high confidence item is found on instance A, but not on instance B. If we increase the search to top 100, the item is also found on instance B. As far as I understand this is due to the approximate KNN search under the hood.\nWhat I am a bit surprised is that the process is not deterministic between instance A and B. I would expect identical search results with identical data. Could this be due to the minor version difference between the Weaviate instances? Or are there also some additional stochastic complexities under the hood? E.g., resource dependent, caching etc.\nWhen limiting the search via filter (and forcing a brute force search) the results are identical. So it really seems the issue is approximate KNN.\nThank you for the help.\n\n----------\n\n[DudaNogueira (2024-07-26T14:03:48.152Z)]: Hi!\nWelcome to our community \nwhen you migrate/copy your data over, for example using this migration guide, your index gets rebuilt.\nSo this can lead to different results indeed. Can you check if ef and efConstruction are the same in both collections?\nThanks!\n\n----------\n\n[tadejkrivec (2024-07-29T07:16:16.439Z)]: ef and efConstruction are the same in both collections.\nThanks for the reply.",
    "date_created": "2024-07-26T10:46:30.718Z",
    "has_accepted_answer": false,
    "title": "Migration from wcs to on-premise",
    "topic_id": 3184
  },
  {
    "user_id": 1632,
    "conversation": "[pvw (2024-10-03T13:58:16.484Z)]: Description\nI have been using the weaviate cloud console for a while now. I am running a weavaite Docker instance on weaviate.myserver.com, which I added as a cluster to the weaviate cloud console. From there I could easily make some checks to see if everything is working as expected. Today I refreshed the console, had to login again and then the clusters were gone. I also do not see a new method to add it. I only see ‘sandbox’, ‘enterprise’ or ‘serverless’, but nowhere an option where I can add my own host.\nAm I missing anything?\n\n----------\n\n[DudaNogueira (2024-10-03T15:32:57.035Z)]: hi @pvw !!\nWelcome to our community \nIndeed we have disabled this feature in our console.\nHowever, you can use softwares like postman or insomnia, here is an example:\nimage1410×902 56.5 KB\n\n----------\n\n[David_Fava (2024-10-14T16:56:29.958Z)]: For anyone looking into an alternative:\n\nhead to Studio\nset the correct headers\nrun queries\n\nScreenshot 2024-10-14 at 17.52.591920×1018 80.5 KB\n\n----------\n\n[DudaNogueira (2024-10-14T19:57:36.715Z)]: Nice tip!!\nThanks for sharing, @David_Fava !!\nAnd welcome to our community",
    "date_created": "2024-10-03T13:58:16.440Z",
    "has_accepted_answer": true,
    "title": "Cloud console not available on self hosted server anymore",
    "topic_id": 4412
  },
  {
    "user_id": 810,
    "conversation": "[engelsl (2024-04-12T08:29:44.172Z)]: Hi\nI’m trying to use the WeaviateHybridSearchRetriever from langchain.\nThe issue i encounter is the following one :\nWeaviateHybridSearchRetriever Requiere the python client v3 which is deprecated\nDoes someone have any solution to build an hybrid search retriever with the python client v4\nThanks in advance\n\n----------\n\n[DudaNogueira (2024-04-12T13:21:26.050Z)]: HI @engelsl !\nI have not yet played with the new integration, to be honest \nI have used this, but for the old integration. I plan on migrating this recipe I did for the new integration:\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/langchain/loading-data at main · weaviate/recipes\n\n\n  This repository shares end-to-end notebooks on how to use various features and integrations with Weaviate at the core! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nPlease, if possible, share a notebook based on that recipe with what you want to accomplish.\nThis helps a lot as we have a MRE minimum reproducible example to play with.\nThanks!\n\n----------\n\n[engelsl (2024-04-16T09:09:29.668Z)]: Hi @DudaNogueira  Thanks a lot  for your help the notebook you shared was really helpful.\nI was missing creating a correctly a collection.\nNow i’m facing a new error and I have trouble to see where it could come from.\nMay you know this error or you see it somewhere else : vector search: knn search: distance between entrypoint and query node: vector lengths don’t match: 384 vs 768\", ‘path’: [‘Get’, ‘TextChunk’]}]\nIf you have any idea on what could have been the potential issue\nI know it’s hard to think just on a error but it’s more like if you have already face this issue on previous work and you have an idea on how to solve it.\nThanks in advance\n\n----------\n\n[engelsl (2024-04-16T12:15:48.752Z)]: I found the solution i had to add into the collection the precise embedding model that i use also to embedded the query\n\n----------\n\n[DudaNogueira (2024-04-17T18:39:12.874Z)]: Awesome, @engelsl !\nAlso, I have just updated that recipe today to use the new Langchain integration\n\n----------\n\n[pj812 (2024-07-15T03:05:02.077Z)]: Hi Duda, I had the same issue @engelsl had, I am trying to use, the Weaviate 4 version client with langchain hybrid retriever function. However, I get this error, when I am instantiating my client as I always doing it and it works for that piece.  Here is the error I get when running the retriever function: alidationError: 1 validation error for WeaviateHybridSearchRetriever\nroot\nclient should be an instance of weaviate.Client, got <class ‘weaviate.client.WeaviateClient’> (type=value_error)       You had responded to engels with the github. However, I think things have moved. I am not seeing code there. Can you point me to the right code. Here is my retriever code: retriever = WeaviateHybridSearchRetriever(\nclient=client,\nindex_name=Newcollection5,  # replace with your collection name\ntext_key=“find this text”,\nattributes=,\n#embeddings=embeddings,\ncreate_schema_if_missing=False\n)  Thanks, Paul\n\n----------\n\n[DudaNogueira (2024-07-15T19:28:38.756Z)]: hi @pj812!\nThis error means that you are passing the wrong client.\nright now, python v4 client package will include both v3 and v4 code.\nthe difference is how you instantiate the client.\nfor v3:\nclient = weaviate.Client(\"http://localhost:8080\")\n\nwhile for v4:\nclient = weaviate.connect_to_local()\n\nconnect_to_local or other option.\nCheck here for a nice doc on how to migrate:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate from v3 to v4 | Weaviate - Vector Database\n\n  The current Python client version is v||site.pythonclientversion||\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!",
    "date_created": "2024-04-12T08:29:44.087Z",
    "has_accepted_answer": true,
    "title": "WeaviateHybridSearchRetriever",
    "topic_id": 1998
  },
  {
    "user_id": 1256,
    "conversation": "[Chaitanya_Bhagavan (2024-07-28T18:07:33.924Z)]: Description\nI have a self hosted weaviate instance consisting of 4 nodes running on a k8s cluster on azure. This is behind a spring cloud gateway and accessed from outside through a path /weaviate and gets routed to the the running weaviate instance.\nPython client V3 accepts a url parameter, but V4 client is not using the base path.\nHow can i connect to the weaivate instance from outside the cluster by using the path ? eg. https://app.example.com/weaviate\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 4\nClient Language and Version: Python and Java\nMultitenancy?:  No\n\nAny additional Information\n\n----------\n\n[Chaitanya_Bhagavan (2024-07-29T12:07:33.911Z)]: I solved this for https by creating a listener and rewrite rule in application gateway. But I am not sure how to expose the grpc service via the application gateway? Any help is greatly appreciated.\n\n----------\n\n[DudaNogueira (2024-07-29T17:44:08.856Z)]: hi @Chaitanya_Bhagavan !!\nWelcome to our community \nWe do not provide specific instructions on how to properly expose Weaviate in different services, as they may vary a lot.\nThe bottom line is the same as exposing a GRPC.\nOne way to test is using tools like grpcurl:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\ngRPC | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThis is how I have done it for traefik, using docker compose, for example:\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nBuild software better, together\n\n  GitHub is where people build software. More than 100 million people use GitHub to discover, fork, and contribute to over 420 million projects.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-07-28T18:07:33.768Z",
    "has_accepted_answer": false,
    "title": "How to use weaviate client v4 to connect to a self hosted instance on k8s",
    "topic_id": 3199
  },
  {
    "user_id": 994,
    "conversation": "[j1mmc1v3r (2024-05-27T00:45:31.615Z)]: Description\nUsing python weaviate-client 3.26.0, I took a back-up of my weaviate data using the following:\n\ndef save_weaviate_data(server, timestamp):\nbackup_id = server + ‘_’ + timestamp\nclient = weaviate.Client(“http://localhost:8081”)\nresult = client.backup.create(backup_id=backup_id, backend=“s3”, wait_for_completion=True)\nprint(result)\n\nWhen I try to restore the data, I get the following error:\nweaviate.exceptions.UnexpectedStatusCodeException: Backup restore! Unexpected status code: 422, with response body: {‘error’: [{‘message’: ‘unable to restore backup as it was produced by a higher version: 2.1 > 2.0’}]}\nAny suggestions would be most helpful\nServer Setup Information\n\nWeaviate Server Version:   1.23.15\nDeployment Method: docker container image: semitechnologies/weaviate:latest\nMulti Node? Number of Running Nodes:  1\nClient Language and Version:   python weaviate-client 3.26.0\n\nAny additional Information\n\n----------\n\n[j1mmc1v3r (2024-05-29T04:11:18.924Z)]: Aha - I have fixed this now.  Turns out, I was trying to restore data to a different weaviate instance but that target instance was a different version that the one I did the back up from.  Updated the target weaviate instance version and it all just worked.  Hope this helps anyone else that finds themselves in the same boat.  Worth noting that my docker-compose file was using the weaviate:latest image - when I created the target instance, the “latest” image was at a higher version.\n\n----------\n\n[Dirk (2024-05-29T06:27:47.802Z)]: j1mmc1v3r:\n\nWorth noting that my docker-compose file was using the weaviate:latest image - when I created the target instance, the “latest” image was at a higher version.\n\n\nplease don’t use latest\n\n----------\n\n[rjalex (2024-07-22T17:47:06.931Z)]: Using latest is a recipe for disaster  Always use a know version/tag so things are repeatable.",
    "date_created": "2024-05-27T00:45:31.551Z",
    "has_accepted_answer": true,
    "title": "Problems restoring from weaviate backup",
    "topic_id": 2489
  },
  {
    "user_id": 985,
    "conversation": "[Neil (2024-05-24T18:11:13.908Z)]: Hello, I’m new to python and I’ve been following the YT on v4 and going through the code to create my own vector db. I’ve been able to create a collection and populate it but having issues with getting aggreatage numbers after data has been populated.\nSeveral questions:\n\n\nwhen importing wvc is, which is the recommended route for aggregate querying:\na) import weaviate.classes.config as wvc\nb) import weaviate.classes as wvc\n\n\nI’m unable to get aggregate metrics as shown here = #Aggregate | Weaviate - Vector Database\n\n\nhere is the error I’m getting:\nError message:\nline 217, in _do\nraise WeaviateQueryError(\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GQL Aggregate failed with message Error in GraphQL response: [\n{\n“locations”: [\n{\n“column”: 34,\n“line”: 1\n}\n],\n“message”: “Cannot query field \"wordCount\" on type \"AggregateUkraine002\".”,\n“path”: null\n}\n], for the following query: {Aggregate{Ukraine002{meta{count}wordCount { count maximum mean median minimum mode sum }}}}.\nsys:1: ResourceWarning: unclosed <ssl.SSLSocket fd=11, family=2, type=1, proto=0, laddr=(‘192.168.1.13’, 62602), raddr=(‘34.149.137.116’, 443)>\nHere is the function I’ve used:\ndef _create_new_weaviate_ukraine001_collections(main_collection_name):\nconfig_file_path = (os.path.join(“parameters.json”))\nconfig = json.load(open(config_file_path))\nprint(\" - - - - - -  - - - - - - create_new_weaviate_ukraine_collections(): - - - - - - - - - - - - - - - -  \")\nconfig_weaviate_sandbox_cluster_url = config[\"weaviate_sandbox_cluster_url\"]\nconfig_weaviate_api_key =config[\"weaviate_api_key\"]\nconfig_open_ai_api = config[\"open_ai_api\"]\nconfig_cohere_test_api_key = config[\"cohere_test_api_key\"] \nconfig_huggingface_token = config[\"huggingface_token\"]\n\n#Access Weaviate_Client\n#https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\nweaviate_client = weaviate.connect_to_wcs(\n        cluster_url = config_weaviate_sandbox_cluster_url,\n        #auth_credentials=weaviate.auth.AuthApiKey(api_key=config_weaviate_api_key), #Weaviate instance API key\n        auth_credentials=weaviate.auth.AuthApiKey(config_weaviate_api_key), #Weaviate instance API key\n        headers={\n            \"X-OpenAI-Api-Key\": config_open_ai_api,\n            \"X-Cohere-Api-Key\": config_cohere_test_api_key,\n            \"X-HuggingFace-Api-Key\": config_huggingface_token,}\n)\n\ntry:\n    #create review collection (YT 1: 050))\n    ukraine_collection = weaviate_client.collections.create(\n        name = main_collection_name,\n        description = 'Save the Children and Ukraine information',\n        properties=[\n            wvc.Property(name = \"title\", data_type=wvc.DataType.TEXT,skip_Vectorization=True),\n            wvc.Property(name = \"author\", data_type=wvc.DataType.TEXT, skip_Vectorization=True),\n            wvc.Property(name = \"content\", description = 'content informaiton', data_type=wvc.DataType.TEXT),\n            wvc.Property(name = \"summary\", data_type=wvc.DataType.TEXT),\n            wvc.Property(name = \"filename\", data_type=wvc.DataType.TEXT,skip_Vectorization=True),\n            wvc.Property(name = \"load_date\", data_type=wvc.DataType.DATE,skip_Vectorization=True),\n            wvc.Property(name = \"uniqueid\", data_type=wvc.DataType.TEXT, skip_Vectorization=True),\n        ],\n        vectorizer_config=wvc.Configure.Vectorizer.text2vec_openai(),\n        generative_config = wvc.Configure.Generative.openai(),\n        vector_index_config=wvc.Configure.VectorIndex.hnsw(\n            distance_metric=wvc.VectorDistances.COSINE\n        ), \n    )\nprint(\" - - - - - -  - - - - - - _add_data_existing_weaviate() - - - - - - - - - - - - - - - -  \")\n            #Specify and ID = https://weaviate.io/developers/weaviate/manage-data/import#specify-an-id-value\n    uniqueid_rows = [{\"uniqueid\": f\"id_{i+1}\"} for i in range(5)] #not sure why it's only 5??\n\n    #Rate limit doc = https://weaviate.io/developers/weaviate/client-libraries/python\n    with weaviate_client.batch.rate_limit(requests_per_minute=300) as batch:\n        batch.add_object(\n            properties={'title': main_title},\n            collection = str(ukraine_collection),\n        )            \n        batch.add_object(\n            properties={'summary': 'No_Summary_YET'},\n            collection = str(ukraine_collection),\n        )\n        batch.add_object(\n            properties={\"load_date\": '2024-05-24T16:00:00-08:00'}, #String w/RFC3339 formatt\n            collection = str(ukraine_collection),\n        )\n        batch.add_object(\n            properties={'filename': main_filename}, #String w/RFC3339 format\n            collection = str(ukraine_collection),\n        )\n        batch.add_object(\n            properties={'author': main_authors}, \n            collection = str(ukraine_collection),\n        )\n    #not this is adding unique id based on defined collection!\n        #https://weaviate.io/developers/weaviate/manage-data/import#specify-an-id-value\n    with ukraine_collection.batch.dynamic() as batch:\n        for uniqueid_row in uniqueid_rows:\n            obj_uuid = generate_uuid5(uniqueid_row)\n            batch.add_object(\n                properties={'uniqueid': uniqueid_row}, \n                uuid=obj_uuid,\n            ) \n    #review the number of imported objects  = https://towardsdatascience.com/getting-started-with-weaviate-a-beginners-guide-to-search-with-vector-databases-14bbb9285839\n    print(' - - '* 20)\n    #https://weaviate.io/developers/weaviate/api/graphql/aggregate\n    #https://weaviate.io/developers/weaviate/api/graphql/aggregate#overview\n    print(f\"Total # of Imported Objects for Ukraine - - - \")\n    response_tot_collection_loaded = ukraine_collection.aggregate.over_all(\n        total_count=True,\n        return_metrics=wvc.query.Metrics(\"wordCount\").integer(\n                count=True,\n                maximum=True,\n                mean=True,\n                median=True,\n                minimum=True,\n                mode=True,\n                sum_=True,\n            ),\n    )\n    print(response_tot_collection_loaded.total_count)\n    print(response_tot_collection_loaded.properties)\n    print(' - - - '*6)\n    print()\n\n\n    #verify batch and end of batch run\n    if len(ukraine_collection.batch.failed_objects) > 0  or len(ukraine_collection.batch.failed_references) > 0:\n        print('error!! with batch run!')\n        pass\n\n    pass # \n\nfinally:\n    #Best practice to close connection with the v4 API.\n    weaviate_client.close()  # Close client gracefully\n\n----------\n\n[DudaNogueira (2024-05-31T18:09:50.133Z)]: hi! Sorry for the delay here!\nWelcome to our community, @Neil ! \nThat query will is over the property wordCount, which you doesn’t seem to have.\nHere is a number example:\nclient.collections.delete(\"Article\")\ncollection = client.collections.create(\n    \"Article\"\n)\n\ncollection.data.insert({\"text\": \"This is an example\", \"number\": 1})\ncollection.data.insert({\"text\": \"This is another example\", \"number\": 2})\ncollection.data.insert({\"text\": \"This is three examples\", \"number\": 3})\nresponse = collection.aggregate.over_all(\n    total_count=True,\n    return_metrics=wvc.query.Metrics(\"number\").integer(\n        sum_=True,\n        mean=True,\n        median=True,\n        minimum=True,\n        maximum=True,\n        count=True,\n        mode=True\n    ),\n)\n\nprint(response.total_count)\nprint(response.properties)\n\nNotice that aggregation properties are dependent on the data type of the metrics field:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAggregate | Weaviate - Vector Database\n\n  This page covers aggregation queries. They are collectively referred to as Aggregate queries within.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Neil (2024-10-01T15:06:47.361Z)]: Thanks! This has resolved my question! =)",
    "date_created": "2024-05-24T18:11:13.840Z",
    "has_accepted_answer": true,
    "title": "\"Cannot query field \\\"wordCount\\\" on type \\\"Aggregate",
    "topic_id": 2466
  },
  {
    "user_id": 263,
    "conversation": "[chirag-phlo (2023-08-30T18:02:03.525Z)]: For testing purposes, I’m trying to deploy weaviate onto a docker desktop instance of kubernetes\nI’ve set up a PVC to be used, and confirmed that it works with other pods, before resetting my cluster and trying again.\nThe PV file (with the directory edited)\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: task-pv-volume\n  labels:\n    type: local\nspec:\n  storageClassName: hostpath\n  capacity:\n    storage: 32Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: /run/desktop/mnt/host/.../weaviate_pv\n\nthe PVC\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: task-pv-claim\nspec:\n  storageClassName: hostpath\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 32Gi\n\nand the storage section in values.yaml\nstorage:\n  fullnameOverride: task-pv-claim\n\nI’ve trying deploying the PV and the PVC to both the default namespace and the weaviate namespace, but I can’t seem to get weaviate to use the PVC as opposed to creating a new claim.\nEDIT:\nthese are the standard commands I use to get things going:\nkubectl create namespace weaviate\nkubectl apply -f pv.yaml --namespace \"weaviate\"\nkubectl apply -f pvc.yaml --namespace \"weaviate\"\nhelm upgrade --install \"weaviate\" weaviate/weaviate --namespace \"weaviate\" --values ./values.yaml\n\nalso running kubectl get pvc --namespace \"weaviate\" gives me:\nNAME                       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\ntask-pv-claim              Bound    task-pv-volume                             32Gi       RWO            hostpath       2s\nweaviate-data-weaviate-0   Bound    pvc-d5690f50-9822-4369-a4b0-eb584140a7f6   32Gi       RWO            hostpath       2s\n\n----------\n\n[DudaNogueira (2023-10-17T13:41:08.139Z)]: Hi @chirag-phlo !\nSorry for the delay here. Missed this one \nWere you able to solve this? This seems more a K8s question instead of a Weaviate one.\nI am no K8s expert (still learning it) but I may be able to proxy this to some more experienced colleagues.\nThanks!\n\n----------\n\n[00.lope.naughts (2024-11-21T16:42:05.043Z)]: @chirag-phlo Did you manage to get it to work? I am also trying this locally.\nmacOS + docker + minikube + helm (very similar to Achieve Zero-Downtime Upgrades with Weaviate’s Multi-Node Setup | Weaviate) where I want to retry replication = 3. For each node, I want their /var/lib/weaviate to map to an external disk with different folders named like /Volumes/My_Disk/weaviate-node-0 , …/weaviate-node-1, …/weaviate-node-2\nhere’s the section I changed for values.yaml:\n# The Persistent Volume Claim settings for Weaviate. If there's a\n# storage.fullnameOverride field set, then the default pvc will not be\n# created, instead the one defined in fullnameOverride will be used\nstorage:\n  size: 50Gi\n  storageClassName: \"\"\n  existingClaim: true\n  fullnameOverride: \"weaviate-pvc\"  # Explicitly disable the default PVC creation\n\n# Add the extraVolumes and extraVolumeMounts sections to use your manually created PVCs\nextraVolumes:\n  - name: weaviate-data-0\n    persistentVolumeClaim:\n      claimName: weaviate-pvc-0\n  - name: weaviate-data-1\n    persistentVolumeClaim:\n      claimName: weaviate-pvc-1\n  - name: weaviate-data-2\n    persistentVolumeClaim:\n      claimName: weaviate-pvc-2\n\nextraVolumeMounts:\n  - name: weaviate-data-0\n    mountPath: /var/lib/weaviate\n    subPath: node-0\n  - name: weaviate-data-1\n    mountPath: /var/lib/weaviate\n    subPath: node-1\n  - name: weaviate-data-2\n    mountPath: /var/lib/weaviate\n    subPath: node-2\n\nand my pvs.yaml:\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: weaviate-pv-0\nspec:\n  capacity:\n    storage: 50Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: \"/Volumes/My_Disk/weaviate-node-0\"\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: weaviate-pv-1\nspec:\n  capacity:\n    storage: 50Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: \"/Volumes/My_Disk/weaviate-node-1\"\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: weaviate-pv-2\nspec:\n  capacity:\n    storage: 50Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: \"/Volumes/My_Disk/weaviate-node-2\"\n\nand pvcs.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: weaviate-pvc-0\n  namespace: weaviate\nspec:\n  storageClassName: \"\"  # Add this line\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  volumeName: weaviate-pv-0\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: weaviate-pvc-1\n  namespace: weaviate\nspec:\n  storageClassName: \"\"  # Add this line\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  volumeName: weaviate-pv-1\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: weaviate-pvc-2\n  namespace: weaviate\nspec:\n  storageClassName: \"\"  # Add this line\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  volumeName: weaviate-pv-2\n\nnote that the only diff is I added the namespace in pvcs.yaml (I also tried without it, and other variations in other parts). And like @chirag-phlo, it also resulted in that weaviate-data-weaviate-0 PV getting created and assigned, which isnt right.\nkubectl get pvc -n weaviate\n\nNAME                       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE\nweaviate-data-weaviate-0   Bound    pvc-f42cdf50-e227-4339-90e9-0afc929ac2b2   50Gi       RWO            standard       <unset>                 4m5s\nweaviate-data-weaviate-1   Bound    pvc-a556ed20-9455-4712-a155-a06cc25d9fdd   50Gi       RWO            standard       <unset>                 4m5s\nweaviate-data-weaviate-2   Bound    pvc-2b88f11e-fc9c-49c1-8719-473fdc673879   50Gi       RWO            standard       <unset>                 4m5s\nweaviate-pvc-0             Bound    weaviate-pv-0                              50Gi       RWO                           <unset>                 5m48s\nweaviate-pvc-1             Bound    weaviate-pv-1                              50Gi       RWO                           <unset>                 5m48s\nweaviate-pvc-2             Bound    weaviate-pv-2                              50Gi       RWO                           <unset>                 5m48s\n\nI think something is still wrong in my values.yaml, esp. about fullnameOverride, which I have low confidence I did the right thing.\nif you have any information, please do share. Maybe if everything is figured out and great, I can help put together a quick blog if this helps others.",
    "date_created": "2023-08-30T18:02:03.482Z",
    "has_accepted_answer": false,
    "title": "Cannot bind to existing PVC",
    "topic_id": 598
  },
  {
    "user_id": 1218,
    "conversation": "[aparna_raj (2024-07-18T13:27:17.557Z)]: Description\n\nWe are using an on prem instance of weaviate. We were able to do some data insertion and retrieval but started getting 401 error and unable to identify the root cause. using multi tenancy model here. here are the error logs for reference.\neaviate.exceptions.WeaviateQueryError: Query call with protocol GQL Aggregate failed with message Error in GraphQL response: [\n{\n“locations”: [\n{\n“column”: 12,\n“line”: 1\n}\n],\n“message”: \"shard Tenantname: status code: 401, error: \",\n“path”: [\n“Aggregate”,\n“collection1”\n]\n}\n], for the following query: {Aggregate{NaaS1(tenant: “Tname”){meta{count}}}}.\nsys:1: ResourceWarning: unclosed <ssl.SSLSocket fd=4, family=2, type=1, proto=0, laddr=(‘10.110.183.26’, 53626), raddr=(‘173.37.11.56’, 6380\nAny guidance on this error is much appreciated.\n\n----------\n\n[DudaNogueira (2024-07-18T13:41:53.046Z)]: hi @aparna_raj !!\nWelcome to our community!\nPlease, when asking for support in forums, always fill in the requested infos like version, deployment, etc.\nPlease, can you share the code used for creating the collection, tenant and ingesting some data?\nTHanks!\n\n----------\n\n[aparna_raj (2024-07-18T15:41:50.495Z)]: Hi Duda\nPlease find the details below\nWeaviate Server Version: 1.25.7\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python 3.12\nMultitenancy?: yes\nCreate multi-tenancy Cluster\ndef create_collection(client, tenant):\n     if client.collections.exists(\"collname\"):\n        client.collections.delete(\"collname \")\n\ncoll = client.collections.create(\n    name=\" collname \",\n    multi_tenancy_config=Configure.multi_tenancy(\n        enabled=True,\n        auto_tenant_activation=True\n    ),\n    # Enabling the vectorizer\n   \n    vectorizer_config=wc.Configure.Vectorizer.text2vec_cohere(model=\"embed-english-v3.0\"),\n    generative_config=wc.Configure.Generative.cohere(model=\"command-xlarge-nightly\"),\n\n    properties=[\n        wc.Property(name=\"source\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"raw_text\", data_type=wc.DataType.TEXT),\n    ],\n)\n\n# Create a tenant inside a collection\ncoll.tenants.create(\n    tenants=[\n        Tenant(name=tenant)\n    ]\n)\ntenants = coll.tenants.get()\nprint(tenants)\n\nprint(\"Collection created successfully: collname\")\n\nInserting the data in Multi tenant collection\ndef insert_data(wvc, content, tenant):\nuuid_lst = \nbase_coll = wvc.collections.get(\"collname\")\ncollection = base_coll.with_tenant(tenant)\n\n# Insert the data objects\nwith collection.batch.fixed_size(\n        batch_size=50,\n        # concurrent_requests=1\n) as batch:\n    batch.add_object(content)\n\n#import pdb; pdb.set_trace()\nprint(\"Data inserted successfully: collname \")\n\nif len(collection.batch.failed_objects) > 0:\n    print(\"Failed to insert data\")\n    for failed_object in collection.batch.failed_objects:\n        print(failed_object)\n\nprint(collection.aggregate.over_all())\n\nreturn collection",
    "date_created": "2024-07-18T13:27:17.500Z",
    "has_accepted_answer": false,
    "title": "Getting 401 error with data insertion",
    "topic_id": 3091
  },
  {
    "user_id": 2014,
    "conversation": "[Bjellis (2024-10-22T11:29:56.338Z)]: I’m new to Weaviate and GraphQL. I have been struggeling with a statement for hours, but still no love:\n{\nGet {\nTrasami_analyse_data {\ncustomer_id\nproject_id\ndata_partial\n}\n}\ngenerate {\nnearText {\nconcepts: [“Sales leads”]  # Reconfirm correct usage\nlimit: 3\ngroupedTask: “Explain why these sales leads fall under the specified date range.”\n}\n}\n}\nI’d really appreciate if someone could point me in the right direction on this.\nThis is the error message I get when running the statement in the Weaviate Query Interface: {\n“errors”: [\n{\n“locations”: [\n{\n“column”: 23,\n“line”: 11\n}\n],\n“message”: “Syntax Error GraphQL request (11:23) Expected Name, found [\\n\\n10:         nearText {\\n11:             concepts: [\"Sales leads\"]  # Reconfirm correct usage\\n                          ^\\n12:             limit: 3\\n”,\n“path”: null\n}\n]\n}\nThanks!\n\n----------\n\n[DudaNogueira (2024-11-01T14:45:50.451Z)]: hi @Bjellis !!\nSorry for the delay here. Missed this message \nWere you able to solve this?",
    "date_created": "2024-10-22T11:29:56.298Z",
    "has_accepted_answer": false,
    "title": "A little help with GraphQL please",
    "topic_id": 5837
  },
  {
    "user_id": 1239,
    "conversation": "[hanumanhuda (2024-10-01T13:44:20.625Z)]: We have upgraded weaviate from 1.24.23 to 1.26.4 and our index had 1.5M chunks earlier, however it is showing 0 chunks after upgrading. Used below API for getting node details localhost:25082/v1/nodes?output=verbose\nSetup: K8s without helm.\n#nodes: 1 node and 3 shards.\n\n----------\n\n[DudaNogueira (2024-10-01T15:25:40.811Z)]: hi @hanumanhuda !!\nHAve you upgraded from 1.24 directly to 1.26?\nThis is not recommended, as there are some migrations.\nThe recommendation is to go from 1.24 to 1.25.latest, then to 1.26.latest\nDo you see any errors on server logs?\n\n----------\n\n[hanumanhuda (2024-10-01T15:30:18.139Z)]: yes, we did directly from 1.24 to 1.26, There wasn’t any specific documentation to move from 1.24 to 1.25 prior to 1.26. Is that data lost or still recoverable by moving to 1.25 then 1.26?\n\n----------\n\n[hanumanhuda (2024-10-01T15:36:41.424Z)]: There are no errors in the logs.\n\n----------\n\n[DudaNogueira (2024-10-02T12:11:52.945Z)]: it was probably not lost, but some migration probably hasn’t been properly done.\nMy suggestion is to restore the backup, set the version to 1.24, then do the migration on stages as described.\nLet me know if that helps!\n\n----------\n\n[hanumanhuda (2024-10-03T08:43:37.018Z)]: Even with downgrade back to 1.24.23, it is not showing any chunks.\n\n----------\n\n[DudaNogueira (2024-10-03T15:36:13.353Z)]: hi @hanumanhuda !!\nOnly downgrading may not be sufficient.\nYou will need to restore the backup, and then proceed with the migrations.\nAlso, can you send me the contents of the persistence path of your cluster?\nYou can find that path under the env variable: PERSISTENCE_DATA_PATH\nThanks!\n\n----------\n\n[hanumanhuda (2024-10-14T09:13:01.570Z)]: Here is the files in that path after migration:\nclassifications.db\t\t\t\t\t\t\t       migration1.19.filter2search.skip.flag\nib_ai_labs_0fa85771_3adb_4990_b49f_0648154b9cc7\t\t\t\t       migration1.19.filter2search.state\nib_ai_labs_0fa85771_3adb_4990_b49f_0648154b9cc7_FpY88CE0uVkQ.hnsw.commitlog.d\nmigration1.22.fs.hierarchy\nib_ai_labs_0fa85771_3adb_4990_b49f_0648154b9cc7_FpY88CE0uVkQ.indexcount\nmodules.db\nib_ai_labs_0fa85771_3adb_4990_b49f_0648154b9cc7_FpY88CE0uVkQ_lsm\t       raft\nib_ai_labs_0fa85771_3adb_4990_b49f_0648154b9cc7_FpY88CE0uVkQ.proplengths\nschema.db\nib_ai_labs_0fa85771_3adb_4990_b49f_0648154b9cc7_FpY88CE0uVkQ.proplengths.bak\nschema.db_v0.bak\nib_ai_labs_0fa85771_3adb_4990_b49f_0648154b9cc7_FpY88CE0uVkQ.version\t       tx.db\n\n----------\n\n[DudaNogueira (2024-10-14T23:07:57.825Z)]: Not sure how to recover.\nProbably the migration jumping versions did a number here \nCan you reimport that data? Or restore it from a backup before the migration?",
    "date_created": "2024-10-01T13:44:20.572Z",
    "has_accepted_answer": false,
    "title": "Chunks are missing in weaviate Upgrade to 1.26.4 from 1.24.23",
    "topic_id": 4386
  },
  {
    "user_id": 323,
    "conversation": "[Dharanish (2023-10-01T12:49:48.493Z)]: {“action”:“startup”,“error”:“could not load or initialize schema: sync schema with other nodes in the cluster: corrupt cluster: other nodes have consensus on schema, but local node has a different (non-null) schema: class models mismatch: class count mismatch: 12!=0”,\nHi Team, I am facing  this issue how to resolve it\n\n----------\n\n[DudaNogueira (2023-10-03T11:38:25.780Z)]: Hi! Were you able to solve this?\nI have never faced it myself, and asked internally for some guidance. As soon as I get a feedback I will post it here.\nThanks!\n\n----------\n\n[Dharanish (2023-10-03T12:15:42.000Z)]: Hi , I cant solve this problem, does locally remove the files of that particular classes\nwill helpful and not cause any other issue ?\nI need a proper solution for that.\n\n----------\n\n[Dharanish (2023-10-05T05:06:07.855Z)]: Hi  , I am using the env variable CLUSTER_SKIP_SCHEMA_REPAIR set to false, but still facing the above issue. does the above variable is correct or any other issue?\nplease provide me a correct solution.\n\n----------\n\n[Dharanish (2024-08-28T06:58:45.596Z)]: Hi , I am currently using the version 1.23.11 , and still getting the above issue\nschema still out of sync: read schema: open transaction: broadcast open transaction: try to reach consenus: did not reach consensus on schema in cluster: class models mismatch: class count mismatch: 1349!=1619\"  makes crashloop\n\n----------\n\n[DudaNogueira (2024-08-28T20:33:00.488Z)]: Can you try latest version?\nThere were a lot of improvements on cache repair.\nI recommend spinning up a new cluster and moving your data over, as this will not only get you a latest version server but also an fix any error in index/schema you seems to be facing.",
    "date_created": "2023-10-01T12:49:48.451Z",
    "has_accepted_answer": false,
    "title": "Schema Sync Error",
    "topic_id": 759
  },
  {
    "user_id": 576,
    "conversation": "[kamal (2024-02-03T09:19:27.334Z)]: So i’m not able to setup weaviate cluster using docker swarm using 2 VMs.\nHere is my docker compose file i’m using\nversion: '3.8'\n\nnetworks:\n  cluster_network:\n    driver: overlay\n\nservices:\n  weaviate-node-1:\n    init: true\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: semitechnologies/weaviate:1.23.6\n    ports:\n      - 8080:8080\n      - 6060:6060\n      - 50051:50051\n      - 7100:7100\n      - 7101:7101\n    restart: on-failure:0\n    volumes:\n      - ./data-node-1:/var/lib/weaviate\n    environment:\n      LOG_LEVEL: 'debug'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      CLUSTER_HOSTNAME: 'node1'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'\n    networks:\n      - cluster_network\n\n  weaviate-node-2:    \n    init: true\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: semitechnologies/weaviate:1.23.6\n    ports:\n      - 8081:8080\n      - 6061:6060\n      - 50052:50051\n      - 7102:7102\n      - 7103:7103\n    restart: on-failure:0\n    volumes:\n      - ./data-node-2:/var/lib/weaviate\n    environment:\n      LOG_LEVEL: 'debug'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      CLUSTER_HOSTNAME: 'node2'\n      CLUSTER_GOSSIP_BIND_PORT: '7102'\n      CLUSTER_DATA_BIND_PORT: '7103'\n      CLUSTER_JOIN: '10.2.0.4:7100'\n    deploy:      \n      placement:\n        constraints: \n        - node.labels.node == node2\n    networks:\n      - cluster_network\n\n\nservice started using\ndocker stack deploy --compose-file docker-compose.yml stackdemo\n\n\nservice status\n docker stack services stackdemo                                                                                                           master-node: Sat Feb  3 09:17:43 2024\n\nID             NAME                        MODE         REPLICAS   IMAGE                              PORTS\nnmpy53htqsn3   stackdemo_weaviate-node-1   replicated   1/1        semitechnologies/weaviate:1.23.6   *:6060->6060/tcp, *:7100-7101->7100-7101/tcp, *:8080->8080/tcp, *:50051->50051/tcp\n061zi7aflznv   stackdemo_weaviate-node-2   replicated   1/1        semitechnologies/weaviate:1.23.6   *:6061->6060/tcp, *:7102-7103->7102-7103/tcp, *:8081->8080/tcp, *:50052->50051/tcp\n\n\n\nlogs on node 1\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"finished initializing modules\",\"time\":\"2024-02-03T09:00:36Z\"}\n{\"action\":\"graphql_rebuild\",\"level\":\"debug\",\"msg\":\"rebuilding the graphql schema\",\"schema\":{\"Objects\":{\"classes\":[]}},\"time\":\"2024-02-03T09:00:36Z\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-02-03T09:00:36Z\"}\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2024-02-03T09:00:36Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=10.0.0.2:39936\",\"time\":\"2024-02-03T09:00:41Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-02-03T09:00:43Z\"}\n{\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-02-03T09:00:44Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-02-03T09:00:44Z\"}\n{\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-02-03T09:00:46Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-02-03T09:00:47Z\"}\n{\"level\":\"info\",\"msg\":\" memberlist: Marking node2 as failed, suspect timeout reached (0 peer confirmations)\",\"time\":\"2024-02-03T09:00:48Z\"}\n{\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-02-03T09:00:50Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=10.0.0.2:49374\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=10.0.0.2:41916\",\"time\":\"2024-02-03T09:01:54Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-02-03T09:01:55Z\"}\n{\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-02-03T09:01:59Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node2 (timeout reached)\",\"time\":\"2024-02-03T09:02:00Z\"}\n{\"level\":\"info\",\"msg\":\" memberlist: Marking node2 as failed, suspect timeout reached (0 peer confirmations)\",\"time\":\"2024-02-03T09:02:03Z\"}\n{\"level\":\"info\",\"msg\":\" memberlist: Suspect node2 has failed, no acks received\",\"time\":\"2024-02-03T09:02:05Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=10.0.0.2:42368\",\"time\":\"2024-02-03T09:02:30Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Stream connection from=10.0.0.2:34052\",\"time\":\"2024-02-03T09:03:08Z\"}\n\n\nlogs on node 2\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"created startup context, nothing done so far\",\"startup_time_left\":\"59m59.998706476s\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"config loaded\",\"startup_time_left\":\"59m59.99841207s\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"configured OIDC and anonymous access client\",\"startup_time_left\":\"59m59.99838947s\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"initialized schema\",\"startup_time_left\":\"59m59.998361669s\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Initiating push/pull sync with:  10.2.0.4:7100\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"level\":\"warning\",\"msg\":\" memberlist: Refuting a suspect message (from: node2)\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"startup routine complete\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"start registering modules\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"module\":\"text2vec-openai\",\"msg\":\"enabled module\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"module\":\"text2vec-huggingface\",\"msg\":\"enabled module\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"module\":\"text2vec-cohere\",\"msg\":\"enabled module\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"action\":\"startup\",\"level\":\"debug\",\"msg\":\"completed registering modules\",\"time\":\"2024-02-03T09:01:17Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node1 (timeout reached)\",\"time\":\"2024-02-03T09:01:19Z\"}\n{\"level\":\"info\",\"msg\":\" memberlist: Suspect node1 has failed, no acks received\",\"time\":\"2024-02-03T09:01:20Z\"}\n{\"level\":\"debug\",\"msg\":\" memberlist: Failed UDP ping: node1 (timeout reached)\",\"time\":\"2024-02-03T09:01:22Z\"}\n{\"level\":\"info\",\"msg\":\" memberlist: Suspect node1 has failed, no acks received\",\"time\":\"2024-02-03T09:01:24Z\"}\n{\"level\":\"info\",\"msg\":\" memberlist: Marking node1 as failed, suspect timeout reached (0 peer confirmations)\",\"time\":\"2024-02-03T09:01:24Z\"}\n{\"action\":\"startup\",\"error\":\"could not load or initialize schema: sync schema with other nodes in the cluster: read schema: open transaction: broadcast open transaction: host \\\"172.25.0.3:7101\\\": send http request: Post \\\"http://172.25.0.3:7101/schema/transactions/\\\": dial tcp 172.25.0.3:7101: i/o timeout\",\"level\":\"fatal\",\"msg\":\"could not initialize schema manager\",\"time\":\"2024-02-03T09:01:47Z\"}\n\n----------\n\n[DudaNogueira (2024-02-06T18:54:55.409Z)]: Hi @kamal !\nWelcome to our community \nWhile I have played with some weavaite + grpc + traefik + let’s encrypt\nI habe not yet used docker swarm.\non CLUSTER_JOIN, have you tried using something like weaviate-node-1?\nI was able to run two nodes using docker compose here:\n\n  \n    \n    \n    Can only Docker Compose be used for multi node deployment? Support\n  \n  \n    Hi @codehelen ! Welcome to our community  \nThis must be some networking issue along the way, as your docker is correct (see below) \nA starting point is making sure that weaviate-node2-IP can communicate with weaviate-node1-IP on all specified ports. \nA good example on how to run with ad-hoc containers (at the same docker host): \nFirst, create a docker attachable network\ndocker network create weaviate --atachable\n\nnote that weaviate, above, can be whatever network name you want. Mak…\n  \n\n\nLet me know if this helps… or will give us a different error \nThanks!\n\n----------\n\n[fenglizzz (2024-03-15T06:08:24.260Z)]: Hi I am experiencing exact same error. And I have tried exactly as you post here Can only Docker Compose be used for multi node deployment? - #2 by DudaNogueira, using ’ weaviate-node-1 on CLUSTER_JOIN. But it will throw the error that \"cannot find weaviate-node-1\". I guess this is because ' weaviate-node-1is deployed to another machine and that is why it cannot be found.\n\n----------\n\n[DudaNogueira (2024-03-15T14:14:07.909Z)]: Hi @fenglizzz !\nCheck this thread for a complete example on multinode with docker compose:\n  \n    \n    \n    Docker Compose with multi node deployment issue Support\n  \n  \n    Hi @fenglizzz !! Welcome to our community  \nIt’s not a good idea to reference the CLUSTER_JOIN by IPs (or any container to container connection inside docker/k8s to be fair), as those will eventually change down the road, or maybe even after a reboot. \nHere are some steps to get this party going.  \nFirst, let’s create a docker attachable network: \ndocker network create --attachable weaviate\n\nNow, using the latest docker compose, and using this doc to adjust it to a multi nod…\n\n----------\n\n[jasper2077 (2024-12-02T02:03:52.844Z)]: Hello, I’m currently facing the same issue. Have you figured out how to solve the error?",
    "date_created": "2024-02-03T09:19:26.872Z",
    "has_accepted_answer": true,
    "title": "Failed while setting Multi node cluster using docker swarm on 2 VM",
    "topic_id": 1364
  },
  {
    "user_id": 1329,
    "conversation": "[Abg79 (2024-08-22T19:35:32.574Z)]: I have generated vector embeddings using the AWS Titan Embedding model and uploaded them with their properties into Weaviate. I’m trying to run queries on specific programs. I have question about the best approach in v4 version. Below is the code I used:\nPython\n# Step 2: Define the collection for the 'Document' class\nfrom weaviate.classes.config import Configure, Property, DataType\n\ncollection_snap = {\n    \"class\": \"Document_snap\",\n    \"description\": \"A class to represent documents of SNAP\",\n    \"vectorizer\": \"none\",  # Set to \"none\" because embeddings are provided\n    \"moduleConfig\": {\n        # \"text2vec-openai\": {},  # Configure if using OpenAI vectorization\n        # \"generative-openai\": {}  # Configure if using generative queries\n    },\n    \"properties\": [\n        {\"name\": \"url\", \"dataType\": [\"text\"]},\n        {\"name\": \"title\", \"dataType\": [\"text\"]},\n        {\"name\": \"chunks\", \"dataType\": [\"text\"]},\n        {\"name\": \"program\", \"dataType\": [\"text\"]},  # includes 'program1', 'program2', 'program3'\n    ]\n}\n\n# Batch Upload:\nwith client.batch.dynamic() as batch:\n    for i, row in df_combined.iterrows():\n        print(f\"Importing document: {i+1}\")\n        properties = {\n            \"url\": row[\"url\"],\n            \"title\": row[\"title\"],\n            \"chunks\": row[\"chunks\"],\n            \"program\": row[\"program\"],  # includes 'program1', 'program2', 'program3'\n        }\n        batch.add_object(\n            collection=\"Document_snap\",  # Specify the collection name here\n            vector=row[\"embeddings\"],\n            properties=properties\n        )\n    failed_objs_a = client.batch.failed_objects\nprint('batch import successful')\nprint(len(failed_objs_a))\n\n# Filter programs based on user choice:\nUser_request_program_options = {\n    'p1': 'program1',\n    'p2': 'program2',\n    'p3': 'program3',\n    'All': ['program1', 'program2', 'program3']\n}\n\nQuestion 1: Is this the right way to run a query with a filter on a single program?\nPython\n# Query 1:\nUser_program_request = User_request_program_options['p1'] #program1\n\ndocument_collection = client.collections.get(\"Document_snap\")\nresponse = document_collection.query.near_vector(\n    filters=(\n        Filter.by_property(\"program\").equal(User_program_request)\n    ),\n    near_vector=query_vector, \n    limit=2,\n    return_metadata=MetadataQuery(distance=True)\n)\n\nfor o in response.objects:\n    print(o.properties)\n    print(o.metadata.distance)\n\nquery = collection.query.fetch_objects(\n    filters=(\n        Filter.by_property(\"program\").equal(User_program_request)\n    )\n)\n\n\nTitle: Running Vector Query with Filter on Weaviate v4 - Multiple Programs Filter\nQuestion 2: How about if the user’s choice is the ‘All’ option, which includes all three programs? Is this the right way to run the query?\nPython\nQuery 2:\nUser_program_request = User_request_program_options[‘All’] # ‘program1’, ‘program2’, ‘program3’\ndocument_collection = client.collections.get(“Document_snap”)\nresponse = document_collection.query.near_vector(\nfilters=(\nFilter.by_property(“program”).equal(User_program_request)\n),\nnear_vector=query_vector,\nlimit=2,\nreturn_metadata=MetadataQuery(distance=True)\n)\nfor o in response.objects:\nprint(o.properties)\nprint(o.metadata.distance)\n\n----------\n\n[Abg79 (2024-08-23T15:34:19.244Z)]: Is there anyone that can help me with Vector query with filter? I appreciate any help!\n\n----------\n\n[DudaNogueira (2024-08-23T16:48:22.229Z)]: Hi!\nYou can check if the user has selected All and never apply that filter.\nsomething like this:\n#base filter\nfilters=(\n    Filter.by_property(\"color\").equal(\"grau\") & \n    Filter.by_property(\"price\").less_or_equal(300)\n)\n\nif selected != \"All\" or selected != None:\n    filters = filters & Filter.by_property(\"program\").equal(selected)\n\nquery = collection.query.fetch_objects(\n    filters=filters\n)\n\nfor object in query.objects:\n    print(object.properties)\n\nWe were discussing more on conditional filters in code here:\n  \n    \n    \n    Conditional filter with python client v4 Support\n  \n  \n    Hi @jhc !! \nNo worries. I think I got you covered. \nIs this what you are looking for? \nGiven this dataset: \nimport weaviate\nclient = weaviate.connect_to_local()\nfrom weaviate.classes.query import Filter\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(name=\"Test\")\ncollection.data.insert({\"color\": \"grau\", \"price\": 300, \"location\": \"Brazil\"})\ncollection.data.insert({\"color\": \"grau\", \"price\": 400, \"location\": \"Netherlands\"})\ncollection.data.insert({\"color\": \"grau\", \"price\":…\n  \n\n\nLet me know if this helps!\n\n----------\n\n[Abg79 (2024-08-27T18:55:56.064Z)]: That helped, thank you!",
    "date_created": "2024-08-22T19:35:32.524Z",
    "has_accepted_answer": true,
    "title": "Running Vector Query with Filter on Weaviate v4",
    "topic_id": 3435
  },
  {
    "user_id": 509,
    "conversation": "[2020ashish (2024-11-14T13:41:07.167Z)]: Description\n\nWhat is behavior of creation time and last_update time in metadata.\nWhy creation_time is always updating.\n\nimport weaviate.classes.config as wcc\nimport weaviate.classes as wvc\n\nclient.collections.create(\n    name=\"Test_time\",\n    vectorizer_config=wcc.Configure.Vectorizer.text2vec_transformers(),\n    inverted_index_config=wcc.Configure.inverted_index(\n        index_timestamps = True\n    ),\n    properties=[\n        wcc.Property(\n            name=\"question\",\n            data_type=wcc.DataType.TEXT,\n            tokenization=wcc.Tokenization.WORD,\n        ),\n        wcc.Property(\n            name=\"answer\",\n            data_type=wcc.DataType.TEXT,\n            tokenization=wcc.Tokenization.FIELD,\n        )\n    ],\n)\n\ndddd = [\n    \n    {\"question\": \"What is 2 + 2?\", \"answer\": \"41\"},\n    {\"question\": \"What is the largest ocean?\", \"answer\": \"Pacific Ocea1n\"},\n   ]\nfrom weaviate.util import generate_uuid5\nimport numpy as np\ncount=0\nwith client.batch.dynamic() as batch:\n    for idd in dddd:\n        count+=1\n        batch.add_object(\n            properties=idd,\n            vector=np.random.rand(1536),\n            collection=\"Test_time\",\n            uuid=generate_uuid5(f\"test_time-id-{count}\")\n        )\nif client.batch.failed_objects:\n    print(\"Failed Objects: \", client.batch.failed_objects)\n\nIf I again use add_object with update data like\ndddd = [\n{\"question\": \"What is 2 + 2?\", \"answer\": \"4\"},\n{\"question\": \"What is the largest ocean?\", \"answer\": \"Pacific Ocean\"},\n\n]\nWhy creation time gets updated ?\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[Mohamed_Shahin (2024-11-15T10:09:58.865Z)]: Good morning @2020ashish, Happy Friday! \nIn Weaviate, each data object has two primary timestamps:\n• creationTimeUnix: The timestamp when the object was initially created.\n• lastUpdateTimeUnix: The timestamp of the object’s most recent update.\nBoth timestamps will remain identical until the object is explicitly updated using the update_object method, which only modifies the lastUpdateTimeUnix while keeping the creationTimeUnix intact.\nHowever, in batch operations with add_object, if the same UUID is provided, Weaviate will overwrite the existing object, treating it as a new insertion. If the UUID is different, no overwriting occurs.\nDoes that make sense?\n\n----------\n\n[2020ashish (2024-11-15T10:29:17.176Z)]: Thanks @Mohamed_Shahin\nCurretly facing huge read/write operation in mentioned case.\ncan you help me optimize my code I am getting hnsw_vector_cache_prefill frequently - #5 by 2020ashish",
    "date_created": "2024-11-14T13:41:07.118Z",
    "has_accepted_answer": true,
    "title": "Metadata properties",
    "topic_id": 7572
  },
  {
    "user_id": 3058,
    "conversation": "[zzzzela (2024-12-19T12:27:51.906Z)]: Description\nI need help with Tenant specific settings like, in my case, each Tenant need to have its own title, description and reference email, just like it has activityStatus property. Also if possible, it should have specific access permission by RBAC.\nCan anyone help me set up that with TS weaviate-client v3?\nThank you!\n\n----------\n\n[Dirk (2024-12-19T21:07:10.119Z)]: Hello!\n[quote=“zzzzela, post:1, topic:9330”]\nin my case, each Tenant need to have its own title, description and reference email, just like it has activityStatus property. [/quote]\nThis is sadly currently not possible, you could do a feature request: Issues · weaviate/weaviate · GitHub\nBut you can use the tennat name as title and store the other info in a different collection?\n\nAlso if possible, it should have specific access permission by RBAC.\n\nRBAC is still in preview and currently you can only filter access by collection. Per-tenant might come later: Authorization & RBAC | Weaviate\nCurrently only the python client has support to add/assign RBAC roles, but the other clients will follow\n\n----------\n\n[zzzzela (2024-12-26T09:11:48.203Z)]: Thank you very much for your response @Dirk\nBut you can use the tennat name as title and store the other info in a different collection?\nCan you please help me on how could i do that? I’m struggling because as far as I can see, cross references are per object, not per tenant. Please look at this code I have for now:\nconst myCollection = client.collections.get('MyCollection')\n\n  const configCollection = client.collections.get('ConfigCollection')\n\n  const tenantA = myCollection.withTenant('TenantA')\n\n  await tenantA.data.referenceAdd({\n    from: {\n      id: myCollection.id,\n      property: 'hasConfig'\n    },\n    to: {\n      id: configCollection.id\n    }\n  })\n\nSo far, i dont know how could I add some data in config collection, that should reference each tenant, for example “description” property from “ConfigCollection” for tenantA?\nThank you upfront!\n\n----------\n\n[Dirk (2024-12-27T08:03:22.669Z)]: zzzzela:\n\nCan you please help me on how could i do that? I’m struggling because as far as I can see, cross references are per object, not per tenant. Please look at this code I have for now:\n\n\nI would create two collections:\n\nyour multi-tenant collection as you are using it right now\na second collection tenantInfo where you store more info about the tenant\n\nset the vectorizer to “none”\nadd a property name, description etc\nwhen you want to get the extra info you can query the extra collection with a filter name==your_tenant_name\n\n\n\ndon’t think there is currently a different way to do it\n\n----------\n\n[zzzzela (2024-12-30T21:50:25.847Z)]: Thank you! And sorry once again for this beginner question. I come from Postgres + pgvector, so all this NoSQL stuff is still a bit confusing to me.\n\n----------\n\n[Dirk (2024-12-31T09:03:54.271Z)]: No worries, happy to help!\nThis is somewhat of a workaround, feel free to add a feature request here: Issues · weaviate/weaviate · GitHub",
    "date_created": "2024-12-19T12:27:51.859Z",
    "has_accepted_answer": true,
    "title": "Can each tenant have specific properties and how?",
    "topic_id": 9330
  },
  {
    "user_id": 1236,
    "conversation": "[ctindel (2024-07-23T19:56:26.804Z)]: Description\nI have one of the weaviate docker configurations running on my laptop and I also have LM Studio running on my laptop so I can serve up the Llama 3 LLM with a local OpenAI compatible endpoint.\nHowever, unlike the ollama module which takes an apiEndpoint parameter, I don’t see how to set a custom local apiEndpoint for the OpenAI module.\nWhat’s the best way to call into an LM Studio LLM from a weaviate module?\n\n----------\n\n[DudaNogueira (2024-07-23T21:05:54.436Z)]: hi @ctindel !!\nWelcome to our community \nI have not played with LM Studio! Just downloaded it here. Awesome project!\nYou can set a base url at query time or define it at collection creation.\nHere is the code I crafted, based on our quickstart:\nimport weaviate\nfrom weaviate import classes as wvc\n\nclient = weaviate.connect_to_local()\n\nclient.collections.delete(\"Question\")\nquestions = client.collections.create(\n    name=\"Question\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(\n        base_url=\"http://host.docker.internal:1234\"\n    ),  # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n    generative_config=wvc.config.Configure.Generative.openai(\n        base_url=\"http://host.docker.internal:1234\"\n    )  # Ensure the `generative-openai` module is used for generative queries\n)\n\n# insert data\nimport requests, json\nresp = requests.get('https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json')\ndata = json.loads(resp.text)  # Load data\n\nquestion_objs = list()\nfor i, d in enumerate(data):\n    question_objs.append({\n        \"answer\": d[\"Answer\"],\n        \"question\": d[\"Question\"],\n        \"category\": d[\"Category\"],\n    })\n\nquestions = client.collections.get(\"Question\")\nquestions.data.insert_many(question_objs)\n\n# now query\n\nquestions = client.collections.get(\"Question\")\n\nresponse = questions.query.near_text(\n    query=\"biology\",\n    limit=2\n)\nprint(response.objects[0].properties)\n\n# now let's generate some content\ngenerate = questions.generate.near_text(limit=2, query=\"biology\", grouped_task=\"generate a tweet about the questions {question}\")\n\nthe output:\n\nHere’s a tweet about the questions:\n“Did you know? Watson & Crick built a model of DNA in 1953! And, did you know that our liver is responsible for removing excess glucose from the blood and storing it as glycogen? Mind blown! #ScienceFacts #DNA #LiverFunction”\nExplanation:\nThe response generates a tweet by combining information from the provided questions. The first question asks about the molecular structure of DNA, which Watson & Crick built in 1953. The second question talks about the liver’s role in removing excess glucose and storing it as glycogen. The response combines these facts into a concise and engaging tweet that includes relevant hashtags to make it discoverable by others interested in science and health-related topics.\n\nLooking at LM logs, I can see data going thru it:\nimage2254×936 327 KB\nand here the generate part:\nimage1846×924 110 KB\nLet me know if this helps!\nThanks!\n\n----------\n\n[ctindel (2024-07-24T05:06:59.824Z)]: Yes that is very helpful!\nIt’s confusing because the docs pages for the text2vec_openai module (text2vec-openai | Weaviate - Vector Database) refer to it in camel case like “baseURL”\nHowever now I’m getting this error:\nFailed to import 1 objects\ne.g. Failed to import object with error: WeaviateInsertManyAllFailedError(‘Every object failed during insertion. Here is the set of all errors: send POST request: Post “http://host.docker.internal:1234/v1/embeddings”: context deadline exceeded (Client.Timeout exceeded while awaiting headers)’)\nAnd I’m wondering if generating the vector is just taking too long because its a large object. Is there an equivalent in openai_text2vec of the text_fields parameter used in multi2vec-bind ? Like, without using named indexes how do I tell openai_text2vec which properties to use for generating the vector?\n\n----------\n\n[DudaNogueira (2024-07-24T20:50:50.822Z)]: Ok! We had an opportunity to tackle this in our office hours, and the issue was that the embedding model was not defined in LM Studio.\nWhen using LM Studio, make sure to also load an embbeding model. So this should work:\ncurl http://localhost:1234/v1/embeddings \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer THIS_WILL_BE_IGNORED\" \\\n  -d '{\n    \"input\": \"Your text string goes here\",\n    \"model\": \"THIS WILL ALSO BE IGNORED\"\n  }'\n\nTHanks!",
    "date_created": "2024-07-23T19:56:26.756Z",
    "has_accepted_answer": false,
    "title": "How to use weaviate with LM Studio?",
    "topic_id": 3136
  },
  {
    "user_id": 934,
    "conversation": "[saurbhhsharrma (2024-08-27T02:48:51.271Z)]: Description\nI am integrating Glue Streaming with Weaviate using Spark Connector. I have uploaded Spark connector jar in S3, and added S3 path in Glue job. After adding, I have below code in my Glue Job.\n@DudaNogueira\ntry:\n    spark = SparkSession.builder.config(\n        \"spark.jars\",\n        \"spark-connector-assembly-1.3.2.jar\", \n    ).appName(\"KafkaToS3\") \\\n        .getOrCreate()\nexcept Exception as e:\n    logger.error(f\"Failed to initialize SparkSession: {str(e)}\")\n    traceback.print_exc()\n    sys.exit(1)\n\n@hsm207 - I’m referring your post for the above.\n  \n      \n\n      weaviate.io – 26 Sep 23\n  \n\n  \n    \n\nMake Real-Time AI a Reality with Weaviate + Confluent | Weaviate - Vector...\n\n  Learn how to build an application using Weaviate and Confluent\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nServer Setup Information\n\nWeaviate Server Version: 1.26\nDeployment Method: Docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python, 3\nMultitenancy?: Yes\n\n----------\n\n[DudaNogueira (2024-08-27T13:18:28.644Z)]: hi @saurbhhsharrma !!\nI have not used the Spark Connector yet \nIts on my lists of things to learn for quite a while now, hehehe\nSorry, not sure if I got it, are you facing any issues here or just sharing the code?\nThanks!",
    "date_created": "2024-08-27T02:48:51.215Z",
    "has_accepted_answer": false,
    "title": "Spark connector with Weaviate",
    "topic_id": 3661
  },
  {
    "user_id": 1274,
    "conversation": "[ROHAN_BALKONDEKAR (2024-08-01T14:45:13.286Z)]: Description\nI am using Weaviate locally with a Docker container and the Weaviate Python client. I encounter a “Deadline Exceeded” error when trying to insert a large batch of data.\nCode:\nimport weaviate\nimport os\n\nclient = weaviate.Client(\n    url=\"http://localhost:8080\",\n    additional_headers={\n        \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"]  # Replace with your inference API key\n    },\n)\n\nclient.schema.create_class({\n    \"class\": \"work_steps\",\n    \"vectorizer\": \"text2vec-openai\",\n    \"module_config\": {\n        \"generative-openai\": {}\n    }\n})\n\nwork_steps_data = [\n    {\"wtd_text\": d[\"wtd_text\"], \"wta_text\": d[\"wta_text\"]}\n    for d in data_json\n]\n\n# len(work_steps_data)  # 106954\n\ntry:\n    client.batch.create_objects(work_steps_data)\nexcept weaviate.exceptions.WeaviateBatchError as e:\n    print(f\"Error: {e}\")\n\nError:\n{\n    \"name\": \"WeaviateBatchError\",\n    \"message\": \"Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\n    status = StatusCode.DEADLINE_EXCEEDED\n    details = \\\"Deadline Exceeded\\\"\n    debug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_message:\\\"Deadline Exceeded\\\", grpc_status:4, created_time:\\\"2024-08-01T18:14:40.555441469+04:00\\\"}\\\"\n>.\",\n    ...\n}\n\ndocker-compose.yaml\nversion: '3.4'\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:1.25.6\n    ports:\n      - 8080:8080\n      - 50051:50051\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    environment:\n      CLIP_INFERENCE_API: 'http://multi2vec-clip:8080'\n      OPENAI_APIKEY: $OPENAI_APIKEY\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'multi2vec-clip'\n      ENABLE_MODULES: 'multi2vec-clip,generative-openai,generative-cohere,text2vec-openai,text2vec-huggingface,text2vec-cohere,reranker-cohere'\n      CLUSTER_HOSTNAME: 'node1'\n    restart: on-failure:0\n  multi2vec-clip:\n    image: semitechnologies/multi2vec-clip:sentence-transformers-clip-ViT-B-32-multilingual-v1\n    environment:\n      ENABLE_CUDA: '0'\nvolumes:\n  weaviate_data:\n\nAdditional Information\nDocker Logs:\nweaviate-1        | {\"action\":\"startup\",\"default_vectorizer_module\":\"multi2vec-clip\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"multi2vec-clip\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-08-01T07:04:33Z\"}\n...\nweaviate-1        | {\"level\":\"warning\",\"msg\":\"prop len tracker file /var/lib/weaviate/work_steps/iPkMMMILWoTR/proplengths does not exist, creating new tracker\",\"time\":\"2024-08-01T08:54:43Z\"}\n...\nmulti2vec-clip-1  | INFO:     Model initialization complete\n...\nweaviate-1        | {\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-08-01T07:04:38Z\"}\n\nProblem\nI am trying to insert a large dataset (about 106,954 records) into Weaviate, but I keep encountering a “Deadline Exceeded” error when using the batch insert functionality.\nQuestions\n\nHow can I avoid the “Deadline Exceeded” error during batch insertion?\nAre there any recommended configurations or settings for handling large batch inserts?\nIs there a way to increase the timeout settings for GRPC batch operations in Weaviate?\n\nAny assistance or recommendations would be greatly appreciated. Thank you!\nP.S:\nI am used below workaround for the batch upsert to avoid any errors:\nwork_step_col = client.collections.get(\"work_steps\")\n# work_step_col.data.insert_many(work_steps_data)\n\nimport time\n\nbatch_size = 1000  # Adjust the batch size as needed\nfor i in range(0, len(work_steps_data), batch_size):\n    batch = work_steps_data[i:i + batch_size]\n    work_step_col.data.insert_many(batch)\n    time.sleep(2)\n\nI has been 15 minutes and counting, so I am posting this anyway\n\n----------\n\n[andrewisplinghoff (2024-08-01T16:45:05.517Z)]: If I understand correctly you tried to import more than 100.000 objects to Weaviate at the same time? It is normal to run into problems with requests that large, what about using the dynamic batching as proposed in the documentation? It will automatically choose appropriate batch sizes for an efficient import.\nBatch import | Weaviate - Vector Database\n\n----------\n\n[ROHAN_BALKONDEKAR (2024-08-02T06:58:05.465Z)]: cool!\nI somehow completely missed dynamic batching.\nDidn’t knew this existed.  Will use this next time\nThanks",
    "date_created": "2024-08-01T14:45:13.231Z",
    "has_accepted_answer": true,
    "title": "Issue During Batch Insert",
    "topic_id": 3249
  },
  {
    "user_id": 356,
    "conversation": "[c-lara (2023-12-08T15:51:54.515Z)]: Hi all,\nusing Azure with Weaviate required defining the “moduleConfig” in the schema.\n            \"vectorizer\": \"text2vec-openai\",\n            \"moduleConfig\": {\n                \"text2vec-openai\": {\n                    \"baseURL\": \"https://COMPANYINSTANCE.openai.azure.com/\",\n                    \"resourceName\": \"COMPANYINSTANCE\",\n                    \"deploymentId\": \"text-embedding-ada-002\",\n                },\n            },\n\nI would like to use the new Weaviate client V4. However, I cannot find any way to specify it with Azure e.g., when inserting data into a collection. Is that not possible yet? Or is there a way to similarly provide the ModuleConfig somewhere so that one can pass the baseURL and the deploymentId, which are needed to use the Azure instance?\nI tried this:\nazure_openai_key = os.getenv(\"AZURE_APIKEY\")\n\nweaviate_client = weaviate.WeaviateClient(\n    connection_params=weaviate.ConnectionParams.from_params(\n        http_host=\"0.0.0.0\",\n        http_port=\"8080\",\n        http_secure=False,\n        grpc_host=\"0.0.0.0\",\n        grpc_port=\"50051\",\n        grpc_secure=False,\n    ),\n    auth_client_secret=weaviate.AuthApiKey(weaviate_secret_key),\n    additional_headers={\n        \"X-Azure-Api-Key\": azure_openai_key\n    },\n)\n\n\n    parameters = {\n        \"collection_name\": \"Test_Collection\",\n        \"vectorizer_config\": wvc.Configure.Vectorizer.text2vec_openai(\n            base_url=\"https://COMPANYINSTANCE.openai.azure.com/\", model=\"ada\"\n        ),\n        \"properties\": [\n            wvc.Property(name=\"property1\", data_type=wvc.DataType.TEXT),\n            wvc.Property(name=\"property2\", data_type=wvc.DataType.TEXT)\n        ],\n    }\n\n    inserter = Inserter(weaviate_client, \"weaviate\", parameters)\n\n    data_to_insert = {\"property1\": \"value1\", \"property2\": \"value2\"}\n\n    inserter.insert_data(data_to_insert)\n\n\nHowever, I get this error:\n[{'message': 'update vector: API Key: no api key found neither in request header: X-Openai-Api-Key nor in environment variable under OPENAI_APIKEY'}]\n\nThe problem also happened before when using V3 and not providing the baseURL (see above config), so providing it is essential. But I have not found any documentation for v4 and Azure and I was wondering whether it is currently just not possible? We would also need to define the deploymentId and within the IDE it does not suggest me any parameter like this.\nMany thanks in advance!\n\n----------\n\n[c-lara (2023-12-11T10:48:34.044Z)]: Does anybody know whether one can use Azure with the V4 Python Client?\n\n----------\n\n[DudaNogueira (2023-12-11T22:02:51.827Z)]: Hi @c-lara !!\nSorry for the delay here! \nAzure Open Ai will require some different parameters (deploymentId, resource_name and base_url) when compared with “Vanilla” Open Ai\nFor that reason, in Weaviate python v4 client, we now have wvc.Configure.Vectorizer.text2vec_azure_openai\nFor defining it, you can do as follow:\nclient.collections.create(\n    name=\"Collection Name\",\n    vectorizer_config=wvc.Configure.Vectorizer.text2vec_azure_openai(\n        resource_name=\"\",\n        deployment_id=\"\",\n        vectorize_class_name=False,\n        base_url=\"\",\n    )\n)\n\nAs our Python V4 client is still in beta, we are yet to produce all the docs.\nLet me know if this helps\n\n----------\n\n[c-lara (2023-12-12T08:07:21.122Z)]: DudaNogueira:\n\ntext2vec_azure_openai\n\n\nAmazing, thank you @DudaNogueira!  That is really helpful and I hope the V4 will make it\n\n----------\n\n[nik (2024-05-17T16:48:43.224Z)]: hi there. i’m not sure i have the entirely same problem, but i’ve encountered the same error upon trying to query data i’d ingested into my weaviate instance. i had in fact used the correct wvc.Configure.Vectorizer.text2vec_azure_openai vectorizer, but i think i’m not sure where to retrieve resource_name, deployment_id, or base_url in the azure openai studio dashboard.\n@DudaNogueira do you know where I might find this?\n\n----------\n\n[DudaNogueira (2024-05-17T20:02:06.359Z)]: Hi! After you deploy a mode in Azure OpenAI you get those informations.\nI don’t have one handy here, but I’ll probably do next week.\n\n----------\n\n[nik (2024-05-19T11:59:28.180Z)]: right, but they have different names – the terms cited in the weaviate documentation don’t exist verbatim in azure openai. i’ve tried a few different combination,s but i’ve not been able to get it to work.\n\n----------\n\n[c-lara (2024-05-19T12:59:04.926Z)]: Hi @Nik,\nI’m not totally sure what your question is referring to but maybe my code below helps you somewhat?\nazure_openai_key = YOUR_KEY \n\n\nweaviate_client = weaviate.WeaviateClient(\n    connection_params=ConnectionParams.from_params(\n        http_host=\"weaviate\",\n        http_port=\"8080\",\n        http_secure=False,\n        grpc_host=\"weaviate\",\n        grpc_port=\"50051\",\n        grpc_secure=False,\n    ),\n    auth_client_secret=weaviate.auth.AuthApiKey(weaviate_secret_key),\n    additional_headers={\n        \"X-Azure-Api-Key\": azure_openai_key,\n    },\n)\n\nvectorizer_config = wvcc.Configure.Vectorizer.text2vec_azure_openai(\n    resource_name=\"NAME-GIVEN-BY-YOUR-COMPANY\",\n    deployment_id=\"text-embedding-ada-002\",\n    base_url=\"https://NAME-GIVEN-BY-YOUR-COMPANY.openai.azure.com/\",\n)\n\ngenerative_config = wvcc.Configure.Generative.azure_openai(\n    resource_name=\"NAME-GIVEN-BY-YOUR-COMPANY\",\n    deployment_id=\"text-embedding-ada-002\",\n    base_url=\"https://NAME-GIVEN-BY-YOUR-COMPANY.openai.azure.com/\",\n    top_p=0.95, \n    max_tokens=800\n)\n\n\nCheers!\n\n----------\n\n[nik (2024-05-20T15:39:13.662Z)]: @c-lara this looks amazingly helpful. thanks so much for sharing.\n\n----------\n\n[c-lara (2024-05-20T16:23:31.657Z)]: You’re more than welcome\n\n----------\n\n[Vindeep_V (2024-08-09T11:03:21.265Z)]: questions = client.collections.create(\n    name=\"Questions\",\n    vectorizer_config=wvcc.Configure.Vectorizer.text2vec_azure_openai(\n        base_url= 'https://xxx.domain.com/',\n        deployment_id=\"text-embedding-3-large\",\n        resource_name=\"xxx\"\n), \n    generative_config=wvcc.Configure.Generative.azure_openai(\n        base_url= 'https://xxx.domain.com/',\n        deployment_id=\"text-embedding-3-large\",\n        resource_name=\"xxx\"\n    )  # Ensure the `generative-openai` module is used for generative queries\n)\n\nI have set all that is needed using wvc.Configure.Vectorizer.text2vec_azure_openai I still get below error while inserting,\nWeaviateInsertManyAllFailedError: Every object failed during insertion. Here is the set of all errors: connection to: Azure OpenAI API failed with status: 401\n\n----------\n\n[DudaNogueira (2024-08-09T18:30:00.126Z)]: hi! Welcome to our community \nThis message indicates that the apikey may be wrong.\n401 - is unauthorized code.\nCan you make sure the apikey is correct?\n\n----------\n\n[jakasspeech2 (2024-08-12T06:28:23.033Z)]: For integrating it with Azure, it might still be a bit unclear how to pass the necessary configurations.\n\n----------\n\n[dror-pipano_SAGCP (2024-08-20T09:08:46.861Z)]: How to set another key for azure gpt as embedding and generative, has different keys  : client = weaviate.connect_to_local(\nhost=‘146.122.25.252’,\nport=8500,\nheaders={\n‘X-Azure-Api-Key’: azure_api_key,\n‘X-Azure-Api-Key’: azure_api_key_gpt, # how to do this?\n})\n\n----------\n\n[DudaNogueira (2024-08-20T12:46:43.047Z)]: hi @dror-pipano_SAGCP !! Welcome to our community \nI don’t think there is this distinction on different azure keys for embedding and generative \nThat’s an interesting edge case.\n\n----------\n\n[dror-pipano_SAGCP (2024-08-20T13:47:41.039Z)]: Thanks.\nAs far as I use it in different project, it’s like that, maybe it’s relates to the way I was provided with Azure resources within my company.\n\n----------\n\n[DudaNogueira (2024-08-20T14:52:32.602Z)]: definitely. It is best to have one api key that will have access to all required resources.",
    "date_created": "2023-12-08T15:51:54.467Z",
    "has_accepted_answer": true,
    "title": "How to use Python V4 Api with Azure?",
    "topic_id": 1078
  },
  {
    "user_id": 11470,
    "conversation": "[user1454 (2025-03-17T09:02:57.586Z)]: If del a collection and then create it again with a new Embedding model and the same collection name, When use this new model to query, get an error：distance between entrypoint and query node: 768 vs 1536: vector lengths don’t match.\n\n----------\n\n[Mohamed_Shahin (2025-03-17T09:49:50.581Z)]: Hello @user1454,\nWelcome to our community! It’s great to have you here.\nThe error you’re seeing about different vector lengths indicates that there was an issue during indexing (or Corruption), where vectors of varying dimensions were inserted into the vector space. However, this has been improved in recent Weaviate versions, as incorrect vector lengths should no longer be accepted based on collection configuration.\nCould you please share which Weaviate version you’re using, as well as details on how you created the collection and the method you’re using to ingest data?\n\n----------\n\n[user1454 (2025-03-17T10:52:07.972Z)]: thank you for your reply.the version is weaviate-client  4.9.3, i used  python client v4,\nself.weaviate_client.collections.delete(\"profile_db_202\")\nafter del, I recreated it with a new Embedding model.\nthis code seems to be temporarily effective,then it will report vector lengths don’t match.\n\n----------\n\n[Mohamed_Shahin (2025-03-17T11:21:32.980Z)]: I meant the Weaviate server—are you running the latest DB version, like 1.28 or 1.29?\n\n----------\n\n[user1454 (2025-03-17T11:36:23.650Z)]: The image used at that time was the latest version, 6 months ago, I don’t know which version it is now.\n\n----------\n\n[Mohamed_Shahin (2025-03-17T12:34:36.926Z)]: Would you please upgrade the server to 1.29.0 and retry?",
    "date_created": "2025-03-17T09:02:57.534Z",
    "has_accepted_answer": false,
    "title": "Collection name setting problem",
    "topic_id": 19904
  },
  {
    "user_id": 1555,
    "conversation": "[Rishi_Prakash (2024-10-17T12:29:08.184Z)]: While creating collection, what happens if dont mention the vector_index_config, is the default distance_metric “Cosine”\nIs it neccesary for me to mention vector_index_config, if am using text2vec_azure_openai and let weaviate create embedding on its own using the cred i give it, wont it by default use Cosine distance metric when I query from collection\nGot below from doc\nclient.collections.create(\n    \"Article\",\n    # Additional configuration not shown\n    vector_index_config=Configure.VectorIndex.hnsw(\n        quantizer=Configure.VectorIndex.Quantizer.bq(),\n        ef_construction=300,\n        distance_metric=VectorDistances.COSINE,\n        filter_strategy=VectorFilterStrategy.SWEEPING  # or ACORN (Available from Weaviate v1.27.0)\n    ),\n)\n\nMy next question is: are the created embeddings from Weaviate normalized.\nThanks.\n\n----------\n\n[DudaNogueira (2024-10-17T13:47:25.930Z)]: hi @Rishi_Prakash !!\nIf you do not provide any values to vector_index_config, it will set the default ones.\nfor example, when you create a collection like this:\ncollection = client.collections.create(\"DefaultCollection\")\nprint(collection.config.get(). vector_index_config.to_dict())\n\n\n{‘cleanupIntervalSeconds’: 300, ‘distanceMetric’: ‘cosine’, ‘dynamicEfMin’: 100, ‘dynamicEfMax’: 500, ‘dynamicEfFactor’: 8, ‘ef’: -1, ‘efConstruction’: 128, ‘filterStrategy’: ‘sweeping’, ‘flatSearchCutoff’: 40000, ‘maxConnections’: 32, ‘skip’: False, ‘vectorCacheMaxObjects’: 1000000000000}\n\nThe created embeddings are stored as it is.\nThose configurations change how the distances will be calculated and searched and how the index will be built.\nNow, if you compress those vectors, for example, Weaviate will now keep both the original and the compressed vectors on disk, but only the compressed vectors on memory.\nLet me know if this helps!\nThanks!",
    "date_created": "2024-10-17T12:29:08.121Z",
    "has_accepted_answer": false,
    "title": "Default distance while creating collection",
    "topic_id": 5707
  },
  {
    "user_id": 3135,
    "conversation": "[darklord.thevader (2025-01-01T07:25:54.538Z)]: As i am trying to use weaviate as vector DB, and I am using weaviate’s community self hosted version, I was reading weaviate has some in-built pre-trained text2vec embeddings available which can work for no cost? or do we have any other vectors available from weaviate which we can use to ensure we can avoid external embedding models\n\n----------\n\n[DudaNogueira (2025-01-02T17:36:03.654Z)]: hi @darklord.thevader !!\nYes, you can run your own transformer/embedding models, as described here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nText Embeddings | Weaviate\n\n  Weaviate's integration with the Hugging Face Transformers library allows you to access their models' capabilities directly from Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWe also provide a docker image that you can run side by side with Weaviate and vectorize your data locally.\nLet me know if that helps!\nThanks!",
    "date_created": "2025-01-01T07:25:54.474Z",
    "has_accepted_answer": false,
    "title": "Does Weaviate has its own embedding model which can be used for text and image embedding",
    "topic_id": 9538
  },
  {
    "user_id": 1485,
    "conversation": "[Owie_de_la_Pena (2024-09-03T09:28:43.119Z)]: Description\n\nHello,\nI’m using python v4 client to do batch import.\nMy code looks like this (basically just a copy of what’s in the documentation edited to work with multi-tenancy):\ncollection = self._client.collections.get(collection_name)\nwith collection.with_tenant(tenant=tenant).batch.dynamic() as batch:\n   for datum in data:\n      vector_uuid = self.generate_deterministic_id(datum)\n      embedding = self.get_embedding(datum)\n      batch.add_object(properties=self.get_properties(datum), uuid=vector_uuid, vector=embedding)\n\n   failed_objects = collection.batch.failed_objects # empty\n   failed_objects1 = collection.with_tenant(tenant=tenant).batch.failed_objects # results to empty\n   failed_objects2 = self._client.batch.failed_objects # also empty\n\n\nNote: this is not the actual complete codes, I simplified it for the sake of brevity. I can confirm though that the code runs fine and is able to run import when correct data is used\nThe batch, in some cases when I’m using improper data, fails with this error:\n{'message': 'Failed to send 1 objects in a batch of 1. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n\nBut when I try to inspect the failed_objects, it’s always empty. I tried different ways to see where the failed_objects are, but all everything result to empty arrays. (see in codes: failed_objects, failed_objects1 and failed_objects2)\nServer Setup Information\n\nWeaviate Server Version: 1.25.11\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python v4\nMultitenancy?: Yes\n\nAny additional Information\nLogs:\n46549357-e140-4347-b5cd-635bbdf758bb\t{'message': 'Failed to send 1 objects in a batch of 1. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n\n[ERROR] 2024-09-03T09:00:15.354Z 46549357-e140-4347-b5cd-635bbdf758bb {'message': 'Failed to send 1 objects in a batch of 1. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n2024-09-03T11:00:15.374+02:00\n[INFO] 2024-09-03T09:00:15.374Z 46549357-e140-4347-b5cd-635bbdf758bb collection.with_tenant(tenant=tenant).batch.failed_objects: [] len=0\n2024-09-03T11:00:15.374+02:00\n[INFO] 2024-09-03T09:00:15.374Z 46549357-e140-4347-b5cd-635bbdf758bb collection.batch.failed_objects: [] len=0\n2024-09-03T11:00:15.374+02:00\n[INFO]\t2024-09-03T09:00:15.374Z\t46549357-e140-4347-b5cd-635bbdf758bb\tself._client.batch.failed_objects: [] len=0\n\n[INFO] 2024-09-03T09:00:15.374Z 46549357-e140-4347-b5cd-635bbdf758bb self._client.batch.failed_objects: [] len=0\n\n\nWhere should I actually get the failed_objects?\n\n----------\n\n[DudaNogueira (2024-09-03T12:09:40.595Z)]: Hi @Owie_de_la_Pena !! Welcome to our community.\nThe issue here is that you should get those failed objects outside of the batch context, like so:\ncollection = self._client.collections.get(collection_name)\nwith collection.with_tenant(tenant=tenant).batch.dynamic() as batch:\n   for datum in data:\n      vector_uuid = self.generate_deterministic_id(datum)\n      embedding = self.get_embedding(datum)\n      batch.add_object(properties=self.get_properties(datum), uuid=vector_uuid, vector=embedding)\n\nfailed_objects = collection.batch.failed_objects # empty\nprint(failed_objects)\n\n\nCheck here the documentation on error handling:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Owie_de_la_Pena (2024-09-03T13:35:55.381Z)]: Hi @DudaNogueira ,\nThank you for looking into my query.\nI tried your suggestion and made sure that the collection.batch.failed_objects line is outside the context manager block. However, I’m getting the same result.\n\n----------\n\n[Owie_de_la_Pena (2024-09-03T14:07:20.017Z)]: Additional info: I am able to pull the logs from the Weaviate node itself, if that’s of any help.\n{\"build_git_commit\":\"2c51c29\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.25.13\",\"build_wv_version\":\"1.25.13\",\"class\":\"MyObject\",\"level\":\"error\",\"msg\":\"[conflict \\\"Validate vector index for 48efafd2-77cc-55e1-9f3c-c4d6457993d2: new node has a vector with length 1536. Existing nodes have vectors with length 1\\\": \\u003cnil\\u003e]\",\"op\":\"put.many\",\"shard\":\"TSTDRV_OWIE3\",\"time\":\"2024-09-03T14:03:51Z\"}\n\nThis is intentional - I’m forcing my batch to fail.\n\n----------\n\n[DudaNogueira (2024-09-03T14:30:39.805Z)]: Owie_de_la_Pena:\n\nnew node has a vector with length 1536. Existing nodes have vectors with length 1\n\n\nThis is the error message.\nYou probably inserted one object with 1 dimension, and now is trying to ingest objects with 1536 dimensions.\nhere is how to reproduce this exact error:\nimport weaviate\nfrom weaviate import classes as wvc\nclient = weaviate.connect_to_local()\n    \nclient.collections.delete(\"Test\")\n\ncollection = client.collections.create(\n    \"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n)\ncollection.data.insert({\"text\": \"1 dimensions\"}, vector=[1])\ncollection.data.insert({\"text\": \"1536 dimensions\"}, vector=list(range(1536)))\n\nError:\nFile ~/dev/weaviate/lab/.venv/lib/python3.12/site-packages/weaviate/connect/v4.py:458, in ConnectionV4.__send(self, method, url, error_msg, status_codes, is_gql_query, weaviate_object, params)\n    456     res = await self._client.send(req)\n    457     if status_codes is not None and res.status_code not in status_codes.ok:\n--> 458         raise UnexpectedStatusCodeError(error_msg, response=res)\n    459     return cast(Response, res)\n    460 except RuntimeError as e:\n\nUnexpectedStatusCodeError: Object was not added! Unexpected status code: 500, with response body: {'error': [{'message': 'put object: import into index test: put local object: shard=\"D483s6MIIvw9\": store object in LSM store: Validate vector index for 3e14872a-fc3d-4e08-9bb7-61debec9a85c: new node has a vector with length 1536. Existing nodes have vectors with length 1'}]}.\n\nLet me know if this helps.\nThanks!\n\n----------\n\n[Owie_de_la_Pena (2024-09-03T16:49:50.923Z)]: Hi again @DudaNogueira,\nYes, that’s also how I’m doing it. Again, I was intentionally making the batch fail. After the batch fails, I want to know which records failed and mark them as failed in my own database.\nGoing back to the original question:\ncollection = self._client.collections.get(collection_name)\nwith collection.with_tenant(tenant=tenant).batch.dynamic() as batch:\n   for datum in data:\n      vector_uuid = self.generate_deterministic_id(datum)\n      embedding = self.get_embedding(datum)\n      batch.add_object(properties=self.get_properties(datum), uuid=vector_uuid, vector=embedding)\n\nfailed_objects = collection.batch.failed_objects\n\nI have this now in my codes. After the batch fails because of the incorrect vector size\nfailed_objects = collection.batch.failed_objects # still empty\n\nIt is still giving me empty array.\n\n----------\n\n[Owie_de_la_Pena (2024-09-03T19:37:51.472Z)]: Update: I got it working by modifying the batch codes to:\nwith client.batch.dynamic() as batch:\n   ...\n      ...\n      batch.add_object(properties=self.get_properties(datum), uuid=vector_uuid, vector=embedding, collection=collection_name, tenant=tenant)\n\ninstead of\nwith collection.with_tenant(tenant=tenant).batch.dynamic() as batch:\n\n----------\n\n[DudaNogueira (2024-09-05T12:53:04.335Z)]: Nice!\nGlad you figured it out and thanks for sharing.\nIndeed you can create a batch context using the client directly and then specifying the collection and tenant.\nThis is a great feature as you can add data to multiple collections in multi tenants in one batch context, only by changing those parameters.\nThanks!\n\n----------\n\n[00.lope.naughts (2024-11-19T06:44:10.181Z)]: I also have question about proper error handling in general. specifically, I am considering:\ncollection.data.delete_many(\nwhere=Filter.by_property(“my_id”).contains_any(my_ids)\n)\nI looked through the doc in the link but I aint sure if collection.batch.failed_objects is still appropriate. for lack of better idea, I am doing this for now:\ntry:\ncollection.data.delete_many(…)\nexcept weaviate.exceptions.UnexpectedStatusCodeError as e:\nprint(e)\n\n----------\n\n[Dirk (2024-11-19T07:49:36.840Z)]: Delete many has the following return:\n@dataclass\nclass DeleteManyReturn(Generic[T]):\n    \"\"\"This class contains the results of a `delete_many` operation..\"\"\"\n\n    failed: int\n    matches: int\n    objects: T\n    successful: int\n\nwhere you get the status for each object (objects: T) if you set verbose to true. Otherwise it is only the counts.\n\n----------\n\n[00.lope.naughts (2024-11-19T16:50:16.642Z)]: Thanks. I will use this to try handle it. I have a container thats admittedly running sometimes close to what the physical memory will allow. And recently, I got this quite often:\nERROR: Error: Query call with protocol GRPC delete failed with message <AiGrpcError that terminated with:\nstatus = StatusCode.DEADLINE_EXCEEDED\ndetails = “Deadline Exceeded”\ndebug_error_string = “UNKNOWN:Error received from peer {created_time:“2024-11-15T17:05:18.271641472+00:00”, grpc_status:4, grpc_message:“Deadline Exceeded”}”\n\nis this kind of error (looks pretty fatal) still have a “nice” DeleteManyReturn obj? or it may still be prudent/necessary to do try/except to detect and handle this?\n\n----------\n\n[Dirk (2024-11-19T18:38:51.893Z)]: That means that the request was aborted because it took too long. You could increase the timeout value like shown here: Python | Weaviate\n(can’t remember which one is used by delete)",
    "date_created": "2024-09-03T09:28:43.059Z",
    "has_accepted_answer": true,
    "title": "Batch insert logs 'Failed to send 1 objects in a batch of 1' but collection.batch.failed_objects is empty",
    "topic_id": 3964
  },
  {
    "user_id": 2790,
    "conversation": "[Tibin_Lukose (2025-03-07T07:33:29.244Z)]: Description\nProduction weaviate crashed out of random, not sure what caused though, running docker-compose setup\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: Docker\nMulti Node? Number of Running Nodes: 2 nodes\nClient Language and Version: http-graphql\nMultitenancy: Yes\n\nersion: '3.9'\nservices:\n  weaviate-node-1:\n    networks:\n        - dev\n        - shared\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.6\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_01_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'backup-s3,text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node1'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'\n      BACKUP_S3_BUCKET: 'xx'\n      AWS_ACCESS_KEY_ID: 'xx'\n      AWS_SECRET_ACCESS_KEY: 'xx'\n      AWS_REGION: 'us-east-1'\n      BACKUP_S3_PATH: 'weaviate-backup/'\n  weaviate-node-2:\n    networks:\n        - dev\n        - shared\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.24.6\n    ports:\n    - 8081:8081\n    - 50052:50052\n    volumes:\n    - weaviate_02_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'backup-s3,text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node2'\n      CLUSTER_GOSSIP_BIND_PORT: '7102'\n      CLUSTER_DATA_BIND_PORT: '7103'\n      CLUSTER_JOIN: 'weaviate-node-1:7100'\n      BACKUP_S3_BUCKET: 'xx'\n      AWS_ACCESS_KEY_ID: 'xx'\n      AWS_SECRET_ACCESS_KEY: 'xx'\n      AWS_REGION: 'us-east-1'\n      BACKUP_S3_PATH: 'weaviate-backup/'\n\nnetworks:\n  dev:\n    driver: \"bridge\"\n  shared:\n    external: true\nvolumes:\n  weaviate_01_data:\n  weaviate_02_data:\n\nAny additional Information\n{\"action\":\"hnsw_commit_logger_combine_condensed_logs\",\"id\":\"main\",\"input_first\":\"/var/lib/weaviate/default/teamQWjneg5YbwZ1/main.hnsw.commitlog.d/1739359455.condensed\",\"input_second\":\"/var/lib/weaviate/default/teamQWjneg5YbwZ1/main.hnsw.commitlog.d/1741147203.condensed\",\"level\":\"info\",\"msg\":\"successfully combined previously condensed commit log files\",\"output\":\"/var/lib/weaviate/default/teamQWjneg5YbwZ1/main.hnsw.commitlog.d/1739359455\",\"time\":\"2025-03-06T04:02:01Z\"}\n\n{\"action\":\"hnsw_commit_logger_combine_condensed_logs\",\"id\":\"main\",\"input_first\":\"/var/lib/weaviate/default/teamLkzPdyP7bQro/main.hnsw.commitlog.d/1731038403.condensed\",\"input_second\":\"/var/lib/weaviate/default/teamLkzPdyP7bQro/main.hnsw.commitlog.d/1741147204.condensed\",\"level\":\"info\",\"msg\":\"successfully combined previously condensed commit log files\",\"output\":\"/var/lib/weaviate/default/teamLkzPdyP7bQro/main.hnsw.commitlog.d/1731038403\",\"time\":\"2025-03-06T04:02:01Z\"}\n\n{\"action\":\"hnsw_commit_logger_combine_condensed_logs\",\"id\":\"main\",\"input_first\":\"/var/lib/weaviate/default/team37N1aMAaWmpn/main.hnsw.commitlog.d/1721027622.condensed\",\"input_second\":\"/var/lib/weaviate/default/team37N1aMAaWmpn/main.hnsw.commitlog.d/1741147203.condensed\",\"level\":\"info\",\"msg\":\"successfully combined previously condensed commit log files\",\"output\":\"/var/lib/weaviate/default/team37N1aMAaWmpn/main.hnsw.commitlog.d/1721027622\",\"time\":\"2025-03-06T04:02:01Z\"}\n\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry update\",\"payload\":\"\\u0026{MachineID:30e421f1-2b92-468d-b726-dd2c34a18fd2 Type:UPDATE Version:1.24.6 Modules:backup-s3,generative-cohere,generative-openai,generative-palm,qna-openai,ref2vec-centroid,reranker-cohere,text2vec-cohere,text2vec-huggingface,text2vec-openai,text2vec-palm NumObjects:643377 OS:linux Arch:amd64}\",\"time\":\"2025-03-06T08:18:09Z\"}\n\n{\"level\":\"info\",\"msg\":\"Created shard default_teamxk8mepg2dMyJ in 2.62715ms\",\"time\":\"2025-03-07T04:00:05Z\"}\n\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-03-07T04:00:05Z\",\"took\":83026}\n\n{\"class\":\"Default\",\"level\":\"info\",\"msg\":\"start uploading files\",\"time\":\"2025-03-07T04:00:05Z\"}\n\n{\"backup_id\":\"app-default-250307-040004\",\"class\":\"Default\",\"level\":\"info\",\"msg\":\"release backup\",\"time\":\"2025-03-07T04:02:09Z\"}\n\n{\"class\":\"Default\",\"level\":\"info\",\"msg\":\"finish uploading files\",\"time\":\"2025-03-07T04:02:09Z\"}\n\n{\"level\":\"info\",\"msg\":\"start uploading meta data\",\"time\":\"2025-03-07T04:02:09Z\"}\n\n{\"level\":\"info\",\"msg\":\"finish uploading meta data\",\"time\":\"2025-03-07T04:02:10Z\"}\n\n{\"action\":\"create_backup\",\"backup_id\":\"app-default-250307-040004\",\"level\":\"info\",\"msg\":\"backup completed successfully\",\"time\":\"2025-03-07T04:02:10Z\"}\n\n{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2025-03-07T07:18:20Z\"}\n\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2025-03-07T07:18:20Z\"}\n\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2025-03-07T07:18:20Z\"}\n\n{\"action\":\"broadcast_abort_transaction\",\"error\":\"host \\\"172.19.0.3:7101\\\": send http request: Delete \\\"http://172.19.0.3:7101/schema/transactions/5ba28efc-2f25-43b6-88f0-e2c11a4f6a38\\\": dial tcp 172.19.0.3:7101: connect: connection refused\",\"id\":\"5ba28efc-2f25-43b6-88f0-e2c11a4f6a38\",\"level\":\"error\",\"msg\":\"broadcast tx abort failed\",\"time\":\"2025-03-07T07:18:20Z\"}\n\n{\"action\":\"startup\",\"error\":\"could not load or initialize schema: sync schema with other nodes in the cluster: read schema: open transaction: broadcast open transaction: host \\\"172.19.0.3:7101\\\": send http request: Post \\\"http://172.19.0.3:7101/schema/transactions/\\\": dial tcp 172.19.0.3:7101: connect: connection refused\",\"level\":\"fatal\",\"msg\":\"could not initialize schema manager\",\"time\":\"2025-03-07T07:18:20Z\"}\n\n{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2025-03-07T07:18:21Z\"}\n\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2025-03-07T07:18:21Z\"}\n\n{\"action\":\"memberlist_init\",\"error\":\"1 error occurred:\\n\\t* Failed to join 172.19.0.3:7100: dial tcp 172.19.0.3:7100: connect: connection refused\\n\\n\",\"level\":\"error\",\"msg\":\"memberlist join not successful\",\"remote_hostname\":[\"weaviate-node-1:7100\"],\"time\":\"2025-03-07T07:18:21Z\"}\n\n{\"action\":\"startup\",\"error\":\"join cluster: 1 error occurred:\\n\\t* Failed to join 172.19.0.3:7100: dial tcp 172.19.0.3:7100: connect: connection refused\\n\\n\",\"level\":\"error\",\"msg\":\"could not init cluster state\",\"time\":\"2025-03-07T07:18:21Z\"}\n\n{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2025-03-07T07:18:22Z\"}\n\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2025-03-07T07:18:22Z\"}\n\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2025-03-07T07:18:22Z\"}\n\n{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2025-03-07T07:18:22Z\"}\n\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2025-03-07T07:18:22Z\"}\n\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2025-03-07T07:18:22Z\"}\n\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:2c582ae5-789d-447c-9b25-1cc60e5b2bc7 Type:INIT Version:1.24.6 Modules:backup-s3,generative-cohere,generative-openai,generative-palm,qna-openai,ref2vec-centroid,reranker-cohere,text2vec-cohere,text2vec-huggingface,text2vec-openai,text2vec-palm NumObjects:0 OS:linux Arch:amd64}\",\"time\":\"2025-03-07T07:18:22Z\"}\n\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Default\",\"index\":\"default\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/objects/segment-1727236802809722618\",\"shard\":\"team0wMvbmZOdYAl\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Default\",\"index\":\"default\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/property__id/segment-1727236802810307015\",\"shard\":\"team0wMvbmZOdYAl\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Default\",\"index\":\"default\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/property_docId/segment-1727236802810364796\",\"shard\":\"team0wMvbmZOdYAl\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Default\",\"index\":\"default\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/property_text/segment-1727236802810419938\",\"shard\":\"team0wMvbmZOdYAl\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Default\",\"index\":\"default\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/property_correctionId/segment-1727236802810704006\",\"shard\":\"team0wMvbmZOdYAl\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Default\",\"index\":\"default\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/lsm/property_text_searchable/segment-1727236802810544466\",\"shard\":\"team0wMvbmZOdYAl\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"level\":\"info\",\"msg\":\"Completed loading shard default_team0wMvbmZOdYAl in 10.048082ms\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-03-07T07:18:23Z\",\"took\":83694}\n\n{\"action\":\"hnsw_commit_logger_combine_condensed_logs\",\"id\":\"main\",\"input_first\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/main.hnsw.commitlog.d/1727236802.condensed\",\"input_second\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/main.hnsw.commitlog.d/1741233604.condensed\",\"level\":\"info\",\"msg\":\"successfully combined previously condensed commit log files\",\"output\":\"/var/lib/weaviate/default/team0wMvbmZOdYAl/main.hnsw.commitlog.d/1727236802\",\"time\":\"2025-03-07T07:18:23Z\"}\n\n----------\n\n[Mohamed_Shahin (2025-03-08T20:12:04.687Z)]: Production weaviate 24.6 crashed Support\n  \n  \n    Hi @Tibin_Lukose, \nThis error is related to an old panic from back in the day, but the bug has already been resolved besides many other improvements: \n“error”: “could not load or initialize schema: sync schema with other nodes in the cluster: read schema: open transaction: broadcast open transaction.” \nPlease be aware that you’re running a very outdated version of Weaviate, even before the RAFT mechanism was implemented for multi-node clusters. \nYou must upgrade to v1.25.32 post-RAFT, despite th…",
    "date_created": "2025-03-07T07:33:29.174Z",
    "has_accepted_answer": false,
    "title": "Crashing weaviate 24.6",
    "topic_id": 11681
  },
  {
    "user_id": 908,
    "conversation": "[00.lope.naughts (2024-11-27T04:24:52.717Z)]: Description\nI am trying to use weaviate v4 python client to batch import data into my weaviate. This is the code setup:\nclient = weaviate.connect_to_local(WEAVIATE_HOST, WEAVIATE_PORT)\n\ndata_jsons = ... # a list of dict of key/values that match up with the collection schema\ncollection = client.collections.get('my_collection')\ntry:\n  with collection.batch.dynamic() as batch:\n    for a_json in tqdm(data_jsons[:10000]):     \n      key = create_key(a_json)    # could be a hash of the data\n      vector = a_json.pop('vector')   # bring my own vector use case\n      batch.add_object(properties=a_json, \n                      uuid=key, \n                      vector=vector)\n\n  failed_objects = collection.batch.failed_objects\n  if len(failed_objects) > 0:\n    raise Exception(f\"Failed to insert {len(failed_objects)} objects\")\nexcept Exception as e:\n  print(f\"Error: {e}\")\n\nwhen there’s intermittent failure, it will complete and failed_objects will indeed be >0, such that I can raise the error to the caller.\nHowever, if the weaviate instance is permanently down (I just pause it to simulate this), then the above code will take a long time to complete and slowly printing out something like:\nUserWarning: Bat003: The dynamic batch-size could not be refreshed successfully: error WeaviateTimeoutError('The request to Weaviate timed out while awaiting a response. Try adjusting the timeout config for your client. Details: ')\n  warnings.warn(\n{'message': 'Failed to send 260 objects in a batch of 260. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n{'message': 'Failed to send 260 objects in a batch of 260. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n{'message': 'Failed to send 260 objects in a batch of 260. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n{'message': 'Failed to send 260 objects in a batch of 260. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n{'message': 'Failed to send 260 objects in a batch of 260. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n{'message': 'Failed to send 260 objects in a batch of 260. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n{'message': 'Failed to send 260 objects in a batch of 260. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n{'message': 'Failed to send 110 objects in a batch of 110. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\nError: Failed to insert 1930 objects\n\nI think these are from the logger in weaviate and it seems add_object never throw any exceptions all along (so the try/except is actually useless above). What I want to achieve is if there are 3 messages like this getting triggered, I want it to just quit and throw exception. Right now, it seems to be waiting for a timeout, then do something, trigger that message, then timeout again, which result in this code running for a very long time before it hits my raise Exception.\nIs there a proper way to handle connection error (e.g. if weaviate instance just died)? my goal is I dont want a very large batch import job to get stuck forever.\nServer Setup Information\n\nWeaviate Server Version: 1.27.0\nDeployment Method: docker on Mac OS\nMulti Node? Number of Running Nodes: 1 (no multi tenancy, no replication, no cluster)\nClient Language and Version: En\nMultitenancy?: No\n\nAny additional Information\nI didnt specify any specific timeout in the client. its just plain simple connect_to_local(WEAVIATE_HOST, WEAVIATE_PORT)\n\n----------\n\n[00.lope.naughts (2024-11-27T18:57:43.992Z)]: As a part of the solution, in the broad context of batch import job monitoring, I launched this with inside a celery task and then build something else to track the status of the task(_id). And then send off an alarm if it takes longer than expected.\nStill it would be better to have the the batch import stops on its own and not hog the cpu until our devops/support come check it out.\n\n----------\n\n[DudaNogueira (2024-11-28T11:40:30.848Z)]: hi @00.lope.naughts !!\nI believe that the batch import will timeout according to the timeout configuration, as documented here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Utilize the Python client library to access Weaviate and streamline data processes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nmaybe, for that batch process, you can initiate the client with a configured timeout?\n\n----------\n\n[00.lope.naughts (2024-11-28T15:04:59.093Z)]: Will check it out. Although, in my setup, I provided no timeout config, Just:\nclient = weaviate.connect_to_local(WEAVIATE_HOST, WEAVIATE_PORT).\n\n----------\n\n[00.lope.naughts (2024-11-28T18:10:31.846Z)]: I now set it to timeout in 1 sec explicitly like this:\nclient = weaviate.connect_to_local(host=WEAVIATE_HOST, \n                                   port=WEAVIATE_PORT,\n                                   additional_config=AdditionalConfig(\n                                    timeout=Timeout(init=1, query=1, insert=1)  # Values in seconds\n                                  )\n)\n\nI still see the same behavior when I hit Pause in the middle of the import. it immediately printed:\n…/python39_env/lib/python3.9/site-packages/weaviate/warnings.py:295](weaviate/warnings.py:295): UserWarning: Bat003: The dynamic batch-size could not be refreshed successfully: error WeaviateTimeoutError('The request to Weaviate timed out while awaiting a response. Try adjusting the timeout config for your client. Details: ') warnings.warn(\nbut then stuck for 2-3 min before printing:\n{‘message’: ‘Failed to send 62 objects in a batch of 62. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\n{‘message’: ‘Failed to send 62 objects in a batch of 62. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\nand then went on for a long while without apparent progress. I hit start the weaviate container and then it proceeded successfully.\nIt seems to me that while it is robust against temporary downtime, like a few min, and able to proceed, i can’t seem to control this error condition such that it returns control back to the rest of my code.\nwhile this isnt necessary severe in my case since I run this in a fork process like a celery task, and I can always ping its backend for status. I am still curious how to convince the batch import to just give up (e.g. after several rounds of whatever it was trying to do).\n\n----------\n\n[DudaNogueira (2024-11-29T10:36:20.468Z)]: Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.\n\nHave you inspected this as the error message suggest?\nhere you find some documentation on proper error handling:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Utilize the Python client library to access Weaviate and streamline data processes.\n\n----------\n\n[00.lope.naughts (2024-12-02T20:36:03.465Z)]: My issue is not being unable to handle message. For one, I know what the error is, it is a disconnect + timeout, 'cos I intentionally caused it in the test.\nThe more severe issue is that it will take a long long time for it to even deliver you those failed_objects.\nas I mentioned, I have no problem with this if the disconnect is only intermittent, and I did observed it before in a realistic run, and capable of inspecting those failed_objects, and do the appropriate retry.\nI am not sure if I have made the issue clear enough.\n\n----------\n\n[DudaNogueira (2024-12-02T21:37:28.937Z)]: Oh, I think I got it.\nYou mean you are are facing a timeout error, and cannot see those objects returning as failed?\n\n----------\n\n[00.lope.naughts (2024-12-04T15:25:37.348Z)]: Not entirely (partially true). But to be precise, it is the timeout mechanism thats problematic, but the “timeout error” is fully expected since I myself “unplug” my weaviate as a sanity test.\n\nclient = weaviate.connect_to_local(host=WEAVIATE_HOST,\nport=WEAVIATE_PORT,\nadditional_config=AdditionalConfig(\ntimeout=Timeout(init=1, query=1, insert=1)  # Values in seconds\n)\n)\n\nI have used a timeout of 1 sec. I noticed this indeed work for querying and objects counting, just not during batch import. So timeout erroring behaviour are correct for query/count (maybe others), but incorrect for batch import.\nwhat I observed is the batch import will effectively stall, and it seems to “work” through the entire data (which can be very large), and I have to sometimes wait >1 hr before it get to the code where I actually went to read the failed objects, and that part worked (I am able to get a specific failed count, attribute of the json, the full objects).\nSo what you said “cannot see those objects returning as failed” is NOT true, but you do have to wait for a long time. And “timeout error” seems to be failure of timeout mechanism itself, but in my experiment, the timeout error is to be expected, just not happening in 1sec as promised.\nI hope this characterize the condition I am facing. While this isnt a showstopper, and I dont even know what the right design should be, given that I don’t know all the constraint.",
    "date_created": "2024-11-27T04:24:52.655Z",
    "has_accepted_answer": false,
    "title": "How to handle error for Batch Import (add_object) when weaviate instance becomes unavailable",
    "topic_id": 8441
  },
  {
    "user_id": 2498,
    "conversation": "[skb (2024-11-12T06:13:27.157Z)]: Hi everyone. Is there a way to retrieve vectors within a specified cosine distance range from the query vector without having to retrieve all the vectors that are closer? For example, retrieving vectors which have a cosine distance in the range [0.5,0.6] from the query vector.\n\n----------\n\n[DudaNogueira (2024-11-20T19:00:21.181Z)]: hi @skb !!\nWelcome to our community \nSorry, missed your message \nIf I understood it correctly, this is what you are looking for:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nVector similarity search | Weaviate\n\n  Vector search returns the objects with most similar vectors to that of the query.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nSo you can set a threshold of distance.\nAlso, you will want to take a look at our auto cut / auto limit feature:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAdditional operators | Weaviate\n\n  Syntax\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[skb (2024-11-21T09:30:11.444Z)]: Thanks @DudaNogueira !\nSearching for vectors near a query vector, gets result vectors with distances ranging from 0 up to the threshold distance. I wanted to know if there was a way to limit the results to only the vectors with a distance between dist1 and dist2.\nI know I can do this using two searches with threshold distances of dist1 and dist2. But if the distances are large, then I end up having to consider a couple of large result sets and getting the difference. It would be great if there was a way to filter out results closer than dist1 while using a threshold distance of dist2 in a single query?\n\n----------\n\n[DudaNogueira (2024-11-21T17:39:53.669Z)]: Hi!\nSo you need a minimum threshold on top of the the one parameter we have?\nI am curious what is the use case here \nYou can always process this post search.  The only downside of this approach is that the objects that will be cut of your post process will be unnecessary sent in the result from the database to the client.\nThis could be a nice feature request, but it would be interesting to request it with some compelling use cases.\nLet me know if this helps!\n\n----------\n\n[skb (2024-11-25T16:22:42.507Z)]: Sorry for the late reply. This is the use case - Not likely to be a very common one: I’m looking to build a classifier model for a category that the query vector represents. I’m looking to select items for the training data spread over the entire range of distances from the query vector. For the higher distances, this represents a lot of items. So, it would be helpful to have a way to randomly choose a particular distance range and identify the items only falling in that range.\nI have found an alternate way to do this. I use the aggregate queries to identify the no. of items for threshold distances of dist1 and dist2. Then randomly choose a no. in between and use that as the offset to identify an item inside the distance range.\n\n----------\n\n[DudaNogueira (2024-11-25T18:57:38.186Z)]: Oh, that’s a smart solution!!\nThanks for sharing.",
    "date_created": "2024-11-12T06:13:27.113Z",
    "has_accepted_answer": true,
    "title": "Vectors within a specified distance range from query",
    "topic_id": 7547
  },
  {
    "user_id": 2493,
    "conversation": "[jensenbox (2024-11-11T07:35:44.094Z)]: How do I have the query return how far away the object is from the supplied GeoCoordinate?\nI cannot seem to get that data from the response.\n\n----------\n\n[DudaNogueira (2024-11-12T18:00:35.526Z)]: hi @jensenbox !!\nThat’s interesting. I don’t believe it does \nI will poke internally about it and keep you posted.\nI have crafted a small test code for future reference:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n    properties=[\n        wvc.config.Property(name=\"city_name\", data_type=wvc.config.DataType.TEXT),\n        wvc.config.Property(name=\"geo\", data_type=wvc.config.DataType.GEO_COORDINATES)\n    ]\n)\ncollection.data.insert_many(\n    objects=[\n        {\"city_name\": \"Belo Horizonte\", \"geo\": {\"latitude\": -19.9191, \"longitude\": -43.9387}},\n        {\"city_name\": \"Amsterdam\", \"geo\": {\"latitude\": 52.377956, \"longitude\": 4.897070}},\n        {\"city_name\": \"São Paulo\", \"geo\": {\"latitude\": -23.5558, \"longitude\": -46.6396}},\n        {\"city_name\": \"Tokyo\", \"geo\": {\"latitude\": 35.6764, \"longitude\": 139.6500}},\n        {\"city_name\": \"New York\", \"geo\": {\"latitude\": 40.7128, \"longitude\": -74.0060}},\n        {\"city_name\": \"Paris\", \"geo\": {\"latitude\": 48.8566, \"longitude\": 2.3522}},\n        {\"city_name\": \"Sydney\", \"geo\": {\"latitude\": -33.8688, \"longitude\": 151.2093}},\n        {\"city_name\": \"Cape Town\", \"geo\": {\"latitude\": -33.9249, \"longitude\": 18.4241}},\n        {\"city_name\": \"Mumbai\", \"geo\": {\"latitude\": 19.0760, \"longitude\": 72.8777}},\n        {\"city_name\": \"Moscow\", \"geo\": {\"latitude\": 55.7558, \"longitude\": 37.6176}}\n    ]\n)\nquery = collection.query.fetch_objects(\n    return_metadata=wvc.query.MetadataQuery(distance=True),\n    filters=(\n        wvc.query.Filter.by_property(\"geo\").within_geo_range(\n            wvc.data.GeoCoordinate(\n                latitude=-17.8575,\n                longitude=-41.5057,\n            ),\n            distance=1000000\n        )\n    )\n)\nfor i in query.objects:\n    print(\"#\"*10)\n    print(i.properties)\n    print(i.metadata)\n\nthe output, as expected:\n\n##########\n{‘geo’: GeoCoordinate(latitude=-23.55579948425293, longitude=-46.63959884643555), ‘city_name’: ‘São Paulo’}\nMetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None)\n##########\n{‘city_name’: ‘Belo Horizonte’, ‘geo’: GeoCoordinate(latitude=-19.919099807739258, longitude=-43.93870162963867)}\nMetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None)\n\nSo having something like, could be helpful:\nreturn_metadata=wvc.query.MetadataQuery(geo_distance=True),",
    "date_created": "2024-11-11T07:35:44.048Z",
    "has_accepted_answer": false,
    "title": "Distance in meters when using within_geo_range",
    "topic_id": 7531
  },
  {
    "user_id": 960,
    "conversation": "[kyle (2024-07-31T00:53:57.589Z)]: Hi Team,\nWe’re using WCS 1.25.9 and experiencing issues with Weaviate in our [production/staging/development] environment. The problem started at 6/30/2024\nError message:\nerror WeaviateStartUpError: Weaviate startup failed with message: Weaviate failed to startup with message: Weaviate makes use of a high-speed gRPC API as well as a REST API.\n      Unfortunately, the gRPC health check against Weaviate could not be completed.\n      This error could be due to one of several reasons:\n        - The gRPC traffic at the specified port is blocked by a firewall.\n        - gRPC is not enabled or incorrectly configured on the server or the client.\n            - Please check that the server address and port: [grpc-address-here].gcp.weaviate.cloud:443 are correct.\n        - your connection is unstable or has a high latency. In this case you can:\n            - increase init-timeout in weaviate.connectToLocal({timeout: {init: X}})'\n            - disable startup checks by connecting using 'skipInitChecks=true'\n\nHere is our code\nexport class WeaviateService {\n  private readonly logger = new Logger(WeaviateService.name);\n  private weaviateClient: WeaviateClient;\n  private readonly env: string;\n\n  constructor(private configService: ConfigService) {\n    this.env = configService.get('NODE_ENV');\n  }\n\n  async onModuleInit() {\n    const weaviateInstanceURL = process.env.WEAVIATE_INSTANCE_URL;\n    const weaviateApiKey = process.env.WEAVIATE_API_KEY;\n    const openAIApiKey = process.env.OPENAI_API_KEY;\n    try {\n      this.weaviateClient = await weaviate.connectToWeaviateCloud(\n        weaviateInstanceURL,\n        {\n          authCredentials: new weaviate.ApiKey(weaviateApiKey),\n          headers: {\n            'X-OpenAI-Api-Key': openAIApiKey,\n          },\n        },\n      );\n    } catch (error) {\n      console.log('error', error);\n    }\n  }\n// more code...\n}\n\nImportant details:\n\nNo changes have been made to our application code since yesterday.\nThe issue appeared suddenly without any apparent trigger.\n\nTroubleshooting steps:\n\nVerified gRPC endpoints and REST endpoints are the endpoints defined in our console dashboard. They are consistent.\nUsed ping and telnet to confirm that the address is valid\n\nWe would appreciate any guidance on resolving this gRPC connection issue. Thank you in advance for your help.\n\n----------\n\n[DudaNogueira (2024-07-31T01:06:55.466Z)]: Hi!\nCan you send an email to support@weaviate.io?\nThat will open a support ticket. Please make sure to state the endpoints or cluster name you are facing this issue.\nThanks!\n\n----------\n\n[kyle (2024-07-31T01:15:47.630Z)]: DudaNogueira:\n\nsupport@weaviate.io\n\n\nGot it. Will do @DudaNogueira",
    "date_created": "2024-07-31T00:53:57.532Z",
    "has_accepted_answer": true,
    "title": "Weaviate Startup Issue - WCS gRPC Connection error",
    "topic_id": 3227
  },
  {
    "user_id": 188,
    "conversation": "[zmliu213 (2025-01-24T20:53:06.524Z)]: Here is an example of properties of an object {…\n‘sectionName’: ‘introduction’,\n‘title’: ‘Tuberculosis manifesting with significant peripheral eosinophilia: A case report and review of literature’,\n‘publishingDate’: datetime.datetime(2023, 10, 23, 0, 0, tzinfo=datetime.timezone.utc),\n‘journal’: ‘Clinical Case Reports’,\n‘ids’: [{‘idValue’: ‘37881201’, ‘idName’: ‘PMID’},\n{‘idValue’: ‘10.1002/ccr3.8085’, ‘idName’: ‘DOI’},\n{‘idValue’: ‘PMC10593972’, ‘idName’: ‘PMCID’}]\nCould you use Filter to obtain papers with PMID (e.g., ‘idValue’ = ‘37881201’)? Property of “ids” is a list. Contains_any does not seem to work with scenario like this.\npmid_filter = Filter.any_of([\nFilter.by_property(“ids”).contains_any([{“idValue”: value, “idName”: “PMID”}])\nfor value in pmid_values\n])\nresult = collection.fetch_objects(\nfilters=pmid_filter\n)\nI keep getting validation error like this:\nvalue.int\nInput should be a valid integer [type=int_type, input_value=[{‘idValue’: ‘35838824’, ‘idName’: ‘PMID’}], input_type=list]\nFor further information visit Redirecting...\nAny suggestions?\n\n----------\n\n[Mohamed_Shahin (2025-01-27T10:57:40.089Z)]: Hello @zmliu213,\nWelcome to our community. It’s great to have you here.\nPlease note that this is not a feature yet but it’s in our road map\n\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Filtering and Vectorization for Nested Objects\n    \n\n    \n      \n        opened 07:34AM - 29 Oct 23 UTC\n      \n\n\n      \n        \n          \n          etiennedi\n        \n      \n    \n\n    \n        \n          backlog\n        \n    \n  \n\n\n  \n    #2424 introduced storing of nested objects. The next step is to make filtering (…and vectorization for modules) available for them.\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nRegards\nMohamed Shahin\nWeaviate Support",
    "date_created": "2025-01-24T20:53:06.441Z",
    "has_accepted_answer": true,
    "title": "Filtering objects based nested property",
    "topic_id": 9893
  },
  {
    "user_id": 1315,
    "conversation": "[lamoboos223 (2024-08-16T14:48:11.247Z)]: Description\nin the Quickstart page you provided how to connect with openai but what if i wanted use ollama or open source models from huggingface, how to do it?\n\ntry:\n    questions = client.collections.create(\n        name=\"Question\",\n        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),  # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n        generative_config=wvc.config.Configure.Generative.openai()  # Ensure the `generative-openai` module is used for generative queries\n    )\n\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: pip install -U weaviate-client\nMulti Node? Number of Running Nodes: one node, localhost\nClient Language and Version: python3.10\nMultitenancy?: no\n\nAny additional Information\nwhen i use ollama like this:\ntry:\n    questions = client.collections.create(\n        name=\"Question\",\n        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(),  # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n        generative_config=wvc.config.Configure.Generative.ollama()  # Ensure the `generative-openai` module is used for generative queries\n    )\n\ni get this error:\nweaviate.exceptions.UnexpectedStatusCodeError: Collection may not have been created properly.! Unexpected status code: 422, with response body: {'error': [{'message': 'vectorizer: no module with name \"text2vec-ollama\" present'}]}.\n\n----------\n\n[Joe (2024-08-16T15:28:16.833Z)]: lamoboos223:\n\nollection may not have been created properly.! Unexpected status code: 422, with response body: {'error': [{'message': 'vectorizer: no module with name \"text2vec-ollama\" present'}]}.\n\n\nHey!\nI can gladly help help here! When you are switching vectorizers you need to make sure the Module is also installed in your instance of Weaviate.   If you are following the quickstart, then the part where you set up your docker-compose.yml, under the environment variables,  you have ENABLE_MODULES here you would enable the modules you want to be able to access with your Weaviate Install.    Do note any changes to your docker compose file will require you to restart the instance of Weaviate with the new compose file!\nYou can find also the available modules here: Vectorizers and Rerankers | Weaviate - Vector Database\nI hope this helps get you past this error!\nRegards!",
    "date_created": "2024-08-16T14:48:11.149Z",
    "has_accepted_answer": true,
    "title": "How to Use different embedding than OpenAI",
    "topic_id": 3374
  },
  {
    "user_id": 1554,
    "conversation": "[Nagendra_Dattatreya (2024-09-18T17:24:04.112Z)]: Hi All,\nI’ve vectorized my data using Azure OpenAI Embeddings, but I wanted to confirm if I’m approaching the creation of collections correctly. So far, only the content itself is vectorized, while other fields are not. Does that sound right, or should the other fields be handled differently? There are 4 fields extension, filename, content, vector. I also want to use generative RAG using Azure OpenAI\nThanks in advance for any guidance!\nevaluators=client.collections.create(\n        name=\"CodeSnippet\",\n        vectorizer_config=None,\n        properties=[\n            wc.Property(name=\"extension\", data_type=wc.DataType.TEXT),\n            wc.Property(name=\"filename\", data_type=wc.DataType.TEXT),\n            wc.Property(name=\"content\", data_type=wc.DataType.TEXT),\n        ],\n    )\n\nServer Setup Information\n\nWeaviate Server Version: 1.27.0-alpha\nDeployment Method: ```\nsemitechnologies/weaviate:latest\n\n- Multi Node? Number of Running Nodes: 1\n- Client Language and Version:\n- Multitenancy?: \n\n### Any additional Information\n<!-- logs, additional setup information, anything extra you did in the setup or variables not included in any guide you followed -->\n\n----------\n\n[DudaNogueira (2024-09-18T18:48:17.569Z)]: hi @Nagendra_Dattatreya !!!\nAre you vectorizing your data yourself or want to let Weaviate vectorize it for you?\nBecause your ar passing vectorizer_config=None, Weaviate will not vectorize your data. This is what we call Bring your own vectors\nNow, regarding the properties to be vectorized, it will depend if that information adds meaning to your object and is relevant to your use case.\nSo removing unnecessary properties can help you have better vectors.\n\n----------\n\n[Nagendra_Dattatreya (2024-09-18T18:52:22.918Z)]: I have already vectorized the data (content column) using Azure OpenAI Embeddings. If I understand correctly, what you are saying is just add the property that is vectorized, is that correct?\nAnother question is if I let Weaviate vectorize the data, I am assuming I have to say which columns need to be vectorized. I also want to query the data based on user input\n\n----------\n\n[DudaNogueira (2024-09-18T21:46:03.975Z)]: Hi!\nThat’s right.\nIf you have vectorized already the content value, you can just pass that value to that content property, along with the vector.\nOn that case, Weaviate will not vectorize it for you, and will build the vector index and the inverted index, that will allow you search using bm25 and hybrid.\nYou can create the collection, specify the vectorizer, and move your data in. When you pass the vector, the vectorization step is not triggered, but when you don’t pass, Weavaite will do it for you.\nAnd yes, you need to specify which properties will be part of the vectorization.\nIf using named vectors, you can specify at the vectorizer config.\nIf you only have one vectorizer, not named, you can define it at the property level.\nLet me know if this helps",
    "date_created": "2024-09-18T17:24:04.064Z",
    "has_accepted_answer": false,
    "title": "Creating RAG using own data vectorized in Azure",
    "topic_id": 4193
  },
  {
    "user_id": 3238,
    "conversation": "[ilsg (2025-01-19T09:45:26.592Z)]: Description\n\nHello, I started using your database, at first everything was fine, but after a long recording of vectors(I recorded 1730168 vectors, disk space Estimated Sizes LSM stores 333Gb), it started to give an error in the logs:\n{\"action\":\"cyclemanager\",\"build_git_commit\":\"\",\"build_go_version\":\"go1.22.0\",\"build_image_tag\":\"\",\"build_wv_version\":\"1.28.2\",\"callback_id\":\"segmentgroup/compaction//home/user/rdata/weaviate/tksad/K5j5EQ9XTNCU/lsm/objects\",\"callbacks_id\":\"store/compaction/..\",\"class\":\"Tksad\",\"index\":\"tksad\",\"level\":\"error\",\"msg\":\"callback panic: runtime error: makeslice: len out of range\",\"shard\":\"K5j5EQ9XTNCU\",\"time\":\"2025-01-19T07:56:44Z\"}\n\nI thought after rebooting the database would be cured and the error would disappear, but this did not happen.\nServer Setup Information\nI use a multi-node configuration, I end up with 2 nodes, each running on its own physical server.\nConfiguration of each server:\n\n128gb memory ram ddr4\nxeon 2678v3\n4tb ssd nvme on raid0\nThere were no such errors on the second node.\nI launch it manually via binary files, here is an example of launching:\n\nexport LOG_LEVEL=\"trace\"\nexport CLUSTER_HOSTNAME=\"wv1\"\nexport CLUSTER_GOSSIP_BIND_PORT=7100\nexport CLUSTER_DATA_BIND_PORT=7101\nexport AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true\nexport PERSISTENCE_DATA_PATH=\"/home/user/rdata/weaviate\"\nexport ASYNC_INDEXING=true\nexport RAFT_BOOTSTRAP_EXPECT=1\nexport RAFT_JOIN=\"wv1:8300\"\nexport RAFT_BOOTSTRAP_TIMEOUT=3600\nexport PROMETHEUS_MONITORING_ENABLED=true\nexport LIMIT_RESOURCES=true\nexport TOMBSTONE_DELETION_MIN_PER_CYCLE=30000\nexport TOMBSTONE_DELETION_MAX_PER_CYCLE=300000\nexport QUERY_DEFAULTS_LIMIT=40\nexport PERSISTENCE_LSM_MAX_SEGMENT_SIZE=\"100GB\"\nexport REPLICATION_MINIMUM_FACTOR=1\n\nexport IMAGE_INFERENCE_API=\"http://192.168.88.246:8111\"\nexport DEFAULT_VECTORIZER_MODULE=\"img2vec-neural\"\nexport ENABLE_MODULES=\"img2vec-neural\"\nexport GO_PROFILING_DISABLE=true\n\n/home/user/app/weaviate --host 0.0.0.0 --port 8080 --scheme http\n\n\nWhy does this error occur?\nAnd how does it affect the functionality of the database?\nHow can I fix this error?\n\n----------\n\n[jeronimo_irazabal (2025-01-20T13:31:38.351Z)]: Hello @ilsg, the error log seems to indicate there is a corrupted .db file at  /home/user/rdata/weaviate/tksad/K5j5EQ9XTNCU/lsm/objects. if such .db file does not have an associated .wal file it may indicate the file got corrupted after being successfully written on disk.\nThere may not be a way to recover such file in an isolated manner but restoring from a backup or by moving out such .db file from that path in a multi-node setup the data will be replicated automatically as the data is queried (there is a replication mechanism called read-repair).\nThere is an ongoing effort already to identify integrity checking on .db files so to automatically detect this situation in a better way.\n\n----------\n\n[ilsg (2025-01-20T13:36:51.676Z)]: And how will this file damage affect the operation of the database itself?\nBecause now, the database works normally, it also writes data and performs searches.\nMaybe there is a way to delete this damaged file?\nUnfortunately, I did not have a replica for this collection in a multi-node configuration to restore it.\n\n----------\n\n[jeronimo_irazabal (2025-01-20T13:46:34.987Z)]: if the collection was created with replication factor greater than one, the same data will be stored in other nodes, in such a case, removing the corrupted .db files may be the simplest solution. If a backup is not available and replication factor is one, it would mean the inserted data stored in such files wont be recoverable and re-ingestion will be required.\nCurrently, having a corrupted file could generate that kind of issues you are seeing, probably preventing the operations to succeed, so I’d recommend to remove such file. In that log line the filename is not shown but this situations will be handled in a better manner once integrity checking in such type of files is completed.\nnote: if possible, it would better to use a three nodes setup as it will be possible to continue normal operations if a node goes down.\n\n----------\n\n[ilsg (2025-01-20T13:52:54.333Z)]: Am I right in understanding that right now there is no way to find out which file is damaged?\nAlso, do I understand correctly that the newly inserted data will work correctly in the database?\n\n----------\n\n[jeronimo_irazabal (2025-01-20T13:56:13.154Z)]: newly inserted data will work correctly. currently you may identify which is the corrupted .db file based on some error log lines, in the compaction one it’s not shown but if you pursue a search e.g. for a non-existing object uuid it may attempt to read from all the .db files and such error may appear (including the filename)\n\n----------\n\n[ilsg (2025-01-20T14:08:48.329Z)]: OK, thank you for your prompt assistance in resolving my issue.",
    "date_created": "2025-01-19T09:45:26.538Z",
    "has_accepted_answer": true,
    "title": "Runtime error: makeslice: len out of range",
    "topic_id": 9811
  },
  {
    "user_id": 813,
    "conversation": "[djjeffr (2025-01-14T22:30:46.956Z)]: Description\nHow to configure cohere as self hosted instead of public cohere url\n\n----------\n\n[Mohamed_Shahin (2025-01-16T10:19:04.553Z)]: Hi @djjeffr,\nIndeed, there are several model providers that you can host locally with Weaviate. Here’s a list of options available for local deployment:\n• GPT4All (locally hosted)\n• KubeAI (Locally hosted)\n• Hugging Face (locally hosted)\n• Meta ImageBind (locally hosted)\n• Ollama (locally hosted)\nAdditionally, our integration with Cohere is available at:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCohere + Weaviate | Weaviate\n\n  Cohere offers a wide range of models for natural language processing and generation. Weaviate seamlessly integrates with Cohere's APIs, allowing users to leverage Cohere's models directly from the Weaviate database.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThese links should give you a good starting point to explore.\nBest regards,\nMohamed Shahin\nWeaviate Support Engineer\n\n----------\n\n[djjeffr (2025-01-16T20:41:02.690Z)]: Still doesn’t say how to connect to a locally hosted cohere? Why is cohere api url hard coded?\nThe reranker-cohere code has cohereAPIurl hard coded, see weaviate/modules/reranker-cohere/clients/ranker.go at 3cbf49a059a36b6c084b8f0ca95392e81122b185 · weaviate/weaviate · GitHub\nThe text2vec-cohere code allows the cohereAPIurl to be passed in, could the reranker-cohere code be changed to allow APIurl to be passed in.",
    "date_created": "2025-01-14T22:30:46.911Z",
    "has_accepted_answer": false,
    "title": "How to configure cohere as self hosted",
    "topic_id": 9759
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-09-13T20:29:03.984Z)]: Description\nHi, it’s been over an hour and the cluster is still on creation.\nThis was a serverless on US West.\nimage1854×502 29.4 KB\nNote: I just tried doing it for US East and it worked so it seems it’s a regional problem.\nServer Setup Information\n\nWeaviate Server Version: 1.25.10\nDeployment Method: Serverless\nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\n----------\n\n[DudaNogueira (2024-09-13T20:36:38.571Z)]: hi @Tejas_Sharma !!\nFor any issue related to our hosted servers, the best place for support is following here (sending an email to support@weaviate.io)\nThat way we can identify the cluster and work on it.\nThanks!",
    "date_created": "2024-09-13T20:29:03.937Z",
    "has_accepted_answer": false,
    "title": "US West Server unable to be created",
    "topic_id": 4154
  },
  {
    "user_id": 1635,
    "conversation": "[kaushik_acharya (2024-10-05T07:25:29.623Z)]: Description\n\nI am running locally on my laptop the assignments from the DeepLearning.ai course: Building Multimodal Search and RAG\nI am facing issue in the assignment L5 Building Multimodal Search and RAG - DeepLearning.AI.\nIn this assignment we load the backup collection (containing images and videos) provided in the course:\n\nclient.backup.restore(\nbackup_id=“resources-img-and-vid”,\ninclude_collections=collection_name,\nbackend=“filesystem”\n)\n\nI am able to get the count of images and videos.\nThe error comes while retrieving similar content based on a text query. (This is a multimodal assignment where we do retrieve images and videos based on text query).\n\nresources = client.collections.get(collection_name)\nresponse = resources.query.near_text(\nquery=query,\nfilters=Filter.by_property(“mediaType”).equal(“image”),  # return only image objects\nreturn_properties=[“path”],\nlimit=1\n)\n\nError stack:\npython3.11/site-packages/weaviate/collections/grpc/query.py:618) raise WeaviateQueryError(e.details(), \"GRPC search\") WeaviateQueryError: Query call with protocol GRPC search failed with message explorer: get class: vectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: connection to Google PaLM failed with status: 403 error: Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/semi-random-dev/locations/us-central1/publishers/google/models/multimodalembedding@001' (or it may not exist)..\nMy understanding for the reason of this failure:\nThe collection was likely created using the below command as mentioned in L2 assignment: Building Multimodal Search and RAG - DeepLearning.AI\nclient.collections.create(\n    name=collection_name,\n    vectorizer_config=Configure.Vectorizer.multi2vec_palm(\n        image_fields=[\"image\"],\n        video_fields=[\"video\"],\n        project_id=\"semi-random-dev\",\n        location=\"us-central1\",\n        model_id=\"multimodalembedding@001\",\n        dimensions=1408\n    )\n)\n\nThe project_id mentioned is semi-random-dev. Whereas the project_id of my project in Google Cloud is different.\nQuestion: Is it possible to change the project_id in the vectorizer_config of the restored collection?\nServer Setup Information\n\nWeaviate Server Version: weaviate-client==4.5.4\nDeployment Method:  embedded\nMulti Node? Number of Running Nodes:\nClient Language and Version: Python 3.11\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-10-06T17:49:40.813Z)]: hi @kaushik_acharya !!\nWelcome to our community \nIt looks like it is indeed what you mentioned.\nYou may need to create the collection with the project name you have access to.\nUnfortunately, those infos are not mutable (check here for a list of mutability configs of a collection).\nWhat you can do, in order to change immutable configs of a collection is to reindex your data using our migration guide.\nLet me know if this helps!\n\n----------\n\n[kaushik_acharya (2024-10-13T13:52:22.646Z)]: Hi @DudaNogueira\nFirst of all thanks for the reply.\nI am facing issue similar to the one mentioned in Embedded Weaviate Port 6060 - Support - Weaviate Community Forum\nAs mentioned in the above thread, I added the environment variable:\n\"GO_PROFILING_DISABLE\": \"true\"\nin weaviate.connect_to_embedded\nwhich gives the message:\nlisten tcp :6060: bind: address already in use\nand throws the error\n\nWeaviateStartUpError: Embedded DB did not start listening on port 8090 within 30 seconds\n\nI have passed a different port and grpc_port for the target weaviate instance.\n\n----------\n\n[DudaNogueira (2024-10-14T23:10:14.223Z)]: hi! There is probably something running also on port 6060, so Weaviate embedded was not able to start.\nAlso, try using a new client version.\n\n----------\n\n[kaushik_acharya (2024-10-15T19:57:32.487Z)]: The command lsof -i:6060 shows\nCOMMAND     PID    USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\nweaviate- 12670 kaushik    8u  IPv6 3175934      0t0  TCP *:6060 (LISTEN)\n\n----------\n\n[DudaNogueira (2024-10-16T02:30:00.251Z)]: Yes, this is probably some conflict on embedded running on port 6060 for profiling.\nCan you try moving away from embedded? This is only meant to allow a quick run on Weaviate directly from the client.\nyou can copy over your data from the Embedded Weaviate path to the same path at PERSISTENCE_DATA_PATH at a docker instance for example.\nAlso, have you tried running on a newer client?\nThanks!\n\n----------\n\n[kaushik_acharya (2024-10-26T10:20:04.595Z)]: Using weaviate client version 4.9.0 on embedded also throws the same error:\n\nWeaviateStartUpError: Embedded DB did not start listening on port 8090 within 30 seconds\n\nOnly difference is the newer client version is not showing the message\n\nlisten tcp :6060: bind: address already in use\n\nI didn’t tried docker instance as suggested by you.",
    "date_created": "2024-10-05T07:25:29.563Z",
    "has_accepted_answer": false,
    "title": "Failure in retrieving content from a backup restored collection created on a different machine",
    "topic_id": 4434
  },
  {
    "user_id": 753,
    "conversation": "[rhuang (2024-09-10T20:00:32.355Z)]: In multitantency setting, we can add different tenants in one collection. What is the maximum number of tenants we can have in one collection?\n\n----------\n\n[Mohamed_Shahin (2024-09-11T08:09:18.695Z)]: Hey @rhuang,\nhow’s your week going?\nThere isn’t a fixed limit in Weaviate either with collections or tenants. It can handle as many as you need, depending on the resources available. The more resources you allocate, the more Weaviate can manage efficiently.\nHave a lovely week!",
    "date_created": "2024-09-10T20:00:32.305Z",
    "has_accepted_answer": true,
    "title": "[Question] How many tenants can we have in one collection?",
    "topic_id": 4095
  },
  {
    "user_id": 2428,
    "conversation": "[Marco_Vinicius_Nobre (2024-10-31T20:56:16.348Z)]: Description\nHey! I have a collection with around 30+ properties available, and I want the user, at query time, to choose relevant properties that´s important for their search.\nThe problem is that right now, from my understanding, to do that in the query_properties field, as exemplified below, requires me to write all other properties that still had the value of 1 for me to consider them:\njeopardy = client.collections.get(\"JeopardyQuestion\")\nresponse = jeopardy.query.bm25(\n    query=\"food\",\n    query_properties=[\"question^2\", \"answer\"],\n    limit=3\n)\n\nThe collection’s properties are dynamic and it´s common for new ones to appear, and it´s not feasible for the client to create the list and send to the server.\nIdeally, I wanted an option where the code above would work the same, with or without the “answer” property in the list.\nDid anyone face this challenge yet? And if so, how do you guys were able to work around this?\nThanks in advance! Appreciate it!\nBy the way, I wanted to avoid adding a step that get´s all properties of a collections before running the query, simply to avoid any overhead\n\n----------\n\n[DudaNogueira (2024-11-01T13:08:26.262Z)]: hi @Marco_Vinicius_Nobre!!\nWelcome to our community \nThat’s a really nice feature to have.\nSomething like: apply_weight that will end up with all properties plus the weighted ones, right?\nDo you think that having also something like exclude_query_properties would be helpful?\nThanks!\n\n----------\n\n[Marco_Vinicius_Nobre (2024-11-01T13:23:23.952Z)]: Hey @DudaNogueira, thanks for the welcome!\nI believe that having both would be extremely helpful! The behaviour I was imagine is exactly what you mentioned.\nJust to give a brief explantion of what I am trying to do: I am using this feature to implement a sort of “nice_to_have” filters, where if a data has a certain property value, it will score higher, but if it doesn´t, it can still show up at the bottom of the result.\nThanks a lot for the quick response\n\n----------\n\n[Marco_Vinicius_Nobre (2024-11-28T13:54:17.611Z)]: Hey @DudaNogueira ! Do you know if there are any news regarding this topic?\n\n----------\n\n[DudaNogueira (2024-11-29T10:15:08.665Z)]: hi!\nwe discussed the syntax of:\n[“*”, “question^2”, “-title”]\nHowever, this is still in the proposition phase.\nWe should open a Feature Request. But unfortunately we do not have a ETA as of now",
    "date_created": "2024-10-31T20:56:16.295Z",
    "has_accepted_answer": false,
    "title": "Changing keyword weight of only one out of 30 properties",
    "topic_id": 7366
  },
  {
    "user_id": 1302,
    "conversation": "[wvuser (2024-09-03T20:43:10.115Z)]: Description\nWe are testing 3-node cluster (replication factor 3), all data synchronized and… suddenly one node physically failed. The new pod (empty) was deployed on a new machine and activated “read repair” procedure (using batch reading), but It work too slowly ~50obj/sec (how to speedup it?).\nProblem: when search request (text/vector) is routed to “empty” node  (with any QUORUM or ALL consistency level) - not valid result avalaible. It seems that the “empty” node explicitly looks for data within itself at first… not founds them and quorum/all conditions are not satisfied. At result:\n\nfor “property equal” search (getting objects by id’s list at once with “ContainsAny”) - not any results returned;\nfor vector search - not self and not closest vectors returned.\n\nIf request routed to any node “with this data”, search results are correct.\nHow to exclude “empty” (not replicated) node from operations or QUORUM/ALL conditions?\nServer Setup Information\n\nWeaviate Server Version: 1.25.12\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: Yes, 3\nClient Language and Version: Python3, Python Client v3\nMultitenancy?: No\n\n----------\n\n[DudaNogueira (2024-09-04T13:30:09.023Z)]: hi @wvuser !!\nAre you aware of the new feature that landed in 1.26, the async replication?\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nReplication | Weaviate\n\n  Weaviate instances can be replicated. Replication can improve read throughput, improve availability, and enable zero-downtime upgrades.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThis will proactively start the repair async.\nIt may reduce the time between the node realizing that it is inconsistent and a part of a cluster.\nI will ask about this scenario to our team.\nThanks!\n\n----------\n\n[wvuser (2024-09-06T06:19:32.176Z)]: DudaNogueira:\n\nAre you aware of the new feature that landed in 1.26, the async replication?\n\n\nYes:) Tried to upgrade:\n\nPods succesfully started with 1.26.3 image version;\nManually updated schema with “asyncEnabled”:true;\nIn logs appeared information about async replication starand crash:\n{“action”:“async_replication”,“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“class_name”:“MyClass”,“level”:“info”,“msg”:“hashtree initialization is progress…”,“object_count”:14842232,“shard_name”:“QZOXu2zY6rKM”,“time”:“2024-09-05T09:49:23Z”}\n{“action”:“async_replication”,“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“class_name”:“MyClass”,“level”:“info”,“msg”:“hashbeater stopped”,“shard_name”:“b4ulnsitcsN2”,“time”:“2024-09-05T09:49:24Z”}\n{“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“level”:“error”,“msg”:“Recovered from panic: runtime error: index out of range [1] with length 1”,“time”:“2024-09-05T09:49:24Z”}\ngoroutine 692758 [running]:\nruntime/debug.Stack()\n\n\n/usr/local/go/src/runtime/debug/stack.go:24 +0x5e*\nruntime/debug.PrintStack()\n/usr/local/go/src/runtime/debug/stack.go:16 +0x13*\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1.1()\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:32 +0x150*\npanic({0x20565e0?, 0xf71f95d218?})\n/usr/local/go/src/runtime/panic.go:914 +0x21f*\n*github.com/weaviate/weaviate/adapters/repos/db/lsmkv.(segment).newCursorWithSecondaryIndex(0xc002ae0870, 0x1)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/cursor_segment_replace.go:58 +0x290*\n*github.com/weaviate/weaviate/adapters/repos/db/lsmkv.(SegmentGroup).newCursorsWithSecondaryIndex(0xc0052dc0c0, 0xf4def49c70?)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/cursor_segment_replace.go:99 +0xab*\n*github.com/weaviate/weaviate/adapters/repos/db/lsmkv.(Bucket).CursorWithSecondaryIndex(0xc003e64000, 0x21996ef?)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/cursor_bucket_replace.go:82 +0x9c*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).ObjectDigestsByTokenRange(0xc0050ff180?, {0x29050a0?, 0xc029e42780?}, 0x150000000000000, 0x19dffffffffffff, 0x3e8)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_read.go:138 +0x9f*\n*github.com/weaviate/weaviate/adapters/repos/db.(Index).DigestObjectsInTokenRange(0x459eab?, {0x29050a0, 0xc029e42780}, {0xc005823a90, 0xc}, 0xf4def4a0d8?, 0x565ff2?, 0x0?)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/replication.go:475 +0x169*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).stepsTowardsShardConsistency(0xc005466000, {0x29050a0, 0xc029e42780}, {0xc005823a90, 0xc}, {0xc5f4305e78, 0x11}, 0xc5f434d440?, 0x19dffffffffffff, 0x186a0)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_hashbeater.go:336 +0x105*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).hashBeat(0xc005466000)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_hashbeater.go:288 +0x81f*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).initHashBeater.func1()\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_hashbeater.go:80 +0x45b*\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1()\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:36 +0x62*\ncreated by github.com/weaviate/weaviate/entities/errors.GoWrapper in goroutine 580955\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:26 +0x79*\n{“action”:“async_replication”,“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“class_name”:“MyClass”,“level”:“info”,“msg”:“hashbeater stopped”,“shard_name”:“PfYchyFAyseL”,“time”:“2024-09-05T09:49:24Z”}\n{“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“level”:“error”,“msg”:“Recovered from panic: runtime error: index out of range [1] with length 1”,“time”:“2024-09-05T09:49:24Z”}\ngoroutine 662155 [running]:\nruntime/debug.Stack()\n/usr/local/go/src/runtime/debug/stack.go:24 +0x5e*\nruntime/debug.PrintStack()\n/usr/local/go/src/runtime/debug/stack.go:16 +0x13*\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1.1()\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:32 +0x150*\npanic({0x20565e0?, 0xf737c47218?})\n/usr/local/go/src/runtime/panic.go:914 +0x21f*\n*github.com/weaviate/weaviate/adapters/repos/db/lsmkv.(segment).newCursorWithSecondaryIndex(0xc002b4e000, 0x1)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/cursor_segment_replace.go:58 +0x290*\n*github.com/weaviate/weaviate/adapters/repos/db/lsmkv.(SegmentGroup).newCursorsWithSecondaryIndex(0xc00553a300, 0xf6e26e1c70?)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/cursor_segment_replace.go:99 +0xab*\n*github.com/weaviate/weaviate/adapters/repos/db/lsmkv.(Bucket).CursorWithSecondaryIndex(0xc004034000, 0x21996ef?)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/cursor_bucket_replace.go:82 +0x9c*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).ObjectDigestsByTokenRange(0xc0050ff180?, {0x29050a0?, 0xc029e428c0?}, 0x2fe000000000000, 0x4b3ffffffffffff, 0x3e8)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_read.go:138 +0x9f*\n*github.com/weaviate/weaviate/adapters/repos/db.(Index).DigestObjectsInTokenRange(0x459eab?, {0x29050a0, 0xc029e428c0}, {0xc0058229f0, 0xc}, 0xf6e26e20d8?, 0x565ff2?, 0x0?)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/replication.go:475 +0x169*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).stepsTowardsShardConsistency(0xc005a20000, {0x29050a0, 0xc029e428c0}, {0xc0058229f0, 0xc}, {0xe825b2cb88, 0x11}, 0xf6e26b0300?, 0x4b3ffffffffffff, 0x186a0)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_hashbeater.go:336 +0x105*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).hashBeat(0xc005a20000)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_hashbeater.go:288 +0x81f*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).initHashBeater.func1()\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_hashbeater.go:80 +0x45b*\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1()\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:36 +0x62*\ncreated by github.com/weaviate/weaviate/entities/errors.GoWrapper in goroutine 580957\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:26 +0x79*\n{“action”:“async_replication”,“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“class_name”:“MyClass”,“level”:“info”,“msg”:“hashtree initialization is progress…”,“object_count”:15064448,“shard_name”:“QZOXu2zY6rKM”,“time”:“2024-09-05T09:49:24Z”}\n{“action”:“async_replication”,“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“class_name”:“MyClass”,“level”:“info”,“msg”:“hashtree successfully initialized”,“shard_name”:“QZOXu2zY6rKM”,“time”:“2024-09-05T09:49:24Z”}\n{“action”:“async_replication”,“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“class_name”:“MyClass”,“level”:“info”,“msg”:“hashbeater started…”,“shard_name”:“QZOXu2zY6rKM”,“time”:“2024-09-05T09:49:24Z”}\n{“action”:“async_replication”,“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“class_name”:“MyClass”,“level”:“info”,“msg”:“hashbeater stopped”,“shard_name”:“QZOXu2zY6rKM”,“time”:“2024-09-05T09:49:28Z”}\n{“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“level”:“error”,“msg”:“Recovered from panic: runtime error: index out of range [1] with length 1”,“time”:“2024-09-05T09:49:28Z”}\ngoroutine 695187 [running]:\nruntime/debug.Stack()\n/usr/local/go/src/runtime/debug/stack.go:24 +0x5e*\nruntime/debug.PrintStack()\n/usr/local/go/src/runtime/debug/stack.go:16 +0x13*\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1.1()\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:32 +0x150*\npanic({0x20565e0?, 0xf653e906a8?})\n/usr/local/go/src/runtime/panic.go:914 +0x21f*\n*github.com/weaviate/weaviate/adapters/repos/db/lsmkv.(segment).newCursorWithSecondaryIndex(0xc003f803c0, 0x1)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/cursor_segment_replace.go:58 +0x290*\n*github.com/weaviate/weaviate/adapters/repos/db/lsmkv.(SegmentGroup).newCursorsWithSecondaryIndex(0xc0040bca80, 0xf4def49c70?)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/cursor_segment_replace.go:99 +0xab*\n*github.com/weaviate/weaviate/adapters/repos/db/lsmkv.(Bucket).CursorWithSecondaryIndex(0xc005a2e240, 0x21996ef?)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/cursor_bucket_replace.go:82 +0x9c*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).ObjectDigestsByTokenRange(0xc0050ff180?, {0x29050a0?, 0xc029e42820?}, 0x0, 0x1ffffffffffff, 0x3e8)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_read.go:138 +0x9f*\n*github.com/weaviate/weaviate/adapters/repos/db.(Index).DigestObjectsInTokenRange(0x459eab?, {0x29050a0, 0xc029e42820}, {0xc005823240, 0xc}, 0xf4def4a0d8?, 0x565ff2?, 0x0?)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/replication.go:475 +0x169*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).stepsTowardsShardConsistency(0xc0004b1dc0, {0x29050a0, 0xc029e42820}, {0xc005823240, 0xc}, {0xf737c47578, 0x11}, 0xf68ad82a40?, 0x1ffffffffffff, 0x186a0)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_hashbeater.go:336 +0x105*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).hashBeat(0xc0004b1dc0)\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_hashbeater.go:288 +0x81f*\n*github.com/weaviate/weaviate/adapters/repos/db.(Shard).initHashBeater.func1()\n/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_hashbeater.go:80 +0x45b*\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1()\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:36 +0x62*\ncreated by github.com/weaviate/weaviate/entities/errors.GoWrapper in goroutine 580956\n/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:26 +0x79*\n{“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-2 xxx.yyy.zzz.www:7000\",“time”:“2024-09-05T09:49:31Z”}\n{“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=xxx.yyy.zzz.www:53136\",“time”:“2024-09-05T09:49:33Z”}\n{“build_git_commit”:“9a4ea6d”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.3”,“build_wv_version”:“1.26.3”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=xxx.yyy.zzz.www:33106\",“time”:“2024-09-05T09:49:41Z”}\n\n\nAsync replication didn’t starts any more;\nTried to restart pods (too long termination time! after ‘timeout’ pod terminated forcelly);\nAfter load “asyncEnabled” flag auto resetted to false.\n\n\n\n\n wvuser:\n\nIt seems that the “empty” node explicitly looks for data within itself at first… not founds them and quorum/all conditions are not satisfied.\n\n\nProblem with “empty for text (or not closest for vectors)” search results with QUORUM consistency when requests routed to “empty” node are stay…",
    "date_created": "2024-09-03T20:43:10.061Z",
    "has_accepted_answer": false,
    "title": "Empty search results when one node (of 3) is not fully replicated",
    "topic_id": 3971
  },
  {
    "user_id": 3243,
    "conversation": "[Axel_Straminsky (2025-02-05T20:29:41.557Z)]: Is there a way to update, for example, a property’s description after the collection has been created?\n\n----------\n\n[Mohamed_Shahin (2025-02-06T08:58:57.195Z)]: Hi @Axel_Straminsky,\nDirectly updating a property description is not currently supported in Weaviate, there might be a workaround.\nIf I come across anything, I will share it with you.\nRegards,\nMohamed Shahin\nSupport Engineer\n\n----------\n\n[Axel_Straminsky (2025-02-06T12:32:11.707Z)]: Hi @Mohamed_Shahin ,\nIs this feature planned to be supported any time soon? Because the only workaround I can think of right now is to create a new collection with the updated property description, and then migrate the old collection to the new one, which would be quite inconvenient for us.\nThanks!\n\n----------\n\n[Mohamed_Shahin (2025-02-06T13:29:23.676Z)]: I have not seen this as feature request. However it’s good one to have.\nI’ve added this: Update property’s description after the collection has been created · Issue #7153 · weaviate/weaviate · GitHub\nFeel free to  as the more we vote for it, it can be prioritized quicker.\nRegards,\nMohamed Shahin\nSupport Engineer",
    "date_created": "2025-02-05T20:29:41.517Z",
    "has_accepted_answer": true,
    "title": "Update collection's properties",
    "topic_id": 10021
  },
  {
    "user_id": 695,
    "conversation": "[weisisheng (2024-09-25T00:34:57.597Z)]: Not understanding the difference in these returned responses:\nUsing the jeopardy quickstart example…\n1/ I set up the collection with a standard cohere embedding (no named vectors)\n  const questions = await weaviateClient.collections.create({\n    name: \"Question\",\n    vectorizers: vectorizer.text2VecCohere({\n      model: \"embed-english-light-v3.0\",\n    }),\n  });\n  console.log(`Collection ${questions.name} created!`);\n}\n\n2/ In my script I insert toy data and query the objects:\nconst myCollection = weaviateClient.collections.get(\"Question\");\n\nconst result = await myCollection.query.fetchObjects({\n  includeVector: true,\n  limit: 1,\n});\n\nconsole.log(\"this is the fetch objects: \", JSON.stringify(result, null, 2));\nwhich results in:\nthis is the fetch objects:  {\n  \"objects\": [\n    {\n      \"metadata\": {},\n      \"properties\": {\n        \"answer\": \"the atmosphere\",\n        \"category\": \"SCIENCE\",\n        \"question\": \"Changes in the tropospheric layer of this are what gives us weather\"\n      },\n      \"uuid\": \"0119e108-5461-48c0-8d28-b8606cd57a83\",\n      \"vectors\": {\n        \"default\": [\n          -0.06719970703125,\n          0.0239715576171875,\n          0.0860595703125,\n...\n\n3/ Separately, in Insomnia, I query the collection’s objects using graphql and the _additional: vector field is blank.\n{\n\tGet {\n\t\tQuestion {\n\t\t\tcategory\n\t\t\tquestion\n\t\t\tanswer\n\t\t\t_additional {\n\t\t\t\tdistance\n\t\t\t\tvector\n\t\t\t\tid\n\t\t\t}\n\t\t}\n\t}\n}\n\nresponse:\n{\n\t\"data\": {\n\t\t\"Get\": {\n\t\t\t\"Question\": [\n\t\t\t\t{\n\t\t\t\t\t\"_additional\": {\n\t\t\t\t\t\t\"distance\": null,\n\t\t\t\t\t\t\"id\": \"0119e108-5461-48c0-8d28-b8606cd57a83\",\n\t\t\t\t\t\t\"vector\": [] <-------shouldn't this be the same values\n\t\t\t\t\t},\n\t\t\t\t\t\"answer\": \"the atmosphere\",\n\t\t\t\t\t\"category\": \"SCIENCE\",\n\t\t\t\t\t\"question\": \"Changes in the tropospheric layer of this are what gives us weather\"\n\t\t\t\t},\n\n\nNotice the UUIDs are the same, so what am I missing?\nServer Setup Information\n\nWeaviate Server Version:  1.26.4\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: typescript v3\nMultitenancy:  no\n\n----------\n\n[weisisheng (2024-09-25T00:38:18.944Z)]: Separately, using this setup notation, is the vectorization done on all the fields?\n\n----------\n\n[Dirk (2024-09-25T05:31:51.586Z)]: Hi,\nwe have a functionality called named vectors: Multiple vectors | Weaviate\nThe TS client creates a named vector called “default” if you just choose a single vectorizer and if you fetch an object it hides that from you.\nHowever in GQL queries you need to put that name in and the following shuld work\nvectors{default}\n\nPS:\nThe code is very hard to read if it is unformated, you can use “```” to start and end a code environment\n\n----------\n\n[weisisheng (2024-09-25T05:54:25.822Z)]: Great advice and much appreciated.  This needs to be documented better in the docs.  I find no reference to vector default when I search in the named vectors section.\nI cleaned up the formatting.\nAll the best, V.\n\n----------\n\n[Dirk (2024-09-25T08:15:48.792Z)]: I’ll let the docs team know!",
    "date_created": "2024-09-25T00:34:57.544Z",
    "has_accepted_answer": true,
    "title": "Explain _additional vector returned response like i am 5",
    "topic_id": 4291
  },
  {
    "user_id": 434,
    "conversation": "[A_S (2024-04-12T06:57:52.906Z)]: Hi, currently facing the following problem:\nwhen extracting the hybrid score in the following manner:\n\n.with_hybrid(\n                query=query,\n                alpha=0.5,\n                vector=embedded_query,\n                fusion_type=HybridFusion.RELATIVE_SCORE\n            ) \\\n            .with_additional(['score', 'explainScore', 'id']) \n\ndef get_score_from_object(obj) -> float | None:\n    if obj is not None \\\n            and isinstance(obj, dict) \\\n            and \"_additional\" in obj \\\n            and obj[\"_additional\"] is not None \\\n            and isinstance(obj[\"_additional\"], dict) \\\n            and \"score\" in obj[\"_additional\"]:\n        return obj[\"_additional\"][\"score\"]\n    else:\n        return None\n\nScore values returned for the same query with the same chunks 3 times delivered following results:\nSCORE 0.8715031\nSCORE 0.62721163\nSCORE 0.6142747\nSCORE 0.5678266\nSCORE 0.5\nSCORE 0.4993174\nSCORE 0.47722983\nThen:\nSCORE 0.018778471\nSCORE None\nSCORE None\nSCORE None\t\nSCORE None\nSCORE None\nSCORE None\nThen:\nAll scores were None\nAnd then by the 4rth time quering, received the same scores as the first time.\nAm I extracting it wrong? Why is it also happening randomly? This problem didn’t seem to occur with the regular vector score…\nThis is what the response from weaviate looks like with and without None:\nSCORE None\n{‘_additional’: {‘explainScore’: ‘\\nHybrid (Result Set keyword) Document a40a4895-ea75-45c0-b09c-dfde5ff94f11: original score NaN, normalized score: NaN’, ‘id’: ‘a40a4895-ea75-45c0-b09c-dfde5ff94f11’, ‘score’: None}, ‘document’: [{‘_additional’: {‘id’: ‘2260563d-8b45-45b6-93fa-217d651387ac’}\nSCORE 0.026299512\n{‘_additional’: {‘explainScore’: ‘\\nHybrid (Result Set vector) Document 6ebf4e68-f63c-4bdd-b6d1-7ec8cc79f71f: original score 0.7842568, normalized score: 0.026299512’, ‘id’: ‘6ebf4e68-f63c-4bdd-b6d1-7ec8cc79f71f’, ‘score’: ‘0.026299512’}, ‘document’: [{‘_additional’: {‘id’: ‘f03cf04d-7af5-4ca2-a0d6-886feac9ed67’}\nSCORE None\n{‘_additional’: {‘explainScore’: ‘\\nHybrid (Result Set vector) Document 70e58854-ff9d-4721-87da-e446035b3f50: original score 0.81138486, normalized score: 0.17339171 - \\nHybrid (Result Set keyword) Document 70e58854-ff9d-4721-87da-e446035b3f50: original score NaN, normalized score: NaN’, ‘id’: ‘70e58854-ff9d-4721-87da-e446035b3f50’, ‘score’: None},\n‘document’: [{‘_additional’: {‘id’: ‘7006ad84-b872-4684-b9b7-bcb892623693’}\nThanks for your help!\n\n----------\n\n[DudaNogueira (2024-04-12T12:57:17.403Z)]: Hi!\nWhat is the version you are using?\nCan you reproduce this on latest version?\n\n----------\n\n[A_S (2024-04-12T13:04:34.724Z)]: Hi, we are on weaviate server version 1.24.3!\n\n----------\n\n[A_S (2024-04-13T14:30:59.799Z)]: We now reproduced with 1.24.8…\n\n----------\n\n[DudaNogueira (2024-04-17T18:28:13.161Z)]: Hi! Can you share a reproducible code example?\nI was not able to reproduce this here \nThanks!\n\n----------\n\n[youssef_ajlani (2024-07-11T16:09:03.031Z)]: @DudaNogueiraIt is not reproducible as it happens very randomly. I am experiencing the same issue.\n\n----------\n\n[DudaNogueira (2024-07-15T16:39:09.673Z)]: hi! Welcome to our community.\nWhat are the version you are using?\nCan you reproduce this with latest?",
    "date_created": "2024-04-12T06:57:52.833Z",
    "has_accepted_answer": false,
    "title": "Hybrid score returning NONE scores randomly for the same query with the same chunks",
    "topic_id": 1996
  },
  {
    "user_id": 1536,
    "conversation": "[Samuel (2024-09-13T13:44:18.909Z)]: I have the following collection that is receiving an error: invalid combination of properties\nclient.collections.create(\n    \"Blogs\",\n    description=\"this is testing db to understand weaviate\",\n    vectorizer_config=Configure.Vectorizer.text2vec_transformers(\n        inference_url=\"http://t2v-transformers:8080\", vectorize_collection_name=False\n    ),\n    properties=[\n        Property(name=\"idCSV\", data_type=DataType.TEXT, skip_vectorization=True),\n        Property(name=\"gender\", data_type=DataType.TEXT, skip_vectorization=True),\n        Property(name=\"age\", data_type=DataType.INT, skip_vectorization=True),\n        Property(name=\"topic\", data_type=DataType.TEXT, skip_vectorization=True),\n        Property(name=\"sign\", data_type=DataType.TEXT, skip_vectorization=True),\n        Property(name=\"date\", data_type=DataType.DATE, skip_vectorization=True),\n        Property(name=\"text\", data_type=DataType.TEXT_ARRAY, skip_vectorization=False),\n    ],\n)\n\n\nNote: This is the v4 python api.\nI have seen another issue that was similar. However, the above collection is vectorizing on the ‘text’ attribute.\nHow do I vectorize on a single attribute? How important is the vectorization of the collection name?\nThank you very much in advance.\n\n----------\n\n[Samuel (2024-09-13T14:05:45.081Z)]: Found the answer. configuring text2vec_transformer is a little different.\nHere is a working updated version.\nclient.collections.create(\n    \"Blogs\",\n    description=\"this is testing db to understand weaviate\",\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_transformers(\n            name=\"text_vector\",\n            source_properties=[\"text\"],\n            vectorize_collection_name=False,\n        )\n    ],\n    properties=[\n        Property(name=\"idCSV\", data_type=DataType.TEXT, skip_vectorization=True),\n        Property(name=\"gender\", data_type=DataType.TEXT, skip_vectorization=True),\n        Property(name=\"age\", data_type=DataType.INT, skip_vectorization=True),\n        Property(name=\"topic\", data_type=DataType.TEXT, skip_vectorization=True),\n        Property(name=\"sign\", data_type=DataType.TEXT, skip_vectorization=True),\n        Property(name=\"date\", data_type=DataType.DATE, skip_vectorization=True),\n        Property(name=\"text\", data_type=DataType.TEXT_ARRAY, skip_vectorization=False),\n    ],\n)\n\n----------\n\n[DudaNogueira (2024-09-13T19:17:41.105Z)]: hi @Samuel ! Welcome to our community! \nWhat is the server version you are running?\nBoth codes gave me the same expected error. \nThe problem here is that it must have at least one text element other than the array.\nBecause you have defined to not vectorize the collection name, you must provide one as a property.\nIf you change the module to openai, it will raise a more detailed error:\n\nUnexpectedStatusCodeError: Collection may not have been created properly.! Unexpected status code: 422, with response body: {‘error’: [{‘message’: “module ‘text2vec-openai’: invalid properties: didn’t find a single property which is of type string or text and is not excluded from indexing. In addition the class name is excluded from vectorization as well, meaning that it cannot be used to determine the vector position. To fix this, set ‘vectorizeClassName’ to true if the class name is contextionary-valid. Alternatively add at least contextionary-valid text/string property which is not excluded from indexing”}]}.\n\nLet me know if this helps!\nTHanks!\n\n----------\n\n[Samuel (2024-09-16T09:41:02.707Z)]: I see. Removing the following line worked.\n\n\n\n Samuel:\n\n            vectorize_collection_name=False,\n\n\n\nQuestion: Why must the DB require one element other the array to work? I’m quite new at vectorDBs.\n\n----------\n\n[DudaNogueira (2024-09-16T20:53:41.811Z)]: Hi!\nWhile checking the code, it looks like this is a guardrail to make sure there is something vectorizable to pass to the embeddings service.\nHowever, it only seems to check for a text data type, but a text_array should pass that validation as well.",
    "date_created": "2024-09-13T13:44:18.848Z",
    "has_accepted_answer": false,
    "title": "Message': \"module 'text2vec-transformers': invalid combination of properties",
    "topic_id": 4147
  },
  {
    "user_id": 1212,
    "conversation": "[YP_Ajie (2024-07-17T13:56:58.426Z)]: Description\nHi all, I am new in this field and I managed to setup Llama3 + Verba  + Weaviate. However I am now stuck on error “no chunks available” when trying to chat after adding documents.  In the log, there is error message like this\n✔ Received query: tell me about owaps testing\n✘ The query retriever result in the window retriever contains an error:\n({'locations': [{'column': 6, 'line': 1}], 'message': 'get vector input from\nmodules provider: VectorFromInput was called without vectorizer', 'path':\n['Get', 'VERBA_Chunk_OLLAMA']})\nℹ No data found for VERBA_Chunk_OLLAMA.\nℹ Retrieved Context of 0 tokens\n✔ Succesfully processed query: tell me about owaps testing in 0.02s\n\nServer Setup Information\n\n\nUbuntu 20.4\n\n\nWeaviate Server Version: semitechnologies/weaviate:1.24.2\n\n\nDeployment Method: Docker Compose taken from GitHub - weaviate/Verba: Retrieval Augmented Generation (RAG) chatbot powered by Weaviate\n\n\nAny additional Information\nThese are indicators from Verba Overview (since I couldn’t put screenshot here)\n\nVERBA_Chunk_OLLAMA 4629\nVERBA_Config 1\nVERBA_Document_OLLAMA 1\ndocx Available\nopenai Available\npypdf Available\ntiktoken Available\nOLLAMA_EMBED_MODEL Available\nOLLAMA_MODEL Available\nOLLAMA_URL Available\nWEAVIATE_URL_VERBA Available\n\nHopefully all these information are sufficient to describe what is gone wrong. Thank in advance\nRegards,\nYP.Ajie\n\n----------\n\n[DudaNogueira (2024-07-18T13:48:57.941Z)]: Hi! Welcome to our community! \nDo you see success logs when importing the data?\nCan you connect to the server and make sure the data is correctly indexed?\nThanks!\n\n----------\n\n[arelyx (2024-07-18T16:27:47.125Z)]: Hello! I installed Verba for the first time last night and ran into the same issue. What worked for me is making sure I downloaded the models in Ollama prior to running Verba.\n~$ ollama run llama3\n~$ ollama run mxbai-embed-large\n\nCtrl+C and then run Verba and Ollama server as usual, see if that works.\n\n----------\n\n[DudaNogueira (2024-07-18T17:53:53.488Z)]: hi @arelyx !!\nWelcome to our community \nThanks for sharing!\n\n----------\n\n[YP_Ajie (2024-07-19T07:09:13.501Z)]: arelyx:\n\nmxbai-embed-large\n\n\nYou are my hero! Thanks bro\n\n----------\n\n[YP_Ajie (2024-07-19T07:33:49.231Z)]: what was happening is I did not define  the OLLAMA_EMBED_MODEL so the embeder falling back to OLLAMA_MODEL which is llama3 and embeding could not be done with it\n\n----------\n\n[DudaNogueira (2024-07-19T16:17:58.796Z)]: THanks for sharing, @YP_Ajie !!\nWe really appreciate it",
    "date_created": "2024-07-17T13:56:58.362Z",
    "has_accepted_answer": true,
    "title": "Verba chat got error no chunks available",
    "topic_id": 3071
  },
  {
    "user_id": 1274,
    "conversation": "[ROHAN_BALKONDEKAR (2024-08-05T10:40:37.199Z)]: I need to export vector embeddings and their associated metadata from my Weaviate instance into TSV files suitable for visualization on TensorFlow Projector. The Projector requires two files:\n\nA TSV file of vectors, where each line represents a vector.\nAn optional TSV file of metadata, where each line represents the metadata corresponding to the vectors.\n\nHere’s the format they expect:\nVectors TSV Example:\n0.1\\t0.2\\t0.5\\t0.9\n0.2\\t0.1\\t5.0\\t0.2\n0.4\\t0.1\\t7.0\\t0.8\n\nMetadata TSV Example:\nPokémon\\tSpecies\nWartortle\\tTurtle\nVenusaur\\tSeed\nCharmeleon\\tFlame\n\nI have a collection named Airarabia_faqs_en in my Weaviate instance, with the following properties:\n\ncontent (TEXT)\ncategory (TEXT)\nurl (TEXT)\ntitle (TEXT)\n\nThe vectors are generated and stored using the text2vec-openai vectorizer.\nCould someone provide a step-by-step guide or script (preferably in Python) to extract these vectors and metadata from Weaviate and save them into the required TSV format?\nI am using Weaviate locally with Docker.\n\n----------\n\n[sebawita (2024-08-05T13:45:23.924Z)]: Hi @ROHAN_BALKONDEKAR,\nWeaviate makes it easy to read all objects with vectors.\nYou need to use the iterator on your collection, like this:\ncollection = client.collections.get(\"YourCollectionName\")\n\nfor item in collection.iterator(include_vector=True):\n    print(item.properties)\n    print(item.vector)\n\nHere are the docs on how to read all data.\nFrom this, you should be able to figure out how to save it to a TSV file.",
    "date_created": "2024-08-05T10:40:37.134Z",
    "has_accepted_answer": false,
    "title": "How to Export Vectors and Metadata to TSV for TensorFlow Projector",
    "topic_id": 3265
  },
  {
    "user_id": 615,
    "conversation": "[D3x (2025-01-23T21:05:29.089Z)]: Hi team,\nWe use the text2vec_openai vectorizer with our Weaviate instance using the default OpenAI base urls directly. Over the past few months there have been multiple API outages/disruptions that have impacted our production workloads and we’d like to mitigate this going forward.\nAre there any formal recommendations from Weaviate how to address this?\n\n\nOne option we explored is that through a proxy like Litellm we can define fallback embedding endpoints (same model, different provider, such as OpenAI → Azure OpenAI) and seemlessly handle disruptions or exceptions. However, calling Litellm requires passing in a header Authorization Bearer token such as demoed here: Embeddings - /embeddings | liteLLM which the current text2vec_openai doesn’t seem to support.\n\n\nAlternatively, could Weaviate provide the ability to define a backup vectorizer internally?  Obviously it would be subject to some validation or understanding that both the primary and backup vectorizer would have to be the same exact model & configurations (dimensions, etc.).\n\n\nThe path of least resistance seem to be #1 for us. Would it be possible for Weaviate to expose a text2vec_openai configuration so we can pass in optional headers to the vectorizer?\nSecondarily, I understand from the discussion at What is the process for changing vectorizer model - #7 by DudaNogueira that the vectorizer configuration is not mutable. Assuming all we want to do is switch to a different provider but keep the exact same model (e.g. change base url and hopefully pass in optional headers as described above) is there a way we can do that without having to recreate an entire new collection from scratch and migrate?\n\n----------\n\n[DudaNogueira (2025-01-24T21:35:05.751Z)]: hi there @D3x !!\nThat’s an interesting use case \nI believe option 2 is more complex. Adding a fallback mechanism will require some code that feels more right for a proxy \nSpecially where there are tools that can do this better, like litellm.\nOne thing that I understand that could be possible, even with a “break the glass” scenario, is allowing changing the vectorizer. Something like a developer mode that you can set. and then change it\nThe main reason for the vectorization not being mutable is to serve as guardrail to avoid changing it wrongfully or expecting it would re vectorize the entire dataset. Hopefully this will be possible in the future with ASYNC Vectorization. \nI have played around with littlellm and the api key seems to be optional.\nhere is what I came up with:\nmodel_list:\n  - model_name: text-embedding-3-large\n    litellm_params:\n      model: openai/text-embedding-3-large\n      api_key: os.environ/OPENAI_API_KEY\n  - model_name: azure-text-embedding-3-large \n    litellm_params:\n      model: azure/text-embedding-my-deployment\n      api_base: os.environ/AZURE_API_BASE\n      api_key: os.environ/AZURE_AI_API_KEY\n\n#general_settings:\n#  master_key: sk-1234 # [OPTIONAL] if set all calls to proxy will require either this key or a valid generated token\n\nrouter_settings:\n  fallbacks: [{\"text-embedding-3-large\": [\"azure-text-embedding-3-large\"]}]\n\nNo I run litellm pointing to this config file\nlitellm --config config.yaml\n\nand can run curls without bearer token:\ncurl --request POST \\\n  --url http://localhost:4000/v1/embeddings \\\n  --header 'content-type: application/json' \\\n  --data '{\"model\":\"text-embedding-3-large\",\"input\":\"The quick brown fox jumps over the lazy dog\"}'\n\nAlso, if you want to set a bearer token to protect your endpoint, you can set it as the openai token on client instantiation, like so:\nopenai_key = \"sk-1234\" # use the same one defined in litellm\n\nheaders = {\n    \"X-OpenAI-Api-Key\": openai_key,\n}\n\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=weaviate_url,                       # `weaviate_url`: your Weaviate URL\n    auth_credentials=Auth.api_key(weaviate_key),      # `weaviate_key`: your Weaviate API key\n    headers=headers\n)\n\nThat, coupled with pointing your collection vectorizer to litellm, will make Weaviate send sk-1234 to litellm just like it would send to openai.\nLet me know if that helps!\n\n----------\n\n[D3x (2025-01-27T06:38:34.355Z)]: Thanks @DudaNogueira for the details!\nThe part that I was missing was that the X-OpenAI-Api-Key header passed into Weaviate would ultimately be passed through the text2vec_openai vectorizer as an Authorization Bearer token to whatever base_url we set. It was a little unintuitive but should work for our use case. I’ll continue down this path and hope that this will keep our services up when OpenAI APIs (inevitably) goes down again.\nAnd just to confirm, as of now there is no way to update an existing collection with a vectorizer base_url change without having to migrate to a brand new collection + updated vectorizer configuration correct?\n\n----------\n\n[DudaNogueira (2025-01-27T13:14:34.915Z)]: hi @D3x !!\nThat’s right. You cannot change the vectorizer conf of a collection.\nHowever, you do can overwrite that at query time passing as a header: X-Openai-Baseurl\nAnd thank you: as I have just found out that this is not documented \nThanks!!!\n\n----------\n\n[D3x (2025-01-28T00:18:52.159Z)]: Amazing, thanks for X-Openai-Baseurl! I was dreading having to migrate an entire collection",
    "date_created": "2025-01-23T21:05:29.001Z",
    "has_accepted_answer": true,
    "title": "Text2vec_openai redundancy via multiple providers?",
    "topic_id": 9873
  },
  {
    "user_id": 3244,
    "conversation": "[Inkyu_Kim (2025-01-20T23:06:16.643Z)]: Description\nI am using near_vector() for similarity search and I am getting the following error:\nFile “C:\\Users\\ikim1\\RAG-blog\\lib\\site-packages\\weaviate\\validator.py”, line 61, in \nreturn all(isinstance(val, args[0]) for val in value)\nTypeError: isinstance() arg 2 must be a type or tuple of types\nServer Setup Information\n\nWeaviate Server Version: Using Local Docker hosting. image: cr.weaviate.io/semitechnologies/weaviate:1.28.3\nDeployment Method:  Docker (straight from the Weaviate website on how to Create Local Docker instance)\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Sorry… I am a software newbie…Not sure what these mean. Python 3.11?\nMultitenancy?:\n\nAny additional Information\nI have used the following method to embed the text to float list:\nembedding_model = HuggingFaceEmbeddings(model_name = ‘sentence-transformers/all-mpnet-base-v2’)\nembedded_chunk = embedding_model.embed_documents(chunk)[0]\nchunks_with_metadata_list.append(wvc.data.DataObject(\nproperties = chunk_metadata,\nvector = embedded_chunk\n))\nWhere the chunks are made with text_splitter from LangChain.\nThis is the full code:\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_huggingface import HuggingFaceEmbeddings\nimport weaviate\nimport weaviate.classes as wvc\nimport weaviate.classes.config as wc\nimport json\nimport os\n\nclient = weaviate.connect_to_local()\n# check if the client is alive\nassert client.is_live()\n\n# delete the existing schema + create schema \nclient.collections.delete(\"AutomotiveFinance\")\nclient.collections.create(\n    name = 'AutomotiveFinance',\n    properties=[\n        wc.Property(name = 'page1', data_type = wc.DataType.INT),\n        wc.Property(name = 'page2', data_type = wc.DataType.INT),\n        wc.Property(name = 'company', data_type = wc.DataType.TEXT),\n        wc.Property(name = 'doc_type', data_type = wc.DataType.TEXT),\n        wc.Property(name = 'raw_text', data_type = wc.DataType.TEXT),\n    ], \n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n)\nauto_finance = client.collections.get(\"AutomotiveFinance\")\n\n# get the path of each json file\njson_top_file_path = r'C:\\Users\\ikim1\\OneDrive\\Desktop\\RAG file'\njson_file_path = []\nfor file in os.listdir(json_top_file_path):\n    if file.endswith('.json'):\n        file_path = os.path.join(json_top_file_path, file)\n        json_file_path.append(file_path)\n\n# Initialize the text splitter +  embedding model\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=500,  # Maximum size of each chunk\n    chunk_overlap=100  # Overlap between consecutive chunks\n)\nembedding_model = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-mpnet-base-v2')\n# for each file path of json get the chunks. \n\nchunks_with_metadata_list = []\nfor one_json_path in json_file_path: \n    # each json had the following structure\n    # json['pages'], json['file_path'], json['company'] json['doc_type']\n    # in json['pages'], there is list of each page as element \n    \n    # open the json file \n    with open(one_json_path, 'r') as file: \n        json_data = json.load(file)\n        pages = json_data['pages']\n        company = json_data['company']\n        doc_type = json_data['doc_type']\n        \n        # make the entire string from the pages\n        # make sure to insert the page numbers as well. \n        old_page_num = 0; old_md = ''; old_raw_txt = ''\n        json_string = '' \n        for i, page in enumerate(pages): \n            md = page['md']\n            raw_txt = page['text']\n            page_num = page['page']\n            print(i)\n            # if this is the second one, then start the chunking process\n            if i > 0: \n                old_combined_str = \"THIS IS PAGE \" + str(old_page_num) + '\\n' + old_md + '\\n' + old_raw_txt\n                new_combined_str = \"THIS IS PAGE \" + str(page_num) + '\\n' + md + '\\n' + raw_txt\n                combined_str = new_combined_str + '\\n' + old_combined_str\n                # chunk the combined_str using recursive splittin,g but inject the metadata. \n                chunks = text_splitter.split_text(combined_str)\n                # inject the metadata into the chunks\n                for chunk in chunks: \n                    # embed the chunk : output is already a list. so no need for conversion for Weaviate\n                    embedded_chunk = embedding_model.embed_documents(chunk)[0]\n                    chunk_metadata = {\n                        \"page1\" : old_page_num, \"page2\" : page_num, \n                        \"company\" : company, \"doc_type\" : doc_type, \n                        'raw_text' : chunk\n                        }\n                    chunks_with_metadata_list.append(wvc.data.DataObject(\n                        properties = chunk_metadata,\n                        vector = embedded_chunk\n                    ))\n            # cache the previous one\n            old_md = md\n            old_raw_txt = raw_txt\n            old_page_num = page_num\n            \nauto_finance.data.insert_many(chunks_with_metadata_list)\n\nquery_vector = embedding_model.embed_documents(\"what is Honda Cash and cash equivalents?\")[0]\nimport time \ntime.sleep(2)\nresponse = auto_finance.query.near_vector(\n    near_vector = query_vector,\n    limit = 4  \n)\n\nfor o in response.objects:\n    print(o.properties['raw_text'])\n    print(o.properties['company'])\n    print(o.properties['page1'])\n    print(o.properties['page2'])\nclient.close()\n\nThen I followed this section to do near_vector() search:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBring your own vectors | Weaviate\n\n  Weaviate is a vector database. Vector databases store data objects and vectors that represent those objects. The vector representation is also called an \"embedding.\"\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nfrom weaviate.classes.query import MetadataQuery\nimport weaviate\nfrom langchain_huggingface import HuggingFaceEmbeddings\nimport numpy as np\nimport base64\n\nembedding_model = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-mpnet-base-v2')\nclient = weaviate.connect_to_local()\nauto_finance= client.collections.get(\"AutomotiveFinance\")\n\nquery_vector = embedding_model.embed_documents(\"what is Honda Cash and cash equivalents?\")[0]\n# I checked query_Vector is list of floats\n\nimport time \ntime.sleep(2)\nresponse = auto_finance.query.near_vector(\n    near_vector = query_vector,\n    limit = 4  \n)\n\nfor o in response.objects:\n    print(o.properties['raw_text'])\n    print(o.properties['company'])\n    print(o.properties['page1'])\n    print(o.properties['page2'])\nclient.close()\n\nBut I am getting the following error:\nTraceback (most recent call last):\n  File \"c:/Users/ikim1/OneDrive/Desktop/RAG file/SimSearch.py\", line 16, in <module>\n    response = auto_finance.query.near_vector(\n  File \"C:\\Users\\ikim1\\RAG-blog\\lib\\site-packages\\weaviate\\syncify.py\", line 23, in sync_method\n    return _EventLoopSingleton.get_instance().run_until_complete(\n  File \"C:\\Users\\ikim1\\RAG-blog\\lib\\site-packages\\weaviate\\event_loop.py\", line 40, in run_until_complete       \n    return fut.result()\n  File \"C:\\Users\\ikim1\\AppData\\Local\\Programs\\Python38\\lib\\concurrent\\futures\\_base.py\", line 439, in result    \n    return self.__get_result()\n  File \"C:\\Users\\ikim1\\AppData\\Local\\Programs\\Python38\\lib\\concurrent\\futures\\_base.py\", line 388, in __get_result\n    raise self._exception\n  File \"C:\\Users\\ikim1\\RAG-blog\\lib\\site-packages\\weaviate\\collections\\queries\\near_vector\\query.py\", line 92, in near_vector\n    res = await self._query.near_vector(\n  File \"C:\\Users\\ikim1\\RAG-blog\\lib\\site-packages\\weaviate\\collections\\grpc\\query.py\", line 361, in near_vector \n    _validate_input(\n  File \"C:\\Users\\ikim1\\RAG-blog\\lib\\site-packages\\weaviate\\validator.py\", line 31, in _validate_input\n    if not any(_is_valid(exp, validate.value) for exp in validate.expected):\n  File \"C:\\Users\\ikim1\\RAG-blog\\lib\\site-packages\\weaviate\\validator.py\", line 31, in <genexpr>\n    if not any(_is_valid(exp, validate.value) for exp in validate.expected):\n  File \"C:\\Users\\ikim1\\RAG-blog\\lib\\site-packages\\weaviate\\validator.py\", line 61, in _is_valid\n    return all(isinstance(val, args[0]) for val in value)\n  File \"C:\\Users\\ikim1\\RAG-blog\\lib\\site-packages\\weaviate\\validator.py\", line 61, in <genexpr>\n    return all(isinstance(val, args[0]) for val in value)\nTypeError: isinstance() arg 2 must be a type or tuple of types\n\nI think i followed every steps - if not. please let me know and I can test them out. But from what I have seen, args[0] is outputting  ~T because the “expected” is typing.List. Not really sure why it is coded like this but also please let me know Thanks!\n\n----------\n\n[Inkyu_Kim (2025-01-20T23:16:23.169Z)]: As a lazy/quick patch, I just commented out line 61 and then did “pass” and it seems to be getting the documents well… I know this is NOT the way it is supposed to be done, but in case it helps anyone.\n\n----------\n\n[DudaNogueira (2025-01-24T20:15:46.128Z)]: Hi! @Inkyu_Kim !! Welcome to our community \nI believe I have answered this same issue here:\n  \n\n      stackoverflow.com\n  \n\n  \n      \n    \n  \n\n\n  TypeError: isinstance() arg 2 must be a type or tuple of types with collections search in Weaviate\n\n\n\n  python-3.x, nlp, vector-database, rag\n\n\n\n  asked by\n  \n  \n    Inkyu Kim\n  \n  on 08:00PM - 20 Jan 25 UTC\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI was not able to reproduce it.\nFor reference, this is the minimal reproducible example:\nimport weaviate\nfrom langchain_huggingface import HuggingFaceEmbeddings\nimport weaviate.classes.config as wc\nfrom weaviate import classes as wvc\n\nclient = weaviate.connect_to_local()\nprint(f\"Client: {weaviate.__version__}, Server: {client.get_meta().get('version')}\")\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name = 'Test',\n    properties=[\n        wc.Property(name = 'text', data_type = wc.DataType.TEXT),\n    ]\n)\n\nembedding_model = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-mpnet-base-v2')\ntexts = [\n    \"A dog is a member of the genus Canis that are carnivorous mammals.\",\n    \"A cat is a member of the genus Felis that are carnivorous mammals.\",\n    \"A seagull is a member of the genus Larus that are carnivorous birds, can flap it's wings and go up im the skies\",\n]\ntext_vector = embedding_model.embed_documents(texts)\n\n# lets add our objects with their vectors\nfor i in range(len(texts)):\n    collection.data.insert(\n        properties={\"text\": texts[i]},\n        vector=text_vector[i]\n    )\n# check if we have the objects:\nprint(collection.aggregate.over_all().total_count)\n\n# we need to wait a little bit for it to index\nimport time\ntime.sleep(2)\n# now we query\nquery = \"will bark at you\"\nquery_vector = embedding_model.embed_documents(query)[0]\n#query_vector = [0.123]*768\nresult = collection.query.hybrid(\n    query = query,\n    vector = query_vector, alpha = 0.25, limit = 2,\n    return_metadata=wvc.query.MetadataQuery(score=True)\n)\nfor o in result.objects:\n    print(\n        o.metadata.score,\n        o.properties[\"text\"]\n    )\n\nLet me know if that helps!\nTHanks!",
    "date_created": "2025-01-20T23:06:16.575Z",
    "has_accepted_answer": false,
    "title": "Near_vector() input validator bug?",
    "topic_id": 9828
  },
  {
    "user_id": 778,
    "conversation": "[Mariam (2024-08-08T10:51:26.538Z)]: Description\nI’m trying to set up a Weaviate cluster consisting of 3 nodes, each running on a different server, using Docker. However, I’m encountering an issue where the nodes fail to join the cluster. The error message I’m seeing is:\ncode{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [172.18.0.2:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"172.18.0.2:8300\"],\"time\":\"2024-08-08T08:02:08Z\",\"voter\":true}{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"192.168.1.52\",\"Address\":\"172.18.0.2:8300\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-08-08T08:02:08Z\"}\n\nBelow is the docker-compose.yml file I’m using for each node:\ncodeversion: '3.7\n'services:weaviate:image: cr.weaviate.io/semitechnologies/weaviate:1.25.4\nenvironment:\n- AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true\n- ASYNC_INDEXING=true\n- PERSISTENCE_DATA_PATH=/var/lib/weaviate\n- ENABLE_MODULES=text2vec-ollama,generative-ollama\n- RAFT_JOIN=IP1:8300,IP2:8300,IP3:8300\n- CLUSTER_HOSTNAME=IP1\n- CLUSTER_GOSSIP_BIND_PORT=7100\n- CLUSTER_GOSSIP_JOIN=IP2:7100,IP3:7100\n- ports:\n- 8080:8080\n- 50051:50051\n- volumes:\n- weaviate_data1:/var/lib/weaviatenetworks:\n- weaviate-clusternetworks:weaviate-cluster:\n- driver: bridgevolumes:weaviate_data1:\n\nEach server has a unique IP address (IP1, IP2, IP3). Despite correctly setting the RAFT_JOIN and CLUSTER_GOSSIP_JOIN environment variables, the nodes aren’t able to join the cluster, and the error above persists.\nHas anyone experienced this issue before or can provide insights on how to resolve it? Any help would be greatly appreciated!\nServer Setup Information\n\nWeaviate Server Version: v1.25.4\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: python v4\nMultitenancy?:\n\n----------\n\n[DudaNogueira (2024-08-08T20:55:14.406Z)]: Hi @Mariam !!\nHave you seen this docker compose for multi node?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nDocker Compose | Weaviate - Vector Database\n\n  Weaviate supports deployment with Docker. If you use the default values, you don't need a docker-compose.yml file to run the image. To customize your instance, edit the configuration settings in the docker-compose.yml file.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nCheck here a working docker-compose.yaml.\nNote that you will have to change it for the ips, and also map the ports defined in each node, as they are not in the same network.\nAlso note: this is not the best way to run a multi node Weaviate server. For multinode deployments, we suggest Kubernetes.\nLet me know if this helps!\nThanks!\n\n----------\n\n[Mariam (2024-08-12T06:11:51.258Z)]: hi @DudaNogueira\nI am still facing issues, please see if I did anything wrong in the docker configuration.\nDescription:\nI am currently configuring a Weaviate cluster with one master node and two worker node, but I am encountering issues with node communication. Below are the details of my setup and the errors I am seeing.\nMaster Node Configuration:\nversion: ‘3.7’\nservices:\nweaviate-node-1:\ncommand:\n- --host\n- 0.0.0.0\n- --port\n- ‘8080’\n- --scheme\n- http\nimage: cr.weaviate.io/semitechnologies/weaviate:1.26.1\nports:\n- 8080:8080\n- 6060:6060\n- 50051:50051\n- 7100:7100\n- 7101:7101\n- 8300:8300\nrestart: on-failure:0\nvolumes:\n- ./data-node-1:/var/lib/weaviate\nenvironment:\nLOG_LEVEL: ‘debug’\nQUERY_DEFAULTS_LIMIT: 25\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: ‘true’\nPERSISTENCE_DATA_PATH: ‘/var/lib/weaviate’\nENABLE_MODULES: ‘text2vec-openai,text2vec-cohere,text2vec-huggingface,text2vec-ollama,generative-ollama’\nDEFAULT_VECTORIZER_MODULE: ‘none’\nCLUSTER_HOSTNAME: ‘node1’\nCLUSTER_GOSSIP_BIND_PORT: ‘7100’\nCLUSTER_DATA_BIND_PORT: ‘7101’\nRAFT_JOIN: ‘192.168.1.52:8300,192.168.1.23:8300,192.168.1.24:8300’\nRAFT_BOOTSTRAP_EXPECT: 3\nMaster Node Error Log:\n{“action”:“raft-net”,“error”:“unknown rpc type 255”,“level”:“error”,“msg”:“raft-net failed to decode incoming command”,“time”:“2024-08-10T06:37:12Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-10T06:37:21Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-10T06:37:31Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“level”:“debug”,“msg”:\" memberlist: Stream connection from=192.168.1.23:36206\",“time”:“2024-08-10T06:37:40Z”}\n{“level”:“debug”,“msg”:\" memberlist: Failed UDP ping: node2 (timeout reached)“,“time”:“2024-08-10T06:37:41Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-10T06:37:41Z”,“url”:{“Scheme”:”“,“Opaque”:”“,“User”:null,“Host”:”“,“Path”:”/metrics\",“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“level”:“info”,“msg”:\" memberlist: Suspect node2 has failed, no acks received\",“time”:“2024-08-10T06:37:41Z”}\n{“level”:“debug”,“msg”:\" memberlist: Failed UDP ping: node2 (timeout reached)“,“time”:“2024-08-10T06:37:43Z”}\n{“level”:“info”,“msg”:” memberlist: Suspect node2 has failed, no acks received\",“time”:“2024-08-10T06:37:44Z”}\n{“level”:“info”,“msg”:\" memberlist: Marking node2 as failed, suspect timeout reached (0 peer confirmations)“,“time”:“2024-08-10T06:37:45Z”}\n{“level”:“debug”,“msg”:” memberlist: Failed UDP ping: node2 (timeout reached)“,“time”:“2024-08-10T06:37:46Z”}\n{“level”:“info”,“msg”:” memberlist: Suspect node2 has failed, no acks received\",“time”:“2024-08-10T06:37:48Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-10T06:37:51Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-10T06:38:01Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-10T06:38:11Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\nWorker Node Configuration\nversion: ‘3.7’\nservices:\nweaviate-node-2:\ninit: true\ncommand:\n- --host\n- 0.0.0.0\n- --port\n- ‘8080’\n- --scheme\n- http\nimage: cr.weaviate.io/semitechnologies/weaviate:1.26.1\nports:\n- 8081:8080\n- 6061:6060\n- 50052:50051\n- 7102:7102\n- 7103:7103\n- 8300:8300\nrestart: on-failure:0\nvolumes:\n- ./data-node-2:/var/lib/weaviate\nenvironment:\nLOG_LEVEL: ‘debug’\nQUERY_DEFAULTS_LIMIT: 25\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: ‘true’\nPERSISTENCE_DATA_PATH: ‘/var/lib/weaviate’\nENABLE_MODULES: ‘text2vec-openai,text2vec-cohere,text2vec-huggingface,text2vec-ollama,generative-ollama’\nDEFAULT_VECTORIZER_MODULE: ‘none’\nCLUSTER_HOSTNAME: ‘node2’\nCLUSTER_GOSSIP_BIND_PORT: ‘7102’\nCLUSTER_DATA_BIND_PORT: ‘7103’\nCLUSTER_JOIN: ‘192.168.1.52:7100’\nRAFT_JOIN: ‘192.168.1.52:8300,192.168.1.23:8300,192.168.1.24:8300’\nRAFT_BOOTSTRAP_EXPECT: 3\nWorker Node Error Log:\n{“action”:“inverted filter2search migration”,“level”:“debug”,“msg”:“starting switching fallback mode”,“time”:“2024-08-10T06:37:42Z”}\n{“action”:“inverted filter2search migration”,“level”:“debug”,“msg”:“no missing filterable indexes, fallback mode skipped”,“time”:“2024-08-10T06:37:42Z”}\n{“docker_image_tag”:“1.26.1”,“level”:“info”,“msg”:“configured versions”,“server_version”:“1.26.1”,“time”:“2024-08-10T06:37:42Z”}\n{“action”:“grpc_startup”,“level”:“info”,“msg”:“grpc server listening at [::]:50051”,“time”:“2024-08-10T06:37:42Z”}\n{“address”:“172.20.0.2:8300”,“level”:“info”,“msg”:“current Leader”,“time”:“2024-08-10T06:37:42Z”}\n{“level”:“info”,“msg”:“starting migration from old schema”,“time”:“2024-08-10T06:37:42Z”}\n{“level”:“info”,“msg”:“legacy schema is empty, nothing to migrate”,“time”:“2024-08-10T06:37:42Z”}\n{“level”:“info”,“msg”:“migration from the old schema has been successfully completed”,“time”:“2024-08-10T06:37:42Z”}\n{“action”:“restapi_management”,“docker_image_tag”:“1.26.1”,“level”:“info”,“msg”:“Serving weaviate at http://[::]:8080”,“time”:“2024-08-10T06:37:42Z”}\n{“action”:“telemetry_push”,“level”:“info”,“msg”:“telemetry started”,“payload”:“\\u0026{MachineID:b6f038ed-5bac-4f0d-8b9e-be97ac935689 Type:INIT Version:1.26.1 NumObjects:0 OS:linux Arch:amd64 UsedModules:}”,“time”:“2024-08-10T06:37:42Z”}\n{“level”:“debug”,“msg”:\" memberlist: Failed UDP ping: node1 (timeout reached)“,“time”:“2024-08-10T06:37:43Z”}\n{“level”:“info”,“msg”:” memberlist: Suspect node1 has failed, no acks received\",“time”:“2024-08-10T06:37:45Z”}\n{“level”:“info”,“msg”:\" memberlist: Marking node1 as failed, suspect timeout reached (0 peer confirmations)“,“time”:“2024-08-10T06:37:46Z”}\n{“level”:“debug”,“msg”:” memberlist: Failed UDP ping: node1 (timeout reached)“,“time”:“2024-08-10T06:37:46Z”}\n{“level”:“info”,“msg”:” memberlist: Suspect node1 has failed, no acks received\",“time”:“2024-08-10T06:37:49Z”}\nconnectivity is available\ntelnet 192.168.1.52 8300\nTrying 192.168.1.52…\nConnected to 192.168.1.52.\nEscape character is ‘^]’.\nthis is from node 2 to node 1\n\n----------\n\n[DudaNogueira (2024-08-12T21:39:05.180Z)]: hi @Mariam !\nThere is very similar issue here:\n\n  \n    \n    \n    Weaviate Cluster Setup with Docker on Different Servers Failing General\n  \n  \n    hi!! \nCheck here a working example of a multi node running in docker: \n\nI believe you should not have the port on the RAFT_JOIN. The example uses only \nRAFT_JOIN: 'node1,node2,node3' \nLet me know if this helps. \nThanks!\n  \n\n\nPlease, let’s move this discussion there as it looks like you have the same issue.\nThanks!\n\n----------\n\n[jasper2077 (2024-12-02T02:23:27.119Z)]: Hello, I’m currently facing the same issue. Have you figured out how to solve the error?\n\n----------\n\n[DudaNogueira (2024-12-03T12:34:20.542Z)]: hi @jasper2077 !!\nThat is probably some connectivity issues between the containers.\nWhat have you tried so far?",
    "date_created": "2024-08-08T10:51:26.483Z",
    "has_accepted_answer": false,
    "title": "Issue: Weaviate Cluster Setup with Docker on Different Servers Failing",
    "topic_id": 3300
  },
  {
    "user_id": 726,
    "conversation": "[Saeed_Rezaei (2024-03-21T19:55:12.252Z)]: Hi,\nI have created a class on a Weaviate cluster using:\nclient.schema.create(class_config)\nI can see the class_config by:\nprint(client.show_class_config(class_name))\nbut when trying to see my available classes on my cluster using:\nclient.show_classes()\nit says: ‘No classes found on cluster.’. I am not sure why I cannot see it on my cluster. Would you please help me understand the root cause?\n\n----------\n\n[DudaNogueira (2024-03-21T21:21:48.163Z)]: Hi @Saeed_Rezaei,\nWelcome to our community \nDo you see any error logs when creating the collection? Can you share the code of class_config?\nAlso, any specific reason not to use the python v4 client? It improved a lot over the v3 one.\nThanks!\n\n----------\n\n[Saeed_Rezaei (2024-03-22T07:41:26.539Z)]: Thanks @DudaNogueira \nNo, I do not see any error logs. First of all I can see there have been stored several objects on my cluster. Also, when I run a vector search, I don’t get any error and I get some results with some scores, but when running the keyword search all the scores are zero. Having said that you can see my code below.\n#external files\nfrom preprocessing import FileIO\nfrom weaviate_interface import WeaviateClient, WeaviateIndexer\n\n#standards\nimport os\nimport time\nimport json\nfrom typing import List\nfrom tqdm.notebook import tqdm\n\nfrom rich import print  \n\n#load from local .env file\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n#read env vars from local .env file\napi_key = os.environ['WEAVIATE_API_KEY']\nurl = os.environ['WEAVIATE_ENDPOINT']\n\n#instantiate client\nclient = WeaviateClient(api_key, url)\n\n#check if WCS instance is live and ready\nclient.is_live(), client.is_ready()\n\ndata_path = './data/Books-minilmL6-256.parquet'\n\ndata = FileIO().load_parquet(data_path)\n\nfrom class_templates import book_class_properties\nprint(book_class_properties)\n\n#create your own class name or use the example from above\nclass_name = 'Books_minilm_256_6'\n\n#Review Indexing Body\nclass_config = {'classes': [\n\n                      {\"class\": class_name,\n\n                       \"description\": \"Books on Parenting\",\n\n                       \"vectorIndexType\": \"hnsw\",\n\n                       # Vector index specific settings\n                       \"vectorIndexConfig\": {\n\n                            \"ef\": 64,\n                            \"efConstruction\": 128,\n                            \"maxConnections\": 32,\n                                            },\n\n                       \"vectorizer\": \"none\",\n\n                       # pre-defined property mappings\n                       \"properties\": book_class_properties }\n                      ]\n               }\n\nclient.schema.create(class_config)\n\n----------\n\n[Saeed_Rezaei (2024-03-24T05:06:29.771Z)]: Also when running the following code for indexing the data:\nindexer = WeaviateIndexer(client, batch_size=200, num_workers=2)\nindexer.batch_index_data(data, class_name)\n\nI get No classes found on cluster. However, when I go to dashboard, I can see objects have been created on my cluster, and the vector search seems to work perfectly fine.\n\n----------\n\n[DudaNogueira (2024-03-25T12:56:37.647Z)]: Are you using any tool to connect to Weaviate?\nAlso, have you tried the python v4?\nWhat is the server version you are running?\nAnd finally, can you create an end to end code, with some sample data? Otherwise it gets hard to reproduce as there are some external code.\n\n----------\n\n[Saeed_Rezaei (2024-12-28T19:55:44.416Z)]: Hi @DudaNogueira ,\nI was using the following piece of code using python v4:\n#read env vars from local .env file\napi_key = os.environ['WEAVIATE_API_KEY']\nurl = os.environ['WEAVIATE_ENDPOINT']\nmodel_path = 'sentence-transformers/all-MiniLM-L6-v2'\n\n#instantiate client\nclient = WeaviateWCS(endpoint=url, api_key=api_key, model_name_or_path=model_path)\n\n#example of using the private _client attribute\nclient._client.is_connected()\n\nAnd it was working until yesterday, but today when I run that code I get the following error:\n---------------------------------------------------------------------------\nConnectError                              Traceback (most recent call last)\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpx/_transports/default.py:69, in map_httpcore_exceptions()\n     68 try:\n---> 69     yield\n     70 except Exception as exc:\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpx/_transports/default.py:233, in HTTPTransport.handle_request(self, request)\n    232 with map_httpcore_exceptions():\n--> 233     resp = self._pool.handle_request(req)\n    235 assert isinstance(resp.stream, typing.Iterable)\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216, in ConnectionPool.handle_request(self, request)\n    215     self._close_connections(closing)\n--> 216     raise exc from None\n    218 # Return the response. Note that in this case we still have to manage\n    219 # the point at which the response is closed.\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196, in ConnectionPool.handle_request(self, request)\n    194 try:\n    195     # Send the request on the assigned connection.\n--> 196     response = connection.handle_request(\n    197         pool_request.request\n    198     )\n    199 except ConnectionNotAvailable:\n    200     # In some cases a connection may initially be available to\n    201     # handle a request, but then become unavailable.\n    202     #\n    203     # In this case we clear the connection and try again.\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpcore/_sync/connection.py:99, in HTTPConnection.handle_request(self, request)\n     98     self._connect_failed = True\n---> 99     raise exc\n    101 return self._connection.handle_request(request)\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpcore/_sync/connection.py:76, in HTTPConnection.handle_request(self, request)\n     75 if self._connection is None:\n---> 76     stream = self._connect(request)\n     78     ssl_object = stream.get_extra_info(\"ssl_object\")\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpcore/_sync/connection.py:154, in HTTPConnection._connect(self, request)\n    153 with Trace(\"start_tls\", logger, request, kwargs) as trace:\n--> 154     stream = stream.start_tls(**kwargs)\n    155     trace.return_value = stream\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpcore/_backends/sync.py:152, in SyncStream.start_tls(self, ssl_context, server_hostname, timeout)\n    148 exc_map: ExceptionMapping = {\n    149     socket.timeout: ConnectTimeout,\n    150     OSError: ConnectError,\n    151 }\n--> 152 with map_exceptions(exc_map):\n    153     try:\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/contextlib.py:153, in _GeneratorContextManager.__exit__(self, typ, value, traceback)\n    152 try:\n--> 153     self.gen.throw(typ, value, traceback)\n    154 except StopIteration as exc:\n    155     # Suppress StopIteration *unless* it's the same exception that\n    156     # was passed to throw().  This prevents a StopIteration\n    157     # raised inside the \"with\" statement from being suppressed.\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpcore/_exceptions.py:14, in map_exceptions(map)\n     13     if isinstance(exc, from_exc):\n---> 14         raise to_exc(exc) from exc\n     15 raise\n\nConnectError: [Errno 54] Connection reset by peer\n\nThe above exception was the direct cause of the following exception:\n\nConnectError                              Traceback (most recent call last)\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/connect/v4.py:429, in _Connection.__send(self, method, url, error_msg, status_codes, weaviate_object, params)\n    422 req = self._client.build_request(\n    423     method,\n    424     url,\n   (...)\n    427     headers=self.__get_latest_headers(),\n    428 )\n--> 429 res = self._client.send(req)\n    430 if status_codes is not None and res.status_code not in status_codes.ok:\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpx/_client.py:914, in Client.send(self, request, stream, auth, follow_redirects)\n    912 auth = self._build_request_auth(request, auth)\n--> 914 response = self._send_handling_auth(\n    915     request,\n    916     auth=auth,\n    917     follow_redirects=follow_redirects,\n    918     history=[],\n    919 )\n    920 try:\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpx/_client.py:942, in Client._send_handling_auth(self, request, auth, follow_redirects, history)\n    941 while True:\n--> 942     response = self._send_handling_redirects(\n    943         request,\n    944         follow_redirects=follow_redirects,\n    945         history=history,\n    946     )\n    947     try:\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpx/_client.py:979, in Client._send_handling_redirects(self, request, follow_redirects, history)\n    977     hook(request)\n--> 979 response = self._send_single_request(request)\n    980 try:\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpx/_client.py:1015, in Client._send_single_request(self, request)\n   1014 with request_context(request=request):\n-> 1015     response = transport.handle_request(request)\n   1017 assert isinstance(response.stream, SyncByteStream)\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpx/_transports/default.py:232, in HTTPTransport.handle_request(self, request)\n    220 req = httpcore.Request(\n    221     method=request.method,\n    222     url=httpcore.URL(\n   (...)\n    230     extensions=request.extensions,\n    231 )\n--> 232 with map_httpcore_exceptions():\n    233     resp = self._pool.handle_request(req)\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/contextlib.py:153, in _GeneratorContextManager.__exit__(self, typ, value, traceback)\n    152 try:\n--> 153     self.gen.throw(typ, value, traceback)\n    154 except StopIteration as exc:\n    155     # Suppress StopIteration *unless* it's the same exception that\n    156     # was passed to throw().  This prevents a StopIteration\n    157     # raised inside the \"with\" statement from being suppressed.\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/httpx/_transports/default.py:86, in map_httpcore_exceptions()\n     85 message = str(exc)\n---> 86 raise mapped_exc(message) from exc\n\nConnectError: [Errno 54] Connection reset by peer\n\nThe above exception was the direct cause of the following exception:\n\nWeaviateConnectionError                   Traceback (most recent call last)\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/connect/v4.py:141, in _Connection.connect(self, skip_init_checks)\n    140 try:\n--> 141     self._weaviate_version = _ServerVersion.from_string(self.get_meta()[\"version\"])\n    142 except (WeaviateConnectionError, ReadError, RemoteProtocolError) as e:\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/connect/v4.py:578, in _Connection.get_meta(self)\n    575 \"\"\"\n    576 Returns the meta endpoint.\n    577 \"\"\"\n--> 578 response = self.get(path=\"/meta\")\n    579 res = _decode_json_response_dict(response, \"Meta endpoint\")\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/connect/v4.py:541, in _Connection.get(self, path, params, error_msg, status_codes)\n    539 request_url = self.url + self._api_version_path + path\n--> 541 return self.__send(\n    542     \"GET\", url=request_url, params=params, error_msg=error_msg, status_codes=status_codes\n    543 )\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/connect/v4.py:436, in _Connection.__send(self, method, url, error_msg, status_codes, weaviate_object, params)\n    435 except ConnectError as conn_err:\n--> 436     raise WeaviateConnectionError(error_msg) from conn_err\n\nWeaviateConnectionError: Connection to Weaviate failed. \n\nThe above exception was the direct cause of the following exception:\n\nWeaviateStartUpError                      Traceback (most recent call last)\nCell In[2], line 7\n      4 model_path = 'sentence-transformers/all-MiniLM-L6-v2'\n      6 #instantiate client\n----> 7 client = WeaviateWCS(endpoint=url, api_key=api_key, model_name_or_path=model_path)\n      9 #example of using the private _client attribute\n     10 client._client.is_connected()\n\nFile ~/Documents/ML_Courses/corise/advanced_rag2/advanced-rag/notebooks/../src/database/weaviate_interface_v4.py:53, in WeaviateWCS.__init__(self, endpoint, api_key, model_name_or_path, embedded, openai_api_key, skip_init_checks, **kwargs)\n     51 else: \n     52     auth_config = AuthApiKey(api_key=api_key) \n---> 53     self._client = weaviate.connect_to_wcs(cluster_url=endpoint, \n     54                                            auth_credentials=auth_config, \n     55                                            skip_init_checks=skip_init_checks)   \n     56 self.model_name_or_path = model_name_or_path\n     57 self._openai_model = False\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/connect/helpers.py:85, in connect_to_wcs(cluster_url, auth_credentials, headers, additional_config, skip_init_checks)\n     73     grpc_host = f\"grpc-{cluster_url}\"\n     75 client = WeaviateClient(\n     76     connection_params=ConnectionParams(\n     77         http=ProtocolParams(host=cluster_url, port=443, secure=True),\n   (...)\n     83     skip_init_checks=skip_init_checks,\n     84 )\n---> 85 return __connect(client)\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/connect/helpers.py:345, in __connect(client)\n    343 except Exception as e:\n    344     client.close()\n--> 345     raise e\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/connect/helpers.py:341, in __connect(client)\n    339 def __connect(client: WeaviateClient) -> WeaviateClient:\n    340     try:\n--> 341         client.connect()\n    342         return client\n    343     except Exception as e:\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/client.py:282, in WeaviateClient.connect(self)\n    280 if self._connection.is_connected():\n    281     return\n--> 282 self._connection.connect(self.__skip_init_checks)\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/connect/v4.py:655, in ConnectionV4.connect(self, skip_init_checks)\n    654 def connect(self, skip_init_checks: bool) -> None:\n--> 655     super().connect(skip_init_checks)\n    656     # create GRPC channel. If Weaviate does not support GRPC then error now.\n    657     self._grpc_channel = self._connection_params._grpc_channel(\n    658         async_channel=False, proxies=self._proxies\n    659     )\n\nFile ~/miniconda3/envs/advanced_rag/lib/python3.10/site-packages/weaviate/connect/v4.py:143, in _Connection.connect(self, skip_init_checks)\n    141     self._weaviate_version = _ServerVersion.from_string(self.get_meta()[\"version\"])\n    142 except (WeaviateConnectionError, ReadError, RemoteProtocolError) as e:\n--> 143     raise WeaviateStartUpError(f\"Could not connect to Weaviate:{e}.\") from e\n    145 if not skip_init_checks:\n    146     try:\n\nWeaviateStartUpError: Could not connect to Weaviate:Connection to Weaviate failed. .\n\nDo you have any idea about it?\n\n----------\n\n[DudaNogueira (2024-12-29T13:59:20.425Z)]: hi @Saeed_Rezaei !!\nIt seems the server is down, so the client is not connected.\nIf that is a server hosted in our cloud, please, open a support ticket from:\n  \n\n      console.weaviate.cloud\n  \n\n  \n    \n\nWeaviate Cloud\n\n  Weaviate Cloud\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIf you are hosting this cluster yourself, do you have any logs from the server?\nThanks!\n\n----------\n\n[Saeed_Rezaei (2024-12-29T19:35:21.615Z)]: Yes, apparently the server was down, as it worked late night last night.\nThanks @DudaNogueira !\n\n----------\n\n[DudaNogueira (2024-12-29T19:36:29.181Z)]: Ok. Just to confirm, is it back online?\nLet me know if you need any help!\nThanks!\n\n----------\n\n[Saeed_Rezaei (2024-12-29T20:03:51.393Z)]: Yes, it is back online now.\n\n----------\n\n[Saeed_Rezaei (2024-12-29T20:04:13.361Z)]: Just to know what is the expected availability?",
    "date_created": "2024-03-21T19:55:12.177Z",
    "has_accepted_answer": true,
    "title": "I cannot see my created class name",
    "topic_id": 1789
  },
  {
    "user_id": 3587,
    "conversation": "[Oasis (2025-03-01T14:08:47.337Z)]: Hi,\nI can not find any information of the exact return format of collection.batch.failed_objects. I need to make sure that my application handles this error correctly and retries failed objects, but without knowing the exact format of the returned objects I can not do that. Can anyone help me out?\nThank you in advance!\n\n----------\n\n[DudaNogueira (2025-03-01T18:56:59.844Z)]: hi @Oasis !!\nWelcome to our community \nYou can provoke that error, like so:\ncollection = client.collections.delete(\"Test\")\nclient.collections.create(\"Test\")\n\nwith client.batch.dynamic() as batch:\n    batch.add_object(\n        collection=\"Test\",\n        properties={\"text\": \"object1\"},\n        vector=[1,2]\n    )\n    batch.add_object(\n        collection=\"Test\",\n        properties={\"text\": \"object2\"}, \n        vector=[1,2,3]\n    )\n\nif client.batch.failed_objects:\n    print(f\"Found {len(client.batch.failed_objects)} failed objects\" )\n    print(client.batch.failed_objects)\n\nthis will be the output:\n\nFound 1 failed objects\n[ErrorObject(message=‘inconsistent vector lengths: 3 != 2’, object_=BatchObject(collection=‘Test’, properties={‘text’: ‘object1’}, references=None, uuid=‘378e10c3-e63a-44ab-bcaf-e41792e69b3c’, vector=[1, 2], tenant=None, index=0, retry_count=0), original_uuid=‘378e10c3-e63a-44ab-bcaf-e41792e69b3c’)]\n\nBy the way, check out this awesome recipe on batch ingestion retry:\n\n  \n      \n\n      github.com\n  \n\n  \n    recipes/weaviate-features/batch/ingest-retry at main · weaviate/recipes\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!\nTHanks!\n\n----------\n\n[Dirk (2025-03-03T08:29:57.036Z)]: Hey, all of our output is typed and will be stable.\nYou can import the definitions of the returned type here:\nfrom weaviate.outputs.batch import ErrorObject\n\ncollection.batch.failed_objects returns List[ErrorObject]",
    "date_created": "2025-03-01T14:08:47.289Z",
    "has_accepted_answer": true,
    "title": "Return format collection.batch.failed_objects",
    "topic_id": 10616
  },
  {
    "user_id": 1330,
    "conversation": "[rich_tweed (2024-08-21T20:11:21.650Z)]: Two questions.\n\n\nI have a list of IDs, and I want the most efficient way of checking which of those IDs exist in the database. I don’t need any information about the objects themselves.\nIs using the HEAD/objects/{className}/{id} endpoint the most efficient way to check which of them exist in the database, or is there a better method?\n(Weaviate - Vector Database)\n\n\nCan the Go client make this request, does it need to be a direct http call? I couldn’t find information on which of the RESTful API end-points were available on the Go client.\n\n----------\n\n[Mohamed_Shahin (2024-08-22T10:59:58.727Z)]: Hello @rich_tweed,\nWelcome to our community! It’s a pleasure to have you with us, and we’re looking forward to helping you.\nI see you’re trying to find the best way to check the existence of an ID for an object in Weaviate DB.\nYou can efficiently check for IDs either by making a HEAD API request or using clients like the GO client. Here’s a detailed explanation in our documentation\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nRead objects | Weaviate - Vector Database\n\n  Instead of querying your database, you can use an ID to retrieve individual objects.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI hope this helps. Have a lovely week!",
    "date_created": "2024-08-21T20:11:21.602Z",
    "has_accepted_answer": false,
    "title": "Questions about HEAD /objects/{className}/{id}",
    "topic_id": 3425
  },
  {
    "user_id": 1623,
    "conversation": "[Jurie_Oberholzer (2024-10-02T05:23:11.641Z)]: Good morning, I hope you can maybe assist me witht he following issue.\nI have a kubernetes cluster with weaviate running on it as setup as per the documentation on the site using minikube.\nI can see that it’s running when I minikube tunnel as I’m able to view it in the browser on 127.0.0.1:80\nI’m also able to curl that location that returns a successful status of 200.\nMy issue is when I try and connect from our python application on my local machine to the local kubernetes cluster it’s not able to connect to weaviate even though above mentioned it worked.\nMy client is as follows (Note i’ve tried on both port 8080 and 80)\nclient = weaviate.connect_to_custom(\n            http_host=\"localhost\",\n            http_port=\"8080\", or 80\n            http_secure=False,\n            grpc_host=\"localhost\",\n            grpc_port=\"50051\",\n            grpc_secure=False,\n        )\n\nSo when I try and run it locally the following error occurs\n{\"errorMessage\": \"An error occurred while processing the file: Failed to initialize Weaviate client: Meta endpoint! Unexpected status code: 404, with response body: None.\", \"errorType\": \"RuntimeError\", \"requestId\": \"82da9ab1-06c3-4e19-beb9-62efb0e72205\"\n\nAny insight into this matter would be greatly appreciated\n\n----------\n\n[DudaNogueira (2024-10-02T07:35:01.427Z)]: hi @Jurie_Oberholzer !!\nWelcome to our community! \nAre you using our official helm chart for that?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nKubernetes | Weaviate\n\n  For a tutorial on how to use minikube to deploy Weaviate on Kubernetes, see the Weaviate Academy course, Weaviate on Kubernetes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIf that’s the case, can you share your values.yml?\nAlso, can you paste the entire stack trace?\nThanks!\n\n----------\n\n[Jurie_Oberholzer (2024-10-02T07:48:54.860Z)]: Thank you very much.\nYes I’m using the official helm chart for that using the values.yml that was generated.\nThe following is my yaml file\nAnd my stacktrace is\nSTART RequestId: d5fe8460-82c9-482e-a2cf-fc59a8838c60 Version: $LATEST\n2024-10-02 07:06:11.079 | INFO     | shared.service.process_file:process_files:14 - Starting process_files for PDF: Expendo Android QRG_SBSA_All Modes_20220318 2.pdf in bucket: mervin-pdf-bucket.\n2024-10-02 07:06:11.079 | INFO     | shared.helper.data.extract_text:extract_text_from_pdfs:9 - Attempting to parse file from S3.\n/var/lang/lib/python3.12/site-packages/botocore/auth.py:419: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  datetime_now = datetime.datetime.utcnow()\n2024-10-02 07:06:12.893 | INFO     | shared.helper.data.extract_text:extract_text_from_pdfs:15 - File loaded successfully.\n/var/lang/lib/python3.12/site-packages/tika/tika.py:667: ResourceWarning: unclosed file <_io.TextIOWrapper name='/dev/null' mode='w' encoding='utf-8'>\n  _ = Popen(java_path, stdout=open(os.devnull, \"w\"), stderr=open(os.devnull, \"w\"))\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n2024-10-02 07:06:12,998 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n[WARNING]       2024-10-02T07:06:12.998Z        6af15f31-d000-459b-b556-5f94d1f6530b    Failed to see startup log message; retrying...\n/var/lang/lib/python3.12/site-packages/tika/tika.py:599: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/tika-server.log' mode='w' encoding='utf-8'>\n  status = startServer(jarPath, TikaJava, TikaJavaArgs, serverHost, port, classpath, config_path)\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n/var/lang/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 18 is still running\n  _warn(\"subprocess %s is still running\" % self.pid,\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n2024-10-02 07:06:18.746 | INFO     | shared.helper.data.extract_text:extract_text_from_pdfs:19 - File parsed successfully.\n2024-10-02 07:06:18.775 | ERROR    | shared.helper.database.get_client:get_client:21 - Failed to initialize Weaviate client: Meta endpoint! Unexpected status code: 404, with response body: None.\n2024-10-02 07:06:18.775 | ERROR    | shared.service.process_file:process_files:41 - An error occurred during processing of Expendo Android QRG_SBSA_All Modes_20220318 2.pdf: Failed to initialize Weaviate client: Meta endpoint! Unexpected status code: 404, with response body: None.\n2024-10-02 07:06:18.776 | ERROR    | create_db_handler:handler:41 - Error: An error occurred while processing the file: Failed to initialize Weaviate client: Meta endpoint! Unexpected status code: 404, with response body: None.\nLAMBDA_WARNING: Unhandled exception. The most likely cause is an issue in the function code. However, in rare cases, a Lambda runtime update can cause unexpected function behavior. For functions using managed runtimes, runtime updates can be triggered by a function change, or can be applied automatically. To determine if the runtime has been updated, check the runtime version in the INIT_START log entry. If this error correlates with a change in the runtime version, you may be able to mitigate this error by temporarily rolling back to the previous runtime version. For more information, see https://docs.aws.amazon.com/lambda/latest/dg/runtimes-update.html\n[ERROR] RuntimeError: An error occurred while processing the file: Failed to initialize Weaviate client: Meta endpoint! Unexpected status code: 404, with response body: None.\nTraceback (most recent call last):\n  File \"/var/task/create_db_handler.py\", line 42, in handler\n    raise e\n  File \"/var/task/create_db_handler.py\", line 30, in handler\n    process_files(s3_pdf_bucket, s3_pdf_key)  # Updated call)\n  File \"/var/task/shared/service/process_file.py\", line 42, in process_files\n    raise RuntimeError(f\"An error occurred while processing the file: {e}\")\nEND RequestId: 6af15f31-d000-459b-b556-5f94d1f6530b\nREPORT RequestId: 6af15f31-d000-459b-b556-5f94d1f6530b  Init Duration: 0.29 ms  Duration: 8487.79 ms    Billed Duration: 8488 ms        Memory Size: 2048 MB  Max Memory Used: 2048 MB\n{\"errorMessage\": \"An error occurred while processing the file: Failed to initialize Weaviate client: Meta endpoint! Unexpected status code: 404, with response body: None.\", \"errorType\": \"RuntimeError\", \"requestId\": \"6af15f31-d000-459b-b556-5f94d1f6530b\", \"stackTrace\": [\"  File \\\"/var/task/create_db_handler.py\\\", line 42, in handler\\n    raise e\\n\", \"  File \\\"/var/task/create_db_handler.py\\\", line 30, in handler\\n    process_files(s3_pdf_bucket, s3_pdf_key)  # Updated call)\\n\", \"  File \\\"/var/task/shared/service/process_file.py\\\", line 42, in process_files\\n    raise RuntimeError(f\\\"An error occurred while processing the file: {e}\\\")\\n\"]}\n[ERROR] [1727852778818] LAMBDA_RUNTIME Failed to get next invocation. No Response from endpoint\n\nThanks for taking the time to respond\n\n----------\n\n[Jurie_Oberholzer (2024-10-21T12:33:14.248Z)]: Hi @DudaNogueira ,\nI would just like to follow up with the above issue.\nKind regards,\nJurie\n\n----------\n\n[Christian_Hooper (2024-10-21T14:59:17.146Z)]: @DudaNogueira any updates?\n\n----------\n\n[DudaNogueira (2024-10-21T21:22:53.127Z)]: Hi!\nThis issue comes with not exposing your Weaviate server correctly.\nHere is culprit:\n\ncreate_db_handler:handler:41 - Error: An error occurred while processing the file: Failed to initialize Weaviate client: Meta endpoint! Unexpected status code: 404, with response body: None.\n\nYou need to make sure that you expose the REST port AND GRPC port correctly.\nThose same ports/hosts need to be passed to Weaviate Client on it’s initialization.\nCan you try forwarding the ports to your local machine and connecting using those ports?\n\n----------\n\n[Jurie_Oberholzer (2024-10-22T12:24:11.286Z)]: I’ve done the port forwarding and minikube tunnel.\nI’m able to view it when I go into my browser (http://127.0.0.1/v1) as well as I’m able to curl it and I receice a status of 200.\nMight the issue be trying to run it locally using sam build with the lambda.\nWe’ve used local lambda testing Chroma / Pinecone and it seemed to work with it.\n\n----------\n\n[DudaNogueira (2024-10-22T13:33:26.178Z)]: Once you are able t connect to the rest and GRPC - you can use GRPCurl to test - the issue should be a network one.",
    "date_created": "2024-10-02T05:23:11.590Z",
    "has_accepted_answer": false,
    "title": "Local Python app connecting to Weaviate client 4.0 within Kubernetes",
    "topic_id": 4392
  },
  {
    "user_id": 1214,
    "conversation": "[elias.gabriel (2025-01-14T22:09:44.057Z)]: Description\nI’m building a web application where certain user-triggered operations involve mutating, updating, cross-referencing etc. several objects across several collections.\nThe python client exposes all those operations as independent queries to my weaviate cluster, which means that if 1 of them fail my data is left in a broken state.\nDoes Weaviate support transactions of any form, where I can group together related queries to ensure that they either all succeed or all fail?\nIf not, are there any recommended design patterns that I can follow to try and prevent getting into bad states because of sporadic (or not) errors?\nServer Setup Information\n\nWeaviate Server Version: 1.27\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python client, latest, async\nMultitenancy?: No\n\n----------\n\n[Mohamed_Shahin (2025-01-16T09:44:29.220Z)]: Hi @elias.gabriel,\nThat’s a good question. Currently, Weaviate doesn’t support the capability to group queries into transactions natively. However, you can implement some sort of actions, retries, or logic on your client side to mitigate the risk of broken states and ensure consistency in your operations.\nBest regards,\nMohamed Shahin\nWeaviate Support\n\n----------\n\n[elias.gabriel (2025-02-14T17:23:41.223Z)]: Are there any suggested patterns here? If I have “operations” that query/mutate separate collections to achieve certain outcomes, and one of those queries ends up failing, implementing “undo” logic for every case in every operation seems crazy unsustainable.",
    "date_created": "2025-01-14T22:09:44.002Z",
    "has_accepted_answer": false,
    "title": "Transactional updates?",
    "topic_id": 9758
  },
  {
    "user_id": 2936,
    "conversation": "[Elian (2024-12-02T06:33:37.021Z)]: Using python lib weaviate-client==4.9.4 to connect to a weaviate cluster running on version 1.26.4, we can observe a memory leak at each connection.\nUsing a memory profiler and the following code to test connection :\nimport weaviate\nfrom weaviate.classes.init import AdditionalConfig, Timeout\nfrom memory_profiler import profile\n\nWEAVIATE_GRPC_HOST = \"xxx\"\nWEAVIATE_HOST = \"xxx\"\n\n@profile\ndef get_weaviate_client(weaviate_host: str, weaviate_grpc_host: str) :\n  weaviate_client = weaviate.connect_to_custom(\n      http_host=weaviate_host,\n      http_port=443,\n      http_secure=True,\n      grpc_host=weaviate_grpc_host,\n      grpc_port=443,\n      grpc_secure=True,\n    skip_init_checks=False,\n    additional_config= AdditionalConfig(\n      timeout=Timeout(init=30, query=60, insert=120)\n    )\n  )\n  weaviate_client.connect()\n  if not weaviate_client.is_ready():\n    raise RuntimeError(f\"Max retries reached: \")\n  return weaviate_client\n\n@profile\ndef test_connexion():\n    weaviate_client = get_weaviate_client(WEAVIATE_HOST, WEAVIATE_GRPC_HOST)\n    print('Client connected')\n    weaviate_client.close()\n\n    weaviate_client.connect()\n    weaviate_client.close()\n\n    weaviate_client.connect()\n    weaviate_client.close()\n\n    weaviate_client.connect()\n    weaviate_client.close()\n\n    del weaviate_client\n\n\nif __name__ == '__main__':\n    test_connexion()\n\nI can see this memory consumption :\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n     8     71.1 MiB     71.1 MiB           1   @profile\n     9                                         def get_weaviate_client(weaviate_host: str, weaviate_grpc_host: str) :\n    10     84.6 MiB     13.5 MiB           2     weaviate_client = weaviate.connect_to_custom(\n    11     71.1 MiB      0.0 MiB           1         http_host=weaviate_host,\n    12     71.1 MiB      0.0 MiB           1         http_port=443,\n    13     71.1 MiB      0.0 MiB           1         http_secure=True,\n    14     71.1 MiB      0.0 MiB           1         grpc_host=weaviate_grpc_host,\n    15     71.1 MiB      0.0 MiB           1         grpc_port=443,\n    16     71.1 MiB      0.0 MiB           1         grpc_secure=True,\n    17     71.1 MiB      0.0 MiB           1       skip_init_checks=False,\n    18     71.1 MiB      0.0 MiB           2       additional_config= AdditionalConfig(\n    19     71.1 MiB      0.0 MiB           1         timeout_=Timeout(init=30, query=60, insert=120)\n    20                                             )\n    21                                           )\n    22     84.6 MiB      0.0 MiB           1     weaviate_client.connect()\n    23     84.6 MiB      0.0 MiB           1     if not weaviate_client.is_ready():\n    24                                             raise RuntimeError(f\"Max retries reached: \")\n    25     84.6 MiB      0.0 MiB           1     return weaviate_client\n\n\nClient connected\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n    27     71.1 MiB     71.1 MiB           1   @profile\n    28                                         def test_connexion():\n    29     84.6 MiB     13.5 MiB           1       weaviate_client = get_weaviate_client(WEAVIATE_HOST, WEAVIATE_GRPC_HOST)\n    30     84.6 MiB      0.0 MiB           1       print('Client connected')\n    31     84.2 MiB     -0.4 MiB           1       weaviate_client.close()\n    32\n    33     86.3 MiB      2.1 MiB           1       weaviate_client.connect()\n    34     86.5 MiB      0.2 MiB           1       weaviate_client.close()\n    35\n    36     87.0 MiB      0.5 MiB           1       weaviate_client.connect()\n    37     87.4 MiB      0.4 MiB           1       weaviate_client.close()\n    38\n    39     88.4 MiB      1.0 MiB           1       weaviate_client.connect()\n    40     88.7 MiB      0.2 MiB           1       weaviate_client.close()\n    41\n    42     88.7 MiB      0.0 MiB           1       del weaviate_client\n\nSo we can see that each weaviate_client.connect() consume more memory than the memory released by weaviate_client.close() .\nSomebody have an idea why and how to fix it ?\nbecause our service is running in EKS cluster and new services scale up frequently accordling to scaling policy based on memory consumption. But never scale down.\nThanks a lot\n\n----------\n\n[Elian (2024-12-02T11:27:53.426Z)]: By continuing test, I’ve found that calling manually the garbage collector after closing a conexion enable to cleanup everything and free memory.\n\n----------\n\n[sebawita (2024-12-02T11:40:03.003Z)]: Hi @Elian,\nThank you for sharing your findings with us.\nI am the garbage collector was able to cleanup everything as expected.\nFYI. there is a discussion on a similar topic on GitHub https://github.com/encode/httpx/discussions/3276. If you discover anything else, feel free to share it with us",
    "date_created": "2024-12-02T06:33:36.967Z",
    "has_accepted_answer": true,
    "title": "[Question] Memory Leak on Connexion using Python Lib",
    "topic_id": 9039
  },
  {
    "user_id": 1630,
    "conversation": "[Sik819 (2024-10-02T22:15:08.443Z)]: Hi I am trying to set up weaviate with a Golang server. However, many of the information within the documentation does not include Golang examples.\n\n----------\n\n[DudaNogueira (2024-10-03T16:18:37.401Z)]: hi @Sik819 !!\nWelcome to our community \nWe are always improving our docs, so thanks for pointing it out.\nA really nice place to learn more how to use our clients is checking our tests folder:\n\n  \n      \n\n      github.com\n  \n\n  \n    weaviate-go-client/test at main · weaviate/weaviate-go-client\n\n\n  Contribute to weaviate/weaviate-go-client development by creating an account on GitHub.\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHopefully, as we are adding more capacity to our team, we’ll be able to improve all client docs soon.\nThanks!",
    "date_created": "2024-10-02T22:15:08.394Z",
    "has_accepted_answer": false,
    "title": "Insufficient Information on Golang",
    "topic_id": 4406
  },
  {
    "user_id": 1264,
    "conversation": "[Cobyboss (2024-08-01T18:06:38.391Z)]: I get Google API Key: no api key found neither in request header even though I am hard coding in the urls and keys as shown below. I also ran gcloud auth print-access-token within the last hour and that is the key I am using.\nweaviate_url = \"a_url\"\nweaviate_key = \"a_key\"\nvertex_key = \"a_key\"\nheaders = {\n    \"X-Google-Vertex-Api-Key\": vertex_key,\n}\n\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=weaviate_url,                       # `weaviate_url`: your Weaviate URL\n    auth_credentials=Auth.api_key(weaviate_key),      # `weaviate_key`: your Weaviate API key\n    headers=headers)\n\ncollection = client.collections.get(\"Testing\")\nwith collection.batch.dynamic() as batch:\n    for src_obj in source_objects:\n        image_b64 = url_to_base64(src_obj[\"image_path\"])\n        weaviate_obj = {\n            \"image\": image_b64,\n            \"source\": src_obj[\"source\"],\n        }\n\n        # The model provider integration will automatically vectorize the object\n        batch.add_object(\n            properties=weaviate_obj,\n            # vector=vector  # Optionally provide a pre-obtained vector\n        )\n        break\n\nfailed_objects = collection.batch.failed_objects # After batch is done\n\n----------\n\n[DudaNogueira (2024-08-02T14:57:37.517Z)]: hi!\nWhat is the version of the client?\nAlso, can you paste the full error stack trace?\nThanks!\n\n----------\n\n[Cobyboss (2024-08-02T19:56:25.755Z)]: The weaviate version is 1.25.9\nThe weaviate client is 4.7.1\n{‘message’: ‘Failed to send 1 objects in a batch of 1. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\n[ErrorObject(message=“WeaviateInsertManyAllFailedError(‘Every object failed during insertion. Here is the set of all errors: Google API Key: no api key found neither in request header: X-Palm-Api-Key or X-Google-Api-Key or X-Google-Vertex-Api-Key or X-Google-Studio-Api-Key nor in environment variable under PALM_APIKEY or GOOGLE_APIKEY’)”\n\n----------\n\n[sebawita (2024-08-05T13:52:22.193Z)]: Hi @Cobyboss,\nI think there is a bug with the multimodal models and the Vertex header.\nCan you try using “X-Palm-Api-Key” instead?\nheaders = {\n    \"X-Palm-Api-Key\": vertex_key,\n}\n\n----------\n\n[Cobyboss (2024-08-05T16:48:24.338Z)]: Should I use Google Palm too or can I just use that header with the same vertex_key?\n\n----------\n\n[jakasspeech2 (2024-08-07T19:53:52.253Z)]: You can definitely use the same header with the vertex_key, no problem there.\n\n----------\n\n[Filipp_Trigub (2024-09-03T07:57:26.652Z)]: I am faced with the same problem, but using X-Palm-Api-Key does not seem to work.\nVertex AI is not compatible with API Keys anymore, hence I am trying Oauth2, service acc or simply an access token.\nEDIT: It now uploads the properties, but does not vectorize.\nMy cluster is 1.25.10 and my python dependency client is 4.7.1.\nI am basically running these lines\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=os.getenv(\"WEAVIATE_URL\"),\n    auth_credentials=weaviate.auth.AuthApiKey(api_key=os.getenv(\"WEAVIATE_API_KEY\")),\n    headers={\"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\"),\n             # \"X-Google-Vertex-Api-Key\": os.getenv(\"GOOGLE_ACCESS_TOKEN\"),\n             \"X-Palm-Api-Key\": os.getenv(\"GOOGLE_ACCESS_TOKEN\")\n             }\n)\n\nfor q in tqdm(collection_src.iterator()):\n     collection_tgt.data.insert(properties=q.properties, uuid=q.uuid)",
    "date_created": "2024-08-01T18:06:38.347Z",
    "has_accepted_answer": true,
    "title": "Can't connect to Google Vertex",
    "topic_id": 3254
  },
  {
    "user_id": 1287,
    "conversation": "[southclaws (2024-08-07T15:38:13.636Z)]: Description\nI saw an error in production where a vector was not found:\nexplorer: get class: concurrentTargetVectorSearch): explorer: get class: vectorize search vector: nearObject params: vector not found\n\nUpon further inspection, I noticed the object being queried does not exist when querying via GraphQL:\nquery {\n  Get {\n    ContentOpenAI(where: {\n      path: [\"datagraph_id\"]\n      operator: Equal\n      valueString: \"cqpnth0vub2s5hpce720\"\n    }) {\n      datagraph_id\n      datagraph_type\n      name\n    }\n  }\n}\n\nHowever, when querying the object list via REST, it is there:\nGET {{baseUrl}}/objects/9f27c258-05d1-5987-bc13-7c39436d3a8a?include=vector\n\n{\n    \"class\": \"ContentOpenAI\",\n    \"creationTimeUnix\": 1723041716137,\n    \"id\": \"9f27c258-05d1-5987-bc13-7c39436d3a8a\",\n    \"lastUpdateTimeUnix\": 1723041716137,\n    \"properties\": {\n        \"content\": \"Things that make me more money\\r\\n\\r\\n\",\n        \"datagraph_id\": \"cqpnth0vub2s5hpce720\",\n        \"datagraph_type\": \"profile\",\n        \"description\": \"Things that make me more money\",\n        \"name\": \"david\"\n    },\n    \"vector\": [ ... ]\n}\n\nNote how the “datagraph_id” is present in the response, the exact same one used in the GQL query above. I’ve also pulled all objects via GQL and it’s not in the list.\nAm I misunderstanding something about Weaviate here? Are there cases where objects appear in one API but not in another? I wondered if it had not indexed correctly via embeddings, but that seems not the case because a full vector is present (omitted from the post for readability.)\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method: Fly.io\nClient Language and Version: Just hitting GQL/REST directly\n\n----------\n\n[DudaNogueira (2024-08-07T19:04:16.384Z)]: Hi @southclaws !!\nWelcome to our community! \nCan you try:\n1 - searching in graphql for that id.\nquery {\n  Get {\n    ContentOpenAI(where: {\n      path: [\"id\"]\n      operator: Equal\n      valueString: \"9f27c258-05d1-5987-bc13-7c39436d3a8a\"\n    }) {\n      datagraph_id\n      datagraph_type\n      name\n    }\n  }\n}\n\n2 - searching with python v4 client. This will search using the GRPC endpoint, so we can try isolating this on graphql.\nThis error you pointed should not be related to that query, because you are not  doing any kind of vector search, but only filtering \nAre you sure this error pop whenever the query is run?\nAnother thing to try is aggregating the objects using it as filter.\nLet me know if you need help crafting those queries.\nThanks!\n\n----------\n\n[southclaws (2024-08-09T14:08:39.240Z)]: Hey, thanks! Searching for the ID did not yield a result either, sadly we’ve re-indexed since this issue occurred so the problem isn’t present any more for debugging.\nThis did occur repeatedly though, whenever a GQL query was run, the query specifically was a vector nearby search, this query specifically: storyden/app/services/semdex/weaviate/relevance.go at main · Southclaws/storyden · GitHub\n\n----------\n\n[DudaNogueira (2024-08-12T21:26:30.364Z)]: Oh!\nWe would love to have a reproducible way for this bug   we have a chaos pipeline, but not always can create this cases.\nSo after reindexing, you didn’t have this issue anymore, right?\nThis could be an index corruption. We are working on mitigating this kind of issue with some async read/repair operations.\nLet us know if you face any other issues so we can help you on this journey \nThanks!",
    "date_created": "2024-08-07T15:38:13.587Z",
    "has_accepted_answer": true,
    "title": "An object is somehow only visible in the REST API but not via GraphQL",
    "topic_id": 3291
  },
  {
    "user_id": 1251,
    "conversation": "[aiqing (2024-07-26T06:10:12.430Z)]: I’m using python weaviate-client 4.7.1,httpx 0.27.0.  The Error msg is\n“weaviate.exceptions.UnexpectedStatusCodeError: Meta endpoint! Unexpected status code: 504, with response body: None.”\nBy debugging, i found that in ‘v4.py’  this AsyncClient object below do not set trust_env, but its default value True is wrong for me.\ndef __make_async_client(self) -> AsyncClient:\n    return AsyncClient(\n        headers=self._headers,\n        mounts=self.__make_mounts(),\n    ) \n\nHere is how i init a client.\nadc = AdditionalConfig()\nadc.proxies = None\nadc.trust_env = False\nclient = weaviate.WeaviateClient(\nconnection_params=ConnectionParams.from_params(\nhttp_host=“10.\",\nhttp_port=8077,\nhttp_secure=False,\ngrpc_host=\"10.”,\ngrpc_port=50051,\ngrpc_secure=False,\n),\nauth_client_secret=weaviate.auth.AuthApiKey(“Tk@R0o”),\nadditional_config=adc,\n)\nclient.connect()\nI also tested this code below, i worked well and got 200, but when trust_env=True, i got 504 error too.\nresp = httpx.get(url=‘http://10.myip*:8077/v1/meta’,headers={“authorization”:“Bearer Tk@R0o”},trust_env=False)\nprint(resp.status_code,resp.content)\n\n----------\n\n[aiqing (2024-07-26T06:44:21.240Z)]: os.environ[“no_proxy”]=“*”\nproblem solved!\n\n----------\n\n[Mohamed_Shahin (2024-07-26T07:53:09.800Z)]: Hello @aiqing,\nWelcome to our community!\nFair play to you finding out the root-cause and solve it! \nHave a lovely weekend!",
    "date_created": "2024-07-26T06:10:12.363Z",
    "has_accepted_answer": true,
    "title": "Connect got 504 error for \"__make_async_client\" method do not set 'trust_env'",
    "topic_id": 3181
  },
  {
    "user_id": 1891,
    "conversation": "[Chris_Blom (2024-10-15T17:52:18.190Z)]: Hi, I am new to Weaviate and followed the QuickStart steps exactly but ran into the following exception. Any help is appreciated!\nDescription\nImplementing the QuickStart on WCD with Python gives the following exception when doing a generative search:\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\nstatus = StatusCode.UNKNOWN\ndetails = “connection to: OpenAI API failed with status: 400 request-id: req_4419cf1a05ed4792171000454b82a998 error: max_tokens is too large: 4097. This model supports at most 4096 completion tokens, whereas you provided 4097.”\ndebug_error_string = “UNKNOWN:Error received from peer  {created_time:“2024-10-15T19:41:41.686614+02:00”, grpc_status:2, grpc_message:“connection to: OpenAI API failed with status: 400 request-id: req_4419cf1a05ed4792171000454b82a998 error: max_tokens is too large: 4097. This model supports at most 4096 completion tokens, whereas you provided 4097.”}”\nServer Setup Information\nWCS Sandbox standard\n\n----------\n\n[DudaNogueira (2024-10-15T19:04:55.931Z)]: hi @Chris_Blom !!\nWelcome to our community \nThis is a known issue that was already tackled here:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n\n\n\n    \n      \n    \n\n  \n\n\n\n      \n        Fix Generative-OpenAI Default 3.5-turbo Max Tokens and add gpt-4o Models\n      \n\n    \n      weaviate:stable/v1.25 ← weaviate:modules/fix-generative-openai-default-max-tokens-and-models\n    \n\n      \n        \n          opened 09:45AM - 11 Oct 24 UTC\n        \n\n        \n          \n            \n            Dannydoesdev\n          \n        \n\n        \n          \n            +8\n            -4\n          \n        \n      \n  \n\n\n  \n    ### What's being changed:\n\nSee Slack discussion: [Link]( https://weaviate-org.…slack.com/archives/C04AT0Y52E6/p1728641537952229?thread_ts=1728635290.391309&cid=C04AT0Y52E6)\n\n- Updated the default model for generative-openai (gpt-3.5-turbo) to reflect the maxTokens of 4096 and resolve error `max_tokens is too large: 4097. This model supports at most 4096 completion tokens, whereas you provided 4097.`\n- Added gpt-4o-mini to available models list\n- gpt-4o was also brought in due to being available in stable/v1.26 - can be edited if needed or merged if this is okay\n\nDocumentation change request: would be worth updating available model list here: [Available Models - openai-generative](https://weaviate.io/developers/weaviate/model-providers/openai/generative#available-models)\n\n### Review checklist\n\n- [ ] Documentation has been updated, if necessary. Link to changed documentation:\n- [ ] Chaos pipeline run or not necessary. Link to pipeline:\n- [ ] All new code is covered by tests where it is reasonable.\n- [ ] Performance tests have been run or not necessary.\n\nUncomment the following section if this PR requires changes in related projects (e.g., documentation, client libraries).\n\nGitHub actions will automatically create an issue in the corresponding repository for each checked box below. (See `.github/workflows/create-cross-functional-issues.yml`)\n\n### Cross-functional impact\n\n- [x] This change requires public documentation (weaviate-io) to be updated. Check the box to automatically create a corresponding issue.\n- Does it require a change in the client libraries? If yes, please check the boxes for the affected client libraries.\n    - [ ] Python (weaviate-python-client)\n    - [ ] JavaScript/TypeScript (typescript-client)\n    - [ ] Go (weaviate-go-client)\n    - [ ] Java (java-client)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIt seems there was a change in OpenAI Api \nthis should be a workaround, but it’s also falling into the same issue:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n    generative_config=wvc.config.Configure.Generative.openai(model=\"gpt-3.5-turbo\", max_tokens=4096),\n)\n\ncollection.data.insert({\n        \"text\": \"something about dogs\",\n    }\n)\ncollection.data.insert({\n        \"text\": \"something about cats\",\n    }\n)\n\nresults = collection.generate.near_text(\n    query=\"animals\",\n    grouped_task=\"Create a content with {text}\",\n    single_prompt=\"Translate {text} to portuguese\"\n)\n\nI’ll get back here with more information as soon as I get it\n\n----------\n\n[DudaNogueira (2024-10-15T19:10:57.303Z)]: ps, for now, if you only want to play around you can use the gpt-4 model, like so:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n    generative_config=wvc.config.Configure.Generative.openai(model=\"gpt-4\"),\n)\n\ncollection.data.insert({\n        \"text\": \"something about dogs\",\n    }\n)\ncollection.data.insert({\n        \"text\": \"something about cats\",\n    }\n)\n\nresults = collection.generate.near_text(\n    query=\"animals\",\n    grouped_task=\"Create a content with {text}\",\n    single_prompt=\"Translate {text} to portuguese\"\n)\n\n----------\n\n[Chris_Blom (2024-10-16T06:03:07.344Z)]: Hi Duda, thanks for the quick reply and I’ll change to gpt-4. regards, Chris\n\n----------\n\n[DudaNogueira (2024-10-16T11:59:14.325Z)]: Great! A new patch is being released to address this change in apis.\nit should be released probably today.\nThanks!",
    "date_created": "2024-10-15T17:52:18.140Z",
    "has_accepted_answer": false,
    "title": "Quickstart tutorial generative search exception on max_token using Python",
    "topic_id": 5434
  },
  {
    "user_id": 383,
    "conversation": "[htbit1990 (2024-07-29T14:09:51.202Z)]: Description\nI have created a RAG application with weaviate as vectorstore, embedding=“BAAI/bge-base-en-v1.5”. I have split some Dutch text using the RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True).\nretriever =vector_store.as_retriever(search_kwargs={“k”:5,“score_threshold”:0.6},search_type=‘similarity_score_threshold’)\nWhen I tested with openai gpt4o-mini, gemini-1.5-flash, gemini-1.5-pro and asks the following question: “wie betaalt de pgb voor de wmo?” I get the following wrong answer: “Ik weet niet wie de pgb voor de Wmo betaalt.” If I asks the same question using gpt-4o then I get the correct answer: “De gemeente betaalt het persoonsgebonden budget (pgb) niet direct aan u, maar aan de Sociale Verzekeringsbank (SVB). De SVB beheert het geld en betaalt uw zorgaanbieder achteraf, aan het eind van de maand, nadat u de facturen heeft gecontroleerd en opdracht heeft gegeven om te betalen”.\nIf I print the response using the retriever: retriever.invoke(input=“wie betaalt de pgb voor de wmo?”) , without submitting to the LLM, I see 5 retrieved document chunks about the information regarding the “PGB” and which organization is paying it. The correct answer (SVB) are inside the 5 retrieved chunks. (see attachment for the results)\nI don’t understand the inconsistency and why the retrieved chunks are NOT used when I am not using gpt4-o… See attachments of the results of the retrieved chunks when using gpt4o-mini (no info about SVB) but the info is available when using gpt4-o. How is this possible? I thought the retrieved document chunks are being used and together with the question submitted as input for the LLM… Maybe its not weaviate related, but I suppose I am not the only one using RAG with weaviate and langchain.\nServer Setup Information\n\nWeaviate Server Version: 24.0.6\nDeployment Method:  docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: 4.6.5\nMultitenancy?: NO\n\nAny additional Information\nVersions of libraries used:\n\nlangchain                                0.2.6\nlangchain-cli                            0.0.25\nlangchain-community                      0.2.6\nlangchain-core                           0.2.11\nlangchain-experimental                   0.0.62\nlangchain-google-genai                   1.0.7\nlangchain-openai                         0.1.14\nlangchain-text-splitters                 0.2.2\nlangchain-weaviate                       0.0.2\nweaviate-client                          4.6.5\n\npython 3.11\nresults output from different LLM+retriever only\n\nLLM=gpt-o-mini\nuser_query: wie betaalt de pgb voor de wmo?\nmodel=gpt-4o-mini, model_type=openai\n[{‘chat_history’: [AIMessage(content=‘Goede dag, ik ben uw virtuele assistent. Waarmee kan ik u helpen?’), HumanMessage(content=‘wie betaalt de pgb voor de wmo?’)], ‘input’: ‘wie betaalt de pgb voor de wmo?’}, {‘context’: [Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 25572.0}, page_content=“Regels en wetten, hoe zit het eigenlijk?\\n\\n  * ## Persoonsgebonden budget\\n\\nEen persoonsgebonden budget (pgb) is een bedrag waarmee u zelf zorg kunt\\ninkopen.\\n\\n  * ## Eigen bijdrage Wmo\\n\\nU betaalt een eigen bijdrage voor de meeste voorzieningen vanuit de Wmo.\\n\\n## Heeft u hulp nodig?\\n\\n### Kom langs\\n\\n Kennedystraat 2a, 5427 CJ Boekel\\n\\nAlleen op afspraak geopend\\n\\n### Bereik ons\\n\\n Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Jeugd en gezin\\n\\n# Jeugd en gezin”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 119220.0}, page_content=“Regels en wetten, hoe zit het eigenlijk?\\n\\n  * ## Persoonsgebonden budget\\n\\nEen persoonsgebonden budget (pgb) is een bedrag waarmee u zelf zorg kunt\\ninkopen.\\n\\n  * ## Eigen bijdrage Wmo\\n\\nU betaalt een eigen bijdrage voor de meeste voorzieningen vanuit de Wmo.\\n\\n## Heeft u hulp nodig?\\n\\n### Kom langs\\n\\n Kennedystraat 2a, 5427 CJ Boekel\\n\\nAlleen op afspraak geopend\\n\\n### Bereik ons\\n\\n Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n\\n# Zorg en ondersteuning\\n\\nUw gezondheid is erg belangrijk. Daar wilt u goed voor zorgen. Maar soms lukt\\nu dat niet alleen. Bijvoorbeeld omdat u (chronisch) ziek bent, hulpbehoevend\\nwordt, een beperking heeft of psychische bijstand nodig heeft. Als het om uw\\ngezondheid gaat, is het belangrijk dat u snel de juiste ondersteuning krijgt.”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 619687.0}, page_content=“Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Eigen bijdrage Wmo\\n\\n# Eigen bijdrage Wmo\\n\\nU betaalt een eigen bijdrage voor alle voorzieningen vanuit de Wmo, behalve\\nvoor rolstoelen, regiotaxi en voor hulpmiddelen voor kinderen tot 18 jaar.\\nKrijgt u een persoonsgebonden budget (PGB)? Dan betaalt u ook een eigen\\nbijdrage.\\n\\n## Hoogte van de eigen bijdrage\\n\\nU betaalt maximaal € 19,00 per maand, per huishouden. Vanaf 1 januari 2024\\nwijzigt dit bedrag naar € 20,60. U krijgt hiervoor een rekening van het CAK. U\\nbetaalt de eigen bijdrage zolang u de voorziening hebt. Maar u betaalt in\\ntotaal nooit meer dan de prijs die de gemeente betaalt voor de voorziening.\\n\\n## Wanneer hoeft u niet te betalen?”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 151859.0}, page_content=“Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Eigen bijdrage Wmo\\n\\n# Eigen bijdrage Wmo\\n\\nU betaalt een eigen bijdrage voor alle voorzieningen vanuit de Wmo, behalve\\nvoor rolstoelen, regiotaxi en voor hulpmiddelen voor kinderen tot 18 jaar.\\nKrijgt u een persoonsgebonden budget (PGB)? Dan betaalt u ook een eigen\\nbijdrage.\\n\\n## Hoogte van de eigen bijdrage\\n\\nU betaalt maximaal € 19,00 per maand, per huishouden. Vanaf 1 januari 2024\\nwijzigt dit bedrag naar € 20,60. U krijgt hiervoor een rekening van het CAK. U\\nbetaalt de eigen bijdrage zolang u de voorziening hebt. Maar u betaalt in\\ntotaal nooit meer dan de prijs die de gemeente betaalt voor de voorziening.\\n\\n## Wanneer hoeft u niet te betalen?”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 616306.0}, page_content=“info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Persoonsgebonden budget\\n\\n# Persoonsgebonden budget (PGB)\\n\\nEen persoonsgebonden budget (pgb) is een bedrag waarmee u zelf zorg kunt\\ninkopen. Dat geeft meer vrijheid dan bij zorg in natura. Het gebruik maken van\\neen pgb brengt ook een aantal verplichtingen met zich mee.\\n\\n## Voorwaarden voor een Wmo-pgb\\n\\nWilt u zelf ondersteuning inkopen met een pgb? Daarvoor gelden de volgende\\nvoorwaarden:\\n\\n  * U kunt het budget beheren;\\n  * U kunt zelf ondersteuning inkopen en hulpverleners aansturen (u mag ook iemand machtigen om dit voor u te doen);\\n  * U koopt ‘doeltreffende’ ondersteuning in (ondersteuning is doeltreffend als u er zelfstandiger door kunt leven);\\n  * De ondersteuning moet cliëntgericht en veilig zijn;\\n  * U kunt motiveren (uitleggen) waarom u zelf ondersteuning wilt inkopen met een pgb.\\n\\n## Hoe gaat het met betalen van het pgb?”)]}, {‘answer’: ‘’}, {‘answer’: ‘Ik’}, {‘answer’: ’ weet’}, {‘answer’: ’ niet’}, {‘answer’: ’ wie’}, {‘answer’: ’ de’}, {‘answer’: ’ p’}, {‘answer’: ‘gb’}, {‘answer’: ’ voor’}, {‘answer’: ’ de’}, {‘answer’: ’ W’}, {‘answer’: ‘mo’}, {‘answer’: ’ betaalt’}, {‘answer’: ‘.’}, {‘answer’: ‘’}]\nresponse:\n** Ik weet niet wie de pgb voor de Wmo betaalt.**\nLLM=gpt-4o\nuser_query: wie betaalt de pgb voor de wmo?\nmodel=gpt-4o, model_type=openai\n[{‘chat_history’: [AIMessage(content=‘Goede dag, ik ben uw virtuele assistent. Waarmee kan ik u helpen?’), HumanMessage(content=‘wie betaalt de pgb voor de wmo?’)], ‘input’: ‘wie betaalt de pgb voor de wmo?’}, {‘context’: [Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 151859.0}, page_content=“Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Eigen bijdrage Wmo\\n\\n# Eigen bijdrage Wmo\\n\\nU betaalt een eigen bijdrage voor alle voorzieningen vanuit de Wmo, behalve\\nvoor rolstoelen, regiotaxi en voor hulpmiddelen voor kinderen tot 18 jaar.\\nKrijgt u een persoonsgebonden budget (PGB)? Dan betaalt u ook een eigen\\nbijdrage.\\n\\n## Hoogte van de eigen bijdrage\\n\\nU betaalt maximaal € 19,00 per maand, per huishouden. Vanaf 1 januari 2024\\nwijzigt dit bedrag naar € 20,60. U krijgt hiervoor een rekening van het CAK. U\\nbetaalt de eigen bijdrage zolang u de voorziening hebt. Maar u betaalt in\\ntotaal nooit meer dan de prijs die de gemeente betaalt voor de voorziening.\\n\\n## Wanneer hoeft u niet te betalen?”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 619687.0}, page_content=“Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Eigen bijdrage Wmo\\n\\n# Eigen bijdrage Wmo\\n\\nU betaalt een eigen bijdrage voor alle voorzieningen vanuit de Wmo, behalve\\nvoor rolstoelen, regiotaxi en voor hulpmiddelen voor kinderen tot 18 jaar.\\nKrijgt u een persoonsgebonden budget (PGB)? Dan betaalt u ook een eigen\\nbijdrage.\\n\\n## Hoogte van de eigen bijdrage\\n\\nU betaalt maximaal € 19,00 per maand, per huishouden. Vanaf 1 januari 2024\\nwijzigt dit bedrag naar € 20,60. U krijgt hiervoor een rekening van het CAK. U\\nbetaalt de eigen bijdrage zolang u de voorziening hebt. Maar u betaalt in\\ntotaal nooit meer dan de prijs die de gemeente betaalt voor de voorziening.\\n\\n## Wanneer hoeft u niet te betalen?”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 618936.0}, page_content=“## Hoe gaat het met betalen van het pgb?\\n\\n  * De gemeente betaalt het pgb niet direct aan u, maar aan de SVB. De SVB beheert het geld.\\n  * U controleert zelf de facturen van uw zorgaanbieder. En geeft zelf opdracht aan de SVB om te betalen.\\n  * De SVB controleert de facturen van uw zorgaanbieder aan de hand van uw zorgovereenkomst.\\n  * Is alles volgens afspraak? Dan betaalt de SVB uw zorgaanbieder achteraf, aan het eind van de maand uit.\\n  * De SVB meldt bij de belastingdienst welke zorgaanbieder(s) zij hebben betaald uit uw pgb en hoeveel.\\n  * U kunt uw saldo en betalingen nakijken op de website van de SVB via ‘Mijn pgb’.\\n\\n## Heeft u hulp nodig?\\n\\n### Kom langs\\n\\n Kennedystraat 2a, 5427 CJ Boekel\\n\\nAlleen op afspraak geopend\\n\\n### Bereik ons\\n\\n Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Eigen bijdrage Wmo\\n\\n# Eigen bijdrage Wmo”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 151108.0}, page_content=“## Hoe gaat het met betalen van het pgb?\\n\\n  * De gemeente betaalt het pgb niet direct aan u, maar aan de SVB. De SVB beheert het geld.\\n  * U controleert zelf de facturen van uw zorgaanbieder. En geeft zelf opdracht aan de SVB om te betalen.\\n  * De SVB controleert de facturen van uw zorgaanbieder aan de hand van uw zorgovereenkomst.\\n  * Is alles volgens afspraak? Dan betaalt de SVB uw zorgaanbieder achteraf, aan het eind van de maand uit.\\n  * De SVB meldt bij de belastingdienst welke zorgaanbieder(s) zij hebben betaald uit uw pgb en hoeveel.\\n  * U kunt uw saldo en betalingen nakijken op de website van de SVB via ‘Mijn pgb’.\\n\\n## Heeft u hulp nodig?\\n\\n### Kom langs\\n\\n Kennedystraat 2a, 5427 CJ Boekel\\n\\nAlleen op afspraak geopend\\n\\n### Bereik ons\\n\\n Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Eigen bijdrage Wmo\\n\\n# Eigen bijdrage Wmo”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 615005.0}, page_content=“## Voorwaarden voor een Wmo-pgb\\n\\nWilt u zelf ondersteuning inkopen met een pgb? Daarvoor gelden de volgende\\nvoorwaarden:\\n\\n  * U kunt het budget beheren;\\n  * U kunt zelf ondersteuning inkopen en hulpverleners aansturen (u mag ook iemand machtigen om dit voor u te doen);\\n  * U koopt ‘doeltreffende’ ondersteuning in (ondersteuning is doeltreffend als u er zelfstandiger door kunt leven);\\n  * De ondersteuning moet cliëntgericht en veilig zijn;\\n  * U kunt motiveren (uitleggen) waarom u zelf ondersteuning wilt inkopen met een pgb.\\n\\n## Hoe gaat het met betalen van het pgb?”)]}, {‘answer’: ‘’}, {‘answer’: ‘De’}, {‘answer’: ’ gemeente’}, {‘answer’: ’ betaalt’}, {‘answer’: ’ het’}, {‘answer’: ’ persoons’}, {‘answer’: ‘geb’}, {‘answer’: ‘onden’}, {‘answer’: ’ budget’}, {‘answer’: ’ (‘}, {‘answer’: ‘pg’}, {‘answer’: ‘b’}, {‘answer’: ‘)’}, {‘answer’: ’ niet’}, {‘answer’: ’ direct’}, {‘answer’: ’ aan’}, {‘answer’: ’ u’}, {‘answer’: ‘,’}, {‘answer’: ’ maar’}, {‘answer’: ’ aan’}, {‘answer’: ’ de’}, {‘answer’: ’ Sociale’}, {‘answer’: ’ Ver’}, {‘answer’: ‘zek’}, {‘answer’: ‘erings’}, {‘answer’: ‘bank’}, {‘answer’: ’ (‘}, {‘answer’: ‘SV’}, {‘answer’: ‘B’}, {‘answer’: ‘).’}, {‘answer’: ’ De’}, {‘answer’: ’ SV’}, {‘answer’: ‘B’}, {‘answer’: ’ behe’}, {‘answer’: ‘ert’}, {‘answer’: ’ het’}, {‘answer’: ’ geld’}, {‘answer’: ’ en’}, {‘answer’: ’ betaalt’}, {‘answer’: ’ uw’}, {‘answer’: ’ zorg’}, {‘answer’: ‘aan’}, {‘answer’: ‘b’}, {‘answer’: ‘ieder’}, {‘answer’: ’ achter’}, {‘answer’: ‘af’}, {‘answer’: ‘,’}, {‘answer’: ’ aan’}, {‘answer’: ’ het’}, {‘answer’: ’ eind’}, {‘answer’: ’ van’}, {‘answer’: ’ de’}, {‘answer’: ’ maand’}, {‘answer’: ‘,’}, {‘answer’: ’ nadat’}, {‘answer’: ’ u’}, {‘answer’: ’ de’}, {‘answer’: ’ fact’}, {‘answer’: ‘uren’}, {‘answer’: ’ heeft’}, {‘answer’: ’ gecontrole’}, {‘answer’: ‘erd’}, {‘answer’: ’ en’}, {‘answer’: ’ opdracht’}, {‘answer’: ’ heeft’}, {‘answer’: ’ gegeven’}, {‘answer’: ’ om’}, {‘answer’: ’ te’}, {‘answer’: ’ betalen’}, {‘answer’: ‘.’}, {‘answer’: ‘’}]\nresponse:\nDe gemeente betaalt het persoonsgebonden budget (pgb) niet direct aan u, maar aan de Sociale Verzekeringsbank (SVB). De SVB beheert het geld en betaalt uw zorgaanbieder achteraf, aan het eind van de maand, nadat u de facturen heeft gecontroleerd en opdracht heeft gegeven om te betalen.\nasking using the retriever without submitting to the LLMretriever =vector_store.as_retriever(search_kwargs={“k”:5,“score_threshold”:0.6},search_type=‘similarity_score_threshold’)\n[Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 151859.0}, page_content=“Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Eigen bijdrage Wmo\\n\\n# Eigen bijdrage Wmo\\n\\nU betaalt een eigen bijdrage voor alle voorzieningen vanuit de Wmo, behalve\\nvoor rolstoelen, regiotaxi en voor hulpmiddelen voor kinderen tot 18 jaar.\\nKrijgt u een persoonsgebonden budget (PGB)? Dan betaalt u ook een eigen\\nbijdrage.\\n\\n## Hoogte van de eigen bijdrage\\n\\nU betaalt maximaal € 19,00 per maand, per huishouden. Vanaf 1 januari 2024\\nwijzigt dit bedrag naar € 20,60. U krijgt hiervoor een rekening van het CAK. U\\nbetaalt de eigen bijdrage zolang u de voorziening hebt. Maar u betaalt in\\ntotaal nooit meer dan de prijs die de gemeente betaalt voor de voorziening.\\n\\n## Wanneer hoeft u niet te betalen?”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 619687.0}, page_content=“Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Eigen bijdrage Wmo\\n\\n# Eigen bijdrage Wmo\\n\\nU betaalt een eigen bijdrage voor alle voorzieningen vanuit de Wmo, behalve\\nvoor rolstoelen, regiotaxi en voor hulpmiddelen voor kinderen tot 18 jaar.\\nKrijgt u een persoonsgebonden budget (PGB)? Dan betaalt u ook een eigen\\nbijdrage.\\n\\n## Hoogte van de eigen bijdrage\\n\\nU betaalt maximaal € 19,00 per maand, per huishouden. Vanaf 1 januari 2024\\nwijzigt dit bedrag naar € 20,60. U krijgt hiervoor een rekening van het CAK. U\\nbetaalt de eigen bijdrage zolang u de voorziening hebt. Maar u betaalt in\\ntotaal nooit meer dan de prijs die de gemeente betaalt voor de voorziening.\\n\\n## Wanneer hoeft u niet te betalen?”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 151108.0}, page_content=“## Hoe gaat het met betalen van het pgb?\\n\\n  * De gemeente betaalt het pgb niet direct aan u, maar aan de SVB. De SVB beheert het geld.\\n  * U controleert zelf de facturen van uw zorgaanbieder. En geeft zelf opdracht aan de SVB om te betalen.\\n  * De SVB controleert de facturen van uw zorgaanbieder aan de hand van uw zorgovereenkomst.\\n  * Is alles volgens afspraak? Dan betaalt de SVB uw zorgaanbieder achteraf, aan het eind van de maand uit.\\n  * De SVB meldt bij de belastingdienst welke zorgaanbieder(s) zij hebben betaald uit uw pgb en hoeveel.\\n  * U kunt uw saldo en betalingen nakijken op de website van de SVB via ‘Mijn pgb’.\\n\\n## Heeft u hulp nodig?\\n\\n### Kom langs\\n\\n Kennedystraat 2a, 5427 CJ Boekel\\n\\nAlleen op afspraak geopend\\n\\n### Bereik ons\\n\\n Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Eigen bijdrage Wmo\\n\\n# Eigen bijdrage Wmo”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 618936.0}, page_content=“## Hoe gaat het met betalen van het pgb?\\n\\n  * De gemeente betaalt het pgb niet direct aan u, maar aan de SVB. De SVB beheert het geld.\\n  * U controleert zelf de facturen van uw zorgaanbieder. En geeft zelf opdracht aan de SVB om te betalen.\\n  * De SVB controleert de facturen van uw zorgaanbieder aan de hand van uw zorgovereenkomst.\\n  * Is alles volgens afspraak? Dan betaalt de SVB uw zorgaanbieder achteraf, aan het eind van de maand uit.\\n  * De SVB meldt bij de belastingdienst welke zorgaanbieder(s) zij hebben betaald uit uw pgb en hoeveel.\\n  * U kunt uw saldo en betalingen nakijken op de website van de SVB via ‘Mijn pgb’.\\n\\n## Heeft u hulp nodig?\\n\\n### Kom langs\\n\\n Kennedystraat 2a, 5427 CJ Boekel\\n\\nAlleen op afspraak geopend\\n\\n### Bereik ons\\n\\n Bel: 0492-328383\\n\\n info@dorpsteamboekel.nl\\n\\nNu niet bereikbaar.  \\nMorgen: 9.00 - 12.00 uur\\n\\n\\n  1. Home\\n  2. Thema’s\\n  3. Zorg en ondersteuning\\n  4. Eigen bijdrage Wmo\\n\\n# Eigen bijdrage Wmo”), Document(metadata={‘source’: ‘E:/llmchat/wmo/boekel/dorpsteam_info.txt’, ‘start_index’: 150577.0}, page_content=“## Voorwaarden voor een Wmo-pgb\\n\\nWilt u zelf ondersteuning inkopen met een pgb? Daarvoor gelden de volgende\\nvoorwaarden:\\n\\n  * U kunt het budget beheren;\\n  * U kunt zelf ondersteuning inkopen en hulpverleners aansturen (u mag ook iemand machtigen om dit voor u te doen);\\n  * U koopt ‘doeltreffende’ ondersteuning in (ondersteuning is doeltreffend als u er zelfstandiger door kunt leven);\\n  * De ondersteuning moet cliëntgericht en veilig zijn;\\n  * U kunt motiveren (uitleggen) waarom u zelf ondersteuning wilt inkopen met een pgb.\\n\\n## Hoe gaat het met betalen van het pgb?”)]\n\n----------\n\n[DudaNogueira (2024-07-29T18:39:51.062Z)]: Hi!\nYes, this is probably something on the LLM side.\nIf you have the vector of your query, you can initiate a client, provide a different base url (for example, pointing to those endpoint debug sites, like https://webhook.site/) and perform a generative search using the vector as query.\nthis will make Weaviate server to send the payload that it would send to your llm to the webhook.site endpoint.\nNow, if you consume the llm api passing the same payload, you should see the same results.\nNot sure how I can help here, considering the answer to the query is in the returned objects",
    "date_created": "2024-07-29T14:09:51.143Z",
    "has_accepted_answer": false,
    "title": "Retrieved document chunks is dependent on LLM in combination with Langchain",
    "topic_id": 3209
  },
  {
    "user_id": 3006,
    "conversation": "[Stefan_Edlund (2024-12-12T22:30:19.942Z)]: Description\nWe are seeing periodic errors in Weaviate, “transferring leadership” but we are only using a single node cluster so the RAFT algorithm makes no sense here. It takes hours for Weaviate to recover sometimes, and it brings down our whole application.\nWe also see these errors  in the client when this happens:\nAPI_ERROR:\nUnexpectedStatusCodeError\nmessage: Collection may not exist.! Unexpected status code: 500, with response body: {‘error’: [{‘message’: ‘failed to execute query: leader not found’}]}.\nThis is our environement variables:\nENV QUERY_DEFAULTS_LIMIT=25\nENV AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true\nENV PERSISTENCE_DATA_PATH=/var/lib/weaviate\nENV DEFAULT_VECTORIZER_MODULE=none\nENV ENABLE_MODULES=text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai,backup-filesystem\nENV CLUSTER_HOSTNAME=node1\nENV BACKUP_FILESYSTEM_PATH=‘/var/lib/weaviate/backups’\nOne proposed solution I saw somewhere is setting:\nENV RAFT_BOOTSTRAP_EXPECT=1\nWill that help?\nServer Setup Information\n\nWeaviate Server Version: Docker file semitechnologies/weaviate:1.26.5\nDeployment Method: k8s\nMulti Node? No Number of Running Nodes: 1\nClient Language and Version: Python  3.10\nMultitenancy?: No\n\nAny additional Information\nFor some reason we are unable to reproduce the problem on our development environment, only in production. The only difference I can see is the size of the database, production is much larger.\n\n----------\n\n[Mohamed_Shahin (2024-12-13T06:30:23.127Z)]: Good morning @Stefan_Edlund \nWelcome to our community! It’s lovely to have you on board.\nRAFT implementation is used to ensure fault tolerance in multi-node clusters. In a single-node setup, RAFT cannot elect leaders or followers as there are no peers. As a result, it is unable to proceed with leadership transfer, which is why you’re seeing those logs\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCluster Architecture | Weaviate\n\n  This page describes how the nodes or clusters in Weaviate's replication design behave.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThese leadership failure messages is not critical issues, and Weaviate should continue functioning as expected in a single-node configuration. For stability & performance, especially in production environments, we typically recommend a 3-node setup as minimum.\nYou can set the following:\n\n\nname: RAFT_JOIN\n\nvalue: weaviate-0\n\nname: RAFT_BOOTSTRAP_EXPECT\n\nvalue: “1”\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nEnvironment variables | Weaviate\n\n  To configure Weaviate in a Docker or a Kubernetes deployment, set these environment variables\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nActually, this step of setting env is not strictly necessary, as the error logs do not affect Weaviate’s operations.\nBest regards,\nMohamed Shahin,\nWeaviate Support Engineer\n\n----------\n\n[Stefan_Edlund (2024-12-13T18:39:36.414Z)]: Stefan_Edlund:\n\nRAFT_BOOTSTRAP_EXPECT\n\n\nHi Mohamed,\nthe fix using RAFT_BOOT_EXPECT did not work work so we reverted back and got rid of it. Weaviate is taking forever for us to start up.  We see lots of entries like this in the log\n{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"353d907\",\"build_go_version\":\"go1.22.7\",\"build_image_tag\":\"1.26.5\",\"build_wv_version\":\"1.26.5\",\"class\":\"INTERNET_SEARCH_cf5bac2e_94d4_45b6_9dd0_37fc3c4f39c5\",\"index\":\"internet_search_cf5bac2e_94d4_45b6_9dd0_37fc3c4f39c5\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/var/lib/weaviate/internet_search_cf5bac2e_94d4_45b6_9dd0_37fc3c4f39c5/eCdjnhtViEoQ/lsm/property__id/segment-1733796788431478066\",\"shard\":\"eCdjnhtViEoQ\",\"time\":\"2024-12-13T17:53:23Z\"}\n{\nAre they harmless? It takes forever to Weaviate to start up, and it’s bringing our application to a halt, we could very much use some help here.\n\n----------\n\n[DudaNogueira (2024-12-13T19:22:04.953Z)]: Hi @Stefan_Edlund !!\nThose messages will usually appear after a crash.\nDo you, by any chance, have a lot of collections?\nThe more collections you have , more Weaviate can take to start accordingly.\nIf you have multiple collections, all of them with the same properties, you need to leverage the multi tenancy feature.\nLet me know if this is your scenario here.\nAlso, we suggest to always use the latest version. There was a lot of improvements since 1.26.5\nThanks!\n\n----------\n\n[Stefan_Edlund (2024-12-13T19:56:12.714Z)]: Hi Duda,\nlikely we have lots of collections. What’s the latest version?\nWe also see these timeout errors in the Python client, what might cause these:\nTraceback (most recent call last):\nFile “/usr/local/lib/python3.10/site-packages/langchain_core/retrievers.py”, line 377, in aget_relevant_documents\nresult = await self._aget_relevant_documents(\nFile “/usr/local/lib/python3.10/site-packages/langchain/retrievers/merger_retriever.py”, line 56, in _aget_relevant_documents\nmerged_documents = await self.amerge_documents(query, run_manager)\nFile “/usr/local/lib/python3.10/site-packages/langchain/retrievers/merger_retriever.py”, line 105, in amerge_documents\nretriever_docs = await asyncio.gather(\nFile “/usr/local/lib/python3.10/site-packages/langchain_core/retrievers.py”, line 384, in aget_relevant_documents\nraise e\nFile “/usr/local/lib/python3.10/site-packages/langchain_core/retrievers.py”, line 377, in aget_relevant_documents\nresult = await self._aget_relevant_documents(\nFile “/workspace/app/langchain_tool/web_research_retriever.py”, line 272, in _aget_relevant_documents\nself.vectorstore.delete_collection()\nFile “/workspace/app/langchain_tool/vectorstore.py”, line 113, in delete_collection\nself._client.collections.delete(self._index_name)\nFile “/usr/local/lib/python3.10/site-packages/weaviate/collections/collections.py”, line 203, in delete\nself._delete(_capitalize_first_letter(name))\nFile “/usr/local/lib/python3.10/site-packages/weaviate/collections/base.py”, line 93, in _delete\nself._connection.delete(\nFile “/usr/local/lib/python3.10/site-packages/weaviate/connect/v4.py”, line 466, in delete\nreturn self.__send(\nFile “/usr/local/lib/python3.10/site-packages/weaviate/connect/v4.py”, line 449, in __send\nres = self._client.send(req)\nFile “/usr/local/lib/python3.10/site-packages/ddtrace/contrib/httpx/patch.py”, line 166, in _wrapped_sync_send\nresp = wrapped(*args, **kwargs)\nFile “/usr/local/lib/python3.10/site-packages/httpx/_client.py”, line 914, in send\nresponse = self._send_handling_auth(\nFile “/usr/local/lib/python3.10/site-packages/httpx/_client.py”, line 942, in _send_handling_auth\nresponse = self._send_handling_redirects(\nFile “/usr/local/lib/python3.10/site-packages/httpx/_client.py”, line 979, in _send_handling_redirects\nresponse = self._send_single_request(request)\nFile “/usr/local/lib/python3.10/site-packages/httpx/_client.py”, line 1015, in _send_single_request\nresponse = transport.handle_request(request)\nFile “/usr/local/lib/python3.10/site-packages/httpx/_transports/default.py”, line 232, in handle_request\nwith map_httpcore_exceptions():\nFile “/usr/local/lib/python3.10/contextlib.py”, line 153, in exit\nself.gen.throw(typ, value, traceback)\nFile “/usr/local/lib/python3.10/site-packages/httpx/_transports/default.py”, line 86, in map_httpcore_exceptions\nraise mapped_exc(message) from exc\nhttpx.ReadTimeout: timed out\n\n----------\n\n[DudaNogueira (2024-12-13T20:14:51.688Z)]: Hi!\nThe latest version is 1.28.0\nIn order to upgrade, we suggest first upgrading for the latest of each release.\nSo for example:\n1.26.5 → 1.26.12 → 1.27.8 → 1.28.0\nNote that langchain already supports multi tenancy.\nHere you can find a recipe I wrote myself with this exact scenario:\n  \n\n      github.com\n  \n\n  \n    weaviate/recipes/blob/main/integrations/llm-frameworks/langchain/loading-data/langchain-simple-pdf-multitenant.ipynb\n\n\n      {\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Multilanguage RAG filtering by multiple PDFs per tenant with Langchain and OpenAi\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 1,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"Note: you may need to restart the kernel to use updated packages.\\n\",\n      \"Requirement already satisfied: langchain-openai in /Users/dudanogueira/dev/weaviate/recipes/.venv/lib/python3.12/site-packages (0.1.21)\\n\",\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWe have identified some issues when there is a lot of collections.\nOne of them, the startup time will grow according to the number of collections.\nAlso, each time you add a new collection, the graphql schema needs to be rebuild, so this can affect some queries on that endpoint.\nLet me know if this helps!\nThanks!\n\n----------\n\n[Stefan_Edlund (2024-12-16T17:22:43.736Z)]: Hi,\nwe have a sick Weaviate, and still need help figuring out what we can do.\nThe k8s liveness probe often restarts Weaviate when failing pings, and when it restarts it goes through some recovery process that takes an hour.\nHow can we diagnose this? We do likely have lots of collections, what’s a quick way to clean that up, since I think most of them are unimportant?\nWe are also struggling with the “leader not found” problem still, it seems to happen when Weaviate has been idle for a while, and suddenly wakes up.\n\n----------\n\n[Stefan_Edlund (2024-12-16T21:40:04.314Z)]: One thing we’re trying to do is deleting collections from the file system (mounted on /var/lib/weaviate), but Weaviate keeps recreating them. How can we prevent that?\n\n----------\n\n[DudaNogueira (2024-12-17T15:00:54.527Z)]: hi @Stefan_Edlund !!\nDeleting from the file system is not advisable \nYou can try increasing the readiness probes on k8s, allowing Weaviate enough time to start up. Because of the number of collections and resource allocated, it can take quite some time.\nThen you clear all collections you can, deleting them using the client, not remove from filesystem.\nOnce you cluster is up, running and stable, you’ll need to spin up a new cluster, using latest version, and migrate your data using multi tenancy.\nSo now each customer collection, let’s say, Customer1234, will be come a tenant id 1234 in the collection Customer for example.\nYou then change your code to initialize the collection with the given tenant.\nLet me know if this helps.\nThanks!\n\n----------\n\n[Stefan_Edlund (2024-12-18T18:20:22.260Z)]: Following your advice, I wrote a python script deleting the unwanted collections. We have about 6000 of them.\nIt took about 30 seconds per deletion (!), and after some time it crashed and restarted (possibly due to liveness probe). When it came back up again the collections deleted were re-created :(.\n\n----------\n\n[DudaNogueira (2024-12-18T19:13:58.681Z)]: They were recreated? \nWith all the same content inside?\nThat doesn’t make sense.\nPlease, if possible, can you reach out to me in our public slack?\nhttps://weaviate.io/slack\nThat way I can take a closer look on it.\nThanks!\n\n----------\n\n[Stefan_Edlund (2024-12-21T02:57:21.165Z)]: Hi,\nthe application is in a maintenance mode, but it’s still popular and we want to keep it up.\nWe were able to get rid of the unwanted collections by disabling the liveness probe and running a script deleting them. We are not sure if the collections will be recreated again when Weaviate restarts.\nIt’s a temporary solution, but for now we’re okay.\nThanks for the help.\n\n----------\n\n[DudaNogueira (2024-12-21T14:48:31.599Z)]: Great!\nLet me know when there is any issue where we can help!\nThanks for using Weaviate",
    "date_created": "2024-12-12T22:30:19.884Z",
    "has_accepted_answer": true,
    "title": "Weaviate error \"transferring leadership\" on single node cluster",
    "topic_id": 9207
  },
  {
    "user_id": 261,
    "conversation": "[Sungwon_Jung (2023-08-29T09:49:31.809Z)]: Hello!\nIt might vary depending on the case, but if I’m looking to manage 5 billion 32-dimensional embeddings, is it okay to operate Weaviate using docker-compose in a multi-node setup for a production environment?\nThank you.\n\n----------\n\n[DudaNogueira (2023-08-29T14:25:13.022Z)]: Hi @Sungwon_Jung ! Welcome to our Community \nThat should work. 5 bilion is a lot of vectors, so you will need some beefy hardware \nWe also have a helm chart in case you want to use K8s:\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nGitHub - weaviate/weaviate-helm: Helm charts to deploy Weaviate to k8s\n\n  Helm charts to deploy Weaviate to k8s. Contribute to weaviate/weaviate-helm development by creating an account on GitHub.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI have answered a similar question here, but with isolated containers:\n  \n    \n    \n    Can only Docker Compose be used for multi node deployment? Support\n  \n  \n    Hi @codehelen ! Welcome to our community  \nThis must be some networking issue along the way, as your docker is correct (see below) \nA starting point is making sure that weaviate-node2-IP can communicate with weaviate-node1-IP on all specified ports. \nA good example on how to run with ad-hoc containers (at the same docker host): \nFirst, create a docker attachable network\ndocker network create weaviate --atachable\n\nnote that weaviate, above, can be whatever network name you want. Mak…\n  \n\n\nLet me know if this helps \nThanks!\n\n----------\n\n[Sungwon_Jung (2023-08-29T15:47:16.251Z)]: Hi, @DudaNogueira\nK8s cannot be used, so it seems that we need to operate with docker-compose using a multi-node setup.\nI will test further whether docker-compose with multi-node can be used in a production environment.\nThank you.\n\n----------\n\n[davide.mietto (2025-03-29T09:32:16.855Z)]: Hello you was able to create a weaviate cluster without K8S in production ?\n\n----------\n\n[DudaNogueira (2025-03-31T14:02:29.401Z)]: hi @davide.mietto !\nI have answered this question here:\n  \n    \n    \n    Production Cluster weaviate multinode without K(S Support\n  \n  \n    hi @davide.mietto !! \nHi! \nWe do have here a docker compose example for 3 nodes: \n\n\nLet me know if this helps. \nTHanks!\n  \n\n\nThanks!",
    "date_created": "2023-08-29T09:49:31.763Z",
    "has_accepted_answer": true,
    "title": "Docker-compose with multi-node setup on production environment",
    "topic_id": 588
  },
  {
    "user_id": 434,
    "conversation": "[A_S (2024-10-01T12:52:42.262Z)]: If you have a list that contains sentences [“Dorthraki language”, “Ktulhu Monster lives in”] and you are searching for text chunk with the operator ContainsAny, is it supposed to match the text chunks only if the full phrase is in the text or also if the text contains a partial match for the string in the list? (like the text chunk doesn’t contain “Dorthraki language” but contains the word “Dorthraki”, is it supposed to match?)\nThanks!\n\n----------\n\n[DudaNogueira (2024-10-01T16:00:32.457Z)]: hi @A_S !! Welcome back \nThe behavior will depend on what is the tokenization you have for that specific property.\nby default, the tokenization is word. This means that for the query you are running, it should match to all word tokens dorthraki language ktulhu``monster (in is a stop word)\nWith that said, consider this code:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n    properties=[\n        wvc.config.Property(\n            name=\"text_word\", data_type=wvc.config.DataType.TEXT, tokenization=wvc.config.Tokenization.WORD,\n        ),\n        wvc.config.Property(\n            name=\"text_field\", data_type=wvc.config.DataType.TEXT, tokenization=wvc.config.Tokenization.FIELD\n        )\n    ]\n)\ncollection.data.insert({\"text_word\": \"Dorthraki language here\", \"text_field\": \"Dorthraki language\"})\ncollection.data.insert({\"text_word\": \"Ktulhu language Dorthraki\", \"text_field\": \"Ktulhu language Dorthraki\"})\n\nnow, when I do a contains any on the text_field that has the field tokenization property, I will find one result, like this:\ncollection.aggregate.over_all(\n    filters=wvc.query.Filter.by_property(\"text_field\").contains_any([\"Dorthraki language\"])\n)\n\n\nAggregateReturn(properties={}, total_count=1)\n\nwhile if I do the same query, but on the text_word property, you will find both objects:\ncollection.aggregate.over_all(\n    filters=wvc.query.Filter.by_property(\"text_word\").contains_any([\"Dorthraki language\"])\n)\n\n\nAggregateReturn(properties={}, total_count=2)\n\nWe have some extensive material on tokenization. Check this out:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nOverview of tokenization | Weaviate\n\n  Tokenization is the process of breaking text into smaller units, called tokens. This is an important step that impacts how text is processed in a variety of contexts.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nand here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\n275 (Keyword) Tokenization | Weaviate\n\n  Course overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps\n\n----------\n\n[A_S (2024-10-02T09:10:16.953Z)]: Thank you! That explained a lot!",
    "date_created": "2024-10-01T12:52:42.211Z",
    "has_accepted_answer": true,
    "title": "How does the filter ContainsAny and ContainsAll work?",
    "topic_id": 4384
  },
  {
    "user_id": 2428,
    "conversation": "[Marco_Vinicius_Nobre (2024-11-27T17:29:36.152Z)]: Description\nHi!\nI have been using the graphql api for iteracting with my weaviate db and currently I have included a colleciton with named vectors. However, I can not find anywhere on how can I get the named vector of an object in weaviate.\nFor example, to get the vector normally I would run:\n{\nGet{\nCollection{\n_additional{\nvector\n}\n}\n}\n}\nHowever, when I have named vector, this vector results in an empty list\n\n----------\n\n[DudaNogueira (2024-11-28T12:10:24.114Z)]: hi @Marco_Vinicius_Nobre !!\nWhen using named vectors, they will be exposed in vectors while using graphql.\nConsidering you have two named vectors, v1 and v2, this is how you can get them:\n{\n\tGet{\n\t\tTest{\n\t\t\t_additional{\n\t\t\t\tvectors{\n\t\t\t\t\tv1 v2\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Marco_Vinicius_Nobre (2024-11-28T12:29:45.089Z)]: Hi Duda! I guess this would be the ideal way, but when I run it says it doesn´t exists this “vectors” key. It only exists “vector” and it is a list of float, so you can´t  have a subselection.\nFor example, with vector\n{\n    Get{\n        LocalTest{\n            _additional{\n                vector{\n                    v1\n                }\n            }\n        }\n    }\n}\n\nI get the following error\nimage732×286 3.99 KB\nAnd with vectors\n{\n    Get{\n        LocalTest{\n            _additional{\n                vectors{\n                    v1\n                }\n            }\n        }\n    }\n}\n\nI get the following error\nCannot query field \"vectors\" on type \"LocalTestAdditional\". Did you mean \"vector\"?\nI did was able to workaround with the api key to list objects, but it´s less perfomant.",
    "date_created": "2024-11-27T17:29:36.106Z",
    "has_accepted_answer": false,
    "title": "Get named vectors in GraphQL",
    "topic_id": 8647
  },
  {
    "user_id": 4254,
    "conversation": "[Jixy (2025-03-07T08:38:46.627Z)]: Problem:\nI recently upgraded to Weaviate v4 and tried to integrate it with LangChain’s WeaviateVectorStore. However, I encountered an error stating that my client must be an instance of WeaviateClient. Additionally, I am using SemanticSimilarityExampleSelector for few-shot learning, which now fails due to this issue.\n\nMy Code (With Hidden Configurations):\nimport weaviate\nfrom weaviate.auth import AuthApiKey\nfrom langchain.prompts import FewShotPromptTemplate, PromptTemplate\nfrom langchain.prompts.example_selector import SemanticSimilarityExampleSelector\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\nfrom langchain_community.vectorstores import Weaviate\nfrom src.embedding import AliyunEmbedding\n\n# **Connect to Weaviate v4 Client**\nclient = weaviate.connect_to_custom(\n    http_host=\"my-server-ip\",\n    http_port=8080,\n    http_secure=False,\n    grpc_host=\"my-server-ip\",\n    grpc_port=50051,\n    grpc_secure=False,\n    auth_credentials=AuthApiKey(\"my-api-key\")\n)\n\n# **Initialize Embedding Model**\nembedding_model = AliyunEmbedding(dimensions=1024)\n\n# **Initialize Weaviate VectorStore**\nvectorstore = WeaviateVectorStore(\n    client=client,\n    index_name=\"CypherExamples\",  # ✅ Stores Cypher query examples\n    text_key=\"text\",\n    attributes=[],\n    embedding=embedding_model\n)\n\n# **Instantiate ExampleSelector**\nexample_selector = SemanticSimilarityExampleSelector.from_examples(\n    examples=[],  # ✅ Weaviate handles retrieval, so no examples are needed\n    vectorstore=vectorstore,\n    embeddings=embedding_model,  # ✅ Provide embeddings explicitly\n    vectorstore_cls=WeaviateVectorStore,  # ✅ Ensure correct vectorstore class\n    k=3  # ✅ Retrieve top 3 most relevant examples\n)\n\n---\n\n###Error Message:\nValueError: client must be an instance of WeaviateClient\n\n---\n\nAny guidance would be greatly appreciated!\n\n----------\n\n[DudaNogueira (2025-03-10T15:06:46.070Z)]: hi @Jixy !!\nYou need to pass the client, index_name and VectorStore class, so SemanticSimilarityExampleSelector instantiate it for you.\nI took the opportunity and wrote a recipe on this:\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/llm-agent-frameworks/langchain/example-selector-similarity...\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nexample_selector = SemanticSimilarityExampleSelector.from_examples(\n    # The list of examples available to select from.\n    examples,\n    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n    OpenAIEmbeddings(),\n    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n    WeaviateVectorStore,\n    client=client,\n    index_name=\"MyExamples\",\n    # The number of examples to produce.\n    k=1,\n)\nsimilar_prompt = FewShotPromptTemplate(\n    # We provide an ExampleSelector instead of examples.\n    example_selector=example_selector,\n    example_prompt=example_prompt,\n    prefix=\"Give the antonym of every input\",\n    suffix=\"Input: {adjective}\\nOutput:\",\n    input_variables=[\"adjective\"],\n)\n\nThis was crafted based doc in How to select examples by similarity | 🦜️🔗 LangChain\nLet me know if that helps!\nThanks!\n\n----------\n\n[Jixy (2025-03-10T15:23:54.029Z)]: thank you very much，it works and the problems have been solved",
    "date_created": "2025-03-07T08:38:46.584Z",
    "has_accepted_answer": true,
    "title": "Weaviate v4 Client not working with LangChain WeaviateVectorStore & ExampleSelector?",
    "topic_id": 11869
  },
  {
    "user_id": 397,
    "conversation": "[asido (2024-07-18T15:36:54.725Z)]: I believe there is a bug in object replace.\nI have a collection that contains both vectorized and non-vectorized fields (set with skip_vectorization=True). When I call collection.data.replace, the object will only update if I change at least one of the vectorized fields.  If I perform a replace changing only non-vectorized fields, no update happens.\nServer Setup Information\n\nWeaviate Server Version: 1.25.6 (local) & 1.25.7 (WCS)\nDeployment Method: local docker & WCS\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python 4.6.5\nMultitenancy?: Yes\n\n----------\n\n[DudaNogueira (2024-07-18T17:52:59.392Z)]: hi @asido !!\nWelcome to our community \nI was not able to reproduce this.\nHere the code a crafted:\nimport weaviate\nfrom weaviate.util import generate_uuid5\nfrom weaviate import classes as wvc\n\nclient = weaviate.connect_to_local()\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    properties=[\n        wvc.config.Property(name=\"vectorized\", data_type=wvc.config.DataType.TEXT, skip_vectorization=False),\n        wvc.config.Property(name=\"non_vectorized\", data_type=wvc.config.DataType.TEXT, skip_vectorization=True)\n    ]\n)\n\n# now we insert an object\ncollection.data.insert({\"vectorized\": \"this should be vectorized\", \"non_vectorized\": \"this should not be vectorized\"}, uuid=generate_uuid5(\"example1\"))\n\n# now we replace the object\ncollection.data.replace(properties={\"non_vectorized\": \"changing here\"}, uuid=generate_uuid5(\"example1\"))\n\n# now we get the object\ncollection.query.fetch_objects().objects[0].properties\n\n#outputs\n#{'vectorized': None, 'non_vectorized': 'changing here'}\n\nPlease, let me know if this code is close to what you have crafted, or let me know how to reproduce this issue.\nThanks!\n\n----------\n\n[asido (2024-07-18T18:15:29.672Z)]: Hi Duga,\nThanks for the prompt reply. I am out of office hours now so will have to try to create a reproducible sample tomorrow, however the main difference I can see between our implementations is that I do the replace on the entire object, even if some of the fields didn’t change. In your case that would be:\ncollection.data.replace(properties={\"non_vectorized\": \"changing here\", \"vectorized\": \"this should be vectorized\"}, uuid=generate_uuid5(\"example1\"))\n\nI can’t confirm right now that this will reproduce it but maybe you could give it a try? Otherwise I will try tomorrow.\nMany thanks\n\n----------\n\n[asido (2024-07-19T14:10:02.643Z)]: Ok this turned out to be more awkward to narrow down than I expected and seems to require some rather odd specifics that maybe point to some other underlying issue?\nHere is a reproducible example:\nimport weaviate\nfrom weaviate.util import generate_uuid5\nfrom weaviate.classes import config as wvc\n\nclient = weaviate.connect_to_local(\n    headers={\"X-OpenAI-Api-Key\": \"<key>\"}\n)\n\n# Create the collection and explicitly set a vectorizer\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    vectorizer_config=(\n        wvc.Configure.Vectorizer.text2vec_openai(\n            model=\"ada\",\n            model_version=\"002\",\n        )\n    ),\n    properties=[\n        wvc.Property(name=\"non_vectorized\", data_type=wvc.DataType.TEXT, skip_vectorization=True),\n        wvc.Property(name=\"vectorized_text\", data_type=wvc.DataType.TEXT),\n        wvc.Property(name=\"vectorized_array\", data_type=wvc.DataType.TEXT_ARRAY)\n    ]\n)\n\n\nuuid = generate_uuid5(\"example1\")\n\n\n# Insert the new object\ndata = {\"non_vectorized\": \"Original Text\", \"vectorized_text\": \"Original Text\", \"vectorized_array\": []}\ncollection.data.insert(properties={**data}, uuid=uuid)\n\n# Replacing a non-vectorized property on its own does not work\nreplace_data = {**data, \"non_vectorized\": \"I Changed\"}\ncollection.data.replace(properties=replace_data, uuid=uuid)\nprint(collection.query.fetch_objects().objects[0].properties)\n\n# Replacing either vectorized property at the same time works\nreplace_data = {**data, \"vectorized_text\": \"I Changed\", \"non_vectorized\": \"I Changed\"}\ncollection.data.replace(properties=replace_data, uuid=uuid)\nprint(collection.query.fetch_objects().objects[0].properties)\n\nreplace_data = {**data, \"vectorized_array\": [\"I Changed\"], \"non_vectorized\": \"I Changed\"}\ncollection.data.replace(properties=replace_data, uuid=uuid)\nprint(collection.query.fetch_objects().objects[0].properties)\n\n\nHere is what makes this strange:\n\nIf I don’t explicitly set a vectorizer_config, this issue does not occur.\nIf I don’t have the text array in my schema, this issue does not occur.",
    "date_created": "2024-07-18T15:36:54.668Z",
    "has_accepted_answer": false,
    "title": "Bug in object replace",
    "topic_id": 3092
  },
  {
    "user_id": 219,
    "conversation": "[JLiz2803 (2025-01-06T23:29:57.023Z)]: Description\n\nWe are ingesting and chunking data from files, and are creating tens of thousands of tenants under a single weaviate class.  Our process runs fine for a short time, but weaviate eventually starts throwing disk quota exceeded errors.  AWS is telling me that Weaviate is creating locks on EFS files and not releasing them.\n{\"action\":\"hnsw_commit_log_condensing\",\"error\":\"open commit log to be condensed: open /var/lib/weaviate/catalogsearch/CatalogItem_BERT_MultiLingual_e5/main.hnsw.commitlog.d/1736210947: disk quota exceeded\",\"level\":\"error\",\"msg\":\"hnsw commit log maintenance (condensing) failed\",\"time\":\"2025-01-07T03:38:27Z\"}\n{\"action\":\"hnsw_commit_log_maintenance\",\"error\":\"stat /var/lib/weaviate/catalogsearch/CatalogItem_BERT_MultiLingual_e5/main.hnsw.commitlog.d/1736212133: use of closed file\",\"level\":\"error\",\"msg\":\"hnsw commit log maintenance failed\",\"time\":\"2025-01-07T03:38:28Z\"}\n\nUnexpectedStatusCodeError: Creating object! Unexpected status code: 500, with response body: {'error': [{'message': 'put object: import into index contractexcellence: put local object: shard=\"e0fc9bf8b418ce94ce0614609813b123f84dd9d4fc2c4a11c6b2214c6a0333ff\": flush prop length tracker to disk: open /var/lib/weaviate/contractexcellence/e0fc9bf8b418ce94ce0614609813b123f84dd9d4fc2c4a11c6b2214c6a0333ff/proplengths.tmp: disk quota exceeded'}]}.\nTraceback (most recent call last):\n  File \"/var/task/lib/python3.9/site-packages/gpai_document_ragification/handlers/rag_creation_event_lambda_handler.py\", line 10, in handle_s3_creation_event\n    to_return = HandlerModule.get_document_create_handler().handle_s3_event(event)\n  File \"/var/task/lib/python3.9/site-packages/gpai_document_ragification/handlers/document_handler.py\", line 32, in handle_s3_event\n    return self._handle_event(state_machine_input, document_rag_record)\n  File \"/var/task/lib/python3.9/site-packages/gpai_document_ragification/handlers/document_create_handler.py\", line 53, in _handle_event\n    self.save_chunks_to_vector_db(\n  File \"/var/task/lib/python3.9/site-packages/gpai_document_ragification/handlers/document_create_handler.py\", line 120, in save_chunks_to_vector_db\n    self.weaviate_proxy.save_object(\n  File \"/var/task/lib/python3.9/site-packages/gpai_document_ragification/proxy/weaviate_proxy.py\", line 26, in save_object\n    self.weaviate_client.data_object.create(\n  File \"/var/task/lib/python3.9/site-packages/weaviate/data/crud_data.py\", line 160, in create\n    raise UnexpectedStatusCodeException(\"Creating object\", response)\n\n{\"action\":\"hnsw_commit_log_maintenance\",\"error\":\"stat /var/lib/weaviate/catalogsearch/CatalogItem_BERT_MultiLingual_e5/main.hnsw.commitlog.d/1736212133: use of closed file\",\"level\":\"error\",\"msg\":\"hnsw commit log maintenance failed\",\"time\":\"2025-01-07T03:36:51Z\"}\n{\"action\":\"lsm_compaction\",\"class\":\"Contractexcellence\",\"error\":\"open /var/lib/weaviate/contractexcellence/9994450152d1268c6f6e6c64c10c31168b4d880906a69ce2bc6c410deeb3b22d/lsm/property_text_chunk/segment-1736207677691312573_1736210936799682015.db.tmp: disk quota exceeded\",\"index\":\"contractexcellence\",\"level\":\"error\",\"msg\":\"compaction failed\",\"path\":\"/var/lib/weaviate/contractexcellence/9994450152d1268c6f6e6c64c10c31168b4d880906a69ce2bc6c410deeb3b22d/lsm/property_text_chunk\",\"shard\":\"9994450152d1268c6f6e6c64c10c31168b4d880906a69ce2bc6c410deeb3b22d\",\"time\":\"2025-01-07T03:36:51Z\"}\n\nServer Setup Information\n\nWeaviate Server Version: 1.24.8\nDeployment Method: EKS on AWS\nMulti Node? Number of Running Nodes: 1 ECS Node\nClient Language and Version: PythonV3\nMultitenancy?: Yes\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2025-01-07T19:03:57.367Z)]: hi @JLiz2803 !!\nEBS volumes provide low-latency, high-performance block storage that is optimized for fast read and write operations. Weaviate requires quick access to vector data and other storage, where high throughput and low latency are crucial, especially for high-query workloads. EFS, on the other hand, is a network file system, which inherently has higher latency due to network overhead and doesn’t support the same high-performance requirements efficiently. Also, EBS volumes offer consistent, predictable performance, which is critical for a database like Weaviate that relies on intensive I/O operations.\nCan you try this same scenario on EBS?\nThanks!\n\n----------\n\n[JLiz2803 (2025-01-07T19:24:28.819Z)]: Hi Duda,\nThanks for your reply.  In the beginning we were using EBS, but due to scaling needs we switched over to EFS to take advantage of the autoscaling EFS offers which EBS does not.  We did so per the weaviate documentation recommendation: Kubernetes | Weaviate\nIt would now be a big, and costly, effort to switch back to EBS as we would have to backfill millions of records, and over scale our storage instance, given the static nature of EBS, to accommodate our needs.\nIs it Weaviate’s reccomendation not to use EFS, but rather use EBS?\n\n----------\n\n[JLiz2803 (2025-01-08T22:13:04.309Z)]: I was able to confirm with the AWS EFS team that Weaviate, for some reason, is opening up 65K+ files and holding locks on them with EFS. This is causing us to reach the limits of EFS and causing our weaviate instance to start failing.\n\n----------\n\n[DudaNogueira (2025-01-10T11:04:50.247Z)]: hi!\nIn cases where there is a limit on the machine running Weaviate, on this case the locks for EFS, the recommended way to avoid this is using more nodes.\nWhile our team is constantly working on improving Weaviate resource usages, adding more nodes and distributing to different nodes is the way to go.\nAlso, tenant offload can help here, as you can offload tenants not being actively used:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage tenant states & temperature | Weaviate\n\n  Manage tenant states in Weaviate to support multitenancy and secure data separation.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nUpgrade will also help, as you can leverage the latest improvements on file and memory management",
    "date_created": "2025-01-06T23:29:56.974Z",
    "has_accepted_answer": false,
    "title": "Weaviate Holding Locks on EFS Files Causing disk quota exceeded Errors",
    "topic_id": 9598
  },
  {
    "user_id": 3157,
    "conversation": "[nemozak1 (2025-01-07T10:59:07.574Z)]: Description\nHi I am trying to add the following swagger schema for an API endpoint using python client v4:\n{'tags': ['Account'],\n 'summary': 'Update Account',\n 'security': [{'directLogin': [], 'gatewayLogin': []}],\n 'description': '\\n\\nUpdate the account.\\n\\nAuthentication is Mandatory\\n\\n**URL Parameters:**\\n\\n[ACCOUNT\\\\_ID](/glossary#Account.account_id): 8ca8a7e4-6d02-40e3-a129-0b2bf89de9f0\\n\\n[BANK\\\\_ID](/glossary#Bank.bank_id): gh.29.uk\\n\\n**JSON response body fields:**\\n\\n[**account\\\\_id**](/glossary#): 8ca8a7e4-6d02-40e3-a129-0b2bf89de9f0\\n\\n[**account\\\\_routings**](/glossary#account_routings):\\n\\n[**address**](/glossary#address):\\n\\n[**bank\\\\_id**](/glossary#): gh.29.uk\\n\\n[**branch\\\\_id**](/glossary#): DERBY6\\n\\n[**label**](/glossary#): My Account\\n\\n[**scheme**](/glossary#scheme): OBP\\n\\n[**type**](/glossary#type):\\n\\n',\n 'operationId': 'OBPv3.1.0-updateAccount',\n 'parameters': [{'in': 'body',\n   'name': 'body',\n   'description': 'JObject object that needs to be added.',\n   'required': True,\n   'schema': {'type': 'object',\n    'properties': {'label': {'type': 'string', 'example': 'Label'},\n     'type': {'type': 'string', 'example': 'CURRENT'},\n     'branch_id': {'type': 'string', 'example': '1234'},\n     'account_routings': {'type': 'array',\n      'items': {'type': 'object',\n       'properties': {'scheme': {'type': 'string', 'example': 'OBP'},\n        'address': {'type': 'string',\n         'example': '8ca8a7e4-6d02-40e3-a129-0b2bf89de9f0'}},\n       'required': ['scheme', 'address']}}},\n    'required': ['label', 'type', 'branch_id', 'account_routings']}},\n  {'in': 'path',\n   'name': 'ACCOUNT_ID',\n   'description': 'The account id',\n   'required': True,\n   'type': 'string'},\n  {'in': 'path',\n   'name': 'BANK_ID',\n   'description': 'The bank id',\n   'required': True,\n   'type': 'string'}],\n 'responses': {'ok_200': {'description': 'Success',\n   'schema': {'type': 'object',\n    'properties': {'bank_id': {'type': 'string', 'example': 'gh.29.uk'},\n     'account_id': {'type': 'string',\n      'example': '8ca8a7e4-6d02-40e3-a129-0b2bf89de9f0'},\n     'label': {'type': 'string', 'example': 'Label'},\n     'type': {'type': 'string', 'example': 'CURRENT'},\n     'branch_id': {'type': 'string', 'example': '1234'},\n     'account_routings': {'type': 'array',\n      'items': {'type': 'object',\n       'properties': {'scheme': {'type': 'string', 'example': 'IBAN'},\n        'address': {'type': 'string',\n         'example': 'DE91 1000 0000 0123 4567 89'}},\n       'required': ['scheme', 'address']}}},\n    'required': ['bank_id',\n     'account_id',\n     'label',\n     'type',\n     'branch_id',\n     'account_routings']}},\n  'badRequest_400': {'description': 'Error',\n   'schema': {'properties': {'message': {'type': 'string',\n      'example': 'OBP-10001: Incorrect json format.'}}}}}}\n\nusing\ntest_collection.data.insert(\n                    properties = endpoint_object,\n                    uuid=endpoint_uuid\n                )\n\nand get the following error from the client:\nUnexpectedStatusCodeError: Object was not added! Unexpected status code: 422, with response body: {'error': [{'message': \"invalid object: invalid object property 'responses' on class 'Test': property 'responses.ok_200': invalid object property 'responses.ok_200' on class 'Test': property 'responses.ok_200.schema': invalid object property 'responses.ok_200.schema' on class 'Test': property 'responses.ok_200.schema.properties': invalid object property 'responses.ok_200.schema.properties' on class 'Test': property 'responses.ok_200.schema.properties.account_routings': invalid object property 'responses.ok_200.schema.properties.account_routings' on class 'Test': property 'responses.ok_200.schema.properties.account_routings.items': invalid object property 'responses.ok_200.schema.properties.account_routings.items' on class 'Test': property 'responses.ok_200.schema.properties.account_routings.items.properties': invalid object property 'responses.ok_200.schema.properties.account_routings.items.properties' on class 'Test': property 'responses.ok_200.schema.properties.account_routings.items.properties.address': invalid object property 'responses.ok_200.schema.properties.account_routings.items.properties.address' on class 'Test': property 'responses.ok_200.schema.properties.account_routings.items.properties.address.example': invalid uuid property 'responses.ok_200.schema.properties.account_routings.items.properties.address.example' on class 'Test': requires a string of UUID format, but the given value is 'DE91 1000 0000 0123 4567 89'\"}]}.\n\nThe key bit of that being invalid uuid property 'responses.ok_200.schema.properties.account_routings.items.properties.address.example' on class 'Test': requires a string of UUID format, but the given value is 'DE91 1000 0000 0123 4567 89'\"}]}.\nFor some reason it is not liking what I’ve given as my example for address i.e.\n 'properties': {'scheme': {'type': 'string', 'example': 'IBAN'},\n        'address': {'type': 'string',\n         'example': 'DE91 1000 0000 0123 4567 89'}},\n       'required': ['scheme', 'address']}}},\n\nI can’t change this to UUID as it encodes a an IBAN bank account address (not a real one don’t get any ideas.\nAny clue why this is happening and how to ovveride this UUID checking? I thought maybe address might be a reserved name or something but I can’t find that anywhere.\nServer Setup Information\n\nWeaviate Server Version: 1.28.2\nDeployment Method: docker\nClient Language and Version: python3\n\nAny additional Information\nI’ll include my docker-compose.yaml file here for completion:\n---\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_API_BASED_MODULES: 'true'\n      ENABLE_MODULES: 'text2vec-ollama,generative-ollama'\n      CLUSTER_HOSTNAME: 'node1'\nvolumes:\n  weaviate_data:\n...\n\n----------\n\n[DudaNogueira (2025-01-07T14:54:10.411Z)]: hi @nemozak1 !!\nWelcome to our community \nindeed, you can only pass a UUID as a parameter.\nYou can always generate a UUID from that value:\nfrom weaviate.utils import generate_uuid\ngenerated_uuid = generate_uuid(endpoint_uuid)\n\ntest_collection.data.insert(\n                    properties = endpoint_object,\n                    uuid=generated_uuid\n                )\n\nLet me know if this works for you.\nThanks!\n\n----------\n\n[nemozak1 (2025-01-07T15:35:46.501Z)]: I’m already doing that actually:\nprops = properties.copy()\n            \n            # Summarize the description of the endpoint in markdown\n            #summary_chain_response = endpoint_summary_chain.invoke({\"raw_description\": properties['description']})\n            #props['description'] = summary_chain_response.content\n            \n            #endpoint_object = {\"path\": path, \"method\": method, \"tags\": props[\"tags\"], \"schema\": str(props)}\n            endpoint_object = props\n\n            # Change the description from HTML to markdown format\n            props['description'] = md(props['description'])\n            # Generate deterministic UUID from OperationID\n            endpoint_uuid = generate_uuid5(props['operationId'])\n\n            #Weaviate does not like straight response codes as object keys i.e. 200 or 404 so we need to change that\n            responses_with_new_keys = {}\n            for response_code, response_schema in endpoint_object['responses'].copy().items():\n                \n                stringified_response_code = response_code_to_string(int(response_code)) \n                \n                responses_with_new_keys[stringified_response_code] = response_schema\n\n            # Replace all keys\n            endpoint_object['responses'] = responses_with_new_keys\n            \n            \n            documents.append(endpoint_object)\n\n            if not test_collection.data.exists(endpoint_uuid):\n                test_collection.data.insert(\n                    properties = endpoint_object,\n                    uuid=endpoint_uuid\n                )\n\nthe problem is with a specific property having an example. Weaviate thinks this should be in UUID format but it shouldn’t as it’s an IBAN\n\n----------\n\n[DudaNogueira (2025-01-07T18:52:56.080Z)]: Hi!\nCan you give a MRE (minimum reproducible example)?\nHere is what I got:\nfrom weaviate.util import generate_uuid5\n\nendpoint_uuid = generate_uuid5(\"some unique text\")\n\nschema = {'tags': ['Account'],\n 'summary': 'Update Account',\n 'security': [{'directLogin': [], 'gatewayLogin': []}],\n 'description': '\\n\\nUpdate the account.\\n\\nAuthentication is Mandatory\\n\\n**URL Parameters:**\\n\\n[ACCOUNT\\\\_ID](/glossary#Account.account_id): 8ca8a7e4-6d02-40e3-a129-0b2bf89de9f0\\n\\n[BANK\\\\_ID](/glossary#Bank.bank_id): gh.29.uk\\n\\n**JSON response body fields:**\\n\\n[**account\\\\_id**](/glossary#): 8ca8a7e4-6d02-40e3-a129-0b2bf89de9f0\\n\\n[**account\\\\_routings**](/glossary#account_routings):\\n\\n[**address**](/glossary#address):\\n\\n[**bank\\\\_id**](/glossary#): gh.29.uk\\n\\n[**branch\\\\_id**](/glossary#): DERBY6\\n\\n[**label**](/glossary#): My Account\\n\\n[**scheme**](/glossary#scheme): OBP\\n\\n[**type**](/glossary#type):\\n\\n',\n 'operationId': 'OBPv3.1.0-updateAccount',\n 'parameters': [{'in': 'body',\n   'name': 'body',\n   'description': 'JObject object that needs to be added.',\n   'required': True,\n   'schema': {'type': 'object',\n    'properties': {'label': {'type': 'string', 'example': 'Label'},\n     'type': {'type': 'string', 'example': 'CURRENT'},\n     'branch_id': {'type': 'string', 'example': '1234'},\n     'account_routings': {'type': 'array',\n      'items': {'type': 'object',\n       'properties': {'scheme': {'type': 'string', 'example': 'OBP'},\n        'address': {'type': 'string',\n         'example': '8ca8a7e4-6d02-40e3-a129-0b2bf89de9f0'}},\n       'required': ['scheme', 'address']}}},\n    'required': ['label', 'type', 'branch_id', 'account_routings']}},\n  {'in': 'path',\n   'name': 'ACCOUNT_ID',\n   'description': 'The account id',\n   'required': True,\n   'type': 'string'},\n  {'in': 'path',\n   'name': 'BANK_ID',\n   'description': 'The bank id',\n   'required': True,\n   'type': 'string'}],\n 'responses': {'ok_200': {'description': 'Success',\n   'schema': {'type': 'object',\n    'properties': {'bank_id': {'type': 'string', 'example': 'gh.29.uk'},\n     'account_id': {'type': 'string',\n      'example': '8ca8a7e4-6d02-40e3-a129-0b2bf89de9f0'},\n     'label': {'type': 'string', 'example': 'Label'},\n     'type': {'type': 'string', 'example': 'CURRENT'},\n     'branch_id': {'type': 'string', 'example': '1234'},\n     'account_routings': {'type': 'array',\n      'items': {'type': 'object',\n       'properties': {'scheme': {'type': 'string', 'example': 'IBAN'},\n        'address': {'type': 'string',\n         'example': 'DE91 1000 0000 0123 4567 89'}},\n       'required': ['scheme', 'address']}}},\n    'required': ['bank_id',\n     'account_id',\n     'label',\n     'type',\n     'branch_id',\n     'account_routings']}},\n  'badRequest_400': {'description': 'Error',\n   'schema': {'properties': {'message': {'type': 'string',\n      'example': 'OBP-10001: Incorrect json format.'}}}}}}\n\nendpoint_object = {\"path\": \"some_path\", \"method\": \"POST\", \"tags\": [\"tag1\", \"tag2\"], \"schema\": schema}\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n                \"Test\",\n                vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n    )\nendpoint_uuid = generate_uuid5(\"some unique text\")\ncollection.data.insert(\n    properties=endpoint_object\n)\n\nNote that, when passing the entire json as schema property, it gets mapped to object:\nfor p in collection.config.get().properties:\n    if p.name == \"schema\":\n        print(p.data_type)\n# DataType.OBJECT\n\nAnd that comes with some limitation:\n\nCurrently, object and object[] datatype properties are not indexed and not vectorized.\nFuture plans include the ability to index nested properties, for example to allow for filtering on nested properties and vectorization options.\n\nso for example, this is the payload that gets to be vectorized on this scenario:\n{\n  \"input\": [\n    \"Test POST some_path tag1 tag2\"\n  ],\n  \"model\": \"text-embedding-3-small\",\n  \"dimensions\": 1536\n}\n\nLet me know if this helps.\nThanks!\n\n----------\n\n[Dirk (2025-01-08T07:02:38.392Z)]: Can you please post your collection definition?\n    config = collection.config.get()\n    print(config.properties)\n\n----------\n\n[nemozak1 (2025-01-09T11:18:30.675Z)]: My config is extremely long with lots of nested properties. I guess that this is part of the problem with putting in a JSON schema like this\n_CollectionConfig(name='Test', description=None, generative_config=_GenerativeConfig(generative=<GenerativeSearches.OPENAI: 'generative-openai'>, model={}), inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='description', description=\"This property was generated by Weaviate's auto-schema feature on Mon Jan  6 20:23:55 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-openai'), _Property(name='operationId', description=\"This property was generated by Weaviate's auto-schema feature on Mon Jan  6 20:23:55 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-openai'), _Property(name='parameters', description=\"This property was generated by Weaviate's auto-schema feature on Mon Jan  6 20:23:55 2025\", data_type=<DataType.OBJECT_ARRAY: 'object[]'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=[_NestedProperty(data_type=<DataType.TEXT: 'text'>, description=\"This nested property was generated by Weaviate's auto-schema feature on Mon Jan  6 20:23:55 2025\", index_filterable=True, index_searchable=True, name='name', nested_properties=None, tokenization=<Tokenization.WORD: 'word'>), _NestedProperty(data_type=<DataType.TEXT: 'text'>, description=\"This nested property was generated by Weaviate's auto-schema feature on Mon Jan  6 20:23:55 2025\", index_filterable=True, index_searchable=True, name='description', nested_properties=None, tokenization=<Tokenization.WORD: 'word'>), \n\n… etc. (with more nested properties)\n\n----------\n\n[Dirk (2025-01-09T12:27:13.127Z)]: I’d only need the problematic property, eg properties.account_routings.items.properties.address.example. The rest doesn’t matter\n\n----------\n\n[Rohini_vaidya (2025-03-01T06:31:20.872Z)]: While generating deterministic uuid is it required to add namespace also.\nor we can skip the namespace parameter ?\nfrom weaviate.util import generate_uuid5\nNAMESPACE = “ABC”\nSame GUID inserted twice\ndata = [{“GUID”: “123”}, {“GUID”: “123”}]\nfor item in data:\nuuid = generate_uuid5(identifier=item[“GUID”], namespace=NAMESPACE)\nprint(uuid)\nWhat is ideal way to generte deterministic UUID ?\n\n----------\n\n[DudaNogueira (2025-03-01T19:09:03.138Z)]: Hi! the namespace is optional.\nYou an use:\ngenerate_uuid5(item[“GUID”])",
    "date_created": "2025-01-07T10:59:07.514Z",
    "has_accepted_answer": false,
    "title": "Weaviate requires a string of UUID format when adding json Schema",
    "topic_id": 9606
  },
  {
    "user_id": 2415,
    "conversation": "[ant0 (2024-10-30T13:13:26.933Z)]: Description\n\nHi All,\nI’m trying to get started with a sandbox I’ve created but due to the way Zscaler is set up in my org, I’m not able to successfully create a weaviate client.\njust following the quick setup tutorial, using the following code:\nclient = weaviate.connect_to_weaviate_cloud(\ncluster_url=wcd_url,\nauth_credentials=Auth.api_key(wcd_api_key)\n)\nIs there any way I can connect to my sandbox (or any weaviate cloud instance) without SSL verification? I’ve tried setting custom certs in my environment, but nothing really seems to work.\nI noticed there was a PR somewhere that attempted to add an “SSL verify false” function to the AdditionalConfig, but it doesn’t seem to be in the release version yet? Are there any other work arounds?\nThanks in advance!\n\n----------\n\n[DudaNogueira (2024-10-30T13:24:17.316Z)]: Hi @ant0 !!\nWelcome to our community \nIndeed, we have faced this issue in the past with other users and tried to bypass the ssl verification, but this was not possible for the grpc calls, as far as I recall.\nThe underlying problem is that httpx, that is used by ou python client relies on certifi in order to provide the Root CA certs.\nAnd certifi “provides Mozilla’s carefully curated collection of Root Certificates for validating the trustworthiness of SSL certificates while verifying the identity of TLS hosts. It has been extracted from the Requests project.”\nSo when you have a SSL Proxy for eg. Zscaler, the client will not get the Root CA from OS certificate store, but use this curated collection from certifi, causing the certificate invalid error.\nThe solution, for now, is to “monkey patch” certifi Root CA certificates with your custom one, as stated here:\n\n  \n\n      help.zscaler.com\n  \n\n  \n    \n\nAdding Custom Certificate to an Application Specific Trust Store | Zscaler\n\n  How to add a custom certificate to an application-specific trust store.\n\n----------\n\n[ant0 (2024-10-30T13:29:23.719Z)]: I’ll try this again and see if it works. Thanks for the support!",
    "date_created": "2024-10-30T13:13:26.886Z",
    "has_accepted_answer": false,
    "title": "SSL errors due to Zscaler",
    "topic_id": 7334
  },
  {
    "user_id": 427,
    "conversation": "[Sandip (2024-03-05T11:42:58.208Z)]: I’m creating an index in Weaviate named “sample_index” and populating it with the following content and vectors:\ncontent1 = [\n    {\n        \"title\": \"title1\",\n        \"article_id\": \"id1\"\n    },\n    {\n        \"title\": \"title2\",\n        \"article_id\": \"id2\"\n    }\n]\n\nvector1 = {\n    \"id1\": [0.1, 0.2],\n    \"id2\": [0.3, 0.4]\n}\n\nNow, when attempting to push another set of data into the same “sample_index” class, I encounter an error due to the varying vector sizes:\ncontent2 = [\n    {\n        \"title\": \"title1\",\n        \"article_id\": \"id1\"\n    },\n    {\n        \"title\": \"title2\",\n        \"article_id\": \"id2\"\n    }\n]\n\nvector2 = {\n    \"id3\": [0.1, 0.2, 0.3, 0.4],\n    \"id4\": [0.5, 0.6, 0.7, 0.8]\n}\n\nThe error message states:\n{'error': [{'message': \"insert to vector index: insert doc id 3 to vector index: find best entrypoint: calculate distance between insert node and entry point at level 1: vector lengths don't match: 2 vs 4\"}]}\n{'error': [{'message': \"insert to vector index: insert doc id 4 to vector index: find best entrypoint: calculate distance between insert node and entry point at level 1: vector lengths don't match: 2 vs 4\"}]}\n\nAlthough the error occurs, the new data seems to be indexed in the “sample_index” class, as observed when attempting to extract all \"article_id\"s from the index.\nTo avoid this scenario, it’s essential to validate the vector size or schema before indexing the data. This can be achieved by implementing a validation step prior to indexing, ensuring that all vectors adhere to the expected size and format. By enforcing consistent vector dimensions across the index, such errors can be prevented.\nDoes anyone have suggestions on how to effectively manage such discrepancies in vector sizes within Weaviate indexing? Any insights or best practices would be greatly appreciated. Thank you.\n\n----------\n\n[DudaNogueira (2024-03-05T14:12:01.361Z)]: Hi! it does check for dimensional consistency.\ncheck this code, for instance:\nimport weaviate\nclient = weaviate.connect_to_local()\nclient.collections.delete(\"MyCollection\")\ncollection = client.collections.create(\"MyCollection\")\ncollection.data.insert({\"name\": \"Duda\"}, vector=[1,2,3,4, 5])\ncollection.data.insert({\"name\": \"Bob\"}, vector=[1,2,3,4,5,6,7,8,9,10])\n\nit will raise this error:\nUnexpectedStatusCodeError: Object was not added! \nUnexpected status code: 500, with response body: \n{'error': [{'message': 'put object: import into index mycollection: put local object: shard=\"lKNQZjKZzAke\": Validate vector index for 2050d246-e87a-4147-a58c-56073f4e607e: new node has a vector with length 10. Existing nodes have vectors with length 5'}]}.\n\nInteresting part: new node has a vector with length 10. Existing nodes have vectors with length 5\nCan you share the code on how you are providing the vectors yourself? Maybe you are never passing the vector, so it’s not raising this same error.\nThanks!\n\n----------\n\n[Sandip (2024-03-05T14:51:56.064Z)]: @DudaNogueira Thanks for your reply. I don’t use insert, I upload the add on content in batch using following code:\nimport weaviate\n\nclient = weaviate.Client(\"'http://localhost:8080'\")\n\nweaviate_class = \"sample_index\"\n\nclass_definition = {\n\t\"class\": weaviate_class\n}\n\nclient.schema.create_class(class_definition)\n\n# This is where I read the content1 first and content2 mentioned above\n# And also read vector for corresponding ids.\nbatch_size = 50\nwith client.batch as batch:\n\tbatch.batch_size = batch_size\n\tfor item in content:\n\t\tclient.batch.add_data_object(\n\t\t\t\tdata_object=item,\n\t\t\t\tvector=vectors[\"article_id\"],\n\t            class_name=weaviate_class,\n\t         )\n\n@DudaNogueira The way collection.data.insert handles this varying vector size condition, apparently client.batch.add_data_object doesn’t handle it.\n\n----------\n\n[Sandip (2024-03-06T08:22:04.717Z)]: Follow-up question: If I want to implement the vector size validation on my side before indexing new data existing class, is there any way to extract the vector size information from weaviate for already indexed data? I am looking into the schema for the current class using:\nschema = client.schema.get(weaviate_class)\nI am unable to find this vector size information in this object.\n\n----------\n\n[DudaNogueira (2024-03-06T11:51:25.335Z)]: Hi @Sandip\nIndeed it is not doing the dimensions check on batch imports, only in insert and insert_many. I was able to reproduce this. An issue in GH should follow soon.\nFor doing the validation yourself at the client level, you can fetch one object from that colection, asking to include its vectors, then you count the dimensions.\nLet me know if that helps.\n\n----------\n\n[Sandip (2024-03-08T09:01:58.481Z)]: Thanks @DudaNogueira , For now I have implemented the way you suggested, i.e. fetching vector size from the first record from weaviate class ‘sample_index’ using following code:\nvector_length = None\ndata_object = self.client.data_object.get(class_name=\"sample_index\", with_vector=True)\n        if data_object[\"objects\"]:\n            vector_length = len(data_object[\"objects\"][0][\"vector\"])\n\nI use this vector_length, which is 2 for my example for validation of future indexing operations.\n\n----------\n\n[DudaNogueira (2024-10-10T10:58:28.225Z)]: Hi!\nWeaviate is now checking for dimensions mismatch on batch imports!",
    "date_created": "2024-03-05T11:42:58.156Z",
    "has_accepted_answer": true,
    "title": "Handling Varying Vector Sizes in Weaviate Indexing: Ensuring Consistency and Error Prevention",
    "topic_id": 1626
  },
  {
    "user_id": 918,
    "conversation": "[jan-miksik (2024-07-20T16:10:14.309Z)]: Description\nHi, looking for any way how to deploy weaviate with django BE on internet. So far trying Railway service (https://railway.app/), but at this moment without much success.\nAll the things, django BE + Weaviate, works good on my local machine.\nAt the end I do not care that much about exact service provider, just looking for any functional and potencially easy to expand solution. BE can be on Railway and Weaviate on some other platform or any other combination or usage of diferent platform for deployment\nTodos:\nA) connect img2vec to weaviate\nB) connect weaviate to django BE\nA) connect img2vec to weaviate\nwith help chatGPT I create small github repo, to be albe deploy img2vec on Railway. It has basicly two files:\nDockerfile\nFROM cr.weaviate.io/semitechnologies/img2vec-pytorch:resnet50\nrailway.toml\n[build]\nbuilder = \"DOCKERFILE\"\ndockerfilePath = \"Dockerfile\"\n\n[deploy]\nstartCommand = \"python -m http.server 8080\"\n\nI was trying to setup public domain, because the internal does not work\nhttps://art-db-img2vec-production.up.railway.app/\nPort 8080\nBut the Railway service for Weaviate have in logs\nimg2vec-neural inference service not ready\nthe env variable in Weaviate service for IMAGE_INFERENCE_API is art-db-img2vec-production.up.railway.app:8080\nB) connect weaviate to django BE\nidealy keep the current v4 client, could be done with this, so far I did not make functional. First may need to resolve point A\n\nHow to support both grpc and http for a railway service? - Railway Help Station\nOne thing which is not clear to me is\nauth_credentials=AuthApiKey(os.getenv(\"WEAVIATE_API_KEY\")),\nin\n\nclient = weaviate.connect_to_custom(\n    http_host=os.getenv(\"WEAVIATE_URL\"),  # URL only, no http prefix\n    http_port=443,\n    http_secure=True,   # Set to True if https\n    grpc_host=os.getenv(\"WEAVIATE_GPC_URL\"),\n    grpc_port=443,      # Default is 50051, WCD uses 443\n    grpc_secure=True,   # Edit as needed\n    auth_credentials=AuthApiKey(os.getenv(\"WEAVIATE_API_KEY\")),\n)\n\nis this value mandatory?\none of the env varaibles in weaviate is\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\nwhat comes to my mind:\n\nrent some server and run all there (just do not have much experience with this)\nuse the Railway template and figure out how to connect all the services together. This may need create service for img2vec and connect to Weavieate service. Plus connect Weavite to djange BE\nrelated posts:\n\n\nClient V4 not instantiating with Railway template - several ports not supported (using v3 client)\nHow to support both grpc and http for a railway service? - Railway Help Station\n\n\nconnect all these things in some other way, based on chatgpt or Claude instruction for example\ntry to setup whole BE in one Railway service\n\nServer Setup Information\n\nWeaviate Server Version: http://cr.weaviate.io/semitechnologies/weaviate:1.24.7\nDeployment Method: railway template and docker for img2vec\nMulti Node? Number of Running Nodes: one node for Weaviate and one for img2vec-neural\nClient Language and Version: python, v4\nMultitenancy?: not sure, probably no?\n\nAny additional Information\nI am acctually not sure where to ask for help, it could be more related to Railway. I will keep trying to find solution on my own\n\n----------\n\n[DudaNogueira (2024-07-23T12:02:42.912Z)]: Hi there!\nI am a Django enthusiast my self   I was even thinking on an App that would help syncing a Django model to Weaviate, thru signals \nBut I have seen some database level integrations and not sure it would be the best approach \nAnyway, sorry my ignorance, but what is Django BE?\nIMHO, the best and safest, considering you will be deploying Weaviate yourself, is to run everything on the same network and only expose what is necessary (I believe Django, on this case).\nI am not familiar with railway \nFrom Weaviate side, you need to correctly expose both http and grpc endpoints and configure the client accordingly.\nIf you are using our hosted offerings, for example, we expose both http and grpc on the same port (443), but on different domains.\nso whenever you call connect_to_weaviate_cloud (or deprecated connect_to_wcs), the client will basically produce a connect_to_custom considering those values.\nthe same goes to connect_to_local, that will use the values you can find in our docker compose.\nFrom my experiences, those deployment automation tools are awesome, but will need some tweaking to get it all running.\nSo first I would make sure to make it work on a VPS, and from there, trying to replicate that deployment on, for example, Railway.\nLet me know if this helps!!\nThanks\n\n----------\n\n[jan-miksik (2024-07-28T16:06:24.785Z)]: Thanks for response\nDjango BE - shortcut for Django backend. I got it from the group where I work, so maybe more local dialect\nIn the end, I running the weaviate task locally and populating the postgres db with the data that weaviate would otherwise return. I’ll probably come back to this later for things where it will need to be more live\n\n----------\n\n[DudaNogueira (2024-07-29T18:28:50.988Z)]: Oh, great!\nI thought it was some app for Django \nLet me know if you need any help.\nThanks!",
    "date_created": "2024-07-20T16:10:14.239Z",
    "has_accepted_answer": false,
    "title": "How to deploy weaviate with django BE on internet - trying Railway",
    "topic_id": 3109
  },
  {
    "user_id": 617,
    "conversation": "[Grzegorz_Pasieka (2024-05-21T15:19:07.006Z)]: Description\n\nHello. Currently, our Weaviate instance has a stable number of vectors which is ~10,5 kk and is not increasing. However we are hitting storage limits because something constantly eating free space in our nodes.\nAt first glance it looks like some failures with operating HNSW commitlogs.\nimage1746×1508 342 KB\nThe disc usage growth look like linear\nimage3392×588 79.2 KB\nWe cannot find any useful logs about commit log cleanup failure\nServer Setup Information\n\nWeaviate Server Version: 1.24.14\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3 replicas x 2 shards\nClient Language and Version:\n\nAny additional Information\n\n----------\n\n[parkerduckworth (2024-05-21T21:14:59.735Z)]: Hey @Grzegorz_Pasieka thanks for raising this.\nIs this something that has only become a problem since upgrading to 1.24.14? Or has it persisted since pre-upgrade?\n\n----------\n\n[jeronimo_irazabal (2024-05-21T21:39:19.314Z)]: Grzegorz_Pasieka:\n\nAt first glance it looks like some failures with operating HNSW commitlogs.\n\n\nHi @Grzegorz_Pasieka, do you know which files are becoming bigger or created over time?\nThanks!\n\n----------\n\n[Grzegorz_Pasieka (2024-05-21T21:59:41.532Z)]: We have had those problems since v1.24.2, that’s why we decided to upgrade to 1.24.14 to check if it helps somehow.\n\n----------\n\n[Grzegorz_Pasieka (2024-05-21T22:01:11.651Z)]: jeronimo_irazabal:\n\nHi @Grzegorz_Pasieka, do you know which files are becoming bigger or created over time?\nThanks!\n\n\nI think main.hnsw.commitlog.d is becoming bigger in each shard\n\n----------\n\n[Grzegorz_Pasieka (2024-05-21T23:11:53.536Z)]: What is also worth mentioning is that one of my replicas constantly crashes because of goroutine panics:\n{\"level\":\"error\",\"msg\":\"Recovered from panic: assignment to entry in nil map\",\"time\":\"2024-05-21T22:52:45Z\"}\ngoroutine 7255736 [running]:\nruntime/debug.Stack()\n\t/usr/local/go/src/runtime/debug/stack.go:24 +0x5e\nruntime/debug.PrintStack()\n\t/usr/local/go/src/runtime/debug/stack.go:16 +0x13\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1.1()\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:30 +0x110\npanic({0x18b86a0?, 0x1fc9980?})\n\t/usr/local/go/src/runtime/panic.go:914 +0x21f\ngithub.com/weaviate/weaviate/adapters/repos/db/inverted.(*JsonPropertyLengthTracker).TrackProperty(0xc0fd697800, {0xc000124ea0, 0x7}, 0x42840000)\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/inverted/new_prop_length_tracker.go:181 +0x3c8\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).SetPropertyLengths(0xc000215000, {0xc0148948c0?, 0x7, 0x41a848?})\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_inverted_lsm.go:205 +0x8f\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).updateInvertedIndexLSM(0xc000215000, 0xc02fe30d20, {0x21084e6, 0x0, 0x0, 0x0, 0x0}, 0x0)\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_put.go:412 +0x38e\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).putObjectLSM(0xc000215000, 0xc02fe30d20, {0xc1023935a0, 0x10, 0x10})\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_put.go:288 +0x3cc\ngithub.com/weaviate/weaviate/adapters/repos/db.(*objectsBatcher).storeObjectOfBatchInLSM(0xc01be01080, {0x1fe7538, 0x2d8dbc0}, 0x0?, 0xc02fe30d20)\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_batch_objects.go:207 +0xd4\ngithub.com/weaviate/weaviate/adapters/repos/db.(*objectsBatcher).storeSingleBatchInLSM.func1()\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_batch_objects.go:177 +0x11a\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1()\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:34 +0x62\ncreated by github.com/weaviate/weaviate/entities/errors.GoWrapper in goroutine 7155590\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:25 +0x79\n{\"action\":\"commit_log_file_switched\",\"id\":\"main\",\"level\":\"info\",\"msg\":\"commit log size crossed threshold, switching to new file\",\"new_file_name\":\"1716332109\",\"old_file_name\":\"1716328911\",\"old_file_size\":105340363,\"time\":\"2024-05-21T22:55:09Z\"}\n{\"action\":\"hnsw_condensing\",\"level\":\"info\",\"msg\":\"start hnsw condensing\",\"time\":\"2024-05-21T22:55:09Z\"}\n{\"action\":\"hnsw_condensing_complete\",\"level\":\"info\",\"msg\":\"completed hnsw condensing\",\"time\":\"2024-05-21T22:55:11Z\"}\n{\"action\":\"hnsw_commit_logger_combine_condensed_logs\",\"id\":\"main\",\"input_first\":\"/var/lib/weaviate/aiskillv2/1efo8r43N3tC/main.hnsw.commitlog.d/1716246649.condensed\",\"input_second\":\"/var/lib/weaviate/aiskillv2/1efo8r43N3tC/main.hnsw.commitlog.d/1716328911.condensed\",\"level\":\"info\",\"msg\":\"successfully combined previously condensed commit log files\",\"output\":\"/var/lib/weaviate/aiskillv2/1efo8r43N3tC/main.hnsw.commitlog.d/1716246649\",\"time\":\"2024-05-21T22:55:14Z\"}\n{\"action\":\"hnsw_condensing\",\"level\":\"info\",\"msg\":\"start hnsw condensing\",\"time\":\"2024-05-21T22:55:14Z\"}\n{\"action\":\"hnsw_condensing_complete\",\"level\":\"info\",\"msg\":\"completed hnsw condensing\",\"time\":\"2024-05-21T22:55:39Z\"}\n\n----------\n\n[antas-marcin (2024-05-22T10:24:02.618Z)]: @Grzegorz_Pasieka we have pushed fixes for hnsw combining logic so if you are using v1.24.14 you should have all of them already deployed.\nDo you observe that your main.hnsw.commitlog.d is becoming already smaller in size?\n\n----------\n\n[Grzegorz_Pasieka (2024-05-22T14:46:42.285Z)]: @Grzegorz_Pasieka we have pushed fixes for hnsw combining logic so if you are using v1.24.14 you should have all of them already deployed.\nDo you observe that your main.hnsw.commitlog.d is becoming already smaller in size?\n\nWe are still observing this deployment however I can see another file size increase in the second shard of one of the replicas.\nimage1792×1560 353 KB\nAlso we constantly observe crashes in the first replica:\n{\"level\":\"error\",\"msg\":\"Recovered from panic: assignment to entry in nil map\",\"time\":\"2024-05-22T14:42:28Z\"}\ngoroutine 22835974 [running]:\nruntime/debug.Stack()\n\t/usr/local/go/src/runtime/debug/stack.go:24 +0x5e\nruntime/debug.PrintStack()\n\t/usr/local/go/src/runtime/debug/stack.go:16 +0x13\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1.1()\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:30 +0x110\npanic({0x18b86a0?, 0x1fc9980?})\n\t/usr/local/go/src/runtime/panic.go:914 +0x21f\ngithub.com/weaviate/weaviate/adapters/repos/db/inverted.(*JsonPropertyLengthTracker).TrackProperty(0xc0fd697800, {0xc000124ea0, 0x7}, 0x42a00000)\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/inverted/new_prop_length_tracker.go:181 +0x3c8\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).SetPropertyLengths(0xc000215000, {0xc048353dc0?, 0x7, 0x41a848?})\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_inverted_lsm.go:205 +0x8f\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).updateInvertedIndexLSM(0xc000215000, 0xc17759ec30, {0x212cc81, 0x0, 0x0, 0x0, 0x0}, 0x0)\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_put.go:412 +0x38e\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).putObjectLSM(0xc000215000, 0xc17759ec30, {0xc15ba27dc0, 0x10, 0x10})\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_put.go:288 +0x3cc\ngithub.com/weaviate/weaviate/adapters/repos/db.(*objectsBatcher).storeObjectOfBatchInLSM(0xc00449f300, {0x1fe7538, 0x2d8dbc0}, 0x0?, 0xc17759ec30)\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_batch_objects.go:207 +0xd4\ngithub.com/weaviate/weaviate/adapters/repos/db.(*objectsBatcher).storeSingleBatchInLSM.func1()\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_batch_objects.go:177 +0x11a\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1()\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:34 +0x62\ncreated by github.com/weaviate/weaviate/entities/errors.GoWrapper in goroutine 22408192\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:25 +0x79\n{\"action\":\"commit_log_file_switched\",\"id\":\"main\",\"level\":\"info\",\"msg\":\"commit log size crossed threshold, switching to new file\",\"new_file_name\":\"1716388985\",\"old_file_name\":\"1716388910\",\"old_file_size\":119471320,\"time\":\"2024-05-22T14:43:05Z\"}\n```\n\n----------\n\n[sebawita (2024-05-22T16:22:11.481Z)]: A post was split to a new topic: Adding removing objects with the same vectors\n\n----------\n\n[Grzegorz_Pasieka (2024-05-24T08:14:17.578Z)]: Today we noticed storage usage drops in each replica. Surprisingly it was not because of commit logs which are still growing, but objects in the second shard.\nimage1920×1041 316 KB\n\n----------\n\n[antas-marcin (2024-05-24T09:46:08.191Z)]: It’s great that the usage is decreasing and that the compaction works for objects. I think that I would be able to share with you a preview docker image with fixes that might help in your situation. I’m just now gathering all of it here internally, I can then share with you a preview image (that is built on top of v1.24)\n\n----------\n\n[Grzegorz_Pasieka (2024-05-27T12:04:53.269Z)]: we recorded another drop in storage usage in the first shard. We also performed migration process to 1.25.1 which I already described in another topic Panic after migration to 1.25.1\n\n----------\n\n[antas-marcin (2024-05-27T13:46:14.695Z)]: @Grzegorz_Pasieka I want to inform you also that we will be releasing tomorrow (the latest on Wednesday) new patch releases of v1.24 and v1.25 that will contain fixes that should improve your situation.\nWe have identified those bugs and we are now pushing all of the fixes to our code base, so please stay tuned. I will let you know once those patch releases will be ready.\n\n----------\n\n[Grzegorz_Pasieka (2024-06-03T12:49:27.339Z)]: Hi! Thanks for addressing the fixes in 1.25.2!\nToday we did the migration from 1.25.1 to 1.25.2 and currently non of our instances are healthy. we observe logs with “restoring snapshots” and then I/O timeouts, restarts and the same process again.\nimage3462×258 111 KB\n\n----------\n\n[Grzegorz_Pasieka (2024-06-24T15:35:39.822Z)]: Hi, @antas-marcin - currently after successfully migrating to 1.25.4 Our weaviate-0 replica is constantly crashing due to the following error:\nruntime/debug.Stack()\n\t/usr/local/go/src/runtime/debug/stack.go:24 +0x5e\nruntime/debug.PrintStack()\n\t/usr/local/go/src/runtime/debug/stack.go:16 +0x13\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1.1()\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:30 +0x110\npanic({0x19b6980?, 0x2116d40?})\n\t/usr/local/go/src/runtime/panic.go:914 +0x21f\ngithub.com/weaviate/weaviate/adapters/repos/db/inverted.(*JsonShardMetaData).TrackProperty(0xc2c850d280, {0xc0038567d0, 0x7}, 0x41e80000)\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/inverted/new_prop_length_tracker.go:218 +0x408\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).SetPropertyLengths(0xc002aa8280, {0xc1580d9500?, 0x7, 0x41a848?})\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_inverted_lsm.go:205 +0x95\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).updateInvertedIndexLSM(0xc002aa8280, 0xc0207e10e0, {0x249985d, 0x0, 0x0, 0x0, 0x0}, 0x0)\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_put.go:413 +0x38e\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).putObjectLSM(0xc002aa8280, 0xc0207e10e0, {0xc0e59d3ce0, 0x10, 0x10})\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_put.go:289 +0x3cc\ngithub.com/weaviate/weaviate/adapters/repos/db.(*objectsBatcher).storeObjectOfBatchInLSM(0xc1a195fa80, {0x2135e70, 0x2f6ca20}, 0xc1c126a460?, 0xc0207e10e0)\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_batch_objects.go:208 +0xd4\ngithub.com/weaviate/weaviate/adapters/repos/db.(*objectsBatcher).storeSingleBatchInLSM.func1()\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard_write_batch_objects.go:178 +0x11a\ngithub.com/weaviate/weaviate/entities/errors.GoWrapper.func1()\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:34 +0x62\ncreated by github.com/weaviate/weaviate/entities/errors.GoWrapper in goroutine 104762307\n\t/go/src/github.com/weaviate/weaviate/entities/errors/go_wrapper.go:25 +0x79\n\nWe have been observing this “new_prop_length_tracker” error for a very long time. Do you think it could be fixed somehow?\n\n----------\n\n[antas-marcin (2024-06-24T16:39:47.544Z)]: @Grzegorz_Pasieka for this panic we have only this way of fixing it atm (look here)\nThis RECOUNT_PROPERTIES_AT_STARTUP setting can be set only on a node on which you see this panics. This setting recreates the proplen file, it may take some time to regenerate this once it’s done then this panic should go away, at the end remember about removing this setting.\n\n----------\n\n[Grzegorz_Pasieka (2024-06-24T17:15:47.389Z)]: Thanks for this suggestion - I’ve just restarted node with this setting and got\n{\"action\":\"recount\",\"level\":\"warning\",\"msg\":\"Recounted 0 objects. Recounting properties complete. Please remove environment variable \\tRECOUNT_PROPERTIES_AT_STARTUP before next startup\",\"time\":\"2024-06-24T17:13:15Z\"}\n\nshould I worry about “Recounted 0 objects” part?\n\n----------\n\n[antas-marcin (2024-06-24T19:14:25.576Z)]: I think it’s OK, did the panic disappear?\nalso I remember that you had a problem with increased storage usage, do you still experience this problem? or the usage started to drop when you upgraded to v1.25.4?\n\n----------\n\n[Grzegorz_Pasieka (2024-06-25T06:12:49.665Z)]: The panic did not disappear\nimage1920×605 187 KB\nwhen it comes to the increased storage usage - it’s still constantly increasing but more often some storage is reclaimed.\nimage1996×332 23.5 KB\n\n----------\n\n[antas-marcin (2024-06-25T09:32:34.520Z)]: Unfortunately in your case you need to manually fix this.\nI think this are the steps that you need to do:\n\nlog into the node where this exception occurs and find the proplengths files which BucketedData is nil and delete those proplengths files\nrestart this node with RECOUNT_PROPERTIES_AT_STARTUP set to true\n\nThis operation should re-create the missing propelengths files. You should see there the a log stating Recounted X objects not Recounted 0 objects.\nPlease let me know if that worked.",
    "date_created": "2024-05-21T15:19:06.952Z",
    "has_accepted_answer": true,
    "title": "Constant storage drain without increasing number of vectors",
    "topic_id": 2406
  },
  {
    "user_id": 1535,
    "conversation": "[Antonio_Cesari (2024-09-13T10:21:05.839Z)]: Description\nI’m trying to perform a pagination using weaviate as near_text search. So I need the total count of results using aggregate, and then I move inside results with limit and offset. However the total count of results given by the aggregate function it’s different from the results taken from the query.\ncount = collection.aggregate.near_text(query=query, filters=filters, target_vector=“search”, distance=0.69 )\nAggregateReturn(properties={}, total_count=6)\nres = collection.query.near_text(query=query, filters=filters, target_vector=“search”, distance=0.69 )\nlen(res.objects)\n2\nI don’t know if I’m missing something\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[Mohamed_Shahin (2024-09-16T11:52:52.065Z)]: Hello @Antonio_Cesari,\nWelcome to our community! It’s great to have you here.\nThe difference in results between the aggregate and query is a result of how Weaviate handles aggregation vs. query searches. The aggregate method retrieves all potential matches within the distance , but the query method also takes into account ranking and limits . By default, the query returns only the top results ranked by relevance, which is why the query returns fewer results compared to the total count from the aggregation.\nI’ve seen your ticket in our support system. Let’s continue working together there since you’re using a Cloud cluster.\nBest regards!\n\n----------\n\n[Antonio_Cesari (2024-09-16T12:46:51.413Z)]: Hello Mohamed,\nwell I was using limit in my application code, however doing some more tests, I’ve found something weird:\nres = collection.query.near_text(query=query, offset=0, limit=10, filters=filters, target_vector=‘search’, distance=0.69 )\nprint(len(res.objects))\n2\nres = collection.query.near_text(query=query, limit=10, filters=filters, target_vector=‘search’, distance=0.69 )\nprint(len(res.objects))\n2\nres = collection.query.near_text(query=query, limit=100, filters=filters, target_vector=‘search’, distance=0.69 )\nprint(len(res.objects))\n6\nres = collection.query.near_text(query=query, offset=0, limit=100, filters=filters, target_vector=‘search’, distance=0.69 )\nprint(len(res.objects))\n6\nIf I limit my results to 10 I get only 2 results, if I go to 100 I get all 6. I have a pagination with 10 results per page so I was getting 2 in the app, but I expect to get all 6.\nLet me know if you need more information.",
    "date_created": "2024-09-13T10:21:05.783Z",
    "has_accepted_answer": false,
    "title": "Aggregate and query results mismatch",
    "topic_id": 4143
  },
  {
    "user_id": 2410,
    "conversation": "[bam (2024-11-12T21:52:53.846Z)]: I’m trying to upload a pdf to train the LLM. I’m using Weaviate in a docker-compose file, running verba and ollama3 locally. I’ve imported multiple pdfs already.\nI’m using a MacBook Pro running 13.17.1 Ventura.\nScreenshot 2024-11-12 at 16.51.34532×350 29.3 KB\nIt looses connection on some pdfs. Some are large and others are a few kbs in size.\nIs there a max file size for importing files?\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\nScreenshot 2024-11-12 at 20.51.261928×1262 128 KB\nScreenshot 2024-11-12 at 20.51.331966×1242 166 KB\n\nAny additional Information\nError message:\nDebugging File Configuration\n{\n  \"fileID\": \"cpt7-nasm-candidate-handbook.pdf\",\n  \"filename\": \"cpt7-nasm-candidate-handbook.pdf\",\n  \"extension\": \"pdf\",\n  \"status_report\": {\n    \"STARTING\": {\n      \"fileID\": \"cpt7-nasm-candidate-handbook.pdf\",\n      \"status\": \"STARTING\",\n      \"message\": \"Starting Import\",\n      \"took\": 0\n    },\n    \"LOADING\": {\n      \"fileID\": \"cpt7-nasm-candidate-handbook.pdf\",\n      \"status\": \"LOADING\",\n      \"message\": \"Loaded cpt7-nasm-candidate-handbook.pdf\",\n      \"took\": 3.97\n    },\n    \"CHUNKING\": {\n      \"fileID\": \"cpt7-nasm-candidate-handbook.pdf\",\n      \"status\": \"CHUNKING\",\n      \"message\": \"Split cpt7-nasm-candidate-handbook.pdf into 96 chunks\",\n      \"took\": 0.04\n    },\n    \"EMBEDDING\": {\n      \"fileID\": \"cpt7-nasm-candidate-handbook.pdf\",\n      \"status\": \"EMBEDDING\",\n      \"message\": \"\",\n      \"took\": 0\n    },\n    \"ERROR\": {\n      \"fileID\": \"cpt7-nasm-candidate-handbook.pdf\",\n      \"status\": \"ERROR\",\n      \"message\": \"Connection was interrupted\",\n      \"took\": 0\n    }\n  },\n  \"source\": \"\",\n  \"isURL\": false,\n  \"metadata\": \"\",\n  \"overwrite\": false,\n  \"content\": \"File Content\",\n  \"labels\": [\n    \"Document\"\n  ],\n  \"rag_config\": {\n    \"Reader\": {\n      \"selected\": \"Default\",\n      \"components\": {\n        \"Default\": {\n          \"name\": \"Default\",\n          \"variables\": [],\n          \"library\": [\n            \"pypdf\",\n            \"docx\",\n            \"spacy\"\n          ],\n          \"description\": \"Ingests text, code, PDF, and DOCX files\",\n          \"config\": {},\n          \"type\": \"FILE\",\n          \"available\": true\n        },\n        \"HTML\": {\n          \"name\": \"HTML\",\n          \"variables\": [],\n          \"library\": [\n            \"markdownify\",\n            \"beautifulsoup4\"\n          ],\n          \"description\": \"Downloads and ingests HTML from a URL, with optional recursive fetching.\",\n          \"config\": {\n            \"URLs\": {\n              \"type\": \"multi\",\n              \"value\": \"\",\n              \"description\": \"Add URLs to retrieve data from\",\n              \"values\": []\n            },\n            \"Convert To Markdown\": {\n              \"type\": \"bool\",\n              \"value\": 0,\n              \"description\": \"Should the HTML be converted into markdown?\",\n              \"values\": []\n            },\n            \"Recursive\": {\n              \"type\": \"bool\",\n              \"value\": 0,\n              \"description\": \"Fetch linked pages recursively\",\n              \"values\": []\n            },\n            \"Max Depth\": {\n              \"type\": \"number\",\n              \"value\": 3,\n              \"description\": \"Maximum depth for recursive fetching\",\n              \"values\": []\n            }\n          },\n          \"type\": \"URL\",\n          \"available\": false\n        },\n        \"Git\": {\n          \"name\": \"Git\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Downloads and ingests all files from a GitHub or GitLab Repo.\",\n          \"config\": {\n            \"Platform\": {\n              \"type\": \"dropdown\",\n              \"value\": \"GitHub\",\n              \"description\": \"Select the Git platform\",\n              \"values\": [\n                \"GitHub\",\n                \"GitLab\"\n              ]\n            },\n            \"Owner\": {\n              \"type\": \"text\",\n              \"value\": \"\",\n              \"description\": \"Enter the repo owner (GitHub) or group/user (GitLab)\",\n              \"values\": []\n            },\n            \"Name\": {\n              \"type\": \"text\",\n              \"value\": \"\",\n              \"description\": \"Enter the repo name\",\n              \"values\": []\n            },\n            \"Branch\": {\n              \"type\": \"text\",\n              \"value\": \"main\",\n              \"description\": \"Enter the branch name\",\n              \"values\": []\n            },\n            \"Path\": {\n              \"type\": \"text\",\n              \"value\": \"\",\n              \"description\": \"Enter the path or leave it empty to import all\",\n              \"values\": []\n            },\n            \"Git Token\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your GitHub/GitLab Token here if you haven't set it up as environment variable `GITHUB_TOKEN` or `GITLAB_TOKEN`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"URL\",\n          \"available\": true\n        },\n        \"Unstructured IO\": {\n          \"name\": \"Unstructured IO\",\n          \"variables\": [\n            \"UNSTRUCTURED_API_KEY\"\n          ],\n          \"library\": [],\n          \"description\": \"Uses the Unstructured API to import multiple file types such as plain text and documents\",\n          \"config\": {\n            \"Strategy\": {\n              \"type\": \"dropdown\",\n              \"value\": \"auto\",\n              \"description\": \"Set the extraction strategy\",\n              \"values\": [\n                \"auto\",\n                \"hi_res\",\n                \"ocr_only\",\n                \"fast\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"Set your Unstructured API Key here or set it as an environment variable `UNSTRUCTURED_API_KEY`\",\n              \"values\": []\n            },\n            \"API URL\": {\n              \"type\": \"text\",\n              \"value\": \"https://api.unstructured.io/general/v0/general\",\n              \"description\": \"Set the base URL to the Unstructured API or set it as an environment variable `UNSTRUCTURED_API_URL`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"FILE\",\n          \"available\": false\n        },\n        \"Firecrawl\": {\n          \"name\": \"Firecrawl\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Use Firecrawl to scrape websites and ingest them into Verba\",\n          \"config\": {\n            \"Mode\": {\n              \"type\": \"dropdown\",\n              \"value\": \"Scrape\",\n              \"description\": \"Switch between scraping and crawling. Note that crawling can take some time.\",\n              \"values\": [\n                \"Crawl\",\n                \"Scrape\"\n              ]\n            },\n            \"URLs\": {\n              \"type\": \"multi\",\n              \"value\": \"\",\n              \"description\": \"Add URLs to retrieve data from\",\n              \"values\": []\n            },\n            \"Firecrawl API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your Firecrawl API Key or set it as environment variable `FIRECRAWL_API_KEY`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"URL\",\n          \"available\": true\n        }\n      }\n    },\n    \"Chunker\": {\n      \"selected\": \"Token\",\n      \"components\": {\n        \"Token\": {\n          \"name\": \"Token\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Splits documents based on word tokens\",\n          \"config\": {\n            \"Tokens\": {\n              \"type\": \"number\",\n              \"value\": 250,\n              \"description\": \"Choose how many Token per chunks\",\n              \"values\": []\n            },\n            \"Overlap\": {\n              \"type\": \"number\",\n              \"value\": 50,\n              \"description\": \"Choose how many Tokens should overlap between chunks\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Sentence\": {\n          \"name\": \"Sentence\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Splits documents based on word tokens\",\n          \"config\": {\n            \"Sentences\": {\n              \"type\": \"number\",\n              \"value\": 5,\n              \"description\": \"Choose how many Sentences per chunks\",\n              \"values\": []\n            },\n            \"Overlap\": {\n              \"type\": \"number\",\n              \"value\": 1,\n              \"description\": \"Choose how many Sentences should overlap between chunks\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Recursive\": {\n          \"name\": \"Recursive\",\n          \"variables\": [],\n          \"library\": [\n            \"langchain_text_splitters \"\n          ],\n          \"description\": \"Recursively split documents based on predefined characters using LangChain\",\n          \"config\": {\n            \"Chunk Size\": {\n              \"type\": \"number\",\n              \"value\": 500,\n              \"description\": \"Choose how many characters per chunks\",\n              \"values\": []\n            },\n            \"Overlap\": {\n              \"type\": \"number\",\n              \"value\": 100,\n              \"description\": \"Choose how many characters per chunks\",\n              \"values\": []\n            },\n            \"Seperators\": {\n              \"type\": \"multi\",\n              \"value\": \"\",\n              \"description\": \"Select seperators to split the text\",\n              \"values\": [\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \".\",\n                \",\",\n                \"​\",\n                \"，\",\n                \"、\",\n                \"．\",\n                \"。\",\n                \"\"\n              ]\n            }\n          },\n          \"type\": \"\",\n          \"available\": false\n        },\n        \"Semantic\": {\n          \"name\": \"Semantic\",\n          \"variables\": [],\n          \"library\": [\n            \"sklearn\"\n          ],\n          \"description\": \"Split documents based on semantic similarity or max sentences\",\n          \"config\": {\n            \"Breakpoint Percentile Threshold\": {\n              \"type\": \"number\",\n              \"value\": 80,\n              \"description\": \"Percentile Threshold to split and create a chunk, the lower the more chunks you get\",\n              \"values\": []\n            },\n            \"Max Sentences Per Chunk\": {\n              \"type\": \"number\",\n              \"value\": 20,\n              \"description\": \"Maximum number of sentences per chunk\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"HTML\": {\n          \"name\": \"HTML\",\n          \"variables\": [],\n          \"library\": [\n            \"langchain_text_splitters \"\n          ],\n          \"description\": \"Split documents based on HTML tags using LangChain\",\n          \"config\": {},\n          \"type\": \"\",\n          \"available\": false\n        },\n        \"Markdown\": {\n          \"name\": \"Markdown\",\n          \"variables\": [],\n          \"library\": [\n            \"langchain_text_splitters\"\n          ],\n          \"description\": \"Split documents based on markdown formatting using LangChain\",\n          \"config\": {},\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Code\": {\n          \"name\": \"Code\",\n          \"variables\": [],\n          \"library\": [\n            \"langchain_text_splitters \"\n          ],\n          \"description\": \"Split code based on programming language using LangChain\",\n          \"config\": {\n            \"Language\": {\n              \"type\": \"dropdown\",\n              \"value\": \"python\",\n              \"description\": \"Select programming language\",\n              \"values\": [\n                \"cpp\",\n                \"go\",\n                \"java\",\n                \"kotlin\",\n                \"js\",\n                \"ts\",\n                \"php\",\n                \"proto\",\n                \"python\",\n                \"rst\",\n                \"ruby\",\n                \"rust\",\n                \"scala\",\n                \"swift\",\n                \"markdown\",\n                \"latex\",\n                \"html\",\n                \"sol\",\n                \"csharp\",\n                \"cobol\",\n                \"c\",\n                \"lua\",\n                \"perl\",\n                \"haskell\",\n                \"elixir\"\n              ]\n            },\n            \"Chunk Size\": {\n              \"type\": \"number\",\n              \"value\": 500,\n              \"description\": \"Choose how many characters per chunk\",\n              \"values\": []\n            },\n            \"Chunk Overlap\": {\n              \"type\": \"number\",\n              \"value\": 50,\n              \"description\": \"Choose how many characters overlap between chunks\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": false\n        },\n        \"JSON\": {\n          \"name\": \"JSON\",\n          \"variables\": [],\n          \"library\": [\n            \"langchain_text_splitters \"\n          ],\n          \"description\": \"Split json files using LangChain\",\n          \"config\": {\n            \"Chunk Size\": {\n              \"type\": \"number\",\n              \"value\": 500,\n              \"description\": \"Choose how many characters per chunks\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": false\n        }\n      }\n    },\n    \"Embedder\": {\n      \"selected\": \"Ollama\",\n      \"components\": {\n        \"Ollama\": {\n          \"name\": \"Ollama\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Vectorizes documents and queries using Ollama. If your Ollama instance is not running on http://localhost:11434, you can change the URL by setting the OLLAMA_URL environment variable.\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"snowflake-arctic-embed:latest\",\n              \"description\": \"Select a installed Ollama model from http://localhost:11434. You can change the URL by setting the OLLAMA_URL environment variable. \",\n              \"values\": [\n                \"snowflake-arctic-embed:latest\",\n                \"llama3:latest\",\n                \"codegemma:latest\",\n                \"llama3.2:latest\"\n              ]\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"SentenceTransformers\": {\n          \"name\": \"SentenceTransformers\",\n          \"variables\": [],\n          \"library\": [\n            \"sentence_transformers\"\n          ],\n          \"description\": \"Embeds and retrieves objects using SentenceTransformer\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"all-MiniLM-L6-v2\",\n              \"description\": \"Select an HuggingFace Embedding Model\",\n              \"values\": [\n                \"all-MiniLM-L6-v2\",\n                \"mixedbread-ai/mxbai-embed-large-v1\",\n                \"all-mpnet-base-v2\",\n                \"BAAI/bge-m3\",\n                \"all-MiniLM-L12-v2\",\n                \"paraphrase-MiniLM-L6-v2\"\n              ]\n            }\n          },\n          \"type\": \"\",\n          \"available\": false\n        },\n        \"Weaviate\": {\n          \"name\": \"Weaviate\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Vectorizes documents and queries using Weaviate's In-House Embedding Service.\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"Embedding Service\",\n              \"description\": \"Select a Weaviate Embedding Service Model\",\n              \"values\": [\n                \"Embedding Service\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"Weaviate Embedding Service Key (or set EMBEDDING_SERVICE_KEY env var)\",\n              \"values\": []\n            },\n            \"URL\": {\n              \"type\": \"text\",\n              \"value\": \"\",\n              \"description\": \"Weaviate Embedding Service URL (if different from default)\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"VoyageAI\": {\n          \"name\": \"VoyageAI\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Vectorizes documents and queries using VoyageAI\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"voyage-2\",\n              \"description\": \"Select a VoyageAI Embedding Model\",\n              \"values\": [\n                \"voyage-2\",\n                \"voyage-large-2\",\n                \"voyage-finance-2\",\n                \"voyage-multilingual-2\",\n                \"voyage-law-2\",\n                \"voyage-code-2\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"OpenAI API Key (or set OPENAI_API_KEY env var)\",\n              \"values\": []\n            },\n            \"URL\": {\n              \"type\": \"text\",\n              \"value\": \"https://api.voyageai.com/v1\",\n              \"description\": \"OpenAI API Base URL (if different from default)\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Cohere\": {\n          \"name\": \"Cohere\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Vectorizes documents and queries using Cohere\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"embed-english-v3.0\",\n              \"description\": \"Select a Cohere Embedding Model\",\n              \"values\": [\n                \"embed-english-v3.0\",\n                \"embed-multilingual-v3.0\",\n                \"embed-english-light-v3.0\",\n                \"embed-multilingual-light-v3.0\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your Cohere API Key here or set it as environment variable `COHERE_API_KEY`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"OpenAI\": {\n          \"name\": \"OpenAI\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Vectorizes documents and queries using OpenAI\",\n          \"config\": {\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"text-embedding-3-small\",\n              \"description\": \"Select an OpenAI Embedding Model\",\n              \"values\": [\n                \"text-embedding-ada-002\",\n                \"text-embedding-3-small\",\n                \"text-embedding-3-large\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"OpenAI API Key (or set OPENAI_API_KEY env var)\",\n              \"values\": []\n            },\n            \"URL\": {\n              \"type\": \"text\",\n              \"value\": \"https://api.openai.com/v1\",\n              \"description\": \"OpenAI API Base URL (if different from default)\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        }\n      }\n    },\n    \"Retriever\": {\n      \"selected\": \"Advanced\",\n      \"components\": {\n        \"Advanced\": {\n          \"name\": \"Advanced\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Retrieve relevant chunks from Weaviate\",\n          \"config\": {\n            \"Suggestion\": {\n              \"type\": \"bool\",\n              \"value\": 1,\n              \"description\": \"Enable Autocomplete Suggestions\",\n              \"values\": []\n            },\n            \"Search Mode\": {\n              \"type\": \"dropdown\",\n              \"value\": \"Hybrid Search\",\n              \"description\": \"Switch between search types.\",\n              \"values\": [\n                \"Hybrid Search\"\n              ]\n            },\n            \"Limit Mode\": {\n              \"type\": \"dropdown\",\n              \"value\": \"Autocut\",\n              \"description\": \"Method for limiting the results. Autocut decides automatically how many chunks to retrieve, while fixed sets a fixed limit.\",\n              \"values\": [\n                \"Autocut\",\n                \"Fixed\"\n              ]\n            },\n            \"Limit/Sensitivity\": {\n              \"type\": \"number\",\n              \"value\": 1,\n              \"description\": \"Value for limiting the results. Value controls Autocut sensitivity and Fixed Size\",\n              \"values\": []\n            },\n            \"Chunk Window\": {\n              \"type\": \"number\",\n              \"value\": 1,\n              \"description\": \"Number of surrounding chunks of retrieved chunks to add to context\",\n              \"values\": []\n            },\n            \"Threshold\": {\n              \"type\": \"number\",\n              \"value\": 80,\n              \"description\": \"Threshold of chunk score to apply window technique (1-100)\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        }\n      }\n    },\n    \"Generator\": {\n      \"selected\": \"Ollama\",\n      \"components\": {\n        \"Ollama\": {\n          \"name\": \"Ollama\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Generate answers using Ollama. If your Ollama instance is not running on http://localhost:11434, you can change the URL by setting the OLLAMA_URL environment variable.\",\n          \"config\": {\n            \"System Message\": {\n              \"type\": \"text\",\n              \"value\": \"You are Fit T Centenarian, a chatbot for Retrieval Augmented Generation (RAG). You will receive a user query and context pieces that have a semantic similarity to that query. Please answer these user queries only with the provided context. Mention documents you used from the context if you use them to reduce hallucination. If the provided documentation does not provide enough information, say so. If the user asks questions about you as a chatbot specifially, answer them naturally. If the answer requires code examples encapsulate them with ```programming-language-name ```. Don't do pseudo-code.\",\n              \"description\": \"System Message\",\n              \"values\": []\n            },\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"llama3.2:latest\",\n              \"description\": \"Select an installed Ollama model from http://localhost:11434.\",\n              \"values\": [\n                \"snowflake-arctic-embed:latest\",\n                \"llama3:latest\",\n                \"codegemma:latest\",\n                \"llama3.2:latest\"\n              ]\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"OpenAI\": {\n          \"name\": \"OpenAI\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Using OpenAI LLM models to generate answers to queries\",\n          \"config\": {\n            \"System Message\": {\n              \"type\": \"text\",\n              \"value\": \"You are Verba, a chatbot for Retrieval Augmented Generation (RAG). You will receive a user query and context pieces that have a semantic similarity to that query. Please answer these user queries only with the provided context. Mention documents you used from the context if you use them to reduce hallucination. If the provided documentation does not provide enough information, say so. If the user asks questions about you as a chatbot specifially, answer them naturally. If the answer requires code examples encapsulate them with ```programming-language-name ```. Don't do pseudo-code.\",\n              \"description\": \"System Message\",\n              \"values\": []\n            },\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"gpt-4o\",\n              \"description\": \"Select an OpenAI Embedding Model\",\n              \"values\": [\n                \"gpt-4o\",\n                \"gpt-3.5-turbo\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your OpenAI API Key here or set it as environment variable `OPENAI_API_KEY`\",\n              \"values\": []\n            },\n            \"URL\": {\n              \"type\": \"text\",\n              \"value\": \"https://api.openai.com/v1\",\n              \"description\": \"You can change the Base URL here if needed\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Anthropic\": {\n          \"name\": \"Anthropic\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Using Anthropic LLM models to generate answers to queries\",\n          \"config\": {\n            \"System Message\": {\n              \"type\": \"text\",\n              \"value\": \"You are Verba, a chatbot for Retrieval Augmented Generation (RAG). You will receive a user query and context pieces that have a semantic similarity to that query. Please answer these user queries only with the provided context. Mention documents you used from the context if you use them to reduce hallucination. If the provided documentation does not provide enough information, say so. If the user asks questions about you as a chatbot specifially, answer them naturally. If the answer requires code examples encapsulate them with ```programming-language-name ```. Don't do pseudo-code.\",\n              \"description\": \"System Message\",\n              \"values\": []\n            },\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"claude-3-5-sonnet-20240620\",\n              \"description\": \"Select an Anthropic Model\",\n              \"values\": [\n                \"claude-3-5-sonnet-20240620\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your Anthropic API Key here or set it as environment variable `ANTHROPIC_API_KEY`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        },\n        \"Cohere\": {\n          \"name\": \"Cohere\",\n          \"variables\": [],\n          \"library\": [],\n          \"description\": \"Generator using Cohere's command-r-plus model\",\n          \"config\": {\n            \"System Message\": {\n              \"type\": \"text\",\n              \"value\": \"You are Verba, a chatbot for Retrieval Augmented Generation (RAG). You will receive a user query and context pieces that have a semantic similarity to that query. Please answer these user queries only with the provided context. Mention documents you used from the context if you use them to reduce hallucination. If the provided documentation does not provide enough information, say so. If the user asks questions about you as a chatbot specifially, answer them naturally. If the answer requires code examples encapsulate them with ```programming-language-name ```. Don't do pseudo-code.\",\n              \"description\": \"System Message\",\n              \"values\": []\n            },\n            \"Model\": {\n              \"type\": \"dropdown\",\n              \"value\": \"embed-english-v3.0\",\n              \"description\": \"Select a Cohere Embedding Model\",\n              \"values\": [\n                \"embed-english-v3.0\",\n                \"embed-multilingual-v3.0\",\n                \"embed-english-light-v3.0\",\n                \"embed-multilingual-light-v3.0\"\n              ]\n            },\n            \"API Key\": {\n              \"type\": \"password\",\n              \"value\": \"\",\n              \"description\": \"You can set your Cohere API Key here or set it as environment variable `COHERE_API_KEY`\",\n              \"values\": []\n            }\n          },\n          \"type\": \"\",\n          \"available\": true\n        }\n      }\n    }\n  },\n  \"file_size\": 502504,`Preformatted text`\n  \"status\": \"ERROR\"\n}\n\n----------\n\n[DudaNogueira (2024-11-13T13:56:32.217Z)]: hi @bam !!\nI believe those are related: Vectorization failed for some batches: 500, message='Internal Server Error'",
    "date_created": "2024-11-12T21:52:53.794Z",
    "has_accepted_answer": false,
    "title": "Max file size for pdf imports & Connection Interruption Error",
    "topic_id": 7557
  },
  {
    "user_id": 1292,
    "conversation": "[Univision_Support (2024-09-09T09:02:56.435Z)]: Description\nAlready exists or is planned a single user interface with only chat interface without admin options (configuration, documents tab, ecc…) ?\nThanks\n\n----------\n\n[DudaNogueira (2024-09-09T14:32:33.331Z)]: hi @Univision_Support !!\nAre you referring to Verba?\nThere is a Production mode in Verba, where you can remove those options and leave the UI only with the querying part.\nI will try to play more with Verba 2.0 later this week.\nLet me know if this helps!\nThanks!\n\n----------\n\n[Univision_Support (2024-09-10T08:55:39.508Z)]: Hi, Thanks for the reply, Yes I was referring to Verba (I test last version Verba 2.0).\nI try with “verba start --prod” but don’t work.\nThe call is correct?\nI see also “–deployment” options it possible start directly in local mode?\n\n----------\n\n[wjbmattingly (2024-10-08T18:21:36.190Z)]: I had this same issue. The trick here is to use this in your .env:\nVERBA_PRODUCTION=“Demo”\nand then run verba start --prod and it should work where you don’t see admin settings.\n\n----------\n\n[DudaNogueira (2024-10-14T21:43:11.357Z)]: thanks for sharing, @wjbmattingly !\nAnd Welcome to our community",
    "date_created": "2024-09-09T09:02:56.387Z",
    "has_accepted_answer": true,
    "title": "Single/Admin user Interface",
    "topic_id": 4027
  },
  {
    "user_id": 3094,
    "conversation": "[chunker (2024-12-24T09:43:31.666Z)]: Description\nWhen I perform a query against the named vectors I have set up, I get a score of 0.\nq = 'example query'\nchunks = client.collections.get(\"Chunks\")\nresponse = chunks.query.near_text(query=q,  \n        limit=2,\n        return_metadata=wvc.query.MetadataQuery(score=True, explain_score=True, distance=True),\n        target_vector=[\"textvector\"]\n    )\n\nfor r in response.objects:\n    print(r.metadata.distance)\n    print(r.metadata.score)\n    print(r.metadata.explain_score)\n\nExample output:\n0.18377846479415894\n0.0\n...\n0.5245028734207153\n0.0\n\n\nThe query score of exactly 0 makes me suspect the encoding of my query might be going wrong or there might be an issue with the score calculation on the query.\nAdditionally, the metadata.explain_score is not populated.\nI do see sensible distances between the objects. Also, I see that vectors have been calculated for my objects (through the REST API).\n\nMy questions:\n\nIs my assumption that a near_text query should return scores >0 correct? If not, what attributes to use to understand the results?\nAny ideas on how to debug this? What are the typical areas to start investigating when encountering query issues?\n\n\nServer Setup Information\n\nWeaviate Server Version: 1.28\nDeployment Method: Docker Compose (cr.weaviate.io/semitechnologies/weaviate:1.28.0)\nMulti Node?: No (Single Node)\nClient Language and Version: Pythonpip list | grep weav\nweaviate                 0.1.2\nweaviate-cli             3.0.2\nweaviate-client          4.9.6\n\n\nMultitenancy?: Not specified\n\n\nAny Additional Information\nHere is the docker-compose.yml file:\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.28.0\n    restart: on-failure: 0\n    ports:\n      - \"8080:8080\"\n      - \"50051:50051\"\n    environment:\n      QUERY_DEFAULTS_LIMIT: 20\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: \"./data\"\n      DEFAULT_VECTORIZER_MODULE: text2vec-transformers\n      ENABLE_MODULES: text2vec-transformers\n      TRANSFORMERS_INFERENCE_API: http://t2v-transformers:8080\n      CLUSTER_HOSTNAME: 'node1'\n  \n  t2v-transformers:\n    image: cr.weaviate.io/semitechnologies/transformers-inference:sentence-transformers-paraphrase-multilingual-MiniLM-L12-v2\n    environment:\n      ENABLE_CUDA: 0 # set to 1 to enable\n      # NVIDIA_VISIBLE_DEVICES: all # enable if running with CUDA\n\n----------\n\n[DudaNogueira (2024-12-24T13:28:00.841Z)]: Hi @chunker !!\nWelcome to our community \nBecause near_text is a purely vector search, you get a distance instead of a score.\nWith bm25 you get a score, and the same for hybrid, where the vector distance and the bm25 score are fused.\nOnly for hybrid, it will populate the explain_score. It will show the distance and score that it got for the hybrid query and also the normalized numbers.\nLet me know if that helps!\nThanks!",
    "date_created": "2024-12-24T09:43:31.610Z",
    "has_accepted_answer": true,
    "title": "Query score 0",
    "topic_id": 9417
  },
  {
    "user_id": 2458,
    "conversation": "[coolrazor (2024-11-05T19:35:56.290Z)]: Description\nI’ve been struggling with getting Ollama and Weaviate (local hosted) to communicate and MAY have found an issue.  Can someone confirm this??  Also, I run the client.py from a different computer that resolves weaviate/ollama api’s just fine.\nERROR:  (note the timeout for http://host.docker.internal:11434/api/embeddings)\nAdded document 86 of 87\nAdded document 87 of 87\nFinished adding documents to batch.  Please wait...\n{'message': 'Failed to send 34 objects in a batch of 39. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n{'message': 'Failed to send 48 objects in a batch of 48. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\nBatch operation completed.\nFailed to send some objects. Details:\n[ErrorObject(message='send POST request: Post \"http://host.docker.internal:11434/api/embeddings\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)', object_=_BatchObject(collection=\n\nHere’s me proving that /api/embed works but /api/embeddings does not FROM the Weaviate container itself.  (FYI, Ollama is running in a container on the same server and I am doing DNS trick)\ncurl http://host.docker.internal:11434/api/embed -d '{\n>  \"model\": \"all-minilm\",\n>  \"input\": \"Why is the sky blue?\"\n> }'\n{\"model\":\"all-minilm\",\"embeddings\":[[0.010062016,-0.0017554946,0.050059456,0.046898536,0.05492503,0.008586371,0.105435975,-0.02585886,0.12960042,0.03196424,-0.04446901,-0.008987563,-0.00048934284,-0.063705765,-0.016032169,0.04664046,-0.022036841,-0.15813273,-0.07283887,-0.061328467,-0.0658716,0.05415806,-0.062132724,0.038911566,-0.045823917,0.05493227,-0.035256814,0.012593464,0.042497203,-0.00791991,-0.019023538,0.060972027,0.0369004,0.013471901,-0.025816392,-0.04346177,0.072602205,-0.04852212,0.004289973,-0.02943973,-0.029135313,-0.032912277,-0.018327639,0.015538654,-0.011697433,0.015307811,-0.0093740765,0.02596869,0.095239274,-0.015505323,-0.024563508,0.00905882,-0.07661391,0.01597137,0.0495439,0.11599131,0.0009903827,-0.020357985,0.092338845,0.008486339,-0.057076585,0.068846054,-0.07661979,0.06932093,0.092274524,-0.05546903,-0.05361791,0.008456234,-0.06313479,-0.06637476,-0.025184836,0.018881764,0.0614203,-0.028226346,0.03623095,0.0011074109,0.060684238,-0.06754768,-0.008165614,-0.012759827,0.030947892,-0.06379601,-0.07449585,0.11916402,0.012604237,0.06534184,0.014816104,0.051461816,-0.085212834,0.010246205,-0.007790781,-0.035579104,-0.115383774,-0.030693283,-0.08326488,0.013688024,0.0566172,-0.040913362,0.04265116,0.022126986,0.04688714,-0.051353518,0.030182738,0.007212158,-0.0041854717,-0.031170908,0.07790212,0.034200206,0.06134735,0.0074944603,-0.036250636,-0.08459046,0.021791892,-0.01941079,-0.039836466,0.054774895,-0.033720702,0.018103762,-0.105538726,-0.050379105,-0.011522215,0.03781235,0.022203606,0.08049023,0.007826529,-0.016847076,-0.05940992,-7.2264985e-33,0.13530928,-0.01122062,0.09228662,0.035975594,0.039652325,-0.05498584,-0.035040457,-0.0037004948,-0.019585393,-0.034948528,-0.0056920326,-0.014604142,-0.024266437,-0.04836174,0.04776316,-0.017078744,-0.06096635,0.0059679267,-0.08307662,0.084326036,-0.1046801,0.041656446,-0.036648408,-0.00807082,-0.028182266,-0.0432105,0.03599302,0.07497103,0.056440875,0.011846439,0.098480076,0.10484118,-0.021833764,0.046026118,-0.026338102,-0.050923478,-0.014703361,-0.006385692,-0.085865304,0.028598264,-0.053600207,0.05653976,-0.05975049,0.012445692,0.06619967,-0.013451253,0.038313355,-0.088933945,-0.057463154,0.031985212,-0.034472626,0.02362452,0.014457598,-0.041595947,0.06799603,0.031194357,0.06971566,-0.03505056,-0.0033061015,0.049345832,-0.013366442,-0.0034659673,0.0507598,0.07866189,0.03761729,-0.011602827,0.038128607,0.042007096,-0.012825245,-0.07895265,0.009025603,0.013359126,0.024172096,0.009767894,-0.010923641,-0.08161844,0.027013624,-0.029674161,-0.0043373145,0.013044075,-0.03524456,-0.019715898,0.055353805,-0.061263584,-0.055034723,0.012540969,-0.019183055,-0.012589377,-0.015817907,-0.0694245,-0.0448946,-0.048921186,0.048258252,-0.104466744,-0.10785244,3.5869857e-33,-0.0004916445,-0.08634525,-0.087862216,0.00721585,-0.007399472,-0.016603751,0.04528791,0.06751051,-0.04286227,0.08635874,0.045557436,0.06797927,0.00993781,-0.0030342652,0.05850576,-0.035561092,0.036206532,0.066166386,-0.03778131,-0.062247746,-0.04456004,0.077223405,0.04342943,-0.021262772,-0.021634147,0.062292643,-0.039129134,0.028107705,-0.013056282,0.05112274,-0.036825743,0.054581434,-0.0664262,0.02286992,0.004798484,0.090448886,0.005099579,-0.08310181,-0.055130087,0.07316554,-0.110448785,-0.020279517,0.1125694,-0.053279936,-0.057589278,-0.02394129,0.05659431,0.12725082,0.035939164,-0.043952655,0.017011488,-0.024847863,0.07269543,0.04313807,0.08050782,-0.019497115,-0.034367483,0.09668477,0.051890664,0.010758555,0.040229112,0.0022059581,-0.0075641256,0.0016752295,0.014182178,0.020362137,-0.0231149,0.021473816,-0.009235045,-0.050511464,-0.016234735,-0.08993932,-0.0606745,0.080994345,0.0024622004,0.0415745,0.04373566,-0.025141884,-0.09528701,0.08870627,-0.098396346,-0.0048426352,0.03536255,0.014155159,-0.06458343,-0.07597527,0.0124133555,-0.050230194,-0.055773806,-0.05700181,-0.018454289,-0.0021796268,-0.0022036426,0.035248876,-0.054714452,-1.4308528e-8,-0.007931117,0.026678042,0.0022828944,0.009996726,-0.021681784,-0.021548975,0.11138375,0.004643359,0.0378477,0.0039836173,-0.06688522,-0.028300066,-0.044328276,0.07121455,0.018713769,-0.049081404,-0.103970364,-0.043620154,0.010162136,0.041800696,-0.013576608,-0.033832546,-0.025055477,-0.01362027,0.0034353742,0.033081193,-0.0218651,0.021916177,0.07145605,0.020513555,0.02442516,0.035869926,-0.00096216256,-0.06136724,-0.08539853,0.0074072084,-0.038768604,0.07987996,-0.02557682,-0.06045561,0.060549967,0.08237212,-0.056718823,0.0048675025,0.045130767,0.023777386,0.043506835,0.091047205,-0.051409125,-0.011231628,-0.06888141,0.0072409785,0.07282593,-0.04335108,0.025920803,-0.114089325,-0.009541741,0.022197897,0.026735239,0.003706583,0.015949031,0.0035650954,-0.020685595,0.033551708]],\"total_duration\":480127694,\"load_duration\":316268926,\"prompt_eval_count\":/ \n\ncurl http://host.docker.internal:11434/api/embeddings -d '{\n>  \"model\": \"all-minilm\",\n>  \"input\": \"Why is the sky blue?\"\n> }'\n{\"embedding\":[]}\n\nCODE SNIPPETS:\nimport weaviate\nfrom weaviate.connect import ConnectionParams\nfrom weaviate.classes.init import AdditionalConfig, Timeout\nfrom weaviate.classes.config import Configure\nimport weaviate.classes.config as weaviate_config\n\ndef connect_to_weaviate(\n    weaviate_host=\"mothership\",\n    weaviate_port=8080,\n    grpc_port=50051,\n    http_secure=False,\n    grpc_secure=False,\n    init_timeout=300,\n    query_timeout=300,\n    insert_timeout=600\n):\n    \"\"\"\n    Connects to a Weaviate instance with custom configuration.\n\n    Returns:\n        weaviate.Client: A connected Weaviate client instance.\n    \"\"\"\n    try:\n        client = weaviate.WeaviateClient(\n            connection_params=ConnectionParams.from_params(\n                http_host=weaviate_host,\n                http_port=weaviate_port,\n                http_secure=False,\n                grpc_host=weaviate_host,\n                grpc_port=grpc_port,\n                grpc_secure=False,\n            ),\n            additional_config=AdditionalConfig(\n                timeout=Timeout(init=init_timeout, query=query_timeout, insert=insert_timeout),  # Values in seconds\n            ),\n            skip_init_checks=True\n        )\n        client.connect()\n        # client = weaviate.connect_to_custom(\n        #     http_host=weaviate_host,\n        #     http_port=weaviate_port,\n        #     http_secure=http_secure,\n        #     grpc_host=weaviate_host,\n        #     grpc_port=grpc_port,\n        #     grpc_secure=grpc_secure,\n        #     skip_init_checks=True,\n        #     additional_config=AdditionalConfig(\n        #         timeout=Timeout(init=init_timeout, query=query_timeout, insert=insert_timeout)\n        #     )\n        # )\n    except Exception as e:\n        print(f\"Could not connect to Weaviate host: {e}\")\n\n    meta_info = client.get_meta()\n    print(\"Meta Data: \", meta_info)\n\n    return client\n\ndef create_collection(client, collection_name, properties):\n    \"\"\"\n    Creates a new collection in Weaviate.\n\n    Args:\n        client (weaviate.Client): The Weaviate client instance.\n        collection_name (str): The name of the collection to create.\n        properties (list): A list of property configurations for the collection.\n\n    Returns:\n        The created collection object.\n    \"\"\"\n    print(f\"Creating collection '{collection_name}'...\")\n\n    collection = client.collections.create(\n        name=collection_name,\n        properties=properties,\n        vectorizer_config=Configure.Vectorizer.text2vec_ollama(\n            api_endpoint=\"http://host.docker.internal:11434\",\n            model=\"snowflake-arctic-embed\"\n        ),\n        generative_config=Configure.Generative.ollama(\n            api_endpoint=\"http://host.docker.internal:11434\",  \n            model=\"llama3.1\"\n        )\n    )\n\n    return collection\n\n\nPart of a function that ingests the documents:\n    try:\n        print(\"Starting batch operation...\")\n        with collection.batch.dynamic() as batch:\n            for i, doc in enumerate(documents):\n                try:\n                    # Check if document has required attributes\n                    if not all(hasattr(doc, attr) for attr in [\"title\", \"content\", \"headings\", \"file_path\", \"file_name\"]):\n                        print(f\"Skipping document {i+1} due to missing attributes.\")\n                        continue\n               \n                    doc_object = {\n                        \"title\": doc.title,\n                        \"content\": doc.content,\n                        \"headings\": doc.headings,\n                        \"file_path\": doc.file_path,\n                        \"file_name\": doc.file_name,\n                    }\n\n                    # # Generate embedding\n                    # print(f\"Generating embedding for document {i+1}...\")\n                    # embeddings_response = ollama.embeddings(model=EMBEDDING_MODEL, prompt=doc.content)\n                    # print(f\"Generated embedding for document {i+1}\")\n                    # if \"embedding\" not in embeddings_response:\n                    #     raise ValueError(f\"Failed to get embedding for document {i+1}\")\n                    # doc_object[\"embedding\"] = embeddings_response[\"embedding\"]\n\n                    batch.add_object(\n                        properties=doc_object,\n                    )\n                    print(f\"Added document {i+1} of {len(documents)}\")\n\nServer Setup Information\n\nWeaviate Server Version: 1.27.1\nDeployment Method: docker\nMulti Node? Number of Running Nodes:  1\nClient Language and Version: Python 3.10.12\nMultitenancy?: No\n\nAny additional Information\nweaviate-client==4.9.2\nollama==0.3.3\n\n----------\n\n[coolrazor (2024-11-05T21:54:09.985Z)]: Link to Ollama docs showing /api/embed:  ollama/docs/api.md at main · ollama/ollama · GitHub\nAh it has been superseded\n\" Note: this endpoint has been superseded by /api/embed\"\n\n----------\n\n[DudaNogueira (2024-11-06T12:30:22.961Z)]: hi @coolrazor !!\nWelcome to our community \nNot sure I understood \nThis is a working example using Weaviate (Docker) and Ollama (Natively):\nimport weaviate\nfrom weaviate import classes as wvc\nclient = weaviate.connect_to_local()\nprint(f\"Client: {weaviate.__version__}, Server: client.get_meta().get('version')\")\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n        name=\"Test\",\n        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n            api_endpoint=\"http://host.docker.internal:11434\",\n            model=\"snowflake-arctic-embed\"\n        ),\n        generative_config=wvc.config.Configure.Generative.ollama(\n            api_endpoint=\"http://host.docker.internal:11434\",  \n            model=\"llama3.1\"\n        )\n    )\ncollection.data.insert({\"text\": \"Why is the sky blue?\"})\nprint(len(collection.query.fetch_objects(include_vector=True).objects[0].vector.get(\"default\")))\nprint(collection.generate.fetch_objects(single_prompt=\"answer: {text}\").objects[0].generated)\nclient.close()\n\nLet me know how I can help on this.\nThanks!\n\n----------\n\n[DudaNogueira (2024-11-06T12:40:00.118Z)]: One interesting thing I noted is that indeed the /embeddings will not work, yet it seems that Ollama module in Weaviate is using it \n\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate/blob/05de0dbea192d8ea59b9408707f0d536f4081b8f/modules/text2vec-ollama/clients/ollama.go#L29\n\n\n\n    \n      \n          \t\"io\"\n          \t\"net/http\"\n          \t\"time\"\n          \n          \t\"github.com/pkg/errors\"\n          \t\"github.com/sirupsen/logrus\"\n          \t\"github.com/weaviate/weaviate/modules/text2vec-ollama/ent\"\n          )\n          \n          func buildURL(apiEndoint string) string {\n          \treturn fmt.Sprintf(\"%s/api/embeddings\", apiEndoint)\n          }\n          \n          type ollama struct {\n          \thttpClient   *http.Client\n          \turlBuilderFn func(apiEndoint string) string\n          \tlogger       logrus.FieldLogger\n          }\n          \n          func New(timeout time.Duration, logger logrus.FieldLogger) *ollama {\n          \treturn &ollama{\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYet, it is working\n\n----------\n\n[coolrazor (2024-11-06T14:33:43.662Z)]: super weird but when I take the example you have above and edit it to use client = weaviate.connect_to_custom it still fails.\nThe script is being ran from my local PC.  Weaviate and Ollama are running on a server called “mothership” and connectivity works otherwise.\nEDITED SCRIPT:\nimport weaviate\nfrom weaviate import classes as wvc\nimport os\nfrom weaviate.classes.init import AdditionalConfig, Timeout\nfrom weaviate.classes.config import Property, DataType\nfrom dotenv import load_dotenv\nload_dotenv()\n\nWEAVIATE_HOST = os.getenv(\"WEAVIATE_HOST\")\nWEAVIATE_PORT = os.getenv(\"WEAVIATE_PORT\")\nEMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")\nOLLAMA_HOST = os.getenv(\"OLLAMA_HOST\")\n\nclient = weaviate.connect_to_custom(\n    http_host=WEAVIATE_HOST,\n    http_port=WEAVIATE_PORT,\n    http_secure=False,\n    grpc_host=WEAVIATE_HOST,\n    grpc_port=50051,\n    grpc_secure=False,\n    skip_init_checks=True,\n    additional_config=AdditionalConfig(\n        timeout=Timeout(init=10, query=20, insert=120)  # Values in seconds\n    )\n)\n\nprint(f\"Client: {weaviate.__version__}, Server: client.get_meta().get('version')\")\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n        name=\"Test\",\n        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n            api_endpoint=\"http://mothership:11434\",\n            model=\"snowflake-arctic-embed\"\n        ),\n        generative_config=wvc.config.Configure.Generative.ollama(\n            api_endpoint=\"http://mothership:11434\",  \n            model=\"llama3.1\"\n        )\n    )\ncollection.data.insert({\"text\": \"Why is the sky blue?\"})\nprint(len(collection.query.fetch_objects(include_vector=True).objects[0].vector.get(\"default\")))\nprint(collection.generate.fetch_objects(single_prompt=\"answer: {text}\").objects[0].generated)\nclient.close()\n\nERROR:\npython test.py\nClient: 4.9.3, Server: client.get_meta().get('version')\nTraceback (most recent call last):\n  File \"/home/razor/repos/assistant/test.py\", line 41, in <module>\n    collection.data.insert({\"text\": \"Why is the sky blue?\"})\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/syncify.py\", line 23, in sync_method\n    return _EventLoopSingleton.get_instance().run_until_complete(\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/event_loop.py\", line 42, in run_until_complete\n    return fut.result()\n  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n    return self.__get_result()\n  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/collections/data/data.py\", line 340, in insert\n    return await self._insert(weaviate_obj)\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/collections/data/data.py\", line 84, in _insert\n    await self._connection.post(\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/connect/v4.py\", line 525, in post\n    return await self.__send(\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/connect/v4.py\", line 480, in __send\n    raise e\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/connect/v4.py\", line 471, in __send\n    raise UnexpectedStatusCodeError(error_msg, response=res)\nweaviate.exceptions.UnexpectedStatusCodeError: Object was not added! Unexpected status code: 500, with response body: {'error': [{'message': 'update vector: send POST request: Post \"http://mothership:11434/api/embeddings\": dial tcp 127.0.1.1:11434: connect: connection refused'}]}.\n/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/warnings.py:329: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n            Please make sure to close the connection using `client.close()`.\n/usr/lib/python3.10/asyncio/selector_events.py:710: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=6 read=idle write=<idle, bufsize=0>>\n\n----------\n\n[coolrazor (2024-11-06T14:46:15.695Z)]: Oh actually I forgot to not use the server hostname since it appears the call is made from within the Weaviate container, not the script (if I’m not mistaken).\nI just edit these lines to use my DNS trick:\napi_endpoint=\"http://host.docker.internal:11434\",\nbut now the error I get is different.  Although still not working.  I tried setting the timeouts to 600 and it still does it.\nERROR:\npython test.py\nClient: 4.9.3, Server: 1.27.1\n1024\nTraceback (most recent call last):\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/collections/grpc/query.py\", line 804, in __call\n    res = await _Retry(4).with_exponential_backoff(\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/collections/grpc/retry.py\", line 31, in with_exponential_backoff\n    raise e\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/collections/grpc/retry.py\", line 28, in with_exponential_backoff\n    return await f(*args, **kwargs)\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/grpc/aio/_call.py\", line 327, in __await__\n    raise _create_rpc_error(\ngrpc.aio._call.AioRpcError: <AioRpcError of RPC that terminated with:\n        status = StatusCode.UNKNOWN\n        details = \"explorer: list class: extend: extend generate: client not found, empty provider\"\n        debug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"explorer: list class: extend: extend generate: client not found, empty provider\", grpc_status:2, created_time:\"2024-11-06T06:39:04.574035292-08:00\"}\"\n>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/razor/repos/assistant/test.py\", line 43, in <module>\n    print(collection.generate.fetch_objects(single_prompt=\"answer: {text}\").objects[0].generated)\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/syncify.py\", line 23, in sync_method\n    return _EventLoopSingleton.get_instance().run_until_complete(\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/event_loop.py\", line 42, in run_until_complete\n    return fut.result()\n  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n    return self.__get_result()\n  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/collections/queries/fetch_objects/generate.py\", line 75, in fetch_objects\n    res = await self._query.get(\n  File \"/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/collections/grpc/query.py\", line 814, in __call\n    raise WeaviateQueryError(str(e), \"GRPC search\")  # pyright: ignore\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n        status = StatusCode.UNKNOWN\n        details = \"explorer: list class: extend: extend generate: client not found, empty provider\"\n        debug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"explorer: list class: extend: extend generate: client not found, empty provider\", grpc_status:2, created_time:\"2024-11-06T06:39:04.574035292-08:00\"}\"\n>.\n/home/razor/repos/assistant/.venvrag/lib/python3.10/site-packages/weaviate/warnings.py:329: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n            Please make sure to close the connection using `client.close()`.\n/usr/lib/python3.10/asyncio/selector_events.py:710: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=6 read=idle write=<idle, bufsize=0>>",
    "date_created": "2024-11-05T19:35:56.216Z",
    "has_accepted_answer": false,
    "title": "Ollama Embeddings call fails with wrong URL path: /api/embeddings",
    "topic_id": 7462
  },
  {
    "user_id": 3229,
    "conversation": "[Sam_Joel (2025-01-15T15:10:44.113Z)]: Is there a user creation API for the recently introduced RBAC functionality in weaviate . In the RBAC I found APIs to create roles, permissions and assign them to users but I found no API to create users which also seems to be crucial when supporting RBAC\nServer Setup Information\n\nWeaviate Server Version: 1.28.2\nDeployment Method: Docker\nClient Language and Version: Weaviate v4 client\nMultitenancy: Yes\n\n----------\n\n[Mohamed_Shahin (2025-01-16T10:14:31.814Z)]: Hello @Sam_Joel,\nRBAC is a relatively new feature in Weaviate, and as you know, it’s continuously evolving with new additions to enhance its capabilities and features\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nWeaviate\n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI encourage you to open a feature request on our GitHub. Your request is a very good one which I would say essential for a lot of developers.\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nweaviate/weaviate\n\n  Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of ...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBest regards,\nMohamed Shahin\nWeaviate Support Engineer",
    "date_created": "2025-01-15T15:10:44.069Z",
    "has_accepted_answer": true,
    "title": "User Creation in RBAC",
    "topic_id": 9790
  },
  {
    "user_id": 3578,
    "conversation": "[tapish_22.11 (2025-02-28T11:16:18.043Z)]: Firstly, if i create a collection in weaviate, is there any way to create multiple subindexes, like there are multiple subfolders in the collection.\nAnd, I have multiple PDFs which i want to save in a collection. I want to make a RAG agent to retrieve answers from any of the pdfs. And i want to save them in same collection but different indexes or names vectors to make retrieval more efficient. And whenever i add a new pdf, the embeddings of other pdfs do not get affected.\n\n----------\n\n[DudaNogueira (2025-02-28T11:25:10.774Z)]: hi @tapish_22.11 !!\nWelcome to our community \nYou can have a property called, for example, source where you can filter out or in the objects you want to generate the answers from.\nI have written an example using Langchain that does exactly this (both using Langchain and querying directly)\nIf you want to do one search thru all PDFs/objects you have, this is the correct approach. That’s because all those objects must be in the same vector space to be compared with.\nYou can also have multiple collections, where you store different content, and with an agentic approach, decide which collection(s) to search for.\nOne question: are you facing efficiency issues on retrieval?\nThanks!\n\n----------\n\n[tapish_22.11 (2025-03-03T09:18:59.988Z)]: Apologies! I should’ve replied back. Actually I am making a RAG where i have to retrieve answers from different PDFs. So i was using weaviate as vector database and Langchain as LLM framework. So what i wanted is, I want to create a collection where i will use multi-tenancy, and i want to save data of each pdf in one of each tenant. So, i saw your code, and during retrieval, or even similarity search, we have to give the name of tenant with the query. So is there any way that we can just give query and model will decide in which tenant to search for.\n\n----------\n\n[DudaNogueira (2025-03-03T14:21:49.950Z)]: hi @tapish_22.11 !!\nNot sure that having one PDF per tenant is optimal. If you separate them per a property (and Langchain already does it, using the source property), you can also create an agent that will understand that a query is about a specific PDF and search for it accordingly.\nWith that said, this is how You can accomplish an Agent that will query different tenants, depending on the query:\ncollection = client.collections.delete(\"Test\")\nclient.collections.create(\n    \"Test\",\n    multi_tenancy_config=wvc.config.Configure.multi_tenancy(enabled=True, auto_tenant_activation=True, auto_tenant_creation=True),\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n    generative_config=wvc.config.Configure.Generative.openai(),\n)\n\nwith client.batch.dynamic() as batch:\n    batch.add_object(\n        collection=\"Test\",\n        tenant=\"T1\",\n        properties={\"text\": \"object1\"},\n    )\n    batch.add_object(\n        collection=\"Test\",\n        tenant=\"T2\",\n        properties={\"text\": \"object2\"}, \n    )\n\nif client.batch.failed_objects:\n    print(f\"Found {len(client.batch.failed_objects)} failed objects\" )\n    print(client.batch.failed_objects)\n\n\nimport weaviate\n\nfrom langchain.agents import Tool\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\n\n# Initialize WeaviateVectorStore for each collection\nvectorstore = WeaviateVectorStore(client, \"Test\", \"text\", embedding=embeddings)\n\ndef query_collection1(query: str) -> str:\n    \"\"\"Queries Collection1 and returns the results.\"\"\"\n    results = vectorstore.similarity_search(query, k=3, tenant=\"T1\") #Return top 3 results\n    return \"\\n\".join([doc.page_content for doc in results])\n\ndef query_collection2(query: str) -> str:\n    \"\"\"Queries Collection2 and returns the results.\"\"\"\n    results = vectorstore.similarity_search(query, k=3, tenant=\"T2\")\n    return \"\\n\".join([doc.page_content for doc in results])\n\n# Define tools\ntools = [\n    Tool(\n        name=\"QueryCollection1\",\n        func=query_collection1,\n        description=\"Useful for when you need to query T1 for information.\",\n    ),\n    Tool(\n        name=\"QueryCollection2\",\n        func=query_collection2,\n        description=\"Useful for when you need to query T2 for information.\",\n    ),\n]\n\n# Defining the agent\nfrom langchain.agents import ZeroShotAgent, AgentExecutor\nfrom langchain import LLMChain\nfrom langchain_openai import OpenAI\n\n# Initialize LLM\nllm = OpenAI(temperature=0)\n\n# Set up the agent\nprefix = \"\"\"Answer the following questions as best you can. You have access to the following tools:\"\"\"\nsuffix = \"\"\"Begin! Remember to answer the question, and use the correct tool.\nQuestion: {input}\n{agent_scratchpad}\"\"\"\n\nprompt = ZeroShotAgent.create_prompt(\n    tools,\n    prefix=prefix,\n    suffix=suffix,\n    input_variables=[\"input\", \"agent_scratchpad\"],\n)\n\nllm_chain = LLMChain(llm=llm, prompt=prompt)\nagent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True) #Verbose for debugging.\nagent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n\n# running a query:\n\nquery1 = \"Tell me about the documents T2\"\nresponse1 = agent_chain.run(query1)\nprint(response1)\n\nand this should be the output:\n\nEntering new AgentExecutor chain…\nThought: I should query T2 for information about the documents.\nAction: QueryCollection2\nAction Input: “documents”\nObservation: object2\nThought: I should query T2 for the specific information about the documents.\nAction: QueryCollection2\nAction Input: “specific information”\nObservation: object2\nThought: I now know the final answer\nFinal Answer: The documents in T2 contain specific information.\n\n\nFinished chain.\nThe documents in T2 contain specific information.\n\nLet me know if that helps!\nThanks!",
    "date_created": "2025-02-28T11:16:17.999Z",
    "has_accepted_answer": false,
    "title": "Issue regarding collections in weaviate",
    "topic_id": 10599
  },
  {
    "user_id": 931,
    "conversation": "[Maxence_Oden (2024-09-16T13:53:06.144Z)]: Description\nThe distance field in the HybridVector.near_text doesn’t filter contrary to the near_text search. Is this the desired behavior or a bug? This issue seems to implement the same behavior as the near_text search. Improve Hybrid Search · Issue #4325 · weaviate/weaviate · GitHub\nFor me, objects with a distance superior to this parameter should be filtered out of the results (independently of the fusion score). In my case, the ability to filter the results with the near_text distance is useful, as we don’t have the vector distance and the BM25 score returned.\nThe results I got with the code in the Any additional Information section.\n== Near text ==\nno distance limit\nQueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('35ddc998-e530-44a2-8b6a-e65dc8cb9afb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=0.11371487379074097, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'title': 'article'}, references=None, vector={}, collection='Article')])\n== Near text ==\ndistance limit 0.1\nQueryReturn(objects=[])\n== Hybrid search ==\ndistance limit 0.1\nQueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('35ddc998-e530-44a2-8b6a-e65dc8cb9afb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'title': 'article'}, references=None, vector={}, collection='Article')])\n\nI would like a way to obtain the same result from the near_text search with the distance limit applied to the hybrid search. For example, with the scores returned after an hybrid search we would be able to apply an post filtering.\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: docker\nMulti Node? Number of Running Nodes: No\nClient Language and Version: python weaviate-client-4.8.1\nMultitenancy?: No\n\nAny additional Information\n# setup.py\nimport os\n\nimport weaviate\nfrom dotenv import load_dotenv\nfrom weaviate.classes.config import Configure, DataType, Property\n\nload_dotenv()\n\nclient = weaviate.connect_to_local(\n    headers={\"X-Azure-Api-Key\": os.getenv(\"AZURE_API_KEY\")}\n)\n\nclient.collections.delete(\"Article\")\nclient.collections.create(\n    \"Article\",\n    properties=[\n        Property(name=\"title\", data_type=DataType.TEXT),\n    ],\n    vectorizer_config=Configure.Vectorizer.text2vec_azure_openai(\n        base_url=os.environ.get(\"AZURE_BASE\"),\n        resource_name=os.environ.get(\"AZURE_RESOURCE_NAME\"),\n        deployment_id=os.environ.get(\"AZURE_DEPLOYMENT_ID\"),\n        vectorize_collection_name=False,\n    ),\n)\n\narticle = client.collections.get(\"Article\")\narticle.data.insert(\n    properties={\n        \"title\": \"article\",\n    },\n)\n\nimport os\n\nimport weaviate\nfrom dotenv import load_dotenv\nfrom weaviate.classes.query import HybridFusion, HybridVector, MetadataQuery, Move\n\nload_dotenv()\nclient = weaviate.connect_to_local(\n    headers={\"X-Azure-Api-Key\": os.getenv(\"AZURE_API_KEY\")}\n)\n\narticle = client.collections.get(\"Article\")\n\nresponse = article.query.near_text(\n    query=\"Article\", return_metadata=MetadataQuery(distance=True)\n)\nprint(f\"== Near text ==\\nno distance limit\\n{response}\")\nresponse = article.query.near_text(\n    query=\"Article\", distance=0.1, return_metadata=MetadataQuery(distance=True)\n)\nprint(f\"== Near text ==\\ndistance limit 0.1\\n{response}\")\n\nresponse = article.query.hybrid(\n    query=\"Article\", vector=HybridVector.near_text(query=\"article\", distance=0.1)\n)\nprint(f\"== Hybrid search ==\\ndistance limit 0.1\\n{response}\")\n\nclient.close()\n\n----------\n\n[Dirk (2024-09-17T07:36:15.241Z)]: Hi,\nit is not yet part of the docs, but there is a new parameter to filter all results based on the vector distance - so any result that has a distance higher than the max vector distance is filtered out:\n    objs_hy_cutoff = collection.query.hybrid(\n        query,\n        max_vector_distance=max_vector_distance,\n        return_metadata=wvc.query.MetadataQuery.full(),\n    ).objects\n\nnot totally sure why the distance is not working for the NT search, but I think it should not be used at all\n\n----------\n\n[Maxence_Oden (2024-09-17T09:56:19.746Z)]: Hello Dirk,\nThank you for your help. Your solution has resolved the issue.",
    "date_created": "2024-09-16T13:53:06.092Z",
    "has_accepted_answer": true,
    "title": "Hybrid Search near_text distance filtering",
    "topic_id": 4173
  },
  {
    "user_id": 11489,
    "conversation": "[mestanam (2025-03-17T14:31:22.315Z)]: Question:\nI have a question regarding Auto Schema in Weaviate.\nScenario:\n• Auto Schema is enabled\n\n\nCreate Collection A\n\n\nAdd the following object:\n\n\n{\n“text”: “test”,\n“files”: [\n{\n“path”: “path”,\n“name”: “name”\n}\n]\n}\n\n\nCreate Collection B\n\n\nAdd the following object:\n\n\n{\n“name”: “name”\n}\n\n\nCreate Collection C\n\n\nTry to add the following object, but an error occurs:\n\n\n{\n“files”: [“file”]\n}\nObservation:\nUpon checking the schema, I noticed that properties were not created separately for each collection. Instead, the properties were generated based on the property types from Collection A and Collection B.\nQuestion:\nWhy is this happening? How does Weaviate handle schema generation across multiple collections when Auto Schema is enabled?\nWeaviate version : 1.26.1\n\n----------\n\n[Mohamed_Shahin (2025-03-18T12:29:00.529Z)]: Hey @mestanam,\nWelcome to our community! Great to have you here.\nI haven’t come across any issues with Auto Schema across multiple collections before when I tested \nWould you be able to share a small script or notebook that you tested locally? I can try reproducing it on my end with it and see what’s happening.",
    "date_created": "2025-03-17T14:31:22.253Z",
    "has_accepted_answer": false,
    "title": "[Question] Weaviate Auto Schema: Why Are Properties Shared Across Collections?",
    "topic_id": 19930
  },
  {
    "user_id": 3243,
    "conversation": "[Axel_Straminsky (2025-01-30T14:08:42.009Z)]: I’m getting the following warning when I do “import weaviate” in python, even if afterwards I don’t do anything with weaviate.\nScreenshot from 2025-01-30 11-04-041622×398 189 KB\nHere is a thread of someone experiencing the same issue: asyncio/selector_events.py: ResourceWarning: unclosed transport _SelectorSocketTransport · langchain-ai/langchain · Discussion #18293 · GitHub\nI’m using Python 3.9.5, and weaviate-client = “4.10.4”\nDid someone encountered the same problem and managed to fix it?\n\n----------\n\n[DudaNogueira (2025-01-30T15:51:55.539Z)]: hi!\nThis will usually come up if you do not close the connection before creating a new one.\nLet me know if this helps.\n\n----------\n\n[Axel_Straminsky (2025-02-17T15:43:43.420Z)]: Hi @DudaNogueira,\nThis problem arises just from doing “import weaviate”, even if I don’t create a client afterwards.\n\n----------\n\n[DudaNogueira (2025-02-17T17:00:18.180Z)]: That’s strange \nDo you happen to see this same behavior if using a newer python version?\nThanks!\n\n----------\n\n[Axel_Straminsky (2025-02-17T17:24:29.936Z)]: Yes, I updated from version 3.9.5 to 3.11.11",
    "date_created": "2025-01-30T14:08:41.955Z",
    "has_accepted_answer": false,
    "title": "Weaviate client throwing \"ResourceWarning: unclosed transport\"",
    "topic_id": 9966
  },
  {
    "user_id": 2431,
    "conversation": "[cw257900 (2024-11-01T06:55:48.222Z)]: Description\n\nis it doable to deploy weaivate image to private azure cloud ? will the current image work ?\nimage: cr.weaviate.io/semitechnologies/weaviate:1.27.0\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-11-01T12:57:43.017Z)]: hi @cw257900 !!\nWelcome to our community! \nIt perfectly doable. You can deploy it yourself, using for example our official helm chart:\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate/weaviate-helm: Helm charts to deploy Weaviate to k8s\n\n    Helm charts to deploy Weaviate to k8s\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nOr, if you prefer, use our BYOC (Bring Your Own CLoud) services, so our team will deploy, monitor and support it for you, running it from your own cloud:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBYOC Vector Database | Weaviate\n\n  Seamlessly integrate our BYOC vector database with AWS, GCP, and Azure to ensure optimized performance and security.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[DudaNogueira (2025-03-06T12:56:43.353Z)]: Ps: If using Azure, make sure to use disk.csi.azure.com and not file.csi.azure.com\nas per doc: Kubernetes | Weaviate",
    "date_created": "2024-11-01T06:55:48.174Z",
    "has_accepted_answer": true,
    "title": "Can weaviate image being deployed to private azure?",
    "topic_id": 7371
  },
  {
    "user_id": 201,
    "conversation": "[evenfrost (2024-07-30T11:25:11.623Z)]: Description\nI’m currently migrating our app to TypeScript client v3 from v2, and we heavily rely on the QnA Transformers module. However, I couldn’t find any info on how to use it with TypeScript client v3, as all the examples are only for v2 of the library:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nQuestion Answering - transfomers | Weaviate - Vector Database\n\n  In short\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: TypeScript, weaviate-client@3.1.2\nMultitenancy?: yes\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-07-30T14:50:02.986Z)]: hi @evenfrost !!\nThe ask capability was not added to the grpc endpoint.\nin ts client v2 you can do a raw graphql query using:\nclient.graphql.raw()\nhowever this raw graphql query method was not included in ts v3 yet. \nI have asked internally, and it will be included in the next release.\nThanks for pointing it out!\n\n----------\n\n[evenfrost (2024-07-30T15:12:03.475Z)]: Hi @DudaNogueira ,\nBut in v2 you can just use\nawait client.graphql\n  .get()\n  .withClassName('Article')\n  .withAsk({\n    question: 'Who is the king of the Netherlands?',\n    properties: ['summary'],\n  })\n\nWithout running the raw query. Is this functionality planned for v3?\nBecause otherwise you’ll have to write a pretty complex wrapper around client.graphql.raw() by yourself if you need e.g. filters and additional params in the query (along with ask).\n\n----------\n\n[DudaNogueira (2024-07-30T20:19:17.472Z)]: I am not sure this will be ported to the new client.\nCan you please open a feature request in GitHub - weaviate/weaviate: Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of a cloud-native database​. so we can track the popularity of porting this feature to grpc?\nThanks!\n\n----------\n\n[evenfrost (2024-07-31T12:51:48.548Z)]: DudaNogueira:\n\ngrpc\n\n\nThanks for the explanation. To me, it looks more like the issue with the client library’s API and the necessity to write complex raw queries than the need for this module to use the new protocol. Because currently if you want add the ask part in your query, you’ll have to dump all the convenience of the client library with already defined methods for querying, filtering, choosing what to return etc., and write the same stuff by yourself to use the QnA module.\nIt would be great to write something like\nconst result = await myCollection.query.fetchObjects({\n  returnProperties: ['question', 'answer','round', 'points'],\n  filters: Filters.and(\n     myCollection.filter.byProperty('round').equal('Double Jeopardy!'),\n     myCollection.filter.byProperty('points').lessThan(600)\n    ),\n  limit: 3,\n  ask: {\n    question: 'Who is the king of the Netherlands?',\n    properties: ['summary'],\n })\n\nand leave the burden of choosing the internal stuff (e.g. protocol) to the client itself.\nBut these are just my considerations, for sure.\n\n----------\n\n[DudaNogueira (2024-07-31T15:00:12.463Z)]: I understand.\nHowever, the problem is that the new clients (both python v4 and ts v3 and) relies on GRPC for querying.\nThe old ones builds the graphql using the client syntax.\nThe new one builds the a GRPC query using the client syntax.\nThat’s why for using the client syntax as you described, it would need to expose the ask also in GRPC.\n\n----------\n\n[Dirk (2024-07-31T18:59:49.219Z)]: evenfrost:\n\nTo me, it looks more like the issue with the client library’s API and the necessity to write complex raw queries than the need for this module to use the new protocol\n\n\nTo give a bit more context - there are some older features that are rarely used anymore and the ask module is among them. They would need special support in the new GRPC protocoll which is not always easy to do and we decided against adding them. Given our capacity constrains it is unlikely that we will add it.\nHowever you can:\n\ncontinue to use TS v2 for the forseeable future. We do not have any plans to deprecate it\nuse TS v2 to build the gql query for you and pipe that into v3 raw gql query",
    "date_created": "2024-07-30T11:25:11.546Z",
    "has_accepted_answer": true,
    "title": "How to use Question Answering module with TypeScript v3 client?",
    "topic_id": 3220
  },
  {
    "user_id": 934,
    "conversation": "[saurbhhsharrma (2024-09-20T10:38:29.934Z)]: We deployed Weaviate in a Docker container on ECS with 4 vCPUs and 8 GB of RAM and are using EFS for storage.\nWe’ve noticed inconsistent behavior during startup, where Weaviate shows random problems. When we tried to launch 4 instances, only 1 started successfully, and the others failed to deploy because the service didn’t start at all.\nEven after logging into the other 3 containers, we are unable to get a 200 response from localhost:8080/v1, while it works for only one container at a time.\nThe Weaviate logs don’t provide any useful information regarding the delay, and we’re stuck because of this issue.\nIs there any way to troubleshoot this?\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: Docker\nMulti Node? Number of Running Nodes:  Single\nMultitenancy?: No\n\n@DudaNogueira @Mohamed_Shahin @Danny_Williams @Dirk\n\n----------\n\n[DudaNogueira (2024-09-23T08:12:29.884Z)]: hi @saurbhhsharrma !!\nDo you have any logs?\nAre those containers running as single node or as a cluster?\n\n----------\n\n[saurbhhsharrma (2024-09-23T09:06:20.282Z)]: It is being used on a Single node.\nBelow are the logs:\nimage1060×437 16.3 KB\n\n----------\n\n[DudaNogueira (2024-09-23T09:07:25.958Z)]: can you copy and paste the entire logs? from start to quit?\nThis looks only a partial log\n\n----------\n\n[Jose_Luis_Franco (2024-09-27T07:48:21.014Z)]: Hello @saurbhhsharrma,\nI believe, the main problem here is that you are using Docker containers to deploy Weaviate instead of the weaviate-helm charts, which is the standard deployment process for Kubernetes. When starting as a docker container, unless configured in the environment variables, each docker instance won’t be aware of the rest of the docker instances. That’s why it is recommended to deploy using weaviate-helm, because it takes care of configuring the environment variables properly, so that a cluster gets succesfuly created.\nIf you are still interested into using Docker compose for the deployment, here is an example of a docker compose template for deploying multinode clusters.\nI hope this helps!\nRegards,\nJosé Luis",
    "date_created": "2024-09-20T10:38:29.873Z",
    "has_accepted_answer": false,
    "title": "Issue with Weaviate Container on Start-up",
    "topic_id": 4218
  },
  {
    "user_id": 854,
    "conversation": "[cpwalker (2024-05-07T21:46:06.089Z)]: Hi there, I have questions related to two topics, both motivated by needing to significantly increase query throughput.\nDescription\n1. Increase number of shards\n(Based on the advice given here)\nI did not set the number of shards when creating my collection, so I have just 1 shard currently. The documentation says the default number of shards though is 128.\nIs 128 shards the recommended number to start with?\nCan I update the number of shards on a collection that already exists?\n2. Update HNSW vector index parameters\nI am using a HNSW index. I would like to decrease dynamicEfMax and increase efConstruction. My understanding is that these changes would make queries faster but imports slower, a trade-off I can make.\nHow do I update dynamicEfMax and efConstruction for an existing collection?\nServer Setup Information\n\nWeaviate Server Version: 1.24\nDeployment Method: Docker\nMulti Node? Number of Running Nodes:  1 node\nClient Language and Version: Python v4\n\n----------\n\n[DudaNogueira (2024-05-08T00:12:48.866Z)]: hi @cpwalker !\nthe 128 value is for the virtualPerPhysical shards.\nefConstruction is not a mutable configuration, as per the docs on mutability.\nSo for that one you will need to reindex your collections.\ndynamicEfMax, on the other hand, is mutable.\nIf you want to increase query throughput , your best path is leveraging replication and using a multi node deployment.\nYou can read more on that here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nReplication Architecture | Weaviate - Vector Database\n\n  Weaviate can automatically replicate data across nodes in the background in a cluster with multiple server nodes. This enables a variety of use cases. For example, if a node goes down, another node can shoulder the load without loss of availability...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.\nThanks!\n\n----------\n\n[cpwalker (2024-05-08T00:31:16.704Z)]: Thanks @DudaNogueira . Do you think it’s worth experimenting with desiredCount in the shard config? If so, what values would you try? I need to stay on 1 node for now.\nIf it helps, here is additional context: I have ~8m vectors, each with 768 dimensions. The node has 24 virtual CPUs and 120GB RAM.\n\n----------\n\n[DudaNogueira (2024-05-08T19:35:21.481Z)]: If you can only use 1 node, I don’t believe having more shards on that same node will be do any good for performance.\nMuch the opposite, as Weaviate will need to check multiple shards for a query in the same node. \nIf, by any chance, you are running a multitenant environment, then it could help. In fact, each tenant is a “shard” on it’s own. The upside of using tenants is that you can enable and disable.\nOn that topic, multi tenant, 1.25 will bring some really nice cool features, like tenant TTL: it can be auto deactivated after some time of inactivity and activated when a new event come it’s way and it is in a COLD/DEACTIVATED state.\nIn order to increase QPS, multi node is something to consider for you use case.\nOther than that, it is about closely monitoring resource consumption, and making sure it has enough room to operate.\n\n----------\n\n[cpwalker (2024-05-08T21:44:45.609Z)]: Thank you this is very helpful.\n\n----------\n\n[bsandi (2024-08-28T18:15:34.079Z)]: Hey @DudaNogueira,\nI am interested in the tenant TTL, and I wasn’t able to find any documentation around it. Was that implemented?\nI only see tenant states and that doesn’t work for my use case.\nIt would be great if you can provide any updates\n\n----------\n\n[DudaNogueira (2024-08-28T20:40:36.768Z)]: hi @bsandi !!\nWelcome to our community. \nThis was under development and it was internal.\nI believe it was already delivered to some of our paying customers.\nLet me know if you want to connect to our sales engineers so we can understand your use case better. Also they have more context on this feature.\nThanks!!",
    "date_created": "2024-05-07T21:46:06.025Z",
    "has_accepted_answer": true,
    "title": "Increase number of shards and update HNSW vector index parameters",
    "topic_id": 2231
  },
  {
    "user_id": 3578,
    "conversation": "[tapish_22.11 (2025-03-06T07:37:01.113Z)]: So, i have made a chatbot. And i want to save the userdata from chatbot into weaviate. So, i am extracting 4 things from that chatbot, user_id, query, response from chatbot, and time taken for response. I want to save it in a structured format and  save it to weaviate. First of all, i want to use my own embeddings, i.e., huggingface embeddings. And i also want to save them in a way that semantic search would be possible in it. So, what are the possibe ways to do this?\nThank You!\n\n----------\n\n[DudaNogueira (2025-03-06T13:03:59.013Z)]: hi @tapish_22.11 !!\nWhen you ingest your data, the collection schema definition will use only fields you want to compose that object vectors, or you can also send all of them.\nYou can both generate the vectors yourself (Bring your own Vectors)  our use huggingface  both as a service  or locally hosted.\nLet me know if this helps!\nTHanks!",
    "date_created": "2025-03-06T07:37:01.062Z",
    "has_accepted_answer": true,
    "title": "Uploading tables to weaviate database",
    "topic_id": 10895
  },
  {
    "user_id": 1064,
    "conversation": "[Arturo_Zambrano (2024-06-13T04:26:05.834Z)]: Is there a way to reach Verba Chat without the UI, through an API or a request for example.\nI have a main app, an currently using Ollama runs in my local, and right now I have a little node application that functions like a RAG, I’m embedding the queries that I get, comparing the vectors and then giving to ollama the context and original query to get the answer.\nIs there a way to introduce Verba here? The UI is really nice, but for the workflow I need an endpoint, is this possible currently?\n\n----------\n\n[DudaNogueira (2024-06-14T14:32:06.974Z)]: Hi @Arturo_Zambrano !! Welcome to our community!\nVerba UI consume  two apis (tested on http://verba.weaviate.io) when doing a query\nhttps://verba.weaviate.io/api/query\nand a websocket at:\nwss://verba.weaviate.io/ws/generate_stream\nWith those you can use probably use it’s backend directly.\nHowever, I don’t believe those are documented or intended to be used outside of that UI.\nAdditionally, you can always code some api that will connect to Weaviate directly.\nI have not found a feature request on this:\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nIssues · weaviate/Verba\n\n  Retrieval Augmented Generation (RAG) chatbot powered by Weaviate - Issues · weaviate/Verba\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIt would be interesting to open one, as this may also be a popular demand from other users.\nLet me know if this helps.\nThanks!\n\n----------\n\n[Kieran_Sears (2025-03-31T10:36:52.418Z)]: I’ve been hacking on the same thing, I pieced a good bit together by going on the chrome developer console while running the default verba chat UI and watching the network tab (there’s an option to copy requests as cURL which is mucho helpful).\nConnecting first requires credentials, these can simply be hardcoded for development but will require making secure by having an actual key later and setting AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED to false:\n{\n    \"url\": \"http://weaviate:8080\",\n    \"key\": \"\",\n    \"deployment\": \"Docker\"\n}\n\nI have my verba / weaviate running in a docker compose, hence why my domain is weaviate, I could also have it as localhost I believe as I’m exposing the port in my compose config, but I’ve not tested that and this works just fine for me at the moment.\nservices:\n  verba:\n    build:\n      context: .\n      dockerfile: ./external/verba/Dockerfile \n    ports:\n      - 8000:8000\n    environment:\n      - WEAVIATE_URL_VERBA=http://weaviate:5433\n      - OPENAI_API_KEY=$OPENAI_API_KEY\n      - COHERE_API_KEY=$COHERE_API_KEY\n      - OLLAMA_URL=http://host.docker.internal:11434\n      - OLLAMA_MODEL=$OLLAMA_MODEL\n      - OLLAMA_EMBED_MODEL=$OLLAMA_EMBED_MODEL\n      - UNSTRUCTURED_API_KEY=$UNSTRUCTURED_API_KEY\n      - UNSTRUCTURED_API_URL=$UNSTRUCTURED_API_URL\n      - GITHUB_TOKEN=$GITHUB_TOKEN\n    volumes:\n      - verba_data:/data/\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8000 || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: semitechnologies/weaviate:1.25.10\n    ports:\n      - 5433:8080\n      - 8001:8080\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n    environment:\n      OPENAI_APIKEY: $OPENAI_API_KEY\n      COHERE_APIKEY: $COHERE_API_KEY\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'e'\n      CLUSTER_HOSTNAME: 'node1'\n\n(your dockerfile location will differ or you could just use the default image: semitechnologies/verba, but I like hacking with the server/frontend code to debug so…)\nAs @DudaNogueira points out there’s a websocket you listen to responses through (wss://verba.weaviate.io/ws/generate_stream, or more likely if you run it as a docker container ws://localhost:8000/ws/generate_stream) that you’ll want to connect to first.\nThen sending, say a query request, requires that you first hit the /api/get_rag_config endpoint and put it’s response into the query request’s payload under a field named “RAG”. You’ll also need the “origin” header headers={\"Origin\": \"<<your_client_url>>\"}\nI think this should get you started. Maybe I’ll throw a PR together for an API doc generator that can be hosted for others, or develop a client library if there’s a language which is most popular like python. Put in a request in Verba’s Github under “Issues”, if it gains enough popularity then it’s more likely to get worked on!\nHope this all helps and Happy hacking",
    "date_created": "2024-06-13T04:26:05.786Z",
    "has_accepted_answer": false,
    "title": "Is there a way to reach Verba Chat without the UI, through an API or a request for example",
    "topic_id": 2694
  },
  {
    "user_id": 1108,
    "conversation": "[dhanshew72 (2024-07-23T21:30:35.755Z)]: Description\nI’m using the Weaviate Python client to run a backup job to dump files into S3. I am using a replicationConfig with a factor of 2 with 2 nodes and I get the following error message:\nweaviate.exceptions.UnexpectedStatusCodeError: Backup creation! Unexpected status code: 422, with response body: {'error': [{'message': 'node {\"node1\" \"XX.XX.XX.XX:XXXX\"}: cannot commit : class MyClass doesn\\'t exist'}]}.\n\nI can run inserts and query against the data, but I am unable to run a backup because it doesn’t think the data exists in a second node.\nAny ideas what could be wrong with this setup? Possible connection issue?\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method: Docker on AWS ECS\nMulti Node? Number of Running Nodes: 2\nClient Language and Version: 4.6.5\nMultitenancy?: Yes\n\nAny additional Information\nOnly other problem I found was this log:\n{\"action\":\"create_backup\",\"level\":\"error\",\"msg\":\"coordinator aborted operation\",\"time\":\"2024-07-23T21:18:29Z\"}\n\nExtra logs I found from inserts, but nothing erroring out on it.\n{\"got\":0,\"level\":\"debug\",\"msg\":\"wait for update version\",\"time\":\"2024-07-23T21:14:51Z\",\"want\":81}\n\n----------\n\n[DudaNogueira (2024-07-24T14:03:46.289Z)]: Hi @dhanshew72 !!\nThat’s strange.\nin your http://localhost:8080/v1/nodes?output=verbose can you see your 2 nodes correctly?\n\n----------\n\n[dhanshew72 (2024-07-24T16:11:28.374Z)]: Here’s what I got\n{\"nodes\":[{\"batchStats\":{\"queueLength\":0,\"ratePerSecond\":171},\"gitHash\":\"6fd2432\",\"name\":\"node0\",\"shards\":[{\"class\":\"ClassName\",\"compressed\":false,\"loaded\":true,\"name\":\"shard_0\",\"objectCount\":1080,\"vectorIndexingStatus\":\"READY\",\"vectorQueueLength\":0},{\"class\":\"ClassName\",\"compressed\":false,\"loaded\":true,\"name\":\"shard_1\",\"objectCount\":88,\"vectorIndexingStatus\":\"READY\",\"vectorQueueLength\":0}],\"stats\":{\"objectCount\":1168,\"shardCount\":2},\"status\":\"HEALTHY\",\"version\":\"1.26.1\"},{\"batchStats\":{\"queueLength\":0,\"ratePerSecond\":0},\"gitHash\":\"6fd2432\",\"name\":\"node1\",\"shards\":null,\"stats\":{\"objectCount\":0,\"shardCount\":0},\"status\":\"HEALTHY\",\"version\":\"1.26.1\"}]}\n\nSeems like it’s just not writing to the other node which is shocking because all other logs show the connection is working.\n\n----------\n\n[dhanshew72 (2024-07-24T17:48:12.245Z)]: Hmm, I downgraded to version 1.24 and it showed the correct output curling that endpoint again.",
    "date_created": "2024-07-23T21:30:35.704Z",
    "has_accepted_answer": false,
    "title": "Unable to Run Backup Process w/ Python Client",
    "topic_id": 3138
  },
  {
    "user_id": 1649,
    "conversation": "[lrx (2024-10-08T10:07:59.881Z)]: Description\nHello dear weaviate team,\nI have came accross an issue using a with_where simple query. Most of previous queries where succesful, without any problem, but somehow, regarding a handful of entries, I have the following behaviour:\nLet’s say I do a simple filter query on my database, that contains, among others, infos on documents. (we focus here on their unique id (uid) and version (version))\nres = (db_client.query\n.get(    \n    collection,\n    [\"uid\",\"version\"]\n    )\n.with_where(    \n    {\n        \"operator\": \"And\",\n        \"operands\": [\n        {            \n             \"path\": [\"uid\"],\n             \"operator\": \"Equal\",\n             \"valueText\": \"QXM8H7\",\n         }\n        ]\n    }\n)\n.do())\nprint(res)\n\nThe output is\n{'data': {'Get': {'collection_name': [{'uid': 'QXM8H7', 'version': 'v2_14'}]}}}\n\nbut when I add a condition on the version\nres = (db_client.query\n.get(    \n    collection,\n    [\"uid\",\"version\"]\n    )\n.with_where(    \n    {\n        \"operator\": \"And\",\n        \"operands\": [\n        {            \n             \"path\": [\"uid\"],\n             \"operator\": \"Equal\",\n             \"valueText\": \"QXM8H7\",\n         },\n        {\n            \"path\": [\"version\"],\n            \"operator\": \"Equal\",\n            \"valueText\": \"v2_14\"\n        }\n        ]\n    }\n)\n.do())\nprint(res)\n\nThe output becomes\n{'data': {'Get': {'collection_name': []}}}\n\nSo, what is happening here ? FYI,\n\nthe tokenization used are both word, but I am looking or exact matches anyways, so it seems unlikely to be the cause.\nBoth previous queries worked well on other documents\nThe collection on which I’m performing queries contains around 990 000 entries, maybe the indexing method struggles with this many entries ?\nthere are other “fields” (other than uid and version), around 30, but they aren’t all filterable nor searchable.\n\nServer Setup Information\n\nDeployment Method: Don’t have the details yet, custom installation\nMulti Node? No.\nClient Language and Version: Python 3.12.3 (API v3)\nMultitenancy? No.\n\nAny additional Information\nTell me if you need me to provide additional information\nThank you for your time!\n\n----------\n\n[lrx (2024-10-31T08:59:43.167Z)]: behaviour fixed by improving the RAM of the server hosting the deployment.\n\n----------\n\n[DudaNogueira (2024-10-31T12:48:00.631Z)]: Oh Wow!\nFirst thanks for sharing, @lrx\nand secondly sorry, as we missed this message \nWhen you say improved, you mean you have increased weaviate allocated memory, right?\nCan you share the version you are running? Even with less memory, this isn’t the expected behavior.",
    "date_created": "2024-10-08T10:07:59.820Z",
    "has_accepted_answer": true,
    "title": "Inconsistent behaviour of with_where search",
    "topic_id": 4468
  },
  {
    "user_id": 1232,
    "conversation": "[gratchie11 (2024-07-23T02:02:41.138Z)]: New to vertexAI/GCP.  I’m trying to do generative search / basic RAG using vertex ai and weaviate vector db. I’m trying to follow the docs but kept running into this issue. Generative Search - Google | Weaviate - Vector Database\nAny thoughts on what could be causing error like this:\n“message”: “remote client vectorize: connection to Google failed with status: 400 error: Invalid resource field value in the request.”\nI’m using Docker Compose, VertexAI.\n\n----------\n\n[antas-marcin (2024-07-23T08:19:08.333Z)]: Hello, we have tests that verify that Weaviate works with Vertex AI and they are green, which version of Weaviate are you using? and which model you are trying out?\n\n----------\n\n[gratchie11 (2024-07-31T13:49:55.223Z)]: Hi @antas-marcin ,\nI have the following versions\nweaviate-client == 4.5.5\ngemini-pro==gemini-1.5-pro-001\nDo you have a reference architecture / repo that I can refer to? thanks\n\n----------\n\n[DudaNogueira (2024-07-31T14:38:37.617Z)]: hi @gratchie11 !\nCan you try with the latest version?\nAlso, can you share some code we can reproduce this issue?\nThanks!",
    "date_created": "2024-07-23T02:02:41.077Z",
    "has_accepted_answer": false,
    "title": "Vertex AI and Weaviate",
    "topic_id": 3128
  },
  {
    "user_id": 3376,
    "conversation": "[user_mollang (2025-02-26T07:01:47.240Z)]: I’m using Weaviate v4 to create a collection and index data. However, when I try to search the indexed data, both multi target vector search and fetch_by_object_id fail with a gRPC-related error.\nCould you help me figure out where the issue is?\nMy Weaviate instance is running via Docker Compose, and I’m using Weaviate version 1.29.0 (also tested with 1.27.0, same issue).\nEnv\nimage: cr.weaviate.io/semitechnologies/weaviate:1.29.0\nweaivate python client: 4.11.0\npython 3.10.12\nError Message\nQuery call with protocol GRPC search failed with message The request to Weaviate failed after 5 retries. Details: <AioRpcError of RPC that terminated with:\n        status = StatusCode.UNAVAILABLE\n        details = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:115.x.x.x:50054: Failed to connect to remote host: connect: Connection refused (111)\"\n        debug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-02-26T06:45:13.059068484+00:00\", grpc_status:14, grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv4:115.x.x.x:50054: Failed to connect to remote host: connect: Connection refused (111)\"}\" \n\nSetup Details\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8083'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.29.0\n    ports:\n    - 8083:8083\n    - 50054:50054\n    ipc: host\n    volumes:\n    - ./weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      ASYNC_INDEXING: 'true'\n      DISABLE_TEMETRY: 'true'\n      LOG_LEVEL: 'debug'\n      QUERY_DEFAULTS_LIMIT: 100\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      DISK_USE_WARNING_PERCENTAGE: 80\n      DISK_USE_READONLY_PERCENTAGE: 95\n      MEMORY_READONLY_PERCENTAGE: 95\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: ''\n      CLUSTER_HOSTNAME: 'node1'\n      GOMAXPROCS: 48\n\n\nPython Create and Insert Code\nimport os \nimport re\nfrom weaviate.classes.query import MetadataQuery\nimport weaviate\nfrom weaviate.connect import ConnectionParams\nfrom weaviate.classes.init import AdditionalConfig, Timeout, Auth\nfrom weaviate.classes.config import Configure, Property, DataType, VectorDistances, VectorFilterStrategy\nfrom weaviate.classes.query import HybridFusion\nfrom weaviate.classes.query import TargetVectors, MetadataQuery\nfrom auto_encoder import auto_encoder\nfrom tqdm import tqdm \n\n\"\"\"Collection creation code (multiple target vectors)\"\"\"\nvdb_grpc_host = 'localhost'\nvdb_http_port = '8083'\nvdb_http_host = 'localhost'\nvdb_grpc_port = '50054'\n\nconnection_params = ConnectionParams.from_params(\n    http_host=vdb_http_host,\n    http_port=vdb_http_port,\n    grpc_host=vdb_grpc_host,\n    grpc_port=vdb_grpc_port,\n    http_secure=False,\n    grpc_secure=False,\n)\nadditional_config = AdditionalConfig(\n    timeout=Timeout(init=30, query=60, insert=120), \n)\n\nconnection = weaviate.WeaviateClient(\n    connection_params=connection_params,\n    additional_config=additional_config,\n    skip_init_checks=True\n)\n\nconnection.connect()\nCOLLECTION_ID = 'Test'\nres = connection.collections.create(\n    COLLECTION_ID,\n    vectorizer_config=[\n        Configure.NamedVectors.none(name=\"name\", vector_index_config=Configure.VectorIndex.hnsw()),\n        Configure.NamedVectors.none(name=\"content\", vector_index_config=Configure.VectorIndex.hnsw()),\n    ]\n)\n\n\"\"\"Collection data indexing code\"\"\"\ndata = {\n    \"name\": \"sample name\",\n    \"content\": \"blahblah\",\n    \"length\": 435\n}\n\nvector = {\n    'name': name_v, \n    'content': content_v\n}\n\ntarget_collection = connection.collections.get(COLLECTION_ID)\nuuid = target_collection.data.insert(\n    properties=data,\n    vector=vector\n)\nprint(uuid)  # > UUID('d15dc94b-efe4-4e92-8e69-0af29c6f6755')\n\npython search Code\ncollection = connection.collections.get(COLLECTION_ID)\nprint(\"----collection-----\")\nprint(collection)\n\ntext_list = [\"name_test\", \"content_v\"]\nname_v, content_v = auto_encoder.local_embedding(text_list, ENCODER_ID)\nprint(len(name_v))  # > 4096\n\ntry:\n    vector_map = {\n        \"name\": name_v,\n        \"content\": content_v\n    }\n\n    response = collection.query.near_vector(\n        near_vector=vector_map,\n        target_vector=[\"name\", \"content\"],\n        return_metadata=MetadataQuery(distance=True)\n    )\n\n    print(\"====response====\")\n    for o in response.objects:\n        print(o.properties)\n        print(o.metadata.distance)\nexcept Exception as e:\n    print(str(e))\nfinally:\n    connection.close()\n\n----------\n\n[Dirk (2025-02-26T08:11:51.639Z)]: Hey, you need to set the GRPC_PORT environment variable.",
    "date_created": "2025-02-26T07:01:47.181Z",
    "has_accepted_answer": true,
    "title": "[Question] gRPC Connection Issues in Weaviate v4 (Hybrid Search & fetch_by_object_id Failing)",
    "topic_id": 10554
  },
  {
    "user_id": 1258,
    "conversation": "[haozhuoyuan (2024-07-29T15:39:18.559Z)]: import time\nimport weaviate\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\nfrom llama_index.vector_stores.weaviate import WeaviateVectorStore\nfrom llama_index.core.node_parser import SentenceSplitter\nfrom llama_index.core import StorageContext, Settings\nfrom llama_index.readers.file import PyMuPDFReader\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.llms.openai import OpenAI\nfrom dotenv import load_dotenv, find_dotenv\nfrom weaviate.classes.query import MetadataQuery\n# Load environment variables\n_ = load_dotenv(find_dotenv())\nimport nest_asyncio\nnest_asyncio.apply()  # Only needed in Jupyter notebooks\n\n# 连接到local,需要启动docker\n# weaviate_client = weaviate.connect_to_local(host=\"localhost\", port=8080, grpc_port=50051, skip_init_checks=True)\n# weaviate_client = weaviate.Client(\"http://localhost:8080\")\nweaviate_client = weaviate.connect_to_local()\n# Set global LLM and embedding models\nSettings.llm = OpenAI(temperature=0, model=\"gpt-4o\")\nSettings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=512)\nsplitter = SentenceSplitter(chunk_size=512, chunk_overlap=100)\n# Load PDF documents\n# documents = SimpleDirectoryReader(\"./data\", file_extractor={\".pdf\": PyMuPDFReader()}).load_data()\ndocuments = SimpleDirectoryReader(\"./data1\").load_data()\n\n# Split nodes\nnodes = splitter.get_nodes_from_documents(documents)\nprint(nodes)\n# schema = {\n#     \"classes\": [\n#         {\n#             \"class\": \"TextNode\",\n#             \"properties\": [\n#                 {\"name\": \"id_\", \"dataType\": [\"string\"]},\n#                 {\"name\": \"embedding\", \"dataType\": [\"number[]\"]},\n#                 {\"name\": \"file_path\", \"dataType\": [\"string\"]},\n#                 {\"name\": \"file_name\", \"dataType\": [\"string\"]},\n#                 {\"name\": \"file_type\", \"dataType\": [\"string\"]},\n#                 {\"name\": \"file_size\", \"dataType\": [\"int\"]},\n#                 {\"name\": \"creation_date\", \"dataType\": [\"string\"]},\n#                 {\"name\": \"last_modified_date\", \"dataType\": [\"string\"]},\n#                 {\"name\": \"source\", \"dataType\": [\"string\"]},\n#                 {\"name\": \"text\", \"dataType\": [\"text\"]},\n#                 {\"name\": \"start_char_idx\", \"dataType\": [\"int\"]},\n#                 {\"name\": \"end_char_idx\", \"dataType\": [\"int\"]},\n#                 {\"name\": \"metadata_str\", \"dataType\": [\"string\"]},\n#                 {\"name\": \"content\", \"dataType\": [\"text\"]},\n#             ],\n#         },\n#     ]\n# }\n# try:\nif weaviate_client.collections.exists(\"TextNode\"):\n    weaviate_client.collections.delete(\"TextNode\")\nschema = {\n           \"class\": \"TextNode\",\n           \"properties\": [\n               {\"name\": \"id_\", \"dataType\": [\"string\"], },\n               {\"name\": \"embedding\", \"dataType\": [\"number[]\"], },\n               {\"name\": \"file_path\", \"dataType\": [\"string\"], },\n               {\"name\": \"file_name\", \"dataType\": [\"string\"], },\n               {\"name\": \"file_type\", \"dataType\": [\"string\"], },\n               {\"name\": \"file_size\", \"dataType\": [\"int\"], },\n               {\"name\": \"creation_date\", \"dataType\": [\"string\"], },\n               {\"name\": \"last_modified_date\", \"dataType\": [\"string\"], },\n               # {\"name\": \"source\", \"dataType\": [\"string\"], },\n               {\"name\": \"text\", \"dataType\": [\"text\"], },\n               {\"name\": \"start_char_idx\", \"dataType\": [\"int\"], },\n               {\"name\": \"end_char_idx\", \"dataType\": [\"int\"], }\n               # {\"name\": \"metadata_str\", \"dataType\": [\"string\"], },\n               # {\"name\": \"content\", \"dataType\": [\"text\"], },\n           ]\n       }\nweaviate_client.collections.create_from_dict(schema)\n# finally:\n#     weaviate_client.close()\n# if not weaviate_client.schema.contains(schema):\n#     weaviate_client.schema.create(schema)\n# if not weaviate_client.collections.exists(\"TextNode\"):\n#     weaviate_client.collections.create(\"TextNode\")\n# # 删除现有的类（如果存在）\n# if weaviate_client.schema.contains(\"TextNode\"):\n#     weaviate_client.schema.delete_class(\"TextNode\")\n\n\n# 将节点数据添加到 Weaviate\ntry:\n    collection = weaviate_client.collections.get(\"TextNode\")\n    data_lines = []\n    for node in nodes:\n        embedding = Settings.embed_model.get_text_embedding(node.text)  # 生成嵌入\n        node.embedding = embedding  # 设置嵌入\n        properties = {\n            \"id\": node.id_,\n            \"embedding\": node.embedding,\n            \"file_path\": node.metadata.get(\"file_path\"),\n            \"file_name\": node.metadata.get(\"file_name\"),\n            \"file_type\": node.metadata.get(\"file_type\"),\n            \"file_size\": node.metadata.get(\"file_size\"),\n            \"creation_date\": node.metadata.get(\"creation_date\"),\n            \"last_modified_date\": node.metadata.get(\"last_modified_date\"),\n            # \"source\": node.metadata.get(\"source\"),\n            \"text\": node.text,\n            \"start_char_idx\": node.start_char_idx,\n            \"end_char_idx\": node.end_char_idx,\n            # \"metadata_str\": node.metadata_template,\n            # \"content\": node.text,\n        }\n        data_lines.append(properties)\n    print(data_lines)\n    with collection.batch.dynamic() as batch:\n        for data_line in data_lines:\n            batch.add_object(properties=data_line)\n    print(\"node insert completation！！！！！！！！！！！\")\n\n\n    # jeopardy = weaviate_client.collections.get(\"TextNode\")\n    # response = collection.query.near_text(\n    #     query=\"docker部署\",\n    #     limit=2,\n    #     return_metadata=MetadataQuery(distance=True)\n    # )\n    #\n    # for o in response.objects:\n    #     print(o.properties)\n    #     print(o.metadata.distance)\n    # 使用 REST API 进行查询\n    # query = {\n    #     \"query\": {\n    #         \"nearText\": {\n    #             \"concepts\": [\"docker部署\"],\n    #         }\n    #     },\n    #     \"limit\": 2,\n    #     \"class\": \"TextNode\"\n    # }\n    #\n    # response = weaviate_client.collections.get(query)\n    # print(response)\n    #\n    # for o in response['data']['Get']['TextNode']:\n    #     print(o['properties'])\n    #     print(o['_additional']['distance'])\n\n    # from weaviate.collections import Collection\n    #\n    # my_collection = weaviate_client.collections.get(\"TextNode\")\n    #\n    #\n    # def work_with_collection(collection: Collection):\n    #     # Do something with the collection, e.g.:\n    #     r = collection.query.near_text(query=\"docker部署\")\n    #     return r\n    # response = work_with_collection(my_collection)\n    # for o in response['data']['Get']['TextNode']:\n    #     print(o['properties'])\n    #     print(o['_additional']['distance'])\n    # exit()\n    # Create Vector Store\n    # vector_store = WeaviateVectorStore(weaviate_client=weaviate_client, index_name=\"TextNode\", text_key=\"content\")\n    vector_store = WeaviateVectorStore(weaviate_client=weaviate_client, index_name=\"TextNode\")\n    # vector_store.delete_nodes()\n    # Specify Vector Store for index\n    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n    index = VectorStoreIndex.from_vector_store(vector_store)\n    # index = VectorStoreIndex.from_vector_store()\n    print(index.index_struct)\n    print(index.storage_context)\n\n    query_engine = index.as_query_engine()\n\n    while True:\n        question = input(\"User: \")\n        if question.strip() == \"\":\n            break\n        start_time = time.time()\n        response = query_engine.query(question)\n        end_time = time.time()\n        print(f\"Time taken: {end_time - start_time} seconds\")\n        print(f\"AI: {response}\")\nfinally:\n    weaviate_client.close()\n\n----------\n\n[DudaNogueira (2024-07-29T17:47:54.137Z)]: hi @haozhuoyuan !\nWelcome to our community! \nNot sure what is your question here \nIf you are looking for error handling by doing batches:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.",
    "date_created": "2024-07-29T15:39:18.478Z",
    "has_accepted_answer": false,
    "title": "[Question] client.batch.failed_objects or collection.batch.failed_objects for the failed objects.",
    "topic_id": 3211
  },
  {
    "user_id": 1263,
    "conversation": "[Anna_Caroline_Symond (2024-07-30T17:18:19.623Z)]: I am trying to use Weaviate with Hugging Face to create vectors to compare semantic similarity, but I keep getting this error: “Every object failed during insertion. Here is the set of all errors: failed with status: 400 error: Authorization header is correct, but the token seems invalid”\nWhen I test to make sure my client is properly connected, it returns true, so I’m confused how the token can be invalid. I’m trying to convert each line in a txt file into a vector, but the error arises when I try to insert the objects themselves. All of my env variables match the keys I was given on WCD and Hugging Face. Also, on Hugging Face, I edited permissions like this:\nScreenshot 2024-07-30 at 1.16.12 PM1894×584 73.4 KB\nHere’s my code. The error arises from the line: test.data.insert_many(objs).\nimport weaviate, os\nimport weaviate.classes as wvc\nfrom sentence_transformers import SentenceTransformer\n\n\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url= os.getenv(\"WEAVIATE_INSTANCE_URL\"),\n    auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"W_API_KEY\")),\n    headers={\n         \"X-HuggingFace-Api-Key\": \"H_F_API_KEY\"  \n    }\n)\nprint(os.getenv(\"H_F_API_KEY\"))\nprint(client.is_ready())\nclient.collections.delete(\"Test\")\ntry:\n    test = client.collections.create(\n        name=\"Test\",\n        vectorizer_config=[\n        wvc.config.Configure.NamedVectors.text2vec_huggingface(\n            name=\"title_vector\",\n            source_properties=[\"title\"],\n            model=\"sentence-transformers/all-MiniLM-L6-v2\",\n        )\n    ],\n    )\n    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n    with open('test1.txt', 'r') as file:\n        lines = [line.strip() for line in file.readlines()]\n\n    vectors = model.encode(lines)\n\n    objs = []\n    for line,vector in zip(lines, vectors):\n        objs.append({\n            \"text\": line,\n            \n    })\n        \n    test = client.collections.get(\"Test\")\n    test.data.insert_many(objs)\n\nfinally:\n    client.close()\n\n----------\n\n[DudaNogueira (2024-07-31T20:48:06.289Z)]: hi @Anna_Caroline_Symond !!\nWelcome to our community \nThis message comes directly from hugging face Api. It indicates that your Hugging Face api token is wrong, not Weaviate’s.\nAlso, there are some other issues with this code, like not passing the vectors your encoded yourself. This will trigger Weaviate to vectorize your object using the Hugging Face.\nYou also created a named vector that uses  title property as source, but was using text as the property receiving the  data.\nI also changed the code to use batch insert, as they can perform better for large amounts of data ingestion.\nHere is my take on this:\nimport weaviate\nimport os\nimport weaviate.classes as wvc\nfrom sentence_transformers import SentenceTransformer\n\nclient = weaviate.connect_to_local(\n    headers={\n        \"X-HuggingFace-Api-Key\": os.getenv(\"HUGGINGFACE_APIKEY\")\n        #\"X-HuggingFace-Api-Key\": \"WRONG\"\n    }\n)\nprint(client.is_ready())\nclient.collections.delete(\"Test\")\ntry:\n    collection = client.collections.create(\n        name=\"Test\",\n        vectorizer_config=[\n            wvc.config.Configure.NamedVectors.text2vec_huggingface(\n                name=\"title_vector\",\n                source_properties=[\"title\"],\n                model=\"sentence-transformers/all-MiniLM-L6-v2\",\n            )\n        ],\n    )\n    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n    lines = [\"Something about dogs\", \"Something about wolfs\"]\n\n    vectors = model.encode(lines)\n\n    objs = []\n    for line, vector in zip(lines, vectors):\n        with collection.batch.dynamic() as batch:\n            batch.add_object(\n                properties={\"title\": line},\n                vector={\n                    \"title_vector\": vector\n                }\n            )\n        if collection.batch.failed_objects:\n            print(\"FAILED OBJECTS\", collection.batch.failed_objects)\nfinally:\n    client.close()\n\nNow you can check  if your objects were indeed ingested:\nclient.connect()\nobjects = collection.query.fetch_objects(include_vector=True).objects\nprint(objects[0].vector)\nprint(objects[0].properties)\nclient.close()\n\nIt should output something similar to:\n\n{‘title_vector’: [-0.05317388474941254, 0.02120402827858925, 0.06296592950820923, …, 0.09222045540809631]}\n{‘title’: ‘Something about dogs’}\n\nNow, we can query this using Hugging face Api, or vectorizing the query ourselves:\nclient.connect()\ncollection = client.collections.get(\"Test\")\nobjects = collection.query.near_text(\n    \"pet animals\", \n    target_vector=\"title_vector\", \n    return_metadata=wvc.query.MetadataQuery(distance=True),\n    include_vector=True\n).objects\nfor object in objects:\n    print(\"#\" * 10)\n    print(object.metadata.distance)\n    print(object.properties)\nclient.close()\n\nOutputs:\n\n##########\n0.3560590147972107\n{‘title’: ‘Something about dogs’}\n##########\n0.5862653255462646\n{‘title’: ‘Something about wolfs’}\n\nIf you don’t want to use the hugging face api, you can vectorize your query. Instead of near_text, you use near_vector:\nclient.connect()\ncollection = client.collections.get(\"Test\")\n\nquery_vector = vectors = model.encode([\"pet animals\"])\n\nobjects = collection.query.near_vector(\n    near_vector=query_vector[0], \n    target_vector=\"title_vector\",\n    return_metadata=wvc.query.MetadataQuery(distance=True),\n    include_vector=True\n).objects\nfor object in objects:\n    print(\"#\" * 10)\n    print(object.metadata.distance)\n    print(object.properties)\nclient.close()\n\nLet me know if this helps",
    "date_created": "2024-07-30T17:18:19.571Z",
    "has_accepted_answer": false,
    "title": "Authorization header is correct, but the token seems invalid",
    "topic_id": 3223
  },
  {
    "user_id": 1234,
    "conversation": "[ksaimohan2k (2024-07-23T14:10:59.569Z)]: We are working on creating a retriever to query data within the Weaviate cluster using the Langchain Framework.\nInitially, we create embeddings for the documents and store them in Weaviate. However, processing them each time is time-consuming. It would be more efficient if we could create a retriever with the existing documents within the cluster.\nIs there a way to achieve this?\n\n----------\n\n[DudaNogueira (2024-07-23T21:28:59.389Z)]: hi @ksaimohan2k !! Welcome to our community! \nWe have just the recipe for this:\n\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/llm-frameworks/langchain/loading-data at main ·...\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nTLDR: You can instantiate your Weaviate VectorStore in langchain like so:\nembeddings = OpenAIEmbeddings()\ndb = WeaviateVectorStore.from_documents([], embeddings, client=client, index_name=\"WikipediaLangChain\")\n\nNote that on this recipe, we create the collection outside Langchain and specify a vectorizer. Now you can query your collection using Langchain or even directly.\nLet me know if this helps!\nThanks!\n\n----------\n\n[ksaimohan2k (2024-07-24T07:22:21.453Z)]: Thank You @DudaNogueira for your info, It worked.",
    "date_created": "2024-07-23T14:10:59.522Z",
    "has_accepted_answer": true,
    "title": "Querying the Exisitng Cluster in Weavaite",
    "topic_id": 3132
  },
  {
    "user_id": 3328,
    "conversation": "[Rodney_Puplampu (2025-02-09T16:42:22.647Z)]: Description\n\nSuccessfully installed Verba at port 8000, proxy 80 and 443 to 8000, but comes up blank white page?\nServer Setup Information\n\nWeaviate Server Version:  Debian Linux\nDeployment Method: \nMulti Node? Number of Running Nodes: 1\nClient Language and Version: English\nMultitenancy?:  No\n\nAny additional Information\n(verbavenv) getonthis@nginx-ai-2-vm:~/weaviate$   curl http://localhost:8000 gets me the html for the start page.\nLogs show: (verbavenv) getonthis@nginx-ai-2-vm:~/weaviate/Verba$ verba start\n No Ollama Model detected\n No Ollama Model detected\nINFO:     Will watch for changes in these directories: [‘/home/getonthis/weaviate/Verba’]\nWARNING:  “workers” flag is ignored when reloading is enabled.\nINFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [10909] using WatchFiles\n No Ollama Model detected\n No Ollama Model detected\nINFO:     Started server process [10916]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     127.0.0.1:37698 - “GET / HTTP/1.1” 200 OK\nINFO:     104.63.129.184:0 - “GET / HTTP/1.1” 200 OK\nINFO:     104.63.129.184:0 - “GET /static/icon.ico HTTP/1.1” 200 OK\nINFO:     104.63.129.184:0 - “GET / HTTP/1.1” 200 OK\nINFO:     104.63.129.184:0 - “GET / HTTP/1.1” 200 OK\nINFO:     104.63.129.184:0 - “GET / HTTP/1.1” 200 OK\nSo i know the server is running.\nAnd here is the docker-compose:\n       - WEAVIATE_URL_VERBA=localhost:8000\n      - OLLAMA_URL=localhost:11434\n      - OLLAMA_MODEL=$OLLAMA_MODEL\n#      - OLLAMA_EMBED_MODEL=$OLLAMA_EMBED_MODEL\n      - UNSTRUCTURED_API_KEY=$UNSTRUCTURED_API_KEY\n      - UNSTRUCTURED_API_URL=$UNSTRUCTURED_API_URL\n\nHowever, when I go to the URL, its a black white screen with the Verba/Weaviate icon, so I know I am hitting the server.\n\n----------\n\n[DudaNogueira (2025-02-10T20:02:56.371Z)]: hi!\nCan you share the entire docker compose?\nhere is a working example I can suggest:\n---\n\nservices:\n  verba:\n    # build:\n    #   context: ./\n    #   dockerfile: Dockerfile\n    image: semitechnologies/verba:latest\n    ports:\n      - 8000:8000\n    environment:\n      - WEAVIATE_URL_VERBA=http://weaviate:8080\n      - OPENAI_API_KEY=$OPENAI_API_KEY\n      - COHERE_API_KEY=$COHERE_API_KEY\n      - OLLAMA_URL=http://ollama:11434\n      - OLLAMA_URL=http://ollama:11434\n      #- OLLAMA_URL=http://host.docker.internal:11434\n      - OLLAMA_MODEL=deepseek-r1:1.5b\n      - OLLAMA_EMBED_MODEL=mxbai-embed-large:latest\n      #- UNSTRUCTURED_API_KEY=$UNSTRUCTURED_API_KEY\n      #- UNSTRUCTURED_API_URL=$UNSTRUCTURED_API_URL\n      #- GITHUB_TOKEN=$GITHUB_TOKEN\n\n    volumes:\n      - ./data:/data/\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8000 || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n    networks:\n      - ollama-docker\n\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: semitechnologies/weaviate:1.28.4\n    ports:\n      - 8080:8080\n      - 3000:8080\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n    environment:\n      OPENAI_APIKEY: $OPENAI_API_KEY\n      COHERE_APIKEY: $COHERE_API_KEY\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'e'\n      CLUSTER_HOSTNAME: 'node1'\n    networks:\n      - ollama-docker\n\n  # Uncomment to use Ollama within the same docker compose\n\n  ollama:\n      image: ollama/ollama:latest\n      ports:\n        - 7869:11434\n      volumes:\n        - .:/code\n        - ./ollama/ollama:/root/.ollama\n      container_name: ollama\n      pull_policy: always\n      tty: true\n      restart: always\n      environment:\n        - OLLAMA_KEEP_ALIVE=24h\n        - OLLAMA_HOST=0.0.0.0\n      networks:\n        - ollama-docker\n\nvolumes:\n  weaviate_data: {}\n\n\nnetworks:\n  ollama-docker:\n    external: false\n...\n\n\nafter running:\ndocker compose up -d\n\nyou should also pull the models to ollama:\ndocker compose exec -ti ollama ollama pull mxbai-embed-large:latest\ndocker compose exec -ti ollama ollama pull deepseek-r1:1.5b\n\nthen restart verba:\ndocker compose restart verba\n\nPs: Make sure that ollama has plenty of resources. If you run ollama under docker, make sure there isn’t resource constraints, otherwise it can fail at ingestion.\nLet me know if this helps!\nThanks!\n\n----------\n\n[DudaNogueira (2025-02-10T21:07:13.697Z)]: Rodney_Puplampu:\n\nOLLAMA_MODEL\nOLLAMA_EMBED_MODEL\n\n\nBy the way, just found out that those env vars were being ignored:\n  \n\n      github.com/weaviate/Verba\n  \n\n  \n    \n\n\n\n    \n      \n    \n\n  \n\n\n\n      \n        use OLLAMA_MODEL OLLAMA_EMBED_MODEL as input suggestion when using Ollama\n      \n\n    \n      main ← dudanogueira:ollama-model-env-vars\n    \n\n      \n        \n          opened 09:06PM - 10 Feb 25 UTC\n        \n\n        \n          \n            \n            dudanogueira\n          \n        \n\n        \n          \n            +2\n            -2\n          \n        \n      \n  \n\n\n  \n    If you set OLLAMA_MODEL and OLLAMA_EMBED_MODEL they will be the ones suggested i…nstead of the first on Ollama's list.",
    "date_created": "2025-02-09T16:42:22.600Z",
    "has_accepted_answer": false,
    "title": "Successfully installed Verba at port 8000, proxy 80 and 443 to 8000, but comes up blank white page?",
    "topic_id": 10118
  },
  {
    "user_id": 3022,
    "conversation": "[Yogesh_Chauhan (2024-12-16T07:13:05.818Z)]: client = weaviate.connect_to_local(host=WEAVIATE_HOST, port=WEAVIATE_PORT,\n                                       grpc_port=WEAVIATE_SECOND_PORT, headers=w_headers,\n                                       auth_credentials=weaviate_auth_credentials,\n                                       skip_init_checks=True,\n                                       additional_config=AdditionalConfig(\n                                           connection=ConnectionConfig(\n                                               session_pool_connections=30,\n                                               session_pool_maxsize=200,\n                                               session_pool_max_retries=3,\n                                           ),\n                                           timeout = (60, 180)\n                                           ,)\n                                       )\n\nweaviate_class_name = email_to_weaviate_class_name(email)\n        if is_collection_available(weaviate_client=client, collection_name=weaviate_class_name):\n\ncollection = client.collections.get(weaviate_class_name)\nprint(f\"started updating {email}\")\nfor item in collection.iterator():\n    properties = item.properties\n    properties[\"data_origin\"] = \"native_data\"\n    collection.data.update(uuid=item.uuid, properties=properties)\n    print(\"data updated\")\n\n----------\n\n[DudaNogueira (2024-12-16T13:24:34.593Z)]: Hi @Yogesh_Chauhan !!\nWelcome to our community \nThis operation can be very costly, depending on your dataset, and it can be putting the cluster under stress.\nIt not only update the property, but (if properly configured) trigger a re vectorization of you object, and reindex this object with the new content.\nIf all your properties have changed, it is best to reindex the entire collection using batch instead of updating it one by one.\nOr, if you know the object ids that you need to update beforehand, you can leverage the batch process, and make sure to pass the same ID, like documented here on using deterministic ids.\nLet me know if those can be solutions for your.\nThanks!",
    "date_created": "2024-12-16T07:13:05.772Z",
    "has_accepted_answer": false,
    "title": "Getting timeout error on the batch insertion of the data",
    "topic_id": 9247
  },
  {
    "user_id": 2419,
    "conversation": "[g_parki (2024-10-30T16:42:24.335Z)]: Description\nHi, I’m seeing a flaky issue in being able to search for an object via text property filter after updating/inserting new items. I first saw this on 1.26.3, but I upgraded to 1.27.1 and still see the same issue. I’ll provide code at the bottom to reproduce, but the general process is:\n\nCollection setup:\n\nMultitenant\nSingle property foldername, using field tokenization\nNo vectorizer\n\n\nGo through various updating/insertion operations in rapid succession for renaming existing folders and adding new ones\nTest the ability to correctly query with a filter:\n\nFetch all items without using a filter (no problem here, works every time)\nIterate through the list and attempt to query each item individually by filtering on its foldername\n\n\nWait 1-2 minutes\nRepeat the test in step 3\n\nThis is where it fails inconsistently. Immediately after the insertion/update operations, the test works and I’m able to individually retrieve each item via a filtered query. But after a 1-2 minute delay, the index appears to break and some items (usually the ones inserted earlier in the script) cannot be found via filtered query. This issue also breaks deletion operations - e.g. “Delete folders not equal to x” deletes everything including x.\nUnfortunately this issue is flaky and I can’t guarantee my example code will break the index every time. Here is example output from this morning:\n\nImmediately after the update/insertion operations:\n\nStarting individual queries at 2024-10-30 07:29:46.896713\n515 found                                            \n0 not found\n\n\nAfter sleeping for one minute and repeating the exact same set of queries:\n\nStarting individual queries at 2024-10-30 07:31:46.411442\n464 found                                            \n51 not found\nNot found: ['/b/z', '/b/b/z/z/z/z/z/z', '/b/z', '/a/a/a', '/b/b/z/z/z/z/z/z', '/b/z', '/b/b/z/z/z/z/z/z', '/b/z', '/a/a', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/z', '', '/b/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b', '/b/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z/z', '/b/z/z/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z', '/b/b/z/z/z/z/z/z/z']\n\nOne weird observation which may just be anecdotal - if I ran the validation queries concurrently (using asyncio.gather() on 515 filtered queries), it didn’t seem to break as much as when I run the 515 queries one-after-another.\nServer Setup Information\n\nWeaviate Server Version: Seen on both 1.26.3 & 1.27.1\nDeployment Method: k8s\nNumber of Running Nodes: 1\nClient Language and Version: Python 4.8.1\nMultitenancy: Yes\n\nAny additional Information\nHere is the script to reproduce. It takes ~4 minutes to run:\nimport weaviate\nimport weaviate.classes as wvc\nimport asyncio\nfrom datetime import datetime\n\nclient = weaviate.use_async_with_weaviate_cloud(...)\nawait client.connect()\n\n# Cleanup from previous tests as needed\nif await client.collections.exists(\"Folders\"):\n    await client.collections.delete(\"Folders\")\n\n# Create collection and tenant\nfolders = await client.collections.create(\n    name=\"Folders\",\n    multi_tenancy_config=wvc.config.Configure.multi_tenancy(\n        True, auto_tenant_creation=True\n    ),\n    properties=[\n        wvc.config.Property(\n            name=\"foldername\",\n            data_type=wvc.config.DataType.TEXT,\n            skip_vectorization=True,\n            tokenization=wvc.config.Tokenization.FIELD,\n        ),\n    ],\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n)\nawait folders.tenants.create(\"me\")\ntenant_collection = folders.with_tenant(\"me\")\n\n# Load up some starting data\nstarting_foldernames = [\"\", \"/a/a\", \"/a/a/a\", \"/b\", \"/b/b\"]\ndata = [{\"foldername\": name} for name in starting_foldernames]\nawait tenant_collection.data.insert_many(objects=data)\n\n# Go through several iterations of updating and inserting data\n# Here we toggle characters to \"c\" and back to \"b\" repeatedly\n# And also insert new items with a \"/z\" appended\niterations = 8\nfor i in range(iterations):\n    all_objects = await tenant_collection.query.fetch_objects(limit=10000)\n    for obj in all_objects.objects:\n        foldername = obj.properties[\"foldername\"]\n        new_foldername = None\n        if \"b\" in foldername:\n            new_foldername = foldername.replace(\"b\", \"c\")\n        elif \"c\" in foldername:\n            new_foldername = foldername.replace(\"c\", \"b\")\n        if new_foldername is not None:\n            print(\n                f\"Iteration {i+1}/{iterations}, updating {foldername} -> {new_foldername}\"\n                + \" \" * 30,\n                end=\"\\r\",\n            )\n            # Update the record, and also insert a new one\n            await asyncio.gather(\n                tenant_collection.data.update(\n                    uuid=obj.uuid, properties={\"foldername\": new_foldername}\n                ),\n                tenant_collection.data.insert(\n                    properties={\"foldername\": new_foldername + \"/z\"}\n                ),\n            )\nprint(\"\")\n\n\n# Define a function to fetch all items, and then perform an individualized\n# search for each item\nasync def do_individualized_searches():\n    print(\" \" * 50)\n    print(f\"Starting individual queries at {datetime.now()}\")\n    all_objects = await tenant_collection.query.fetch_objects(\n        return_metadata=wvc.query.MetadataQuery(last_update_time=True), limit=10000\n    )\n    found = []\n    not_found = []\n    total = len(all_objects.objects)\n\n    for i, obj in enumerate(all_objects.objects):\n        print(f\"Performing filtered query {i+1}/{total}\" + \" \" * 20, end=\"\\r\")\n        foldername = obj.properties[\"foldername\"]\n        individual_query_result = await tenant_collection.query.fetch_objects(\n            filters=wvc.query.Filter.by_property(\"foldername\").equal(foldername)\n        )\n\n        if individual_query_result.objects:\n            found.append(foldername)\n        else:\n            not_found.append(foldername)\n\n    print(\" \" * 50, end=\"\\r\")\n    print(f\"{len(found)} found\")\n    print(f\"{len(not_found)} not found\")\n    if not_found:\n        print(f\"Not found: {not_found}\")\n\n\n# Do the searches immediately, which is usually successful for all records\nawait do_individualized_searches()\n\n# Wait some time\ndelay = 60\nfor i in range(int(delay)):\n    print(f\"Sleeping {delay - i} seconds\" + \" \" * 50, end=\"\\r\")\n    await asyncio.sleep(delay=1)\n\n# Do the searches again - here is where we sometimes see the index fail\nawait do_individualized_searches()\n\n----------\n\n[DudaNogueira (2024-11-01T13:55:26.273Z)]: hi @g_parki !!\nWelcome to our community \nThanks for the report and experiments  !!!\nThis is Chaos material! hehehe\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate/weaviate-chaos-engineering: Chaos-Engineering-Style CI Pipelines to make sure...\n\n    Chaos-Engineering-Style CI Pipelines to make sure Weaviate handles whatever the real world throws at it.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nDo you think you that on top of that script you could provide some dataset we could iterate on?\nI will escalate this internally.\nThanks!\n\n----------\n\n[Jose_Luis_Franco (2024-11-07T09:32:28.609Z)]: Hello @g_parki ,\nFirst of all, thanks for reporting this issue. My name is Jose Luis and I am QA at Weaviate.\nI have been trying to reproduce your issue in 1.27.1 in a kind local kubernetes cluster but it did work for me, so I guess it has something to do with the configuration parameters. Could you please share your values.yaml or the environment variables you enabled in your k8s cluster?\nThanks in advance!\n\n----------\n\n[DudaNogueira (2024-11-12T14:48:11.778Z)]: hi @g_parki !!\nThank you VERY MUCH for this bug report!\nAnd great news: we already have a fix cooked:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n\n\n\n    \n      \n    \n\n  \n\n\n\n      \n        fix: byteops reads buf of length 0 as empty slice instead of nil\n      \n\n    \n      weaviate:stable/v1.25 ← weaviate:fix_byteops_reading_empty_slice\n    \n\n      \n        \n          opened 10:58AM - 12 Nov 24 UTC\n        \n\n        \n          \n            \n            aliszka\n          \n        \n\n        \n          \n            +20\n            -10\n          \n        \n      \n  \n\n\n  \n    ### What's being changed:\n\n**ReadWriter::ReadBytesFromBufferWithUint32LengthIn…dicator** used to replace empty `[]byte` with `nil` when length indicator was == 0.\nThat replacement caused `PrimaryKey` of `SegmentNode` of roaringset index being incorrectly read as `nil` instead of empty `[]byte`, making SegmentCursor also return key = nil, whenever empty string was indexed and stored in segment.\nAs `key == nil` is a stop condition for looping through segment by cursor and `\"\"` is alphabetically first, segment accessed by cursor seemed empty. That could cause data lost in case of compaction segment containing `\"\"` with other segment,\nresulting in merged segment being just copy of the 2nd one.\n\nNote: **ReadWriter::ReadBytesFromBufferWithUint64LengthIndicator** does not have empty `[]byte` to `nil` replacement.\n\nBug identified thanks to **g_parki**, who reported the issue: https://forum.weaviate.io/t/filter-index-breaks-after-updating-inserting-new-records/7348\n\n### Review checklist\n\n- [ ] Documentation has been updated, if necessary. Link to changed documentation:\n- [x] Chaos pipeline run or not necessary. Link to pipeline: https://github.com/weaviate/weaviate-chaos-engineering/actions/runs/11796272571\n- [x] All new code is covered by tests where it is reasonable.\n- [ ] Performance tests have been run or not necessary.\n\n<!-- Uncomment the following section if this PR requires changes in related projects (e.g., documentation, client libraries).\n\nGitHub actions will automatically create an issue in the corresponding repository for each checked box below. (See `.github/workflows/create-cross-functional-issues.yml`)\n\n### Cross-functional impact\n\n- [ ] This change requires public documentation (weaviate-io) to be updated. Check the box to automatically create a corresponding issue.\n- Does it require a change in the client libraries? If yes, please check the boxes for the affected client libraries.\n    - [ ] Python (weaviate-python-client)\n    - [ ] JavaScript/TypeScript (typescript-client)\n    - [ ] Go (weaviate-go-client)\n    - [ ] Java (java-client)\n\n-->\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIt was merged already and should be released soon!\nThanks!\n\n----------\n\n[g_parki (2024-11-12T15:24:26.071Z)]: Woohoo! Thank you @DudaNogueira @Jose_Luis_Franco and team for the quick action\n\n----------\n\n[g_parki (2024-11-13T17:30:24.536Z)]: For anybody finding this in the future, the fix is included in v1.27.3, v1.26.10, and v1.25.25",
    "date_created": "2024-10-30T16:42:24.282Z",
    "has_accepted_answer": true,
    "title": "Filter index breaks after updating/inserting new records",
    "topic_id": 7348
  },
  {
    "user_id": 2515,
    "conversation": "[Charlie (2024-11-16T11:40:26.193Z)]: Description\nI’m trying to use weaviate to handle chinese documents, I know weaviate support gse as the tokenization, but how can I config the gse. I need to load chinese dict to the gse for particular terms. (The official gse support LoadDict method.)\nThe schema looks like as below:\n{\n                    \"class\": self.index_name,\n                    \"description\": \"Chunks of Documentations\",\n                    \"vectorizer\": \"none\",\n                    \"properties\": [\n                        {\n                            \"name\": \"text\",\n                            \"dataType\": [\"text\"],\n                            \"description\": \"Content of the document\",\n                            \"tokenization\": \"gse\",\n                            \"indexSearchable\": True,\n                        },\n                   ]\n}\n\nThanks.\n\n----------\n\n[DudaNogueira (2024-11-18T13:11:36.408Z)]: hi @Charlie !!\nWelcome to our community \nIn order to enable GSE tokenization, you will need to enable it in your server.\nFor that, you need to set the environment variable ENABLE_TOKENIZER_GSE to true as documented here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection definition | Weaviate\n\n  Schema Configuration in Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!\nThanks!\n\n----------\n\n[Charlie (2024-11-20T10:05:23.168Z)]: Thanks, I already enabled the gse. But I don’t know how to customize the gse option, as I need to load chinese dict like below:\nvar seg1 gse.Segmenter\nseg1.DictSep = \",\"\nerr := seg1.LoadDict(\"./testdata/test_cn.txt\")",
    "date_created": "2024-11-16T11:40:26.147Z",
    "has_accepted_answer": false,
    "title": "How can I config the gse tokenization",
    "topic_id": 7600
  },
  {
    "user_id": 30,
    "conversation": "[SomebodySysop (2025-02-08T08:05:02.308Z)]: Description\n\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method:  WCS\nMulti Node? Number of Running Nodes:  no\nClient Language and Version: php curl\nMultitenancy?: no\n\nAny additional Information\n\nI think these queries should be bringing back only objects which contain ‘not working yet’ in the title, content, location or summary properties.\nHowever, they are not.  I am getting results that indicate that the keyword filters aren’t being executed.\n{ Get { SolrCopy ( limit: 10 nearText: { concepts: [\"specific text discussing query configurations in \\\"It's not working yet\\\"\"], } where: { operator: And, operands: [ { path: [\"site\"], operator: Equal, valueText:\"https://master1and1.schoolboard.net/\"},{ operator: Or, operands: [ { path: [\"groups\"], operator: Equal, valueText: \"Development\" } ] },{ operator: Or, operands: [ { operator: And, operands: [ { path: [\"content\"], operator: Like, valueText: \"'not working yet'\" } ] }, { operator: And, operands: [ { path: [\"title\"], operator: Like, valueText: \"'not working yet'\" } ] }, { operator: And, operands: [ { path: [\"location\"], operator: Like, valueText: \"'not working yet'\" } ] }, { operator: And, operands: [ { path: [\"summary\"], operator: Like, valueText: \"'not working yet'\" } ] } ] } ] } ){ _additional { distance certainty } docId site title nid type public url content taxonomy groups date summary questions sourceUrl solrId location } } }\n\n{ Get { SolrCopy ( limit: 10 hybrid: { query: \"query configurations in \\\"It's not working yet\\\"\" alpha: 0.5 } where: { operator: And, operands: [ { path: [\"site\"], operator: Equal, valueText:\"https://master1and1.schoolboard.net/\"},{ operator: Or, operands: [ { path: [\"groups\"], operator: Equal, valueText: \"Development\" } ] },{ operator: Or, operands: [ { operator: And, operands: [ { path: [\"content\"], operator: Like, valueText: \"'not working yet'\" } ] }, { operator: And, operands: [ { path: [\"title\"], operator: Like, valueText: \"'not working yet'\" } ] }, { operator: And, operands: [ { path: [\"location\"], operator: Like, valueText: \"'not working yet'\" } ] }, { operator: And, operands: [ { path: [\"summary\"], operator: Like, valueText: \"'not working yet'\" } ] } ] } ] } ){ _additional { distance score } docId site title nid type public url content taxonomy groups date summary questions sourceUrl solrId location } } }\n\nI’m executing these commands in the Weaviate console, and when I search the results, ‘not working yet’ is not found in any of the returned content.\nI do not see any error in the response.  The only thing that may be unusual is that the “location” property is null as I just added it and it doesn’t contain any data.  Other than that the output seems correct – it’s just not filtered by the keywords.\nUpdate: I removed “location” property, same results.\nAny suggestions?  I can send you sample output if you like (it’s pretty long).\n\n----------\n\n[sebawita (2025-02-10T10:33:56.019Z)]: Hi @SomebodySysop,\nBy default, Weaviate indexes keywords word-by-word, which means that matching is considered successful when a keyword matches.\nThis behaviour is defined by Tokenization.\nIn your case, you need to change the tokenization for properties you want to match exactly to field.\nHere is a docs example on how to set tokenization when you create a collection.\n\nnote, I don’t think Weaviate allows updating tokenization on an existing collection.\n\n----------\n\n[SomebodySysop (2025-02-10T11:05:18.390Z)]: I do not use Python.  All of my requests are by curl.\nMy filter code has worked now for at least a year.  I just noticed that it had stopped working recently, so I would estimate that it has topped within the past few weeks if not months.\nBelow is my schema.   “content”, “title”, “summary” and “location” are all text properties.  Are you saying I now need to add a “tokenization” element to each text property?  Wouldn’t “word” already be the default tokenizer for text?\n$schema = [\n    \"class\" => \"SolrAI\",\n    \"description\" => \"Class representing the SolrAI index\",\n    \"vectorizer\" => \"text2vec-openai\",\n    \"moduleConfig\" => [\n      \"generative-openai\" => [\n        \"model\" => \"gpt-4o\",\n        ],\n\t  \"text2vec-openai\" => [\n\t\t\t\"vectorizeClassName\" => true,\n\t\t\t\"model\" => \"text-embedding-3-large\",\n\t\t\t\"dimensions\" => 3072,\n\t\t\t\"type\" => \"text\",\n\t\t\t\"vectorizeClassName\" => false\n\t\t],\n    ],\n    \"multiTenancyConfig\" => [\n\t  \"text2vec-openai\" => True\n    ],\n\t\"properties\" => [\n\t[\n\t\t\"name\" => \"docId\",\n\t\t\"dataType\" => [\"text\"],\n\t\t\"description\" => \"The unique identifier of the document - nid-dstype-dsid-delta\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => \n\t\t\t[ \"skip\" => false, \"vectorizePropertyName\" => false ]\n\t\t\t]\n\t\t],\n\t[\n\t\t\"name\" => \"site\",\n\t\t\"dataType\" => [\"text\"],\n\t\t\"description\" => \"The site name.\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => false ]]\n\t],\n\t[\n\t\t\"name\" => \"title\",\n\t\t\"dataType\" => [\"text\"],\n\t\t\"description\" => \"The title of the document\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => true ]]\n\t],\n\t[\n\t\t\"name\" => \"summary\",\n\t\t\"dataType\" => [\"text\"],\n\t\t\"description\" => \"Summarization of the source document from which this text taken\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => true ]]\n\t],\n\t[\n\t\t\"name\" => \"nid\",\n\t\t\"dataType\" => [\"int\"],\n\t\t\"description\" => \"ID of node associated with this content.\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => true]]\n\t],\n\t[\n\t\t\"name\" => \"public\",\n\t\t\"dataType\" => [\"text\"],\n\t\t\"description\" => \"Is this content public (Y or N)..\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => false]]\n\t],\n\t[\n\t\t\"name\" => \"url\",\n\t\t\"dataType\" => [\"text\"],\n\t\t\"description\" => \"The url to the content on site\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => false ]]\n\t],\n\t[\n\t\t\"name\" => \"type\",\n\t\t\"dataType\" => [\"text\"],\n\t\t\"description\" => \"Solr datasource type\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => false ]]\n\t],\n\t[\n\t\t\"name\" => \"timestamp\",\n\t\t\"dataType\" => [\"date\"],\n\t\t\"description\" => \"Last Solr index date\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => false ]]\n\t],\n\t[\n\t\t\"name\" => \"content\",\n\t\t\"dataType\" => [\"text\"],\n\t\t\"description\" => \"Document content\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => true ]]\n\t],\n\t[\n\t\t\"name\" => \"groups\",\n\t\t\"dataType\" => [\"text[]\"],\n\t\t\"tokenization\" => \"word\",\n\t\t\"description\" => \"The group(s) to which this text document belongs.\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => true ]]\n\t],\n\t[\n\t\t\"name\" => \"date\",\n\t\t\"dataType\" => [\"text\"],\n\t\t\"description\" => \"The date for this event / activity.\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => true ]]\n\t],\n\t[\n\t\t\"name\" => \"taxonomy\",\n\t\t\"dataType\" => [\"text[]\"],\n\t  \"tokenization\" => \"word\", \n\t\t\"description\" => \"The taxonomy or taxonomies (tag or tags) assigned to this text document.\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => true ]]\n\t],\n\t[\n\t\t\"name\" => \"solrId\",\n\t\t\"dataType\" => [\"text\"],\n\t\t\"description\" => \"The Solr database id.\",\n\t\t\"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => false ]]\n\t],\n\t[\n\t  \"name\" => \"questions\",\n\t  \"dataType\" => [\"text\"],\n\t  \"description\" => \"Questions that this document answers.\",\n\t  \"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => true ]]\n\t],\n\t[\n\t  \"name\" => \"dsid\",\n\t  \"dataType\" => [\"int\"],\n\t  \"description\" => \"Datasource ID.\",\n\t  \"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => false ]]\n\t],\t\n        [\n          \"name\" => \"sourceUrl\",\n          \"dataType\" => [\"text\"],\n          \"description\" => \"URL to original source document.\",\n          \"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => false ]]\n        ],\n        [\n          \"name\" => \"categories\",\n          \"dataType\" => [\"text[]\"],\n          \"description\" => \"Keyword categories.\",\n          \"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => true ]]\n        ],\n        [\n          \"name\" => \"location\",\n          \"dataType\" => [\"text\"],\n          \"description\" => \"Location of document text (breadcrumb trail).\",\n          \"moduleConfig\" => [ \"text2vec-openai\" => [ \"skip\" => false, \"vectorizePropertyName\" => true ]]\n        ]\n  ]\n];\n\n----------\n\n[SomebodySysop (2025-02-10T11:11:19.380Z)]: sebawita:\n\nBy default, Weaviate indexes keywords word-by-word, which means that matching is considered successful when a keyword matches.\n\n\nThis is exactly what I want to happen.  But, it’s not.\nAccording to the documentation:\nThe word tokenization is the default tokenization method in Weaviate.\nSo, all of the filter elements in my query should be matching by word, but they are not.\n{ Get { SolrCopy ( limit: 10 nearText: { concepts: [\"specific text discussing query configurations in \\\"It's not working yet\\\"\"], } where: { operator: And, operands: [ { path: [\"site\"], operator: Equal, valueText:\"https://master1and1.schoolboard.net/\"},{ operator: Or, operands: [ { path: [\"groups\"], operator: Equal, valueText: \"Development\" } ] },{ operator: Or, operands: [ { operator: And, operands: [ { path: [\"content\"], operator: Like, valueText: \"'not working yet'\" } ] }, { operator: And, operands: [ { path: [\"title\"], operator: Like, valueText: \"'not working yet'\" } ] }, { operator: And, operands: [ { path: [\"location\"], operator: Like, valueText: \"'not working yet'\" } ] }, { operator: And, operands: [ { path: [\"summary\"], operator: Like, valueText: \"'not working yet'\" } ] } ] } ] } ){ _additional { distance certainty } docId site title nid type public url content taxonomy groups date summary questions sourceUrl solrId location } } }\n\n----------\n\n[sebawita (2025-02-10T11:21:24.651Z)]: SomebodySysop:\n\nAccording to the documentation:\nThe word tokenization is the default tokenization method in Weaviate.\n\n\nYes, that is correct. word is the default, while to achieve an exact match on the whole field, you need field tokenization.\nSome background\nWord tokenization only looks for alpha-numeric characters.\nFor example, it converts \"Hello, (beautiful) world\" into \"hello\", \"beautiful\", \"world\".\nSo later, when you query for \"hello-world\", that also gets tokenized into \"hello\", \"world\". And then Weaviate looks for a match of “hello” and “world”, which results in a positive match.\nField tokenization preserves the whole field as a single index item.\nFor example, \"Hello, (beautiful) world\" stays as \"Hello, (beautiful) world\".\nThen the query \"hello-world\" won’t match, as it is different.\n\n----------\n\n[SomebodySysop (2025-02-10T11:26:08.428Z)]: sebawita:\n\nField tokenization preserves the whole field as a single index item.\nFor example, \"Hello, (beautiful) world\" stays as \"Hello, (beautiful) world\".\nThen the query \"hello-world\" won’t match, as it is different.\n\n\nOK, I see.  Thanks.\n\n\n\n sebawita:\n\nnote, I don’t think Weaviate allows updating tokenization on an existing collection.\n\n\nSo, how do I fix this?\nAlso, if I change the tokenization on these objects to accommodate keyword filtering, how will that affect my NearText and Hybrid semantic queries which, to this point, have been working very well?\n\n----------\n\n[sebawita (2025-02-10T11:41:03.949Z)]: SomebodySysop:\n\nSo, how do I fix this?\n\n\nI think you might need to recreate the collection, as I don’t think you can update tokenization.\n@DudaNogueira do you know if we can update tokenization on an existing collection?\n\n\n\n SomebodySysop:\n\nAlso, if I change the tokenization on these objects to accommodate keyword filtering, how will that affect my NearText and Hybrid semantic queries which, to this point, have been working very well?\n\n\nThis won’t affect NearText, as it only uses vector embeddings for search.\nHowever, yes, this would affect the keyword component of the Hybrid search.\nI don’t necessarily recommend changing all properties to Field tokenization. However, if you need an exact match on say the URL, then you could set that property to use Field tokenization.\n\n----------\n\n[Mohamed_Shahin (2025-02-10T11:52:43.663Z)]: @sebawita Tokenization is immutable\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection definition | Weaviate\n\n  Schema Configuration in Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThe collection needs to be recreated.\nRegards,\nMohamed Shahin,\nSupport Engineer\n\n----------\n\n[SomebodySysop (2025-02-10T12:01:09.054Z)]: I don’t know.  It sounds like FIELD tokenization may not be the solution here.  The entire field may be 2500 characters long, and all I want to do is match a string within that field.  But, it doesn’t sound like that’s possible with FIELD tokenization either – it sounds like I’d need to match the entire field.\nThat’s not what I want to do either.\nIt would be nice if you guys had a way to match a keyword string within a field, whether with WORD or FIELD tokenization.\n\n----------\n\n[SomebodySysop (2025-02-10T21:12:04.156Z)]: Thank you @Mohamed_Shahin and @sebawita for your help.\nI thought the filtering supported phrase searching because we normally use it with nouns - unique persons, places and things.  It did not work as expected with ‘not working yet’ because we are dealing with a less unique verb and adverbs.\nHaving worked with database and text retrieval systems for the past 40+ years, I am a bit surprised at discovering that Weaviate does not support substring phrase searching in keyword filters.\nNonetheless, I will follow @Mohamed_Shahin advice and submit a feature request.\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nBuild software better, together\n\n  GitHub is where people build software. More than 150 million people use GitHub to discover, fork, and contribute to over 420 million projects.\n\n----------\n\n[sebawita (2025-02-11T09:46:04.910Z)]: Hey @SomebodySysop,\n\n\n\n SomebodySysop:\n\nI thought the filtering supported phrase searching because we normally use it with nouns - unique persons, places and things. It did not work as expected with ‘not working yet’ because we are dealing with a less unique verb and adverbs.\nHaving worked with database and text retrieval systems for the past 40+ years, I am a bit surprised at discovering that Weaviate does not support substring phrase searching in keyword filters.\n\n\nI misread your original question, as I thought that you wanted an exact match on the whole field. \nYou don’t need to change to Field, that was not a correct advice by me.\nApologies \nQuestion\nWhen you get your results back, do any of the properties contain the 3 words “not”, “working”, “yet” (not necessarily next to each other)?\nBonus\nAs a side note, I dived deeper into your GraphQL query.\nThere seems to be something odd about your where filter, as you have a few AND/OR operators with only one statement inside. Althogh, I am not sure if that affects your query.\nFor example, this OR contains only “groups”==“Development”\n{operator: Or, operands: [ #THIS OR only contains \"groups\"==\"Development\"\n  {path: [\"groups\"], operator: Equal, valueText: \"Development\"}\n]},\n\nAnd there is a bunch of AND operators like this:\n{operator: And, operands: [\n  {path: [\"content\"], operator: Like, valueText: \"'not working yet'\"}\n]},\n\nHere is your fully formatted GraphQL:\n{\n  Get {\n    SolrCopy(\n      limit: 10\n      hybrid: {query: \"query configurations in \\\"It's not working yet\\\"\", alpha: 0.5}\n      where: {\n        operator: And, operands: [ # AND1 START\n          {path: [\"site\"], operator: Equal, valueText: \"https://master1and1.schoolboard.net/\"},\n          {operator: Or, operands: [ #THIS OR only contains \"groups\"==\"Development\"\n            {path: [\"groups\"], operator: Equal, valueText: \"Development\"}\n          ]},\n          {operator: Or, operands: [ \n            {operator: And, operands: [\n              {path: [\"content\"], operator: Like, valueText: \"'not working yet'\"}\n            ]}, \n            {operator: And, operands: [\n              {path: [\"title\"], operator: Like, valueText: \"'not working yet'\"}\n            ]},\n            {operator: And, operands: [\n              {path: [\"location\"], operator: Like, valueText: \"'not working yet'\"}\n            ]}, \n            {operator: And, operands: [\n              {path: [\"summary\"], operator: Like, valueText: \"'not working yet'\"}\n            ]}\n          ]}\n        ]}# AND1 END\n    ) \n{ _additional { distance score } docId site title nid type public url content taxonomy groups date summary questions sourceUrl solrId location } } }\n\nYou query could be trimmed to:\n{\n  Get {\n    SolrCopy(\n      limit: 10\n      hybrid: {query: \"query configurations in \\\"It's not working yet\\\"\", alpha: 0.5}\n      where: {\n        operator: And, operands: [ # AND1 START\n          {path: [\"site\"], operator: Equal, valueText: \"https://master1and1.schoolboard.net/\"},\n          {path: [\"groups\"], operator: Equal, valueText: \"Development\"},\n          {operator: Or, operands: [ \n              {path: [\"content\"], operator: Like, valueText: \"'not working yet'\"}, \n              {path: [\"title\"], operator: Like, valueText: \"'not working yet'\"},\n              {path: [\"location\"], operator: Like, valueText: \"'not working yet'\"},\n              {path: [\"summary\"], operator: Like, valueText: \"'not working yet'\"}\n          ]}\n        ]}# AND1 END\n    )\n{ _additional { distance score } docId site title nid type public url content taxonomy groups date summary questions sourceUrl solrId location } } }\n\n----------\n\n[SomebodySysop (2025-02-11T14:17:27.910Z)]: sebawita:\n\nFor example, this OR contains only “groups”==“Development”\n\n\n\n\nYes, that is correct.\nAnd there is a bunch of AND operators like this:\nThere could be other restrictions as well.  The query looks a little clunky  because it’s generated by code designed to dynamically create the filters according to the options it receives.  I could try using a model to do this, but code is more reliable.\n\n\n\n sebawita:\n\nWhen you get your results back, do any of the properties contain the 3 words “not”, “working”, “yet” (not necessarily next to each other)?\n\n\nYes, the results will contain all the words in at least one of the property fields listed.  Sort of like the “contains all” filter, but not necessarily as a phrase ‘not working yet’, which is what I was looking for.\nThanks for the assistance!\n\n----------\n\n[SomebodySysop (2025-02-14T20:08:32.287Z)]: Feature request posted: Keyword filters should support substring phrase searching · Issue #7206 · weaviate/weaviate · GitHub",
    "date_created": "2025-02-08T08:05:02.261Z",
    "has_accepted_answer": true,
    "title": "Filters do not seem to be working as expected",
    "topic_id": 10045
  },
  {
    "user_id": 1214,
    "conversation": "[elias.gabriel (2024-10-17T17:04:26.941Z)]: Description\nThe documentation for optimizing Weaviate performance mentions setting the GOMEMLIMIT env variable on Weaviate replicas to 10-20% of the total memory available on the host.\nHowever, there is a blog post where it’s set to ~45% of the max RAM.\nWhat factor am I actually looking at here to know how to set that optimally? Based on what’s said in that article (I may be misunderstanding), I would assume that I’d set it to close to the max RAM available, with a buffer of maybe 10%.\nI’m also running Weaviate in a very controlled K8s environment where each replica gets its own node, so there are no other processes or anything involved. I suspect that also contributes to the recommendation.\nServer Setup Information\n\nWeaviate Server Version: 1.26.6\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: N/A\nMultitenancy?: No\n\n----------\n\n[DudaNogueira (2024-10-17T23:48:41.704Z)]: hi @elias.gabriel !\nNice catch!\nThank you VERY MUCH \nI checked with our team, and the recommendation is the other way around:\nSetting GOMEMLIMIT  between 90%-80% of your TOTAL memory. This room can be used for any exceeding memory that the runtime may require under pressure.\nCertain specific cases may require a different configuration.\nI will change that in our docs ASAP.\nThanks again!\n\n----------\n\n[elias.gabriel (2024-10-18T14:46:46.691Z)]: Ah ok! I thought there was something I was really not understanding hahaha, so it being a typo makes a lot more sense!\nThanks for acting quickly.",
    "date_created": "2024-10-17T17:04:26.896Z",
    "has_accepted_answer": true,
    "title": "GOMEMLIMIT clarification",
    "topic_id": 5731
  },
  {
    "user_id": 1087,
    "conversation": "[Sharhad_Bashar (2024-07-12T05:11:37.439Z)]: I have a simple collection with 1700 items\nI want to retrieve all of them\nto do so, I am using the following code:\ncollection = client.collections.get('collection_name')\nresponse = collection.query.fetch_objects()\nall_items = [i.properties for i in response.objects]\nprint(len(all_items)) -> this prints 10\n\nbut if i do the following:\ncollection = client.collections.get('collection_name')\nresponse = collection.query.fetch_objects(limit = 2000)\nall_items = [i.properties for i in response.objects]\nprint(len(all_items)) -> this prints 1700\n\nIs there a way to get all the items in a collection without having to specify the limit?\n\n----------\n\n[Mohamed_Shahin (2024-07-12T06:36:29.337Z)]: Hi @Sharhad_Bashar,\nWelcome to our community and it’s great to have you here.\nYou can fetch all objects and print them out using the following way:\nI provide an example with a counter for demonstration:\nI’ve 88 objects in my dataset\n\ncollection = client.collections.get(“docs”)\ncounter = 0\nfor item in collection.iterator(\ninclude_vector=False\n):\ncounter += 1\nprint(item.properties)\nprint(counter)\n\nResult:\n\nRef:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nRead all objects | Weaviate - Vector Database\n\n  Weaviate provides the necessary APIs to iterate through all your data. This is useful when you want to manually copy/migrate your data (and vector embeddings) from one place to another.\n\n----------\n\n[SoftwearEnginear (2024-07-12T06:48:04.710Z)]: This is what I did to get all files in the collection:\ncollection = client.collections.get('collection_name')\nfile_list = []\nfor obj in collection.iterator():\n  file_list.append(obj.properties['file_path'])\n\nUsing that, you can print the number of documents too:\nprint(len(file_list))\n\n----------\n\n[Carsten_Schnober (2024-12-17T15:36:00.959Z)]: Unfortunately, the iterator() is not a solution if you want to apply a filter, see Getting all items with filter?",
    "date_created": "2024-07-12T05:11:37.381Z",
    "has_accepted_answer": true,
    "title": "Fetch_objects only returns 10 items is limit is no specified",
    "topic_id": 3026
  },
  {
    "user_id": 875,
    "conversation": "[Syed_Hamza (2024-10-15T16:00:04.895Z)]: Description\n\nServer Setup Information\n\nWeaviate Server Version: 1.21.2\nDeployment Method:  docker\nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\nRunning into \" An error occurred: The ‘objects’ creation was cancelled because it took longer than the configured timeout of 60s. Try reducing the batch size (currently 1) to a lower value. Aim to on average complete batch request within less than 10s \" when trying to import data with batch size one using following snippet\n\n    @staticmethod\n    def import_data_to_weaviate(client, vectorDB, properties, emb1, emb2, embedding_to_insert):\n        \"\"\"\n        Imports data into Weaviate by adding objects with embeddings.\n        \"\"\"\n        client.batch.configure(batch_size=1)  # Configure batch\n        with client.batch as batch:\n            try:\n                # Generate a unique identifier based on the embeddings\n                uuid = weaviate.util.generate_uuid5(emb1.tobytes() + emb2.tobytes())\n                batch.add_data_object(properties, vectorDB, uuid=uuid, vector=np.array(embedding_to_insert))\n                \n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n\nThe error seems to occur randomly at times.\n\n----------\n\n[DudaNogueira (2024-10-15T16:05:22.627Z)]: hi @Syed_Hamza !!\nWelcome to our community \nVersion 1.21 is really old, I would strongly suggest you to migrate it.\nConsidering the version, you are probably using the python v3 version.\nHow are you vectorizing that object?\nWe strongly suggest you to move to a newer version and leverage the new python v4 client with GRPC. Not only it is more performant, but also easier to debug.\nIt would be interesting to check this documentation on how to do error handling with python v3 client:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nLegacy (v3) API (DEPRECATED) | Weaviate\n\n  This document relates to the legacy v3 client and API.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!",
    "date_created": "2024-10-15T16:00:04.848Z",
    "has_accepted_answer": true,
    "title": "An error occurred: The 'objects' creation was cancelled because it took longer than the configured timeout of 60s. Try reducing the batch size (currently 1) to a lower value. Aim to on average complete batch request within less than 10s",
    "topic_id": 5423
  },
  {
    "user_id": 985,
    "conversation": "[Neil (2024-09-27T17:40:37.172Z)]: Hello,\nI have successfully created a collection with has a ‘trim’ property with the following attributes: wv_config.Property(name = “trim”, description = “trim”, data_type=wv_config.DataType.TEXT,  skip_vectorization=True)\nI am loading a pipe delimited file where the content for ‘trim’ = 4531 for a specific record, while other records have both alphanumeric records, several records are numeric only.\nDuring the load process, I continue to receive this error: failed_objs_b = = >  [ErrorObject(message=‘WeaviateInsertManyAllFailedError(“Every object failed during insertion. Here is the set of all errors: invalid text property 'trim' on class \\test_name': not a string, but float64”)’\nWhy are text fields not able to load just a number? How can i resolve this error so that a datatype of TEXT can also take numerical values for some records?  Also, how can empty data be loaded in. Is there some sort of optional parameter or  should it be labeled as ‘N/A’ for TEXT and 0 for FLOAT and INT fields?\nAlso, what is the absolute character length that TEXT will allow to load in? I know that BLOBS have very large space but I can’t find max limit for TEXT properties.\nAlso, this was asked before but I am not sure if I understood. How can exact keyword match be done on a field either by query or via filtering? Are there examples you can show me of both scenarios?\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nMulti Node? Number of Running Nodes: Single-node\nClient Language and Version: Python 3.12\nMultitenancy?:  Single tenancy\n\nAny additional Information:\nFull error message:\nERROR:weaviate-client:{‘message’: ‘Failed to send 1 objects in a batch of 1. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\n{‘message’: ‘Failed to send 1 objects in a batch of 1. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\nFinished importing 1 articles.\nfailed_objs_b = = >  [ErrorObject(message=‘WeaviateInsertManyAllFailedError(“Every object failed during insertion. Here is the set of all errors: invalid text property 'trim' on class 'test_name': not a string, but float64”)’, object_=_BatchObject(collection=‘test_collection03’, vector=None, uuid=‘1ae67e70-3a8b-4ecd-8f23-a07960a83634’, properties={‘content’: ‘2020 RV Aire’, ‘length_feet’: 44, ‘sleeping_capacity’: 4, ‘gross_weight_lbs’: 54000, ‘weight_class’: ‘Class A’, ‘class_type’: ‘A’, ‘fuel_type’: ‘Diesel’, ‘awnings’: 0, ‘slideouts’: 3, ‘freshwater_cap_gal’: 105, ‘greywater_cap_gal’: 80, ‘blackwater_cap_gal’: 60, ‘address’: ‘1751 Wildwood Dr, Suamico, WI 54173’, ‘stock_no’: ‘18CONS138’, ‘vin’: ‘4VZVU1E91LC086329’, ‘year’: 2020, ‘make’: ‘Newmar’, ‘model’: ‘King Aire’, ‘trim’: 4531, ‘body_type’: ‘RV’, ‘condition’: ‘Used’, ‘exterior_color’: ‘BLACK’, ‘interior_color’: nan, ‘mileage’: 22967, ‘dealership_name’: ‘dealername’, ‘url’: ‘https://testurl.com’, ‘msrp’: 897564, ‘dealer_price’: 149999, ‘price_savings’: 243365, ‘description’: \" This Class A motorhome is built on the robust Spartan K3 chassis with a tag axle.\"}, tenant=None, references=None, index=0, retry_count=0), original_uuid=None)]\n\n----------\n\n[DudaNogueira (2024-09-30T15:06:51.295Z)]: hi @Neil !!\nWelcome to our community \nI believe the issue is that you may be passing a number instead of a text.\nFor example, this will not work:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    properties=[\n        wvc.config.Property(\n            name=\"text\", data_type=wvc.config.DataType.TEXT\n        )\n    ]\n)\ncollection.data.insert({\"text\": 4531})\n\n\nbut this insert will work:\ncollection.data.insert({\"text\": \"4531\"})\n\nLet me know if this works for you.\nThanks!",
    "date_created": "2024-09-27T17:40:37.111Z",
    "has_accepted_answer": false,
    "title": "Error loading numbers into a TEXT Field. Error = invalid text property \\'trim\\' on class \\'test_class\\': not a string, but float64\")",
    "topic_id": 4358
  },
  {
    "user_id": 8921,
    "conversation": "[Daniel_Engelhardt (2025-03-17T16:22:23.916Z)]: Description\nI have a KnowledgeBase-collection with the following keywords text-array property:\n  {\n          name: 'keywords',\n          dataType: 'text[]',\n          indexSearchable: true,\n          tokenization: 'word',\n }\n\nand I am trying to  query this collection with the following gql-query:\nquery Get($tenant: String!, $where: GetObjectsKnowledgeBaseWhereInpObj) {\n    Get {\n        KnowledgeBase(limit: 10, tenant: $tenant, where: $where) {\n            content\n            keywords\n        }\n    }\n}\n\nand these variables:\n{\n    \"tenant\": \"xxx\",\n    \"where\": {\n        \"operator\": \"ContainsAny\",\n        \"path\": [\n            \"keywords\"\n        ],\n        \"valueText\": [\n            \"keyword1\",\n            \"keyword2\"\n        ]\n    }\n}\n\nThe response shows the following error:\n\"explorer: list class: search: object search at index knowledgebase_xxx: local shard object search knowledgebase_xxx: value type should be []string but is string\",\nhere the collection config:\n{\n    \"class\": \"KnowledgeBase\",\n    \"invertedIndexConfig\": {\n        \"bm25\": {\n            \"b\": 0.75,\n            \"k1\": 1.2\n        },\n        \"cleanupIntervalSeconds\": 60,\n        \"stopwords\": {\n            \"additions\": null,\n            \"preset\": \"en\",\n            \"removals\": null\n        }\n    },\n    \"multiTenancyConfig\": {\n        \"autoTenantActivation\": false,\n        \"autoTenantCreation\": true,\n        \"enabled\": true\n    },\n    \"properties\": [\n        {\n            \"dataType\": [\n                \"text\"\n            ],\n            \"indexFilterable\": true,\n            \"indexRangeFilters\": false,\n            \"indexSearchable\": true,\n            \"moduleConfig\": {\n                \"text2vec-aws\": {\n                    \"skip\": false,\n                    \"vectorizePropertyName\": false\n                }\n            },\n            \"name\": \"content\",\n            \"tokenization\": \"word\"\n        },\n        {\n            \"dataType\": [\n                \"text[]\"\n            ],\n            \"indexFilterable\": true,\n            \"indexRangeFilters\": false,\n            \"indexSearchable\": true,\n            \"moduleConfig\": {\n                \"text2vec-aws\": {\n                    \"skip\": false,\n                    \"vectorizePropertyName\": false\n                }\n            },\n            \"name\": \"keywords\",\n            \"tokenization\": \"word\"\n        }\n    ],\n    \"replicationConfig\": {\n        \"asyncEnabled\": false,\n        \"deletionStrategy\": \"NoAutomatedResolution\",\n        \"factor\": 1\n    },\n    \"shardingConfig\": {\n        \"actualCount\": 0,\n        \"actualVirtualCount\": 0,\n        \"desiredCount\": 0,\n        \"desiredVirtualCount\": 0,\n        \"function\": \"\",\n        \"key\": \"\",\n        \"strategy\": \"\",\n        \"virtualPerPhysical\": 0\n    },\n    \"vectorConfig\": {\n        \"content_vector\": {\n            \"vectorIndexConfig\": {\n                \"distance\": \"cosine\",\n                \"flat\": {\n                    \"bq\": {\n                        \"cache\": false,\n                        \"enabled\": false,\n                        \"rescoreLimit\": -1\n                    },\n                    \"distance\": \"cosine\",\n                    \"pq\": {\n                        \"cache\": false,\n                        \"enabled\": false,\n                        \"rescoreLimit\": -1\n                    },\n                    \"sq\": {\n                        \"cache\": false,\n                        \"enabled\": false,\n                        \"rescoreLimit\": -1\n                    },\n                    \"vectorCacheMaxObjects\": 1000000000000\n                },\n                \"hnsw\": {\n                    \"bq\": {\n                        \"enabled\": false\n                    },\n                    \"cleanupIntervalSeconds\": 300,\n                    \"distance\": \"cosine\",\n                    \"dynamicEfFactor\": 8,\n                    \"dynamicEfMax\": 500,\n                    \"dynamicEfMin\": 100,\n                    \"ef\": -1,\n                    \"efConstruction\": 128,\n                    \"filterStrategy\": \"sweeping\",\n                    \"flatSearchCutoff\": 40000,\n                    \"maxConnections\": 32,\n                    \"multivector\": {\n                        \"aggregation\": \"maxSim\",\n                        \"enabled\": false\n                    },\n                    \"pq\": {\n                        \"bitCompression\": false,\n                        \"centroids\": 256,\n                        \"enabled\": false,\n                        \"encoder\": {\n                            \"distribution\": \"log-normal\",\n                            \"type\": \"kmeans\"\n                        },\n                        \"segments\": 0,\n                        \"trainingLimit\": 100000\n                    },\n                    \"skip\": false,\n                    \"sq\": {\n                        \"enabled\": false,\n                        \"rescoreLimit\": 20,\n                        \"trainingLimit\": 100000\n                    },\n                    \"vectorCacheMaxObjects\": 1000000000000\n                },\n                \"threshold\": 10000\n            },\n            \"vectorIndexType\": \"dynamic\",\n            \"vectorizer\": {\n                \"text2vec-aws\": {\n                    \"model\": \"cohere.embed-multilingual-v3\",\n                    \"region\": \"eu-central-1\",\n                    \"service\": \"bedrock\",\n                    \"sourceProperties\": [\n                        \"content\"\n                    ],\n                    \"vectorizeClassName\": false\n                }\n            }\n        }\n    }\n}\n\nI also tried the same request via Postman with the same results.\nServer Setup Information\n\nWeaviate Server Version:  1.29.0\nDeployment Method: cloud\nClient Language and Version: bare gql weaviate cloud query console\nMultitenancy: true\n\nAny additional Information\nI also tried the same request via Postman with the same results.\n\n----------\n\n[Daniel_Engelhardt (2025-03-17T16:52:03.452Z)]: Addition:\nI successfully use this filter for delete operations with the valueTextArray-Filter property.\n\n----------\n\n[Mohamed_Shahin (2025-03-18T12:14:13.114Z)]: Hey @Daniel_Engelhardt,\nI see you mentioned that your deployment is cloud.\nCould you please open a ticket with us in our ticketing system for our cloud users by email support@weaviate.io ?\nGenerally message indicates that there’s a data type mismatch for the valueText field in your GraphQL query. The ContainsAny operator expects an array of strings ([…]string), but the query is interpreting it as a single string.\nHave you tried switching from valueText to valueTextArray?\nTry modifying your query like this:\n{\n    \"tenant\": \"xxx\",\n    \"where\": {\n        \"operator\": \"ContainsAny\",\n        \"path\": [\n            \"keywords\"\n        ],\n        \"valueTextArray\": [\n            \"keyword1\",\n            \"keyword2\"\n        ]\n    }\n}\n\n----------\n\n[Daniel_Engelhardt (2025-03-18T13:05:37.047Z)]: Hi @Mohamed_Shahin,\nyeah I already tried that and every other thinkable combination of array, string and valueText and valueTextArray-properties.\nThe valueTextArray-option is not allowed for the where-input (also mentioned in the documentation: Conditional filters | Weaviate) and results in this error:\n\"message\": \"Variable \\\"$where\\\" got invalid value {\\\"operator\\\":\\\"ContainsAny\\\",\\\"path\\\":[\\\"keywords\\\"],\\\"valueTextArray\\\":[\\\"xxx\\\"]}.\\nIn field \\\"valueTextArray\\\": Unknown field.\",\nThe cloud console also complains about it:\nimage1352×492 41.9 KB\n\n----------\n\n[DudaNogueira (2025-03-19T14:12:53.494Z)]: Hi Daniel!\nI have reproduced this.\nHere in python first:\nfrom weaviate import classes as wvc\nclient.collections.delete(\"Test\")\ncol = client.collections.create(\n    \"Test\",\n    multi_tenancy_config=wvc.config.Configure.multi_tenancy(\n        enabled=True, auto_tenant_creation=True, auto_tenant_activation=True\n    ),\n    properties=[\n        wvc.config.Property(name=\"content\", data_type=wvc.config.DataType.TEXT),\n        wvc.config.Property(name=\"keywords\", data_type=wvc.config.DataType.TEXT_ARRAY),\n    ]\n)\n\ncol.with_tenant(\"t1\").data.insert({\"content\": \"Hello 1\", \"keywords\": [\"tag1\", \"tag2\"]})\ncol.with_tenant(\"t1\").data.insert({\"content\": \"Hello 2\", \"keywords\": [\"tag2\", \"tag3\"]})\n\ncol.with_tenant(\"t1\").query.fetch_objects(\n    filters=wvc.query.Filter.by_property(\"keywords\").contains_any([\"tag2\", \"tag10\"])\n)\n\nNow, while experimenting connecting direct to the cluster using insomnia:\nThis will work:\nimage1754×946 81.6 KB\nThis will not:\nimage1734×1390 291 KB\nI was able to nail it down to TextGetObjectsTest:\nimage1804×1306 297 KB\nI will poke internally to see if this makes sense.\nThanks!",
    "date_created": "2025-03-17T16:22:23.853Z",
    "has_accepted_answer": false,
    "title": "Plain GQL query with \"containsAny\" operator not working",
    "topic_id": 19943
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-09-12T16:18:14.301Z)]: When using not_equal, it does not seem to work in retrieving objects.\nPlease see my minimal reproducible code below that creates an object with a lastUpdateDeviceId and then uses lastUpdateDeviceId as something else and runs not_equal.\nHowever, no objects are returned. But if I remove the not_equal filter (the 2nd filter), it will return the last inserted objects.\nimport uuid\nimport weaviate\nimport weaviate.classes as wvc\nfrom weaviate.classes.query import Filter, MetadataQuery\nfrom weaviate.classes.config import Configure, VectorDistances, Property, DataType\nfrom weaviate.classes.tenants import Tenant\nfrom datetime import datetime, timedelta\nimport pytz\n\ntry:\n\t# TODO: use different credentials for production\n\t# Best practice: store your credentials in environment variables\n\twcd_url = \"\" #TODO: insert url\n\twcd_api_key = \"\" #TODO: insert key\n\n\tclient = weaviate.connect_to_weaviate_cloud(\n\t\tcluster_url=wcd_url,                                    # Replace with your Weaviate Cloud URL\n\t\tauth_credentials=wvc.init.Auth.api_key(wcd_api_key),    # Replace with your Weaviate Cloud key\n\t)\nexcept:\n\tpass\n\ndef parse_weaviate_results(results):\n\t\"\"\"\n\tConverts results into a list[JSON] for easy\n\tparsing for the frontends\n\t\"\"\"\n\tparsed_objs = []\n\n\tfor result in results:\n\t\tparsed_objs.append(parse_weaviate_result(result))\t\n\n\treturn parsed_objs\n\ndef parse_weaviate_result(result):\n\n\n\tpst = pytz.timezone('US/Pacific')\n\tlast_update_time_utc = result.metadata.last_update_time\n\tlast_update_time_pst = last_update_time_utc.astimezone(pst)\n\tprint(f\"Last update time in PST: {last_update_time_pst} for {result.properties['title']} with device id: {result.properties['lastUpdateDeviceId']}\")\n\treturn {\n\t\t**result.properties,\n\t\t# adding this after unpack to prevent override\n\t\t\"uniqueid\": str(result.uuid),\n\t\t\"score\": result.metadata.distance if hasattr(result.metadata, 'distance') else -1,\n\t\t\"vector\": result.vector,\n\t\t\"last_updated_utc\": result.metadata.last_update_time\n\t}\n\nnodes_collection = None\n\n# TODO: after production launch, delete this as it's dangerous\n# client.collections.delete('Nodes')\n\ntry:\n\t# For all objects\n\tnodes_collection = client.collections.create(\n\t\tname=\"Nodes\",\n\t\tvectorizer_config=wvc.config.Configure.Vectorizer.none(),\n\t\tvector_index_config=Configure.VectorIndex.hnsw(\n\t\t\tdistance_metric=VectorDistances.COSINE\n\t\t),\n\t\t# Multi tenancy to separate each user's data\n\t\tmulti_tenancy_config=Configure.multi_tenancy(enabled=True, auto_tenant_creation=True, auto_tenant_activation=True),\n\t\tinverted_index_config=Configure.inverted_index( \n\t\t\tindex_null_state=True,\n        \tindex_property_length=True,\n\t\t\tindex_timestamps=True\n\t\t)\n\t\t# Specify some properties beforehand to set right data type (i.e. obj[] instead of string[])\n\t\t# properties=[\n\t\t# \tProperty(name=\"tags\", data_type=DataType.OBJECT_ARRAY),\n\t\t# ]\n\t)\nexcept:\n\tnodes_collection = client.collections.get(\"Nodes\")\n\ntry:\n\t# Create tenant on JeopardyQuestion\n\tnodes_collection.tenants.create(\n\t\ttenants=[\n\t\t\tTenant(name=\"tenantA\"),\n\t\t\tTenant(name=\"tenantB\"),\n\t\t]\n\t)\nexcept:\n\tpass\n\nnodes_collection.with_tenant('tenantA').data.insert(\n\tvector=[0.0] * 384,\n\tproperties={'lastUpdateDeviceId': 'device-78C24351-F40A-4E37-8953-F003FA474877'},\n\tuuid=str(uuid.uuid4())\n)\n\n\n# get the last inserted object in last 10 mins\nlast_sync_datetime = datetime.now() - timedelta(minutes=10)\n\nquery_result = nodes_collection.with_tenant('tenantA').query.fetch_objects(\n\tfilters=Filter.by_update_time().greater_than(last_sync_datetime) &\n\t\tFilter.by_property(\"lastUpdateDeviceId\").not_equal('device-d06e69fb200a1b8fdb8a96d8aff91e9e7839f35d9ac0ad69780067174e26fda1'), \n# if I comment out the above, it will return objects\n\tinclude_vector=True, # TOOD: include_vector=True\n\treturn_metadata=MetadataQuery(last_update_time=True),\n)\n\nprint('Objects returned: ')\nprint(parse_weaviate_results(query_result.objects))\n\n# TODO: expected the inserted object to be returned\n# actual: []\n\n\nclient.close()\n\n----------\n\n[Tejas_Sharma (2024-09-12T16:27:25.758Z)]: I am not sure if specifying tokenization will fix it as I found in Not_equal filter seems not work\nBut the main problem is then when specifying properties along with tenancy, I run into this bug here:\n  \n    \n    \n    Specifying properties with multi-tenancy causes bug Support\n  \n  \n    Hi @DudaNogueira , aplogies for the delay, here’s the minimal reproducible code: \nimport uuid\nimport weaviate\nimport weaviate.classes as wvc\nfrom weaviate.classes.query import Filter, MetadataQuery\nfrom weaviate.classes.config import Configure, VectorDistances, Property, DataType\nfrom weaviate.classes.tenants import Tenant\nfrom datetime import datetime, timedelta\nimport pytz\n\ntry:\n\t# TODO: use different credentials for production\n\t# Best practice: store your credentials in environment variables\n…\n  \n\n\n(which I just updated with a minimal code example too, sorry for the delay on that one)\n\n----------\n\n[DudaNogueira (2024-09-16T13:52:30.972Z)]: Hi!\nI have created a code with tokenization set to field, and now it works as expected\nfrom weaviate import classes as wvc\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n    vector_index_config=wvc.config.Configure.VectorIndex.hnsw(\n        distance_metric=wvc.config.VectorDistances.COSINE\n    ),\n    # Multi tenancy to separate each user's data\n    multi_tenancy_config=wvc.config.Configure.multi_tenancy(\n        enabled=True, auto_tenant_creation=True, auto_tenant_activation=True\n    ),\n    properties=[\n        wvc.config.Property(\n            name=\"lastUpdateDeviceId\",\n            data_type=wvc.config.DataType.TEXT,\n            tokenization=wvc.config.Tokenization.FIELD\n        )\n    ],\n    inverted_index_config=wvc.config.Configure.inverted_index(\n        index_null_state=True,\n        index_property_length=True,\n        index_timestamps=True\n    )\n    # Specify some properties beforehand to set right data type (i.e. obj[] instead of string[])\n    # properties=[\n    # \tProperty(name=\"tags\", data_type=DataType.OBJECT_ARRAY),\n    # ]\n)\n\ncollection.tenants.create(\n    tenants=[\n        wvc.tenants.Tenant(name=\"tenantA\"),\n        wvc.tenants.Tenant(name=\"tenantB\"),\n    ]\n)\n\nfrom weaviate.util import generate_uuid5\ncollection.with_tenant('tenantA').data.insert(\n\tvector=[0.0] * 384,\n\tproperties={'lastUpdateDeviceId': 'device-78C24351-F40A-4E37-8953-F003FA474877'},\n\tuuid=generate_uuid5(\"object1\")\n)\n\nfrom datetime import datetime, timedelta, timezone\nlast_sync_datetime = datetime.now(timezone.utc).astimezone() - timedelta(minutes=10)\n\ncollection.with_tenant('tenantA').query.fetch_objects(\n\tfilters=wvc.query.Filter.by_update_time().greater_than(last_sync_datetime) &\n\t\twvc.query.Filter.by_property(\"lastUpdateDeviceId\").not_equal('device-d06e69fb200a1b8fdb8a96d8aff91e9e7839f35d9ac0ad69780067174e26fda1'), \n\tinclude_vector=True,\n\treturn_metadata=wvc.query.MetadataQuery(last_update_time=True),\n)\n\nNote that, if I set the search query to d06e69fb200a1b8fdb8a96d8aff91e9e7839f35d9ac0ad69780067174e26fda1, instead of device-d0.... it will also work.\nThis is because device-d06.... will become two key workds: device and d06...\nLet me know if this helps!\n\n----------\n\n[Tejas_Sharma (2024-09-16T18:17:30.812Z)]: Thanks Duda!\nOur nodes collection is already in production though so the alternate solution you mentioned was to just remove ‘device-’ from the front right?\nI guess to update the property, I can do\narticles.config.add_property(\n    Property(\n        name=\"onHomepage\",\n        data_type=DataType.BOOL\n    )\n)\n\n----------\n\n[DudaNogueira (2024-09-16T18:40:32.534Z)]: Hi!\nYou will need to set the tokenization of that property to FIELD.\nCheck this part, where we define the lastUpdateDeviceId property.\n\n\n\n DudaNogueira:\n\n        wvc.config.Property(\n            name=\"lastUpdateDeviceId\",\n            data_type=wvc.config.DataType.TEXT,\n            tokenization=wvc.config.Tokenization.FIELD\n        )\n\n\n\nWeaviate will tokenize you content, according to the tokenization.\nif you have property with a value device-123456,  and the tokenization is word (the default), you will endup with two keywords: device and 123456.\nNow, when the tokenization is set to field, you endup with only one keyword: device-123456.\nSo the best solution is defining this new property.\nLet me know if this helps!",
    "date_created": "2024-09-12T16:18:14.248Z",
    "has_accepted_answer": true,
    "title": "[Question] Bug in not_equal filter",
    "topic_id": 4125
  },
  {
    "user_id": 1655,
    "conversation": "[Rajesh (2025-03-22T03:49:46.917Z)]: Description\n\nThese days my service is down and I am unnecessarily paying for my Weaviate Cluster. Please tell me the instructions to take a backup of my Vector DB and shutdown my Cluster on the Weaviate Cloud so that I stop paying the monthly fee. Later, when I restart my website then I would like to restore my Vector DB and restart the Cluster.\nThank you very much,\nAstranetix AI\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2025-03-25T17:52:46.633Z)]: hi @Rajesh !!\nYou can configure a backup module (for example a backup bucket in s3, os google cp, for example).\nYou then backup there and when the times come,  restore using the bucket and backup id.\nHere you have more docs:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBackups | Weaviate\n\n  Weaviate's Backup feature is designed to work natively with cloud technology. Most notably, it allows:",
    "date_created": "2025-03-22T03:49:46.868Z",
    "has_accepted_answer": false,
    "title": "Instructions to back-up my Vector Database and shutdown my Cluster",
    "topic_id": 20182
  },
  {
    "user_id": 1081,
    "conversation": "[Dominic_poi (2024-06-19T07:45:05.577Z)]: Description\nHi,\nI’m new to weaviate and I am trying to deploy a multi-node setup using docker-compose for testing :\nservices:\n  weaviate-node-11:\n    init: true\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.4\n    ports:\n    - 8080:8080\n    - 50051:50051\n    - 6060:6060\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface'\n      CLUSTER_HOSTNAME: 'node1'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'\n      HTTP_PROXY: ''\n      http_proxy: ''\n      LOG_LEVEL: 'debug'\n  weaviate-node-12:\n    init: true\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.4\n    ports:\n    - 8081:8080\n    - 50052:50051\n    - 6061:6060\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface'\n      CLUSTER_HOSTNAME: 'node2'\n      CLUSTER_GOSSIP_BIND_PORT: '7102'\n      CLUSTER_DATA_BIND_PORT: '7103'\n      CLUSTER_JOIN: 'weaviate-node-11:7100'\n      HTTP_PROXY: ''\n      http_proxy: ''\n      LOG_LEVEL: 'debug'\n\nAfter starting, I found that the /v1/nodes endpoint seems to return results normally.\n{\n\t\"nodes\": [{\n\t\t\"batchStats\": {\n\t\t\t\"queueLength\": 0,\n\t\t\t\"ratePerSecond\": 0\n\t\t},\n\t\t\"gitHash\": \"a61909a\",\n\t\t\"name\": \"node1\",\n\t\t\"shards\": null,\n\t\t\"status\": \"HEALTHY\",\n\t\t\"version\": \"1.25.4\"\n\t}, {\n\t\t\"batchStats\": {\n\t\t\t\"queueLength\": 0,\n\t\t\t\"ratePerSecond\": 0\n\t\t},\n\t\t\"gitHash\": \"a61909a\",\n\t\t\"name\": \"node2\",\n\t\t\"shards\": null,\n\t\t\"status\": \"HEALTHY\",\n\t\t\"version\": \"1.25.4\"\n\t}]\n}\n\nNext, I used the Python client to create a collection.\nimport weaviate\nimport weaviate.classes as wvc\nimport os\n\n\nclient = weaviate.connect_to_custom(\n    http_host=\"localhost\",\n    http_port=8080,\n    http_secure=False,\n    grpc_host=\"localhost\",\n    grpc_port=50051,\n    grpc_secure=False,\n    # headers={\n    #     \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY\"]  # Replace with your inference API key\n    # }\n)\n\n\n\ntry:\n    questions = client.collections.create(\n        name=\"Question\",\n        sharding_config=wvc.config.Configure.sharding(\n            desired_count=3\n        ),\n        replication_config=wvc.config.Configure.replication(\n            factor=2\n        ),\n        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),    # Set the vectorizer to \"text2vec-openai\" to use the OpenAI API for vector-related operations\n        generative_config=wvc.config.Configure.Generative.cohere(),             # Set the generative module to \"generative-cohere\" to use the Cohere API for RAG\n        properties=[\n            wvc.config.Property(\n                name=\"question\",\n                data_type=wvc.config.DataType.TEXT,\n            ),\n            wvc.config.Property(\n                name=\"answer\",\n                data_type=wvc.config.DataType.TEXT,\n            ),\n        ],\n        # Configure the vector index\n        vector_index_config=wvc.config.Configure.VectorIndex.hnsw(  # Or `flat` or `dynamic`\n            distance_metric=wvc.config.VectorDistances.COSINE,\n            quantizer=wvc.config.Configure.VectorIndex.Quantizer.bq(),\n        ),\n        # Configure the inverted index\n        inverted_index_config=wvc.config.Configure.inverted_index(\n            index_null_state=True,\n            index_property_length=True,\n            index_timestamps=True,\n        ),\n    )\n\nfinally:\n    client.close()\n\nAfter creation, I found that all the shards were concentrated on the node from which I made the call, and the other node did not have the corresponding collection.\nhttp://localhost:8080/v1/schema/Question/shards shows that:\n[{\n\t\"name\": \"pklJTouifT37\",\n\t\"status\": \"READY\",\n\t\"vectorQueueSize\": 0\n}, {\n\t\"name\": \"1gTDzdO9guT0\",\n\t\"status\": \"READY\",\n\t\"vectorQueueSize\": 0\n}, {\n\t\"name\": \"IOgYO9o0RmDG\",\n\t\"status\": \"READY\",\n\t\"vectorQueueSize\": 0\n}]\n\nwhile the other node http://localhost:8081/v1/schema/Question/shards returns:\n{\n\t\"error\": [{\n\t\t\"message\": \"cannot get shards status for a non-existing index for Question\"\n\t}]\n}\n\nThen, I tried to import data:\nimport weaviate\nimport json\n\n\nclient = weaviate.Client(\n    url=\"http://localhost:8080/\",  # Replace with your Weaviate endpoint\n    additional_headers={\n        \"X-OpenAI-Api-Key\": \"YOUR-OPENAI-API-KEY\"  # Or \"X-Cohere-Api-Key\" or \"X-HuggingFace-Api-Key\"\n    }\n)\n\n\n# ===== import data =====\n# Load data\nimport requests\nurl = 'https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json'\nresp = requests.get(url)\ndata = json.loads(resp.text)\n\n# Prepare a batch process\nclient.batch.configure(batch_size=100)  # Configure batch\nwith client.batch as batch:\n    # Batch import all Questions\n    for i, d in enumerate(data):\n        # print(f\"importing question: {i+1}\")  # To see imports\n\n        properties = {\n            \"answer\": d[\"Answer\"],\n            \"question\": d[\"Question\"],\n            \"category\": d[\"Category\"],\n        }\n\n        batch.add_data_object(properties, \"Question\")\n\nAnd encountered the following error, it seems that weaviate cannot found the class on the other node.\n2024-06-19 15:31:46 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"status code: 500, error: digest objects: local index \\\"Question\\\" not found\\n: context deadline exceeded\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"pklJTouifT37\",\"time\":\"2024-06-19T07:31:46Z\",\"uuid\":\"7bc9bf37-0d63-40c7-9c63-70d10aea7683\"}\n2024-06-19 15:31:56 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"status code: 500, error: digest objects: local index \\\"Question\\\" not found\\n: context deadline exceeded\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"pklJTouifT37\",\"time\":\"2024-06-19T07:31:56Z\",\"uuid\":\"b5565857-9e61-40a1-88b8-7b0bbb82c139\"}\n2024-06-19 15:32:06 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"status code: 500, error: digest objects: local index \\\"Question\\\" not found\\n: context deadline exceeded\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"pklJTouifT37\",\"time\":\"2024-06-19T07:32:06Z\",\"uuid\":\"d4f7e703-2e07-47ad-8615-a4cc0da979ea\"}\n2024-06-19 15:32:16 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"status code: 500, error: digest objects: local index \\\"Question\\\" not found\\n: context deadline exceeded\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"pklJTouifT37\",\"time\":\"2024-06-19T07:32:16Z\",\"uuid\":\"dd5e7784-129f-42dc-ba3a-2e2665812359\"}\n2024-06-19 15:32:26 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"status code: 500, error: digest objects: local index \\\"Question\\\" not found\\n: context deadline exceeded\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"pklJTouifT37\",\"time\":\"2024-06-19T07:32:26Z\",\"uuid\":\"609a7b08-a4df-4664-ae5e-d5a0952c9e4c\"}\n2024-06-19 15:32:35 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"status code: 500, error: digest objects: local index \\\"Question\\\" not found\\n: context canceled\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"1gTDzdO9guT0\",\"time\":\"2024-06-19T07:32:35Z\",\"uuid\":\"6f1b6157-1eb9-4a71-81dc-fe0ac4550910\"}\n2024-06-19 15:32:35 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"connect: Get \\\"http://172.23.0.2:7103/replicas/indices/Question/shards/1gTDzdO9guT0/objects/_digest?schema_version=0\\\": context canceled\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"1gTDzdO9guT0\",\"time\":\"2024-06-19T07:32:35Z\",\"uuid\":\"ba872283-31a9-46fa-bcae-83a24bfd750c\"}\n2024-06-19 15:32:35 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"connect: Get \\\"http://172.23.0.2:7103/replicas/indices/Question/shards/IOgYO9o0RmDG/objects/_digest?schema_version=0\\\": context canceled\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"IOgYO9o0RmDG\",\"time\":\"2024-06-19T07:32:35Z\",\"uuid\":\"0473a789-e36b-4b1e-b97f-d3a7379a54a8\"}\n2024-06-19 15:32:35 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"connect: Get \\\"http://172.23.0.2:7103/replicas/indices/Question/shards/pklJTouifT37/objects/_digest?schema_version=0\\\": context canceled\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"pklJTouifT37\",\"time\":\"2024-06-19T07:32:35Z\",\"uuid\":\"a94ed56b-625d-4f92-b214-974bee6d4545\"}\n2024-06-19 15:32:35 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"connect: Get \\\"http://172.23.0.2:7103/replicas/indices/Question/shards/IOgYO9o0RmDG/objects/_digest?schema_version=0\\\": context canceled\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"IOgYO9o0RmDG\",\"time\":\"2024-06-19T07:32:35Z\",\"uuid\":\"95e0ce69-c5be-46fa-bdd0-30c2d68916c5\"}\n2024-06-19 15:32:35 weaviate-weaviate-node-11-1  | {\"description\":\"An I/O timeout occurs when the request takes longer than the specified server-side timeout.\",\"error\":\"write tcp 172.23.0.3:8080-\\u003e172.23.0.1:57940: i/o timeout\",\"hint\":\"Either try increasing the server-side timeout using e.g. '--write-timeout=600s' as a command line flag when starting Weaviate, or try sending a computationally cheaper request, for example by reducing a batch size, reducing a limit, using less complex filters, etc. Note that this error is only thrown if client-side and server-side timeouts are not in sync, more precisely if the client-side timeout is longer than the server side timeout.\",\"level\":\"error\",\"method\":\"POST\",\"msg\":\"i/o timeout\",\"path\":{\"Scheme\":\"\",\"Opaque\":\"\",\"User\":null,\"Host\":\"\",\"Path\":\"/v1/batch/objects\",\"RawPath\":\"\",\"OmitHost\":false,\"ForceQuery\":false,\"RawQuery\":\"\",\"Fragment\":\"\",\"RawFragment\":\"\"},\"time\":\"2024-06-19T07:32:35Z\"}\n2024-06-19 15:32:47 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"status code: 500, error: digest objects: local index \\\"Question\\\" not found\\n: context deadline exceeded\",\"op\":\"exists\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"pklJTouifT37\",\"time\":\"2024-06-19T07:32:47Z\",\"uuid\":\"7bc9bf37-0d63-40c7-9c63-70d10aea7683\"}\n2024-06-19 15:32:47 weaviate-weaviate-node-11-1  | {\"action\":\"requests_total\",\"api\":\"rest\",\"class_name\":\"Question\",\"error\":\"msg:repo.exists code:500 err:cannot achieve consistency level \\\"QUORUM\\\": read error\",\"level\":\"error\",\"msg\":\"unexpected error\",\"query_type\":\"objects\",\"time\":\"2024-06-19T07:32:47Z\"}\n2024-06-19 15:32:57 weaviate-weaviate-node-11-1  | {\"class\":\"Question\",\"level\":\"error\",\"msg\":\"status code: 500, error: digest objects: local index \\\"Question\\\" not found\\n: context deadline exceeded\",\"op\":\"get\",\"replica\":\"172.23.0.2:7103\",\"shard\":\"pklJTouifT37\",\"time\":\"2024-06-19T07:32:57Z\",\"uuid\":\"7bc9bf37-0d63-40c7-9c63-70d10aea7683\"}\n2024-06-19 15:32:57 weaviate-weaviate-node-11-1  | {\"action\":\"requests_total\",\"api\":\"rest\",\"class_name\":\"\",\"error\":\"repo: object by id: search index question: cannot achieve consistency level \\\"QUORUM\\\": read error\",\"level\":\"error\",\"msg\":\"unexpected error\",\"query_type\":\"objects\",\"time\":\"2024-06-19T07:32:57Z\"}\n\nI noticed that /v1/cluster/statistics shows both nodes as leaders and synchronized is false:\n{\n\t\"statistics\": [{\n\t\t\"bootstrapped\": true,\n\t\t\"candidates\": {},\n\t\t\"dbLoaded\": true,\n\t\t\"isVoter\": true,\n\t\t\"leaderAddress\": \"172.23.0.3:8300\",\n\t\t\"leaderId\": \"node1\",\n\t\t\"name\": \"node1\",\n\t\t\"open\": true,\n\t\t\"raft\": {\n\t\t\t\"appliedIndex\": \"7\",\n\t\t\t\"commitIndex\": \"7\",\n\t\t\t\"fsmPending\": \"0\",\n\t\t\t\"lastContact\": \"0\",\n\t\t\t\"lastLogIndex\": \"7\",\n\t\t\t\"lastLogTerm\": \"2\",\n\t\t\t\"lastSnapshotIndex\": \"0\",\n\t\t\t\"lastSnapshotTerm\": \"0\",\n\t\t\t\"latestConfiguration\": [{\n\t\t\t\t\"address\": \"172.23.0.3:8300\",\n\t\t\t\t\"id\": \"node1\",\n\t\t\t\t\"suffrage\": 0\n\t\t\t}],\n\t\t\t\"latestConfigurationIndex\": \"0\",\n\t\t\t\"numPeers\": \"0\",\n\t\t\t\"protocolVersion\": \"3\",\n\t\t\t\"protocolVersionMax\": \"3\",\n\t\t\t\"protocolVersionMin\": \"0\",\n\t\t\t\"snapshotVersionMax\": \"1\",\n\t\t\t\"snapshotVersionMin\": \"0\",\n\t\t\t\"state\": \"Leader\",\n\t\t\t\"term\": \"2\"\n\t\t},\n\t\t\"ready\": true,\n\t\t\"status\": \"HEALTHY\"\n\t}, {\n\t\t\"bootstrapped\": true,\n\t\t\"candidates\": {},\n\t\t\"dbLoaded\": true,\n\t\t\"isVoter\": true,\n\t\t\"leaderAddress\": \"172.23.0.2:8300\",\n\t\t\"leaderId\": \"node2\",\n\t\t\"name\": \"node2\",\n\t\t\"open\": true,\n\t\t\"raft\": {\n\t\t\t\"appliedIndex\": \"2\",\n\t\t\t\"commitIndex\": \"2\",\n\t\t\t\"fsmPending\": \"0\",\n\t\t\t\"lastContact\": \"0\",\n\t\t\t\"lastLogIndex\": \"2\",\n\t\t\t\"lastLogTerm\": \"2\",\n\t\t\t\"lastSnapshotIndex\": \"0\",\n\t\t\t\"lastSnapshotTerm\": \"0\",\n\t\t\t\"latestConfiguration\": [{\n\t\t\t\t\"address\": \"172.23.0.2:8300\",\n\t\t\t\t\"id\": \"node2\",\n\t\t\t\t\"suffrage\": 0\n\t\t\t}],\n\t\t\t\"latestConfigurationIndex\": \"0\",\n\t\t\t\"numPeers\": \"0\",\n\t\t\t\"protocolVersion\": \"3\",\n\t\t\t\"protocolVersionMax\": \"3\",\n\t\t\t\"protocolVersionMin\": \"0\",\n\t\t\t\"snapshotVersionMax\": \"1\",\n\t\t\t\"snapshotVersionMin\": \"0\",\n\t\t\t\"state\": \"Leader\", <-- both are leaders\n\t\t\t\"term\": \"2\"\n\t\t},\n\t\t\"ready\": true,\n\t\t\"status\": \"HEALTHY\"\n\t}],\n\t\"synchronized\": false <-- Why it cannot be synchronized?\n}\n\nWhat could be the reason that the collection shards are not synchronizing between nodes?\nServer Setup Information\n\nWeaviate Server Version: 1.25.4\nDeployment Method:  docker/binary\nMulti Node? Number of Running Nodes: 2\nClient Language and Version: python 3.8\nMultitenancy?: No\n\nAny additional Information\nenv : Mac ARM64\n\n----------\n\n[DudaNogueira (2024-06-20T18:56:18.419Z)]: hi @Dominic_poi !! Welcome to our community \nBecause you only have 2 nodes in your cluster, you will not be able to reach a consensus on who will be the leader \nSo I believe that both nodes will declare themselves leader \nSo first solution, is having least 3+ nodes.\nAnother solution is explicitly selecting who will be able to vote.\nso adding:\nRAFT_JOIN: node1\n\nAs an environment variable in both your nodes will bring the cluster to behave as expected.\nCheck here for similar configurations:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nEnvironment variables | Weaviate - Vector Database\n\n  To configure Weaviate in a Docker or a Kubernetes deployment, set these environment variables\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Dominic_poi (2024-06-21T02:01:18.213Z)]: Thank you for your reply @DudaNogueira ,\nIn fact I have tried 3 nodes in my cluster, here’s the docker-compose.yml:\nservices:\n  weaviate-node-11:\n    init: true\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.4\n    ports:\n    - 8080:8080\n    - 50051:50051\n    - 6060:6060\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface'\n      CLUSTER_HOSTNAME: 'node1'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'\n      HTTP_PROXY: ''\n      http_proxy: ''\n      LOG_LEVEL: 'debug'\n  weaviate-node-12:\n    init: true\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.4\n    ports:\n    - 8081:8080\n    - 50052:50051\n    - 6061:6060\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface'\n      CLUSTER_HOSTNAME: 'node2'\n      CLUSTER_GOSSIP_BIND_PORT: '7102'\n      CLUSTER_DATA_BIND_PORT: '7103'\n      CLUSTER_JOIN: 'weaviate-node-11:7100'\n      HTTP_PROXY: ''\n      http_proxy: ''\n      LOG_LEVEL: 'debug'\n  weaviate-node-13:\n    init: true\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.4\n    ports:\n    - 8082:8080\n    - 50053:50051\n    - 6062:6060\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface'\n      CLUSTER_HOSTNAME: 'node3'\n      CLUSTER_GOSSIP_BIND_PORT: '7104'\n      CLUSTER_DATA_BIND_PORT: '7105'\n      CLUSTER_JOIN: 'weaviate-node-11:7100'\n      HTTP_PROXY: ''\n      http_proxy: ''\n      LOG_LEVEL: 'debug'\n\nAnd I created a collection with 3 shards and 2 replicas, it’s expected 2 shards on each node:\nimport weaviate\nimport weaviate.classes as wvc\nimport os\n\nweaviate_url=\"http://10.148.12.177:8080/\"\n\nclient = weaviate.connect_to_custom(\n    http_host=\"localhost\",\n    http_port=8080,\n    http_secure=False,\n    grpc_host=\"localhost\",\n    grpc_port=50051,\n    grpc_secure=False,\n)\n\nclient.is_ready()\ntry:\n    questions = client.collections.create(\n            \"Question\",\n            vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n            sharding_config=wvc.config.Configure.sharding(\n                desired_count=2\n            ),\n            replication_config=wvc.config.Configure.replication(\n                factor=3\n        ),\n    )\nfinally:\n    client.close()\n\nbut there’s still only 2 shards on the single node by /nodes endpoint:\n{\n\t\"nodes\": [{\n\t\t\"batchStats\": {\n\t\t\t\"queueLength\": 0,\n\t\t\t\"ratePerSecond\": 0\n\t\t},\n\t\t\"gitHash\": \"a61909a\",\n\t\t\"name\": \"node1\",\n\t\t\"shards\": [{\n\t\t\t\"class\": \"Question\",\n\t\t\t\"compressed\": false,\n\t\t\t\"loaded\": true,\n\t\t\t\"name\": \"jOszJZZURggS\",\n\t\t\t\"objectCount\": 0,\n\t\t\t\"vectorIndexingStatus\": \"READY\",\n\t\t\t\"vectorQueueLength\": 0\n\t\t}, {\n\t\t\t\"class\": \"Question\",\n\t\t\t\"compressed\": false,\n\t\t\t\"loaded\": true,\n\t\t\t\"name\": \"NOfUltlxacum\",\n\t\t\t\"objectCount\": 0,\n\t\t\t\"vectorIndexingStatus\": \"READY\",\n\t\t\t\"vectorQueueLength\": 0\n\t\t}],\n\t\t\"stats\": {\n\t\t\t\"objectCount\": 0,\n\t\t\t\"shardCount\": 2\n\t\t},\n\t\t\"status\": \"HEALTHY\",\n\t\t\"version\": \"1.25.4\"\n\t}, {\n\t\t\"batchStats\": {\n\t\t\t\"queueLength\": 0,\n\t\t\t\"ratePerSecond\": 0\n\t\t},\n\t\t\"gitHash\": \"a61909a\",\n\t\t\"name\": \"node2\",\n\t\t\"shards\": null,\n\t\t\"stats\": {\n\t\t\t\"objectCount\": 0,\n\t\t\t\"shardCount\": 0\n\t\t},\n\t\t\"status\": \"HEALTHY\",\n\t\t\"version\": \"1.25.4\"\n\t}, {\n\t\t\"batchStats\": {\n\t\t\t\"queueLength\": 0,\n\t\t\t\"ratePerSecond\": 0\n\t\t},\n\t\t\"gitHash\": \"a61909a\",\n\t\t\"name\": \"node3\",\n\t\t\"shards\": null,\n\t\t\"stats\": {\n\t\t\t\"objectCount\": 0,\n\t\t\t\"shardCount\": 0\n\t\t},\n\t\t\"status\": \"HEALTHY\",\n\t\t\"version\": \"1.25.4\"\n\t}]\n}\n\n/cluster/statistics (synchronized is still false):\n{\n\t\"statistics\": [{\n\t\t\"bootstrapped\": true,\n\t\t\"candidates\": {},\n\t\t\"dbLoaded\": true,\n\t\t\"isVoter\": true,\n\t\t\"leaderAddress\": \"192.168.32.2:8300\",\n\t\t\"leaderId\": \"node1\",\n\t\t\"name\": \"node1\",\n\t\t\"open\": true,\n\t\t\"raft\": {\n\t\t\t\"appliedIndex\": \"3\",\n\t\t\t\"commitIndex\": \"3\",\n\t\t\t\"fsmPending\": \"0\",\n\t\t\t\"lastContact\": \"0\",\n\t\t\t\"lastLogIndex\": \"3\",\n\t\t\t\"lastLogTerm\": \"2\",\n\t\t\t\"lastSnapshotIndex\": \"0\",\n\t\t\t\"lastSnapshotTerm\": \"0\",\n\t\t\t\"latestConfiguration\": [{\n\t\t\t\t\"address\": \"192.168.32.2:8300\",\n\t\t\t\t\"id\": \"node1\",\n\t\t\t\t\"suffrage\": 0\n\t\t\t}],\n\t\t\t\"latestConfigurationIndex\": \"0\",\n\t\t\t\"numPeers\": \"0\",\n\t\t\t\"protocolVersion\": \"3\",\n\t\t\t\"protocolVersionMax\": \"3\",\n\t\t\t\"protocolVersionMin\": \"0\",\n\t\t\t\"snapshotVersionMax\": \"1\",\n\t\t\t\"snapshotVersionMin\": \"0\",\n\t\t\t\"state\": \"Leader\",\n\t\t\t\"term\": \"2\"\n\t\t},\n\t\t\"ready\": true,\n\t\t\"status\": \"HEALTHY\"\n\t}, {\n\t\t\"bootstrapped\": true,\n\t\t\"candidates\": {},\n\t\t\"dbLoaded\": true,\n\t\t\"isVoter\": true,\n\t\t\"leaderAddress\": \"192.168.32.4:8300\",\n\t\t\"leaderId\": \"node2\",\n\t\t\"name\": \"node2\",\n\t\t\"open\": true,\n\t\t\"raft\": {\n\t\t\t\"appliedIndex\": \"2\",\n\t\t\t\"commitIndex\": \"2\",\n\t\t\t\"fsmPending\": \"0\",\n\t\t\t\"lastContact\": \"0\",\n\t\t\t\"lastLogIndex\": \"2\",\n\t\t\t\"lastLogTerm\": \"2\",\n\t\t\t\"lastSnapshotIndex\": \"0\",\n\t\t\t\"lastSnapshotTerm\": \"0\",\n\t\t\t\"latestConfiguration\": [{\n\t\t\t\t\"address\": \"192.168.32.4:8300\",\n\t\t\t\t\"id\": \"node2\",\n\t\t\t\t\"suffrage\": 0\n\t\t\t}],\n\t\t\t\"latestConfigurationIndex\": \"0\",\n\t\t\t\"numPeers\": \"0\",\n\t\t\t\"protocolVersion\": \"3\",\n\t\t\t\"protocolVersionMax\": \"3\",\n\t\t\t\"protocolVersionMin\": \"0\",\n\t\t\t\"snapshotVersionMax\": \"1\",\n\t\t\t\"snapshotVersionMin\": \"0\",\n\t\t\t\"state\": \"Leader\",\n\t\t\t\"term\": \"2\"\n\t\t},\n\t\t\"ready\": true,\n\t\t\"status\": \"HEALTHY\"\n\t}, {\n\t\t\"bootstrapped\": true,\n\t\t\"candidates\": {},\n\t\t\"dbLoaded\": true,\n\t\t\"isVoter\": true,\n\t\t\"leaderAddress\": \"192.168.32.3:8300\",\n\t\t\"leaderId\": \"node3\",\n\t\t\"name\": \"node3\",\n\t\t\"open\": true,\n\t\t\"raft\": {\n\t\t\t\"appliedIndex\": \"2\",\n\t\t\t\"commitIndex\": \"2\",\n\t\t\t\"fsmPending\": \"0\",\n\t\t\t\"lastContact\": \"0\",\n\t\t\t\"lastLogIndex\": \"2\",\n\t\t\t\"lastLogTerm\": \"2\",\n\t\t\t\"lastSnapshotIndex\": \"0\",\n\t\t\t\"lastSnapshotTerm\": \"0\",\n\t\t\t\"latestConfiguration\": [{\n\t\t\t\t\"address\": \"192.168.32.3:8300\",\n\t\t\t\t\"id\": \"node3\",\n\t\t\t\t\"suffrage\": 0\n\t\t\t}],\n\t\t\t\"latestConfigurationIndex\": \"0\",\n\t\t\t\"numPeers\": \"0\",\n\t\t\t\"protocolVersion\": \"3\",\n\t\t\t\"protocolVersionMax\": \"3\",\n\t\t\t\"protocolVersionMin\": \"0\",\n\t\t\t\"snapshotVersionMax\": \"1\",\n\t\t\t\"snapshotVersionMin\": \"0\",\n\t\t\t\"state\": \"Leader\",\n\t\t\t\"term\": \"2\"\n\t\t},\n\t\t\"ready\": true,\n\t\t\"status\": \"HEALTHY\"\n\t}],\n\t\"synchronized\": false\n}\n\nIt’s strange…\n\n----------\n\n[Dominic_poi (2024-06-21T02:07:44.770Z)]: Then I add 2 env variable to each node…:\n      RAFT_JOIN: node1\n      RAFT_BOOTSTRAP_EXPECT: 1\n\nIt works!\n{\n\t\"statistics\": [{\n\t\t\t\"bootstrapped\": true,\n\t\t\t\"candidates\": {},\n\t\t\t\"dbLoaded\": true,\n\t\t\t\"isVoter\": true,\n\t\t\t\"leaderAddress\": \"192.168.48.4:8300\",\n\t\t\t\"leaderId\": \"node1\",\n\t\t\t\"name\": \"node1\",\n\t\t\t\"open\": true,\n\t\t\t\"raft\": {\n\t\t\t\t\"appliedIndex\": \"4\",\n\t\t\t\t\"commitIndex\": \"4\",\n\t\t\t\t\"fsmPending\": \"0\",\n\t\t\t\t\"lastContact\": \"0\",\n\t\t\t\t\"lastLogIndex\": \"4\",\n\t\t\t\t\"lastLogTerm\": \"2\",\n\t\t\t\t\"lastSnapshotIndex\": \"0\",\n\t\t\t\t\"lastSnapshotTerm\": \"0\",\n\t\t\t\t\"latestConfiguration\": [{\n\t\t\t\t\t\t\"address\": \"192.168.48.4:8300\",\n\t\t\t\t\t\t\"id\": \"node1\",\n\t\t\t\t\t\t\"suffrage\": 0\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"address\": \"192.168.48.2:8300\",\n\t\t\t\t\t\t\"id\": \"node3\",\n\t\t\t\t\t\t\"suffrage\": 1\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"address\": \"192.168.48.3:8300\",\n\t\t\t\t\t\t\"id\": \"node2\",\n\t\t\t\t\t\t\"suffrage\": 1\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"latestConfigurationIndex\": \"0\",\n\t\t\t\t\"numPeers\": \"0\",\n\t\t\t\t\"protocolVersion\": \"3\",\n\t\t\t\t\"protocolVersionMax\": \"3\",\n\t\t\t\t\"protocolVersionMin\": \"0\",\n\t\t\t\t\"snapshotVersionMax\": \"1\",\n\t\t\t\t\"snapshotVersionMin\": \"0\",\n\t\t\t\t\"state\": \"Leader\",\n\t\t\t\t\"term\": \"2\"\n\t\t\t},\n\t\t\t\"ready\": true,\n\t\t\t\"status\": \"HEALTHY\"\n\t\t},\n\t\t{\n\t\t\t\"candidates\": {},\n\t\t\t\"dbLoaded\": true,\n\t\t\t\"leaderAddress\": \"192.168.48.4:8300\",\n\t\t\t\"leaderId\": \"node1\",\n\t\t\t\"name\": \"node2\",\n\t\t\t\"open\": true,\n\t\t\t\"raft\": {\n\t\t\t\t\"appliedIndex\": \"4\",\n\t\t\t\t\"commitIndex\": \"4\",\n\t\t\t\t\"fsmPending\": \"0\",\n\t\t\t\t\"lastContact\": \"62.741042ms\",\n\t\t\t\t\"lastLogIndex\": \"4\",\n\t\t\t\t\"lastLogTerm\": \"2\",\n\t\t\t\t\"lastSnapshotIndex\": \"0\",\n\t\t\t\t\"lastSnapshotTerm\": \"0\",\n\t\t\t\t\"latestConfiguration\": [{\n\t\t\t\t\t\t\"address\": \"192.168.48.4:8300\",\n\t\t\t\t\t\t\"id\": \"node1\",\n\t\t\t\t\t\t\"suffrage\": 0\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"address\": \"192.168.48.2:8300\",\n\t\t\t\t\t\t\"id\": \"node3\",\n\t\t\t\t\t\t\"suffrage\": 1\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"address\": \"192.168.48.3:8300\",\n\t\t\t\t\t\t\"id\": \"node2\",\n\t\t\t\t\t\t\"suffrage\": 1\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"latestConfigurationIndex\": \"0\",\n\t\t\t\t\"numPeers\": \"0\",\n\t\t\t\t\"protocolVersion\": \"3\",\n\t\t\t\t\"protocolVersionMax\": \"3\",\n\t\t\t\t\"protocolVersionMin\": \"0\",\n\t\t\t\t\"snapshotVersionMax\": \"1\",\n\t\t\t\t\"snapshotVersionMin\": \"0\",\n\t\t\t\t\"state\": \"Follower\",\n\t\t\t\t\"term\": \"2\"\n\t\t\t},\n\t\t\t\"ready\": true,\n\t\t\t\"status\": \"HEALTHY\"\n\t\t},\n\t\t{\n\t\t\t\"candidates\": {},\n\t\t\t\"dbLoaded\": true,\n\t\t\t\"leaderAddress\": \"192.168.48.4:8300\",\n\t\t\t\"leaderId\": \"node1\",\n\t\t\t\"name\": \"node3\",\n\t\t\t\"open\": true,\n\t\t\t\"raft\": {\n\t\t\t\t\"appliedIndex\": \"4\",\n\t\t\t\t\"commitIndex\": \"4\",\n\t\t\t\t\"fsmPending\": \"0\",\n\t\t\t\t\"lastContact\": \"44.880084ms\",\n\t\t\t\t\"lastLogIndex\": \"4\",\n\t\t\t\t\"lastLogTerm\": \"2\",\n\t\t\t\t\"lastSnapshotIndex\": \"0\",\n\t\t\t\t\"lastSnapshotTerm\": \"0\",\n\t\t\t\t\"latestConfiguration\": [{\n\t\t\t\t\t\t\"address\": \"192.168.48.4:8300\",\n\t\t\t\t\t\t\"id\": \"node1\",\n\t\t\t\t\t\t\"suffrage\": 0\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"address\": \"192.168.48.2:8300\",\n\t\t\t\t\t\t\"id\": \"node3\",\n\t\t\t\t\t\t\"suffrage\": 1\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"address\": \"192.168.48.3:8300\",\n\t\t\t\t\t\t\"id\": \"node2\",\n\t\t\t\t\t\t\"suffrage\": 1\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"latestConfigurationIndex\": \"0\",\n\t\t\t\t\"numPeers\": \"0\",\n\t\t\t\t\"protocolVersion\": \"3\",\n\t\t\t\t\"protocolVersionMax\": \"3\",\n\t\t\t\t\"protocolVersionMin\": \"0\",\n\t\t\t\t\"snapshotVersionMax\": \"1\",\n\t\t\t\t\"snapshotVersionMin\": \"0\",\n\t\t\t\t\"state\": \"Follower\",\n\t\t\t\t\"term\": \"2\"\n\t\t\t},\n\t\t\t\"ready\": true,\n\t\t\t\"status\": \"HEALTHY\"\n\t\t}\n\t],\n\t\"synchronized\": true\n}\n\n{\n\t\"nodes\": [{\n\t\t\t\"batchStats\": {\n\t\t\t\t\"queueLength\": 0,\n\t\t\t\t\"ratePerSecond\": 0\n\t\t\t},\n\t\t\t\"gitHash\": \"a61909a\",\n\t\t\t\"name\": \"node1\",\n\t\t\t\"shards\": [{\n\t\t\t\t\t\"class\": \"Question\",\n\t\t\t\t\t\"compressed\": false,\n\t\t\t\t\t\"loaded\": true,\n\t\t\t\t\t\"name\": \"YE9uSk0mbYUT\",\n\t\t\t\t\t\"objectCount\": 0,\n\t\t\t\t\t\"vectorIndexingStatus\": \"READY\",\n\t\t\t\t\t\"vectorQueueLength\": 0\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"class\": \"Question\",\n\t\t\t\t\t\"compressed\": false,\n\t\t\t\t\t\"loaded\": true,\n\t\t\t\t\t\"name\": \"ji9QxFNEnzph\",\n\t\t\t\t\t\"objectCount\": 0,\n\t\t\t\t\t\"vectorIndexingStatus\": \"READY\",\n\t\t\t\t\t\"vectorQueueLength\": 0\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"stats\": {\n\t\t\t\t\"objectCount\": 0,\n\t\t\t\t\"shardCount\": 2\n\t\t\t},\n\t\t\t\"status\": \"HEALTHY\",\n\t\t\t\"version\": \"1.25.4\"\n\t\t},\n\t\t{\n\t\t\t\"batchStats\": {\n\t\t\t\t\"queueLength\": 0,\n\t\t\t\t\"ratePerSecond\": 0\n\t\t\t},\n\t\t\t\"gitHash\": \"a61909a\",\n\t\t\t\"name\": \"node2\",\n\t\t\t\"shards\": [{\n\t\t\t\t\t\"class\": \"Question\",\n\t\t\t\t\t\"compressed\": false,\n\t\t\t\t\t\"loaded\": true,\n\t\t\t\t\t\"name\": \"YE9uSk0mbYUT\",\n\t\t\t\t\t\"objectCount\": 0,\n\t\t\t\t\t\"vectorIndexingStatus\": \"READY\",\n\t\t\t\t\t\"vectorQueueLength\": 0\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"class\": \"Question\",\n\t\t\t\t\t\"compressed\": false,\n\t\t\t\t\t\"loaded\": true,\n\t\t\t\t\t\"name\": \"ji9QxFNEnzph\",\n\t\t\t\t\t\"objectCount\": 0,\n\t\t\t\t\t\"vectorIndexingStatus\": \"READY\",\n\t\t\t\t\t\"vectorQueueLength\": 0\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"stats\": {\n\t\t\t\t\"objectCount\": 0,\n\t\t\t\t\"shardCount\": 2\n\t\t\t},\n\t\t\t\"status\": \"HEALTHY\",\n\t\t\t\"version\": \"1.25.4\"\n\t\t},\n\t\t{\n\t\t\t\"batchStats\": {\n\t\t\t\t\"queueLength\": 0,\n\t\t\t\t\"ratePerSecond\": 0\n\t\t\t},\n\t\t\t\"gitHash\": \"a61909a\",\n\t\t\t\"name\": \"node3\",\n\t\t\t\"shards\": [{\n\t\t\t\t\t\"class\": \"Question\",\n\t\t\t\t\t\"compressed\": false,\n\t\t\t\t\t\"loaded\": true,\n\t\t\t\t\t\"name\": \"ji9QxFNEnzph\",\n\t\t\t\t\t\"objectCount\": 0,\n\t\t\t\t\t\"vectorIndexingStatus\": \"READY\",\n\t\t\t\t\t\"vectorQueueLength\": 0\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"class\": \"Question\",\n\t\t\t\t\t\"compressed\": false,\n\t\t\t\t\t\"loaded\": true,\n\t\t\t\t\t\"name\": \"YE9uSk0mbYUT\",\n\t\t\t\t\t\"objectCount\": 0,\n\t\t\t\t\t\"vectorIndexingStatus\": \"READY\",\n\t\t\t\t\t\"vectorQueueLength\": 0\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"stats\": {\n\t\t\t\t\"objectCount\": 0,\n\t\t\t\t\"shardCount\": 2\n\t\t\t},\n\t\t\t\"status\": \"HEALTHY\",\n\t\t\t\"version\": \"1.25.4\"\n\t\t}\n\t]\n}\n\nBut is it necessary? What will happen if the only specific voter - node1 is down?  Is there a negative impact on the HA of the cluster?\n\n----------\n\n[DudaNogueira (2024-06-21T14:32:58.384Z)]: Great!\nYou can add all nodes to RAFT_JOIN (even with only 2 nodes):\nRAFT_JOIN: 'node1,node2,node3'\n\ncheck here for how this part is configured from our helm:\n\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate-helm/blob/fd59b85ac441e228021e0b7b6342cd94e2a577b7/weaviate/templates/_helpers.tpl#L194\n\n\n\n    \n      \n              {{- $priorityClassName = .priorityClassName -}}\n            {{- end -}}\n          \n            {{- if (not (empty $priorityClassName)) -}}\n              {{- printf \"priorityClassName: %s\" $priorityClassName -}}\n            {{- end -}}\n          {{- end -}}\n          \n          \n          {{/*\n          Raft cluster configuration settings\n          */}}\n          {{- define \"raft_configuration\" -}}\n            {{- $replicas := .Values.replicas | int -}}\n            {{- $voters := .Values.env.RAFT_BOOTSTRAP_EXPECT | int -}}\n            {{- $metada_only_voters := false -}}\n            {{- if not (empty .Values.env.RAFT_METADATA_ONLY_VOTERS) -}}\n              {{- $metada_only_voters = .Values.env.RAFT_METADATA_ONLY_VOTERS -}}\n            {{- end -}} \n            {{- if empty .Values.env.RAFT_BOOTSTRAP_EXPECT -}}\n              {{- if ge $replicas 10 -}}\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\n\n----------\n\n[FalconDinesh (2024-12-03T06:55:15.763Z)]: Thanks for the detailed explanation. Helped a lot. Nandrigal pala",
    "date_created": "2024-06-19T07:45:05.510Z",
    "has_accepted_answer": true,
    "title": "Multi nodes running unnormally",
    "topic_id": 2747
  },
  {
    "user_id": 869,
    "conversation": "[peguerosdc (2024-08-28T00:58:29.079Z)]: I have a FastAPI running a weaviate client (weaviate-client==4.7.0). The setup is done like this:\nfrom contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom api.weaviate_client import weaviate_client\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    await weaviate_client.connect()\n    yield\n    await weaviate_client.close()\n\n\napp = FastAPI(lifespan=lifespan)\n\nWhere weaviate_client is instantiated depending on the environment:\ndef get_weaviate_client():\n    print(\"getting client\")\n    if os.environ.get(\"TEST\"):\n        return weaviate.use_async_with_embedded(\n            version=\"1.26.1\",\n            headers={\"X-OpenAI-Api-Key\": envvars.OPENAI_API_KEY},\n        )\n    else:\n        return weaviate.use_async_with_weaviate_cloud(\n            cluster_url=envvars.WEAVIATE_HOST,\n            auth_credentials=AuthApiKey(envvars.WEAVIATE_API_KEY),\n            headers={\"X-OpenAI-Api-Key\": envvars.OPENAI_API_KEY},\n        )\n\n\nweaviate_client = get_weaviate_client()\n\nAnd I run my FastAPI server using hypercorn like this: hypercorn api.main:app --reload.\nThe problem is that the my app works correctly when the client comes from use_async_with_weaviate_cloud, but it fails to bootstrap when using use_async_with_embedded complaining that the ports are already in use:\nweaviate.exceptions.WeaviateStartUpError: Embedded DB did not start because processes are already listening on ports http:8079 and grpc:50050use weaviate.connect_to_local(port=8079, grpc_port=50050) to connect to the existing instance\n\nMy suspicion is that get_weaviate_client is getting called twice (I noticed because the print is logged twice, but I don’t know why. Maybe related to hypercorn?) so the embedded server is tried to be created twice and the second one is failing.\nMy whole goal is to mock my weaviate cloud cluster when testing my FastAPI app and I was sort of following this guide, but now I’m not sure how to proceed given that I might not be able to mock it.\nIs there any recommended approach?\nThe full logs are here:\n\n\nSummary\nUsing embedded weaviate client. Only for testing!\n{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":50766},\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"address\":\"192.168.0.39:50767\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"address\":\"192.168.0.39:50766\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"action\":\"raft\",\"index\":1,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8087 Address:192.168.0.39:52912}]]\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"last_snapshot_index\":0,\"last_store_applied_index\":0,\"last_store_log_applied_index\":0,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":4,\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-08-27T18:38:17-06:00\"}\n{\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, not part of a stable configuration or a non-voter, not triggering a leader election\",\"time\":\"2024-08-27T18:38:19-06:00\"}\n{\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-08-27T18:38:19-06:00\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-08-27T18:38:19-06:00\"}\n{\"action\":\"restapi_management\",\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-08-27T18:38:19-06:00\"}\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [192.168.0.39:50766]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"192.168.0.39:50766\"],\"time\":\"2024-08-27T18:38:19-06:00\",\"voter\":true}\n{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"Embedded_at_8079\",\"Address\":\"192.168.0.39:50766\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-08-27T18:38:19-06:00\"}\n{\"action\":\"bootstrap\",\"error\":\"bootstrap only works on new clusters\",\"level\":\"error\",\"msg\":\"could not bootstrapping cluster\",\"time\":\"2024-08-27T18:38:19-06:00\"}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"192.168.0.39:50766\"],\"time\":\"2024-08-27T18:38:19-06:00\"}\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:HIDDEN Type:INIT Version:1.26.1 NumObjects:0 OS:darwin Arch:amd64 UsedModules:[]}\",\"time\":\"2024-08-27T18:38:19-06:00\"}\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [192.168.0.39:50766]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"192.168.0.39:50766\"],\"time\":\"2024-08-27T18:38:21-06:00\",\"voter\":true}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"192.168.0.39:50766\"],\"time\":\"2024-08-27T18:38:21-06:00\"}\nUsing embedded weaviate client. Only for testing!\nProcess SpawnProcess-1:\nTraceback (most recent call last):\n  File \"/Users/user/miniforge3/envs/projectpy/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/Users/user/miniforge3/envs/projectpy/lib/python3.11/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/Users/user/miniforge3/envs/projectpy/lib/python3.11/site-packages/hypercorn/asyncio/run.py\", line 179, in asyncio_worker\n    app = load_application(config.application_path, config.wsgi_max_body_size)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/miniforge3/envs/projectpy/lib/python3.11/site-packages/hypercorn/utils.py\", line 115, in load_application\n    module = import_module(import_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/miniforge3/envs/projectpy/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/Users/user/dev/project-api-py/api/main.py\", line 4, in <module>\n    from api.weaviate_client import weaviate_client\n  File \"/Users/user/dev/project-api-py/api/weaviate_client.py\", line 22, in <module>\n    weaviate_client = get_weaviate_client()\n                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/dev/project-api-py/api/weaviate_client.py\", line 10, in get_weaviate_client\n    return weaviate.use_async_with_embedded(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/miniforge3/envs/projectpy/lib/python3.11/site-packages/weaviate/connect/helpers.py\", line 637, in use_async_with_embedded\n    client = WeaviateAsyncClient(\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/miniforge3/envs/projectpy/lib/python3.11/site-packages/weaviate/client.py\", line 150, in __init__\n    super().__init__(\n  File \"/Users/user/miniforge3/envs/projectpy/lib/python3.11/site-packages/weaviate/client_base.py\", line 68, in __init__\n    connection_params, embedded_db = self.__parse_connection_params_and_embedded_db(\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/miniforge3/envs/projectpy/lib/python3.11/site-packages/weaviate/client_base.py\", line 107, in __parse_connection_params_and_embedded_db\n    embedded_db.start()\n  File \"/Users/user/miniforge3/envs/projectpy/lib/python3.11/site-packages/weaviate/embedded.py\", line 305, in start\n    raise WeaviateStartUpError(\nweaviate.exceptions.WeaviateStartUpError: Embedded DB did not start because processes are already listening on ports http:8079 and grpc:50050use weaviate.connect_to_local(port=8079, grpc_port=50050) to connect to the existing instance\n\n----------\n\n[peguerosdc (2024-08-28T02:32:04.842Z)]: I was able to solve it.\nIn case someone finds it useful, my “solution” was to create the embedded db in a pytest fixture along with the app like this:\n@pytest_asyncio.fixture(scope=\"session\")\nasync def app_instance():\n    print(\"Creating weaviate embedded instance to connect to\")\n    weaviate.use_async_with_embedded(\n        version=\"1.26.1\",\n        headers={\"X-OpenAI-Api-Key\": envvars.OPENAI_API_KEY},\n        port=8079,\n        grpc_port=50050,\n    )\n    print(\"Creating app instance\")\n    async with LifespanManager(app) as manager:\n        print(\"We're in!\")\n        yield manager.app\n\n\n@pytest_asyncio.fixture(scope=\"session\")\nasync def client(app_instance):\n    async with AsyncClient(app=app_instance, base_url=\"http://app.io\") as client:\n        print(\"Client is ready\")\n        yield client\n\nAnd replace my weaviate_instance client with just a connection to it like this:\ndef get_weaviate_client():\n        return weaviate.use_async_with_local(port=8079, grpc_port=50050)\n\nNote that my rationale of using scope=\"session\" was that I only want an app and embedded db per pytest run, but then I’m forced to run all my tests within that same event loop to avoid errors like tasks attached to a different loop:\n@pytest.mark.asyncio(loop_scope=\"session\")\nasync def test_search_endpoint(client):\n    pass\n\nNot sure if this is the optimal, though, and also note that this applies not only to embedded instances",
    "date_created": "2024-08-28T00:58:29.024Z",
    "has_accepted_answer": true,
    "title": "How to run embedded weaviate with fastapi+hypercorn?",
    "topic_id": 3756
  },
  {
    "user_id": 1555,
    "conversation": "[Rishi_Prakash (2024-10-22T19:21:31.060Z)]: I have to check in my code if a collection have some data. I have created a function where it loads all the data from collection, but this will take time everytime, is there any other way to do it quickly without loading all the data from collection.\nBelow is my sample function to load all data, Thanks!\ndef load_all_data_from_class_with_embeddings(class_name):\nGet the collection\ncollection = client.collections.get(class_name)\n# Fetch all objects using iterator\nall_results = []\nfor item in collection.iterator():\n    result = {'skill_name': item.properties.get('skill_name')}\n    all_results.append(result)\n# Convert the list of results into a DataFrame\ndf = pd.DataFrame(all_results)\nreturn df (edited)\n\n----------\n\n[Dirk (2024-10-23T04:07:41.252Z)]: Hi,\nyou can just do\ncollection = client.collections.get(class_name)\nnr_objects = len(collection)\n\nthen you know how many objects there are in the collection",
    "date_created": "2024-10-22T19:21:31.007Z",
    "has_accepted_answer": true,
    "title": "Check if data exist in collection",
    "topic_id": 5846
  },
  {
    "user_id": 1655,
    "conversation": "[Rajesh (2024-10-09T19:55:11.850Z)]: Can the Free Serverless Sandbox plan be upgraded to Paid Persistent Version? That is, if I want to keep my Cluster in the Free Plan, then can I upgrade to the Paid Serverless Plan with $25 per month?\nWould I be told in advance how much my Cluster will cost per month?\nAlso, can I specify the Billing Limits for my Paid Account? That is, how much maximum my credit card can be charged? We don’t want to be surprised by an astronomical bill at the end of the month.\nThanks.\n\n----------\n\n[DudaNogueira (2024-10-10T07:03:39.361Z)]: hi @Rajesh !!\nWelcome to our community \nThe feature of converting a free sandbox to a paid account is in our roadmap for Q4/2024.\nRight now we suggest migrating your data over the new cluster using this migration guide:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThere is a price calculator here, click on view price:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPricing | Weaviate\n\n  Pricing models\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThere you can fill in the number of objects and dimensions, tier plan and get the running cost for a cluster.\nWe do not have a billing limit for a serverless cluster.\nHowever, if this is a concern or a blocker, we do provide Enterprise plans that can get you a fixed resource allocation that can help you control this cost closer.\nFor that I suggest your contacting our sales team.\nLet me know if this helps or if I can assist you further.\nThanks!\n\n----------\n\n[Rajesh (2024-10-11T17:02:01.777Z)]: Thank you very much for your reply. I have a follow-up question.\nDoes Weaviate send warning messages that Customer’s Free Sandbox Cluster is about to be deleted and that within a stipulated period they should transition their Data to the Paid Cluster.\nPlease let me know if the Weaviate sends such a warning in advance.\nThanks again,\nRajesh\n\n----------\n\n[DudaNogueira (2024-10-11T20:37:16.494Z)]: hi @Rajesh !!\nIt will send you a warning email that the sandbox is about to expire, and you can even extend the trial a couple times",
    "date_created": "2024-10-09T19:55:11.799Z",
    "has_accepted_answer": false,
    "title": "Free Serverless Sandbox Plan to Paid Persistent Version",
    "topic_id": 4495
  },
  {
    "user_id": 2501,
    "conversation": "[lisascat (2024-11-13T00:03:38.888Z)]: Weaviate Server Version: 1.27.0\nDeployment Method: docker\nMulti Node? Number of Running Nodes: single node\nClient Language and Version: Client:  4.9.3, python\nMultitenancy?: no\n\nI’m encountering an issue with filtering results in Weaviate using the near_text query.\nFirst of all:\n\nclient.collections.create(\n    name=\"RAG\",\n    properties=[\n        wc.Property(name=\"transcription\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"data\", data_type=wc.DataType.DATE, inverted_index_config={\"IndexTimestamps\": True}),\n        wc.Property(name=\"hora_inicio_video\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"hora_fim_video\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"chave_unica\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"highlights_assunto\", data_type=wc.DataType.TEXT_ARRAY),\n        wc.Property(name=\"highlight_start\", data_type=wc.DataType.NUMBER),\n        wc.Property(name=\"highlight_end\", data_type=wc.DataType.NUMBER),\n        wc.Property(name=\"action_log\", data_type=wc.DataType.TEXT_ARRAY),\n        wc.Property(name=\"action_log_start\", data_type=wc.DataType.NUMBER),\n        wc.Property(name=\"action_log_end\", data_type=wc.DataType.NUMBER),\n        wc.Property(name=\"location\", data_type=wc.DataType.TEXT_ARRAY),\n        wc.Property(name=\"offset_start\", data_type=wc.DataType.NUMBER),\n        wc.Property(name=\"offset_end\", data_type=wc.DataType.NUMBER)\n    ],\n    vectorizer_config=wc.Configure.Vectorizer.text2vec_huggingface(model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"),\n    generative_config=wc.Configure.Generative.google(\n                                                     project_id=project,\n                                                     model_id=\"gemini-1.5-pro-preview-0514\", \n                                                     temperature=0.3,\n                                                    )\n)\n\nHere is my initial query that works fine:\nresponse_time_near_text = rag.query.near_text(\n    query=\"limpar a piscina\",\n    limit=1,\n    return_metadata=wq.MetadataQuery(distance=True),\n)\n\nThis query returns data and metadata successfully. However, when I take one of the metadata values returned (in this case, chave_unica, but it’s the same for other metadata) and use it as an exact match filter, the query returns no results:\nresponse_time_near_text = rag.query.near_text(\n    query=\"limpar a piscina\",\n    limit=1,\n    return_metadata=wq.MetadataQuery(distance=True),\n    filters=wq.Filter.by_property(\"chave_unica\").equal(\"060a2b340101010101010f0013-000000-00000141d33e6dbe-060e2b347f7f-2a80\")\n)\n\nQueryReturn(objects=[])\n\nThe filter value \"060a2b340101010101010f0013-000000-00000141d33e6dbe-060e2b347f7f-2a80\" is copied exactly from the metadata returned in the first query, but with this filter applied, the query returns no results.\nAdditionally, if I use:\nresponse_time_near_text = rag.query.near_text(\n    query=\"limpar a piscina\",\n    limit=1,\n    return_metadata=wq.MetadataQuery(distance=True),\n    filters=wq.Filter.by_property(\"chave_unica\").not_equal(\"60a2b340101010101010f0013-000000-00000141d33e6dbe-060e2b347f7f-2a80\")\n)\n\nIn other words, when I perform the query with not_equal and provide an incorrect value, the query returns data correctly.\nAny advice on why this happens or how to fix it would be greatly appreciated. Thank you!\nI’ve performed some additional testing.\nIf I populate my collection with the following code (using langchain):\ndef carregar_documentos(pasta):\n    documentos = []\n    arquivos = os.listdir(pasta)\n    for arquivo in arquivos:\n        caminho_completo = os.path.join(pasta, arquivo)\n        if os.path.isfile(caminho_completo):\n            with open(caminho_completo, 'r') as f:\n                dados = json.load(f)\n                documentos.extend([\n                    Document(page_content=chunk['transcription'], metadata=chunk['metadata'])\n                    for chunk in dados\n                ])\n    return documentos\n\ndocuments = carregar_documentos('data/data_constructed')\n\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n\ndb = WeaviateVectorStore.from_documents(documents, embedding=embeddings, client=client, index_name=\"RAG\")\n\nThe search works fine. The issue is that I want to avoid having to define the embeddings like embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\nSo I tried this other way (batch.dynamic()):\ndef carregar_documentos(pasta):\n    documentos = []\n    arquivos = os.listdir(pasta)\n    for arquivo in arquivos:\n        caminho_completo = os.path.join(pasta, arquivo)\n        if os.path.isfile(caminho_completo):\n            with open(caminho_completo, \"r\") as f:\n                dados = json.load(f)\n                documentos.extend(\n                    [\n                        {\n                            \"page_content\": chunk[\"transcription\"],\n                            \"metadata\": chunk[\"metadata\"],\n                        }\n                        for chunk in dados\n                    ]\n                )\n    return documentos\n\ndata_rows = carregar_documentos('data/data_constructed')\n\nrag = client.collections.get(\"RAG\")\n\nwith rag.batch.dynamic() as batch:\n    for data_row in data_rows:\n        try:\n            batch.add_object(properties=data_row)\n            print(f\"Adicionado: {data_row}\")\n        except Exception as e:\n            print(f\"Erro ao adicionar {data_row}: {e}\")\n\n\nfor both cases, if I do the test:\nresponse = rag.aggregate.over_all(total_count=True)\neverything is fine.\n\n----------\n\n[DudaNogueira (2024-11-13T14:09:21.459Z)]: hi @lisascat !!\nWelcome to our community \nI was not able to reproduce this.\nHere is some code so we can share:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n    properties=[\n        wvc.config.Property(name=\"text\", data_type=wvc.config.DataType.TEXT),\n        wvc.config.Property(name=\"chave_unica\", data_type=wvc.config.DataType.TEXT),\n    ]\n)\ncollection.data.insert_many(\n    objects=[\n        {\n            \"chave_unica\": \"060a2b340101010101010f0013-000000-00000141d33e6dbe-060e2b347f7f-2a80\",\n            \"text\": \"Clean swimming pool\"\n        },\n        {\n            \"chave_unica\": \"111a2b340101010101010f0013-000000-00000141d33e6dbe-060e2b347f7f-2a80\",\n            \"text\": \"Clean garage\"\n        },        \n        \n    ]\n)\nquery = collection.query.near_text(\n    query=\"limpar a piscina\",\n    limit=1,\n    return_metadata=wvc.query.MetadataQuery(distance=True),\n    filters=wvc.query.Filter.by_property(\"chave_unica\").equal(\"060a2b340101010101010f0013-000000-00000141d33e6dbe-060e2b347f7f-2a80\")\n)\nprint(query.objects)\n\n----------\n\n[DudaNogueira (2024-11-13T14:10:18.982Z)]: note that if you have an ID for you objects, you can use it, like explained here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCreate objects | Weaviate\n\n  The examples on this page demonstrate how to create individual objects in Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThat way, when performing batch operations, you can insert/update your objects\n\n----------\n\n[lisascat (2024-11-13T19:35:36.994Z)]: Hello @DudaNogueira\nthank you for your response!\nThe insertion worked, and the search is also functioning correctly. What I don’t understand is why, when using:\nbatch_size = 100  # Batch size\nfor i in range(0, len(data_rows), batch_size):\n    batch_data = data_rows[i : i + batch_size]\n    try:\n        rag.data.insert_many(objects=batch_data)\n        print(f\"Batch {i // batch_size + 1} successfully inserted!\")\n    except Exception as e:\n        print(f\"Error inserting batch {i // batch_size + 1}: {e}\")\n\nthe chunks returned by the search with query.near_text are different from those generated when using:\ndb = WeaviateVectorStore.from_documents(documents, embedding=embeddings, client=client, index_name=\"RAG\")\n\nIt seems that the embedding model is not being loaded correctly. The “distance” values are also inconsistent.\n\n----------\n\n[DudaNogueira (2024-11-13T20:02:42.918Z)]: Oh, I see.\nWhen you use WeaviateVectorStore.from_documents the framework (not sure what are you using, llamaindex or langchain) will embed it for you following it’s own login. This means it will concatenate each doc, vectorize it, and then bring the vectors to Weaviate.\nWhen you let Weaviate vectorize it for you, you control which fields you want to be part of the vector.\nWith that said, and considering the collection schema you pasted, there is probably more properties being used as part of your vector.\nSo I believe that the two different ways of ingesting data will output different vectors, hence the difference.\n\n----------\n\n[lisascat (2024-11-13T23:43:06.506Z)]: Hi @DudaNogueira!\nThanks again for your previous help. The solution you suggested worked perfectly, and I was able to resolve the initial issue. However, I encountered other challenges as I adapted the code to my specific needs.\nIdeally, I want the semantic search to happen only on one specific field: transcription. I managed to make this work using Named Vectors:\n\nclient.collections.create(\n    name=\"RAG\",\n    properties=[\n        wc.Property(name=\"transcription\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"data\", data_type=wc.DataType.DATE),\n        wc.Property(name=\"hora_inicio_video\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"hora_fim_video\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"chave_unica\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"highlights_assunto\", data_type=wc.DataType.TEXT_ARRAY),\n        wc.Property(name=\"highlight_start\", data_type=wc.DataType.NUMBER),\n        wc.Property(name=\"highlight_end\", data_type=wc.DataType.NUMBER),\n        wc.Property(name=\"action_log\", data_type=wc.DataType.TEXT_ARRAY),\n        wc.Property(name=\"action_log_start\", data_type=wc.DataType.NUMBER),\n        wc.Property(name=\"action_log_end\", data_type=wc.DataType.NUMBER),\n        wc.Property(name=\"location\", data_type=wc.DataType.TEXT_ARRAY),\n        wc.Property(name=\"offset_start\", data_type=wc.DataType.NUMBER),\n        wc.Property(name=\"offset_end\", data_type=wc.DataType.NUMBER)    \n    ],\n    # Define the vectorizer module\n    vectorizer_config=[\n        wc.Configure.NamedVectors.text2vec_huggingface(\n            name=\"transcription_vector\",\n            source_properties=[\"transcription\"],\n            model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n        )\n    ],\n    # Define the generative module\n    generative_config=wc.Configure.Generative.google(\n        project_id=project_id,\n        model_id=\"gemini-1.5-pro-preview-0514\", \n        temperature=0.3,\n    )\n)\n\n\nThe following query works as expected:\nresponse = rag.query.near_text( \n    query=\"o que aconteceu na piscina\",\n    target_vector=\"transcription_vector\",\n    limit=5,\n    return_metadata=wq.MetadataQuery(distance=True),\n)\n\nHowever, when I try to use a filter along with the semantic search, like this:\nresponse_unique_key = rag.query.near_text(\n    query=\"limpar a piscina\",\n    target_vector=\"transcription_vector\",\n    limit=1,\n    return_metadata=wq.MetadataQuery(distance=True),\n    filters=wq.Filter.by_property(\"chave_unica\").equal(\"060a2b340101010101010f0013-000000-00000141d33e6dbe-060e2b347f7f-2a80\")\n)\n\n\nIt does not work. My understanding is that this might happen because I vectorized only the transcription field. To address this, I tried adding another Named Vector for the chave_unica field:\nwc.Configure.NamedVectors.text2vec_huggingface(\n    name=\"chave_unica_vector\",\n    source_properties=[\"chave_unica\"],\n    model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n)\n\n\nAnd then queried like this:\nresponse_unique_key = rag.query.near_text(\n    query=\"limpar a piscina\",\n    target_vector=\"chave_unica_vector\",\n    limit=1,\n    return_metadata=wq.MetadataQuery(distance=True),\n    filters=wq.Filter.by_property(\"chave_unica\").equal(\"060a2b340101010101010f0013-000000-00000141d33e6dbe-060e2b347f7f-2a80\")\n)\n\nBut this still does not work…\nWhat I Need\nI need the semantic search to occur only in the transcription field, but I also need to be able to apply filters on other fields during the semantic search.\nIs there a recommended way to achieve this? tks for all the support!!!\n\n----------\n\n[DudaNogueira (2024-11-14T13:13:15.340Z)]: Hi!\nGreat! Glad to hear we are making progress \nNow, you need to understand that in your scenario, Weaviate will have two indices:\n1 - A Named Vector called transcription_vector\n2 - An inverted index with all the tokenized content that is searchable and filterable.\nSo no need to add a second NamedVector only for chave_unica, the filtering happens on the inverted index, and not on the vector index.\nYou near_text with that filter should work. One thing you can try, but it shouldn’t make a difference, is to set the tokenization to field for the chave_unica property, like so\n...\nwc.Property(name=\"chave_unica\", data_type=wc.DataType.TEXT, tokenization=wc.Tokenization.FIELD),\n...\n\nthis will ensure that all content that you set for chave_unica will be considered as a token.\nBut I am finding it strange that it should work already.\nLet me know if you can share the dataset so I can try reproducing it in my end.\nTHanks!\n\n----------\n\n[DudaNogueira (2024-11-14T13:16:00.685Z)]: If you want to learn more on tokenization:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nOverview of tokenization | Weaviate\n\n  Tokenization is the process of breaking text into smaller units, called tokens. This is an important step that impacts how text is processed in a variety of contexts.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nso for example, if you let the default, word, and create a url property, this is what happens when you have a google.com value for your property\nWITH WORD TOKENIZATION\ngoogle.com becomes 2 tokens: google and com\nnow when you search for property url equal to google.com you will NOT find that object.\nWITH FIELD TOKENIZATION\ngoogle.com becomes 1 token google.com\nnow, when you search for property url equal to google.com, you will find that object\n\n----------\n\n[lisascat (2024-11-14T23:53:59.695Z)]: Hello @DudaNogueira, thank you again for your response!\nEverything worked out; there was a typo in my code that was super hidden and was causing the error…\n\n----------\n\n[DudaNogueira (2024-11-18T13:00:07.123Z)]: Oh!! that happens, hahaha\nAnd when that happens, it can drive us nutts! \nThanks for sharing, whenever you need help with your Weaviate journey, we are here to help!\nHappy building!",
    "date_created": "2024-11-13T00:03:38.835Z",
    "has_accepted_answer": true,
    "title": "Problem with near_text Query and Metadata Filtering in Weaviate",
    "topic_id": 7559
  },
  {
    "user_id": 19,
    "conversation": "[vamsi (2023-08-26T16:59:30.835Z)]: Hi all,\nI am seeing a continuous stream of compaction errors in the log stream. Is this normal? Does it have any affect on the performance?\nERRO[0679] compaction failed                             action=lsm_compaction class=Document error=\"replace compacted segments: precompute segment meta: init bloom filter for secondary index at 0: a secondary bloom filter already exists with path /root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects/segment-1689676389149982374.secondary.0.bloom.tmp\" index=document path=/root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects shard=kxlWAyuQqVRN\nERRO[0685] compaction failed                             action=lsm_compaction class=Document error=\"replace compacted segments: precompute segment meta: init bloom filter for secondary index at 0: a secondary bloom filter already exists with path /root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects/segment-1689676389149982374.secondary.0.bloom.tmp\" index=document path=/root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects shard=kxlWAyuQqVRN\nERRO[0689] compaction failed                             action=lsm_compaction class=Document error=\"replace compacted segments: precompute segment meta: init bloom filter for secondary index at 0: a secondary bloom filter already exists with path /root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects/segment-1689676389149982374.secondary.0.bloom.tmp\" index=document path=/root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects shard=kxlWAyuQqVRN\nERRO[0694] compaction failed                             action=lsm_compaction class=Document error=\"replace compacted segments: precompute segment meta: init bloom filter for secondary index at 0: a secondary bloom filter already exists with path /root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects/segment-1689676389149982374.secondary.0.bloom.tmp\" index=document path=/root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects shard=kxlWAyuQqVRN\nERRO[0699] compaction failed                             action=lsm_compaction class=Document error=\"replace compacted segments: precompute segment meta: init bloom filter for secondary index at 0: a secondary bloom filter already exists with path /root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects/segment-1689676389149982374.secondary.0.bloom.tmp\" index=document path=/root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects shard=kxlWAyuQqVRN\nERRO[0703] compaction failed                             action=lsm_compaction class=Document error=\"replace compacted segments: precompute segment meta: init bloom filter for secondary index at 0: a secondary bloom filter already exists with path /root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects/segment-1689676389149982374.secondary.0.bloom.tmp\" index=document path=/root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects shard=kxlWAyuQqVRN\nERRO[0708] compaction failed                             action=lsm_compaction class=Document error=\"replace compacted segments: precompute segment meta: init bloom filter for secondary index at 0: a secondary bloom filter already exists with path /root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects/segment-1689676389149982374.secondary.0.bloom.tmp\" index=document path=/root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects shard=kxlWAyuQqVRN\nERRO[0712] compaction failed                             action=lsm_compaction class=Document error=\"replace compacted segments: precompute segment meta: init bloom filter for secondary index at 0: a secondary bloom filter already exists with path /root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects/segment-1689676389149982374.secondary.0.bloom.tmp\" index=document path=/root/vectorstore_weaviate/weaviate_data/data/weaviate/document_kxlWAyuQqVRN_lsm/objects shard=kxlWAyuQqVRN\n\n----------\n\n[DudaNogueira (2023-08-28T22:25:00.923Z)]: Hi! I have asked about this with our team.\nIs there any compaction success messages or all of them fails?\n\n----------\n\n[DevD (2023-10-18T08:46:00.769Z)]: I have a similar compaction error issue. All of them fail, never a success. For days on end.\nDocker image: semitechnologies/weaviate:1.21.1\nSchema for Matches:\n[\n{“name”: “client_id”, “dataType”: [“int”]},\n{“name”: “category_id”, “dataType”: [“int”]},\n{“name”: “ctn_id”, “dataType”: [“int”]},\n{“name”: “is_description_only”, “dataType”: [“boolean”]},\n{“name”: “is_material_ctn”, “dataType”: [“boolean”]},\n{“name”: “created_at”, “dataType”: [“date”]},\n]\nError message:\n{“action”:“lsm_compaction”,“class”:“Matches”,“error”:“replace compacted segments: precompute segment meta: a bloom filter already exists with path /var/lib/weaviate/matches_V0cXxiU61Q6I_lsm/property_is_description_only/segment-1697059248081165705.bloom.tmp”,“index”:“matches”,“level”:“error”,“msg”:“compaction failed”,“path”:“/var/lib/weaviate/matches_V0cXxiU61Q6I_lsm/property_is_description_only”,“shard”:“V0cXxiU61Q6I”,“time”:“2023-10-18T08:42:43Z”}\n{“action”:“lsm_compaction”,“class”:“Matches”,“error”:“replace compacted segments: precompute segment meta: a bloom filter already exists with path /var/lib/weaviate/matches_V0cXxiU61Q6I_lsm/property_is_description_only/segment-1697059248081165705.bloom.tmp”,“index”:“matches”,“level”:“error”,“msg”:“compaction failed”,“path”:“/var/lib/weaviate/matches_V0cXxiU61Q6I_lsm/property_is_description_only”,“shard”:“V0cXxiU61Q6I”,“time”:“2023-10-18T08:42:46Z”}\n{“action”:“lsm_compaction”,“class”:“Matches”,“error”:“replace compacted segments: precompute segment meta: a bloom filter already exists with path /var/lib/weaviate/matches_V0cXxiU61Q6I_lsm/property_is_description_only/segment-1697059248081165705.bloom.tmp”,“index”:“matches”,“level”:“error”,“msg”:“compaction failed”,“path”:“/var/lib/weaviate/matches_V0cXxiU61Q6I_lsm/property_is_description_only”,“shard”:“V0cXxiU61Q6I”,“time”:“2023-10-18T08:42:49Z”}\n{“action”:“lsm_compaction”,“class”:“Matches”,“error”:“replace compacted segments: precompute segment meta: a bloom filter already exists with path /var/lib/weaviate/matches_V0cXxiU61Q6I_lsm/property_is_description_only/segment-1697059248081165705.bloom.tmp”,“index”:“matches”,“level”:“error”,“msg”:“compaction failed”,“path”:“/var/lib/weaviate/matches_V0cXxiU61Q6I_lsm/property_is_description_only”,“shard”:“V0cXxiU61Q6I”,“time”:“2023-10-18T08:42:52Z”}\n{“action”:“lsm_compaction”,“class”:“Matches”,“error”:“replace compacted segments: precompute segment meta: a bloom filter already exists with path /var/lib/weaviate/matches_V0cXxiU61Q6I_lsm/property_is_description_only/segment-1697059248081165705.bloom.tmp”,“index”:“matches”,“level”:“error”,“msg”:“compaction failed”,“path”:“/var/lib/weaviate/matches_V0cXxiU61Q6I_lsm/property_is_description_only”,“shard”:“V0cXxiU61Q6I”,“time”:“2023-10-18T08:42:55Z”}\n\n----------\n\n[Yogesh_Sharma (2024-03-27T08:44:26.264Z)]: I am also facing similar issue. Is there any solution?\n\n----------\n\n[jeronimo_irazabal (2024-03-27T13:33:02.458Z)]: Hi @Yogesh_Sharma, this issue should be solved since v1.24.4\nSome temporal files with .tmp extensions were not automatically deleted next compaction iteration and it’s causing the failure.\nMy recommendation is either to upgrade or directly remove those temporary files from the data folder if the upgrade is not a possibility (always it’s better to make a backup of the data before upgrading or deleting files from the data folder just for in case)\n\n----------\n\n[saurbhhsharrma (2024-09-16T15:20:38.134Z)]: I’m using latest version(v1.26.4) but still getting the same error:\nIt is on Single mode.\n{\"action\":\"lsm_compaction\",\"class\":\"ItemV3\",\"error\":\"write index: unlinkat /var/lib/weaviate/itemv3/aGmlzfgC3gOv/lsm/property_createdate_searchable/segment-1726498768692898772.dbcompaction.scratch.d: directory not empty\",\"index\":\"itemv3\",\"level\":\"error\",\"msg\":\"compaction failed\",\"path\":\"/var/lib/weaviate/itemv3/aGmlzfgC3gOv/lsm/property_createdate_searchable\",\"shard\":\"aGmlzfgC3gOv\",\"time\":\"2024-09-16T15:01:17Z\"}\nDue to this we are not able to trigger any new change on the Weaviate.\nCould you please help me with the fix of the issue?\nWe are stuck due to this issue.\n@jeronimo_irazabal @DudaNogueira",
    "date_created": "2023-08-26T16:59:30.789Z",
    "has_accepted_answer": true,
    "title": "Compaction Errors",
    "topic_id": 582
  },
  {
    "user_id": 588,
    "conversation": "[mnkasikci (2024-02-09T13:47:12.525Z)]: I’m currently dealing with Weaviate classes that are expected to contain over 100,000 objects, and I continuously add to and remove objects from these classes. Now, as I import objects into newly created classes, which again will accumulate more than 100,000 objects, the process seems inefficient. It takes upwards of a minute to import just a batch of 50 objects.\nI have 24GB Ram, 8 vcpu allocated for Weaviate in ECS. Async indexing is enabled.\nGiven this context, I suspect that the significant delay is due to Weaviate creating a new HSNW index each time new objects (and their associated vectors) are imported, which is inherently costly.\nWith this in mind, I have a couple of questions:\n\nIs the HSNW indexing approach suboptimal for classes containing such a high volume of objects, where each object is represented by a 1024-length vector?\nIn terms of HSNW indexing, does it help weaviate to know that there are 100.000 objects to index before starting indexing, instead of feeding objects 50 by 50?\n3- I checked the mutable fields on the documentation, and vectorizerIndexConfig->skip is one of them. Does this mean, i could skip indexing during import, and then set it to true? Would this start indexing once it is set to true, while not slowing me down during uploads?\n\nAny insights on managing large-scale imports more efficiently in Weaviate, especially when HSNW indexing is involved, would be greatly appreciated.\n\n----------\n\n[DudaNogueira (2024-02-09T22:55:54.250Z)]: Hi @mnkasikci!\nGreat questions! Thanks!\nI am assuming you are already using latest Weaviate server version (1.23.8).\nAlso using the python client v4, as it uses GRPC, and greatly improves performance.\nThe import process is very CPU bound, and because of that, you may see a import rate reduction over time when importing a lot of objects in a short period of time, as Weaviate will needs to both receive new objects and index the received ones.\nThe ASYNC INDEX is experimental. I have not played with it yet  But I plan on covering that soon in our recipes.\nSo you will need to reach a balance on that. Because there is a lot of differences in the data being indexed (size, properties, images, skip, etc), there isn’t a one size fits all.\nA good practice is to start with a small portion of the data set, and increase the batch size and workers, monitoring for resource consumption both on client and server.\nRegarding your questions:\n\n\n100.000 objects isn’t a high volume at all. It can go way beyod. Something around 2Gb is probably enough to serve those 100.000 objects.\n\n\nNot sure It does as the index is built based on those vectors, and on the ammount of them. Considering the ASYNC INDEX, maybe is better to fill in as much as objects you can thru a bigger batch.\n\n\nThe skip is about using or not that property to generate the vectorization. If you are providing the vectors yourself (not sure that is your case) Weaviate will not vectorize that object for your.\n\n\nLet me know if this helps",
    "date_created": "2024-02-09T13:47:12.473Z",
    "has_accepted_answer": false,
    "title": "Optimizing Object Import Performance in Large Weaviate Classes with HSNW Indexing",
    "topic_id": 1438
  },
  {
    "user_id": 3310,
    "conversation": "[Naseer_Faheem (2025-02-03T19:23:15.966Z)]: Description\n\nHi, I am very new to Weaviate and really help here. I am migrating a dataset from Mongodb to Weaviate. I have created collections and loaded my data which is real estate sample data.\nclient.connect()\nproperties = client.collections.get(\"Property\")\nresponse = properties.query.fetch_objects(\n    limit=10,\n    return_properties=[\"zipCode\", \"city\", \"bedrooms\", \"fullBathrooms\", \"price\"],\n)\nfor o in response.objects:\n    print(o.properties)\n\nBut whenever, I add filters, it’s taking around 2 seconds per query.\n# Filter results - single filter\nimport weaviate\nimport weaviate.classes as wvc\nimport os\nfrom weaviate.classes.query import MetadataQuery, Filter\n\ntry:\n    client.connect()\n    properties = client.collections.get(\"Property\")\n    response = properties.query.fetch_objects(\n        filters = Filter.by_property(\"bedrooms\").equal(3),\n        limit=20\n        #return_metadata=MetadataQuery(distance=True)\n        )\n    for o in response.objects:\n        print(o.properties)  # View the returned properties\n        print(o.metadata.creation_time)  # View the returned creation time\nfinally:\n    client.close()\n\nServer Setup Information\n\nWeaviate Server Version:  ‘1.27.11’\nDeployment Method:  Docker compose\nMulti Node? Number of Running Nodes: Single Node. The host is a VM on ESXI 8, on nvme disks\nClient Language and Version:\nMultitenancy?: NO\n\nAny additional Information\n\nCollection Setup:\nproperty_collection = client.collections.create(\n        name=\"Property\",\n        description=\"Comprehensive real estate property listings\",\n        properties=[\n            # Unique identifier first\n            wvc.config.Property(\n                name=\"property_uuid\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=True,\n                description=\"Unique identifier to link with images\"\n            ),\n            \n            # Source Information\n            wvc.config.Property(name=\"sourceIds\", data_type=wvc.config.DataType.TEXT),\n            wvc.config.Property(name=\"sourceUrls\", data_type=wvc.config.DataType.TEXT),\n            \n            # Basic Information (Primary Search Fields)[[]]\n            wvc.config.Property(\n                name=\"address\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=True,\n                index_searchable=True\n            ),\n            wvc.config.Property(\n                name=\"city\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=True,\n                index_searchable=True\n            ),\n            wvc.config.Property(\n                name=\"state\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=False\n            ),\n            wvc.config.Property(\n                name=\"zipCode\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=True,\n                #index_searchable=True\n            ),\n            wvc.config.Property(\n                name=\"propertyType\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=True\n            ),\n            wvc.config.Property(\n                name=\"status\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=True\n            ),\n            \n            # Numeric Features (Commonly Searched)\n            wvc.config.Property(\n                name=\"price\",\n                data_type=wvc.config.DataType.NUMBER,\n                #index_filterable=True,\n                index_range_filters=True\n            ),\n            # This is a discretized version of price for faster filtering\n            wvc.config.Property(\n                name=\"priceRange\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=True,\n                description=\"Discretized price range for faster filtering\"\n            ),\n            wvc.config.Property(\n                name=\"pricePerSqft\",\n                data_type=wvc.config.DataType.NUMBER,\n                #index_filterable=True,\n                index_range_filters=True\n            ),\n            wvc.config.Property(\n                name=\"bedrooms\",\n                data_type=wvc.config.DataType.NUMBER,\n                index_filterable=True\n            ),\n            wvc.config.Property(\n                name=\"fullBathrooms\",\n                data_type=wvc.config.DataType.NUMBER,\n                index_filterable=True\n            ),\n            wvc.config.Property(\n                name=\"halfBathrooms\",\n                data_type=wvc.config.DataType.NUMBER,\n                index_filterable=True\n            ),\n            wvc.config.Property(\n                name=\"totalSqft\",\n                data_type=wvc.config.DataType.NUMBER,\n                index_filterable=True,\n                index_range_filters=True\n            ),\n            wvc.config.Property(\n                name=\"lotSize\",\n                data_type=wvc.config.DataType.NUMBER,\n                index_filterable=True\n            ),\n            wvc.config.Property(\n                name=\"yearBuilt\",\n                data_type=wvc.config.DataType.NUMBER,\n                index_filterable=True,\n                index_range_filters=True\n            ),\n            \n            # Listing Details\n            wvc.config.Property(\n                name=\"daysOnMarket\",\n                data_type=wvc.config.DataType.NUMBER,\n                index_filterable=True\n            ),\n            wvc.config.Property(\n                name=\"listDate\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=True\n            ),\n            \n            # Description and Features (Semantic Search)\n            wvc.config.Property(\n                name=\"description\",\n                data_type=wvc.config.DataType.TEXT,\n                index_searchable=True\n            ),\n            wvc.config.Property(\n                name=\"keyFeatures\",\n                data_type=wvc.config.DataType.TEXT_ARRAY,\n                index_searchable=True\n            ),\n            \n            # Construction and Structure\n            wvc.config.Property(\n                name=\"constructionMaterial\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=False\n            ),\n            wvc.config.Property(\n                name=\"structureType\",\n                data_type=wvc.config.DataType.TEXT,\n                index_filterable=False\n            )\n],\n        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n            api_endpoint=\"http://192.168.10.11:11434\",\n            model=\"nomic-embed-text\"\n        ),\n        generative_config=wvc.config.Configure.Generative.ollama(\n            api_endpoint=\"http://192.168.10.11:11434\",\n            model=\"phi4\"\n        )\n    )\n\nAgain, I appreciate your help and debugging this. Mongodb is lightening fast and I came to weaviate because of it’s ai friendly features.\nEdit 1:\nI tried testing raw graphql using requests library and it’s lightening fast. Here is the query I tried with 4 filters:\nimport requests\nimport json\n\n# Create headers\nheaders = {\n   'Content-Type': 'application/json'\n}\n\n# Define the GraphQL query with multiple filters\nquery = \"\"\"\n{\n Get {\n   Property(\n     limit: 20\n     where: {\n       operator: And\n       operands: [\n         { path: [\"zipCode\"], operator: Equal, valueString: \"22066\" }\n         { path: [\"bedrooms\"], operator: Equal, valueNumber: 4 }\n         { path: [\"fullBathrooms\"], operator: Equal, valueNumber: 3 }\n         { path: [\"price\"], operator: LessThan, valueNumber: 3000000 }\n       ]\n     }\n   ) {\n     zipCode\n     city\n     bedrooms\n     fullBathrooms\n     price\n     address\n     listDate\n   }\n }\n}\n\"\"\"\n\n# Use session for connection pooling\nwith requests.Session() as session:\n   response = session.post(\n       'http://192.168.10.11:8082/v1/graphql',\n       headers=headers,\n       json={'query': query}\n   )\n\n   if response.status_code == 200:\n       result = response.json()\n       if 'errors' in result:\n           print(\"GraphQL Errors:\", result['errors'])\n       else:\n           properties = result['data']['Get']['Property']\n           for property in properties:\n               print(property)\n   else:\n       print(f\"Error: {response.status_code}\")\n       print(response.text)\n\n----------\n\n[DudaNogueira (2025-02-03T20:30:25.143Z)]: hi @Naseer_Faheem !!\nWelcome to our community \nThose are interesting findings! Do you get the same output if running on Weaviate 1.28.4?\nAlso, what is the client version you are using?\nThanks!",
    "date_created": "2025-02-03T19:23:15.898Z",
    "has_accepted_answer": true,
    "title": "Search with Filter takes longer",
    "topic_id": 10009
  },
  {
    "user_id": 323,
    "conversation": "[Dharanish (2024-03-18T09:46:59.554Z)]: collection = client.collections.get(\"WineReview\").with_consistency_level(ConsistencyLevel.ALL)\nfor item in collection.iterator():\n    print(print(item.uuid, item.properties))\n\nHi team , does the above retrieves all the objects present in the collection and read on repair happens parallely ,  regardless of no limit and after params given ?\n\n----------\n\n[DudaNogueira (2024-03-18T12:42:06.004Z)]: Hi @Dharanish !\nIt should. AFAIK, it will fix those eventual inconsistencies on read.\nAlso, keep an eye for our roadmap.\nHopefully we’ll have async repair in 1.25:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Replication: Async replication and async repairs\n    \n\n    \n      \n        opened 11:54AM - 02 Dec 22 UTC\n      \n\n\n      \n        \n          \n          etiennedi\n        \n      \n    \n\n    \n        \n          backlog\n        \n        \n          planned-1.25\n        \n    \n  \n\n\n  \n    If a multi-node cluster with replication is out of sync, an async process should… run constantly to repair inconsistencies.\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nPs: Don’t forget to leave your thumbs up on this issue \nPs: And, for course, our  in our Github repo \nThanks!\n\n----------\n\n[clpurcell (2025-01-21T02:54:42.421Z)]: Hey, just following up to this since I also would like this feature.\nI want to run a process on each node in a collection and save if the process has been completed as a DoneProcessing boolean property in each node. Since I will be running on all nodes I should naturally be using your iterator class, but if my script fails and I need to start again I’d prefer not to read nodes that have already been processed. I know I can run queries with the boolean filter in a while loop, but it feels like an antipattern if you have an iterator class.\nGreat work with Weaviate btw, it’s an amazing tool!!\n\n----------\n\n[Mohamed_Shahin (2025-01-21T16:44:01.658Z)]: @clpurcell Please see Consistency | Weaviate\n\n----------\n\n[clpurcell (2025-01-21T18:33:24.849Z)]: Hi Mohamed,\nThank you for the quick reply!\nI’m not sure how your link helps. I’m not running with any replication, just a single-node local deployment.\nIn case what I described wasn’t clear here is some more background information. The process I’m running takes a node and calculates other nodes that may match it. If matches are found, I save them as references for that node. To track which nodes I’ve already run this matching process on I’ve created a boolean field called DoneProcessing and set all nodes to False. As my script iterates over all nodes and runs this matching process I update DoneProcessing to True.\nAgain, thanks for the help and your great work!\n\n----------\n\n[Mohamed_Shahin (2025-01-22T12:34:59.143Z)]: Hey @clpurcell\nThank you for your confirmation, I may misread that.\nWould you please open a new topic and put all details there including your snippet of code?\nI will try to replicate and we have a dedicated thread in the forum for that in case we rule out any bugs.\nI appreciate it.",
    "date_created": "2024-03-18T09:46:59.496Z",
    "has_accepted_answer": true,
    "title": "Read all objects",
    "topic_id": 1750
  },
  {
    "user_id": 2410,
    "conversation": "[bam (2024-11-24T22:23:25.430Z)]: Description\nI imported a bunch of pdfs before understanding all the features of the tool. Now I’d like to use the metadata and labels to the documents in weaviate.\nIs it possible to add metadata and labels after the documents are vectorized?\nIf so, how?\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-11-25T12:41:43.659Z)]: hi @bam !!\nIt is possible. Note that, if you have not set that property to be skipped from vectorization, whenever you update an object, it will trigger a new vectorization of that object.\nIf you don’t want that, you can set the property you want to use as metadata/filtering needs to be skipped or not listed as the source_properties if using a named vector.\nLet me know if this helps!\nThanks!\n\n----------\n\n[bam (2024-11-25T22:49:27.684Z)]: Thank you for the quick reply. Can this be done inside Verba? I followed the link. The instructions imply it may only be done by coding it with the object id and collection name. I’m not able to see the object id nor collection name in Verba.\n\n----------\n\n[DudaNogueira (2024-11-26T20:34:17.632Z)]: hi! Verba do not provide a way to edit chunks, so I believe you will need to drop the entire document and reupload, or connect direct to Weaviate and change the objects you want.\nAFAIK, Verba do not expose the ID or collection at UI level. \nSo you’ll need to list the collections, and look for the object you want to change.\nLet me know if this helps!",
    "date_created": "2024-11-24T22:23:25.384Z",
    "has_accepted_answer": false,
    "title": "Update Document Metadata and labels after importing and vectorizing",
    "topic_id": 7940
  },
  {
    "user_id": 219,
    "conversation": "[JLiz2803 (2025-01-15T07:00:11.836Z)]: Description\nRecently we added a couple new fields to our weaviate class.  After doing so weaviate started throwing a lot of errors.  It works sparingly for some calls but for the most part it fails.  Below are the errors we are seeing\nMeta endpoint! Unexpected status code: 500, with response body: {'message': 'Internal server error'}.\n\nweaviate.exceptions.UnexpectedStatusCodeError: Query was not successful! Unexpected status code: 504, with response body: {'message': 'Endpoint request timed out'}.\n\n\nServer Setup Information\n\nWeaviate Server Version: 1.28.0\nDeployment Method: AWS EKS via Manifest files\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python V3\nMultitenancy?: Yes\n\nAny additional Information\nIt’s odd one moment it is returning results just fine, and more consistently returning the schema, class tenants, and counts of objects within class tenant, and then all of the sudden it just starts failing\n\n----------\n\n[Mohamed_Shahin (2025-01-16T09:58:15.362Z)]: Hi @JLiz2803,\nIf possible, could you upgrade to the latest Python client to leverage the latest improvements and changes then do some querying and see if the issue persists?\nAdditionally, please share more details about the query, the stack trace of the error, and details about the collection. It would be helpful to know what the state of the collection was before you added properties and which properties you added.\nIt’s also worth mentioning that the latest stable release for version 1.28 is v1.28.2.\nBest regards,\nMohamed Shahin\nWeaviate Support Engineer",
    "date_created": "2025-01-15T07:00:11.789Z",
    "has_accepted_answer": false,
    "title": "Weaviate Failing after adding fields to Class",
    "topic_id": 9775
  },
  {
    "user_id": 3557,
    "conversation": "[xbc5 (2025-02-26T22:34:42.463Z)]: Description\nI am a beginner, I lack any real experience with AI, so deep technical knowledge on the topic escapes me. I just want to clarify some details at a high level, because there are some questions that I find difficult to answer via the documentation.\nMy primary goal is to use a quantised model for CPU inference (the ONNX images); i need to squeeze as much as I can from the CPU, for semantic search.\nThis is my proposed setup:\n\nquantised model: Snowflake Arctic embed sm (30m; 384d; Q8) – the ONNX image provided by Weaviate\nbring your own vectors: the vectoriser is set to none because it’s a static database, and I will vectorise off-site\nscalar quantisation: I think that I need this right? if the model produces int8, then it should compare to an int8 index?\n\nMy setup reflects what I think is required; these questions will help clarify my confusion:\na. do I bring my own vectors as f32?\n- weaviate-go accepts only f32, so I assume that it quantises the vectors as it indexes them\n- would the unquantised model yield suitable vectors? (If I understand it correctly Weaviate quantises them before indexing – but are the int8 quantised vectors from the model suitable to match against Weaviate’s int8 index vectors?)\nb. do I need to use SQ if the model that I use produces int8 vectors?\n- if not, how does that work? how does it compare vectors (are they int8, float32, or what?) I assumed that Q8 model produces int8, and it needs to compare against int8 (SQ index)\nb. if the vectoriser is “none”: do i vectorise my own queries (via HTTP request to the container)?\n- I will set the vectoriser to none, because it’s a static database, and I intend to vectorise everything off-site\nGenerally speaking my approach (and understanding) to batch loading the database is:\n\nvectorise off-site using the unquantised snowflake, arctic embed model – produce f32\nsend those to Weaviate via my gRPC server (as f32)\nWeaviate creates the collection and strores the uncompressed vectors, but indexes as int8 (SQ)\n\nNow, a query comes in:\n\nI send it to the snowflake artctic embed model for vectorisation, it returns an int8 vector\nIt’s then sent to weaviate, a near vector search commences\nWeaviate compares the int8 query to the SQ index (int8)\nsome other magic happens (possibly re-scoring, or not: perhaps that’s only BQ pr PQ)\nWeaviate returns the result\n\nIs my understanding way off? I just want a general feel for what’s occurring, I don’t want to waste a lot of CPU cycles doing something stupid. It doesn’t need to be perfect.\nServer Setup Information\n\nWeaviate Server Version: 1.28.4\nDeployment Method: Docker compose\nMulti Node? No, single, for the time being (perhaps a year or two down the line this will change)\nClient Language and Version: Go 1.23\nMultitenancy?: Yes, but set to a single value (only during testing do I set this to a randm UUID per test)\n\nAny additional Information\n\nI understand and have considered binary quantisation: a consideration for the future, if i need it\n\n----------\n\n[DudaNogueira (2025-02-28T12:19:21.942Z)]: Hi @xbc5 !! Welcome to our community \nOne thing to consider here is that Weaviate will quantize the vectors for you. So you must bring your vectors as is.\nEven if your model produces int8 vectors, it’s still recommended to use SQ in Weaviate. Here’s why:\n\n\nWeaviate’s SQ implementation is designed to work with float32 input vectors and optimize them for storage and comparison within Weaviate’s index.\n\n\nSQ in Weaviate analyzes your data and distributes dimension values into 256 buckets, which may differ from the quantization scheme used by your model.\n\n\nYour understanding is generally correct, but with a few adjustments:\n\n\nVectorize off-site using the unquantized Snowflake Arctic embed model, producing float32 vectors.\n\n\nSend these float32 vectors to Weaviate.\n\n\nIf SQ is enabled, Weaviate will store the uncompressed vectors but index them using SQ (8-bit integers).\n\n\nFor querying:\n\n\nVectorize the query off-site, producing a float32 vector (not int8).\n\n\nSend this float32 query vector to Weaviate.\n\n\nWeaviate will compare the query vector against the SQ-compressed index.\n\n\nWeaviate may perform additional steps like over-fetching and re-scoring to improve recall.\n\n\nOne thing to consider is using, if possible, dynamic index, allowing you to define a threshold to move away from a flat (disk) to hsnw (memory) index.\nLet me know if this helps!\nThanks!\n\n----------\n\n[xbc5 (2025-02-28T16:48:30.591Z)]: That does help a lot; thanks for the quick response.\n\nVectorize the query off-site, producing a float32 vector (not int8).\n\n\nSQ in Weaviate analyzes your data and distributes dimension values into 256 buckets, which may differ from the quantization scheme used by your model.\n\nI misunderstood. It turns out that the model that I use[1] produces f32 vectors (despite being a quantised model).\nAre these suitable for both query and initial vectorisation? Essentially I am asking: If I use it for both, will the SQ index work? Or should I use the original (unquantised) model[2] for initial vectorisation?\nThanks for putting up with my stupid questions.\nModel Details\n\nSnowflake arctic-embed sm ONNX, provided by Weaviate[1:1].\nThis model produces floats, but its clearly a quantised model.\nIts ort_config.json:\n\nFull config\n{\n  \"one_external_file\": true,\n  \"opset\": null,\n  \"optimization\": {},\n  \"quantization\": {\n    \"activations_dtype\": \"QUInt8\",\n    \"activations_symmetric\": false,\n    \"format\": \"QOperator\",\n    \"is_static\": false,\n    \"mode\": \"IntegerOps\",\n    \"nodes_to_exclude\": [],\n    \"nodes_to_quantize\": [],\n    \"operators_to_quantize\": [\n      \"Conv\",\n      \"MatMul\",\n      \"Attention\",\n      \"LSTM\",\n      \"Gather\",\n      \"Transpose\",\n      \"EmbedLayerNormalization\"\n    ],\n    \"per_channel\": false,\n    \"qdq_add_pair_to_weight\": false,\n    \"qdq_dedicated_pair\": false,\n    \"qdq_op_type_per_channel_support_to_axis\": {\n      \"MatMul\": 1\n    },\n    \"reduce_range\": false,\n    \"weights_dtype\": \"QUInt8\",\n    \"weights_symmetric\": true\n  },\n  \"use_external_data_format\": false\n}\n\n\n{\n  ...\n  \"quantization\": {\n    \"activations_dtype\": \"QUInt8\",\n    \"mode\": \"IntegerOps\",\n    \"weights_dtype\": \"QUInt8\",\n    ...\n  },\n}\n\n\nt2v-transformers-1  | INFO:     Running on CPU\nt2v-transformers-1  | INFO:     Running ONNX vectorizer with quantized model for amd64 (AVX2)\n\n\n\n\nSnowflake arctic-emded sm ONNX (quantised for CPU inference): semitechnologies/transformers-inference:snowflake-snowflake-arctic-embed-s-onnx-1.10.1 ↩︎ ↩︎\n\nSnowflake/snowflake-arctic-embed-s · Hugging Face (unquantised; f32) ↩︎\n\n----------\n\n[DudaNogueira (2025-02-28T18:00:28.743Z)]: Hi!! Not stupid at all! Much the opposite \nANd please, feel free to always reach out to us and ask any questions. We are here to help!\nIf you have a vectorizer configured, Weaviate will vectorize your content. Or, if you bring your own vector, Weaviate will quantize the vector for you.\nAs you noted, the model you have chosen will vectorize using f32, so it should work as expected. Now you can either generate your own vectors and provide it while creating the object, or let Weavaite vectorize it for you.\nLet me know if this clarifies!\nThanks!\n\n----------\n\n[DudaNogueira (2025-02-28T18:01:26.529Z)]: By the way, every week we host some nice events that you will certainly benefit from:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nOnline Workshops & Events | Weaviate\n\n  -Join us at conferences, meetups, webinars or workshops\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nPro Tip: if you can’t join, make sure to subscribe and you’ll get the recording delivered to your email\n\n----------\n\n[xbc5 (2025-02-28T20:42:40.562Z)]: Thanks.\nI was concerned that the ONNX model would generate a small loss in accuracy because it does inference internally via int8 (outputting f32). I thought that further quantising the vector during indexing would exacerbate that loss in accuracy.\n\nBy the way, every week we host some nice events that you will certainly benefit from\n\nLooks good. I’ll give it a try. The one on Mar 6th looks interesting.",
    "date_created": "2025-02-26T22:34:42.400Z",
    "has_accepted_answer": true,
    "title": "Am I thinking correctly about quantiation?",
    "topic_id": 10564
  },
  {
    "user_id": 1618,
    "conversation": "[Abyl_Ikhsanov (2024-10-01T11:58:00.406Z)]: Description\n\nI am using Azure Durable Functions that creates a new instance of WeaviateDB but does close it down when finished with it.\nThis is how I create the WeaviateDB:\ndef get_weaviate_db(kb_id: str):\n    db = WeaviateVectorDB(kb_id=kb_id, http_host=os.getenv(\"WEAVIATE_HTTP_HOST\"),\n                          http_secure=True, grpc_host=os.getenv(\"WEAVIATE_GRPC_HOST\"),\n                          grpc_secure=True, weaviate_secret=os.getenv(\"WEAVIATE_API_KEY\"))\n    return db\n\nclass WeaviateVectorDB(VectorDB):\n    \"\"\"\n    An implementation of the VectorDB interface for Weaviate using the Python v4 client.\n\n    This class provides methods for adding, removing, and searching for vectorized data\n    within a Weaviate instance.\n    \"\"\"\n\n    def __init__(\n        self,\n        kb_id: str,\n        http_host=\"localhost\",\n        http_port=8099,\n        http_secure=False,\n        grpc_host=\"localhost\",\n        grpc_port=50052,\n        grpc_secure=False,\n        weaviate_secret=\"secr3tk3y\",\n        init_timeout: int = 2,\n        query_timeout: int = 45,\n        insert_timeout: int = 120,\n        use_embedded_weaviate: bool = False,\n    ):\n        \"\"\"\n        Initializes a WeaviateVectorDB instance.\n\n        Args:\n            http_host: The hostname of the Weaviate server.\n            http_port: The HTTP port of the Weaviate server.\n            http_secure: Whether to use HTTPS for the connection.\n            grpc_host: The hostname of the Weaviate server for gRPC connections.\n            grpc_port: The gRPC port of the Weaviate server.\n            grpc_secure: Whether to use gRPCs for the connection.\n            class_name: The name of the Weaviate class to use for storing data.\n            kb_id: An optional identifier for the knowledge base.\n        \"\"\"\n\n        # save all of these parameters as attributes so they're easily accessible for the to_dict method\n        self.kb_id = kb_id\n        self.http_host = http_host\n        self.http_port = http_port\n        self.http_secure = http_secure\n        self.grpc_host = grpc_host\n        self.grpc_port = grpc_port\n        self.grpc_secure = grpc_secure\n        self.weaviate_secret = weaviate_secret\n        self.init_timeout = init_timeout\n        self.query_timeout = query_timeout\n        self.insert_timeout = insert_timeout\n        self.use_embedded_weaviate = use_embedded_weaviate\n\n        additional_headers = {}\n        if use_embedded_weaviate:\n            additional_headers[\"ENABLE_MODULES\"] = (\n                \"backup-filesystem,text2vec-openai,text2vec-cohere,text2vec-huggingface,ref2vec-centroid,generative-openai,qna-openai\"\n            )\n            additional_headers[\"BACKUP_FILESYSTEM_PATH\"] = \"./weaviate/backups\"\n            self.client = weaviate.WeaviateClient(\n                embedded_options=weaviate.embedded.EmbeddedOptions(\n                    persistence_data_path=\"./weaviate/data\",\n                ),\n                additional_headers=additional_headers,\n            )\n        else:\n            self.client = weaviate.connect_to_wcs(\n                cluster_url=self.http_host,\n                auth_credentials=weaviate.auth.AuthApiKey(self.weaviate_secret), skip_init_checks=True, additional_config=AdditionalConfig(\n                connection=ConnectionConfig(\n                    session_pool_connections=100,\n                    session_pool_maxsize=500,\n                    session_pool_max_retries=3,\n                )\n            ),)\n\n        self.client.connect()\n        self.collection_name = \"dsrag_test\"\n        self.collection = self.client.collections.get(\n            self.collection_name\n        )\n\nSo when I create only 1 instance, is slowly but does work. When I have 10+ instances opened and running at the same time, I get this error:\nQuery call with protocol GRPC search failed with message Deadline Exceeded\nServer Setup Information\n\nWeaviate Server Version: weaviate-client~=4.6.5\nDeployment Method: Using Python V4 SDK\nMulti Node? Number of Running Nodes: Not sure what does it mean\nClient Language and Version: Python V4\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-10-01T15:34:36.848Z)]: hi @Abyl_Ikhsanov !!\nWelcome to our community \nThis error usually indicates a lack of resource from the server side.\nI see you are using our cloud. For any issues like this, the best place to ask for support is following this page inside your console\nHow many objects are you currently hosting and how many objects do you plan on hosting?\nif you are using a sandbox, be aware that it has a limited resource allocated for it.\nLet me know if this helps.\nThanks!\n\n----------\n\n[Abyl_Ikhsanov (2024-10-01T15:57:59.326Z)]: Hi @DudaNogueira ,\nThanks, I will ask support next time.\nCurrently it is around 900 objects that is being hosted in a single cluster. The plan is to host a lot more (100k-1 million).\nAs sanbox, you mean the actual cluster I might be using? I chose the “serverless” cluster. Or do you mean the Python V4 wrapper that I use? Is there a way to use a more performant then?\n\n----------\n\n[DudaNogueira (2024-10-02T12:10:41.537Z)]: hi @Abyl_Ikhsanov !!\nThe sandbox is the free instance we provide for experimenting.\nSo it looks like you are using our serverless, and should have enough resources for your objects.\nI don’t have visibility of your clusters or metrics from the forums. That’s why for any issues on clusters hosted on our cloud, the best support option is open a support ticket.",
    "date_created": "2024-10-01T11:58:00.354Z",
    "has_accepted_answer": false,
    "title": "Keep getting \"Query call with protocol GRPC search failed with message Deadline Exceeded\"",
    "topic_id": 4383
  },
  {
    "user_id": 3323,
    "conversation": "[violin1443 (2025-02-17T20:56:29.524Z)]: Hi! I just started using the Weaviate Python client (version 4.10.4). I have a collection movies that includes the following properties: movie_description (text, used for vector based search) and movie_tags (text array). movie_tags can have no or one or more tags, such as ‘blockbuster’, ‘high IMDb rating’, ‘crowd favorite’, etc.\nI would like to define a query Filter to pass to near_text during a semantic search, with weaviate.classes.query.Filter to do the following:\n\nfilter to search from only objects with EMPTY movie_tags array\nfilter to search from only objects with NON-EMPTY movie_tags arrray\n\nCould you provide instructions on correctly building the filter? I’m hoping there’s a better way than using Filter.by_property(\"movie_tags\").contains_any(all_unique_movie_tags) \nPointers to the python client documentation on filtering text arrays based on array size will also be greatly appreciated. Thank you very much!\n\n----------\n\n[DudaNogueira (2025-02-17T21:43:36.597Z)]: hi @violin1443 !!\nWelcome to our community \nIf you want to filter by property length or null state, you need to first create a collection and specify that at inverted_index_config, like so:\nimport weaviate\nfrom weaviate import classes as wvc\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=[\n        wvc.config.Configure.NamedVectors.text2vec_openai(name=\"default\"),\n    ],\n    inverted_index_config=wvc.config.Configure.inverted_index(\n        index_null_state=True,\n        index_property_length=True\n    ),\n    properties=[\n        wvc.config.Property(name=\"movie_description\", data_type=wvc.config.DataType.TEXT),\n        wvc.config.Property(name=\"movie_tags\", data_type=wvc.config.DataType.TEXT_ARRAY),\n    ]\n)\ncollection = client.collections.get(\"Test\")\ncollection.data.insert_many([\n    { \"movie_description\": \"Move desc 1. No tag\"},\n    { \"movie_description\": \"Move desc 2. One Tag\", \"movie_tags\": [\"tag1\"]},\n    { \"movie_description\": \"Move desc 3. Two Tags\", \"movie_tags\": [\"tag1\", \"tag2\"]},\n    { \"movie_description\": \"Move desc 4. OverLap tags\", \"movie_tags\": [\"tag2\", \"tag3\"]},\n])\n\n\nNow you can perform different searches and filters:\n# movies with no tags\nfilters = wvc.query.Filter.by_property(\"movie_tags\").is_none(True) # change to False if you want movies with tags\n# movies with any of the given tags\nfilters = wvc.query.Filter.by_property(\"movie_tags\").contains_any([\"tag3\", \"tag2\"])\n# movies with tags all of the given tags\nfilters = wvc.query.Filter.by_property(\"movie_tags\").contains_all([\"tag3\", \"tag2\"])\n# movies with tags count > 2\n# https://weaviate.io/developers/weaviate/search/filters#by-object-property-length\nfilters=wvc.query.Filter.by_property(\"movie_tags\", length=True).greater_or_equal(2)\n\nquery = collection.query.near_text(\n    query=\"some movie\",\n    filters= filters\n)\nfor o in query.objects:\n    print(o.properties)\n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[violin1443 (2025-02-19T20:13:51.758Z)]: This is very helpful! Thank you so much \nThe current collection I am working on doesn’t have inverted_index_config specified–do I have to delete and rebuild the index? Or is there any way to add these index config to the existing collection, just to avoid having to vectorize all the texts again?\nThanks a lot!\n\n----------\n\n[DudaNogueira (2025-02-19T21:22:36.643Z)]: Hi!\nYes, you will need to create a new collection and copy over the data.\nNot all collection configuration is mutable. Here is a list of the ones you can change:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection definition | Weaviate\n\n  Schema Configuration in Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAnd here a fairly simple guide on how to migrate your data over:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Learn how to migrate data within Weaviate for easy data handling.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!",
    "date_created": "2025-02-17T20:56:29.462Z",
    "has_accepted_answer": true,
    "title": "Filter near_text search based on empty/non-empty text array",
    "topic_id": 10421
  },
  {
    "user_id": 2431,
    "conversation": "[cw257900 (2024-11-01T22:21:32.593Z)]: I tried local connection with data inserted successfully. When I switch from connect_to_local to connect_to_embeded, data can’t insert .\nI saw error on the path now. anyway to suppress those messages to only show error? I tried to set log level which seems not working\nINFO:weaviate-client:Started /Users/connie.wang/.cache/weaviate-embedded: process ID 33040\n{“action”:“startup”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“default_vectorizer_module”:“none”,“level”:“info”,“msg”:“the default vectorizer modules is set to \"none\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer”,“time”:“2024-11-01T17:24:14-05:00”}\n{“action”:“startup”,“auto_schema_enabled”:true,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“auto schema enabled setting is set to \"true\"”,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true”,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“module offload-s3 is enabled”,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“warning”,“msg”:“Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.”,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“open cluster service”,“servers”:{“Embedded_at_8079”:62794},“time”:“2024-11-01T17:24:14-05:00”}\n{“address”:“192.168.1.44:62795”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“starting cloud rpc server …”,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“starting raft sub-system …”,“time”:“2024-11-01T17:24:14-05:00”}\n{“address”:“192.168.1.44:62794”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“tcp transport”,“tcpMaxPool”:3,“tcpTimeout”:10000000000,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“loading local db”,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“local DB successfully loaded”,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“schema manager loaded”,“n”:0,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“metadata_only_voters”:false,“msg”:“construct a new raft node”,“name”:“Embedded_at_8079”,“time”:“2024-11-01T17:24:14-05:00”}\n{“action”:“raft”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“index”:98,“level”:“info”,“msg”:“raft initial configuration”,“servers”:“[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.1.44:62432}]]”,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“last_snapshot_index”:0,“last_store_applied_index_on_start”:72,“level”:“info”,“msg”:“raft node constructed”,“raft_applied_index”:0,“raft_last_index”:98,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“hasState”:true,“level”:“info”,“msg”:“raft init”,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“192.168.1.44:62794”],“time”:“2024-11-01T17:24:14-05:00”}\n{“action”:“raft”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“follower”:{},“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“raft entering follower state”,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“192.168.1.44:62794”,“status”:8,“time”:“2024-11-01T17:24:14-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“192.168.1.44:62794”],“time”:“2024-11-01T17:24:15-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“192.168.1.44:62794”,“status”:8,“time”:“2024-11-01T17:24:15-05:00”}\n{“action”:“raft”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“last-leader-addr”:“”,“last-leader-id”:“”,“level”:“warning”,“msg”:“raft heartbeat timeout reached, starting election”,“time”:“2024-11-01T17:24:15-05:00”}\n{“action”:“raft”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“raft entering candidate state”,“node”:{},“term”:48,“time”:“2024-11-01T17:24:15-05:00”}\n{“action”:“raft”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“raft pre-vote successful, starting election”,“refused”:0,“tally”:1,“term”:48,“time”:“2024-11-01T17:24:15-05:00”,“votesNeeded”:1}\n{“action”:“raft”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“raft election won”,“tally”:1,“term”:48,“time”:“2024-11-01T17:24:15-05:00”}\n{“action”:“raft”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“leader”:{},“level”:“info”,“msg”:“raft entering leader state”,“time”:“2024-11-01T17:24:15-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“reload local db: update schema …”,“time”:“2024-11-01T17:24:15-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“index”:“PDF_COLLECTION”,“level”:“info”,“msg”:“reload local index”,“time”:“2024-11-01T17:24:15-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“docker_image_tag”:“localhost”,“level”:“info”,“msg”:“configured versions”,“server_version”:“1.26.6”,“time”:“2024-11-01T17:24:16-05:00”}\n{“action”:“grpc_startup”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“grpc server listening at [::]:50050”,“time”:“2024-11-01T17:24:16-05:00”}\n{“address”:“192.168.1.44:62794”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“current Leader”,“time”:“2024-11-01T17:24:16-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“192.168.1.44:62794”],“time”:“2024-11-01T17:24:16-05:00”}\n{“action”:“raft”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“command”:0,“level”:“info”,“msg”:“raft updating configuration”,“server-addr”:“192.168.1.44:62794”,“server-id”:“Embedded_at_8079”,“servers”:“[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.1.44:62794}]]”,“time”:“2024-11-01T17:24:16-05:00”}\n{“action”:“restapi_management”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“docker_image_tag”:“localhost”,“level”:“info”,“msg”:“Serving weaviate at http://127.0.0.1:8079”,“time”:“2024-11-01T17:24:16-05:00”}\nError from /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/with_weaviate/app/rag/data/constitution.pdf: Invalid PDF file path: /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/with_weaviate/app/rag/data/constitution.pdf\nError: Invalid PDF file path: /Users/connie.wang/Desktop/connie/inspiration_azure/fastapi_onazure/app/with_weaviate/app/rag/data/constitution.pdf\n{“action”:“restapi_management”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“docker_image_tag”:“localhost”,“level”:“info”,“msg”:“Shutting down… “,“time”:“2024-11-01T17:24:16-05:00”}\n{“action”:“restapi_management”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“docker_image_tag”:“localhost”,“level”:“info”,“msg”:“Stopped serving weaviate at http://127.0.0.1:8079”,“time”:“2024-11-01T17:24:16-05:00”}\n{“action”:“hnsw_prefill_cache_async”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“not waiting for vector cache prefill, running in background”,“time”:“2024-11-01T17:24:17-05:00”,“wait_for_cache_prefill”:false}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“Completed loading shard pdf_collection_uo8EdlUehjpj in 11.185209ms”,“time”:“2024-11-01T17:24:17-05:00”}\n{“action”:“hnsw_compressed_vector_cache_prefill”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“count”:0,“level”:“info”,“msg”:“prefilled compressed vector cache”,“time”:“2024-11-01T17:24:17-05:00”,“took”:399084}\n{“action”:“telemetry_push”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“telemetry started”,“payload”:”\\u0026{MachineID:3eedf617-c28f-47d7-adf0-449c23f70447 Type:INIT Version:1.26.6 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[generative-cohere text2vec-openai]}”,“time”:“2024-11-01T17:24:17-05:00”}\n{“action”:“telemetry_push”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“telemetry terminated”,“payload”:“\\u0026{MachineID:3eedf617-c28f-47d7-adf0-449c23f70447 Type:TERMINATE Version:1.26.6 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[generative-cohere text2vec-openai]}”,“time”:“2024-11-01T17:24:17-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“closing raft FSM store …”,“time”:“2024-11-01T17:24:17-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“shutting down raft sub-system …”,“time”:“2024-11-01T17:24:17-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“transferring leadership to another server”,“time”:“2024-11-01T17:24:17-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“error”:“cannot find peer”,“level”:“error”,“msg”:“transferring leadership”,“time”:“2024-11-01T17:24:17-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“closing raft-net …”,“time”:“2024-11-01T17:24:17-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“closing log store …”,“time”:“2024-11-01T17:24:17-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“closing data store …”,“time”:“2024-11-01T17:24:17-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“closing loaded database …”,“time”:“2024-11-01T17:24:17-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“closing raft-rpc client …”,“time”:“2024-11-01T17:24:17-05:00”}\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“closing raft-rpc server …”,“time”:“2024-11-01T17:24:17-05:00”}\n\n----------\n\n[DudaNogueira (2024-11-02T16:13:12.884Z)]: Hi!\nOnce that you get a valid client, with a connected instance behind it, you should be able to insert your objects.\nYou can check that with client.is_ready()\nPlease note that Weaviate Embedded is marked as experimental.\nAlso, that when you run Weaviate Embedded, and close the client, the server will be stopped.\nIf you do not close the server, it may still be running on background, so if you spin a second embedded, you may have problems with port bindings.\n\n----------\n\n[cw257900 (2024-11-03T07:32:49.673Z)]: yah. i made the connection work yesterday, and observed the issue with connection as you planned already. Will data be persist after client is disconnected?\n\n----------\n\n[DudaNogueira (2024-11-04T13:50:13.143Z)]: Hi!\nYes, the data will persist.\nIf you do not specify a persistence_path, as describre here, by default, it will store your data in ~/.local/share/weaviate\nIf you have issues running the embedded client, because there is another process binding to that port, you will need to kill the process.\nSo:\nps aux | grep weaviate\n\nthen kill the ID of the running process.\nLet me know if that helps!",
    "date_created": "2024-11-01T22:21:32.547Z",
    "has_accepted_answer": false,
    "title": "Once weaviate.connect_to_embedded , do I need to start it before insert data into collection?",
    "topic_id": 7381
  },
  {
    "user_id": 1211,
    "conversation": "[Khorppun_Sontipanya (2024-08-22T04:14:44.182Z)]: Hello, I am a beginner trying out Weaviate. However, when I ran a simple code, I encountered an error that I think is related to the SSL Certificate. I would like to know how to fix this issue, and whether Weaviate has a method to disable SSL verification. (I have updated the certifi library in Python.)\nThank You\nThis is my code:\nCapture909×896 72.1 KB\nThis is result with error:\nstatus_weaviate :  True\nHello\nE0822 10:59:44.842000000  5040 src/core/tsi/ssl_transport_security.cc:1654] Handshake failed with fatal error SSL_ERROR_SSL: error:1000007d:SSL routines:OPENSSL_internal:CERTIFICATE_VERIFY_FAILED.\nTraceback (most recent call last):\nFile “C:\\software_dev_flook\\KM_AI\\KM-AI-V0-main\\myenv\\Lib\\site-packages\\weaviate\\collections\\grpc\\query.py”, line 762, in __call\nres = await self._connection.grpc_stub.Search(\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “C:\\software_dev_flook\\KM_AI\\KM-AI-V0-main\\myenv\\Lib\\site-packages\\grpc\\aio_call.py”, line 318, in await\nraise _create_rpc_error(\ngrpc.aio._call.AioRpcError: <AioRpcError of RPC that terminated with:\nstatus = StatusCode.UNAVAILABLE\ndetails = “failed to connect to all addresses; last error: UNKNOWN: ipv4:34.98.85.103:443: Ssl handshake failed: SSL_ERROR_SSL: error:1000007d:SSL routines:OPENSSL_internal:CERTIFICATE_VERIFY_FAILED”\ndebug_error_string = “UNKNOWN:Error received from peer  {created_time:“2024-08-22T03:59:45.0595101+00:00”, grpc_status:14, grpc_message:“failed to connect to all addresses; last error: UNKNOWN: ipv4:34.98.85.103:443: Ssl handshake failed: SSL_ERROR_SSL: error:1000007d:SSL routines:OPENSSL_internal:CERTIFICATE_VERIFY_FAILED”}”\n\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile “C:\\software_dev_flook\\KM_AI\\KM-AI-V0-main\\test_weaviate.py”, line 36, in \nresponse = jeopardy.query.hybrid(\n^^^^^^^^^^^^^^^^^^^^^^\nFile “C:\\software_dev_flook\\KM_AI\\KM-AI-V0-main\\myenv\\Lib\\site-packages\\weaviate\\syncify.py”, line 23, in sync_method\nreturn _EventLoopSingleton.get_instance().run_until_complete(\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “C:\\software_dev_flook\\KM_AI\\KM-AI-V0-main\\myenv\\Lib\\site-packages\\weaviate\\event_loop.py”, line 40, in run_until_complete\nreturn fut.result()\n^^^^^^^^^^^^\nFile “C:\\Users\\KHORPPUN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures_base.py”, line 456, in result\nreturn self.__get_result()\n^^^^^^^^^^^^^^^^^^^\nFile “C:\\Users\\KHORPPUN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures_base.py”, line 401, in __get_result\nraise self._exception\nFile “C:\\software_dev_flook\\KM_AI\\KM-AI-V0-main\\myenv\\Lib\\site-packages\\weaviate\\collections\\queries\\hybrid\\query.py”, line 107, in\nhybrid\nres = await self._query.hybrid(\n^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “C:\\software_dev_flook\\KM_AI\\KM-AI-V0-main\\myenv\\Lib\\site-packages\\weaviate\\collections\\grpc\\query.py”, line 769, in __call\nraise WeaviateQueryError(str(e), “GRPC search”)  # pyright: ignore\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\nstatus = StatusCode.UNAVAILABLE\ndetails = “failed to connect to all addresses; last error: UNKNOWN: ipv4:34.98.85.103:443: Ssl handshake failed: SSL_ERROR_SSL: error:1000007d:SSL routines:OPENSSL_internal:CERTIFICATE_VERIFY_FAILED”\ndebug_error_string = “UNKNOWN:Error received from peer  {created_time:“2024-08-22T03:59:45.0595101+00:00”, grpc_status:14, grpc_message:“failed to connect to all addresses; last error: UNKNOWN: ipv4:34.98.85.103:443: Ssl handshake failed: SSL_ERROR_SSL: error:1000007d:SSL routines:OPENSSL_internal:CERTIFICATE_VERIFY_FAILED”}”\n\n----------\n\n[etiennedi (2024-08-22T06:28:02.222Z)]: Hi @Khorppun_Sontipanya\nThanks for the report. Let me see what we can do to help you.\nOne question up front – since you mentioned the connect_to_wcs method – is this a paid cluster or a free sandbox? If it’s a paid cluster you’re also eligible to contact support@weaviate.io – which may lead to faster responses. But also if it’s a free cluster, we’re happy to help you on a best effort basis right here.\nOff the top of my head I can see potential causes:\n\nThere could be some sort of a global SSL issue with Weaviate Cloud. I have already pinged the correct folks to investigate if this is the cause.\nIt could be that something is off with your configuration and the error is an unfortunate error message obscuring the true error.\n\nWe’ll get back to you shortly!\n-Etienne\n\n----------\n\n[pauldegrijp (2024-08-22T07:33:21.254Z)]: Hi @Khorppun_Sontipanya\nWe have investigated Weaviate Cloud, but we do not see any SSL issues. We would like to help you resolve this as soon as possible. Could you please share the endpoint of the Weaviate Cluster you are using you are experiencing the issue with and send it to support@weaviate.io? Thank you.\n\n----------\n\n[Khorppun_Sontipanya (2024-08-22T09:58:19.720Z)]: This is my endpoint :\n‘https://s9qiyurarzso9rrjklwfda.c0.us-central1.gcp.weaviate.cloud’\nNow, I try to use free sandbox.\nThis issue just recently occurred, I never had this issue before. it had never happened before. It only started happening the other day. Could it be related to a Windows update? Because after the Windows update, this problem started. However, some of my friends also have this problem, while others don’t when running the same code as I do.\nThank you for your support.\n\n----------\n\n[DudaNogueira (2024-08-22T13:45:03.402Z)]: hi @Khorppun_Sontipanya !\nWhat is the client version you are using?\nyou can get that information with:\nimport weaviate\nprint(weaviate.__version__)\n\nThanks!\n\n----------\n\n[DudaNogueira (2024-08-23T13:27:43.935Z)]: hi @Khorppun_Sontipanya !!\nCan you check if you have this library in your python environment?\npip freeze | grep certifi\nif you don’t, please, install it:\npip install -U certifi\n\n----------\n\n[Khorppun_Sontipanya (2024-08-27T16:18:01.462Z)]: I checked the version of Weaviate; it is currently version 4.7.1.\nAnd I also have ‘certifi’ in the Python environment, and I’ve already upgraded ‘certifi’.\n\nThank you very much for the effort to help.\n\n----------\n\n[DudaNogueira (2024-08-27T18:03:41.683Z)]: hi @Khorppun_Sontipanya !!\nAre you behind a corporate network by any chance?\nWe have identified some situations where, under this condition, it can affect the client connection.\nWe are working on a PR to with a workaround here:\n  \n\n      github.com/weaviate/weaviate-python-client\n  \n\n  \n    \n\n\n\n    \n      \n    \n\n  \n\n\n\n      \n        Add disable ssl verification to client instantiation \n      \n\n    \n      weaviate:main ← dudanogueira:add-disable-ssl-verification\n    \n\n      \n        \n          opened 10:02PM - 26 Aug 24 UTC\n        \n\n        \n          \n            \n            dudanogueira\n          \n        \n\n        \n          \n            +151\n            -28\n          \n        \n      \n  \n\n\n  \n    Initial work. \nStill need to figure: \n- a way to pass disable_ssl_verification… to aopen in __batch_send method of _BatchBase class.\n- Write some tests or at least check if the httpx client was initiated with the correct verify parameter\n\nThe idea is to print this message on exception with CERTIFICATE_VERIFY_FAILED\n\n            We have identified a SSL CERTIFICATE_VERIFY_FAILED error.\n\n            This error could be due to one of several reasons:\n            - Weaviate client is under a corporate network that terminates ssl and issues it's own certificates.\n            - You have a self signed certificate\n\n            Weaviate python client uses certifi, and because of that, it will not be able to trust\n            Potential fixes:\n            - disable ssl verification by setting using `disable_ssl_verification=True` in client initialization\n                - note that Weaviate will trust any certificate\n            - Replace certifi cacert with the same cacert that is issued by your corporate network.\n                - for example: cat MyCompanyRootCA.pem >> $(python -m certifi)\n\nTo test this, you can rename the cacert.pem inside certifi package, like so:\n\n```python\nimport certifi\nright_path = certifi.where()\nwrong_path = right_path + \"renamed\"\n\nimport os \nos.rename(right_path, wrong_path)\n```\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nTo check if this is your situation, you access your cluster url with chrome, and do the following:\nclick the button at the left side of the url. click at Connection is secure:\nimage1052×872 105 KB\nand finally at Certificate is valid\nimage724×578 60.5 KB\nthis is the information you should see (of course, some details may change due to the AZ your cluster is at):\nimage1090×1156 83.1 KB\nIf you see anything other than Issued By “Google Trust Services”, you probably have a networking configuration that is terminating your SSL in between the client and server.\nIn this scenario, the CA CERT provided by certifi will not trust that issuer.\nAs a workaround you can replace certifi’s cacert.pm with the one you have.\nyou can find where this file is located issuing the following command:\npython -m certifi\n\nLet me know if this helps!\nThanks",
    "date_created": "2024-08-22T04:14:44.126Z",
    "has_accepted_answer": false,
    "title": "SSL Verification failure",
    "topic_id": 3428
  },
  {
    "user_id": 509,
    "conversation": "[2020ashish (2024-03-21T11:41:20.329Z)]: Description\n\nAs mentioned here\nA cross-reference can be added from a multi-tenancy collection object to:\n\nA non-multi-tenancy collection object,\n\nproblem Statement:\nI have two class A { price, Has_Item}  &  B { item} .\nA with multi tenancy and B with without it.\nI have CrossRef from A → B\nWhen I tried to fetch information from\njeopardy = client.collections.get(“A”).with_tenant(‘1234’)\nresponse = jeopardy.query.fetch_objects(\nreturn_references=wvc.query.QueryReference(link_on=“Has_Item”, return_properties=[“item”]),\nreturn_properties=[‘price’]\n)\nfor o in response.objects:\nprint(o.properties)\nprint(o.references[“Has_Item”].objects[0].properties[“item”])\nAbove query gives error such as\nlist class: search: resolve cross-refs: build reference cache: build request cache: fetch job list: index “B”: class B has multi-tenancy disabled, but request was with tenant.\nHow should i read those object as weaviate already mentioned they are supporting this type of cross-ref ?\nServer Setup Information\n\nWeaviate Server Version: latest version\nClient Language and Version:  V4\n\n----------\n\n[DudaNogueira (2024-03-21T19:01:04.716Z)]: Hi!\nThis scenario is interesting to create a notebook so it gets easily reproducible.\nI will be away the next couple days, but could do that when I get back.\nThanks!\n\n----------\n\n[2020ashish (2024-03-28T15:14:14.944Z)]: I’m waiting for your response ?\n\n----------\n\n[2020ashish (2024-04-01T12:19:09.446Z)]: Help me solve this puzzle\n\n----------\n\n[DudaNogueira (2024-04-05T21:18:10.490Z)]: hi @2020ashish ! Really sorry.\nI was out those days and only got back now \nWere you able to reproduce something?\n\n----------\n\n[2020ashish (2024-04-06T17:42:19.941Z)]: No, still on same page.\n\n----------\n\n[2020ashish (2024-05-10T05:00:46.934Z)]: @DudaNogueira  Kindly take a look at this above one.\n\n----------\n\n[2020ashish (2024-06-27T11:34:55.299Z)]: @DudaNogueira Please take a look on this status on this.\n\n----------\n\n[DudaNogueira (2024-06-27T13:26:04.192Z)]: hi @2020ashish !! Sorry here again \nI was able to reproduce this:\nfrom weaviate.classes import config\n\ncollection_b = client.collections.create(\n    \"CollectionB\",\n    properties=[\n        config.Property(name=\"text\", data_type=config.DataType.TEXT)\n    ]\n)\n\ncollection_a = client.collections.create(\n    \"CollectionA\",\n    multi_tenancy_config=config.Configure.multi_tenancy(\n        enabled=True, auto_tenant_creation=True, auto_tenant_activation=True\n    ),\n    properties=[\n        config.Property(name=\"price\", data_type=config.DataType.TEXT)\n    ],\n    references=[\n        config.ReferenceProperty(\n            name=\"has_item\", target_collection=\"CollectionB\"\n        )]\n)\n\nfrom weaviate.util import generate_uuid5\n# add some content for classB, non multi tenant - Item\ncollection_b.data.insert({\"text\": \"computer\"}, uuid=generate_uuid5(\"computer\"))\ncollection_b.data.insert({\"text\": \"mouse\"}, uuid=generate_uuid5(\"mouse\"))\n\n# now we get the collection with tenant 1234\ncollection_a_tenant = collection_a.with_tenant(\"1234\")\n#classa_tenant = class_a\n\n# now we add an object, cross referencing a non tenant collection\ncollection_a_tenant.data.insert(\n    properties={\"price\": \"1\"},\n    references={\"has_item\": generate_uuid5(\"computer\")}\n)\n\nfrom weaviate.classes import query\nresult = collection_a_tenant.query.fetch_objects(\n    return_references=query.QueryReference(\n       link_on=\"has_item\", return_properties=[\"text\"]\n    )\n)\n\n\nthe error:\n\nWeaviateQueryError: Query call with protocol GRPC search failed with message explorer: list class: search: resolve cross-refs: build reference cache: build request cache: fetch job list: index “collectionb”: class CollectionB has multi-tenancy disabled, but request was with tenant.\n\nLet me know if this is close to what you are after.\nAccording to docs. it should be possible to cross reference a non multi tenant collection (on this case, ClassB):\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMulti-tenancy operations | Weaviate - Vector Database\n\n  Multi-tenancy provides data isolation. Each tenant is stored on a separate shard. Data stored in one tenant is not visible to another tenant. If your application serves many different users, multi-tenancy keeps their data private and makes database...\n\n----------\n\n[DudaNogueira (2024-06-27T13:29:03.609Z)]: Ps: I also tried pyv3 version:\nclientv3 = weaviate.Client(\"http://localhost:8080\")\nresponse = (\n    clientv3.query\n    .get(\n        \"ClassA\",\n        [\"price\", \"has_Item { ... on ClassB { text } }\"],\n    )\n    .with_limit(2).with_tenant(\"1234\").do()\n)\n\nand got a similar error ( but the check was inverted)\n\n{‘data’: {‘Get’: {‘ClassA’: None}},\n‘errors’: [{‘locations’: [{‘column’: 6, ‘line’: 1}],\n‘message’: ‘explorer: list class: search: resolve cross-refs: build reference cache: build request cache: fetch job list: index “classb”: class ClassB has multi-tenancy disabled, but request was with tenant’,\n‘path’: [‘Get’, ‘ClassA’]}]}\n\n----------\n\n[2020ashish (2024-06-27T14:02:57.074Z)]: yes it is same think.\nplease check  if it is possible to fetch data as mentioned in document.\n\n----------\n\n[Paul_Hechinger (2024-07-20T22:25:31.089Z)]: Hey, has this issue been fixed?\n\n----------\n\n[DudaNogueira (2024-07-23T12:42:06.994Z)]: hi @Paul_Hechinger !!\nWelcome to our community \nWe have reproduced this and have a GH issue here:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      WeaviateQueryError when searching for objects stored as a refrence property in a multitenant collection or schema\n    \n\n    \n      \n        opened 11:55AM - 02 Jul 24 UTC\n      \n\n\n      \n        \n          \n          rthiiyer82\n        \n      \n    \n\n    \n        \n          bug\n        \n    \n  \n\n\n  \n    ### How to reproduce this bug?\n\nAs per the weaviate documentation one should be …able to cross reference from a multi tenant to a non multi tenant.\n\nRun the below script\n```\nimport random\nimport string\nfrom weaviate.classes.config import Property, DataType, ReferenceProperty\nimport weaviate\nimport weaviate.classes.config as wvc\nfrom weaviate.classes.tenants import Tenant\nfrom weaviate.classes.query import QueryReference\n\nclient = weaviate.connect_to_local()\n\n# Create collection\nif (client.collections.exists(\"JeopardyCategory\")):\n  # delete collection \"Article\" - THIS WILL DELETE THE COLLECTION AND ALL ITS DATA\n  client.collections.delete(\"JeopardyCategory\")  # Replace with your collection name\n\n# Create collection\nif (client.collections.exists(\"JeopardyQuestion\")):\n  # delete collection \"Article\" - THIS WILL DELETE THE COLLECTION AND ALL ITS DATA\n  client.collections.delete(\"JeopardyQuestion\")  # Replace with your collection name\n\n\ncategory = client.collections.create(\n    name=\"JeopardyCategory\",\n    description=\"A Jeopardy! category\",\n    properties=[\n        Property(name=\"title\", data_type=DataType.TEXT)\n    ],\n     replication_config=wvc.Configure.replication(factor=1),\n    \n)\n\n\njeopardy_question= client.collections.create(\n    name=\"JeopardyQuestion\",\n    description=\"A Jeopardy! question\",\n    properties=[\n        Property(name=\"question\", data_type=DataType.TEXT),\n        Property(name=\"answer\", data_type=DataType.TEXT),\n    ],\n    references=[\n        ReferenceProperty(\n            name=\"hasCategory\",\n            target_collection=\"JeopardyCategory\"\n        )\n    ],\n    replication_config=wvc.Configure.replication(factor=1),\n    multi_tenancy_config=wvc.Configure.multi_tenancy(enabled=True, auto_tenant_creation=True, auto_tenant_activation=True)\n\n)\n\n# Create tenant on JeopardyQuestion\njeopardy_question.tenants.create(\n    tenants=[\n        Tenant(name=\"tenantA\"),\n        Tenant(name=\"tenantB\"),\n    ]\n)\n\n# Insert objects to the collection\ndef get_random_string(length):\n    # choose from all lowercase letter\n    letters = string.ascii_lowercase\n    result_str = ''.join(random.choice(letters) for i in range(length))\n    return result_str\n    # print(\"Random string of length\", length, \"is:\", result_str)\n\n# Add category to JeopardyCategory\n\njeopardy = client.collections.get(\"JeopardyCategory\")\n\ncategory_uuid = jeopardy.data.insert({\n    \"title\": get_random_string(10)\n})\n\nquestions= jeopardy_question.with_tenant(tenant=\"tenantA\")\n\nquestions.data.insert({\n    \"question\": \"question\" + get_random_string(10),\n    \"answer\" : \"answer\"+ get_random_string(10)\n},\n    references={\"hasCategory\": category_uuid},  # e.g. {\"hasCategory\": \"583876f3-e293-5b5b-9839-03f455f14575\"}\n)\n\nresponse = questions.query.fetch_objects(return_references=QueryReference(link_on=\"hasCategory\", return_properties=[\"question\", \"answer\"]))\n\nfor o in response.objects:\n    print(o.properties)\n\nclient.close()\n\n```\n\n### What is the expected behavior?\n\nNo error should be displayed and user should be able to query the reference property in a multitenant collection.\n\n### What is the actual behavior?\n\n```\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n        status = StatusCode.UNKNOWN\n        details = \"explorer: list class: search: resolve cross-refs: build reference cache: build request cache: fetch job list: index \"jeopardycategory\": class JeopardyCategory has multi-tenancy disabled, but request was with tenant\"\n        debug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-07-01T19:38:14.318273+01:00\", grpc_status:2, grpc_message:\"explorer: list class: search: resolve cross-refs: build reference cache: build request cache: fetch job list: index \\\"jeopardycategory\\\": class JeopardyCategory has multi-tenancy disabled, but request was with tenant\"}\"\n>.\n\n```\n\n### Supporting information\n\nhttps://weaviate.io/developers/weaviate/manage-data/multi-tenancy#cross-references\n\n### Server Version\n\n1.25.6\n\n### Code of Conduct\n\n- [X] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nOur team will look into this as soon as they have capacity!\nThanks!",
    "date_created": "2024-03-21T11:41:20.262Z",
    "has_accepted_answer": false,
    "title": "Multi-tenant cross-reference",
    "topic_id": 1784
  },
  {
    "user_id": 3434,
    "conversation": "[cfloressuazo (2025-03-18T01:46:50.270Z)]: Description\nHi,\nI’ve deployed Weaviate in a kubernetes cluster using the Helm chart and custom values in the values.yaml file. I have deployed the first time an API key for the text2vec-openai module which is no longer valid. I have updated the value with a new api key, which works (confirmed that is working), but it seems like the older api key is still being used, even after applying the help upgrade... command. Has anyone faced the same issue, and if so, how could I fix this, so that changes such as the API key are effective after applying the helm upgrade ... command?\nServer Setup Information\n\nWeaviate Server Version: 1.29.0\nDeployment Method: k8s via Helm chart\nMulti Node? Number of Running Nodes: 2\nClient Language and Version: Python v4\nMultitenancy?: No\n\nAny additional Information\nThe following is a log that demonstrate the error:\nWeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"explorer: get class: concurrentTargetVectorSearch): explorer: get class: vectorize search vector: vectorize params: vectorize params: vectorize keywords: remote client vectorize: connection to: OpenAI API failed with status: 429 request-id: req_2d22fee09e16eeda10ced1b3692e9339 error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"explorer: get class: concurrentTargetVectorSearch): explorer: get class: vectorize search vector: vectorize params: vectorize params: vectorize keywords: remote client vectorize: connection to: OpenAI API failed with status: 429 request-id: req_2d22fee09e16eeda10ced1b3692e9339 error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", grpc_status:2, created_time:\"2025-03-17T22:37:42.023459-03:00\"}\"\n>.\n\nThe following is the values.yaml configuration of the api key:\n...\n  text2vec-openai:\n    enabled: true\n    apiKey: 'xxxxxxxxx' (it was yyyyy before)\n...\n\nThanks\n\n----------\n\n[Mohamed_Shahin (2025-03-18T12:03:34.448Z)]: @cfloressuazo That’s strange.\nCould you try storing them according to the following and see if that helps?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAuthentication | Weaviate\n\n  Authentication and authorization are closely related concepts, and sometimes abbreviated as AuthN and AuthZ. Authentication (AuthN) is the process of verifying the identity of a user, while authorization (AuthZ) is the process of determining what...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWhen you do any changes, running the following should apply the update:\nhelm upgrade --install \\\n  \"weaviate\" \\\n  weaviate/weaviate \\\n  --namespace \"weaviate\" \\\n  --values ./values.yaml\n\n----------\n\n[DudaNogueira (2025-03-18T12:15:07.733Z)]: Hi @cfloressuazo !!\nWhen you edit the open ai key as well as any other key or option that will end up as an env var in your helm chart values.yaml, it kubernetes will update the secret.\nHowever, it will not trigger a restart. And we need that!\nSo after updating your values in helm chart, and upgrading your helm deployment, you need to rollout a restart in your Weaviate cluster:\nkubernetes rollout restart statefulset/weaviate -n weaviate\n\nLet me know if this helps!\n\n----------\n\n[cfloressuazo (2025-03-18T14:01:57.091Z)]: Yes this did the trick. Thanks!",
    "date_created": "2025-03-18T01:46:50.224Z",
    "has_accepted_answer": true,
    "title": "API Key change in values.yaml when deploying Weaviate in k8s does not update in the cluster",
    "topic_id": 19969
  },
  {
    "user_id": 1236,
    "conversation": "[ctindel (2024-07-25T19:43:40.371Z)]: Description\nI am connecting with these timeout settings:\nclient = weaviate.connect_to_local(\n    headers=headers,     \n    additional_config=AdditionalConfig(\n        timeout=Timeout(init=30, query=60, insert=120)  # Values in seconds\n    )\n)\n\nI am using the dynamic batch functionality which I specifically thought would rate limit itself to avoid any timeout issues, but I am seeing these types of errors at the end of my batch:\nFailed to import object with error: %s \"ErrorObject(message=‘WeaviateBatchError(\\‘Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\\\n\\\\tstatus = StatusCode.DEADLINE_EXCEEDED\\\\n\\\\tdetails = \"Deadline Exceeded\"\\\\n\\\\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-07-25T15:35:02.96801-04:00\", grpc_status:4, grpc_message:\"Deadline Exceeded\"}\"\\\\n>.\\’)’, object_=_BatchObject(collection=‘Product’, vector=None, uuid=‘190f46bd-9a54-5a77-8463-b4845e0e4384’, properties=\n…\nI can see that the count of objects doesn’t match the number that went into the batch processor (it’s off by almost half), so I’m guessing there is a timeout going into the vectorizer and so the object fails to insert?\nIs there a different timeout I should be setting (infinite?) or some other way I should be throttling or retrying these things?\nDo you advise people to infinitely loop over the failed batch objects and retry them until the failed batch array is empty?\n\n----------\n\n[DudaNogueira (2024-07-25T20:26:51.409Z)]: hi @ctindel !!\nIf with the default timeout settings you are seeing timeouts and errors in batch imports, the problem is usually on the resource you have allocated or the network connection between those parties.\nThis message doesn’t indicate the timeout occurred between Weaviate and the inference model api, but from the client to the server.\nDo you have any observability in place for this setup? What are the cpu and memory readings?\nLet me know if this helps!\nThanks!\n\n----------\n\n[ctindel (2024-07-25T21:15:03.463Z)]: This is all just running directly on my laptop, python on the macos and weaviate inside of docker.\nI did set the insert timeout to 120 seconds as you can see, are you saying its taking longer than 120 seconds to insert even though i’m using the throttled dynamic batch functionality?\nWhen I looked at Activity Monitor, between qemu and LM Studio but the CPU and GPU are pretty busy but the system is still very responsive.\nI’ve given colima 4 CPUs and 12 GB RAM, not sure if the weaviate process needs more than to handle a single batch insertion thread?\n\n----------\n\n[ctindel (2024-07-25T21:47:03.249Z)]: Also are there any examples anywhere of looping over the failed object array and re-inserting them? I am having trouble finding code samples that show how to properly deal with the WeaviateBatchError() object type. Do you just peek into the private object_ property and replay it from there?\n\n----------\n\n[DudaNogueira (2024-07-26T23:40:09.651Z)]: The indexing part is very CPU bound. So maybe it is having a hard time processing both indexing, the vectorization and answering those query/ingestion requests.\nOn top of the resources you gave to colima, it is interesting to play around with some resource limiting env vars:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nResource Planning | Weaviate - Vector Database\n\n  Weaviate scales well for large projects. Smaller projects, less than 1M objects, do not require resource planning. For medium and large-scale projects, you should plan how to get the best performance from your resources. While you design you system,...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWe have some error handling tips you can do while importing, but we indeed can improve the docs on advanced batching tips and tricks.\nThere is a Spark connector, that can be used to create a more robust pipeline and I recall some other tools too.\nFor example, some time ago, we had this awesome integration between quix and weaviate:\n\n  \n    \n  \n\n\nLet me know if this helps!",
    "date_created": "2024-07-25T19:43:40.323Z",
    "has_accepted_answer": false,
    "title": "Vectorizer Timeout settings and behavior",
    "topic_id": 3174
  },
  {
    "user_id": 655,
    "conversation": "[alisha_liu (2025-01-16T01:12:07.864Z)]: I want to integrate cohere reranker into weaviate typescript version, and the cohere reranker is provided by AWS, how can i achieve my goal?\nIf yes, can i dynamic enable reranker or disable rerank on each query based on one collection?\n\n----------\n\n[Mohamed_Shahin (2025-01-16T09:53:40.909Z)]: Hi @alisha_liu,\nHere is how you can configure the Renaker integration we have with Cohere:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nReranker | Weaviate\n\n  Cohere Reranker Model Provider\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nCurrently, there isn’t an integration available for ReRanker using models provided by AWS.\nRegards,\nMohamed Shahin\nWeaviate Support Engineer",
    "date_created": "2025-01-16T01:12:07.822Z",
    "has_accepted_answer": true,
    "title": "Does weaviate support reranker model provided by aws in typescript version?",
    "topic_id": 9795
  },
  {
    "user_id": 655,
    "conversation": "[alisha_liu (2024-08-28T21:59:09.747Z)]: Description\n1 Upgrade the typescript  client library from v2 to v3, does the previous v2 code still work?\n2 Upgrade the python client library from v3 to v4, does the previous v3 code still work?\n\n----------\n\n[Mohamed_Shahin (2024-08-30T15:09:22.912Z)]: Hello @alisha_liu,\nWe are always working on features and improvements in our clients to best developer experience.\nYou probably come across that the Weaviate Python client to an extensively re-written (and improved) v4 API around six months ago. Up until now, the v4 client versions had included the older v3 API in order to ease the transition.\nStarting in December 2024, the v4 client will no longer include the v3 API (i.e. the weaviate.Client class). This will help us to provide the best developer experience for you, support for the latest features, and clearly separate the two.\nThe v3 client will continue to get critical security updates and bugfixes for the foreseeable future, but it will not support any new features.\nTo take advantage of the latest developments on the Weaviate core database, we recommend migrating your codebase to use the v4 API.\nIf you have an existing codebase and Weaviate core database that you expect to remain static, we recommend pinning the version in your requirements file (e.g. requirements.txt), like so:\n  weaviate-client>=3.26.7,<4.0.0\n\nI hope this helps\nHave a lovely weekend!",
    "date_created": "2024-08-28T21:59:09.702Z",
    "has_accepted_answer": true,
    "title": "Upgrade weaviate client, does previous code still work?",
    "topic_id": 3885
  },
  {
    "user_id": 934,
    "conversation": "[saurbhhsharrma (2024-07-11T09:40:27.367Z)]: As per the Weaviate documentation, a newly added property to a Collection/Schema doesn’t allow re-indexing of the data that is inserted in newly added properties of already existing objects.\nimage1065×519 45.3 KB\nAs per my understanding, updating the newly added properties of existing objects in Weaviate won’t index the data.\nIf we use Replace for this scenario. Does it index the data?\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nUpdate objects | Weaviate - Vector Database\n\n  Weaviate allows partial or complete object updates.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nServer Setup Information\n\nWeaviate Server Version: 1.25.7\nDeployment Method:Docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python\nMultitenancy?: Yes\n\n@DudaNogueira\n\n----------\n\n[Mohamed_Shahin (2024-07-11T10:01:53.894Z)]: Hi @saurbhhsharrma,\nThe Replace operation allows for replacing the entire object but does not trigger re-indexing for new properties added after the initial import. Therefore, using Replace will not help in indexing the newly added properties of existing objects.\nCurrently, the only way to ensure the new property is indexed for existing data is to delete the collection and re-import it with the new property. This will build the entire vector space properly for the collection.\nWe are working on a re-indexing API for future releases to address this.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection schema | Weaviate - Vector Database\n\n  Introduction\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHave a lovely week!\n\n----------\n\n[saurbhhsharrma (2024-07-11T10:16:17.688Z)]: Thanks @Mohamed_Shahin for the quick response.\nI understand that Weaviate is working on Re-indexing API. However, deleting the collection and re-import it with the new property will be quite expensive operation in all aspects.\nAssuming that we have objects on a single shard, can we delete the shard and re-import the data to re-index the newly added fields.\nAdditionally, would you be able to share the roadmap for the re-indexing API? I understand this might be a common issue, and any information you can provide would be greatly appreciated.\n\n----------\n\n[Mohamed_Shahin (2024-07-11T14:42:47.818Z)]: @saurbhhsharrma  I am not sure if deleting the shard would work! however I am digging a bit into if there is a way around until the feature is implemented! Also seeking to know when we plan to release such feature. I will let you know once I hear something from our engineers.\n\n----------\n\n[saurbhhsharrma (2024-07-11T14:55:38.560Z)]: Thanks alot @Mohamed_Shahin. It’ll be a great help for us.\n\n----------\n\n[Mohamed_Shahin (2024-07-15T07:33:16.235Z)]: Hey @saurbhhsharrma,\nI hope you had a good weekend!\nWe’ve this open request Reindex API (Inverted Index) · Issue #2359 · weaviate/weaviate · GitHub\ngive it a thumb up as we are increasing its priority on our roadmap.\n\n----------\n\n[saurbhhsharrma (2024-07-15T09:52:14.902Z)]: Thanks @Mohamed_Shahin for sharing the roadmap. It will be a great help.",
    "date_created": "2024-07-11T09:40:27.318Z",
    "has_accepted_answer": true,
    "title": "Alternate to Reindexing of existing records",
    "topic_id": 3013
  },
  {
    "user_id": 2022,
    "conversation": "[Ahmed_Mahmoud (2025-01-07T07:55:21.186Z)]: we have added the following ref property, now wondering how to remove it without recreating the collection and losing data.\nfrom weaviate.classes.config import ReferenceProperty\ncategory = client.collections.get(“Rechtspraak_nl”)\ncategory.config.add_reference(\nReferenceProperty(\nname=“extracted_content_outline”,\ntarget_collection=“Rechtspraak_nl_metadata”\n)\n)\nso is there a way using python client to remove this refrence ?\n\n----------\n\n[Dirk (2025-01-07T09:54:28.676Z)]: Hello!\nRemoving properties (data and references) is not possible. You’d have to create a new collection and transfer your data over. Or simply ignore that the reference property is there\n\n----------\n\n[Ahmed_Mahmoud (2025-01-07T10:21:15.777Z)]: Thanks for the fast reply.\nHow to transfer your data over from one collection to another , is it easy ?\nOr simply ignore that the reference property is there\nI wish to ignore it, however, I am currently getting error when appending to the schema getting the following error:\ncode to append:\nto_add.withColumnRenamed(“id”, “uuid”) \n.write.format(“io.weaviate.spark.Weaviate”) \n.option(“batchSize”, 200) \n.option(“scheme”, “http”) \n.option(“host”, weaviate_url) \n.option(“id”, “uuid”) \n.option(“grpc:host”, “10.2.0.13:50051”) \n.option(“grpc:secured”, “false”) \n.option(“className”, schema[‘class’]) \n.mode(“append”).save()\nError:\n[INCOMPATIBLE_DATA_FOR_TABLE.CANNOT_FIND_DATA] Cannot write incompatible data for the table Rechtspraak_nl: Cannot find data for the output column ecli_uuid. SQLSTATE: KD000\nDiagnose errorHighlight error\nAnd the schema have 2 references that we added recently :\n“references”: [\n{\n“name”: “ecli_uuid”,\n“description”: null,\n“target_collections”: [\n“Rechtspraak_nl_metadata”\n]\n},\n{\n“name”: “extracted_content_outline”,\n“description”: null,\n“target_collections”: [\n“Rechtspraak_nl_metadata”\n]\n}\n],\n\n----------\n\n[Ahmed_Mahmoud (2025-01-07T11:02:54.214Z)]: should we add 2 empty columns for the 2 references in the datafram when writing to weaviate ?\n\n----------\n\n[Dirk (2025-01-07T12:56:59.379Z)]: In the python client you could just leave it out. Not sure about the spark connector, I’ll ping someone\n\n----------\n\n[Ahmed_Mahmoud (2025-01-07T13:32:45.000Z)]: btw if we have 2 collections\none for document data (id, chunks) and one for document metadata (id, summery, …)\nwe want to connect the collections using references, to avoid duplicating all the metadata for each chunk/row.\nin this case we create the reference based on the document unique id or based on the specific fields we need from metadata collection ?\nso for example:\nfrom weaviate.classes.config import ReferenceProperty\ncategory = client.collections.get(“document_data”)\ncategory.config.add_reference(\nReferenceProperty(\nname=“document_id”,\ntarget_collection=“document_metadata” ) )\nor we create the reference based on the specific fields we need :\nfrom weaviate.classes.config import ReferenceProperty\ncategory = client.collections.get(“document_data”)\ncategory.config.add_reference(\nReferenceProperty(\nname=“document_summary”,\ntarget_collection=“document_metadata” ) )\nAnd how we insert in different cases ?",
    "date_created": "2025-01-07T07:55:21.131Z",
    "has_accepted_answer": false,
    "title": "How to remove reference property",
    "topic_id": 9600
  },
  {
    "user_id": 1593,
    "conversation": "[Praveenkasani (2024-09-25T08:31:50.369Z)]: Hi Team,\nI want to fetch results for mis-spelled words i.e. when a user types ‘sprate’ instead of ‘sprite’ search, he has to see the results for ‘sprite’. Another example would be when user types ‘man’ instead of ‘men’, he has to see results for ‘men’.\nI tried few examples in python using ‘with_near_text’ and the below query but couldn’t get the results that I’m expecting. Could you please let me know what exactly is the query for my usecase?\nDefine the near_text query\nnear_text = {\n“concepts”: [“man”],  # Correct the spelling here\n}\nPerform the query\nresult = (\nclient.query\n.get(“TGIDICTIONARY3”, [“answerlabels”,“questionlabel”] )\n.with_near_text(near_text)\n.do()\n)\nPrint the results\nprint(result)\nThanks for your Help in Advance !!!\n\n----------\n\n[Mohamed_Shahin (2024-09-25T12:53:22.583Z)]: Hi @Praveenkasani,\nWelcome to our community, and it’s lovely to have you here!\nBased on what you described, you can leverage the Weaviate text-spellcheck module to handle cases where a user types a misspelled word.\nYou can explore more here: Weaviate Spellcheck Module\nAlso, you can experiment with near_text certainty to fine-tune the matching accuracy.",
    "date_created": "2024-09-25T08:31:50.321Z",
    "has_accepted_answer": false,
    "title": "Python V3 query for getting results of mis-spelled words search",
    "topic_id": 4304
  },
  {
    "user_id": 1954,
    "conversation": "[Devalci_Santos (2024-10-16T13:16:06.590Z)]: Azureopenai with WeaViate (Insert and Search data) + Rag Azureopenai. Combined WeaViate with a RAG from my company (RAG in Azure). Is it possible?\n\n----------\n\n[DudaNogueira (2024-10-21T22:05:41.500Z)]: Hi @Devalci_Santos !\nSure!\nHere we have a recipe for doing that:\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/llm-frameworks/langchain/loading-data at main ·...\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWhile it uses a different vectorizer and generative modules, you can easily use any other model providers that Weaviate supports:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nModel provider integrations | Weaviate\n\n  Weaviate integrates with a variety of self-hosted and API-based models from a range of providers.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps and how else I can assist you further!\nThanks!\n\n----------\n\n[Devalci_Santos (2024-10-23T01:56:38.213Z)]: Muito obrigado! Thanks!!",
    "date_created": "2024-10-16T13:16:06.542Z",
    "has_accepted_answer": true,
    "title": "Azureopenai with WeaViate (Insert and Search data) + Rag Azureopenai. Combined WeaViate with a RAG from my company (RAG in Azure). Is it possible?",
    "topic_id": 5632
  },
  {
    "user_id": 990,
    "conversation": "[moaabid (2024-08-14T17:16:15.598Z)]: Hi.\nI have jewellery dataset around 3000 products. Single product has around 15 images and details. I wanted to do the hybrid search so how to structure it and store the data in the vector DB?.\nHave to store each image with same description? or is there a way to group the image and description based on the sku?.\n\n----------\n\n[DudaNogueira (2024-08-14T19:13:02.457Z)]: hi @moaabid !!\nYou could use multi2vec-clip, and define a collection with properties details, image1, image2, …\nHere is how using the new python v4 client:\ncollection = client.collections.create(\n    \"Jewellery\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.multi2vec_clip(\n        image_fields=[\n            wvc.config.Multi2VecField(name=\"image1\", weight=0.3),\n            wvc.config.Multi2VecField(name=\"image2\", weight=0.3)\n            #...\n        ],\n        text_fields=[\n            wvc.config.Multi2VecField(name=\"details\", float=0.7)\n        ]\n        \n    ),\n    properties=[\n        wvc.config.Property(name=\"details\", data_type=wvc.config.DataType.TEXT),\n        wvc.config.Property(name=\"image1\", data_type=wvc.config.DataType.BLOB),\n        wvc.config.Property(name=\"image2\", data_type=wvc.config.DataType.BLOB),\n        # ...\n    ]\n)\n\nWhat will happen “under the hood” is that Weaviate will combine all those vectors into one, taking into account the weights you specified.\nHere is where this “magic” take place:\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate/blob/502456b502bbffac6f47e880eb1343662c5be16e/modules/multi2vec-clip/vectorizer/vectorizer.go#L114\n\n\n\n    \n      \n          \t\t\treturn nil, err\n          \t\t}\n          \t\tvectors = append(vectors, res.TextVectors...)\n          \t\tvectors = append(vectors, res.ImageVectors...)\n          \t}\n          \tweights, err := v.getWeights(ichek)\n          \tif err != nil {\n          \t\treturn nil, err\n          \t}\n          \n          \treturn libvectorizer.CombineVectorsWithWeights(vectors, weights), nil\n          }\n          \n          func (v *Vectorizer) getWeights(ichek ClassSettings) ([]float32, error) {\n          \tweights := []float32{}\n          \ttextFieldsWeights, err := ichek.TextFieldsWeights()\n          \tif err != nil {\n          \t\treturn nil, err\n          \t}\n          \timageFieldsWeights, err := ichek.ImageFieldsWeights()\n          \tif err != nil {\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[DudaNogueira (2024-08-14T19:14:55.320Z)]: Regarding the sku, you can use deterministic ids to make sure each product is unique:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCreate objects | Weaviate - Vector Database\n\n  The examples on this page demonstrate how to create individual objects in Weaviate.\n\n----------\n\n[moaabid (2024-09-25T16:54:15.257Z)]: @DudaNogueira\nInstead of statically mentioning image1, image2. Is there an array of blob datatype?. Some of the product can have 3 images and other products can have more than that. So it will dynamic.\n\n----------\n\n[moaabid (2024-09-26T02:24:35.643Z)]: Example\nsku1\n\nImage1\nImage2\nsku2\nImage1\nImage2\nImage3\nsku3\nImage1\nimage2\nimage3\nimage4\n\nIf i store the images individually and i tried to get the response for the input image.\nreponse - [{sku1, image1}, {sku2, image1}, {sku1, image2}, {sku3, image4}]\nmay be sku2 image 1 is closer than the sku1, image2. But i need a response grouping by the sku\nresponse  - [{sku1}, {sku2}, {sku3}]\nor if there is a way to store multiple images dynamically under one sku. If the input images matches anyone of the image in the array should return the sku. this way the results will have unique data.\nOr it has to be handled in the code?. retrieving 50 data and find unique value based on sku\n\n----------\n\n[DudaNogueira (2024-09-30T15:10:02.970Z)]: I believe you can try using cross references, so you can have a dynamic number of images to store:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCross-references | Weaviate\n\n  Use cross-references to establish directional relationships between collections.\n\n----------\n\n[moaabid (2024-10-01T03:32:42.760Z)]: Thanks @DudaNogueira. Actually i wanted to group the result based on sku. There is a group by option in weaviate. Now i’m store the images individually and group it by sku",
    "date_created": "2024-08-14T17:16:15.558Z",
    "has_accepted_answer": true,
    "title": "How to store data in the weaviate vector DB",
    "topic_id": 3350
  },
  {
    "user_id": 1612,
    "conversation": "[Sumat_Mallick (2024-09-30T10:27:49.780Z)]: Description\nWe are moving from v3 to v4. Now, when I use batch upload or multi-insert, I get an error message saying the text is too long for vectorization.\nCan anyone help me regarding this?\nBelow is my code.\ndef vectorize_tag_page_data(texts, class_name, layer_name):\n# Append layer suffix to class name\nclass_name = f\"{class_name}01pagedata\"\n\n# Load configuration from environment variables\nweaviate_url = os.getenv(f\"URL\")\nweaviate_auth_key = os.getenv(f\"AUTH_KEY\")\nopenai_key = os.getenv(\"OPENAI_API_KEY\")\n\nif not weaviate_url or not weaviate_auth_key or not openai_key:\n    raise EnvironmentError(\"One or more required environment variables are missing\")\n\n# Prepare data objects for insertion\ndata_objs = [{\"text\": texts[key], \"metadata\": key} for key in texts]\ntotal = len(data_objs)\n\nprint(f\"\\n{total} data objects prepared for insertion.\\n\")\nprint(f\"Layer URL: {weaviate_url}\")\n\n# Initialize client with authentication\nclient = initialize_weaviate_client(weaviate_url, weaviate_auth_key, openai_key)\n\n# Create collection in Weaviate\ntry:\n    response = client.collections.create(\n        name=class_name,\n        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n        properties=[\n            wvc.config.Property(name=\"text\", data_type=wvc.config.DataType.TEXT),\n            wvc.config.Property(name=\"metadata\", data_type=wvc.config.DataType.TEXT),\n        ],\n    )\n    print(response.config.get(simple=False))\nexcept Exception as e:\n    print(f\"Error while creating collection: {e}\")\nfinally:\n    client.close()\n\n# Reinitialize client for data insertion\nclient = initialize_weaviate_client(weaviate_url, weaviate_auth_key, openai_key)\n\n# Insert data using batching\ntry:\n    collection = client.collections.get(class_name)\n    with collection.batch.dynamic() as batch:\n        print(\"Batch insertion started.\")\n        for i, data_obj in enumerate(data_objs, 1):\n            batch.add_object(properties=data_obj)\n            print(f\"Uploaded Tag Data: {i}/{total}\")\n\n        # Check for batch insertion errors\n        if batch.number_errors > 0:\n            print(f\"Number of errors during batch insertion: {batch.number_errors}\")\n        else:\n            print(\"Batch insertion completed successfully.\")\n\n    # Optional: Verify insertion by querying the collection\n    try:\n        result = collection.query.bm25(query=\"genAI\", limit=10)\n        print(\"\\nQuery Results:\", result)\n    except Exception as e:\n        print(f\"Error while querying: {e}\")\nexcept Exception as e:\n    print(f\"An exception occurred: {e}\")\nfinally:\n    if client is not None:\n        client.close()\n\ndef initialize_weaviate_client(url, auth_key, openai_key):\nclient = wvc.Client(\n    url=url,\n    auth_client_secret=wvc.AuthApiKey(api_key=auth_key),\n    additional_headers={\n        \"X-OpenAI-Api-Key\": openai_key\n    }\n)\nreturn client\n\nServer Setup Information\n\nWeaviate Server Version: 4.8.1\nDeployment Method:  I am using on python directly\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python 3.12.3\nMultitenancy?:\n\nAny additional Information\n[ErrorObject(message=“WeaviateInsertManyAllFailedError(‘Every object failed during insertion. Here is the set of all errors: text too long for vectorization’)”, object_=BatchObject(collection=‘Sswhhsdflesdfesssssr01pagedata’, vector=None, uuid=‘fb5fc0a6-f652-4e64-bc36-d1bcc0536e0b’, properties={‘text’: ‘a’, ‘metadata’: ‘name1’}, tenant=None, references=None, index=0, retry_count=0), original_uuid=None), ErrorObject(message=“WeaviateInsertManyAllFailedError(‘Every object failed during insertion. Here is the set of all errors: text too long for vectorization’)”, object=_BatchObject(collection=‘Sswhhsdflesdfesssssr01pagedata’, vector=None, uuid=‘e21581f3-c7dd-447b-b240-bf566314eea7’, properties={‘text’: ‘1’, ‘metadata’: ‘value1’}, tenant=None, references=None, index=1, retry_count=0), original_uuid=None)]\ndata I am trying to insert = [{‘text’: ‘a’, ‘metadata’: ‘name1’}, {‘text’: ‘1’, ‘metadata’: ‘value1’}]\n\n----------\n\n[DudaNogueira (2024-09-30T14:44:24.414Z)]: hi @Sumat_Mallick !!\nWelcome to our community \nCan you past the entire stace track?\nAlso, can you share here the code snippet so I can try to reproduce this?\nThanks!\n\n----------\n\n[Michael_Pont (2024-10-01T14:20:13.218Z)]: I am having the same issue.\nSee the following links for reference. @Dirk has also been investigating this.\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Maximum content length - token count incorrectly counted for object (open ai vectorizer)\n    \n\n    \n      \n        opened 07:33PM - 18 Aug 24 UTC\n      \n\n\n      \n        \n          \n          michael-pont\n        \n      \n    \n\n    \n        \n          bug\n        \n    \n  \n\n\n  \n    ### How to reproduce this bug?\n\nUse v3 of typescript client (    \"weaviate-clien…t\": \"^3.1.3\",) batch update the object\n```typescript\nasync function insertSingleBatch<T>({\n  batch,\n  collection,\n}: {\n  batch: (DataObject<T> | NonReferenceInputs<T>)[]\n  collection: Collection<T, string>\n}) {\n  const failedItems: BatchObject<T>[] = []\n\n  const errors = new Set()\n\n  const response = await backOff(() => collection.data.insertMany(batch), {\n    delayFirstAttempt: false,\n    numOfAttempts: 6,\n    startingDelay: 15000,\n    jitter: 'full',\n    timeMultiple: 2,\n    retry: (err) => {\n      logger.error(err, `Error batch inserting objects`)\n      return true\n    },\n  })\n  if (response.hasErrors) {\n    for (const [_index, error] of Object.entries(response.errors)) {\n      errors.add(error.message)\n      if (error.message.includes('maximum context length')) {\n        logger.error(\n          { originalObject: error.object },\n          'Maximum context length error - aborting as we do not want to keep retrying the same large text'\n        )\n        // For now, we do not want to keep rerying the same text so let's simply throw an error\n        throw new VectorDbExportError(\n          'Maximum context length error - aborting as we do not want to keep retrying the same large text'\n        )\n      }\n      failedItems.push(error.object)\n    }\n  }\n  if (errors.size > 0) {\n    logger.error(\n      {\n        errors: Array.from(errors),\n      },\n      `Failed to insert ${failedItems.length} items to vector DB`\n    )\n  }\n  return failedItems\n}\n\n```\n\n### What is the expected behavior?\n\nObject should be correctly vectorized and updated/created in database. Instead there is a token limit even though pasting the text into a online tokenizer shows around 2000 tokens.\n\n### What is the actual behavior?\n\nObject fails even though it is clearly smaller than 8192 tokens\n\n### Supporting information\n\n```json\n{\n    \"originalObject\": {\n        \"class\": \"WebPage\",\n        \"properties\": {\n            \"url\": \"https://www.avast.com/en-in/index\",\n            \"categories\": [\n                \"other\"\n            ],\n            \"text\": \"We’re sorry, your browser appears to be outdated.To see the content of this webpage correctly, please update to the latest version or install a new browser for free, such as Avast Secure Browser or Google Chrome. Avast Secure Browser Google Chrome Save 48% on Premium Security List of available regions Americas Argentina Brasil Canada (English) Canada (français) Chile Colombia EE.UU. (español) México USA (English) América Latina (español) Europe, Middle East & Africa België (Nederlands) Belgique (français) Česká republika Danmark Deutschland España France Italia Magyarország Nederland Norge Polska Portugal România Schweiz (Deutsch) Slovensko (česky) South Africa Suisse (français) Suomi Sverige Türkiye United Arab Emirates United Kingdom Ελλάδα ישראל Казахстан Россия Україна (українська) Украина (русский) المملكة العربية السعودية الدول العربية Europe (English) Worldwide (English) Asia & Pacific Australia India इंडिया (हिंदी) Indonesia (English) Indonesia (Bahasa Indonesia) Malaysia (English) Malaysia (Bahasa Melayu) New Zealand Philippines (English) Pilipinas (Filipino) Singapore Việt Nam 日本語 대한민국 简体中文 繁體中文 ประเทศไทย Main regions Worldwide (English) América Latina (español) Europe (English) Free antivirus is your first step to online freedom Free We believe everyone has the right to be safe online, which is why we offer our award-winning free antivirus to millions of people around the world. free antivirus Free download Free download Download freefrom Google Play Download freefrom the App Store Also available for Mac, Android, and iOS Mac Android iOS Also available for PC, Android, and iOS PC Android iOS Also available for Mac, Android, and PC Mac Android PC Also available for PC, Mac, and iOS PC Mac iOS 2024Top Rated Top Rated 2024Best Protection Best Protection Trustpilot Award-winning Antivirus Catch even new & emerging threats Hundreds of millions of users worldwide We have 30+ years of experience Download free antivirus 2022Top Rated Top Rated Get it for free! Free download Free download Download freefrom Google Play Download freefrom the App Store Avast Free Antivirus Get free antivirus that comes with advanced privacy and security tools Avast Free Antivirus is more than just an antivirus — it also includes these specialist tools: 6 layers of security Effortlessly run smart scans on software, files, and apps to help find vulnerabilities, plus analyze suspicious files in the cloud, get threat alerts, and more. Easy to install and use It only takes a moment to install Avast Free Antivirus and once it’s done, it’ll run quietly in the background, helping to protect you against viruses and other malware in real time, 24/7. Wi-Fi network security Connect more safely to any Wi-Fi network, even unsecured public networks, plus see who’s using your home Wi-Fi and help block intruders with a click. Protection against ransomware attacks Help protect your information. Don't let your personal photos, files, and documents fall victim to hackers using ransomware. Free download Free download Download freefrom Google Play Download freefrom the App Store Learn more Avast Premium Security Comprehensive protection for all your devices Our most advanced protection is your toughest defense against viruses, ransomware, zero-day threats, Wi-Fi vulnerabilities, and more. viruses ransomware zero-day threats Get protected Avast SecureLine VPN Choose a VPN for more online privacy Help block ISPs from tracking your activity, help avoid geo-restrictions from content providers, and ensure public Wi-Fi is safer with Avast’s Virtual Private Network (VPN). Virtual Private Network (VPN) Discover VPN Avast Cleanup Premium Enjoy more storage space and a faster device Reclaim gigabytes of storage space and get your device working like new by removing junk like leftover files, bloatware, and unwanted programs. Avast Cleanup also updates your software automatically, hibernates resource-draining apps, and more. Discover Cleanup It’s so easy to install — switching to Avast takes seconds You can start using Avast’s award-winning antivirus immediately. It’s quick and easy to install, and gives you all the protection you need to live your online life securely. And it’s totally free — so give it a try right now. Free download Free download Download freefrom Google Play Download freefrom the App Store Avast has hundreds of millions of users worldwide I have used Avast for a few years. The protection is the best for the money. I also cover my phones with Avast and I haven’t had any problems yet. Ryan R. 4.5 I have used Avast for many years. The reason is very simple: you offer a great free version that actually works. This lets me afford the other amazing services you offer when needed, like Avast Cleanup. Eric S. I've used Avast Free Antivirus on my computers, tablets, and smart phones for many years. It updates frequently and automatically. It automatically scans and protects me from malicious web sites. It does what I need. What more could I ask? Daryl C. 4.5 “The well-known security specialist Avast received a total of three awards for its outstanding performance ... shows how reliably and securely the security software renders its service...” Awarded Top-Rated Product 2023by AV-Comparatives Get privacy and performance tips, straight from the experts Read more at Avast Academy What Is a Computer Virus and How Does It Work? A computer virus is designed to infect programs & files with malicious code, changing how a computer operates and spreading across systems. Learn more What Is a VPN & How Does It Work? A VPN is a secure, encrypted connection that protects your online privacy. Learn what VPNs are, how they work, and what they do to protect you. Learn more How to Increase Your Internet Speed Right Now Wondering why your internet speed is slow? Learn how to improve your internet connection right now, whether you're on Wi-Fi or Ethernet. Learn more What Is Hacking? We all have some concept of hacking - but do you really know what it is? Read our full hacking definition here. Learn more What Is the about:blank Page? How to Use or Remove It Ever seen the about:blank page while browsing? Discover what about:blank is, why it appears, how to remove it, and how to browse safely. Learn more How to Encrypt Email on Gmail, Outlook, iOS, Android, and Other Platforms Learn how to encrypt your emails using different email providers to keep your communications safe. Start using end-to-end encryption. Learn more How to Fix the Blue Screen of Death (BSOD) on Windows 10 and 11 Seeing the blue screen of death on your Windows computer can be devastating. Understand the causes and learn how to fix the BSOD. Learn more What Is a Swatting Incident and How Does Swatting Work? Swatting is an incident where a hoax call is made to the police. Find out how people get swatted and why gamers are targeted. Learn more Why Is My Battery Draining So Fast? Tips and Troubleshooting Guide Why is my phone dying so fast? Learn how to fix a draining battery and boost your phone's overall performance in this guide. Learn more Keeping people around the world safer & more secure Using real-time intelligence from hundreds of millions of Avast users, we prevent more than 66 million threats every day. Download Free Protection Download Free Protection Download freefrom Google Play Download freefrom the App Store Looks like you're using Windows Looks like you're using Mac Looks like you're using Android Looks like you're using iOS Would you like this app for Windows or Mac? Windows Mac Would you like this app for Windows or Android? Windows Android Would you like this app for Windows or iOS? Windows iOS Would you like this app for Mac or Windows? Mac Windows Would you like this app for Mac or Android? Mac Android Would you like this app for Mac or iOS? Mac iOS Would you like this app for Android or Windows? Android Windows Would you like this app for Android or Mac? Android Mac Would you like this app for Android or iOS? Android iOS Would you like this app for iOS or Windows? iOS Windows Would you like this app for iOS or Android? iOS Android Would you like this app for iOS or Mac? iOS Mac Windows Mac Download freefrom Google Play Download freefrom the App Store Windows Mac Download freefrom Google Play Download freefrom the App Store Back Newsletter India (English) For home Support Security Privacy Performance Blog Forum For business Business support Business products Business partners Business blog Affiliates For partners Mobile Carriers Company Contact Us Careers Press center Digital trust Technology Research Participation © 2024 Gen Digital Inc. All rights reserved. Privacy policy Products policy Legal Report vulnerability Contact security Modern Slavery Statement Do not sell my info Subscription details Close Almost done! Complete installation by clicking your downloaded file and following the instructions. Initiating download... Note: If your download did not start automatically, please click here. Note: click here Click this file to start installing Avast. Close\",\n            \"accountId\": \"01a99d03-e306-4cef-8cf4-3836eed4b952\",\n            \"source\": \"website\",\n            \"title\": \"Avast | Download Free Antivirus & VPN | 100% Free & Easy\",\n            \"scrapedAt\": \"2024-08-18T14:38:28.836Z\"\n        },\n        \"id\": \"db44aa2b-1cea-5975-9344-c4b966ab8723\",\n        \"collection\": \"WebPage\"\n    },\n    \"errorMessage\": \"connection to: OpenAI API failed with status: 400 error: This model's maximum context length is 8192 tokens, however you requested 8225 tokens (8225 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.\",\n    \"msg\": \"Maximum context length error - aborting as we do not want to keep retrying the same large text\"\n}\n\n```\n\n### Server Version\n\n1.25.10\n\n### Code of Conduct\n\n- [X] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\n  \n      \n\n      Slack\n  \n\n  \n    \n\nAI Work Management & Productivity Tools\n\n  Slack is a new way to communicate with your team. It’s faster, better organized, and more secure than email.\n\n----------\n\n[Sumat_Mallick (2024-10-04T11:27:05.922Z)]: Thank you @DudaNogueira\nAfter further debugging, I found the solution.\nI have been using the free version of Weaviate for the last two months, by extending it for another two weeks.\nWhen I move to the new Weaviate layer, it starts working fine.\nNew Code:\nif not client.collections.exists(class_name):\n        bot = client.collections.create(\n            name=class_name,\n            vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(  \n                model=\"ada\", \n                model_version=\"002\",\n                vectorize_collection_name = False\n            ),\n            properties=[\n                wvc.config.Property(\n                    name=\"text\",\n                    data_type=wvc.config.DataType.TEXT,  \n                    vectorize_property_name=True  \n                ),\n                wvc.config.Property(\n                    name=\"metadata\",\n                    data_type=wvc.config.DataType.TEXT,  \n                    vectorize_property_name=True  \n                )\n            ]\n        )\n\nOld Code\ntry:\n    bot = client.collections.create(\n    name=class_name,\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai( \n        model=\"ada\", \n        model_version=\"002\",\n        vectorize_collection_name = False\n    ),\n    properties=[\n        wvc.config.Property(\n            name=\"text\",\n            data_type=wvc.config.DataType.TEXT, \n            vectorize_property_name=True  \n        ),\n        wvc.config.Property(\n            name=\"metadata\",\n            data_type=wvc.config.DataType.TEXT,  \n            vectorize_property_name=False  \n        ),\n    ]\n)\n\nexcept Exception as e:\n    print(\"Error:\", e)\n    print(\"--------*--------**\")\n    bot = client.collections.get(class_name)\n\n----------\n\n[DudaNogueira (2024-10-07T09:21:41.167Z)]: hi @Sumat_Mallick !!\nI didn’t understand.\nApart from the try/except the code seems similar to me.\nAlso, the only difference from the sandbox (“free version”) from a paid cluster are the resources.\nThe same Weaviate you get at a sandbox, is the same you get from a paid account and from our public releases.\nThanks!\n\n----------\n\n[Dirk (2024-10-07T09:38:25.003Z)]: I think it is a bug in weaviate, but it has certain preconditions to happen - restarting wipes the state but it could reappear any time.\nThe latest version contains additional information in the error, which can help me to pin down what the actual reason is.\n\n----------\n\n[Sumat_Mallick (2024-10-09T11:04:07.960Z)]: Hello @Dirk and @DudaNogueira,\nI hope this message finds you well.\nWe are currently facing a challenge with our setup on an AWS Ubuntu instance. While we are able to connect to the Weaviate cloud from our local Windows machine, we encounter an error when attempting to do so on the Ubuntu instance. The error message we receive is as follows:\n[2024-10-09 10:56:37 +0000] [445826] [ERROR] Worker (pid:445830) was sent SIGKILL! Perhaps out of memory?\n\nTo replicate this issue, please create a file named vec.py and add the relevant code to it. You can then use the following command to check if it works:\ngunicorn --workers 4 --worker-class gevent --bind 0.0.0.0:8000 --timeout 120 vec:app\n\nAny insights or assistance you can provide on this matter would be greatly appreciated.\nThank you!\n\n----------\n\n[DudaNogueira (2024-10-14T21:53:07.194Z)]: Hi @Sumat_Mallick !\nThis seems to be code before weaviate client receiving this SIGKILL. So not sure if Weaviate has any effect on this.\nHave you tried running with more verbose logs from gunicorn?\n\n----------\n\n[fellalli (2024-12-17T13:38:05.266Z)]: Hi @DudaNogueira,\nThanks for looking at this! I assume that this is the same issue as here. I have the same problem when trying to use Weaviate v4 with gevent or eventlet to perform a simple search query. The logs do not seem to give any more information. But the problem seems to be well reproducible.\n\n----------\n\n[Dirk (2024-12-18T05:45:53.248Z)]: I answered in the linked thread!",
    "date_created": "2024-09-30T10:27:49.728Z",
    "has_accepted_answer": true,
    "title": "Error : text too long for vectorization",
    "topic_id": 4373
  },
  {
    "user_id": 3155,
    "conversation": "[DhanushKumar_R (2025-01-30T09:43:33.750Z)]: # Connect to Weaviate\nclient = weaviate.connect_to_wcs(\n    cluster_url=weaviate_url,\n    auth_credentials=weaviate.auth.AuthApiKey(weaviate_key),\n    headers={\n        \"X-OpenAI-Api-Key\": openai.api_key  # Replace with your OpenAI key\n    }\n)\n\n# Check if Weaviate is ready\nclient.is_ready()\n\n# Configure Weaviate Schema for Two Collections\nimport weaviate.classes.config as wc\n\n# Schema for Credit Card Documents\nclient.collections.create(\n    name=\"CreditCardDocuments\",\n    vectorizer_config=wc.Configure.Vectorizer.text2vec_openai(\n        model=\"ada\",\n        model_version=\"002\",\n        type_=\"text\"\n    ),\n    generative_config=wc.Configure.Generative.openai(\n        model=\"gpt-4\"\n    ),\n    properties=[\n        wc.Property(name=\"type\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"element_id\", data_type=wc.DataType.TEXT, skip_vectorization=True),\n        wc.Property(name=\"text\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"embeddings\", data_type=wc.DataType.NUMBER_ARRAY, skip_vectorization=True),\n    ],\n)\n\n# Schema for HR Documents\nclient.collections.create(\n    name=\"HRDocuments\",\n    vectorizer_config=wc.Configure.Vectorizer.text2vec_openai(\n        model=\"ada\",\n        model_version=\"002\",\n        type_=\"text\"\n    ),\n    generative_config=wc.Configure.Generative.openai(\n        model=\"gpt-4\"\n    ),\n    properties=[\n        wc.Property(name=\"type\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"element_id\", data_type=wc.DataType.TEXT, skip_vectorization=True),\n        wc.Property(name=\"text\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"embeddings\", data_type=wc.DataType.NUMBER_ARRAY, skip_vectorization=True),\n    ],\n)\n\n# Define Writer for Weaviate\ndef get_writer(collection_name: str) -> Writer:\n    return WeaviateWriter(\n        connector_config=SimpleWeaviateConfig(\n            access_config=WeaviateAccessConfig(api_key=weaviate_key),\n            host_url=weaviate_url,\n            class_name=collection_name,\n        ),\n        write_config=WeaviateWriteConfig(),\n    )\n\n# Ingest Data into CreditCardDocuments\ncredit_card_writer = get_writer(\"CreditCardDocuments\")\ncredit_card_runner = S3Runner(\n    processor_config=ProcessorConfig(\n        verbose=True,\n        output_dir=\"s3-output-credit-card\",\n        num_processes=40,\n    ),\n    read_config=ReadConfig(),\n    partition_config=PartitionConfig(\npartition_by_api=True,\n        api_key=\"marmfWUWJpM8ncY6GQRrftfjKG7LLw\",  # Replace with your Unstructured API key\n        partition_endpoint=\"\",  # Replace with your Unstructured API URL\n    ),\n    connector_config=SimpleS3Config(\n        access_config=S3AccessConfig(\n            key=\"A\",  # Replace with your AWS key\n            secret=\"SI\",  # Replace with your AWS secret\n        ),\n        remote_url=\"s3://g/credit-card-documents\",  # Replace with your S3 bucket path\n    ),\n    chunking_config=ChunkingConfig(\n        chunk_elements=True,\n        chunking_strategy=\"by_title\",\n        max_characters=8192,\n        combine_text_under_n_chars=1000,\n    ),\n    embedding_config=EmbeddingConfig(\n        provider=\"azure\",\n        api_key=openai.api_key,\n    ),\n    writer=credit_card_writer,\n    writer_kwargs={},\n)\n\ncredit_card_runner.run()\n\n# Ingest Data into HRDocuments\nhr_writer = get_writer(\"HRDocuments\")\nhr_runner = S3Runner(\n    processor_config=ProcessorConfig(\n        verbose=True,\n        output_dir=\"s3-output-hr\",\n        num_processes=40,\n    ),\n    read_config=ReadConfig(),\n    partition_config=PartitionConfig(\n        partition_by_api=True,\n        api_key=\"mw\",  # Replace with your Unstructured API key\n        partition_endpoint=\"https://api.unstructuredapp.io\",  # Replace with your Unstructured API URL\n    ),\n    connector_config=SimpleS3Config(\n        access_config=S3AccessConfig(\n            key=\"AKR\",  # Replace with your AWS key\n            secret=\"nI\",  # Replace with your AWS secret\n        ),\n        remote_url=\"s3://gg/hr-documents\",  # Replace with your S3 bucket path\n    ),\n    chunking_config=ChunkingConfig(\n        chunk_elements=True,\n        chunking_strategy=\"by_title\",\n        max_characters=8192,\n        combine_text_under_n_chars=1000,\n    ),\n    embedding_config=EmbeddingConfig(\n        provider=\"azure\",\n        api_key=openai.api_key,\n    ),\n    writer=hr_writer,\n    writer_kwargs={},\n)\n\nhr_runner.run()\n\n# Search in CreditCardDocuments\ncredit_card_documents = client.collections.get(\"CreditCardDocuments\")\ncredit_card_response = credit_card_documents.query.hybrid(\n    query=\"What is the annual fee for the premium credit card?\",\n    alpha=0.5,\n    return_properties=['text'],\n    auto_limit=2\n)\n\nprint(\"Credit Card Documents Search Results:\")\nfor obj in credit_card_response.objects:\n    print(json.dumps(obj.properties, indent=2))\n\n# Search in HRDocuments\nhr_documents = client.collections.get(\"HRDocuments\")\nhr_response = hr_documents.query.hybrid(\n    query=\"What is the company's policy on remote work?\",\n    alpha=0.5,\n    return_properties=['text'],\n    auto_limit=2\n)\n\nprint(\"HR Documents Search Results:\")\nfor obj in hr_response.objects:\n    print(json.dumps(obj.properties, indent=2))\n\nWhen i try the api key with normal chat completion ,it works, but it fails when it works with weaviate\n\n----------\n\n[DudaNogueira (2025-01-30T13:34:49.228Z)]: Hi!\nCan you share the questions asked in a template for a new topic? Infos like version, deployment method etc help us understand it better.\nDo you see any error messages? Can you share it?\nAlso, it helps when you share a code we can run entirely.\nI see some code (WeaviateWriter) that I don’t know it’s origin, so I can reproduce it \nTHanks!\n\n----------\n\n[DhanushKumar_R (2025-01-31T05:39:17.194Z)]: may i have your email id because my code contains credentials and as well ,i dont feel safe to share it publicly\n\n----------\n\n[DudaNogueira (2025-01-31T21:11:58.462Z)]: You can create the code and remove any sensitive information. That will help.\nFrom what I have seen, if you are using  unstructured-ingest, note that that integration is outdated as it is using our python v3 client \n    embedding_config=EmbeddingConfig(\n        provider=\"azure\",\n        api_key=openai.api_key,\n    ),\n\nshouldn’t the provider here be openai?\nPs: I never used this code from unstructured-ingest",
    "date_created": "2025-01-30T09:43:33.667Z",
    "has_accepted_answer": false,
    "title": "Openai API key fails when i connect with weaviate but works with normal chat completion api",
    "topic_id": 9964
  },
  {
    "user_id": 799,
    "conversation": "[Alan_Sun (2024-05-30T07:32:04.253Z)]: Description\n\nI have successfully running my weaviate and also writing data already. Now i am trying to use Prometheus to get the monitoring stuff.\nHowever when i directly port-forward 2112, i can see all metrics having classname are equals to na\nfor example:\nbatch_durations_ms_count{class_name=\"n/a\",operation=\"total_persistence_level\",shard_name=\"n/a\"} 10499\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\",le=\"10\"} 7971\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\",le=\"50\"} 8915\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\",le=\"100\"} 10079\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\",le=\"500\"} 10498\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\",le=\"1000\"} 10499\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\",le=\"5000\"} 10499\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\",le=\"+Inf\"} 10499\nbatch_durations_ms_sum{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\"} 214940.27587399905\nbatch_durations_ms_count{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\"} 10499\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_uc_level\",shard_name=\"n/a\",le=\"10\"} 217\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_uc_level\",shard_name=\"n/a\",le=\"50\"} 5912\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_uc_level\",shard_name=\"n/a\",le=\"100\"} 6874\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_uc_level\",shard_name=\"n/a\",le=\"500\"} 8507\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_uc_level\",shard_name=\"n/a\",le=\"1000\"} 9151\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_uc_level\",shard_name=\"n/a\",le=\"5000\"} 10496\n\nServer Setup Information\n\nWeaviate Server Version:  1.25.0\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python weaviate-client==4.5.5\nMultitenancy?: no\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-06-03T22:21:46.810Z)]: Hi @Alan_Sun !!\nHave you deployed using our helm charts?\nI was not able to reproduce this on a single deployment in docker.\nI will need to follow up on this to try replicating the same environment.\nCan you see any outstanding logs?\nThanks!\n\n----------\n\n[Alan_Sun (2024-06-04T03:19:06.789Z)]: Hi @DudaNogueira ,\nYes I am using your official helm chart as following:\n|NAME               |NAMESPACE    |REVISION|UPDATED                             |STATUS  |CHART                    |APP VERSION|\n|---|---|---|---|---|---|---|\n|ssdl-weaviate      |ssdl-weaviate|34      |2024-06-03 14:25:44.220168 +0800 CST|deployed|weaviate-17.0.0          |1.25.0|\n\nOf course we created our collections and inserted data into this collections by using following python code\n!pip install \"weaviate-client==4.*\"\n!pip install -U weaviate-client\n\n\ninit get client then\nimport weaviate.classes.config as wvcc\n\nclient.collections.create(\n    name=\"EmilyTest1\",\n    properties=[\n        wvcc.Property(\n          name=\"solution_number\",\n          data_type=wvcc.DataType.NUMBER\n        )\n      ],\n    replication_config=Configure.replication(\n        factor=3\n    ),\n)\n\nThen batch import\nstart_time = datetime.datetime.now()\nwith client.batch.fixed_size(batch_size=200) as batch:\n    with open(\"embedding_3m.pkl\", \"rb\") as f:\n        loaded_data = pickle.load(f)\n        # objects = ijson.items(f, \"item\")\n        for obj_soln, obj_vector in loaded_data.items():\n            properties = {\n                \"solution_number\": obj_soln,\n            }\n            batch.add_object(\n                collection=\"EmilyTest1\",\n                properties=properties,\n                vector=obj_vector\n            )\n\n            # Calculate and display progress\n            counter += 1\n            if counter % interval == 0:\n                print(f\"Imported {counter} solutions...\")\n\nend_time = datetime.datetime.now()\ndelta_time = end_time - start_time\nprint(\"Time taken:\", delta_time)\nprint(f\"Finished importing {counter} solutions.\")\n\n----------\n\n[DudaNogueira (2024-06-07T20:18:55.451Z)]: Hi!\nI believe this is only the case for the totals.\nIn my environment I get:\nbatch_durations_ms_count{class_name=\"Test_Batch\",operation=\"object_storage\",shard_name=\"2uApOMYRXmM7\"} 247\n....\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_persistence_level\",shard_name=\"n/a\",le=\"10\"} 0\n.....\n\nSo all that entries that has class_name as “n/a” is referring to the overall.\nthose were my two configurations for the exposed metrics:\nExpose metrics on port 2112 for Prometheus to scrape\nPROMETHEUS_MONITORING_ENABLED: true\nPROMETHEUS_MONITORING_GROUP: false\nLet me know if this helps.\nThanks!\n\n----------\n\n[Alan_Sun (2024-06-11T03:28:10.999Z)]: Hi,\nYes, i have enabled prometheus monitoring thats why i am able to see the metrics through 2112.\nBut i am still not seeing class_name even for ms_count.\nAre you also testing with batch upload  with weaviate-client 4.* ?\nbatch_durations_ms_bucket{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\",le=\"+Inf\"} 10509\nbatch_durations_ms_sum{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\"} 47322.00007900016\nbatch_durations_ms_count{class_name=\"n/a\",operation=\"total_preprocessing\",shard_name=\"n/a\"} 10509\n\n----------\n\n[DudaNogueira (2024-06-11T19:10:18.467Z)]: Can you check your values.yaml for those variables:\nPROMETHEUS_MONITORING_ENABLED: true\nPROMETHEUS_MONITORING_GROUP: false\n\nif PROMETHEUS_MONITORING_GROUP is set to true, it will not expose per collection metrics.\nLet me know if this helps.\nThanks!\n\n----------\n\n[Alan_Sun (2024-06-12T03:08:40.769Z)]: Oh thanks for your tips. Looks good now.\n\n----------\n\n[SStalciuss (2025-02-06T09:20:38.809Z)]: Are you planning to change grouping in a way that it would expose class  data? It makes sense to group shards if multi-tenancy is enabled, but it would still be good to see per class metrics\n\n----------\n\n[DudaNogueira (2025-02-06T12:20:23.206Z)]: hi @SStalciuss !! Welcome to our community \nWhat metrics are you looking for?\nWe had recently a PR that touches this:\n\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n\n\n\n    \n      \n    \n\n  \n\n\n\n      \n        metric: Support `weaviate_schema_collections`\n      \n\n    \n      stable/v1.25 ← kavirajk/metrics-add-collection-guauge-metric\n    \n\n      \n        \n          opened 10:23AM - 22 Jan 25 UTC\n        \n\n        \n          \n            \n            kavirajk\n          \n        \n\n        \n          \n            +85\n            -19\n          \n        \n      \n  \n\n\n  \n    ### What's being changed:\nThis metric is a guage metric that represents the num…ber of collections per \"node\". Useful to have high level view of collections for operators. Also to sanity check after any migrations.\n\nExample:\n```\n# HELP weaviate_schema_collections Number of collections per node\n# TYPE weaviate_schema_collections gauge\nweaviate_schema_collections{nodeID=\"weaviate-0\"} 1\n```\n### Review checklist\n\n- [ ] Documentation has been updated, if necessary. Link to changed documentation:\n- [ ] Chaos pipeline run or not necessary. Link to pipeline:\n- [ ] All new code is covered by tests where it is reasonable.\n- [ ] Performance tests have been run or not necessary.\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThere are probably some more metrics that could be interesting to expose.\nI suggest opening a new thread so we can discuss this further \nThanks!\n\n----------\n\n[DudaNogueira (2025-02-06T12:20:26.169Z)]: ",
    "date_created": "2024-05-30T07:32:04.196Z",
    "has_accepted_answer": true,
    "title": "Prometheus metrics showing n/a for class name",
    "topic_id": 2547
  },
  {
    "user_id": 19,
    "conversation": "[vamsi (2024-01-28T00:58:50.062Z)]: Server\nI have weaviate hosted on k8s with grpc enabled as follows:\n# The service controls how weaviate gRPC endpoint is exposed to the outside world.\n# If you don't want a public load balancer, you can also choose 'ClusterIP' to make\n# weaviate gRPC port be only accessible within your cluster.\ngrpcService:\n  # Set this to true in order to deploy Weaviate gRPC service\n  enabled: true\n  name: weaviate-grpc\n  ports:\n    - name: grpc\n      protocol: TCP\n      port: 50052\n      # Target port is going to be the same for every port\n  type: LoadBalancer\n  loadBalancerSourceRanges: []\n  # optionally set cluster IP if you want to set a static IP\n  clusterIP:\n  annotations: {}\n\nNAME                        TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)           AGE\nservice/weaviate            LoadBalancer   a.b.c.d   e.f.g.h   80:30357/TCP      8d\nservice/weaviate-grpc       LoadBalancer   i.j.k.l   m.n.o.p  50052:31927/TCP   8d\nservice/weaviate-headless   ClusterIP      None           <none>          80/TCP            8d\n\nClient\nI’m on weaviate-client-4.4b8 python client.\nWhen I try to query weaviate with bm25 or hybrid search using the python v4 client I am getting following error:\n_InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Socket closed\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"Socket closed\", grpc_status:14, created_time:\"2024-01-27T19:46:26.102631-05:00\"}\"\n>\n\nDuring handling of the above exception, another exception occurred:\n\nWeaviateQueryError                        Traceback (most recent call last)\n.\n.\n.\n  561     return res\n    563 except grpc.RpcError as e:\n--> 564     raise WeaviateQueryError(e.details(), \"GRPC search\")\n\nWeaviateQueryError: Query call with protocol GRPC search failed with message Socket closed.\n\nI am instantiating weaviate as follows:\ntarget_client = weaviate.connect_to_custom(\n    http_host=\"e.f.g.h\",\n    http_port=\"80\",\n    http_secure=False,\n    grpc_host=\"m.n.o.p\",\n    grpc_port=\"50052\",\n    grpc_secure=False,\n    auth_credentials=AuthApiKey(\"xxxxxxxxxx\")\n)\n\nAny help is appreciated. Thank you.\n\n----------\n\n[DudaNogueira (2024-02-02T12:43:44.283Z)]: Hi @vamsi.\nWere you able to fix this?\nWeaviate Python v4 Client is now available. Also, make sure to run it with the latest Weaviate server, so you need to change the tag in your values.yml too\nYou shouldn’t have any issues deploying on K8s with our helm chart, unless your loadbalancer is interfering.\nLet me know if I can help.\nThanks!\n\n----------\n\n[vamsi (2024-02-03T02:38:46.465Z)]: This issue has been resolved with the latest versions of python client and weaviate @DudaNogueira . Thanks for the help\n\n----------\n\n[zbloss (2024-06-15T15:48:00.055Z)]: Can you tell me which versions of weaviate and the python client you were using?\nI am facing this same issue using weaviate==1.24.5 and weaviate-client==4.6.4\n\n----------\n\n[DudaNogueira (2024-06-17T17:58:30.331Z)]: hi @zbloss !!\nYou need to expose both ports for HTTP and GRPC.\nHow is your cluster deployed?\n\n----------\n\n[zbloss (2024-06-17T18:25:18.797Z)]: I am running weaviate as a statefulset\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: weaviate-statefulset\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: weaviate\n    spec:\n      containers:\n        - name: weaviate-container\n          image: semitechnologies/weaviate:1.25.4\n          command: [\"/bin/weaviate\"]\n          args:\n            - '--host'\n            - '0.0.0.0'\n            - '--port'\n            - '8080'\n            - '--scheme'\n            - 'http'\n            - --read-timeout=600s \n            - --write-timeout=600s\n          ports:\n            - containerPort: 8080\n            - containerPort: 50051\n\nAnd have a service object exposing both ports as below:\napiVersion: v1\nkind: Service\nmetadata:\n  name: weaviate-service\nspec:\n  selector:\n    matchLabels:\n      app: weaviate\n  ports:\n    - port: 8080\n      targetPort: 8080\n      name: http\n    - port: 2112\n      targetPort: 2112\n      name: metrics\n    - port: 50051\n      targetPort: 50051\n      name: grpc\n  type: ClusterIP\n  selector:\n    app: weaviate\n\n----------\n\n[DudaNogueira (2024-06-17T19:04:28.878Z)]: This is how you can check if your GRPC service is up and running:\nFor non TLS/SSL:\n# lets test our grpc connection\n❯ wget https://raw.githubusercontent.com/grpc/grpc/master/src/proto/grpc/health/v1/health.proto\n❯ grpcurl --plaintext -d '{\"service\": \"Weaviate\"}' -proto health.proto grpc.weaviate.mydomain.com:50051 grpc.health.v1.Health/Check\n{\n  \"status\": \"SERVING\"\n}\n\nLet me know if you can do this test and have this same outcome?\nThanks!\n\n----------\n\n[zbloss (2024-06-17T19:35:33.565Z)]: Yes I’m also getting\n{\n    \"status\": \"SERVING\"\n}\n\n----------\n\n[DudaNogueira (2024-06-17T19:42:35.538Z)]: Ok, can you share the code you have that is getting this error?\nThanks!\n\n----------\n\n[zbloss (2024-06-17T19:55:22.627Z)]: Instantiating a client will produce the error unless I set skip_init_checks=True.\nWhen I enable skip_init_checks I don’t get the error until I run a query.\n\nimport weaviate\nimport weaviate.classes as wvc\nfrom weaviate.collections.classes.internal import Object, QueryReturn\n\nclass MyWeaviateClient:\n\n    weaviate_host: str\n    weaviate_http_port: int\n    weaviate_grpc_port: int\n    weaviate_query_timeout_seconds: int\n    weaviate_insert_timeout_seconds: int\n    weaviate_init_timeout_seconds: int\n    weaviate_skip_init_checks: bool\n\n    @property\n    def client(self) -> weaviate.WeaviateClient:\n        weaviate_client: weaviate.WeaviateClient = weaviate.connect_to_custom(\n            http_host=self.weaviate_host,\n            http_port=self.weaviate_http_port,\n            http_secure=False,\n            grpc_host=self.weaviate_host,\n            grpc_port=self.weaviate_grpc_port,\n            grpc_secure=False,\n            additional_config=wvc.init.AdditionalConfig(\n                timeout=wvc.init.Timeout(\n                    query=self.weaviate_query_timeout_seconds,\n                    insert=self.weaviate_insert_timeout_seconds,\n                    init=self.weaviate_init_timeout_seconds,\n                )\n            ),\n            skip_init_checks=self.weaviate_skip_init_checks,\n        )\n\n        return weaviate_client\n    \n    @property\n    def example_collection(self) -> weaviate.collections.Collection:\n        return self.client.collections.get(\"Example\")\n    \n    def query_example_collection(self, limit: int = 100) -> list[Object]:\n        \n        query_return: QueryReturn = self.example_collection.query.fetch_objects(\n            limit=limit\n        )\n\n        return query_return.objects\n\nif __name__ == \"__main__\":\n\n    client: MyWeaviateClient = MyWeaviateClient(\n        weaviate_host=\"localhost\",\n        weaviate_http_port=8080,\n        weaviate_grpc_port=50051,\n        weaviate_query_timeout_seconds=60,\n        weaviate_insert_timeout_seconds=60,\n        weaviate_init_timeout_seconds=30,\n        weaviate_skip_init_checks=True,\n    )\n\n    objects: list[Object] = client.query_example_collection(limit=10)\n\n----------\n\n[DudaNogueira (2024-06-17T20:32:09.438Z)]: can you specify those in your custom_to_custom\nhttp_secure=False,\ngrpc_secure=False\n\nThanks!\n\n----------\n\n[zbloss (2024-06-17T20:35:27.398Z)]: Yes, I get the same error\n\n----------\n\n[DudaNogueira (2024-06-17T20:47:12.198Z)]: Are you running this locally? Using something like Kind?\nAlso, are you using our helm chart?\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nGitHub - weaviate/weaviate-helm: Helm charts to deploy Weaviate to k8s\n\n  Helm charts to deploy Weaviate to k8s. Contribute to weaviate/weaviate-helm development by creating an account on GitHub.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI could try reproducing this deployment.\nThanks!\n\n----------\n\n[zbloss (2024-06-17T21:40:41.739Z)]: I am not using the helm chart. I have this deployed in google kubernetes engine. The error does not always appear which is equally confusing\n\n----------\n\n[DudaNogueira (2024-06-21T11:17:52.785Z)]: Strange. Nothing on logs from Weaviate or firewall?\n\n----------\n\n[ajay (2024-10-11T05:15:50.098Z)]: Hey @zbloss , did you get your issue solved? what was the RCA? I am also facing similar issue with query when I set skip_init_checks=True.\n\n----------\n\n[DudaNogueira (2024-10-14T23:05:39.130Z)]: hi @ajay !\nNot sure those are related",
    "date_created": "2024-01-28T00:58:50.015Z",
    "has_accepted_answer": true,
    "title": "WeaviateQueryError: Query call with protocol GRPC search failed with message Socket closed",
    "topic_id": 1311
  },
  {
    "user_id": 11472,
    "conversation": "[Aditya_Shukla (2025-03-17T07:49:48.664Z)]: Description\nI’m encountering an error when trying to add objects to my Weaviate collection using the VoyageAI vectorizer. Despite verifying that my API key works and the module appears to be available, I’m still getting the following error:\nUnexpectedStatusCodeError: Object was not added! Unexpected status code: 500, with response body: {'error': [{'message': 'vectorize target vector content_embeddings: update vector: connection to VoyageAI failed with status: 404 error: Not Found'}]}.\n\nI’ve verified the following:\n\n\nMy VoyageAI API key works (confirmed with a successful curl request to VoyageAI API)\n\n\nI’m using the correct header format with both the API key and baseurl\n\n\nThe model names I’m using are correct\n\n\nThe VoyageAI module appears to be available on my cluster\n\n\nServer Setup Information\n\nWeaviate Server Version: 1.29.0\nDeployment Method: Weaviate Cloud Service\nClient Language and Version: Python, weaviate-client v4 (4.11.1)\nMultitenancy?:  Yes\n\nCode Example\nHere’s how I’m initializing my client:\nself.client = weaviate.connect_to_weaviate_cloud(\n    cluster_url=self.url,\n    auth_credentials=Auth.api_key(api_key=self.auth_key),\n    additional_config=AdditionalConfig(\n        timeout=Timeout(init=120, query=120, insert=300)\n    ),\n    headers={\"X-VoyageAI-Api-Key\": self.voyage_key, \"X-VoyageAI-Baseurl\": self.voyage_baseurl},\n    skip_init_checks=False,\n)\n\nself.client.integrations.configure(\n    [\n        Integrations.voyageai(\n            api_key=self.voyage_key,\n            requests_per_minute_embeddings=self.config[\"Voyage_tpm\"],\n            tokens_per_minute_embeddings=self.config[\"Voyage_rpm_embeddings\"],\n        ),\n    ]\n)\n\nAnd here’s how I’m creating my collection:\nself.client.collections.create(\n    name=self.config[\"SuperBotCollection\"],\n    multi_tenancy_config=Configure.multi_tenancy(\n        enabled=True, auto_tenant_creation=False\n    ),\n    reranker_config=Configure.Reranker.voyageai(\n        model=self.config[\"Voyage_Reranker_Model\"]\n    ),\n    properties=[\n        Property(name=\"chunk_id\", data_type=DataType.TEXT),\n        Property(name=\"content\", data_type=DataType.TEXT),\n        Property(\n            name=\"file_name\",\n            data_type=DataType.TEXT,\n            skip_vectorization=True,\n        ),\n        Property(name=\"meta_data\", data_type=DataType.TEXT),\n    ],\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_voyageai(\n            model=self.config[\"Voyage_Text_Embedding_Model\"],\n            vectorize_collection_name=False,\n            name=\"content_embeddings\",\n            source_properties=[\"content\"],\n            vector_index_config=Configure.VectorIndex.hnsw(\n                quantizer=None,\n                ef_construction=128,\n                distance_metric=VectorDistances.COSINE,\n                max_connections=64,\n                filter_strategy=VectorFilterStrategy.ACORN,\n            ),\n        )\n    ],\n)\n\nWhen I try to insert data:\ndocument = self.client.collections.get(class_name)\ndocument_ten = document.with_tenant(str(tenant))\ndocument_ten.data.insert({\n    \"chunk_id\": \"DUMMY TEXT\",\n    \"content\": \"DUMMY TEXT\",\n    \"meta_data\": \"{'DUMMY TEXT': 'DUMMY TEXT'}\",\n    \"file_name\": \"DUMMY TEXT\"\n})\n\nAlso While try to make use of batch be it fixed , rate_limit or dynamic getting this error:-\nErrorObject(message='WeaviateBatchError(\\'Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\\\n\\\\tstatus = StatusCode.UNAVAILABLE\\\\n\\\\tdetails = \"Received http2 header with status: 502\"\\\\n\\\\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-03-17T13:09:03.914196782+05:30\", grpc_status:14, grpc_message:\"Received http2 header with status: 502\"}\"\\\\n>.\\')'\n\nEven After retry mechanism it doesn’t help:-\nERROR:weaviate-client:{'message': 'Failed to send all objects in a batch of 10', 'error': 'WeaviateBatchError(\\'Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\\\n\\\\tstatus = StatusCode.UNAVAILABLE\\\\n\\\\tdetails = \"Received http2 header with status: 502\"\\\\n\\\\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"Received http2 header with status: 502\", grpc_status:14, created_time:\"2025-03-17T13:37:05.529298246+05:30\"}\"\\\\n>.\\')'}\nERROR:weaviate-client:{'message': 'Failed to send 10 objects in a batch of 10. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n2025-03-17 08:07:05,543944      l=WARNING       ip=Unkknown     m=Unkknown      url=Unkknown    msg=Attempt 1: Still failed to insert 10 objects for tenant: 679cc320af0f91e204fdd470\nWARNING:rq.worker:Attempt 1: Still failed to insert 10 objects for tenant: 679cc320af0f91e204fdd470\nERROR:weaviate-client:{'message': 'Failed to send all objects in a batch of 10', 'error': 'WeaviateBatchError(\\'Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\\\n\\\\tstatus = StatusCode.UNAVAILABLE\\\\n\\\\tdetails = \"Received http2 header with status: 502\"\\\\n\\\\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"Received http2 header with status: 502\", grpc_status:14, created_time:\"2025-03-17T13:37:36.658112152+05:30\"}\"\\\\n>.\\')'}\nERROR:weaviate-client:{'message': 'Failed to send 10 objects in a batch of 10. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n2025-03-17 08:07:36,670347      l=WARNING       ip=Unkknown     m=Unkknown      url=Unkknown    msg=Attempt 2: Still failed to insert 10 objects for tenant: 679cc320af0f91e204fdd470\nWARNING:rq.worker:Attempt 2: Still failed to insert 10 objects for tenant: 679cc320af0f91e204fdd470\nERROR:weaviate-client:{'message': 'Failed to send all objects in a batch of 10', 'error': 'WeaviateBatchError(\\'Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\\\n\\\\tstatus = StatusCode.UNAVAILABLE\\\\n\\\\tdetails = \"Received http2 header with status: 502\"\\\\n\\\\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-03-17T13:38:07.774087886+05:30\", grpc_status:14, grpc_message:\"Received http2 header with status: 502\"}\"\\\\n>.\\')'}\nERROR:weaviate-client:{'message': 'Failed to send 10 objects in a batch of 10. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n2025-03-17 08:08:07,785726      l=WARNING       ip=Unkknown     m=Unkknown      url=Unkknown    msg=Attempt 3: Still failed to insert 10 objects for tenant: 679cc320af0f91e204fdd470\nWARNING:rq.worker:Attempt 3: Still failed to insert 10 objects for tenant: 679cc320af0f91e204fdd470\n2025-03-17 08:08:07,786009      l=ERROR ip=Unkknown     m=Unkknown      url=Unkknown    msg=Failed to insert 10 objects after 3 attempts for tenant: 679cc320af0f91e204fdd470\nERROR:rq.worker:Failed to insert 10 objects after 3 attempts for tenant: 679cc320af0f91e204fdd470\n\nThe strange part is my token and API counts on voyage ai are increasing with every request.\nimage1040×686 24.1 KB\n\n----------\n\n[Aditya_Shukla (2025-03-17T08:26:55.696Z)]: Deleted The cluster and created a new one and it started working\n\n----------\n\n[Mohamed_Shahin (2025-03-17T10:34:37.975Z)]: Hey @Aditya_Shukla,\nWelcome to our community! It’s great to have you here.\nAwesome news that you managed to fix it! I would have suspected the request to VoyageAI’s service might have failed for some reason.\nAs a side note, when batching, you can add a printout to log the actual reason why an object wasn’t inserted. Here’s an example I created:\n\n  \n\n      github.com/Shah91n/WeaviateDB-Docs-Snippets-Python-Client\n  \n\n  \n    CreateCollectionViaBatchingFromFile.py\n\n\n  d47383085\n\n\n\n\n    \n      \n                              }\n                              batch.add_object(\n                                  properties=obj_properties,\n                                  collection=collection_name\n                              )\n                          print(f\"Batch processing completed. {i + 1} objects added.\")\n              except Exception as e:\n                  raise Exception(f\"Batch insertion failed: {e}\")\n          \n              # Check for failed objects and reason behind to be printed out\n              failed_objects = client.batch.failed_objects\n              if failed_objects:\n                  print(f\"Number of failed objects: {len(failed_objects)}\")\n                  for i, failed_obj in enumerate(failed_objects, 1):\n                      print(f\"Failed object {i}: {failed_obj}\")\n              else:\n                  print(f\"All objects successfully inserted into '{collection_name}'.\")\n          \n          if __name__ == \"__main__\":\n              collection_name = \"<COLLECTION_NAME>\"  # Update the collection name\n              CSV_FILE_PATH = \"<PATH>.csv\"  # Update this path when requires",
    "date_created": "2025-03-17T07:49:48.607Z",
    "has_accepted_answer": true,
    "title": "VoyageAI Integration Error: 500 Status Code with 404 Not Found Response",
    "topic_id": 19901
  },
  {
    "user_id": 3387,
    "conversation": "[Tatul_Danielyan (2025-02-10T09:58:47.065Z)]: Hi everyone. I have deployed FastAPI on Azure, and from there, I connect to the Weaviate cloud serverless via URL. After deployment, everything works fine. However, after some time, when I make a hybrid search call, I get a timeout error.\nQuery call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.DEADLINE_EXCEEDED\n\nI don’t encounter these types of errors when calling from my local machine. I’ve noticed that if do periodic calls to Weaviate, the errors disappear (I guess server sleeps after some time of inactivity). I believe this might be related to latency or network issues. I have ensured that the Weaviate server is as close as possible to the Azure deployment region. Increasing timeout for queries didn’t help.\nIf you have any ideas on how to resolve this, I would appreciate your help.\n\n----------\n\n[DudaNogueira (2025-02-10T19:22:49.195Z)]: hi @Tatul_Danielyan !!\nWelcome to our community \nThe best place for any support on a weaviate hosted in our cloud is to open a support ticket at Weaviate Cloud\nThis will allow us to take a look on your cluster and have logs that we can work with.\nThis message (I am assuming it’s from the client) indeed points to some latency/network issues, and most probably from the client running in azure to where Weaviate is running.\nHave you tried increasing the query timeout?\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Utilize the Python client library to access Weaviate and streamline data processes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!\nThanks!",
    "date_created": "2025-02-10T09:58:46.989Z",
    "has_accepted_answer": false,
    "title": "Azure FastAPI GRPC search failed to Weaviate cloud",
    "topic_id": 10214
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-08-10T04:59:47.028Z)]: On the local embedded version of Weaviate, I keep getting a fetch failed error:\n(node:56242) UnhandledPromiseRejectionWarning: TypeError: fetch failed\n    at Object.fetch (node:internal/deps/undici/undici:11457:11)\n    at async file:///Users/tejas1/Documents/Code/_Constella/desktop-electron-app/node_modules/graphql-request/src/index.ts:191:12\n    at async makeRequest (file:///Users/tejas1/Documents/Code/_Constella/desktop-electron-app/node_modules/graphql-request/src/index.ts:408:20)\n    at async getWeaviateClient (/Users/tejas1/Documents/Code/_Constella/desktop-electron-app/src/db/weaviate.js:62:12)\n\nMy code is:\n// connects to client -> creates collection -> adds data -> searches\nexport const testWeaviateClient = async () => {\n  const client = await clientPromise;\n  await client.embedded.start();\n\n  try {\n    const className = 'NodeNew';\n    const classObj = {\n      class: className,\n      properties: [\n        {\n          name: 'title',\n          dataType: ['text'],\n        },\n        {\n          name: 'content',\n          dataType: ['text'],\n        },\n      ],\n      vectorizer: 'none',\n    };\n    await client.schema.classCreator().withClass(classObj).do();\n  } catch (err) {\n    console.log('COLLECTION ALREADY EXISTS');\n  }\n\n  let result = await client.data\n    .creator()\n    .withClassName('NodeNew')\n    .withProperties({\n      title: 'napolean bonaparte',\n      content: 'an emperor of France',\n    })\n    .withVector(Array(1536).fill(0.12345))\n    .do();\n\n  console.log('CREATED NODE');\n  console.log(result);\n\n  // wait 5 seconds to ensure local weaviate is ready\n  await new Promise((resolve) => setTimeout(resolve, 5000));\n  console.log('STARTING SEARCH');\n\n  result = await client.graphql\n    .get()\n    .withClassName('NodeNew')\n    .withNearVector({\n      vector: [\n        -0.0125526935, -0.021168863, -0.01076519, -0.02589537, -0.0070362035,\n        0.019870078, -0.010001986, -0.019120263, 0.00090044655, -0.017393013,\n        0.021302758, 0.010055545, 0.02937665, -0.003816019, 0.007692291,\n        0.012385325, 0.032750815, 0.020847514, 0.020311933, -0.022159688,\n        -0.0009924996, 0.009399457, 0.0022226637, -0.029510546, 0.014393755,\n        -0.007223657, 0.018276723, -0.03639277, -0.010001986, -0.022842556,\n        0.010363504, -0.020927852, -0.006929087, -0.022521207, -0.007652122,\n        -0.011126708, 0.0279038, -0.01721895, 0.016482525, 0.002281243,\n        -0.00169294, 0.009191919, -0.019655844, -0.022869334, -0.012412104,\n        0.0031967526, -0.0033457114, -0.01483561, -0.03173321, 0.004746592,\n        0.010095714, 0.007973471, -0.032134898, -0.023739655, -0.008040419,\n        0.018290112, -0.013637247, -0.008488968, 0.024623364, -0.039365247,\n        -0.0032586793, 0.0009606995, -0.029510546, 0.0063265576, -0.019602288,\n        0.003081268, 0.013463182, -0.006601043, 0.019910246, -0.01542475,\n        0.0367409, -0.01193008, 0.012961075, -0.015625594, 0.0062462203,\n        -0.0058646183, -0.0059248717, 0.01889264, 0.008127451, 0.0037155973,\n        0.037142586, -0.025373178, -0.005503101, 0.014982895, 0.035053816,\n        -0.012432188, -0.017285896, 0.022936283, 0.0024620018, 0.016937768,\n        -0.0062127467, 0.02154377, 0.0066378643, 0.029698, 0.0013071538,\n        0.0043850746, -0.008040419, 0.024797428, -0.012452273, -0.025132166,\n        -0.0031900578, 0.0000019433794, -0.002378317, -0.008629559, 0.0126732,\n        -0.0022494427, 0.0009623732, 0.0035582704, 0.017312676, -0.024569806,\n        -0.008890655, 0.023056788, 0.014902558, -0.047104403, -0.009011161,\n        -0.030447815, 0.017982153, -0.0042009684, -0.00654079, 0.00069249026,\n        0.011936775, 0.023378137, 0.025105387, -0.009245478, 0.030929837,\n        0.00394322, 0.02123581, -0.0042545265, 0.0022578111, -0.017259117,\n        0.047157962, -0.00022029977, 0.03497348, -0.00072094303, -0.023605758,\n        0.036499888, -0.015384582, 0.011099929, -0.0139519, -0.03408977,\n        0.013155223, 0.030501373, -0.026698742, 0.004311432, -0.010236303,\n        0.011361024, 0.023793213, -0.00014874942, 0.0020352101, 0.0026829292,\n        0.00989487, 0.0074780583, 0.02734144, 0.003826061, 0.011722542,\n        0.00712993, -0.013992069, 0.0009406152, 0.010785274, -0.012325072,\n        0.01692438, 0.010617905, 0.016750315, -0.0070295087, 0.017687583,\n        0.038320865, 0.020485997, 0.005054551, -0.018812304, 0.0007201062,\n        0.0015381235, 0.0349467, 0.014728494, 0.050773136, -0.017901815,\n        0.0027716348, 0.0064704954, 0.026671965, -0.015063233, -0.013536825,\n        0.016696757, 0.008127451, 0.026966535, 0.029912233, -0.0031431946,\n        0.015156959, 0.012412104, -0.047907773, 0.022012403, -0.027006702,\n        -0.0069491714, 0.010718327, 0.011976943, -0.008127451, -0.65212417,\n        0.00024289463, 0.0051214993, -0.013007938, 0.022373922, 0.0337952,\n        -0.0026829292, -0.0110463705, -0.013034717, -0.0012167745, 0.010062239,\n        -0.0023013272, 0.024409132, -0.009118277, -0.020191427, -0.01597372,\n        0.010115798, -0.030929837, -0.010932559, 0.010912475, -0.0009841312,\n        0.010571042, -0.008348378, -0.009104887, 0.02711382, 0.0036553445,\n        -0.018263333, -0.030876279, 0.014594599, 0.037704945, -0.030126465,\n        0.014366977, 0.0055533117, 0.003487975, 0.044988856, 0.009881481,\n        -0.012699978, 0.041132666, 0.01744657, 0.05417408, -0.004686339,\n        0.016121006, 0.0070495927, 0.015478308, -0.020593112, 0.0012376956,\n        0.027127208, -0.0051248465, 0.0005979267, 0.0063366, -0.008616169,\n        0.027877023, -0.00042679158, 0.008442105, 0.00069751136, 0.023806602,\n        0.029296314, -0.0047332025, 0.027877023, 0.0033005215, 0.014996285,\n        -0.0061424514, 0.00451897, 0.015531867, -0.015317634, 0.044185482,\n        0.010196134, 0.007504837, 0.012405409, -0.030126465, 0.03821375,\n        0.0256008, -0.016710145, 0.0032804373, -0.013884953, 0.022775607,\n        0.030608488, -0.023431696, -0.008502358, 0.008683117, -0.0045490963,\n        -0.0030143203, -0.024074392, 0.00874337, 0.009466405, -0.0072370465,\n        -0.021383096, 0.001360712, 0.020298542, 0.0040168623, 0.008201093,\n        0.011106623, -0.03202778, 0.0046461704, -0.00088370964, -0.008957602,\n        0.0057575023, 0.00037407028, 0.017259117, -0.0482559, -0.0049507823,\n        -0.024235068, -0.0014418861, 0.004425243, 0.023244241, 0.0107919695,\n        -0.017058274, 0.0183035, 0.033339955, -0.009091497, 0.000118936776,\n        0.0031900578, -0.000044483608, -0.017058274, 0.001529755, -0.027984139,\n        0.02740839, -0.015344413, 0.015264076, -0.01719217, 0.010463926,\n        -0.0067048124, 0.014942727, -0.00026653553, 0.02677908, -0.00036570182,\n        -0.043194655, -0.022855945, -0.011294077, 0.005764197, 0.004910614,\n        -0.0029724778, 0.0056637754, -0.01425986, -0.000008708432, 0.01866502,\n        0.031626094, 0.0050378144, 0.015451529, 0.009406152, -0.030742384,\n        -0.0024318753, -0.029751558, -0.008348378, 0.0028519721, -0.008388547,\n        -0.010611211, 0.0139519, -0.0006895613, -0.001230164, -0.0062462203,\n        -0.013510046, 0.010617905, -0.010229609, 0.022213247, -0.00610563,\n        -0.00568386, -0.0056503857, 0.02416812, -0.0076253433, 0.015183738,\n        -0.005188447, -0.016080838, 0.013516741, 0.0062897364, -0.0068520973,\n        0.021396484, 0.007799407, -0.01721895, -0.025266062, 0.013791226,\n        -0.017205559, -0.002068684, 0.032938268, 0.014661547, 0.023552202,\n        -0.005827797, -0.008442105, -0.0074914475, 0.009111582, 0.016817262,\n        -0.0050244248, -0.005871313, -0.008368462, 0.040329296, 0.008683117,\n        0.031518977, 0.026109602, -0.025815032, 0.011006202, -0.0034310697,\n        0.019575508, -0.013831395, -0.008676422, -0.008770149, -0.019990584,\n        0.008750064, 0.02851972, 0.0337952, 0.012666505, 0.021383096,\n        -0.027448557, 0.0035448808, -0.016214734, 0.015197128, -0.027582452,\n        -0.0138046155, -0.03899034, 0.008261346, 0.015478308, 0.017888425,\n        0.0153979715, 0.010658074, -0.011581952, 0.02530623, 0.017982153,\n        -0.0059449556, 0.0054294583, 0.0022879376, -0.018758746, -0.0076119537,\n        -0.027689569, 0.013463182, 0.011186961, -0.0063165156, 0.028412605,\n        0.011347636, 0.008709895, -0.003374164, -0.007919913, -0.025828423,\n        0.0033875536, -0.013831395, -0.0035716598, 0.010450536, -0.025172336,\n        0.003990083, -0.00093224674, 0.024047613, 0.008027029, -0.0029440252,\n        0.023458473, 0.016643198, -0.0326437, 0.019147042, 0.01925416,\n        -0.0020151257, 0.0038628823, -0.026738912, 0.0008753412, -0.025105387,\n        0.0069491714, -0.02623011, 0.027033482, -0.0040737675, -0.021034967,\n        0.019468391, 0.0026042655, 0.03467891, 0.016107617, -0.0057139862,\n        -0.011735932, 0.017687583, 0.011628816, 0.015090012, -0.006678033,\n        -0.011715848, -0.01833028, 0.008040419, -0.01921399, -0.03267048,\n        -0.005914829, 0.0014435598, -0.0030662047, 0.005479669, 0.01597372,\n        -0.01454104, 0.023257632, 0.019722793, 0.0344379, 0.006929087,\n        -0.043248214, 0.015853215, 0.012766927, -0.007417805, -0.018316891,\n        -0.01163551, -0.017352844, -0.01978974, 0.015304244, -0.00005920687,\n        0.033580966, -0.0022343795, 0.0047800657, -0.007357552, 0.00033536615,\n        0.00887057, -0.025654359, 0.016388796, -0.011361024, 0.00019090556,\n        0.0060119033, -0.010075629, -0.0131485285, 0.01604067, -0.015531867,\n        0.0035616176, -0.017259117, 0.0035415334, 0.009265562, -0.0043348637,\n        -0.005867966, -0.03283115, -0.004773371, -0.018410617, -0.0095400475,\n        -0.006520706, -0.00414741, 0.031197628, 0.013690805, -0.008984381,\n        -0.022320364, -0.012492441, -0.005724028, 0.09806499, 0.017272506,\n        -0.00007704216, 0.00858939, 0.0030126465, -0.002835235, -0.023753043,\n        -0.025587412, 0.016067449, 0.0024536331, 0.004719813, -0.02908208,\n        0.027743127, 0.0023414958, 0.0152908545, 0.00552988, -0.031974223,\n        0.0019582203, 0.010812053, -0.01952195, -0.00006171741, -0.02241409,\n        0.025252672, 0.013737668, 0.002356559, -0.03719614, 0.021637497,\n        0.033580966, 0.0044453274, -0.0074378895, -0.014715104, -0.01741979,\n        -0.013489962, -0.003221858, 0.0038561875, -0.013121749, -0.012974464,\n        0.012619642, 0.053424265, -0.020459218, 0.011581952, 0.041962817,\n        -0.00087032013, -0.0036988605, -0.0010025419, -0.020392269, 0.014902558,\n        0.021409875, 0.01771436, -0.006483885, 0.036633782, -0.00028808432,\n        0.011983639, 0.014326808, 0.024931323, 0.002629371, -0.01223804,\n        -0.010972728, -0.011253908, 0.013831395, -0.01748674, -0.013777837,\n        -0.0043449057, -0.009292341, -0.0015849868, -0.019455003, -0.031170849,\n        -0.014393755, -0.03778528, -0.0028335615, -0.00785966, -0.027528895,\n        -0.021008188, -0.03786562, -0.0008226199, -0.005539922, 0.011970249,\n        -0.016937768, -0.0044553694, 0.015839826, -0.014929337, -0.011166876,\n        0.0031448682, -0.032402687, -0.011207045, -0.009432931, 0.0034059642,\n        -0.00089124124, -0.009439626, -0.012840569, 0.013610467, 0.008877265,\n        0.006108978, 0.0021289368, 0.039124236, 0.0025557284, -0.004277958,\n        0.02822515, 0.022373922, -0.00888396, 0.032777593, -0.021610718,\n        -0.010490704, -0.0017222296, -0.011113319, -0.024569806, 0.0024703701,\n        0.021155473, -0.004555791, -0.0060353354, 0.008241262, -0.03234913,\n        -0.00048076818, -0.0069960346, 0.02910886, 0.013315897, -0.014728494,\n        0.01454104, -0.00567047, -0.0012602905, 0.0001736456, 0.005302258,\n        -0.0000424961, 0.035589397, -0.01570593, 0.0107919695, 0.0051348885,\n        -0.015331023, -0.0034193539, 0.003625218, -0.010477315, 0.024583196,\n        -0.0030226887, -0.011776101, -0.040115062, -0.009091497, -0.003886314,\n        0.017888425, -0.03143864, -0.008629559, -0.005533227, -0.017138612,\n        0.01338954, -0.02681925, -0.006688075, -0.026538068, 0.0050210776,\n        0.011401193, 0.0076655117, 0.008576, -0.028171593, -0.0022025793,\n        0.005911482, 0.017205559, -0.02066006, -0.0413469, -0.016910989,\n        0.0097944485, 0.020807344, 0.030742384, 0.026738912, -0.011628816,\n        0.03350063, 0.011146792, -0.024556417, 0.019709403, -0.00712993,\n        0.012110839, -0.044694286, 0.02795736, 0.016777094, -0.0054729744,\n        0.025975708, 0.0109191695, 0.009821228, 0.012485746, 0.01571932,\n        0.0018661672, -0.014567819, -0.010972728, 0.0022394005, 0.01626829,\n        0.0014820547, -0.0030026045, 0.004120631, -0.023699487, 0.040918436,\n        0.0011640531, -0.0092856465, -0.0180491, 0.03459857, -0.013161918,\n        -0.0036151758, -0.0073910262, 0.0028737301, -0.017968763, -0.016549472,\n        -0.01355691, 0.0031616052, 0.0067516756, 0.0023096956, -0.0076789013,\n        -0.009955123, 0.011233824, -0.0072906045, 0.016402187, 0.009727501,\n        -0.0153979715, 0.020445827, -0.0042980425, -0.024556417, -0.048496913,\n        -0.026886197, -0.047693543, 0.0007615301, -0.013925122, -0.010437147,\n        0.01483561, -0.0050277724, -0.022266805, 0.02793058, -0.015264076,\n        0.032563362, 0.00472316, 0.017526908, 0.021061746, -0.013818005,\n        -0.021945456, 0.028573278, -0.0313583, 0.016469134, 0.00013180329,\n        -0.000116426236, -0.0018477566, -0.03722292, -0.002868709, 0.001186648,\n        -0.037463933, -0.046568822, 0.0128004, 0.015197128, 0.013054801,\n        -0.017821478, -0.022320364, -0.022012403, 0.013289118, -0.0043516005,\n        -0.0029808464, -0.01660303, -0.03786562, -0.024877766, -0.013356066,\n        -0.006825318, 0.027582452, -0.0042545265, -0.0017063295, 0.024891155,\n        -0.0049240035, -0.014500872, -0.016803874, 0.008127451, 0.022855945,\n        -0.0014284966, -0.006339947, 0.01604067, 0.0026092867, 0.012057281,\n        -0.008569306, 0.00007374708, 0.02766279, -0.025774864, 0.0047064233,\n        -0.024676923, 0.013938512, -0.002286264, -0.011166876, -0.024074392,\n        -0.018450785, -0.0049842563, 0.0035080595, 0.028305488, 0.033286396,\n        -0.003054489, -0.003272069, -0.024502859, 0.021302758, -0.015558646,\n        -0.006798539, 0.005667123, -0.01716539, 0.003325627, 0.00885718,\n        -0.0047767186, -0.0073843314, -0.0038193662, -0.009352594, 0.0209948,\n        0.041507576, -0.036526665, -0.0022661798, -0.035401944, 0.012204566,\n        -0.034759246, -0.008850486, -0.0009975208, -0.00022176426, -0.008629559,\n        -0.015357803, -0.01455443, -0.0059416085, -0.01687082, 0.014487483,\n        -0.0008845465, -0.0010284841, 0.02708704, 0.028653616, 0.0033189321,\n        -0.025373178, 0.0036620393, 0.018772135, -0.0031130682, 0.0070495927,\n        -0.00006830758, -0.017674193, 0.000969068, -0.018290112, -0.005546617,\n        0.0037658082, -0.00016872912, -0.024784038, -0.020860903, 0.02070023,\n        0.0029138986, -0.036285654, -0.041159447, -0.022106132, -0.018651629,\n        0.03435756, -0.008194398, -0.020485997, 0.01660303, 0.026270278,\n        0.0079065235, 0.0015649025, -0.005807713, -0.012733453, -0.0042377897,\n        -0.021891898, -0.0180491, -0.008783538, -0.017111832, 0.005493059,\n        0.011501615, -0.0025657706, -0.018946199, 0.006052072, -0.0120438915,\n        0.010644685, -0.005165015, 0.009881481, 0.02677908, -0.0035716598,\n        0.005449543, 0.021758003, -0.0072035724, 0.010745106, -0.012130924,\n        -0.0011799532, 0.0036620393, -0.0034411119, 0.013028023, 0.045095973,\n        -0.021396484, -0.01895959, 0.016281681, 0.0020050837, 0.008214483,\n        0.004632781, -0.030501373, -0.019709403, -0.021075137, -0.0027230978,\n        -0.015183738, 0.0008828728, 0.015304244, -0.0034578487, -0.02940343,\n        0.015344413, 0.00785966, -0.0026260235, -0.008529137, 0.00442859,\n        0.0013900016, 0.0001500047, -0.024368962, -0.005580091, -0.017205559,\n        -0.0285465, 0.0054729744, -0.0009422889, -0.0076722065, 0.02475726,\n        -0.02241409, -0.016469134, -0.0064370213, 0.00018034037, 0.009044634,\n        -0.0044486746, 0.000060462142, -0.014942727, 0.026658574, -0.0043181265,\n        0.030046128, -0.042043157, 0.016616419, -0.007170099, 0.02040566,\n        -0.008227873, 0.025975708, -0.027877023, -0.022668492, 0.0051181517,\n        -0.007116541, 0.016522693, -0.0025373178, -0.0018259985, -0.015906774,\n        0.013858174, -0.019843299, 0.0029942358, -0.01632185, -0.029831896,\n        -0.024007445, -0.0045022327, -0.015946941, 0.030662047, 0.18091947,\n        -0.016576251, 0.003936525, 0.039659817, -0.008160925, 0.021168863,\n        0.026002487, -0.0043248213, -0.008488968, 0.0125526935, -0.007839575,\n        0.024020836, -0.014500872, 0.008529137, 0.0011925059, -0.015652372,\n        -0.00050880254, -0.0032017739, -0.006353337, -0.03438434, -0.013208781,\n        -0.0023113694, -0.011608731, -0.015411361, 0.022842556, 0.0013423014,\n        -0.0017356192, -0.005104762, 0.0062395255, 0.0056403438, 0.0061960095,\n        -0.033018608, 0.0053591635, -0.02067345, -0.001453602, -0.013289118,\n        -0.02851972, 0.028118035, 0.0052687842, 0.01338954, -0.0035314912,\n        0.009673943, 0.009191919, 0.01281379, -0.013992069, 0.008134145,\n        -0.004575875, 0.0015013022, -0.00028620142, 0.03550906, -0.0512016,\n        0.010477315, 0.008897349, 0.03347385, -0.02471709, 0.0011297425,\n        0.005851229, -0.019588897, 0.012037196, 0.010182745, 0.0065776114,\n        0.030233582, -0.01309497, 0.018839084, -0.024623364, 0.0072370465,\n        -0.02241409, 0.03400943, -0.00069207186, -0.014674936, -0.0031833632,\n        -0.024784038, -0.02645773, -0.012793706, -0.0008506542, -0.03583041,\n        -0.012325072, 0.026966535, 0.01018944, 0.013356066, -0.02474387,\n        -0.014326808, -0.007658817, 0.012827179, -0.02740839, -0.015277465,\n        0.021784782, -0.0015858236, -0.0018460829, 0.0004573365, -0.0057072914,\n        -0.019588897, 0.0058411867, -0.002308022, -0.00066278223, 0.006460453,\n        -0.00038369402, 0.018705187, -0.009078108, -0.020298542, -0.035991084,\n        -0.047211517, 0.018571293, -0.0041775363, -0.008676422, -0.002138979,\n        -0.007504837, -0.00078579865, 0.014621378, -0.0043850746, -0.01455443,\n        -0.015906774, 0.0010176051, 0.006935782, 0.025199115, -0.0038093242,\n        0.013690805, -0.022253416, 0.036874793, -0.019053316, -0.0044821487,\n        0.0042377897, 0.005998514, 0.0064102425, 0.008080588, -0.028064476,\n        -0.025239283, 0.0070295087, 0.023083568, -0.028653616, -0.010771885,\n        -0.019280938, -0.005563354, -0.012579473, -0.005258742, 0.0012109166,\n        0.015531867, -0.017339455, 0.016241511, 0.0069424766, 0.015652372,\n        0.014380367, 0.006791844, -0.0023967277, 0.037945956, -0.0285465,\n        0.02128937, 0.0049942983, -0.029831896, -0.023819992, -0.016281681,\n        -0.0031850368, 0.0029691304, -0.0038227136, 0.023645928, -0.036473107,\n        -0.02153038, -0.025279451, -0.010242999, 0.018156216, -0.025413347,\n        0.0036218707, 0.005111457, -0.014487483, -0.0059784297, -0.013690805,\n        -0.171279, -0.0037222921, 0.01626829, -0.010417062, -0.0007322405,\n        -0.001834367, 0.008776844, -0.012867348, -0.005884703, -0.0027147292,\n        0.022306973, 0.0042244, -0.049300287, -0.0157461, 0.016054058,\n        0.002781677, 0.00197161, 0.007980166, -0.014366977, -0.0071834885,\n        0.021048358, -0.024971493, 0.017955374, -0.007692291, 0.0043683373,\n        0.018557902, 0.01570593, 0.0027063608, 0.0011791164, -0.03698191,\n        -0.014875779, 0.008455494, 0.016536081, 0.009486489, -0.001415107,\n        0.002960762, -0.008368462, -0.021878509, -0.022454258, 0.004686339,\n        0.012392019, 0.04394447, 0.016121006, -0.0068085813, 0.014085797,\n        -0.0022946324, 0.008509053, -0.0063868104, 0.022333752, -0.026591627,\n        0.006497274, -0.01454104, 0.0080337245, -0.0059014396, 0.01602728,\n        0.02651129, -0.010738411, 0.014567819, -0.010303251, -0.031010175,\n        -0.03821375, -0.0056403438, -0.00006835988, -0.0011732584, -0.021945456,\n        -0.011146792, -0.023498643, 0.021409875, -0.026712133, -0.004190926,\n        0.002542339, 0.0062462203, -0.004522317, -0.02967122, 0.008334989,\n        0.00029415145, -0.018544514, 0.022240026, -0.024261847, -0.021811562,\n        -0.020566333, 0.0390439, -0.025466906, 0.014059017, 0.013476572,\n        -0.007451279, -0.0101760505, -0.021918677, 0.004093852, -0.003772503,\n        0.034304, -0.029483767, -0.025574021, -0.015893385, -0.003407638,\n        0.030233582, 0.007799407, 0.00002280406, 0.021838339, -0.01633524,\n        -0.006875529, -0.010229609, 0.0053256894, 0.02011109, -0.010885696,\n        0.04016862, 0.028760733, 0.015183738, 0.013061496, -0.0073307734,\n        0.0077324593, 0.007739154, 0.015344413, 0.03783884, -0.012124228,\n        0.0145276515, -0.00086027797, 0.0006744981, 0.035375167, -0.0044620642,\n        0.030903058, 0.01567915, -0.0053189946, -0.014045628, -0.018852472,\n        0.0035683124, -0.09554776, -0.013791226, -0.015116791, 0.0013891648,\n        -0.026377395, 0.019147042, -0.008254652, 0.040623866, -0.01656286,\n        0.01948178, 0.01310836, -0.006025293, 0.005971735, -0.0051348885,\n        0.019843299, 0.02007092, -0.027421778, 0.00007709446, 0.0038896615,\n        0.005737418, 0.010095714, -0.0044988855, 0.011294077, -0.001899641,\n        -0.01567915, 0.007216962, -0.02095463, 0.024797428, -0.0064805374,\n        0.010691548, 0.01208406, -0.012867348, -0.0057775867, -0.023110347,\n        -0.019588897, 0.0060821986, -0.019374665, -0.0061391043, 0.031331524,\n        -0.018490955, 0.004043641, 0.0032017739, -0.003973346, -0.014982895,\n        0.008696507, -0.025989097, 0.007156709, 0.013523435, -0.0041139363,\n        -0.03055493, -0.02793058, -0.011106623, -0.02851972, 0.023753043,\n        0.04689017, 0.0035850494, 0.009834617, 0.0096003, 0.016147785,\n        0.019856688, 0.0031582578, 0.004666255, -0.00829482, 0.0395527,\n        -0.01077858, -0.020512775, -0.020512775, 0.012057281, 0.027006702,\n        -0.021999015, -0.009633774, 0.02878751, -0.026645185, -0.005057899,\n        -0.016964547, 0.003315585, -0.02910886, -0.008107367, 0.0138046155,\n        -0.023538811, -0.0028804247, -0.03491992, 0.0076789013, -0.03781206,\n        0.014032238, 0.019642456, 0.021798171, -0.0074780583, -0.01602728,\n        -0.011909996, -0.015183738, 0.0031063734, 0.0016686714, -0.036553446,\n        -0.0018594724, 0.015906774, -0.009225393, 0.006755023, 0.0065776114,\n        0.0139117325, -0.0045524435, 0.0051583205, -0.049166393, 0.018477565,\n        -0.010182745, 0.0031398472, 0.022614934, 0.0048905294, 0.027234325,\n        -0.005191794, 0.026966535, -0.0012477378, -0.029483767, 0.010303251,\n        -0.0072370465, 0.015505088, -0.015183738, -0.009948429, 0.00054185797,\n        -0.016844042, 0.0015339392, -0.008495663, 0.01105976, 0.008375158,\n        0.013992069, 0.00698934, 0.0035448808, 0.01427325, 0.0080538085,\n        0.005382595, -0.021677665, 0.004900572, 0.008977687, -0.034812804,\n        0.005998514, 0.024984881, 0.0032687215, -0.02795736, 0.009124972,\n        0.0022778956, 0.0038126716, 0.012646421, 0.0019180516, -0.0128004,\n        0.013034717, -0.046033237, -0.00021506949, -0.005104762, -0.010309946,\n        0.0054093744, 0.01632185, -0.005737418, 0.016937768, 0.010945949,\n        -0.018129438, 0.0039532618, -0.0047432445, -0.04051675, 0.03703547,\n        0.007551701, 0.0031264576, 0.00073935365, 0.012887432, 0.00020000625,\n        0.003869577, -0.012961075, -0.010443841, 0.038481537, 0.0037089025,\n        -0.013643941, 0.03639277, -0.040329296, -0.022293584, 0.004087157,\n        0.011709153, 0.014902558, -0.006122367, 0.007852965, 0.003081268,\n        0.018571293, -0.0077190697, 0.020927852, 0.021195643, -0.00010554723,\n        -0.029055303, 0.006269652, 0.029885454, 0.0060554193, -0.0075583956,\n        0.0008188541, 0.013041412, -0.006453758, -0.03467891, 0.005814408,\n        0.015090012, 0.010383588, 0.013818005, 0.018504344, -0.025761476,\n        -0.011856438, 0.0052219206, 0.021423263, 0.00829482, -0.009881481,\n        -0.01326234, -0.0038093242, -0.016951159, -0.005590133, -0.0067115068,\n        -0.03483958, -0.010838833, 0.01717878, 0.038053073, -0.015612204,\n        -0.004231095, 0.008027029, -0.008040419, 0.025667747, -0.005677165,\n        -0.016455745, -0.028010918, 0.024342183, 0.010095714, 0.014219692,\n        0.016910989, -0.00083266204, 0.010182745, 0.021516992, 0.011950164,\n        -0.03055493, -0.012104144, 0.004468759, -0.006969256, -0.014393755,\n        -0.021342928, 0.0085626105, -0.015665762, 0.0021841687, -0.004234442,\n        0.030715605, -0.017138612, 0.042712633, 0.0062462203, 0.020057531,\n        0.008073892, -0.0326437, 0.01250583, 0.024342183, 0.04747931,\n        -0.027020091, 0.0019414834, 0.015170349, -0.016362019, 0.02825193,\n        -0.009566827, -0.039954387, -0.00697595, -0.023927107, -0.0285465,\n        -0.000100316945, -0.024850987, 0.022963062, 0.002122242, 0.027877023,\n        0.0012870695, -0.018182995, -0.0079266075, 0.016174564, -0.010068934,\n        -0.015090012, -0.0054227635, 0.0051516257, -0.013235561, -0.0075583956,\n        -0.0131485285, 0.039365247, 0.0065575275, -0.011474836, 0.0028268667,\n        -0.004425243, -0.0020703576, -0.010631295, -0.011702458, -0.0038394507,\n        0.0059784297, 0.032268792, 0.02244087, -0.023458473, -0.0053859423,\n        -0.01925416,\n      ],\n    })\n    .withLimit(2)\n    .withFields('content title { distance }')\n    .do();\n\n  console.log('SEARCH RESULTS:');\n  console.log(JSON.stringify(result, null, 2));\n\n  return await clientPromise;\n};\n\n\nConnecting to a node, creating a collection, and adding a node seems to work fine. Just the searching part seems to be giving this opaque error.\n\n----------\n\n[DudaNogueira (2024-08-12T21:17:24.412Z)]: hi @Tejas_Sharma !!\nWelcome to our community \nyour query is asking for\ncontent title { distance }\n\nwhere it should ask for\ncontent title _additional { distance }\n\nI was not able to get this from the error message, and had to reproduce it in code to catch that error.\nMore on additional graphql metadata here\nand this is the code I used to reproduce it (it’s a mix of your code and the example in embedded)\nimport weaviate, { EmbeddedOptions } from 'weaviate-ts-embedded';\n\n// if (process.platform !== 'linux') {\n//   throw new Error('EmbeddedDB only supports Linux at the moment. Try me in a Docker container!');\n// }\n\nconst client = weaviate.client(\n  new EmbeddedOptions({\n    port: 9898,\n  }),\n  {\n    scheme: 'http',\n    host: 'localhost:9898',\n  }\n);\n\nconsole.log('Weaviate binary:', client.embedded?.options.binaryPath);\nconsole.log('Data path:', client.embedded?.options.persistenceDataPath);\n\nawait client.embedded.start();\nawait client.schema.classDeleter().withClassName(\"NodeNew\").do()\ntry {\n  const className = 'NodeNew';\n  const classObj = {\n    class: className,\n    properties: [\n      {\n        name: 'title',\n        dataType: ['text'],\n      },\n      {\n        name: 'content',\n        dataType: ['text'],\n      },\n    ],\n    vectorizer: 'none',\n  };\n  await client.schema.classCreator().withClass(classObj).do();\n} catch (err) {\n  console.log('COLLECTION ALREADY EXISTS');\n}\n\nlet result = await client.data\n    .creator()\n    .withClassName('NodeNew')\n    .withProperties({\n      title: 'napolean bonaparte',\n      content: 'an emperor of France',\n    })\n    .withVector(Array(1536).fill(0.12345))\n    .do();\n\nconsole.log('CREATED NODE');\nconsole.log(result);\n\nconst query = await client.graphql\n.get()\n.withClassName('NodeNew')\n.withNearVector({\n  vector: [\n    -0.0125526935, -0.021168863, -0.01076519, -0.02589537, -0.0070362035,\n    0.019870078, -0.010001986, -0.019120263, 0.00090044655, -0.017393013,\n    0.021302758, 0.010055545, 0.02937665, -0.003816019, 0.007692291,\n    0.012385325, 0.032750815, 0.020847514, 0.020311933, -0.022159688,\n    -0.0009924996, 0.009399457, 0.0022226637, -0.029510546, 0.014393755,\n    -0.007223657, 0.018276723, -0.03639277, -0.010001986, -0.022842556,\n    0.010363504, -0.020927852, -0.006929087, -0.022521207, -0.007652122,\n    -0.011126708, 0.0279038, -0.01721895, 0.016482525, 0.002281243,\n    -0.00169294, 0.009191919, -0.019655844, -0.022869334, -0.012412104,\n    0.0031967526, -0.0033457114, -0.01483561, -0.03173321, 0.004746592,\n    0.010095714, 0.007973471, -0.032134898, -0.023739655, -0.008040419,\n    0.018290112, -0.013637247, -0.008488968, 0.024623364, -0.039365247,\n    -0.0032586793, 0.0009606995, -0.029510546, 0.0063265576, -0.019602288,\n    0.003081268, 0.013463182, -0.006601043, 0.019910246, -0.01542475,\n    0.0367409, -0.01193008, 0.012961075, -0.015625594, 0.0062462203,\n    -0.0058646183, -0.0059248717, 0.01889264, 0.008127451, 0.0037155973,\n    0.037142586, -0.025373178, -0.005503101, 0.014982895, 0.035053816,\n    -0.012432188, -0.017285896, 0.022936283, 0.0024620018, 0.016937768,\n    -0.0062127467, 0.02154377, 0.0066378643, 0.029698, 0.0013071538,\n    0.0043850746, -0.008040419, 0.024797428, -0.012452273, -0.025132166,\n    -0.0031900578, 0.0000019433794, -0.002378317, -0.008629559, 0.0126732,\n    -0.0022494427, 0.0009623732, 0.0035582704, 0.017312676, -0.024569806,\n    -0.008890655, 0.023056788, 0.014902558, -0.047104403, -0.009011161,\n    -0.030447815, 0.017982153, -0.0042009684, -0.00654079, 0.00069249026,\n    0.011936775, 0.023378137, 0.025105387, -0.009245478, 0.030929837,\n    0.00394322, 0.02123581, -0.0042545265, 0.0022578111, -0.017259117,\n    0.047157962, -0.00022029977, 0.03497348, -0.00072094303, -0.023605758,\n    0.036499888, -0.015384582, 0.011099929, -0.0139519, -0.03408977,\n    0.013155223, 0.030501373, -0.026698742, 0.004311432, -0.010236303,\n    0.011361024, 0.023793213, -0.00014874942, 0.0020352101, 0.0026829292,\n    0.00989487, 0.0074780583, 0.02734144, 0.003826061, 0.011722542,\n    0.00712993, -0.013992069, 0.0009406152, 0.010785274, -0.012325072,\n    0.01692438, 0.010617905, 0.016750315, -0.0070295087, 0.017687583,\n    0.038320865, 0.020485997, 0.005054551, -0.018812304, 0.0007201062,\n    0.0015381235, 0.0349467, 0.014728494, 0.050773136, -0.017901815,\n    0.0027716348, 0.0064704954, 0.026671965, -0.015063233, -0.013536825,\n    0.016696757, 0.008127451, 0.026966535, 0.029912233, -0.0031431946,\n    0.015156959, 0.012412104, -0.047907773, 0.022012403, -0.027006702,\n    -0.0069491714, 0.010718327, 0.011976943, -0.008127451, -0.65212417,\n    0.00024289463, 0.0051214993, -0.013007938, 0.022373922, 0.0337952,\n    -0.0026829292, -0.0110463705, -0.013034717, -0.0012167745, 0.010062239,\n    -0.0023013272, 0.024409132, -0.009118277, -0.020191427, -0.01597372,\n    0.010115798, -0.030929837, -0.010932559, 0.010912475, -0.0009841312,\n    0.010571042, -0.008348378, -0.009104887, 0.02711382, 0.0036553445,\n    -0.018263333, -0.030876279, 0.014594599, 0.037704945, -0.030126465,\n    0.014366977, 0.0055533117, 0.003487975, 0.044988856, 0.009881481,\n    -0.012699978, 0.041132666, 0.01744657, 0.05417408, -0.004686339,\n    0.016121006, 0.0070495927, 0.015478308, -0.020593112, 0.0012376956,\n    0.027127208, -0.0051248465, 0.0005979267, 0.0063366, -0.008616169,\n    0.027877023, -0.00042679158, 0.008442105, 0.00069751136, 0.023806602,\n    0.029296314, -0.0047332025, 0.027877023, 0.0033005215, 0.014996285,\n    -0.0061424514, 0.00451897, 0.015531867, -0.015317634, 0.044185482,\n    0.010196134, 0.007504837, 0.012405409, -0.030126465, 0.03821375,\n    0.0256008, -0.016710145, 0.0032804373, -0.013884953, 0.022775607,\n    0.030608488, -0.023431696, -0.008502358, 0.008683117, -0.0045490963,\n    -0.0030143203, -0.024074392, 0.00874337, 0.009466405, -0.0072370465,\n    -0.021383096, 0.001360712, 0.020298542, 0.0040168623, 0.008201093,\n    0.011106623, -0.03202778, 0.0046461704, -0.00088370964, -0.008957602,\n    0.0057575023, 0.00037407028, 0.017259117, -0.0482559, -0.0049507823,\n    -0.024235068, -0.0014418861, 0.004425243, 0.023244241, 0.0107919695,\n    -0.017058274, 0.0183035, 0.033339955, -0.009091497, 0.000118936776,\n    0.0031900578, -0.000044483608, -0.017058274, 0.001529755, -0.027984139,\n    0.02740839, -0.015344413, 0.015264076, -0.01719217, 0.010463926,\n    -0.0067048124, 0.014942727, -0.00026653553, 0.02677908, -0.00036570182,\n    -0.043194655, -0.022855945, -0.011294077, 0.005764197, 0.004910614,\n    -0.0029724778, 0.0056637754, -0.01425986, -0.000008708432, 0.01866502,\n    0.031626094, 0.0050378144, 0.015451529, 0.009406152, -0.030742384,\n    -0.0024318753, -0.029751558, -0.008348378, 0.0028519721, -0.008388547,\n    -0.010611211, 0.0139519, -0.0006895613, -0.001230164, -0.0062462203,\n    -0.013510046, 0.010617905, -0.010229609, 0.022213247, -0.00610563,\n    -0.00568386, -0.0056503857, 0.02416812, -0.0076253433, 0.015183738,\n    -0.005188447, -0.016080838, 0.013516741, 0.0062897364, -0.0068520973,\n    0.021396484, 0.007799407, -0.01721895, -0.025266062, 0.013791226,\n    -0.017205559, -0.002068684, 0.032938268, 0.014661547, 0.023552202,\n    -0.005827797, -0.008442105, -0.0074914475, 0.009111582, 0.016817262,\n    -0.0050244248, -0.005871313, -0.008368462, 0.040329296, 0.008683117,\n    0.031518977, 0.026109602, -0.025815032, 0.011006202, -0.0034310697,\n    0.019575508, -0.013831395, -0.008676422, -0.008770149, -0.019990584,\n    0.008750064, 0.02851972, 0.0337952, 0.012666505, 0.021383096,\n    -0.027448557, 0.0035448808, -0.016214734, 0.015197128, -0.027582452,\n    -0.0138046155, -0.03899034, 0.008261346, 0.015478308, 0.017888425,\n    0.0153979715, 0.010658074, -0.011581952, 0.02530623, 0.017982153,\n    -0.0059449556, 0.0054294583, 0.0022879376, -0.018758746, -0.0076119537,\n    -0.027689569, 0.013463182, 0.011186961, -0.0063165156, 0.028412605,\n    0.011347636, 0.008709895, -0.003374164, -0.007919913, -0.025828423,\n    0.0033875536, -0.013831395, -0.0035716598, 0.010450536, -0.025172336,\n    0.003990083, -0.00093224674, 0.024047613, 0.008027029, -0.0029440252,\n    0.023458473, 0.016643198, -0.0326437, 0.019147042, 0.01925416,\n    -0.0020151257, 0.0038628823, -0.026738912, 0.0008753412, -0.025105387,\n    0.0069491714, -0.02623011, 0.027033482, -0.0040737675, -0.021034967,\n    0.019468391, 0.0026042655, 0.03467891, 0.016107617, -0.0057139862,\n    -0.011735932, 0.017687583, 0.011628816, 0.015090012, -0.006678033,\n    -0.011715848, -0.01833028, 0.008040419, -0.01921399, -0.03267048,\n    -0.005914829, 0.0014435598, -0.0030662047, 0.005479669, 0.01597372,\n    -0.01454104, 0.023257632, 0.019722793, 0.0344379, 0.006929087,\n    -0.043248214, 0.015853215, 0.012766927, -0.007417805, -0.018316891,\n    -0.01163551, -0.017352844, -0.01978974, 0.015304244, -0.00005920687,\n    0.033580966, -0.0022343795, 0.0047800657, -0.007357552, 0.00033536615,\n    0.00887057, -0.025654359, 0.016388796, -0.011361024, 0.00019090556,\n    0.0060119033, -0.010075629, -0.0131485285, 0.01604067, -0.015531867,\n    0.0035616176, -0.017259117, 0.0035415334, 0.009265562, -0.0043348637,\n    -0.005867966, -0.03283115, -0.004773371, -0.018410617, -0.0095400475,\n    -0.006520706, -0.00414741, 0.031197628, 0.013690805, -0.008984381,\n    -0.022320364, -0.012492441, -0.005724028, 0.09806499, 0.017272506,\n    -0.00007704216, 0.00858939, 0.0030126465, -0.002835235, -0.023753043,\n    -0.025587412, 0.016067449, 0.0024536331, 0.004719813, -0.02908208,\n    0.027743127, 0.0023414958, 0.0152908545, 0.00552988, -0.031974223,\n    0.0019582203, 0.010812053, -0.01952195, -0.00006171741, -0.02241409,\n    0.025252672, 0.013737668, 0.002356559, -0.03719614, 0.021637497,\n    0.033580966, 0.0044453274, -0.0074378895, -0.014715104, -0.01741979,\n    -0.013489962, -0.003221858, 0.0038561875, -0.013121749, -0.012974464,\n    0.012619642, 0.053424265, -0.020459218, 0.011581952, 0.041962817,\n    -0.00087032013, -0.0036988605, -0.0010025419, -0.020392269, 0.014902558,\n    0.021409875, 0.01771436, -0.006483885, 0.036633782, -0.00028808432,\n    0.011983639, 0.014326808, 0.024931323, 0.002629371, -0.01223804,\n    -0.010972728, -0.011253908, 0.013831395, -0.01748674, -0.013777837,\n    -0.0043449057, -0.009292341, -0.0015849868, -0.019455003, -0.031170849,\n    -0.014393755, -0.03778528, -0.0028335615, -0.00785966, -0.027528895,\n    -0.021008188, -0.03786562, -0.0008226199, -0.005539922, 0.011970249,\n    -0.016937768, -0.0044553694, 0.015839826, -0.014929337, -0.011166876,\n    0.0031448682, -0.032402687, -0.011207045, -0.009432931, 0.0034059642,\n    -0.00089124124, -0.009439626, -0.012840569, 0.013610467, 0.008877265,\n    0.006108978, 0.0021289368, 0.039124236, 0.0025557284, -0.004277958,\n    0.02822515, 0.022373922, -0.00888396, 0.032777593, -0.021610718,\n    -0.010490704, -0.0017222296, -0.011113319, -0.024569806, 0.0024703701,\n    0.021155473, -0.004555791, -0.0060353354, 0.008241262, -0.03234913,\n    -0.00048076818, -0.0069960346, 0.02910886, 0.013315897, -0.014728494,\n    0.01454104, -0.00567047, -0.0012602905, 0.0001736456, 0.005302258,\n    -0.0000424961, 0.035589397, -0.01570593, 0.0107919695, 0.0051348885,\n    -0.015331023, -0.0034193539, 0.003625218, -0.010477315, 0.024583196,\n    -0.0030226887, -0.011776101, -0.040115062, -0.009091497, -0.003886314,\n    0.017888425, -0.03143864, -0.008629559, -0.005533227, -0.017138612,\n    0.01338954, -0.02681925, -0.006688075, -0.026538068, 0.0050210776,\n    0.011401193, 0.0076655117, 0.008576, -0.028171593, -0.0022025793,\n    0.005911482, 0.017205559, -0.02066006, -0.0413469, -0.016910989,\n    0.0097944485, 0.020807344, 0.030742384, 0.026738912, -0.011628816,\n    0.03350063, 0.011146792, -0.024556417, 0.019709403, -0.00712993,\n    0.012110839, -0.044694286, 0.02795736, 0.016777094, -0.0054729744,\n    0.025975708, 0.0109191695, 0.009821228, 0.012485746, 0.01571932,\n    0.0018661672, -0.014567819, -0.010972728, 0.0022394005, 0.01626829,\n    0.0014820547, -0.0030026045, 0.004120631, -0.023699487, 0.040918436,\n    0.0011640531, -0.0092856465, -0.0180491, 0.03459857, -0.013161918,\n    -0.0036151758, -0.0073910262, 0.0028737301, -0.017968763, -0.016549472,\n    -0.01355691, 0.0031616052, 0.0067516756, 0.0023096956, -0.0076789013,\n    -0.009955123, 0.011233824, -0.0072906045, 0.016402187, 0.009727501,\n    -0.0153979715, 0.020445827, -0.0042980425, -0.024556417, -0.048496913,\n    -0.026886197, -0.047693543, 0.0007615301, -0.013925122, -0.010437147,\n    0.01483561, -0.0050277724, -0.022266805, 0.02793058, -0.015264076,\n    0.032563362, 0.00472316, 0.017526908, 0.021061746, -0.013818005,\n    -0.021945456, 0.028573278, -0.0313583, 0.016469134, 0.00013180329,\n    -0.000116426236, -0.0018477566, -0.03722292, -0.002868709, 0.001186648,\n    -0.037463933, -0.046568822, 0.0128004, 0.015197128, 0.013054801,\n    -0.017821478, -0.022320364, -0.022012403, 0.013289118, -0.0043516005,\n    -0.0029808464, -0.01660303, -0.03786562, -0.024877766, -0.013356066,\n    -0.006825318, 0.027582452, -0.0042545265, -0.0017063295, 0.024891155,\n    -0.0049240035, -0.014500872, -0.016803874, 0.008127451, 0.022855945,\n    -0.0014284966, -0.006339947, 0.01604067, 0.0026092867, 0.012057281,\n    -0.008569306, 0.00007374708, 0.02766279, -0.025774864, 0.0047064233,\n    -0.024676923, 0.013938512, -0.002286264, -0.011166876, -0.024074392,\n    -0.018450785, -0.0049842563, 0.0035080595, 0.028305488, 0.033286396,\n    -0.003054489, -0.003272069, -0.024502859, 0.021302758, -0.015558646,\n    -0.006798539, 0.005667123, -0.01716539, 0.003325627, 0.00885718,\n    -0.0047767186, -0.0073843314, -0.0038193662, -0.009352594, 0.0209948,\n    0.041507576, -0.036526665, -0.0022661798, -0.035401944, 0.012204566,\n    -0.034759246, -0.008850486, -0.0009975208, -0.00022176426, -0.008629559,\n    -0.015357803, -0.01455443, -0.0059416085, -0.01687082, 0.014487483,\n    -0.0008845465, -0.0010284841, 0.02708704, 0.028653616, 0.0033189321,\n    -0.025373178, 0.0036620393, 0.018772135, -0.0031130682, 0.0070495927,\n    -0.00006830758, -0.017674193, 0.000969068, -0.018290112, -0.005546617,\n    0.0037658082, -0.00016872912, -0.024784038, -0.020860903, 0.02070023,\n    0.0029138986, -0.036285654, -0.041159447, -0.022106132, -0.018651629,\n    0.03435756, -0.008194398, -0.020485997, 0.01660303, 0.026270278,\n    0.0079065235, 0.0015649025, -0.005807713, -0.012733453, -0.0042377897,\n    -0.021891898, -0.0180491, -0.008783538, -0.017111832, 0.005493059,\n    0.011501615, -0.0025657706, -0.018946199, 0.006052072, -0.0120438915,\n    0.010644685, -0.005165015, 0.009881481, 0.02677908, -0.0035716598,\n    0.005449543, 0.021758003, -0.0072035724, 0.010745106, -0.012130924,\n    -0.0011799532, 0.0036620393, -0.0034411119, 0.013028023, 0.045095973,\n    -0.021396484, -0.01895959, 0.016281681, 0.0020050837, 0.008214483,\n    0.004632781, -0.030501373, -0.019709403, -0.021075137, -0.0027230978,\n    -0.015183738, 0.0008828728, 0.015304244, -0.0034578487, -0.02940343,\n    0.015344413, 0.00785966, -0.0026260235, -0.008529137, 0.00442859,\n    0.0013900016, 0.0001500047, -0.024368962, -0.005580091, -0.017205559,\n    -0.0285465, 0.0054729744, -0.0009422889, -0.0076722065, 0.02475726,\n    -0.02241409, -0.016469134, -0.0064370213, 0.00018034037, 0.009044634,\n    -0.0044486746, 0.000060462142, -0.014942727, 0.026658574, -0.0043181265,\n    0.030046128, -0.042043157, 0.016616419, -0.007170099, 0.02040566,\n    -0.008227873, 0.025975708, -0.027877023, -0.022668492, 0.0051181517,\n    -0.007116541, 0.016522693, -0.0025373178, -0.0018259985, -0.015906774,\n    0.013858174, -0.019843299, 0.0029942358, -0.01632185, -0.029831896,\n    -0.024007445, -0.0045022327, -0.015946941, 0.030662047, 0.18091947,\n    -0.016576251, 0.003936525, 0.039659817, -0.008160925, 0.021168863,\n    0.026002487, -0.0043248213, -0.008488968, 0.0125526935, -0.007839575,\n    0.024020836, -0.014500872, 0.008529137, 0.0011925059, -0.015652372,\n    -0.00050880254, -0.0032017739, -0.006353337, -0.03438434, -0.013208781,\n    -0.0023113694, -0.011608731, -0.015411361, 0.022842556, 0.0013423014,\n    -0.0017356192, -0.005104762, 0.0062395255, 0.0056403438, 0.0061960095,\n    -0.033018608, 0.0053591635, -0.02067345, -0.001453602, -0.013289118,\n    -0.02851972, 0.028118035, 0.0052687842, 0.01338954, -0.0035314912,\n    0.009673943, 0.009191919, 0.01281379, -0.013992069, 0.008134145,\n    -0.004575875, 0.0015013022, -0.00028620142, 0.03550906, -0.0512016,\n    0.010477315, 0.008897349, 0.03347385, -0.02471709, 0.0011297425,\n    0.005851229, -0.019588897, 0.012037196, 0.010182745, 0.0065776114,\n    0.030233582, -0.01309497, 0.018839084, -0.024623364, 0.0072370465,\n    -0.02241409, 0.03400943, -0.00069207186, -0.014674936, -0.0031833632,\n    -0.024784038, -0.02645773, -0.012793706, -0.0008506542, -0.03583041,\n    -0.012325072, 0.026966535, 0.01018944, 0.013356066, -0.02474387,\n    -0.014326808, -0.007658817, 0.012827179, -0.02740839, -0.015277465,\n    0.021784782, -0.0015858236, -0.0018460829, 0.0004573365, -0.0057072914,\n    -0.019588897, 0.0058411867, -0.002308022, -0.00066278223, 0.006460453,\n    -0.00038369402, 0.018705187, -0.009078108, -0.020298542, -0.035991084,\n    -0.047211517, 0.018571293, -0.0041775363, -0.008676422, -0.002138979,\n    -0.007504837, -0.00078579865, 0.014621378, -0.0043850746, -0.01455443,\n    -0.015906774, 0.0010176051, 0.006935782, 0.025199115, -0.0038093242,\n    0.013690805, -0.022253416, 0.036874793, -0.019053316, -0.0044821487,\n    0.0042377897, 0.005998514, 0.0064102425, 0.008080588, -0.028064476,\n    -0.025239283, 0.0070295087, 0.023083568, -0.028653616, -0.010771885,\n    -0.019280938, -0.005563354, -0.012579473, -0.005258742, 0.0012109166,\n    0.015531867, -0.017339455, 0.016241511, 0.0069424766, 0.015652372,\n    0.014380367, 0.006791844, -0.0023967277, 0.037945956, -0.0285465,\n    0.02128937, 0.0049942983, -0.029831896, -0.023819992, -0.016281681,\n    -0.0031850368, 0.0029691304, -0.0038227136, 0.023645928, -0.036473107,\n    -0.02153038, -0.025279451, -0.010242999, 0.018156216, -0.025413347,\n    0.0036218707, 0.005111457, -0.014487483, -0.0059784297, -0.013690805,\n    -0.171279, -0.0037222921, 0.01626829, -0.010417062, -0.0007322405,\n    -0.001834367, 0.008776844, -0.012867348, -0.005884703, -0.0027147292,\n    0.022306973, 0.0042244, -0.049300287, -0.0157461, 0.016054058,\n    0.002781677, 0.00197161, 0.007980166, -0.014366977, -0.0071834885,\n    0.021048358, -0.024971493, 0.017955374, -0.007692291, 0.0043683373,\n    0.018557902, 0.01570593, 0.0027063608, 0.0011791164, -0.03698191,\n    -0.014875779, 0.008455494, 0.016536081, 0.009486489, -0.001415107,\n    0.002960762, -0.008368462, -0.021878509, -0.022454258, 0.004686339,\n    0.012392019, 0.04394447, 0.016121006, -0.0068085813, 0.014085797,\n    -0.0022946324, 0.008509053, -0.0063868104, 0.022333752, -0.026591627,\n    0.006497274, -0.01454104, 0.0080337245, -0.0059014396, 0.01602728,\n    0.02651129, -0.010738411, 0.014567819, -0.010303251, -0.031010175,\n    -0.03821375, -0.0056403438, -0.00006835988, -0.0011732584, -0.021945456,\n    -0.011146792, -0.023498643, 0.021409875, -0.026712133, -0.004190926,\n    0.002542339, 0.0062462203, -0.004522317, -0.02967122, 0.008334989,\n    0.00029415145, -0.018544514, 0.022240026, -0.024261847, -0.021811562,\n    -0.020566333, 0.0390439, -0.025466906, 0.014059017, 0.013476572,\n    -0.007451279, -0.0101760505, -0.021918677, 0.004093852, -0.003772503,\n    0.034304, -0.029483767, -0.025574021, -0.015893385, -0.003407638,\n    0.030233582, 0.007799407, 0.00002280406, 0.021838339, -0.01633524,\n    -0.006875529, -0.010229609, 0.0053256894, 0.02011109, -0.010885696,\n    0.04016862, 0.028760733, 0.015183738, 0.013061496, -0.0073307734,\n    0.0077324593, 0.007739154, 0.015344413, 0.03783884, -0.012124228,\n    0.0145276515, -0.00086027797, 0.0006744981, 0.035375167, -0.0044620642,\n    0.030903058, 0.01567915, -0.0053189946, -0.014045628, -0.018852472,\n    0.0035683124, -0.09554776, -0.013791226, -0.015116791, 0.0013891648,\n    -0.026377395, 0.019147042, -0.008254652, 0.040623866, -0.01656286,\n    0.01948178, 0.01310836, -0.006025293, 0.005971735, -0.0051348885,\n    0.019843299, 0.02007092, -0.027421778, 0.00007709446, 0.0038896615,\n    0.005737418, 0.010095714, -0.0044988855, 0.011294077, -0.001899641,\n    -0.01567915, 0.007216962, -0.02095463, 0.024797428, -0.0064805374,\n    0.010691548, 0.01208406, -0.012867348, -0.0057775867, -0.023110347,\n    -0.019588897, 0.0060821986, -0.019374665, -0.0061391043, 0.031331524,\n    -0.018490955, 0.004043641, 0.0032017739, -0.003973346, -0.014982895,\n    0.008696507, -0.025989097, 0.007156709, 0.013523435, -0.0041139363,\n    -0.03055493, -0.02793058, -0.011106623, -0.02851972, 0.023753043,\n    0.04689017, 0.0035850494, 0.009834617, 0.0096003, 0.016147785,\n    0.019856688, 0.0031582578, 0.004666255, -0.00829482, 0.0395527,\n    -0.01077858, -0.020512775, -0.020512775, 0.012057281, 0.027006702,\n    -0.021999015, -0.009633774, 0.02878751, -0.026645185, -0.005057899,\n    -0.016964547, 0.003315585, -0.02910886, -0.008107367, 0.0138046155,\n    -0.023538811, -0.0028804247, -0.03491992, 0.0076789013, -0.03781206,\n    0.014032238, 0.019642456, 0.021798171, -0.0074780583, -0.01602728,\n    -0.011909996, -0.015183738, 0.0031063734, 0.0016686714, -0.036553446,\n    -0.0018594724, 0.015906774, -0.009225393, 0.006755023, 0.0065776114,\n    0.0139117325, -0.0045524435, 0.0051583205, -0.049166393, 0.018477565,\n    -0.010182745, 0.0031398472, 0.022614934, 0.0048905294, 0.027234325,\n    -0.005191794, 0.026966535, -0.0012477378, -0.029483767, 0.010303251,\n    -0.0072370465, 0.015505088, -0.015183738, -0.009948429, 0.00054185797,\n    -0.016844042, 0.0015339392, -0.008495663, 0.01105976, 0.008375158,\n    0.013992069, 0.00698934, 0.0035448808, 0.01427325, 0.0080538085,\n    0.005382595, -0.021677665, 0.004900572, 0.008977687, -0.034812804,\n    0.005998514, 0.024984881, 0.0032687215, -0.02795736, 0.009124972,\n    0.0022778956, 0.0038126716, 0.012646421, 0.0019180516, -0.0128004,\n    0.013034717, -0.046033237, -0.00021506949, -0.005104762, -0.010309946,\n    0.0054093744, 0.01632185, -0.005737418, 0.016937768, 0.010945949,\n    -0.018129438, 0.0039532618, -0.0047432445, -0.04051675, 0.03703547,\n    0.007551701, 0.0031264576, 0.00073935365, 0.012887432, 0.00020000625,\n    0.003869577, -0.012961075, -0.010443841, 0.038481537, 0.0037089025,\n    -0.013643941, 0.03639277, -0.040329296, -0.022293584, 0.004087157,\n    0.011709153, 0.014902558, -0.006122367, 0.007852965, 0.003081268,\n    0.018571293, -0.0077190697, 0.020927852, 0.021195643, -0.00010554723,\n    -0.029055303, 0.006269652, 0.029885454, 0.0060554193, -0.0075583956,\n    0.0008188541, 0.013041412, -0.006453758, -0.03467891, 0.005814408,\n    0.015090012, 0.010383588, 0.013818005, 0.018504344, -0.025761476,\n    -0.011856438, 0.0052219206, 0.021423263, 0.00829482, -0.009881481,\n    -0.01326234, -0.0038093242, -0.016951159, -0.005590133, -0.0067115068,\n    -0.03483958, -0.010838833, 0.01717878, 0.038053073, -0.015612204,\n    -0.004231095, 0.008027029, -0.008040419, 0.025667747, -0.005677165,\n    -0.016455745, -0.028010918, 0.024342183, 0.010095714, 0.014219692,\n    0.016910989, -0.00083266204, 0.010182745, 0.021516992, 0.011950164,\n    -0.03055493, -0.012104144, 0.004468759, -0.006969256, -0.014393755,\n    -0.021342928, 0.0085626105, -0.015665762, 0.0021841687, -0.004234442,\n    0.030715605, -0.017138612, 0.042712633, 0.0062462203, 0.020057531,\n    0.008073892, -0.0326437, 0.01250583, 0.024342183, 0.04747931,\n    -0.027020091, 0.0019414834, 0.015170349, -0.016362019, 0.02825193,\n    -0.009566827, -0.039954387, -0.00697595, -0.023927107, -0.0285465,\n    -0.000100316945, -0.024850987, 0.022963062, 0.002122242, 0.027877023,\n    0.0012870695, -0.018182995, -0.0079266075, 0.016174564, -0.010068934,\n    -0.015090012, -0.0054227635, 0.0051516257, -0.013235561, -0.0075583956,\n    -0.0131485285, 0.039365247, 0.0065575275, -0.011474836, 0.0028268667,\n    -0.004425243, -0.0020703576, -0.010631295, -0.011702458, -0.0038394507,\n    0.0059784297, 0.032268792, 0.02244087, -0.023458473, -0.0053859423,\n    -0.01925416,\n  ],\n})\n.withLimit(2)\n.withFields('content title _additional { distance }')\n.do();\n\nconsole.log('SEARCH RESULTS:', query);\nconsole.log(JSON.stringify(query, null, 2));\n\nconsole.info('\\nStopping...');\nclient.embedded.stop();\nconsole.info('Exiting...');\n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Tejas_Sharma (2024-08-13T13:01:12.737Z)]: Thanks Duda, I think this should work now will try it out",
    "date_created": "2024-08-10T04:59:46.934Z",
    "has_accepted_answer": true,
    "title": "[Question] Fetch failed for embedded weaviate javascript",
    "topic_id": 3325
  },
  {
    "user_id": 1211,
    "conversation": "[Khorppun_Sontipanya (2024-07-17T11:35:13.618Z)]: I create easily sample collection and add data in the collection.\nWhen I try to query that using the exact same words in semantic search, Why distance score (‘A’) from the result not equal to 0 ?\nimage1148×730 32.2 KB\nAm I missing something? This is a correct behavior?\nThank You.\n\n----------\n\n[DudaNogueira (2024-07-17T13:43:37.180Z)]: Hi! @Khorppun_Sontipanya !!\nWelcome to our community!!\nThis is the correct behavior.\nWhen you query (“A”) gets vectorized, it will not return the exact same vectors. So some difference is expected on the distance calculation.\nTake this example:\nimport weaviate\nfrom weaviate.util import generate_uuid5\n\nclient = weaviate.connect_to_local()\n\nclient.collections.delete(\"Test\")\ncollection = client.collections.get(\"Test\")\ncollection.data.insert({\"text\": \"example a\"}, uuid=generate_uuid5(\"example a\"))\ncollection.data.insert({\"text\": \"example b\"}, uuid=generate_uuid5(\"example b\"))\ncollection.data.insert({\"text\": \"example c\"}, uuid=generate_uuid5(\"example c\"))\n\n\nNow if I search with nearText:\nfrom weaviate.classes.query import MetadataQuery\nfor object in collection.query.near_text(\"example a\", return_metadata=MetadataQuery(distance=True)).objects:\n    print(object)\n    print(object.metadata.distance)\n\nI will not get the 0 distance for a.\nIf you search using nearObject, or nearVector, then you can get it:\nfrom weaviate.classes.query import MetadataQuery\nfor object in collection.query.near_object(near_object=generate_uuid5(\"example a\"), return_metadata=MetadataQuery(distance=True)).objects:\n    print(object.properties)\n    print(object.metadata.distance)\n\nwill output:\n\n{‘text’: ‘example a’}\n0.0\n{‘text’: ‘example b’}\n0.05546557903289795\n{‘text’: ‘example c’}\n0.08070778846740723\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Khorppun_Sontipanya (2024-07-18T04:34:28.222Z)]: Thank you very much for the answer. But when I follow you, why are there no output?\nimage1322×533 30.9 KB\n\n----------\n\n[Dirk (2024-07-18T04:50:31.667Z)]: IIRC weaviate also adds the collection name into the vectorized text. Try it again with\nConfigure.Vectorizer.text2vec_openai(\n           ...., vectorize_collection_name=False\n        )",
    "date_created": "2024-07-17T11:35:13.567Z",
    "has_accepted_answer": false,
    "title": "Why distance score not equal to 0 (searching exactly the same words)",
    "topic_id": 3069
  },
  {
    "user_id": 2949,
    "conversation": "[Steven (2024-12-03T08:30:54.051Z)]: Description\nWhen I was trying to populate the database with “db = WeaviateVectorStore.from_documents(docs, hf_emb, client=weaviate_client)”, I received “UnexpectedStatusCodeError: Collection may not exist.! Unexpected status code: 500, with response body: {‘error’: [{‘message’: ‘failed to execute query: leader not found’}]}.”.\nServer Setup Information\nI set up the weaviate instance with Singularity (since docker is not available in my case). I first pulled a built image, and then run the “singularity exec” command as follows:\nsingularity exec \n–bind ~/weaviate_data:/var/lib/weaviate \n–env “QUERY_DEFAULTS_LIMIT=25” \n–env “AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true” \n–env “PERSISTENCE_DATA_PATH=/var/lib/weaviate” \n–env “ENABLE_API_BASED_MODULES=true” \n–env “ENABLE_MODULES=text2vec-ollama,generative-ollama” \n–env “CLUSTER_HOSTNAME=node1” \n~/singularity/weaviate_1.27.6.sif \nweaviate --host 0.0.0.0 --port 8095 --scheme http\n.\n\nWeaviate Server Version: 1.27.6\nDeployment Method: Singularity\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python v4\n\n----------\n\n[DudaNogueira (2024-12-03T12:33:40.269Z)]: hi @Steven !!\nWelcome to our community \nI see you reproduced the docker env vars, so that shouldn’t happen \nCan you try setting RAFT_BOOTSTRAP_EXPECT to 1?\nI don’t have any experience with singularity \nLet me know if this will unblock you, otherwise I can play around with it and try reproducing it myself.\nThanks!\n\n----------\n\n[Steven (2024-12-17T02:07:35.779Z)]: Hi @DudaNogueira ,\nthanks for replying! Unfortunately the issue’s still there:(. Here’s some extra information, maybe that’ll help:\nclient.is_connected() and client.is_live() are both True, but client.ready() is false.\nHere’s the server’s log after starting:\n[\n{\n“build_git_commit”: “9069628”,\n“build_go_version”: “go1.22.10”,\n“build_image_tag”: “v1.28.0”,\n“build_wv_version”: “1.28.0”,\n“level”: “info”,\n“msg”: “attempting to join”,\n“remoteNodes”: [\n“10.5.167.151:8300”\n],\n“time”: “2024-12-17T02:09:49+01:00”\n},\n{\n“build_git_commit”: “9069628”,\n“build_go_version”: “go1.22.10”,\n“build_image_tag”: “v1.28.0”,\n“build_wv_version”: “1.28.0”,\n“level”: “info”,\n“msg”: “attempted to join and failed”,\n“remoteNode”: “10.5.167.151:8300”,\n“status”: 14,\n“time”: “2024-12-17T02:09:49+01:00”\n},\n{\n“action”: “bootstrap”,\n“build_git_commit”: “9069628”,\n“build_go_version”: “go1.22.10”,\n“build_image_tag”: “v1.28.0”,\n“build_wv_version”: “1.28.0”,\n“error”: “could not join a cluster from [10.5.167.151:8300]”,\n“level”: “warning”,\n“msg”: “failed to join cluster”,\n“servers”: [\n“10.5.167.151:8300”\n],\n“time”: “2024-12-17T02:09:49+01:00”,\n“voter”: true\n},\n{\n“action”: “bootstrap”,\n“build_git_commit”: “9069628”,\n“build_go_version”: “go1.22.10”,\n“build_image_tag”: “v1.28.0”,\n“build_wv_version”: “1.28.0”,\n“error”: “rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing: failed to do connect handshake, response: \\\"HTTP/1.1 403 Forbidden…”,\n“level”: “error”,\n“msg”: “failed to notify peers”,\n“servers”: [\n“10.5.167.151:8300”\n],\n“time”: “2024-12-17T02:09:49+01:00”\n}\n]\nThanks again for helping!\n\n----------\n\n[DudaNogueira (2024-12-17T14:53:09.911Z)]: hi @Steven !!\nI will have to save time play around with singularity so I can try figuring it out (never used)\nWhat is the singularity version you are using?",
    "date_created": "2024-12-03T08:30:53.992Z",
    "has_accepted_answer": false,
    "title": "{'error': [{'message': 'leader not found'}]} when using LangChain, and Singularity instead of docker",
    "topic_id": 9067
  },
  {
    "user_id": 3577,
    "conversation": "[bhayubha (2025-02-28T10:36:58.829Z)]: Description\nclient = weaviate.connect_to_local(\nhost=“127.0.0.1”,  # Use a string to specify the host\nport=8080,\ngrpc_port=50051,\n)\nreviews = client.collections.get(“TestArticle”)\nresponse = reviews.query.hybrid(\nquery=“france”,\ntarget_vector=“question_vector”,\nlimit=2\n)\ngetting this error:\nWeaviateQueryError: Query call with protocol GRPC search failed with message .\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2025-02-28T11:01:40.365Z)]: hi @bhayubha !!\nWelcome to our community! \nHow have you deployed this cluster?\nWhat is the version you are running?\nAlso, Can you paste the entire error stack?\nThanks!",
    "date_created": "2025-02-28T10:36:58.782Z",
    "has_accepted_answer": false,
    "title": "Grpc connection issue at the time of hybrid search",
    "topic_id": 10596
  },
  {
    "user_id": 3181,
    "conversation": "[fbernard (2025-01-09T14:29:23.205Z)]: Description\nI am running in a conda env python 3.12 on linux and installed weaviate via pip\nNAME=“Red Hat Enterprise Linux”\nVERSION=“8.10 (Ootpa)”\nthis worked fine on Windows but here I get\nFile “/home/fbernard/.conda/envs/llmao_m4py_DALE/lib/python3.12/site-packages/weaviate/init.py”, line 3, in \nfrom . import classes\nImportError: cannot import name ‘classes’ from partially initialized module ‘weaviate’ (most likely due to a circular import)\nThis is a simple script using only the one file and this fails at the top of the script when it tries to import weaviate…\n\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2025-01-10T11:18:15.379Z)]: hi @fbernard !! Welcome to our community \nCan you provide those?\n\n\n\n fbernard:\n\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method:\nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\n\n\nAlso, can you provide a reproducible example?\nPreferably, by creating a new python environment and running the code you have there.\nThanks!\n\n----------\n\n[fbernard (2025-01-10T12:31:36.698Z)]: I think the problem was that I needed to do ‘pip install weaviate-client’ instead of ‘pip install weaviate’ (which for some reason seemed ok on windows)\nWhen I did this things worked fine.\n\n----------\n\n[DudaNogueira (2025-01-23T14:53:59.954Z)]: Oh…  We do have that as placeholder. \nThanks for sharing!",
    "date_created": "2025-01-09T14:29:23.139Z",
    "has_accepted_answer": true,
    "title": "Python 3.12 import error for weaviate",
    "topic_id": 9652
  },
  {
    "user_id": 2414,
    "conversation": "[nan_dou (2024-10-30T14:20:11.534Z)]: WechatIMG3142022×902 180 KB\nHello! When I log in using the local method, it shows “Failed to connect to Weaviate Couldn’t connect to Weaviate, check your URL/API KEY: [Errno 30] Read-only file system: ‘/home/mjzheng/.cache/weaviate-embedded’.” I know this is because the ‘/home/mjzheng/.cache’ path I am using is read-only since I am using the school’s server. I want to change the cache path to ‘/data2/mjzheng/.cache’. What should I do specifically?\n\n----------\n\n[DudaNogueira (2024-10-30T15:34:01.941Z)]: hi @nan_dou !!\nWelcome to our community \nCan you try defining a different environment variable for XDG_DATA_HOME  right before running Verba?\nAccording to here: Embedded Weaviate | Weaviate\nit should define the persistence path as {XDG_DATA_HOME}/weaviate/\nThanks!\n\n----------\n\n[nan_dou (2024-10-31T11:18:01.774Z)]: oh, thanks. I’ve logged on the front-end page of verba. and i started ollama serve and ollama run llama3 in the background, but I couldn’t get feedback from the model. like this:\n“Query failed: 500, message=‘Internal Server Error’,\nurl=URL(‘http://localhost:11434/api/embed’)”\n\n----------\n\n[DudaNogueira (2024-10-31T12:51:38.621Z)]: Can you paste the entire error stack?\nThis seems a 500 error in ollama.\nDo you see any outstanding errors in\n~/.ollama/logs/server.log\n\n?\n\n----------\n\n[nan_dou (2024-11-01T06:27:00.256Z)]: I still haven’t solved the problem. ollama serve turned like :\nINFO [main] model loaded | tid=“139740393578496” timestamp=1730437064\ntime=2024-11-01T12:57:44.375+08:00 level=INFO source=server.go:626 msg=“llama runner started in 5.02 seconds”\ntime=2024-11-01T12:57:44.424+08:00 level=INFO source=server.go:992 msg=“llm encode error: 500 Internal Server Error\\nn_Map_base::at”,\nand i upload documents to verba failed ,verba log:\n Succesfully retrieved document: 0 documents\nINFO:     127.0.0.1:41544 - “POST /api/get_all_documents HTTP/1.1” 200 OK\nINFO:     127.0.0.1:41534 - “POST /api/get_labels HTTP/1.1” 200 OK\n Succesfully retrieved document: 0 documents\nshould i do to adjust ?\n\n----------\n\n[DudaNogueira (2024-11-01T12:52:32.659Z)]: That is strange.\nCould we do a screen share session? Feel free to join us in our slack so we can align this:\nhttps://weaviate.io/slack\nOne thing we could try doing is entering Weaviate container and try vectorizing something in ollama from there, so we can try getting more from this error message.\n\n----------\n\n[DudaNogueira (2024-11-01T12:53:54.370Z)]: nan_dou:\n\ntime=2024-11-01T12:57:44.424+08:00 level=INFO source=server.go:992 msg=“llm encode error: 500 Internal Server Error\\nn_Map_base::at”,\n\n\nBy the way, this message you got from ollama logs, right?\nThis seems an ollama issue. Are you running the latest ollama version?\nCan you run a docker on that computer? That could make things easier…\n\n----------\n\n[nan_dou (2024-11-01T14:07:42.562Z)]: Dear, it is very regrettable that my server does not have permission to use Docker. I plan to use Start an Embedded Weaviate instance—Python Client v3. However, after executing the Python code, an error occurred as follows. My confusion is that after using the XDG variable for the persistence path, the problem still hasn’t been solved. Is there an error in the way I declare environment variables? Another confusion is how can I deploy Weaviate to my local server? Is there any tutorial?By the way, I am using the local deployment method.\n11719×757 146 KB\nTraceback (most recent call last):\nFile “”, line 1, in \nFile “/data_temp/mjzheng/env/temp_rag/lib/python3.10/site-packages/weaviate/client.py”, line 268, in init\nurl, embedded_db = self.__parse_url_and_embedded_db(url, embedded_options)\nFile “/data_temp/mjzheng/env/temp_rag/lib/python3.10/site-packages/weaviate/client.py”, line 302, in __parse_url_and_embedded_db\nembedded_db = EmbeddedV3(options=embedded_options)\nFile “/data_temp/mjzheng/env/temp_rag/lib/python3.10/site-packages/weaviate/embedded.py”, line 60, in init\nself.ensure_paths_exist()\nFile “/data_temp/mjzheng/env/temp_rag/lib/python3.10/site-packages/weaviate/embedded.py”, line 129, in ensure_paths_exist\nPath(self.options.binary_path).mkdir(parents=True, exist_ok=True)\nFile “/data_temp/mjzheng/env/temp_rag/lib/python3.10/pathlib.py”, line 1175, in mkdir\nself._accessor.mkdir(self, mode)\nOSError: [Errno 30] Read-only file system: ‘/home/mjzheng/.cache/weaviate-embedded’\n\n----------\n\n[DudaNogueira (2024-11-01T14:24:35.307Z)]: This has worked for me.\ntry this:\nmkdir -p /tmp/nan-temp/data\ncd /tmp/nan-temp\nexport XDG_DATA_HOME=/tmp/nan-temp/data\necho \"import weaviate\nclient = weaviate.connect_to_embedded()\nclient.close()\" > app.py\npython3 app.py\nls data/\n\nthis should be the output:\n\n{“action”:“startup”,“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“default_vectorizer_module”:“none”,“level”:“info”,“msg”:“the default vectorizer modules is set to \"none\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer”,“time”:“2024-11-01T11:22:15-03:00”}\n…\nsome logs here…\n…\n{“build_git_commit”:“ab0312d5d”,“build_go_version”:“go1.23.1”,“build_image_tag”:“localhost”,“build_wv_version”:“1.26.6”,“level”:“info”,“msg”:“closing raft-rpc server …”,“time”:“2024-11-01T11:22:19-03:00”}\nclassifications.db                    migration1.22.fs.hierarchy            schema.db\nmigration1.19.filter2search.skip.flag modules.db\nmigration1.19.filter2search.state     raft\n\nLet me know if this works.\nThis will basically set the correct data path, create the path, run the server locally, close the connection, and list the provided data path\n\n----------\n\n[DudaNogueira (2024-11-04T12:08:04.218Z)]: hi @nan_dou !!\nLet me know if this worked for you.\nAlso, if necessary, happy to jump in a call \nHave a great day!\n\n----------\n\n[nan_dou (2024-11-14T09:03:46.886Z)]: Thank you very much for your help. I have successfully used cloud weaviate, and now I want to deploy Embedded Weaviate locally, but I don’t seem to see the command for downloading in Embedded Weaviate | Weaviate\n截屏2024-11-14 17.01.491636×810 92.4 KB\n\n----------\n\n[DudaNogueira (2024-11-14T13:20:52.728Z)]: hi @nan_dou ! Glat to hear that!\nYou run Embedded mode from “within” the client.\nIt will first then download the go binary and run it for you.\nThis is all you need for running with python:\nimport weaviate\nclient = weaviate.connect_to_embedded()\nprint(client.get_meta().get(\"version\"))\n\nnow you content will be stored, by default, at ~/.local/share/weaviate/ (unless you specify otherwise)\nLet me know if that helps!\nThanks!",
    "date_created": "2024-10-30T14:20:11.492Z",
    "has_accepted_answer": false,
    "title": "Couldn't connect to Weaviate, check your URL/API KEY: [Errno 30] Read-only file system: ",
    "topic_id": 7338
  },
  {
    "user_id": 722,
    "conversation": "[moruga123 (2024-08-30T18:31:24.828Z)]: Description\nWhen viewing logs of a batch upsert jobs, I have to wait several minutes between progress bar printouts. I ran the process with python3 -u but it did not help. Does the progress bar in weaviate need to specifically run with some internal print buffer flushing arguments? Can weaviate be updated with this feature?\nServer Setup Information\n\nWeaviate Server Version: docker image version 1.24.2\nDeployment Method:  k8s\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: python, weaviate-client==4.5.3\nMultitenancy?: no\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-08-30T18:37:48.756Z)]: hi @moruga123 !!\nI believe you are talking about the tqdm lib, right?\nIf that’s the case, this is not a builtin feature in Weaviate cliente, but just a wrapper used around the insert.\nHere is more info on tqm:\n  \n      \n\n      tqdm.github.io\n  \n\n  \n    \n\ntqdm documentation\n\n  A Fast, Extensible Progress Meter\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this is the case here.\nthanks!",
    "date_created": "2024-08-30T18:31:24.777Z",
    "has_accepted_answer": false,
    "title": "Batch insert progress bar updates rarely in logs view. Buffer flush?",
    "topic_id": 3935
  },
  {
    "user_id": 908,
    "conversation": "[00.lope.naughts (2024-10-30T02:29:32.215Z)]: Description\nI am using local docker container weaviate instance on a Mac. I have test run with it for past week and have >1.2m doc with embedding vectors. I am on “bring my own vector” case. What I noticed is one day, when I started out the weaviate instance, it will use single digit % in cpu, but after roughly 4-5min, it will ramp up to 500% (I have 12 cores). When I looked at the log, I highly suspect it is running “tombstone_cleanup_begin” (see below for more details). I don’t notice ever this has caused so much CPU and going at it for so long (still waiting…). Is this normal? I did make a lot of deletions. This is only a dev env, we will eventually expect this to be either on weaviate cloud, or roll our own on GCP. But I would like to understand if what’s causing this and if this could disrupt service in a deployment env. Any advice or debug tip will be appreciated. (we are new and still poking around in dev, and touching a little on scalability matter).\nServer Setup Information\n\nWeaviate Server Version: 1.27.0\nDeployment Method: docker version 4.34.3 (170107) on macOS 14.2.1 (23C71)\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: ?\nMultitenancy?: No\n\nAny additional Information\n\n2024-10-29 21:49:29 {“action”:“lsm_recover_from_active_wal”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“class”:“Listing_Text”,“index”:“listing_text”,“level”:“warning”,“msg”:“empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.”,“path”:“/var/lib/weaviate/listing_text/48GOdFIN20rh/lsm/property_baths_searchable/segment-1730088224356409675”,“shard”:“48GOdFIN20rh”,“time”:“2024-10-30T01:49:29Z”}\n2024-10-29 21:49:30 {“action”:“hnsw_prefill_cache_async”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“not waiting for vector cache prefill, running in background”,“time”:“2024-10-30T01:49:30Z”,“wait_for_cache_prefill”:false}\n2024-10-29 21:49:30 {“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“Completed loading shard listing_text_48GOdFIN20rh in 1.691448875s”,“time”:“2024-10-30T01:49:30Z”}\n2024-10-29 21:49:33 {“action”:“hnsw_prefill_cache_async”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“not waiting for vector cache prefill, running in background”,“time”:“2024-10-30T01:49:33Z”,“wait_for_cache_prefill”:false}\n2024-10-29 21:49:33 {“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“Completed loading shard listing_image_48d5dFITJv7f in 4.504469669s”,“time”:“2024-10-30T01:49:33Z”}\n2024-10-29 21:49:57 {“action”:“hnsw_vector_cache_prefill”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“count”:401613,“index_id”:“main”,“level”:“info”,“limit”:2000000,“msg”:“prefilled vector cache”,“time”:“2024-10-30T01:49:57Z”,“took”:26793010096}\n2024-10-29 21:50:37 {“action”:“hnsw_vector_cache_prefill”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“count”:1221520,“index_id”:“main”,“level”:“info”,“limit”:2000000,“msg”:“prefilled vector cache”,“time”:“2024-10-30T01:50:37Z”,“took”:64299448321}\n2024-10-29 21:54:29 {“action”:“tombstone_cleanup_begin”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“class”:“Listing_Image”,“level”:“info”,“msg”:“class Listing_Image: shard 48d5dFITJv7f: starting tombstone cleanup”,“shard”:“48d5dFITJv7f”,“time”:“2024-10-30T01:54:29Z”,“tombstones_in_cycle”:22162,“tombstones_total”:22162}\n\nFocusing on last 2 lines, I think CPU was low up until tombstone_cleanup_begin when it ramped to 500% and after >20min, it is still apparently working on it… since I dont see tombstone_cleanup_complete.\n\n----------\n\n[DudaNogueira (2024-11-01T14:38:09.394Z)]: hi @00.lope.naughts !!\nYou can set the up the aggressiveness of the tombstone cycles:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nEnvironment variables | Weaviate\n\n  To configure Weaviate in a Docker or a Kubernetes deployment, set these environment variables\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYou will want to tweak the TOMBSTONE_DELETION_ variables.\nThis blogpost also can help you understanding how Weaviate uses GC or run cycles:\n\n  \n      \n\n      weaviate.io – 15 Aug 22\n  \n\n  \n    \n\nGOMEMLIMIT is a game changer for high-memory applications | Weaviate\n\n  Go 1.19 introduced GOMEMLIMIT, which completely changes how you can manage memory limits in Go. Learn how it helps Weaviate be more reliable.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!\n\n----------\n\n[00.lope.naughts (2024-11-01T17:30:21.703Z)]: Thanks, I will check out those pages. I looked back at older logs and found the tombstone delete operations took only few sec to a few min even with >10k in size. So the one that got stuck is not out of the norm in terms of size. what I remembered was I shutdown the container, maybe too soon after a large delete op, or maybe I was unlucky doing so during some preset cycle/schedule. I ended up just exporting all data, delete the instance, and just create a new one. I suspect something is corrupted, and I have these old collections saved on disk.\nand so far, I haven’t seen this happen again. perhaps, I shouldnt have just stop the weaviate container, but just “pause” it.\n\n----------\n\n[00.lope.naughts (2024-11-12T17:45:49.504Z)]: Unfortunately, I see my weaviate container instance stuck at CPU intensive cycle for doing tombstone cleanup again, and this time it isnt due to shutdown corruption. I noted that this round, I have caused it delete over 36k in ~3min span.\nI will take a look at TOMBSTONE_DELETION_* to see what I can tune. But it does appear this is prune to happen if I try to delete a large # of docs within a short span of time.",
    "date_created": "2024-10-30T02:29:32.161Z",
    "has_accepted_answer": false,
    "title": "Weaviate using tons of CPU during \"tombstone_cleanup_begin\"",
    "topic_id": 7290
  },
  {
    "user_id": 1527,
    "conversation": "[Oscar_Dalmau_Roig (2024-09-12T15:50:34.104Z)]: Description\nWe are experiencing performance issues with a Weaviate multi-node deployment running in Kubernetes. Problems we are facing:\n\nMemory usage. The memory keeps increasing heavily as there’s more data in the cluster. We can also see it increases every time we perform a backup and it never goes down to the starting level.\nTimeouts. We are getting 500 and 502 errors. We are exposing Weaviate through ingress and have ensured the timeouts are not occurring at the LB level.\n\nWe have tried the following:\n\nUpdate environment variables to optimise memory usage.\nUpdated LB and Weaviate timeout from 60 to 600.\nUpgrade Weaviate to version 1.26.x.\nRefactor collections to use a better replication factor/sharding configuration.\nIncrease Kubernetes nodes capacity and pod requested resources.\n\nLogs are not being really helpful. Sometimes we can see context deadline exceeded but sometimes there are no logs at all until we restart the pods.\nWhen we restart the pods, the memory decreases for a bit and things start working again. However, we have ended up in a situation where we don’t think the memory usage is the only root cause of the issues, as sometimes the pods have enough space to scale memory and the application keeps malfunctioning.\nBelow you can see the values we are using to deploy the Helm chart.\nServer Setup Information\n\nWeaviate Server Version: 1.25.0\nDeployment Method: Kubernetes - Helm chart (17.0.0)\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python3\nMultitenancy?: No\n\nAny additional Information\nValues used to deploy Helm chart:\nUSER-SUPPLIED VALUES:\nannotations:\n  ad.datadoghq.com/weaviate.checks: |-\n    {\n      \"weaviate\": {\n        \"instances\": [\n          {\n            \"openmetrics_endpoint\": \"http://%%host%%:2112/metrics\"\n          }\n        ]\n      }\n    }\nargs:\n- --host\n- 0.0.0.0\n- --port\n- \"8080\"\n- --scheme\n- http\n- --config-file\n- /weaviate-config/conf.yaml\n- --read-timeout=600s\n- --write-timeout=600s\nauthentication:\n  anonymous_access:\n    enabled: false\n  apikey:\n    allowed_keys:\n    - xxxxxxxxxxxxxxxxxx\n    enabled: true\n    users:\n    - api-key-user-admin\nauthorization:\n  admin_list:\n    enabled: true\n    users:\n    - api-key-user-admin\nbackups:\n  s3:\n    enabled: true\n    envconfig:\n      AWS_REGION: us-east-1\n      BACKUP_S3_BUCKET: weaviate-backup-platform-platform-prod-us-east-1\ndebug: false\nenv:\n  LIMIT_RESOURCES: true\n  #LOG_LEVEL: trace\n  PERSISTENCE_LSM_ACCESS_STRATEGY: pread\n  PROMETHEUS_MONITORING_ENABLED: true\n  PROMETHEUS_MONITORING_GROUP: false\n  QUERY_SLOW_LOG_ENABLED: true\nmodules:\n  generative-cohere:\n    enabled: true\n  generative-openai:\n    enabled: true\n  generative-palm:\n    enabled: true\n  qna-openai:\n    enabled: true\n  ref2vec-centroid:\n    enabled: true\n  reranker-cohere:\n    enabled: true\n  text2vec-cohere:\n    enabled: true\n  text2vec-huggingface:\n    enabled: true\n  text2vec-openai:\n    enabled: true\n  text2vec-palm:\n    enabled: true\nquery_defaults:\n  limit: 100\nreplicas: 3\nresources:\n  requests:\n    cpu: 100m\n    memory: 150Gi\nservice:\n  name: weaviate\n  ports:\n  - name: https\n    port: 443\n    protocol: TCP\n  type: ClusterIP\nserviceAccountName: weaviate-sa\nstorage:\n  size: 300Gi\n  storageClassName: weaviate-sc-platform\n\nAll collections were originally created with replication factor 3 and no sharding. Now we are trying to refactor all of them to optimise the setup. We are recreating the collections in a new cluster with the right config, and importing data.\nIn the image below it can be seen how around 2am a backup is performed and the memory is increased. It never goes down again until we restart the pods (13:00).\nimage1940×662 69.6 KB\nLog error examples:\nconnect: Get \"http://10.10.17.12:7001/replicas/indices/collection_name/shards/oc2DaAtccNfT/objects/613aa6d3-b328-4221-8754-ee5fa446c5be?schema_version=0\": context canceled\n\n\"http://10.10.21.74:7001/replicas/indices/collection_name/shards/oc2DaAtccNfT:commit?request_id=weaviate-1-64-191e683965f-3ee\": context deadline exceeded 10.10.21.74:7001: connect: Post\n\n----------\n\n[DudaNogueira (2024-09-13T14:13:07.500Z)]: hi @Oscar_Dalmau_Roig !!\nWelcome to our community \nHave you tried defining a limit to VectorCacheMaxObjects?\nFor more info on this:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nResource Planning | Weaviate\n\n  Weaviate scales well for large projects. Smaller projects, less than 1M objects, do not require resource planning. For medium and large-scale projects, you should plan how to get the best performance from your resources. While you design you system,...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nMaybe it can hold down the memory during backups.\n\n----------\n\n[Oscar_Dalmau_Roig (2024-10-09T08:37:14.085Z)]: Hey @DudaNogueira - thanks for your reply!\nWe are using this value (half the default value):\n“vectorCacheMaxObjects”:500000000000\nWe have also updated our setup with the following configuration:\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: Kubernetes - Helm chart (17.2.1)\nMulti Node? Number of Running Nodes: 6\nClient Language and Version: Python3\nMultitenancy?: No\n\nAny additional Information\nValues used to deploy Helm chart:\nUSER-SUPPLIED VALUES:\nannotations:\n  ad.datadoghq.com/weaviate.checks: |-\n    {\n      \"weaviate\": {\n        \"instances\": [\n          {\n            \"openmetrics_endpoint\": \"http://%%host%%:2112/metrics\"\n          }\n        ]\n      }\n    }\nargs:\n- --host\n- 0.0.0.0\n- --port\n- \"8080\"\n- --scheme\n- http\n- --config-file\n- /weaviate-config/conf.yaml\n- --read-timeout=600s\n- --write-timeout=600s\nauthentication:\n  anonymous_access:\n    enabled: false\n  apikey:\n    allowed_keys:\n    - xxxxxxxxxxxxxxxx\n    enabled: true\n    users:\n    - api-key-user-admin\nauthorization:\n  admin_list:\n    enabled: true\n    users:\n    - api-key-user-admin\nbackups:\n  s3:\n    enabled: true\n    envconfig:\n      AWS_REGION: us-east-1\n      BACKUP_S3_BUCKET: weaviate-backup-platform-platform-prod-us-east-1\ndebug: false\nenv:\n  GOGC: 20\n  GOMEMLIMIT: 50GiB\n  PERSISTENCE_LSM_ACCESS_STRATEGY: pread\n  PROMETHEUS_MONITORING_ENABLED: true\n  PROMETHEUS_MONITORING_GROUP: false\n  QUERY_SLOW_LOG_ENABLED: true\n  RAFT_ENABLE_FQDN_RESOLVER: true\n  RAFT_FQDN_RESOLVER_TLD: weaviate-headless.weaviate-platform.svc.cluster.local\nimage:\n  tag: 1.26.4\nmodules:\n  generative-cohere:\n    enabled: true\n  generative-openai:\n    enabled: true\n  generative-palm:\n    enabled: true\n  qna-openai:\n    enabled: true\n  ref2vec-centroid:\n    enabled: true\n  reranker-cohere:\n    enabled: true\n  text2vec-cohere:\n    enabled: true\n  text2vec-huggingface:\n    enabled: true\n  text2vec-openai:\n    enabled: true\n  text2vec-palm:\n    enabled: true\nquery_defaults:\n  limit: 100\nreplicas: 6\nresources:\n  requests:\n    cpu: 12000m\n    memory: 100Gi\nservice:\n  name: weaviate\n  ports:\n  - name: https\n    port: 443\n    protocol: TCP\n  type: ClusterIP\nserviceAccountName: weaviate-sa\nstorage:\n  size: 400Gi\n  storageClassName: weaviate-sc-platform\n\nOur collections have the following configuration:\n\nReplication factor: 2\nSharding: 24\nVector compression enabled\nMax number of cached objects: 500000000000\n\nWith the changes described above, we have got some better results in terms of memory and performance. However, backups are still an issue. Memory increases a lot during the execution of backups and it does not go back to the starting point. Restarting the pods frees some memory, but that’s is not an acceptable solution.\nPlease let us know if you need any further information. Would appreciate some support here.\n\n----------\n\n[DudaNogueira (2024-10-14T21:49:12.894Z)]: hi @Oscar_Dalmau_Roig !\nGOMEMLIMIT is recommended to be something around 10% to 20% of the total memory, as per the doc.\nHave you tried changing that?\nI will need to ask internally about this.\nSorry for the delay, we were out the last week on a off site meeting.\nThanks!\n\n----------\n\n[DudaNogueira (2024-10-17T12:58:38.613Z)]: hi @Oscar_Dalmau_Roig !!\nHAve you tried changing the cpuPercentage as stated here?\nWhile we have seen some spikes in backups, our team were not able to consistently reproduce this.",
    "date_created": "2024-09-12T15:50:34.035Z",
    "has_accepted_answer": false,
    "title": "Support needed for fixing Weaviate performance issues",
    "topic_id": 4124
  },
  {
    "user_id": 3135,
    "conversation": "[darklord.thevader (2024-12-31T12:13:31.004Z)]: Can we connect our Weaviate community Self Hosted DB with Weaviate Cloud Console? If yes what are the operations we can perform and will it be a true replacement of UI driven functions should weaviate vector db’s own UI would have been there.\nI have been able to setup Weaviate Community DB on our server, however I am unable to provide a UI console for my client who wants an GUI based accessed for easy operations day to day basis\n\n----------\n\n[DudaNogueira (2024-12-31T13:51:36.392Z)]: hi @darklord.thevader !!\nWelcome to our community! \nWe have disabled the ability to register self hosted Weaviate servers in our console, because of security concerns.\nHowever, you can use any graphql client to get the same feature of auto complete, etc.\nHere is an example using Insomnia:\nimage2122×1328 291 KB\nLet me know if that helps!\nThanks!\n\n----------\n\n[darklord.thevader (2024-12-31T14:08:43.000Z)]: Thanks for the quick reply although i am hoping extremely high with weaviate now. Can you suggest some alternate easy to use ways access weaviate somewhat similar to neo4j.\nAlso do you have any inbuilt cpu compatible embedding models which can be as good as helping us in text and image embeddings?\nAnd i am not talking about huggingface\nAninda\n\n----------\n\n[DudaNogueira (2024-12-31T14:53:13.343Z)]: Hi!\nWe provide, for now, the client to access the DB. And we do not have an Web or App that you could run to “navigate” in Weaviate \nFor your second question, I believe a good option here is using Ollama:\n  \n      \n\n      ollama.com\n  \n\n  \n    \n\nOllama\n\n  Get up and running with large language models.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThey make it really easy to run models locally. It also have a module to integrate with Weaviate, so it make everything very simple:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nText Embeddings | Weaviate\n\n  Ollama Embedding Provider\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBy the way, you can find a really nice recipe here that will cover all the steps needed to integrate those:\n  \n\n      github.com\n  \n\n  \n    weaviate/recipes/blob/main/weaviate-features/generative-search/local_rag_using_ollama_integration_using_embedded.ipynb\n\n\n      {\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Local RAG with Ollama and Weaviate\\n\",\n    \"## Using Weaviate integration\\n\",\n    \"\\n\",\n    \"This example shows how to use the text2vec-ollama as well the generative-ollama \"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Setup \\n\",\n    \"1. Download and install Ollama for your operating system: https://ollama.com/download\\n\",\n    \"2. `pip` install the Python library to generate vector embeddings from the model  with `pip install ollama`. (REST API or JavaScript library also available)\"\n   ]\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!\nThanks!",
    "date_created": "2024-12-31T12:13:30.957Z",
    "has_accepted_answer": false,
    "title": "Can we connect our Weaviate community Self Hosted DB with Weaviate Cloud Console?",
    "topic_id": 9534
  },
  {
    "user_id": 778,
    "conversation": "[Mariam (2024-07-18T07:27:03.951Z)]: Hi, I am encountering an error: type object '_Generative' has no attribute 'ollama'. According to the documentation, this feature is available in version 1.25.0, and I am using version 1.25.4. I installed Weaviate using Docker and enabled the modules with the following configuration: ENABLE_MODULES: 'text2vec-ollama,generative-ollama'.\nHere is my code:\n client.collections.create(\n    collection_name,\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n        api_endpoint=\"http://host.docker.internal:11434\",\n        model=\"mxbai-embed-large\"\n    ),\n    generative_config=wvc.config.Configure.Generative.ollama(\n        api_endpoint=\"http://host.docker.internal:11434\",\n        model=\"llama3\"\n    )\n)\n\nCan you please help me resolve this issue?\n\n----------\n\n[DudaNogueira (2024-07-18T13:47:25.783Z)]: Hi!\nFor technical questions, please, use the Support category, as we have a template there that will ask to provide infos like server version, etc.\nCan you paste the entire traceback of that code? Also, was this code for client.collections.create that raised this error?\nI was able to create a collection with this exact same code…\nLet me know those info so I can help you.\nThanks!\n\n----------\n\n[Mariam (2024-07-19T11:36:03.794Z)]: Hi, @DudaNogueira , yes issue was related to  the client.collections.create,  later I just ran same code in Jupiter Notebook collection was created maybe was issue in Pycharm.\nthanks",
    "date_created": "2024-07-18T07:27:03.887Z",
    "has_accepted_answer": true,
    "title": "Type object '_Generative' has no attribute 'ollama'",
    "topic_id": 3083
  },
  {
    "user_id": 1304,
    "conversation": "[cyc00518 (2024-08-13T05:49:30.554Z)]: Description\n\nI want to get all documents in weaviate, but it always return just part of my query to me.\nFor example,\nclient=weaviate.Client(weaviate_url) \nquery = (\n    client.query.get(class_name, [\"content\", \"source\", \"idx\"])\n    .with_where({\n        \"path\": [\"source\"],  \n        \"operator\": \"Equal\",  \n        \"valueString\": doc_name\n    })\n)\n\nlen(response['data']['Get'][class_name])  # 100\n\nBut it’s actually 450 documents. If I add with_limit(2000), I can get right response.\nclient=weaviate.Client(weaviate_url) \nquery = (\n    client.query.get(class_name, [\"content\", \"source\", \"idx\"])\n    .with_where({\n        \"path\": [\"source\"],  \n        \"operator\": \"Equal\",  \n        \"valueString\": doc_name\n    })\n)\nresponse = query.with_limit(2000).do()\n\nlen(response['data']['Get'][class_name])  # 450\n\nBut If real number of documents are larger than 2000, it will return wrong result for me.\nWould somebody can tell me how to deal with it?\nThanks!\nServer Setup Information\n\nWeaviate Server Version:  3.24.1\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-08-13T12:33:49.022Z)]: hi @cyc00518 !! Welcome to our community  !!\nYou can use our cursor api, as stated here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nRead all objects | Weaviate - Vector Database\n\n  Weaviate provides the necessary APIs to iterate through all your data. This is useful when you want to manually copy/migrate your data (and vector embeddings) from one place to another.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAlso, I noticed you are using our python client version 3.24.1.\nWe strongly suggest using the new python v4 client, as it will have significant performance improvements for read and write operations, as it will leverage  GRPC instead REST/HTTP\nLet me know if this helps or if there is any other help I can provide!\nThanks!\n\n----------\n\n[cyc00518 (2024-08-14T01:03:56.231Z)]: Hi, @DudaNogueira!\nThanks for your quick reply!\nSorry, I think I might lose that document on your guide page.\nHonestly, I do really find that you release v4 version. But I build a knowledge platform in my company based on v3 version early last year. So it might took quite much time to transfer to new v4 version… \nIn fact, I still have one question, hope you don’t mind I ask in this page.\nAbout my knowledge platform mentioned above, I should build a delete function for user to delete what they uploaded before. I use with_where  to filter those data in weaviate , but I find\nEqual operator doesn’t return precise result for me.\nFor example, I want to filter source == '請假.txt', but it will return source == 請假.txt and  source == 請假_53.txt. So I need to add filter rule by myself.\nimport weaviate\nclass_name= 'TEST'\nclient=weaviate.Client(weaviate_url)\ndoc_name='請假.txt'     \nresponse = (\n    client.query.get(class_name, properties=[\"_additional {id}\", \"source\"])\n    .with_where({\n        \"path\": [\"source\"],\n        \"operator\": \"Equal\",\n        \"valueString\": doc_name\n    })  \n).with_limit(20000).do()\n\nsource_set = set([item['source'] for item in response['data']['Get'][class_name]])\nprint(source_set)\n# {'請假.txt', '請假_53.txt'} ->  I hope it should only be '請假.txt'\n\nIs it a right behavior for Equal operator ? Or  it is some bug for Chinese file_name?\nThanks!!",
    "date_created": "2024-08-13T05:49:30.497Z",
    "has_accepted_answer": false,
    "title": "[Question] How to retrieve all documents in weaviate?",
    "topic_id": 3339
  },
  {
    "user_id": 3538,
    "conversation": "[d_khlebokazov (2025-02-24T14:20:25.655Z)]: Hello! I’m currently working with Weaviate 1.26.14 (I’ve updated from 1.25.27) and have a bunch of problems:\nInformation\n\nWe have a 3-node cluster with 46mln objects each.\nEach node has been deployed with k8s and has 30 request cpu and 40 limit and both 500GiB request and limit for RAM\nEnvironment configs:\n\nASYNC_BRUTE_FORCE_SEARCH_LIMIT = 1000\nASYNC_INDEXING=true\nDISABLE_LAZY_LOAD_SHARDS=true\nDISABLE_TELEMETRY=true\nFORCE_FULL_REPLICAS_SEARCH=false\nGOGC=85\nGOMAXPROCS=39\nHNSW_STARTUP_WAIT_FOR_VECTOR_CACHE=true\nLIMIT_RESOURCES=true\nPERSISTENCE_HNSW_MAX_LOG_SIZE=8GiB\nTOMBSTONE_DELETION_CONCURRENCY=4\n\n\nSchema config\n\n{\n  \"class\": \"TEST\",\n  \"invertedIndexConfig\": {\n    \"bm25\": {\n      \"b\": 0.75,\n      \"k1\": 1.2\n    },\n    \"cleanupIntervalSeconds\": 60,\n    \"indexTimestamps\": true,\n    \"stopwords\": {\n      \"additions\": null,\n      \"preset\": \"en\",\n      \"removals\": null\n    }\n  },\n  \"multiTenancyConfig\": {\n    \"autoTenantActivation\": false,\n    \"autoTenantCreation\": false,\n    \"enabled\": false\n  },\n  \"properties\": [\n// cannot show\n  ],\n  \"replicationConfig\": {\n    \"asyncEnabled\": true,\n    \"deletionStrategy\": \"NoAutomatedResolution\",\n    \"factor\": 3\n  },\n  \"shardingConfig\": {\n    \"actualCount\": 3,\n    \"actualVirtualCount\": 384,\n    \"desiredCount\": 3,\n    \"desiredVirtualCount\": 384,\n    \"function\": \"murmur3\",\n    \"key\": \"_id\",\n    \"strategy\": \"hash\",\n    \"virtualPerPhysical\": 128\n  },\n  \"vectorIndexConfig\": {\n    \"bq\": {\n      \"enabled\": false\n    },\n    \"cleanupIntervalSeconds\": 300,\n    \"distance\": \"cosine\",\n    \"dynamicEfFactor\": 8,\n    \"dynamicEfMax\": 500,\n    \"dynamicEfMin\": 100,\n    \"ef\": 640,\n    \"efConstruction\": 640,\n    \"flatSearchCutoff\": 40000,\n    \"maxConnections\": 64,\n    \"pq\": {\n      \"bitCompression\": false,\n      \"centroids\": 256,\n      \"enabled\": false,\n      \"encoder\": {\n        \"distribution\": \"log-normal\",\n        \"type\": \"kmeans\"\n      },\n      \"segments\": 0,\n      \"trainingLimit\": 100000\n    },\n    \"skip\": false,\n    \"sq\": {\n      \"enabled\": false,\n      \"rescoreLimit\": 20,\n      \"trainingLimit\": 100000\n    },\n    \"vectorCacheMaxObjects\": 1000000000000\n  }\n\n\nVector dimentions - 512\n\n\nSlow async replication?\n\nI don’t know the speed of the async replication but it seems to be really slow because within an hour it replicated about 50 objects (or maybe even not because other team may also use it). Delta was about 90 objects.\nThen I decied that this was because of a small difference and did further steps:\n\ndeleted some number of objects\ndownscale cluster to 3 nodes\nimport some data\nupscale 3rd node back\n\nThe delta become ~700k but even though async replication was really slow. (Same 1-2 object per minute or two)\nThen we had some problems with disk space and we cleared out one node  and returned it back to cluster (looks like adding brand new node to cluster)\nObjects counts we like\nweaviate-0 - 0\nweaviate-1 - 46900k\nweaviate-2 - 46200k\n\nStill after that async replication is really really slow\nWithin 2 hours only replicated 200k objects\nAnd from ‘adding new’ node I have the next problem\n\nPeriodical timeouts\n\nWe use a python weaviate-client 4.10.4\nWhen we used batch import before it was fine and worked correctly but after the steps I mentioned I started receive timeout errors (interesting that only after ~50k objects inserted):\n{'message': 'Failed to send 1678 objects in a batch of 5000. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n{'message': 'Failed to send 1722 in a batch of 5000', 'errors': {'addr-0:7001: connect: Post \"http://addr-0:7001/replicas/indices/TEST/shards/xxxx:commit?request_id=weaviate-2-64-195384f4b71-1fa\": context deadline exceeded'}}\n{'message': 'Failed to send 1722 objects in a batch of 5000. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\n\n\nStrange logs\n\nAlso I receive really strange logs on weaviate-1 (leader for now) about async replication:\nhashbeat iteration failed: collecting differences: \"addr-0:7001\": connect: Post \"http://addr:7001/replicas/indices/TEST/shards/xxxx/objects/hashtree/0?schema_version=0\": context deadline exceeded\n\nI thought it is a problem with network but when I tried to do ping from different host I had no problems\n64 bytes from addr-0: seq=207 ttl=63 time=0.150 ms\n\nSo, what would you suggest to solve this?\nThank you in advance\n\n----------\n\n[jeronimo_irazabal (2025-02-24T15:02:18.349Z)]: Hello @d_khlebokazov, thanks for reaching out.\nI encourage you to upgrade to latest release 1.29.0 in order to get much better results with async replication. Several settings can now be adjusted in order to optimize it for your use case (Replication | Weaviate), also performance among other improvements has landed in that release.\nIf upgrading is an impediment for you please let me know.\nThanks again,\nJeronimo\n\n----------\n\n[d_khlebokazov (2025-02-25T05:08:33.927Z)]: Hello @jeronimo_irazabal ! Thank you for a quick response\nI will think about upgrading to 1.29 but now I also cannot change my TEST schema. Python library just raises a timeout error.\ncollection.config.update(replication_config=weaviate.classes.config.Reconfigure.replication(\n        async_enabled=False))\n\nOutput -----------------\nweaviate.exceptions.WeaviateTimeoutError: The request to Weaviate timed out while awaiting a response. Try adjusting the timeout config for your client. Details: Collection configuration may not have been updated.\n\nThis is kind of annoying because I wanted to try to turn off the async replication.\nAlso a small update about previous problems:\nEven after 12 hours of waiting for async replication the situation looks like this:\nweaviate-0 - 2373977\nweaviate-1 - 46966225\nweaviate-2 - 46793858\n\nWhat is the async replication speed should be?\nAnd I still have these logs:\nhashbeat iteration failed: collecting differences: \"addr-0:7001\": connect: Post \"http://addr-0:7001/replicas/indices/TEST/shards/xxxxx/objects/hashtree/0?schema_version=0\": context deadline exceeded\n\nIt seems to be nodes problem because hosts can easily communicate with each other.\nMay be some weaviate cluster or schema config must be changed to solve this?\n\n----------\n\n[d_khlebokazov (2025-02-25T05:12:52.776Z)]: It seems to be similar to Async_replication context deadline exceeded, unable to Activate Tenant\nWas it possible to find a solution? @jeronimo_irazabal\n\n----------\n\n[d_khlebokazov (2025-02-25T07:15:17.852Z)]: @jeronimo_irazabal\nNew update:\nI restarted cluster and async_enabled seted false\nI change it back to async_enabled: true and again have timeouts for python library\nhttpcore.ReadTimeout\nThe above exception was the direct cause of the following exception:\n\nhttpx.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\nFile \"C:\\Users\\khlebokazov\\Desktop\\weaviate-tools\\benchmark\\schemas\\base.py\", line 155, in update_schema\n    collection.config.update(\n  File \"C:\\Users\\khlebokazov\\Desktop\\weaviate-tools\\venv\\Lib\\site-packages\\weaviate\\syncify.py\", line 23, in sync_method\n    return _EventLoopSingleton.get_instance().run_until_complete(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\khlebokazov\\Desktop\\weaviate-tools\\venv\\Lib\\site-packages\\weaviate\\event_loop.py\", line 42, in run_until_complete\n    return fut.result()\n           ^^^^^^^^^^^^\n  File \"C:\\Users\\khlebokazov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 456, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\khlebokazov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\khlebokazov\\Desktop\\weaviate-tools\\venv\\Lib\\site-packages\\weaviate\\collections\\config\\config.py\", line 161, in update\n    await self._connection.put(\n  File \"C:\\Users\\khlebokazov\\Desktop\\weaviate-tools\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py\", line 552, in put\n    return await self.__send(\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\khlebokazov\\Desktop\\weaviate-tools\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py\", line 487, in __send\n    raise WeaviateTimeoutError(error_msg) from read_err\nweaviate.exceptions.WeaviateTimeoutError: The request to Weaviate timed out while awaiting a response. Try adjusting the timeout config for your client. Details: Collection configuration may not have been updated.\n\nThe most interesting thing is that every GET requests are working fine.\n\n----------\n\n[d_khlebokazov (2025-02-25T07:46:55.238Z)]: Abother update:\nWe have a proxy service build with FastAPI that communicates with weaviate and now because of async replication it is imposible to create object\n\nCREATE:\n\ncreated_uuid = await collection.data.insert(\n                properties=props,\n                uuid=vector_id,\n                vector=embedding,\n            )\n\n\"Object was not added! Unexpected status code: 500, with response body: {'error': [{'message': 'cannot achieve consistency level \\\"QUORUM\\\": read repair error: conflict: object has been deleted on another replica'}]}.\n\nBut fine when trying to change uuid (so may be this is inconsistency error)\n\nDELETE time outs for 10s\nGET works fine\nfetch_objects works fine\nnear_vector started working awfuly, 800ms instead of 20ms\n\nAlso I have these error in logs:\nerror waiting for local schema to catch up to version 47: deadline exceeded for waiting for update: version got=46  want=47\n\nand a lot of wait for update version so it seems that schema cannot be updated on weaviate-0\n\n----------\n\n[jeronimo_irazabal (2025-02-25T12:48:44.062Z)]: Hello @d_khlebokazov, if your objetive is to use async replication then upgrading to 1.29 should be highly recommended.\nI’d only suggest to use async replication in 1.26 in case of need and impediment of upgrading.\nWith regards to performance, in 1.29 it was possible to repair 1mi objects in less than 15mins (with a single propagation thread, this can be customized).\nIn order to automatically resolve the situation when an object was deleted in a subset of the nodes but not in all of them it’s required to specify a deletion strategy:\nConsistency | Weaviate.\nThis is not specific for async replication but also for read-repair (when nodes try to get in sync when resolving a query).",
    "date_created": "2025-02-24T14:20:25.580Z",
    "has_accepted_answer": true,
    "title": "[QUESTION] Async replication hashbeat fails with context deadline timeout",
    "topic_id": 10527
  },
  {
    "user_id": 3434,
    "conversation": "[cfloressuazo (2025-02-13T20:34:25.405Z)]: This page is missing the imports: Custom connections | Weaviate\nThe code suggest using AdditionalConfig and Timeout but does not specifies where to import them from.\nThese should come from from weaviate.config import AdditionalConfig, Timeout\nThanks\n\n----------\n\n[DudaNogueira (2025-02-13T21:04:07.945Z)]: Hi @cfloressuazo !!\nWelcome to our community \nThank you very much! We really appreciate it.\n“It takes a village to create great documentation”\nPR here:\n  \n\n      github.com/weaviate/weaviate-io\n  \n\n  \n    \n\n\n\n    \n      \n    \n\n  \n\n\n\n      \n        Add Auto Tenant Creation / Activation availability details and in versions / missing import in custom connection\n      \n\n    \n      main ← add-auto-tenant-creation-availability-details\n    \n\n      \n        \n          opened 09:01PM - 13 Feb 25 UTC\n        \n\n        \n          \n            \n            dudanogueira\n          \n        \n\n        \n          \n            +4\n            -0\n          \n        \n      \n  \n\n\n  \n    Add missing import from custom connection / grpc timeouts\nAdd Auto Tenant Creat…ion / Activation availability details and in versions\n\n\n\n### What's being changed:\n\n\n\n### Type of change:\n\n\n\n- [x] **Documentation** updates (non-breaking change to fix/update documentation)\n- [ ] **Website** updates (non-breaking change to update main page, company pages, pricing, etc)\n- [ ] **Content** updates – **blog**, **podcast** (non-breaking change to add/update content)\n- [ ] **Bug fix** (non-breaking change to fixes an issue with the site)\n- [ ] **Feature** or **enhancements** (non-breaking change to add functionality)\n\n### How Has This Been Tested?\n\n\n\n- [ ] **GitHub action** – automated build completed without errors\n- [x] **Local build** - the site works as expected when running `yarn start`\n\n> note, you can run `yarn verify-links` to test site links locally",
    "date_created": "2025-02-13T20:34:25.359Z",
    "has_accepted_answer": true,
    "title": "[Docs] Missing Imports for some examples",
    "topic_id": 10336
  },
  {
    "user_id": 977,
    "conversation": "[Nancy_Viviana_Espino (2024-05-27T16:59:55.622Z)]: Hi all, I need help with a problem I am having during a migration. I am declaring a variable as follows:\nvector_result = collection.query.fetch_objects(\n                    limit=1,\n                    filters=Filter.by_property(\"weaviate_post_id\").equal(post.get(\"weaviate_post_id\")),\n                    return_properties=[],\n                    include_vector=True,\n                )\n\nWhen I try to access vector_result.vector[“default”] , I get the following error: \"QueryReturn’ object has no attribute ‘vector’. Could someone please assist me with this?\n\n----------\n\n[sebawita (2024-05-27T17:04:07.978Z)]: Hi @Nancy_Viviana_Espino,\nWelcome to the community.\nCan you share the code of how you are trying to access the vector?\nIs it something like:\nprint(vector_result.objects[0].vector)\n\nor\nprint(vector_result.objects[0].vector[\"default\"])\n\nAlso, can you share the code you used to create your collection?\nOr in other words, did you define a vectorizer in there?\n\n----------\n\n[Nancy_Viviana_Espino (2024-07-31T21:55:20.009Z)]: Thanks for your reply",
    "date_created": "2024-05-27T16:59:55.569Z",
    "has_accepted_answer": true,
    "title": "Need Help Accessing 'include_vector' Property in Weaviate Migration Process",
    "topic_id": 2500
  },
  {
    "user_id": 590,
    "conversation": "[EntrustGabri (2024-02-06T15:40:57.980Z)]: I would like to connect to a remote weaviate instance deployed using docker. The problem I have is that when I run connect_to_custom I get WeaviateGRPCUnavailableError.\nI am using Python’s weaviate-client v4.4.0, the version of Weaviate is the latest (1.23.7). The equivalent with v3 (using http) works great. The client code:\nclient2 = weaviate.connect_to_custom(\n    http_host=\"myhost\",\n    http_port=8080,\n    http_secure=False,\n    grpc_host=\"myhost\",\n    grpc_port=50051,\n    grpc_secure=False\n)\n\nThe docker services:\n  weaviate:\n    image: semitechnologies/weaviate:latest\n    restart: on-failure:0\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n      - /home/...:/var/lib/weaviate\n    environment:\n      QUERY_DEFAULTS_LIMIT: 20\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: \"./data\"\n      DEFAULT_VECTORIZER_MODULE: text2vec-transformers\n      ENABLE_MODULES: text2vec-transformers\n      TRANSFORMERS_INFERENCE_API: http://t2v-transformers:8080\n      CLUSTER_HOSTNAME: 'node1'\n      \n  t2v-transformers:\n    image: semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1\n    environment:\n      ENABLE_CUDA: 0 # set to 1 to enable\n\n----------\n\n[DudaNogueira (2024-02-06T17:50:36.664Z)]: Hi @EntrustGabri\nThis has worked.\ncan you check if the running version is indeed 1.23.7?\nYou can get this at:\nhttp://localhost:8080/v1/meta\nMy guess here is that you have an old version with the latest tag.\nany version other than 1.23.7 in that endpoint, you can update the image with:\ndocker compose pull weaviate\n\nLet me know if this helps\n\n----------\n\n[EntrustGabri (2024-02-07T11:58:10.129Z)]: I have checked http://myremotehost:8080/v1/meta and it displays 1.23.7 . In fact, before using “latest” I had “1.23.7”, I changed it to try to fix the error. I have deployed the same locally and it works with connect_to_local(). The problem seems to be when connecting to a remote host. The port is reachable so I don’t know what might be going wrong.\n\n----------\n\n[DudaNogueira (2024-02-07T18:31:51.151Z)]: Do you see any outstanding log in server?\nif you run a python http server on that port, can you reach it?\nPlease, feel free to reach me at our Slack and I can try looking into that closely on a call session.\nThanks!\n\n----------\n\n[dawid-laszuk-sp (2024-02-16T04:19:13.990Z)]: What was the solution here?\nI’m having the exact same issue on freshly installed latest Python client (v4.4.4) and the latest image (1.23.9). I can confirm, through pinging from local host (ping -p 50051 hostIp) that the host is reachable. Also, I can see in logs on the remote host, that the gRPC is setup\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-02-16T04:14:25Z\"}\n\nCould someone from Weaviate please update the documentation on how to setup the gRPC? It says that only exposing port 50051 is enough, yet, when an error on the client shows, it says to make sure it’s configured correctly.\n\n----------\n\n[dawid-laszuk-sp (2024-02-16T04:30:00.748Z)]: Actually, seems that passing  skip_init_checks=True to connect_to_custom fixes the issue, i.e.\nclient = weaviate.connect_to_custom(\n    http_host=\"myhost\",\n    http_port=8080,\n    http_secure=False,\n    grpc_host=\"myhost\",\n    grpc_port=50051,\n    grpc_secure=False,\n   skip_init_checks=True,\n)\n\nclient.connect()\n\n----------\n\n[DudaNogueira (2024-02-16T14:07:32.132Z)]: Hi! I believe this may fix it partially, as it will not leverage the GRPC part of the client.\nI have seen this kind of issue, and usually it was related to firewall, both on client and on server.\nPlease, feel free to ping me in our slack channel so I can take a closer look.\nThanks!\n\n----------\n\n[dawid-laszuk-sp (2024-02-16T16:24:45.885Z)]: Hello,\nAs hopefully I have proven, I’m able to access the port (50051) which, according to the documentation, is the only requirement. So, I have the highest doubts that it’s the firewall issue. If that isn’t enough, I’d appreciate providing information on the actual requirements.\nI don’t know what slack you refer to, and I think more people would benefit from keeping the conversation open; if they stumble on the same problem, they could also benefit. For example, this ticket was open 10 days ago and I have the exact issue. I don’t know if the previous asker fixed their problem, or just got gave up all together.\nSide note: are you suggesting that disabling the initial checks (that’s my guess is behind skip_init_checks=False) disables a feature? Based on the source code, that doesn’t seem to be true. The check makes a requests and then investigates why it has failed. There also seems to be some requirement for openid when doing the init check which is missing from documentation.\n\nI can’t add new response, so editing this one;\nIs TLS (https/ssl) required? If so, I’d urge Weaviate to update the documentation. I’m getting exception\n❯ grpcurl -d '{\"service\": \"Weaviate\"}' -proto health.proto $RHOST:50051 grpc.health.v1.Health/Check\nFailed to dial target host \"54.173.187.190:50051\": remote error: tls: unexpected message\n\nIn all honesty, without the check things work, and as I’m setting this up for someone else, I’m going to leave it as is. I’m not keen on slack conversation as I haven’t had smooth experience so far, and this is at the bottom of my priority list.\nIn case anyone from Weaviate is interested debugging the issue, here’s a terraform script to setup the use case:\nresource \"aws_iam_role\" \"ecs_execution_role\" {\n  name = \"mlops-terraform-vector-db\"\n\n  managed_policy_arns = [\n    \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\",\n    \"arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\",\n    \"arn:aws:iam::aws:policy/AmazonBedrockFullAccess\",\n  ]\n\n  inline_policy {\n    name = \"bedrock-ecr\"\n    policy = jsonencode({\n      \"Version\" : \"2012-10-17\",\n      \"Statement\" : [\n        {\n          \"Sid\" : \"PermissiveECR\",\n          \"Effect\" : \"Allow\",\n          \"Action\" : [\n            \"ecr:*\"\n          ],\n          \"Resource\" : \"*\"\n        },\n        {\n          \"Sid\" : \"MarketplaceSubscriptionToLLMs\",\n          \"Effect\" : \"Allow\",\n          \"Action\" : [\n            \"aws-marketplace:Subscribe\"\n          ],\n          \"Resource\" : \"*\",\n          \"Condition\" : {\n            \"ForAnyValue:StringEquals\" : {\n              \"aws-marketplace:ProductId\" : [  # check: https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html#model-access-permissions\n                \"c468b48a-84df-43a4-8c46-8870630108a7\", # Anthropic Claude 12k\n                \"prod-ariujvyzvd2qy\"  # Meta Llama 2 13B\n              ]\n            }\n          }\n        }\n      ]\n    })\n  }\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        \"Sid\" : \"\",\n        \"Effect\" : \"Allow\",\n        \"Principal\" : {\n          \"Service\" : \"ecs-tasks.amazonaws.com\"\n        },\n        \"Action\" : \"sts:AssumeRole\"\n      }\n    ]\n  })\n\n}\n\nresource \"aws_ecs_cluster\" \"weaviate_cluster\" {\n  name = \"weaviate_cluster\"\n}\n\nresource \"aws_ecs_task_definition\" \"weaviate_task\" {\n  family                   = \"weaviate_task\"\n  network_mode             = \"awsvpc\"\n  requires_compatibilities = [\"FARGATE\"]\n  execution_role_arn       = aws_iam_role.ecs_execution_role.arn\n  cpu                      = \"1024\"\n  memory                   = \"2048\"\n\n\n  container_definitions = jsonencode([{\n    name    = \"weaviate_container\"\n    image   = \"semitechnologies/weaviate:1.23.9\" # TODO: Might need to migrate to own ECR\n    command = [\"--host\", \"0.0.0.0\", \"--port\", \"8080\", \"--scheme\", \"http\"]\n\n    healthCheck = {\n      command     = [\"CMD-SHELL\", \"wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\"]\n      interval    = 30\n      timeout     = 5\n      retries     = 3\n      startPeriod = 0\n    }\n\n    portMappings = [{\n      containerPort = 8080\n      hostPort      = 8080\n      protocol      = \"tcp\"\n      }, {\n      containerPort = 443\n      hostPort      = 443\n      protocol      = \"tcp\"\n      }, {\n      containerPort = 80\n      hostPort      = 80\n      protocol      = \"tcp\"\n      }, {\n      containerPort = 50051\n      hostPort      = 50051\n      protocol      = \"tcp\"\n      }\n    ]\n    environment = [\n      { \"name\" : \"ECS_ENABLE_AWSLOGS_EXECUTIONROLE_OVERRIDE\", \"value\" : \"true\" },\n      { \"name\" : \"AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED\", \"value\" : \"true\" },\n      { \"name\" : \"DEFAULT_VECTORIZER_MODULE\", \"value\" : \"text2vec-aws\" },\n      { \"name\" : \"ENABLE_MODULES\", \"value\" : \"text2vec-aws,generative-aws\" },\n      { \"name\" : \"PERSISTENCE_DATA_PATH\", \"value\" : \"/var/lib/weaviate\" },\n      { \"name\" : \"QUERY_DEFAULTS_LIMIT\", \"value\" : \"25\" },\n      { \"name\" : \"CLUSTER_HOSTNAME\", \"value\" : \"node1\" },\n    ]\n\n    logConfiguration = {\n      logDriver = \"awslogs\"\n      options = {\n        \"awslogs-group\"         = aws_cloudwatch_log_group.weaviate_logs.name\n        \"awslogs-region\"        = var.aws_region  # TODO: Might need updating\n        \"awslogs-stream-prefix\" = \"ecs\"\n      }\n    }\n  }])\n}\n\nresource \"aws_ecs_service\" \"weaviate_service\" {\n  name            = \"weaviate_service\"\n  cluster         = aws_ecs_cluster.weaviate_cluster.id\n  task_definition = aws_ecs_task_definition.weaviate_task.arn\n  launch_type     = \"FARGATE\"\n  desired_count   = 1\n\n\n  network_configuration {\n    assign_public_ip = true\n    subnets = [\n      # TODO: Add appropriate subnets\n    ]\n    security_groups = [\n      # TODO: Add appropriate security groups\n    ]\n  }\n\n}\nresource \"aws_cloudwatch_log_group\" \"weaviate_logs\" {\n  name = \"/ecs/weaviate_service\"\n}\n\nresource \"aws_cloudwatch_log_stream\" \"weaviate_logs_stream\" {\n  name           = \"weaviate_service_logs\"\n  log_group_name = aws_cloudwatch_log_group.weaviate_logs.name\n  depends_on     = [aws_cloudwatch_log_group.weaviate_logs]\n}\n\n----------\n\n[DudaNogueira (2024-02-16T20:18:52.978Z)]: Hi!\nWe have a public slack. You can access it from our website, or directly thru:\nhttps://weaviate.io/slack\nMy suggestion is that you could share your screen and I could take a closer look.\nIn my experience, this kind of issue is better solved like that \nWe can for sure bring back our findings here so others can benefit.\nOne way to make sure the GRPC is healthy and serving, is to do a grpcurl, like so:\n# lets test our grpc connection\n❯ wget https://raw.githubusercontent.com/grpc/grpc/master/src/proto/grpc/health/v1/health.proto\n❯ grpcurl -d '{\"service\": \"Weaviate\"}' -proto health.proto grpc.weaviate.mydomain.com:50051 grpc.health.v1.Health/Check\n{\n  \"status\": \"SERVING\"\n}\n\nHere I have created a docker compose that uses Weaviate + Traefik + Let’s Encrypt, so you can server Weaviate behind a reverse proxy with  https/ssl:\n\n  \n    \n    \n    Weaviate with Traefik and gRPC Support\n  \n  \n    Hi @qnlbnsl ! Sorry for the delay here. \nLooks like I was finally able to tame this \nHere is what I got: \n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:1.23.5\n    #ports:\n    # - 8081:8080 # unsafe http\n    # - 50052:50051 # unsafe grpc\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTI…\n\n----------\n\n[sri-postgres-cassand (2025-01-10T22:28:15.321Z)]: Can someone please provide steps how to secure the gRPC port. I am able to connect using both grpc_secure=true and grpc_secure=false . My http connection is secured.\nclient = weaviate.connect_to_custom(\nhttp_host=‘hostname’,        # Hostname for the HTTP API connection\nhttp_port=8181,\nhttp_secure=True,\ngrpc_host=‘hostname’,\ngrpc_port=50051,\ngrpc_secure=False,\nskip_init_checks=True,\nauth_credentials=Auth.api_key(“###############”)  # API key for authentication\n)\n\n----------\n\n[DudaNogueira (2025-01-23T14:57:06.034Z)]: hi @sri-postgres-cassand !!\nHere you have some information that can help, like how to expose it using docker and traefik.\nIf you need further, please open a new topic as this one is already solved.\nThanks!\n\n----------\n\n[DudaNogueira (2025-01-23T14:57:10.445Z)]: ",
    "date_created": "2024-02-06T15:40:57.931Z",
    "has_accepted_answer": true,
    "title": "WeaviateGRPCUnavailableError: gRPC is not available",
    "topic_id": 1399
  },
  {
    "user_id": 778,
    "conversation": "[Mariam (2024-07-22T07:40:07.336Z)]: Description\nCan you please help me fix this issue? What could be causing it? Is there any configuration I can add to increase the execution time?\nI have created the Weavaite index with Ollama and stored the doc. When I perform a generated search I face this issue.\nthis command is working\n!curl myserverurl:11434/api/generate -d ‘{“model”: “llama3”,“prompt”:“What is a vector database?”, “stream”: false }’\nServer Setup Information\n\nWeaviate Server Version: 1.25.4\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version:python v4\nMultitenancy?: no\n\nAny additional Information\nindex schema\nvectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\napi_endpoint=“myserverurl:11435” ,\nmodel=“mxbai-embed-large” ),\ngenerative_config=wvc.config.Configure.Generative.ollama(\napi_endpoint=“myserverurl::11435”,\nmodel=“llama3”\n),\n)\nproperties=[wvc.config.Property(\nname=“text”,\ndata_type=wvc.config.DataType.TEXT,\nskip_vectorization=False,\nvectorize_property_name=True,\ntokenization=wvc.config.Tokenization.LOWERCASE\n…\n]\n)\n\n----------\n\n[DudaNogueira (2024-07-22T21:15:36.767Z)]: Hi @Mariam!!\nCan you post the full stacktrace?\nMy bet here is that the GRPC port is not exposed properly.\nAlso, could you share the docker compose you are using?\nconsidering you are mapping the ports in you docker, it should be something like this, considering both the curl and the error message:\n    ports:\n    - 11434:8080\n    - 11435:50051\n\nso http endpoint is mapped to 11434 and grpcto 11435\nLet me know if that helps!\nThanks!\n\n----------\n\n[Mariam (2024-07-24T14:21:39.689Z)]: Hi , @DudaNogueira\nI updated my Docker configuration to include the following port mappings:\nports:\n- 11434:8080\n- 11435:50051\nHowever, I am still encountering the same issue when running the following code:\nrresult = client.collections.get(collection_name)\nresponse = result.generate.near_text(\nquery=prompt,\nlimit=1,\ngrouped_task=f\"Answer the question: {prompt}? only using the given context in {{chunk}}\"\n)\nprint(response.generated)\nI suspect the problem might be related to the models I am using. Is that possible? The vectorizer model is ‘mxbai-embed-large’ and the generative model is ‘llama3’.\n@DudaNogueira  Thank you for your prompt response and support.\n\n----------\n\n[DudaNogueira (2024-07-24T21:05:08.150Z)]: Hi!\nOh, sorry. I didn’t noticed you are using ollama.\nHave you seen this recipe?\n\n  \n\n      github.com\n  \n\n  \n    weaviate/recipes/blob/main/weaviate-features/generative-search/local_rag_using_ollama_integration_using_embedded.ipynb\n\n\n      {\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Local RAG with Ollama and Weaviate\\n\",\n    \"## Using Weaviate integration\\n\",\n    \"\\n\",\n    \"This example shows how to use the text2vec-ollama as well the generative-ollama \"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Setup \\n\",\n    \"1. Download and install Ollama for your operating system: https://ollama.com/download\\n\",\n    \"2. `pip` install the Python library to generate vector embeddings from the model  with `pip install ollama`. (REST API or JavaScript library also available)\"\n   ]\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIt is using ollama, so pretty much the same as you are doing.\nIf you are using ollama installed on your machine, you will need to change the base url to host.docker.internal: (check the notebook for more info)\nSo I believe you can leave the ports mapped as:\n    ports:\n    - 8080:8080\n    - 50051:50051\n\nAnd now, set ollama url to where it is running (again, depending on how you are running ollama)\nLet me know if this helps or I can help you.\nWe just had an office hours today. This is an online event where I answer any questions you bring \nStay tuned for more here: Online Workshops & Events | Weaviate - Vector Database",
    "date_created": "2024-07-22T07:40:07.282Z",
    "has_accepted_answer": false,
    "title": "weaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message send POST request: Post \"serverurl:11435/api/generate\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)",
    "topic_id": 3118
  },
  {
    "user_id": 3282,
    "conversation": "[MCKBS (2025-01-28T16:17:08.958Z)]: Hi,\nI was following the Weaviate quickstart tutorial (Locally hosted | Weaviate) and stumbled upon an error while doing step 2.2 (python).\nI successfully did the prerequisites, all of step 1 and step 2.1.\nNow, when I run my ‘quickstart_import.py’ I did for step 2.2 I get the following error:\n{'message': 'Failed to send all objects in a batch of 10', 'error': 'WeaviateInsertManyAllFailedError(\\'Every object failed during insertion. Here is the set of all errors: send POST request: Post \"http://host.docker.internal:11434/api/embed\": dial tcp: lookup host.docker.internal on 127.0.0.11:53: no such host\\')'}\n{'message': 'Failed to send 10 objects in a batch of 10. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.'}\nNumber of failed imports: 10\nFirst failed object: ErrorObject(message='WeaviateInsertManyAllFailedError(\\'Every object failed during insertion. Here is the set of all errors: send POST request: Post \"http://host.docker.internal:11434/api/embed\": dial tcp: lookup host.docker.internal on 127.0.0.11:53: no such host\\')', object_=BatchObject(collection='Question', properties={'answer': 'Liver', 'question': 'This organ removes excess glucose from the blood & stores it as glycogen', 'category': 'SCIENCE'}, references=None, uuid='99dbfe6e-02db-4b7c-aa57-bbaed5513e08', vector=None, tenant=None, index=0, retry_count=0), original_uuid=None)\n\nThe ‘dial tcp: lookup host.docker.internal on 127.0.0.11:53: no such host’ part seems to be the major culprit. I bet it is a stupidly simple solution but I just can’t figure it out.\nCan anyone help me?\n\n----------\n\n[DudaNogueira (2025-01-28T21:07:46.183Z)]: hi @MCKBS !!\nWelcome to our community \nThis looks like an issue with docker failing to resolve host.docker.internal\nfor example, if your weaviate can find ollama at host.docker.internal, it should be able to run this, that is basicallying Weaviate vectorizing something in Ollama:\ndocker-compose exec -ti weaviate wget -O - --post-data='{\"model\":\"nomic-embed-text\",\"input\":\"Why is the sky blue?\"}' http://host.docker.internal:11434/api/embed\n\nthis should outcome some thing like\nConnecting to host.docker.internal:11434 (0.250.250.254:11434)\nwriting to stdout\n{\"model\":\"nomic-embed-text\",\"embeddings\":[[0.009724553,0.04449892,-0.14063916,0.\n\nAre you running this on Linux, Mac or Windows?\nLet me know if that helps!\nThanks!\n\n----------\n\n[MCKBS (2025-01-29T07:25:15.514Z)]: Hi!\nThank you for your reply!\nI’am running this on Linux (Ubuntu 24.04).\nUnfortunately that did not work:\n\nfor example, if your weaviate can find ollama at host.docker.internal, it should be able to run this, that is basicallying Weaviate vectorizing something in Ollama:\n\nwget: bad address 'host.docker.internal:11434'\n\nAlso, if I try:\nwget host.docker.internal:11434\n\nI get:\n--2025-01-29 08:22:45--  http://host.docker.internal:11434/\nResolving host.docker.internal (host.docker.internal)... failed: Name or service not known.\nwget: unable to resolve host address ‘host.docker.internal’\n\n----------\n\n[DudaNogueira (2025-01-29T10:51:10.232Z)]: ok, do you mind running ollama also inside docker?\nMaybe the host.docker.internal name is a Docker Desktop thing \nWe have recently discussed about this here:\n  \n    \n    \n    [Question] Getting Weaviate and Ollama working together running locally Support\n  \n  \n    I have been trying to get weaviate and ollama working together on my local machine.  I have yet to get weaviate to successfully connect to ollama at all.  Does anyone any tips? \nHere is my docker-compose.yml file: \nversion: \"3.7\"\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2\n    ports:\n      - 8080:8080\n      - 50051:50051\n    environment:\n      ENABLE_MODULES: text2vec-ollama\n      OLLAMA_URL: http://ollama:11434\n      TEXT2VEC_OLLAMA_BASE_URL: http://ollama:1…\n  \n\n\nRunning ollama alongside your Weaviate, will allow you to use:\nhttp://ollama:11434\nas your ollama endpoint.\nLet me know if that helps!\n\n----------\n\n[DudaNogueira (2025-01-29T10:53:15.272Z)]: Oh, just found this, that can help you still use the local:\n\n  \n\n      stackoverflow.com\n  \n\n  \n      \n    \n  \n\n\n  How to access host port from docker container\n\n\n\n  docker, docker-container\n\n\n\n  asked by\n  \n  \n    Tri Nguyen\n  \n  on 06:01PM - 09 Jul 15 UTC\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nSo maybe adding it to the container:\nextra_hosts:\n    - \"host.docker.internal:host-gateway\"\n\nThanks!\n\n----------\n\n[MCKBS (2025-01-29T13:53:57.941Z)]: Thank you!!! Now it is running without errors!\nI actually had to use both of your solutions to make it work \nI’am now running Ollama in docker instead AND added\nextra_hosts:\n    - \"host.docker.internal:host-gateway\"\n\nThank you again for the help and have a nice day!!\nEDIT: I still can’t reach\nhttp://ollama:11434\n\nbut it is working fine right now so I don’t mind lol",
    "date_created": "2025-01-28T16:17:08.900Z",
    "has_accepted_answer": true,
    "title": "Quickstart local hosted 'no such host' error",
    "topic_id": 9927
  },
  {
    "user_id": 3146,
    "conversation": "[Bohdan_Klishchov (2025-01-08T20:49:30.869Z)]: How can i use ref2vec-centroid on v4 python client?\nI use this code, but vector was empty:\nimport asyncio\n\nimport weaviate\nfrom weaviate.classes.config import Configure\nfrom weaviate.client import WeaviateAsyncClient\nfrom weaviate.collections.classes.grpc import QueryReference\nfrom weaviate.collections.classes.config_vectorizers import Multi2VecField\nfrom weaviate.collections.classes.config import Property, DataType, ReferenceProperty\n\nfrom core.settings import get_settings\n\nsettings = get_settings()\n\n\nasync def init_collections(client: WeaviateAsyncClient):\n\n    if await client.collections.exists('Short'):\n        return\n    if await client.collections.exists('UserInteractions'):\n        return\n    await client.collections.create(\n        \"Short\",\n        properties=[\n            Property(\n                name='object_id',\n                data_type=DataType.INT,\n                description=\"Unique identifier for the short.\",\n                skip_vectorization=True,\n            ),\n            Property(\n                name='description',\n                data_type=DataType.TEXT,\n                description=\"Short description of the content.\",\n            ),\n            Property(\n                name='category',\n                data_type=DataType.TEXT,\n                description=\"Category of the short.\",\n            ),\n        ],\n        vectorizer_config=[\n            # Set a named vector\n            Configure.NamedVectors.multi2vec_bind(\n                name=\"shorts_vec\",\n                text_fields=[\n                    Multi2VecField(name='description', weight=0.6),\n                    Multi2VecField(name='category', weight=0.4),\n                ]\n            ),\n        ],\n    )\n\n    await client.collections.create(\n        \"UserInteractions\",\n        properties=[\n            Property(\n                name='object_id',\n                data_type=DataType.INT,\n                description=\"Unique identifier for the user.\"\n            ),\n        ],\n        references=[\n            ReferenceProperty(\n                name='liked_shorts',\n                target_collection=\"Short\",\n                description=\"Short which liked by current user\",\n            ),\n        ],\n        vectorizer_config=Configure.Vectorizer.ref2vec_centroid(\n            reference_properties=[\n                'liked_shorts'\n            ]\n        ),\n    )\n\n\nasync def main():\n    client: WeaviateAsyncClient = weaviate.use_async_with_local(\n        host=settings.WEAVIATE_HOST,\n        port=settings.WEAVIATE_PORT,\n        skip_init_checks=True\n    )\n    await client.connect()\n    try:\n        await init_collections(client=client)\n\n        short_collection = client.collections.get('Short')\n        user_collection = client.collections.get('UserInteractions')\n\n        short_uuid = await short_collection.data.insert(properties={\n            'object_id': 1,\n            'description': 'description1',\n            'category': 'category1'\n        }, uuid=uuid.uuid4())\n        print(f'created short: {short_uuid}')\n\n        user_uuid = await user_collection.data.insert(properties={'object_id': 1}, uuid=uuid.uuid4())\n        print(f'created user: {user_uuid}')\n\n        # creating cross-reference\n        await user_collection.data.reference_add(\n            from_uuid=user_uuid,\n            from_property='liked_shorts',\n            to=short_uuid\n        )\n\n        resp = await user_collection.query.fetch_object_by_id(\n            uuid=user_uuid,\n            include_vector=True,\n            return_references=QueryReference(\n                link_on='liked_shorts',\n                return_properties=[\"object_id\"],\n            ),\n        )\n\n        print(resp)\n\n    finally:\n        await client.close()\n\nif __name__ == '__main__':\n    asyncio.run(main())\n\nOutput:\ncreated short: 09e06d77-a1f6-4274-b0ae-485f532322fd\ncreated user: 0c6ff736-ef4a-45e9-9e34-93ff67a53dfe\nObjectSingleReturn(uuid=_WeaviateUUIDInt('0c6ff736-ef4a-45e9-9e34-93ff67a53dfe'), metadata=MetadataSingleObjectReturn(creation_time=datetime.datetime(2025, 1, 6, 15, 20, 12, 837000, tzinfo=datetime.timezone.utc), last_update_time=datetime.datetime(2025, 1, 6, 15, 20, 12, 840000, tzinfo=datetime.timezone.utc), is_consistent=None), properties={'object_id': 1}, references={'liked_shorts': <weaviate.collections.classes.internal._CrossReference object at 0x7c28da11e610>}, vector={}, collection='UserInteractions')\n\n----------\n\n[DudaNogueira (2025-01-28T15:08:02.274Z)]: hi @Bohdan_Klishchov !!\nSorry for the delay here.\nI have produced a recipe (soon to be published) and can share some example here:\n\n# lets create our collections\nclient.collections.delete(\"Interaction\")\ninteraction = client.collections.create(\n    \"Interaction\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n    properties=[\n        wvc.config.Property(name=\"text\", data_type=wvc.config.DataType.TEXT),\n    ]\n)\n\nclient.collections.delete(\"Person\")\nperson = client.collections.create(\n    \"Person\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.ref2vec_centroid(\n        reference_properties=[\"interactions\"]\n    ),\n    properties=[\n        wvc.config.Property(name=\"name\", data_type=wvc.config.DataType.TEXT),\n    ],\n    references=[\n        wvc.config.ReferenceProperty(name=\"interactions\", target_collection=\"Interaction\")\n    ]\n)\n\ncreating the data\nfrom weaviate.util import generate_uuid5\n\n# Lets create our people\nperson.data.insert({\"name\": \"Bob Smith\"}, uuid=generate_uuid5(\"bob\"))\nperson.data.insert({\"name\": \"Oliver Doe\"}, uuid=generate_uuid5(\"oliver\"))\nperson.data.insert({\"name\": \"Mary Jane\"}, uuid=generate_uuid5(\"mary\"))\n\n# Lets create our interactions\ninteraction.data.insert({\"text\": \"Is a vegetarian\"}, uuid=generate_uuid5(\"interaction1\"))\ninteraction.data.insert({\"text\": \"Like Indian and Asian food\"}, uuid=generate_uuid5(\"interaction2\"))\ninteraction.data.insert({\"text\": \"Is carnivore\"}, uuid=generate_uuid5(\"interaction3\"))\ninteraction.data.insert({\"text\": \"likes playing soccer\"}, uuid=generate_uuid5(\"interaction4\"))\n\n## now lets add our interactions to our people\n# bob is vegetarian\nperson.data.reference_add(\n    from_uuid=generate_uuid5(\"bob\"),\n    from_property=\"interactions\",\n    to=generate_uuid5(\"interaction1\")\n)\n\n# John like some indian and asian food\nperson.data.reference_add(\n    from_uuid=generate_uuid5(\"oliver\"),\n    from_property=\"interactions\",\n    to=generate_uuid5(\"interaction2\")\n)\n\n# mary plays soccer, and is carnivore\nperson.data.reference_add(\n    from_uuid=generate_uuid5(\"mary\"),\n    from_property=\"interactions\",\n    to=generate_uuid5(\"interaction3\")\n)\nperson.data.reference_add(\n    from_uuid=generate_uuid5(\"mary\"),\n    from_property=\"interactions\",\n    to=generate_uuid5(\"interaction4\")\n)\n\nPrinting some results:\n# this is how we will find the person with the most similar interactions\ndef print_results_to(target_person):\n    suggestion = person.query.near_object(\n        near_object=generate_uuid5(target_person),\n        return_references=wvc.query.QueryReference(\n            return_properties=[\"text\"], link_on=\"interactions\"\n        ),\n        return_metadata=wvc.query.MetadataQuery(distance=True),\n        include_vector=True\n    )\n    for o in suggestion.objects:\n        print(f\"### {o.metadata.distance}\")\n        print(o.properties)\n        print([i.properties.get(\"text\") for i in o.references[\"interactions\"].objects], \"\\n\")\n\nprint_results_to(\"bob\")\n\nwill output:\n\n0.0\n{‘name’: ‘Bob Smith’}\n[‘Is a vegetarian’]\n0.2569286823272705\n{‘name’: ‘Mary Jane’}\n[‘Is carnivore’, ‘likes playing soccer’]\n0.37227851152420044\n{‘name’: ‘Oliver Doe’}\n[‘Like Indian and Asian food’]\n\nnow we create a new customer, and check the resulting similarity:\n# creating a new customer that want to do a barbecue\n# let's first create the person\nperson.data.insert({\"name\": \"New Customer\"}, uuid=generate_uuid5(\"customer\"))\n# create the interaction\ninteraction.data.insert({\"text\": \"Want to do a barbecue\"}, uuid=generate_uuid5(\"interaction5\"))\n# tie the nots\nperson.data.reference_add(\n    from_uuid=generate_uuid5(\"customer\"),\n    from_property=\"interactions\",\n    to=generate_uuid5(\"interaction5\")\n)\n\nand now, printing the results to this person:\nprint_results_to(\"customer\")\n\nWill print the output:\n\n-7.152557373046875e-07\n{‘name’: ‘New Customer’}\n[‘Want to do a barbecue’]\n0.3768976926803589\n{‘name’: ‘Mary Jane’}\n[‘Is carnivore’, ‘likes playing soccer’]\n0.4221373200416565\n{‘name’: ‘Bob Smith’}\n[‘Is a vegetarian’]\n0.42987650632858276\n{‘name’: ‘Oliver Doe’}\n[‘Like Indian and Asian food’]\n\nAs you can see, you can create a new person, with at least one interaction, and it will start to get close to other persons.\nLet me know if that helps!\nThanks!",
    "date_created": "2025-01-08T20:49:30.813Z",
    "has_accepted_answer": false,
    "title": "Ref2vec-centroid on v4 client",
    "topic_id": 9637
  },
  {
    "user_id": 1640,
    "conversation": "[Sandon (2024-10-05T14:08:01.577Z)]: Environment: free cloud sandbox instance on Weaviate Cloud (WCD)\nCode language: nodejs (v18.20.4)\nVersion: weaviate-client (v3.1.5)\nCode:\nconst client = await weaviate.connectToWeaviateCloud(\n  clusterUrl,\n  {\n    authCredentials: new weaviate.ApiKey(apiKeyAdmin),\n    headers: {\n      'X-OpenAI-Api-Key': openaiApiKey\n    }\n  }\n)\n\nawait client.collections.create({\n    name: testCollectionName,\n    vectorizers: [\n      weaviate.configure.vectorizer.text2VecOpenAI({\n        name: 'question_vector',\n        sourceProperties: ['question'],\n        model: 'text-embedding-3-large',\n        dimensions: 1024\n      })\n    ],\n    properties: [\n      { name: 'category', dataType: dataType.TEXT },\n      { name: 'question', dataType: dataType.TEXT },\n      { name: 'answer', dataType: dataType.TEXT },\n    ]\n})\n\nIt’s demo code from the document.  But it can not create collection with vectorizer. (The result is : collection is created, but the Vectorizer is empty when view in console page)\nPlus: The openaiApiKey provided is corrent.\nI don’t know what’s wrong. Need help here. Thanks.\n\n----------\n\n[DudaNogueira (2024-10-06T17:43:56.216Z)]: hi @Sandon !!\nWelcome to our community \nThis may be a bug in the console.\nApart from the vectorizer not being showed in the console, do you were you able to index and query your data as expected?\n\n----------\n\n[Sandon (2024-10-07T14:01:14.471Z)]: Hi, @DudaNogueira\nI use the following code, but did not get vector showed (it is an empty object):\n    for await (let item of questions.iterator({\n      includeVector: true\n    })) {\n      console.log('item.vectors', item.vectors)\n    }\n\n\nNot only failed to create collection with named vector above. Also failed to create collection with default vector by code:\n    await client.collections.create({\n        name: testCollectionName,\n        vectorizers: vectorizer.text2VecOpenAI(),\n        properties: [\n          { name: 'category', dataType: dataType.TEXT },\n          { name: 'question', dataType: dataType.TEXT },\n          { name: 'answer', dataType: dataType.TEXT },\n        ]\n      })\n\nAfter using this code to create. Then use code:\n    for await (let item of questions.iterator({\n      includeVector: true\n    })) {\n      console.log('item.vectors', item.vectors)\n    }\n\nto query vector data. Still get empty object.\n\n----------\n\n[DudaNogueira (2024-10-14T21:16:28.126Z)]: hi @Sandon !\nWhat is the error message you get?\nhere is a full working code for typescript:\nimport weaviate, { dataType, vectorizer, WeaviateClient } from 'weaviate-client';\n\nasync function runFullExample() {\n  \n  const client: WeaviateClient = await weaviate.connectToLocal(\n  )\n  console.log(await client.isReady());\n\n  await client.collections.delete(\"Test\")\n\n  await client.collections.create({\n    name: \"Test\",\n    vectorizers: vectorizer.text2VecOpenAI(),\n    properties: [\n      { name: 'category', dataType: dataType.TEXT },\n      { name: 'question', dataType: dataType.TEXT },\n      { name: 'answer', dataType: dataType.TEXT },\n    ]\n  })\n\n  const collection = client.collections.get(\"Test\")\n  await collection.data.insert({\n    \"category\": \"cat1\",\n    \"question\": \"q1\",\n    \"answer\": \"a1\"\n  })\n\n  const obj = (await collection.query.fetchObjects({limit:1, includeVector:true})).objects[0]\n  console.log(obj.vectors)\n  \n}\n\nrunFullExample();\n\nLet me know if this helps!",
    "date_created": "2024-10-05T14:08:01.527Z",
    "has_accepted_answer": false,
    "title": "Failed to create collection with vectorizers using demo code in nodejs",
    "topic_id": 4436
  },
  {
    "user_id": 1246,
    "conversation": "[captainmccurry (2024-07-24T21:40:41.626Z)]: Description\nI am unable to configure GRCP with TLS Security, I am attempting to use AWS load balancer notations and am able to connect using the secure_grcp: False flag, but adding annotations for TLS make it fail. I can’t find guidance anywhere on how to configure GRPC with TLS security.\nServer Setup Information\n\nWeaviate Server Version: 1.25.6\nDeployment Method: Helm/k8s/AWS\nMulti Node? No\nClient Language and Version: Python v4\nMultitenancy?: No\n\nAny additional Information\ngrpcService:\nenabled: true\nname: weaviate-grpc\nports:\n- name: grpc\nprotocol: TCP\nport: 50051\ntype: LoadBalancer\nloadBalancerSourceRanges: \nclusterIP:\nannotations:\nservice. beta. kubernetes. io/aws-load-balancer-type: internal\nservice. beta. kubernetes. io/aws-load-balancer-internal: “true”\nservice. beta. kubernetes. io/aws-load-balancer-subnets: ${subnets}\nI have tried adding the following to add TLS, and control the ALPN policy:\nservice.beta.kubernetes.io/aws-load-balancer-ssl-cert: ${acm_certificate_arn}\nservice.beta.kubernetes.io/aws-load-balancer-alpn-policy: HTTP2Preferred\n\nError I receive with TLS cert on the end point:\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\nstatus = StatusCode.UNAVAILABLE\ndetails = “failed to connect to all addresses; last error: UNKNOWN: ipv4:10.219.217.106:50051: Cannot check peer: missing selected ALPN property.”\ndebug_error_string = “UNKNOWN:Error received from peer  {created_time:“2024-07-24T14:18:48.657627534-07:00”, grpc_status:14, grpc_message:“failed to connect to all addresses; last error: UNKNOWN: ipv4:10.219.217.106:50051: Cannot check peer: missing selected ALPN property.”}”\n\n----------\n\n[DudaNogueira (2024-07-31T21:06:16.599Z)]: hi @captainmccurry !!\nSorry! Missed this message. \nJust discovered some messages that went under my radar \nHope you were able to solve this already \nAre you still facing this issue?\nUnfortunately we do not have extensive documentation on how to expose Weaviate in different deployments as those can vary a lot.\nBottom line is that you need to expose http and grpc ports.\nYou can also use tools like grpcurl to check it serving status.\nlike so:\n# lets test our grpc connection\n❯ wget https://raw.githubusercontent.com/grpc/grpc/master/src/proto/grpc/health/v1/health.proto\n❯ grpcurl -d '{\"service\": \"Weaviate\"}' -proto health.proto grpc.weaviate.mydomain.com:50051 grpc.health.v1.Health/Check\n{\n  \"status\": \"SERVING\"\n}\n\nthere is some discussion around this subject (docker compose + traefik) here:\n\n  \n    \n    \n    Weaviate with Traefik and gRPC Support\n  \n  \n    Hello everyone!. I was trying out weaviate and wanted to implement a reverse proxy. Currently weaviate is hosted on docker that runs with traefik. I was able to connect to weaviate’s REST API without any issues. However, what i was unable to do is proxy the gRPC connection. \nHere is the error is see on my debugger: \nException has occurred: WeaviateQueryException\nQuery call failed with message Stream removed.\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus…\n  \n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-07-24T21:40:41.565Z",
    "has_accepted_answer": false,
    "title": "Configure Secure/TLS GRPC with Helm Chart/AWS",
    "topic_id": 3161
  },
  {
    "user_id": 1260,
    "conversation": "[Nazarii_Zabolotnyi (2024-08-06T09:58:53.825Z)]: Description\nHello, everybody. Currently I’m trying to find a way to search records by numbers.\nFor example:\nRecords are represented as strings (\ne.g.:\" Report for Transaction ID 777:\nAmount: 6.50 USD\nMerchant: Demo merchant\nStatus: COMPLETE\n…\n\").\nIt works good when I’m trying to find a record by merchant name or status. But when I tried to find a record by transaction ID, it found many records with wrong IDs (like 776 or 787).\nMy query has different representations such as:\n\nProvide me info about transaction with ID 777\nTransaction ID 777\n777\n\nBut I still can’t retrieve suitable data.\nServer Setup Information\n\nWeaviate Server Version: 1.26.0\nDeployment Method: docker\nClient Language and Version: v4\nqna-transformers: installed via docker\n\nAny additional Information\nI’m creating a flow in langflow, so I tried to use different components:\n\nThe base one (regular similarity search)\nCustom component with raw GraphQL query\n\n----------\n\n[DudaNogueira (2024-08-07T17:42:14.434Z)]: hi @Nazarii_Zabolotnyi !!\nThe results will depend mostly on how you index the data, and what/how are you searching for it.\nSo for example, by default, a text field will have a word tokenization (more on tokenization). This means that your properties will be broken down in word and some tokens will be considered from there.\nSo in the middle of the text, you may have data for transaction ID 1234. You will end up with roughly 4 tokens (some are ignored, etc). Let’s say data transaction ID (id may also be removed) and 1234.\nThere are more content from indexed properties that will also get into the inverted index.\nNow whenever you search using bm25 (keyword) search, this is our search index.\nAlso, your content can be embedded/vectorized. The content used to generated this vector will be a concatenation of some (or all) you properties. You define this with the skip_index for each property.\nThe “problem” of using tools like langlow, langchain, llama-index, is that it will create the collection, index everything and make it work like magic.\nBut there may be some automatic properties that you do now want to index. So what you can do is to inspect the created collection, export the schema, and fine tune it.\nNow, with all data indexed, you need to experiment the best results, searching with bm25 alone, near_text alone, and then mixing them up with  hybrid search.\nWe recently had a really nice webinar on advanced rag techniques that you will certainly enjoy:\n\n  \n    \n  \n\n\nFor example, while chunking your data, you can create better metadata that will expose the closest object better on this kind of queries.\nHere we have some other events that we are doing:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nOnline Workshops & Events | Weaviate - Vector Database\n\n  -Join us at conferences, meetups, webinars or workshops\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-08-06T09:58:53.716Z",
    "has_accepted_answer": false,
    "title": "Search by numbers (RAG)",
    "topic_id": 3274
  },
  {
    "user_id": 977,
    "conversation": "[Nancy_Viviana_Espino (2024-07-31T22:03:53.260Z)]: DescriptionGood morning, everyone!\nI recently migrated from Weaviate v3 to v4 and made some adjustments during the process. However, I’ve noticed that processing times in v4 seem to be longer compared to v3 for the same files.\nHas anyone else encountered this issue? I would greatly appreciate any recommendations for best practices or tips on how to validate and improve processing times. Your insights would be invaluable as I work to optimize performance.\nThank you very much for your help!\nweaviate-client = 4.7.1\nversion=1.24.9\n\n----------\n\n[DudaNogueira (2024-07-31T22:10:33.047Z)]: Hi Nancy!\nWelcome to our community \nI believe you have the same Weaviate Server version (for instance 1.24.9) for both the v3 and v4 clients, right?\nCan you share the code you are using for both clients?\nthe python v4 should deliver significant improvements as it leverages GRPC instead of pure REST.\nPs: the latest in 1.24.X is 1.24.21 as I write. We strongly recommend keeping it updated to avoid any of the known issues of previous versions.\nThanks!\n\n----------\n\n[Nancy_Viviana_Espino (2024-08-05T14:17:25.662Z)]: The process we mainly use consists of doing this\nwith ProcessPoolExecutor(mp_context=mp.get_context(\"spawn\")) as executor:\n    for post in collection.iterator(include_vector=False, after=cursor, return_properties=columns_to_retrieve):\n        ... # get post filters\n        post_requests = {\n            \"uid\": str(post.uuid),\n            \"weaviate_post_id\": post.properties[\"weaviate_post_id\"],\n            \"where_filters\": rel_filters_cache[rel_filters_combination],\n        }\n        batch_posts.append(post_requests)\n\n        if len(batch_posts) % batch_size == 0:\n            res = vector_db.process_batch_posts(batch_posts, max_recommendations, executor)\n\nInside the process_batch_posts what we do is with executor.map(partial(…)) to get the closest ones by batch. For this what we do is\nweaviate.connect_to_local(\n        # Avoid timeouts by setting one minute\n        port=DEFAULT_PORT,\n        grpc_port=DEFAULT_GRPC_PORT,\n        additional_config=AdditionalConfig(\n            timeout=Timeout(init=60, query=60, insert=120),  # Values in seconds\n        skip_init_checks=True,\n        ),\n\n    ) as thread_client:\ncollection = thread_client.collections.get(collection_name)\nann_result = collection.query.near_object(  # type: ignore\n            near_object=post_uid,\n            limit=n_neighbors,\n            return_metadata=MetadataQuery(distance=True),\n            filters=filters,\n            return_properties=[\"weaviate_post_id\"],\n        )",
    "date_created": "2024-07-31T22:03:53.210Z",
    "has_accepted_answer": false,
    "title": "Increased processing time on Weaviate v3 to v4 migration",
    "topic_id": 3235
  },
  {
    "user_id": 1481,
    "conversation": "[Jasper_van_den_Berg (2024-09-02T13:17:24.097Z)]: Description\nI’m using Weaviate as vector store database for my LangChain FastAPI app, and it seems that every time I restart the weaviate Docker image, the previously created vector store will start throwing errors when querying.\nSpecifically this error will be returned when querying (hybrid search):\nTraceback (most recent call last):\n  File \"venv/lib/python3.11/site-packages/weaviate/collections/grpc/query.py\", line 649, in __call\n    res, _ = self._connection.grpc_stub.Search.with_call(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"venv/lib/python3.11/site-packages/grpc/_channel.py\", line 1198, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"venv/lib/python3.11/site-packages/grpc/_channel.py\", line 1006, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n        status = StatusCode.UNKNOWN\n        details = \"dense search: search index idx_27d57efa8da7ac6e31a654e5503f1f01: remote shard KkYLQghuTYXB: resolve node name \"0cfd736f585d\" to host\"\n        debug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"dense search: search index idx_27d57efa8da7ac6e31a654e5503f1f01: remote shard KkYLQghuTYXB: resolve node name \\\"0cfd736f585d\\\" to host\", grpc_status:2, created_time:\"2024-09-02T14:26:53.369983+02:00\"}\"\n>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"venv/lib/python3.11/site-packages/langchain_weaviate/vectorstores.py\", line 279, in _perform_search\n    result = collection.query.hybrid(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"venv/lib/python3.11/site-packages/weaviate/collections/queries/hybrid/query.py\", line 105, in hybrid\n    res = self._query.hybrid(\n          ^^^^^^^^^^^^^^^^^^^\n  File \"venv/lib/python3.11/site-packages/weaviate/collections/grpc/query.py\", line 246, in hybrid\n    return self.__call(request)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"venv/lib/python3.11/site-packages/weaviate/collections/grpc/query.py\", line 658, in __call\n    raise WeaviateQueryError(e.details(), \"GRPC search\")  # pyright: ignore\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nweaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message dense search: search index idx_27d57efa8da7ac6e31a654e5503f1f01: remote shard KkYLQghuTYXB: resolve node name \"0cfd736f585d\" to host.\n\nThe query call is done from another Docker which runs the Langchain app within a FastAPI framework.\nDo note that I’m not getting this error when I create the vector store from it first, and then query it directly after. It’s only after I restart the Weaviate Docker that the previously created vector store will start returning this error when queried from my app.\nServer Setup Information\n\nWeaviate Server Version: 1.26.3 ( Docker image from semitechnologies/weaviate:latest )\nDeployment Method: Docker\nMulti Node? Number of Running Nodes:\nI’m not sure I’m deploying it through:\n\ndocker run -p 8080:8080 -p 50051:50051 --env-file .env.local -e QUERY_DEFAULTS_LIMIT=20 -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true -e PERSISTENCE_DATA_PATH=/data -v weaviate_data:/data semitechnologies/weaviate:latest\n\nwhere .env.local:\nENVIRONMENT=local\nHOST=0.0.0.0\nPORT=80\nACCESSIBLE_HOST=localhost\nACCESSIBLE_PORT=8000\nGOOGLE_APPLICATION_CREDENTIALS=/code/app/auth.json\nWEAVIATE_SERVER_URL=http://weaviate:8080\nWEAVIATE_SERVER_GRPC_PORT=50051\nOPENAI_API_KEY=<key>\n\n\nClient Language and Version:\nlangchain-weaviate==0.0.2\nweaviate-client==4.6.4\npython 3.11.9\nMultitenancy?:\nNot that I know of, using default configs\n\nAdditional information\nThe vector store is created through the LangChain FastAPI backend using langchain-weaviate:\nWeaviateVectorStore.from_documents(\n    documents,\n    client=WeaviateClient(connection_params=ConnectionParams.from_url(\"http://localhost:8080\", 50051)),\n    embedding=OpenAIEmbeddings(api_key=os.environ[\"OPENAI_API_KEY\"]),\n    index_name=index_name\n)\n\nloaded through:\nWeaviateVectorStore(\n    client=WeaviateClient(connection_params=ConnectionParams.from_url(\"http://localhost:8080\", 50051)),\n    embedding=OpenAIEmbeddings(api_key=os.environ[\"OPENAI_API_KEY\"]),\n    index_name=index_name,\n    text_key=\"text\"\n)\n\nand queried through:\nWeaviateVectorStore.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 50, \"filters\": retriever_filters})\n\n----------\n\n[DudaNogueira (2024-09-02T14:06:53.327Z)]: hi @Jasper_van_den_Berg !!\nCan you add, as a environment variable:\nCLUSTER_HOSTNAME=0cfd736f585d\nThis may be a known issue from upgraded versions:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigration Guide | Weaviate\n\n  Migration for version 1.19.0\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAlso, it is not advised to use the latest image tag, but to link the deployment on a specific version.\nLet me know if this helps.\nThanks!\n\n----------\n\n[Jasper_van_den_Berg (2024-09-02T14:38:20.195Z)]: Hi there @DudaNogueira ,\nThank you for the prompt response, I’ve just tested adding the suggested environment variable and it seems to indeed solve the issue, great!\nI’ll do some more testing just to make sure but so far so good. Thanks a lot!\nKind regards,\nJasper\nP.S. Nice catch on the latest tag indeed, will definitely set it to a static version",
    "date_created": "2024-09-02T13:17:24.031Z",
    "has_accepted_answer": true,
    "title": "Dense search grcp error after restarting weaviate Docker",
    "topic_id": 3958
  },
  {
    "user_id": 532,
    "conversation": "[wechwech (2024-08-07T18:47:44.549Z)]: Description\n\nHi I am using Weaviate embedded with python api v3, is there a way to set  the resources usage limit, as I could not find this documented on the python Api so far, thanks\nI am instantiating the weaviate client like this\nclient = weaviate.Client(             embedded_options=weaviate.embedded.EmbeddedOptions(                 persistence_data_path=PERSISTANCE_PATH             ) \nServer Setup Information\n\nWeaviate Server Version: python v3\nDeployment Method: embedded \nMulti Node? Number of Running Nodes: no\nClient Language and Version: api v3, python\nMultitenancy?: no\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-08-07T19:53:25.663Z)]: hi @wechwech !!\nWelcome to our community \nWhat the Embedded installation method does is to run, on your host system, the weaviate go binary.\nBecause of that, you will need to tweak your host system on how to limit those resources.\nThat’s when tools like docker comes in, taking control of not only resource usage, but volumes, ports, etc.\nYou can, however, define some of the environment variables from Weaviate, like LIMIT_RESOURCES, GOMEMLIMIT and GOMAXPROCS\nYou can do that passing extra env vars like so:\nclient = weaviate.Client(\n  embedded_options=EmbeddedOptions(\n      additional_env_vars={\n      \"ENABLE_MODULES\":\n      \"backup-s3,text2vec-openai,text2vec-cohere,text2vec-huggingface,ref2vec-centroid,generative-openai,qna-openai\"}\n  )\n)\n\nlike described here: Embedded Weaviate | Weaviate - Vector Database\nNote: we strongly suggest moving to python v4 code as it has a lot of improvements.\nLet me know if this helps!\nThanks!\n\n----------\n\n[wechwech (2024-08-09T22:03:50.645Z)]: Hi Duda,\nthanks a lot, this clear to me, I will try that",
    "date_created": "2024-08-07T18:47:44.485Z",
    "has_accepted_answer": true,
    "title": "How to set up resources usage limit for Weaviate embedded with python",
    "topic_id": 3294
  },
  {
    "user_id": 2473,
    "conversation": "[Ajay_T (2024-11-19T06:03:37.228Z)]: Description\n\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: Docker Compose\nClient Language and Version: Python 3.9\nMultitenancy?: Yes\n\nAdditional Context\n\n\nUsing autoTenantActivation feature\n\n\nNeed to identify “idle” tenants for state management\n\n\nCurrently monitoring through Grafana/Prometheus\n\n\nCurrent Limitations\n\nPrometheus metrics only show class-level activity:\n\nqueries_filtered_vector_durations_ms{\n    class_name=\"Paragraph\",\n    operation=\"vector\"\n}\n\nQuestion\nI was wondering if there are any existing or planned to be added ways to track tenant-specific activity in Weaviate? I’m also particularly curious how autoTenantActivation is able to detect when a tenant needs to be activated.\nAny help would be appreciated, thanks\n\n----------\n\n[Mohamed_Shahin (2024-11-19T11:42:58.829Z)]: Hello @Ajay_T,\nGreat questions!\nThe autoTenantActivation feature detects when a tenant needs to be activated by monitoring specific operations, such as search, read, update, or delete requests performed on the tenant. If a tenant is inactive or offloaded and one of these operations is initiated, the system automatically triggers the activation process, ensuring the tenant becomes active and accessible for the requested operation.\nFor metrics, you can leverage the PROMETHEUS_MONITORING_GROUP environment variable: Monitoring Multi-Tenancy.\nHowever, If you have a specific way you’d like to track, it might make for a great feature request!\nRegards,\nMohamed Shahin,\nWeaviate Support",
    "date_created": "2024-11-19T06:03:37.173Z",
    "has_accepted_answer": true,
    "title": "Tracking Multi-Tenant Activity in Weaviate",
    "topic_id": 7690
  },
  {
    "user_id": 586,
    "conversation": "[Spun (2025-02-28T13:39:02.848Z)]: Description\nHi! I have setup with multiple tenants(users) with the same schema. At the current moment I need to move some data from one tenant to another. As the schema contains many collections with multiple cross-references I see that the script from ‘Migrate data’ topic(from official documentation) would be not so easy to implement, because I have connections to other data on S3 storage and those connections use UUIDs from the weaviate objects as a part of the data object paths.\nSo, my question is - Does a way to change a tenant for the data in a collection in a simple way exist ? Or will I need to make a huge script for this (I will need to insert the main data again, recreate all the references and reupload additional data to the S3 storage with new UUIDs as a parts of new S3 object paths)?\nThanks in advance\nServer Setup Information\n\nWeaviate Server Version: 1.26.8\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python 4.11.0\nMultitenancy?: Yes\n\n----------\n\n[DudaNogueira (2025-02-28T18:51:09.461Z)]: hi @Spun !!\nI am afraid you are in for some scripting. The migration guide, will cover some basic scenarios and good practices.\nYou can keep the uuids originated by Weaviate and used as a reference in other systems by reading the original ones and making sure to provide them as the uuid argument when moving your tenant data to a different collection or even cluster.\nNow for migrating the cross references, you’ll need to migrate the cross-referenced collections first, and only then the the collection.\nAre you moving from one cluster to another, or plan on doing some remodeling?\nLet me know if this helps.\nThanks!\n\n----------\n\n[Spun (2025-03-02T09:56:12.822Z)]: Hi @DudaNogueira !\nNo, this is no cluster to cluster migration, this is tenant to tenant migration inside the same cluster. Thats why the question about UUIDs is important - because I’m afraid I can’t use the same UUID for different tenants in the cluster.\n\n----------\n\n[DudaNogueira (2025-03-03T13:32:52.206Z)]: Hi @Spun !\nYou can use the same uuid for objects in different tenants without a problems, as they are isolated.\nThe only problem here, depending on your dataset size, would be the resource usage. But as soon as you delete the entire migrated data from a tenant, Weaviate should free the resources, but during the migration, it should use the resources for both tenants.\nOther than that, you shouldn’t have issues.\nIf you need further assistance, we are here to help!\nLet me know if this helps\n\n----------\n\n[Spun (2025-03-03T16:01:18.237Z)]: You can use the same uuid for objects in different tenants without a problems, as they are isolated.\n\nThis is great, thank you!",
    "date_created": "2025-02-28T13:39:02.798Z",
    "has_accepted_answer": true,
    "title": "How to move data from one tenant to another in an easy way",
    "topic_id": 10606
  },
  {
    "user_id": 588,
    "conversation": "[mnkasikci (2024-09-17T08:40:12.216Z)]: I want to connect to my old weaviate instance. However, in its current settings, it doesn’t have a load balancer with grpc configured, so i want to do it without grpc.\nI want to connect to it via  “weaviate-client”: “^3.1.4”.\nIs there a way to tell the client to connect WITHOUT grpc?\nI tried doing this:\n          this.client = await weaviate.connectToCustom({\n            httpHost: config.weaviate.httpHost,\n            httpPort: config.weaviate.httpPort,\n            httpSecure: true,\n            authCredentials: new weaviate.ApiKey(config.weaviate.apiKey),\n          });\n\nWhile it passes the health/live check, i get this error:\nQuery call with protocol gRPC failed with message: /weaviate.v1.Weaviate/Search UNKNOWN: extract auth: oidc auth is not configured, please try another auth scheme or set up weaviate with OIDC configured\nI can confirm that config.weaviate.apiKey is the correct api key.\n\n----------\n\n[Dirk (2024-09-17T11:26:26.542Z)]: Hey, then you need to use the old typescript client (v2). V3 only works with GRPC\n\n----------\n\n[mnkasikci (2024-09-18T09:31:21.525Z)]: Thank you so much for the clarification.\nFor me it was not clear whether grpc was mandatory for the client, i thought it preferred grpc over http.\nWhat mislead me was, the fact that grpcHost was optional in ConnectToCustomOptions and that with the configuration above, it passed the ready & live checks. (I am aware that ready and live checks are for the server, not client. But i said to myself, “if the client can initialize & connect & even do ready checks with this configuration, it should be good to go”.\nIn this case, wouldn’t it be semantically more correct to make the grpcHost parameter in ConnectToCustomOptions mandatory? Am i missing something? I’d be glad to send a pr for this. Moreover, httpHost parameter could be mandatory as well.\n\n----------\n\n[mnkasikci (2024-09-18T09:32:13.609Z)]: Another solution would be making a fallback mechanism. I’d be glad to help prepare a pr for that as well, but obviously that’d take more time.\n\n----------\n\n[Dirk (2024-09-19T06:19:57.854Z)]: mnkasikci:\n\nFor me it was not clear whether grpc was mandatory for the client, i thought it preferred grpc over http.\n\n\nFor v3 GRPC is mandatory and most functionality does not work without it. It is a complete rewrite from v2 and it is not possible to fall back on http/REST/GQL.\nI will pass on your feedback to the TS client dev",
    "date_created": "2024-09-17T08:40:12.164Z",
    "has_accepted_answer": true,
    "title": "Connect to Weaviate instance WITHOUT grpc",
    "topic_id": 4180
  },
  {
    "user_id": 323,
    "conversation": "[Dharanish (2024-09-03T12:34:07.115Z)]: col = ext_client.collections.get(name=“TEST_TENANT_0”)\ncol.config.get_shards()\nworking fine if all tenants are HOT\nbut getting the below exception If tenant is in COLD status.\nUnexpectedStatusCodeError: get shards! Unexpected status code: 404, with response body: {‘error’: [{‘message’: ‘shard Tenant_A: shard Tenant_A does not exist’}]}.\nserver : v1.23.11\nclient : v4.5.7\n\n----------\n\n[DudaNogueira (2024-09-03T13:56:54.728Z)]: hi @Dharanish !!\nI was not able to reproduce this.\nhere is what I have tried:\nimport weaviate\nfrom weaviate import classes as wvc\nclient = weaviate.connect_to_local()\n    \nprint(weaviate.__version__, client.get_meta().get(\"version\"))\nclient.collections.delete(\"Test\")\n\ncollection = client.collections.create(\n    \"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_cohere(),\n    multi_tenancy_config=wvc.config.Configure.multi_tenancy(enabled=True, auto_tenant_creation=True, auto_tenant_activation=True)\n)\ncollection.with_tenant(\"T1\").data.insert({\"text\": \"Text for T1\"})\ncollection.with_tenant(\"T2\").data.insert({\"text\": \"Text for T2\"})\n\ncollection.tenants.update(tenants=[\n    wvc.tenants.Tenant(name=\"T1\", activity_status=wvc.tenants.TenantActivityStatus.COLD),\n    wvc.tenants.Tenant(name=\"T2\", activity_status=wvc.tenants.TenantActivityStatus.COLD)\n])\n\ncol = client.collections.get(name=\"Test\")\ncol.config.get_shards()\n\nIs something similar to this that you are trying?\nThanks!",
    "date_created": "2024-09-03T12:34:07.067Z",
    "has_accepted_answer": false,
    "title": "Exception while getting shards status if tenant in `COLD` status",
    "topic_id": 3965
  },
  {
    "user_id": 3516,
    "conversation": "[exsvn (2025-02-21T13:38:13.565Z)]: I’m running into an issue with multi-vector setup and could use some help. I’m trying to implement a LongTermMemory class that stores objects with separate text_embedding and image_embedding vectors. These are external embeddings. I keep getting a 422 error:\nweaviate.exceptions.UnexpectedStatusCodeError: Object was not added! Unexpected status code: 422, with response body: {'error': [{'message': 'invalid object: collection MemoryEvent is configured without multiple named vectors, but received named vectors: map[image_embedding:[...] text_embedding:[...]]'}]}.\n\nfrom weaviate.classes.config import Property, DataType, Configure\n\ndef _initialize_schema(self):\n    \"\"\"Initializes the schema.\"\"\"\n    if not self.client.collections.exists(self.class_name):\n        if Config.USE_SEPARATE_EMBEDDINGS_FOR_RETRIEVAL:\n            # Multi-vector configuration\n            self.client.collections.create(\n                name=self.class_name,\n                vectorizer_config=[\n                    Configure.NamedVectors.none(name=\"text_embedding\", vector_index_config=Configure.VectorIndex.hnsw()),\n                    Configure.NamedVectors.none(name=\"image_embedding\", vector_index_config=Configure.VectorIndex.hnsw())\n                ],\n                properties=[\n                    Property(name=\"metadata\", data_type=DataType.TEXT),\n                    Property(name=\"importance\", data_type=DataType.NUMBER),\n                    Property(name=\"timestamp\", data_type=DataType.DATE),\n                    Property(name=\"last_accessed\", data_type=DataType.DATE),\n                    Property(name=\"category\", data_type=DataType.TEXT,\n                            description=\"safety_critical/routine\"),\n                    Property(name=\"access_count\", data_type=DataType.NUMBER)\n                ]\n            )\n\n        else:\n            # Single-vector configuration\n            self.client.collections.create(\n                name=self.class_name,\n                vectorizer_config=Configure.Vectorizer.none(),\n                properties=[\n                    Property(name=\"metadata\", data_type=DataType.TEXT),\n                    Property(name=\"importance\", data_type=DataType.NUMBER),\n                    Property(name=\"timestamp\", data_type=DataType.DATE),\n                    Property(name=\"last_accessed\", data_type=DataType.DATE),\n                    Property(name=\"category\", data_type=DataType.TEXT,\n                            description=\"safety_critical/routine\"),\n                    Property(name=\"access_count\", data_type=DataType.NUMBER)\n                ]\n            )\n\nHere is how I add events:\ndef add(self, embedding, metadata, initial_importance=0.7):\n    \"\"\"\n    Stores an event.\n    \"\"\"\n    metadata_str = json.dumps(metadata)\n    collection = self.client.collections.get(self.class_name)\n    \n    uuid = metadata.get(\"image_path\", \"\").split(\"/\")[-1].split(\".\")[0] or None\n    \n    if Config.USE_SEPARATE_EMBEDDINGS_FOR_RETRIEVAL:\n        vectors = {\n            \"text_embedding\": metadata.get(\"embeddings\", {}).get(\"text_embedding\"),\n            \"image_embedding\": metadata.get(\"embeddings\", {}).get(\"image_embedding\")\n        }\n    else:\n        vectors = embedding\n\n    collection.data.insert(\n        properties={\n            \"metadata\": metadata_str,\n            \"importance\": initial_importance,\n            \"timestamp\": datetime.now().astimezone().isoformat(),\n            \"last_accessed\": datetime.now().astimezone().isoformat(),\n            \"category\": self._determine_category(metadata_str),\n            \"access_count\": 0\n        },\n        vector=vectors,\n        uuid=uuid\n    )\n\nI have followed these documentations but I still cannot figure out the problem. Btw, I already delete the collection before running my agent. Also, my single vector setup works perfectly. I’m using Weaviate v4.11. Thank you!\n\nManage collections | Weaviate\nCreate objects | Weaviate\n\n----------\n\n[DudaNogueira (2025-02-21T18:01:56.641Z)]: Hi @exsvn !\nWelcome to our community \nI was not able to reproduce this.\nHere is a MRE:\nfrom weaviate.classes.config import Configure, DataType, Property\nclient.collections.delete(name=\"Test\")\nclient.collections.create(\n    name=\"Test\",\n    vectorizer_config=[\n        Configure.NamedVectors.none(name=\"text_embedding\", vector_index_config=Configure.VectorIndex.hnsw()),\n        Configure.NamedVectors.none(name=\"image_embedding\", vector_index_config=Configure.VectorIndex.hnsw())\n    ],\n    properties=[\n        Property(name=\"metadata\", data_type=DataType.TEXT),\n        Property(name=\"importance\", data_type=DataType.NUMBER),\n        Property(name=\"timestamp\", data_type=DataType.DATE),\n        Property(name=\"last_accessed\", data_type=DataType.DATE),\n        Property(name=\"category\", data_type=DataType.TEXT,\n                description=\"safety_critical/routine\"),\n        Property(name=\"access_count\", data_type=DataType.NUMBER)\n    ]\n)\ncollection = client.collections.get(\"Test\")\ncollection.data.insert(\n    {\"metadata\": \"new Object\"},\n    vector={\n        \"text_embedding\": [0.1, 0.2, 0.3],\n        \"image_embedding\": [0.4, 0.5, 0.6, 0.4,]\n    }\n)\n\nConsidering the error message, it seems you are trying to pass a multivector to your a single vector collection.\nThis will result in the same error message:\nfrom weaviate.classes.config import Configure, DataType, Property\nclient.collections.delete(name=\"Test\")\nclient.collections.create(\n    name=\"Test\",\n    vectorizer_config=Configure.Vectorizer.none(),\n    properties=[\n        Property(name=\"metadata\", data_type=DataType.TEXT),\n        Property(name=\"importance\", data_type=DataType.NUMBER),\n        Property(name=\"timestamp\", data_type=DataType.DATE),\n        Property(name=\"last_accessed\", data_type=DataType.DATE),\n        Property(name=\"category\", data_type=DataType.TEXT,\n                description=\"safety_critical/routine\"),\n        Property(name=\"access_count\", data_type=DataType.NUMBER)\n    ]\n)\ncollection = client.collections.get(\"Test\")\ncollection.data.insert(\n    {\"metadata\": \"new Object\"},\n    vector={\n        \"text_embedding\": [0.1, 0.2, 0.3],\n        \"image_embedding\": [0.4, 0.5, 0.6, 0.4,]\n    }\n)\n\nOutput:\nUnexpectedStatusCodeError: Object was not added! Unexpected status code: 422, with response body: {'error': [{'message': 'invalid object: collection Test is configured without multiple named vectors, but received named vectors: map[image_embedding:[0.4 0.5 0.6 0.4] text_embedding:[0.1 0.2 0.3]]'}]}.\nLet me know if that helps!\nTHanks!\n\n----------\n\n[exsvn (2025-02-22T03:00:29.069Z)]: Thanks for the reply! The flag USE_SEPARATE_EMBEDDINGS_FOR_RETRIEVAL = True and I believe I’m creating a multi-vector schema correctly with named vectors (text_embedding and image_embedding). Here is the schema collection:\n<weaviate.Collection config={\n  \"name\": \"MemoryEvent\",\n  \"description\": null,\n  \"generative_config\": null,\n  \"inverted_index_config\": {\n    \"bm25\": {\n      \"b\": 0.75,\n      \"k1\": 1.2\n    },\n    \"cleanup_interval_seconds\": 60,\n    \"index_null_state\": false,\n    \"index_property_length\": false,\n    \"index_timestamps\": false,\n    \"stopwords\": {\n      \"preset\": \"en\",\n      \"additions\": null,\n      \"removals\": null\n    }\n  },\n  \"multi_tenancy_config\": {\n    \"enabled\": false,\n    \"auto_tenant_creation\": false,\n    \"auto_tenant_activation\": false\n  },\n  \"properties\": [....some properties....],\n  \"references\": [],\n  \"replication_config\": {\n    \"factor\": 1,\n    \"async_enabled\": false,\n    \"deletion_strategy\": \"NoAutomatedResolution\"\n  },\n  \"reranker_config\": null,\n  \"sharding_config\": {\n    \"virtual_per_physical\": 128,\n    \"desired_count\": 1,\n    \"actual_count\": 1,\n    \"desired_virtual_count\": 128,\n    \"actual_virtual_count\": 128,\n    \"key\": \"_id\",\n    \"strategy\": \"hash\",\n    \"function\": \"murmur3\"\n  },\n  \"vector_index_config\": null,\n  \"vector_index_type\": null,\n  \"vectorizer_config\": null,\n  \"vectorizer\": null,\n  \"vector_config\": {\n    \"image_embedding\": {\n      \"vectorizer\": {\n        \"vectorizer\": \"none\",\n        \"model\": {},\n        \"source_properties\": null\n      },\n      \"vector_index_config\": {\n        \"multi_vector\": null,\n        \"quantizer\": null,\n        \"cleanup_interval_seconds\": 300,\n        \"distance_metric\": \"cosine\",\n        \"dynamic_ef_min\": 100,\n        \"dynamic_ef_max\": 500,\n        \"dynamic_ef_factor\": 8,\n        \"ef\": -1,\n        \"ef_construction\": 128,\n        \"filter_strategy\": \"sweeping\",\n        \"flat_search_cutoff\": 40000,\n        \"max_connections\": 32,\n        \"skip\": false,\n        \"vector_cache_max_objects\": 1000000000000\n      }\n    },\n    \"text_embedding\": {\n      \"vectorizer\": {\n        \"vectorizer\": \"none\",\n        \"model\": {},\n        \"source_properties\": null\n      },\n      \"vector_index_config\": {\n        \"multi_vector\": null,\n        \"quantizer\": null,\n        \"cleanup_interval_seconds\": 300,\n        \"distance_metric\": \"cosine\",\n        \"dynamic_ef_min\": 100,\n        \"dynamic_ef_max\": 500,\n        \"dynamic_ef_factor\": 8,\n        \"ef\": -1,\n        \"ef_construction\": 128,\n        \"filter_strategy\": \"sweeping\",\n        \"flat_search_cutoff\": 40000,\n        \"max_connections\": 32,\n        \"skip\": false,\n        \"vector_cache_max_objects\": 1000000000000\n      }\n    }\n  }\n}>\n\nCould you please confirm that this is a correct multi-vector configuration? Thank you!",
    "date_created": "2025-02-21T13:38:13.517Z",
    "has_accepted_answer": false,
    "title": "Collection is configured without multiple named vectors, but received named vectors",
    "topic_id": 10492
  },
  {
    "user_id": 655,
    "conversation": "[alisha_liu (2024-11-21T18:19:52.306Z)]: Description\nGet this error when batch insert object into weaviate collection\n[ERROR]\t2024-11-21T17:34:17.506Z\t1da0187e-ee0e-511a-bdb1-47c780dec089\t{‘message’: ‘Failed to send 1 objects in a batch of 1. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: k8s\nMulti Node? No\nClient Language and Version: python 3.9\nMultitenancy?: No\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-11-21T20:43:44.472Z)]: hi @alisha_liu !!\nYou need to inspect the failed_objects  in order to discover what the error is about.\nCheck here for more information:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Utilize the Python client library to access Weaviate and streamline data processes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!",
    "date_created": "2024-11-21T18:19:52.265Z",
    "has_accepted_answer": false,
    "title": "Batch insert error",
    "topic_id": 7764
  },
  {
    "user_id": 1250,
    "conversation": "[Denis_K (2024-07-25T16:37:23.489Z)]: Hey everyone! Have a question, when an object is updated, if property is the same, will it be revectorized?\nFor example:\nobj = {id:1, content: ‘some content’, content2: ‘some other content’}\nconst response = await myCollection.data.update({\nid: 1,\nproperties: {\n‘content’: ‘some content’,\n‘content2’: ‘updated content 2’\n},\n\n----------\n\n[DudaNogueira (2024-07-25T18:32:37.602Z)]: hi @Denis_K !! Welcome to our community \nIt will!\nUnless you explicitly set the property to skip vectorization or you have named vectors that do not reference that property.\nSo in your example, given that skip vectorization is False by default and you have not set it to True, Weaviate will revectorize that object, so the new vector has the meaning that “updated content 2” will add to that object.\nIn order to vectorize an object, Weaviate will, according to your collection configuration, concatenate collection name and properties names and values that should be vectorized, and the end result is then sent to the embedding model to generate the vectors.\nHere you can check the exact steps Weaviate will do on generating the payload for the vectorization step:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection schema | Weaviate - Vector Database\n\n  Introduction\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-07-25T16:37:23.440Z",
    "has_accepted_answer": false,
    "title": "Object update revectorize",
    "topic_id": 3172
  },
  {
    "user_id": 1097,
    "conversation": "[uma_shankar (2024-07-07T10:38:27.830Z)]: I just started with verba and I am using  ADAEmbedder\nQuery:  “find me renovated apartment for less than 1 million”\nThe search does not care about 1 million at all.  Also it does not consider “refurbished apartments” (as refurbished is a synonym of renovated).\nHow can I make this simple search work perfect ?  Should I use some other Embedder or should I make a custom embedder for myself ?\nI do not know about these embedders at all, as I am very new to LLMs\n\n----------\n\n[DudaNogueira (2024-07-08T12:06:24.655Z)]: hi @uma_shankar !!\nthe results will depend on the vectorizer used, the content you have indexed (how it was chunked, some metadata, etc) and the query.\nI am not sure that using a “natural language” filtering (less than 1 million) will indeed get you the results you expect. \nYou will, however, get the closest object from your query based on the vector distance.\nLet me know if this helps!\nThanks!\n\n----------\n\n[uma_shankar (2024-07-08T12:14:53.472Z)]: Thanks I understand.\nI do not know which Vectorizer is best for my case “property recommendation”.\nShould I do any thing special regarding “metadata” during ingestion ?\nOr I just have to add “metadata” during the query ?\n\n----------\n\n[DudaNogueira (2024-07-08T18:26:05.998Z)]: hi!\nThe vectorizer will depend on some experimentation, really. if it must be multilingual, the size of dimensions, etc.\nRegarding metadata, consider for example 20 chunks. 10 for each document. You will want to store at least the main title of that document with each chunk.\nOtherwise, for each chunk, you don’t add the meaning of those words per chunk.\nWith that said, and considering metadata, you want to make sure that each chunk has not only it’s content, but some metadata that can add context to what that chunk is related to.\nLet me know if this helps.\nIf you want to learn more on chunking, check this docs:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nA brief introduction to chunking | Weaviate - Vector Database\n\n  <!-- import imageUrl from '../../tmpimages/academyplaceholder.jpg';\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!\n\n----------\n\n[Ghattas_Salloum (2024-07-10T10:28:37.545Z)]: Hi,\ni already have experience with that same situation, after lots of testing i find out that vector search is not the best for property recommendations at all, what you will need to do is create  set of features like price and size and locations and so one then use gpt-4 to extract the features from the query as json then use that json to search properties in sql database that will give way better results that using vector database\nI have already done that and thr difference is huge,\nthe vector database is better of unstructured data like huge amounts text which i use weaviate for and it works really well\nHope that helps\n\n----------\n\n[DudaNogueira (2024-07-11T20:26:59.502Z)]: thanks for sharing, @Ghattas_Salloum !!\n\n----------\n\n[Ghattas_Salloum (2024-07-12T08:21:19.999Z)]: Sure any time\nhave a great one\n\n----------\n\n[uma_shankar (2024-07-15T08:41:28.398Z)]: I did some more work on this.  It looks like @Ghattas_Salloum  is right.  I used metadata(gpt extracted) search for filtering price, nr_bedrooms, etc…  I then relied on dense-search to match other criterias like amenities, patio, etc…\nBut the vector-search is not doing its job at all.  For instance, if I search for a simple query “close to school”.  The apartment which is close to school is getting less score than the other without any mention about school.\nThis is the only criteria I want to match.  But it is not working. I wonder why.\n\n----------\n\n[Ghattas_Salloum (2024-07-15T09:17:24.435Z)]: Hi,\nI think i can help with that too but with a different acpect,\nWhen i add a property info i always add the lat and long coordinates for that property ,\nSo when i do the search i would use these coordinates with google maps api to check the schools near by or the bus station or restaurants etc…\nin that way i don’t really have to depend on search to find that but google maps api can handle that really well.\nother advice in your situation i would look at chucking methods used that might have huge impact on the results, i would parse all the data as csv, and each chunk will be a full csv row.\nHope that hepls\n\n----------\n\n[uma_shankar (2024-07-15T09:25:51.306Z)]: Should the csv be like\n“type: apartment,  bedrooms: 2,  bathrooms: 2” ?\n\n----------\n\n[Ghattas_Salloum (2024-07-15T09:38:43.023Z)]: yes that would be correct, and you can add any more search criteria in csv,\none more important note in this case you shoud not depend on the search score at all just do the search and pass the results to gpt-4 along with chat history and last query and leave task of chose best match to gpt-4  believe me you will get best results ever.\n\n----------\n\n[uma_shankar (2024-07-16T18:02:53.951Z)]: The CSV solution works perfectly! You’re amazing. \nI’m feeling optimistic again about vector search.\n\n----------\n\n[Ghattas_Salloum (2024-07-17T17:06:38.680Z)]: Nice to hear that worked out for you\nAny other help let me know\n\n----------\n\n[uma_shankar (2024-07-18T10:42:11.952Z)]: @Ghattas_Salloum   I am using GPT34o for metadata extraction.\nI used openAI embedder (text-embedding-3-small - 1536 dimensions), with good results.\nI am thinking of using huggingface sentence transformers for embeddings, to reduce cost.\nWill opensource model work as well for my property search ?\nI do not know which model to choose either.\nimage1457×711 76 KB\n\n----------\n\n[Ghattas_Salloum (2024-07-18T19:09:34.364Z)]: Well unfortunately i haven’t tested that much with open source so can’t advise on that one\ni am sorry.\n\n----------\n\n[Gene_Mc (2024-07-19T17:04:02.535Z)]: For what it’s worth I am getting acceptable results with multi-qa-MiniLM-L6-cos-v1.\nMy use case is primarily technical documentation embedding.\nIf you are using Docker, Weaviate has a pre-built image for this one. As well as others: GitHub - weaviate/t2v-transformers-models: This is the repo for the container that holds the models for the text2vec-transformers module",
    "date_created": "2024-07-07T10:38:27.782Z",
    "has_accepted_answer": true,
    "title": "Semantic search is not as good as I expected",
    "topic_id": 2963
  },
  {
    "user_id": 888,
    "conversation": "[Benjamin_Lush (2024-05-27T18:15:16.737Z)]: Description\nUsing Weaviate running from docker-compose\nImage: cr.weaviate.io/semitechnologies/weaviate:1.25.1\nReranker: cr.weaviate.io/semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2\nServer Setup Information\n\nWeaviate Server Version: 1.25.1\nDeployment Method docker-compose\nMulti Node? No\nClient Language and Version: Python 3.12.3\n\nAny additional Information\nWhen running\ncollection = clientv4.collections.get(collection_name)\nhybrid_documentsv4 = collection.query.hybrid(\n    query=user_input,\n    limit=4,\n    query_properties=[\"text\", \"key\"],\n    rerank=Rerank(prop=\"text\", query=user_input),\n    return_metadata=MetadataQuery(score=True)\n)\n\nresponses take 50000+ ms\nWhen I disable reranking:\ncollection = clientv4.collections.get(collection_name)\nhybrid_documentsv4 = collection.query.hybrid(\n    query=user_input,\n    limit=4,\n    query_properties=[\"text\", \"key\"],\n    return_metadata=MetadataQuery(score=True)\n)\n\nresponses take 500 ms (100x faster)\nMy reranker-transformers docker container uses a max of about 109% of 1 of 10 CPU core and 1.6GB RAM when executing for the 50 seconds. Even if I run parallel python threads there is no improvement in speed of reranking. And I cannot get the CPU and RAM usage to take more from my host.\nI have confirmed my Docker machine can access up to 10 cores and 14 GB of RAM and there is no resoruce contention while doing the hybrid-search. This is purely and issue with the container or how weaviate client does the reranking it seems. I am unsure of how to improve my performance. 50 seconds is dreadfully slow!\n\n----------\n\n[DudaNogueira (2024-05-31T18:14:37.569Z)]: Hi!\nI believe that for improving performance you will need a CUDA enabled hardware and make sure it will run with it.\nLet me know if that helps.\nThanks!\n\n----------\n\n[Nicholas_Miller (2024-07-11T22:31:59.903Z)]: I had a similar issue.  Same docker container.  In my case, the memory usage of the container climbed a bit with each rerank call.  Eventually the host machine needed to use swap, which reduced performance.  Then the host machine crashed.  Took some time to diagnose as I couldn’t even ssh to the machine when out of memory!\nSo there must be a memory leak in the reranker container somewhere.  I note from the source on Github that the CrossEncoder class uses the threadpool.  There are some bugs filed with sentence-transformers to do with memory leaks and the threadpool.\n\n----------\n\n[DudaNogueira (2024-07-15T16:45:32.645Z)]: hi @Nicholas_Miller !!\nWelcome to our community!!\nDo you mean this code, right?\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nIssues · weaviate/reranker-transformers\n\n  Contribute to weaviate/reranker-transformers development by creating an account on GitHub.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nSo in your findings, this could be something from upstream?\nCould you open a issue so we can keep track of that? Also, mentioning this thread.\nThanks for helping us on that!",
    "date_created": "2024-05-27T18:15:16.686Z",
    "has_accepted_answer": false,
    "title": "Using a local reranker-transformers reduces performance by 100x",
    "topic_id": 2502
  },
  {
    "user_id": 1564,
    "conversation": "[Dimitris_Krasakis (2024-09-20T13:20:13.494Z)]: Description\n\nI am trying to use verba for a RAG demo connecting verba with a weaviate sandbox.\nThough i have sucessfuly uploaded my data on weaviate (sandbox) and the collection is visible in the admin panel(verba) i cannot interact with any record of the collection.\nI can normally upload documents and use them in the chat section, but it seems like I cannot interact with the collections on the sandbox.\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: pip\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: python v4\nMultitenancy:No\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-09-23T08:19:13.902Z)]: hi @Dimitris_Krasakis !\nWelcome to our community \nYou have uploaded your content using Verba, and now want to inspect it directly in Weaviate Cloud Console?\nOr was it the other way around? You have uploaded your content thru a client and now want to see it in Verba?\nVerba have it’s own way of uploading, querying and generating data.\nFor example, Verba will query the data, and send it to the LLM to generate the answer outside of Weaviate, meaning, it doesn’t use the generative phase. It was designed that way so you can easily change the generative option and to also use the stream capabilities (the content appear while it is generated, instead of only after generated).\nLet me know if this helps or how else I can help you further.\nThanks!\nLet me know if this help\n\n----------\n\n[Dimitris_Krasakis (2024-09-23T08:25:01.120Z)]: Hi @DudaNogueira ,\nThank you for your response,\nIn my case i have first created the sand box and uploaded data in a Waeviate collection.\nSo it is the second scenario (uploaded through a client and want to see it in Verba)\nFrom your response I can assume that already created weaviate collections are not visible/intractable through verba and i can only querry/interact with the ones that I have uploaded through the upload document option in verba. Is this the case?\nThank you in advance.\n\n----------\n\n[DudaNogueira (2024-09-23T08:54:32.214Z)]: That’s right.\nIf you upload your content to Weaviate, and connect a Verba instance to that same cluster, you will not be able to see those contents in Verba, as Verba has its own way of storing data.\nSo indeed, you need to connect your Verba to a Weaviate cluster, and upload your content from Verba.\nHope that helps!\n\n----------\n\n[Dimitris_Krasakis (2024-09-23T08:58:07.654Z)]: @DudaNogueira , thank you ,\nYour response was really helpfull.",
    "date_created": "2024-09-20T13:20:13.442Z",
    "has_accepted_answer": true,
    "title": "Weaviate collections not visible to verba",
    "topic_id": 4221
  },
  {
    "user_id": 216,
    "conversation": "[msj242 (2024-10-14T14:55:23.127Z)]: I’d like to query multiple Ids but in one call to the server - I am using the client on nodejs.\nwould\nbuilder.withWhere({\n                    path: [\"id\"],\n                    operator: \"ContainsAny\",\n                    valueString: [...ids...]\n                });\n\nAssuming there are 10 ids will this definitely find all 10 if they exist? Or are there efficiency limits so that it won’t search the whole database to get all 10? (I know these limits can happen with text/vector searches etc…).\nIe: should I do 10 separate find by id searches to definitely find the objects - or can I safely use the above?\n\n----------\n\n[DudaNogueira (2024-10-14T15:29:35.613Z)]: hi @msj242 !!\nI believe this is the best way to filter.\nHere is a full python v4 example:\nfrom weaviate.util import generate_uuid5\nclient.collections.delete(\"Test\")\n\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n    properties=[\n        wvc.config.Property(\n            name=\"text\",\n            data_type=wvc.config.DataType.TEXT,\n            vectorize_property_name=True,\n            tokenization=wvc.config.Tokenization.WORD\n        ),\n    ]\n)\n\nfor i in range(10):\n    collection.data.insert({\"text\": f\"content {i}\"}, uuid=generate_uuid5(i))\n\nquery = collection.query.fetch_objects(\n    filters=wvc.query.Filter.by_property(\"_id\").contains_any([generate_uuid5(1), generate_uuid5(3)])\n)\n\nfor object in query.objects:\n    print(object.properties)\n\n----------\n\n[msj242 (2024-10-14T16:32:23.965Z)]: @DudaNogueira Just curious though if “contains_any” will search the database for all the ids - or if there is a limit to the search. I understood text/vector searches have some limit to preserve resources.\nThanks!\n\n----------\n\n[parkerduckworth (2024-10-15T20:01:39.869Z)]: Hey @msj242, under the hood, contains_any just builds a filter which is passed into the same search function as any other search. So the global max limit, QUERY_MAXIMUM_RESULTS, will be applied in the same manner",
    "date_created": "2024-10-14T14:55:23.084Z",
    "has_accepted_answer": true,
    "title": "How to get multiple objects by id in one call?",
    "topic_id": 5278
  },
  {
    "user_id": 848,
    "conversation": "[sanjeev1678 (2024-09-06T08:44:14.340Z)]: Hello Team,\nWe are encountering a strange issue after recently upgrading our Weaviate version to 1.25. We are using the Python client (v3) for schema creation and data insertion. After inserting new data into the upgraded version, we are getting unexpected results during filter searches.\nSpecifically, one of our property names is “year.” When we attempt to filter based on this property, the search returns no documents, even though the records are present in the database. Interestingly, when we search using the UUID, the records are correctly found. Here is the filter we are using:\nwhere_filter = {\n“path”: [“year”],\n“operator”: “Equal”,\n“valueString”: year\n}\nquery_result = (\nclient.query.get(index, properties).with_where(where_filter).with_limit(2).do())\nCould you please advise on how to resolve this issue? — Let me know if you need further adjustments!\n\nWeaviate Server Version:\nDeployment Method: Kubernetes\nNumber of Running Nodes: One node\nWeaviate Version: 1.25.0\n\n----------\n\n[DudaNogueira (2024-09-06T20:34:20.106Z)]: hi @sanjeev1678 !!\nThat’s strange.\nCan you reproduce this issue with the python v4 client?\nAlso, what is the exact version you are running?\nThanks!\n\n----------\n\n[sanjeev1678 (2024-10-01T08:33:56.627Z)]: Hello @DudaNogueira\nThanks for your response.\nI am currently running the Python Weaviate client version 3.18.0.\nI noticed an issue when trying to use an older backup file (version 1.18.0) with the new version of Weaviate (version 1.25.0). While the migration works, some column filtering no longer functions properly.\nThe data is still present in the object, but when I try to apply a filter, it returns an empty result. Is there any way to resolve this issue?\n\n----------\n\n[DudaNogueira (2024-10-01T08:43:50.412Z)]: You shouldn’t do that.\nIf you backup on 1.18, you restore to 1.18, and not to 1.25 or any other different version.\nThis is because there are some migrations.\nAlso, you should not skip versions.\nSo in your case, you restore from 1.18 to 1.18, then upgrade to 1.19.latest, 1.20.latest, and so one.\nRegarding the backup, the client will have no influence here, as the backup is a simple rest call to the server.\nLet me know if this helps.",
    "date_created": "2024-09-06T08:44:14.273Z",
    "has_accepted_answer": false,
    "title": "New weaviate version filtering issue",
    "topic_id": 3989
  },
  {
    "user_id": 1302,
    "conversation": "[wvuser (2024-09-18T21:14:21.394Z)]: Description\nWhen trying to remove/restart any pod, whole cluster hangups - requests “fall off” by timeout (60sec).\nAPI’s “/v1/nodes?output=verbose” requests freeze too.\nPods forcelly terminated by k8s after 10min waiting (terminationGracePeriodSeconds: 600).\nThere were no such errors in versions 1.23/24/25.\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: yes, 3\nClient Language and Version: Python3, WeaviateClient3.26\nMultitenancy?: no\n\nAny additional Information\nLogs (internal ips also masked):\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-1 10.xxx.aaa.bbb:7000\",“time”:“2024-09-17T09:20:07Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.aaa.bbb:44766\",“time”:“2024-09-17T09:20:17Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-2 10.xxx.ccc.ddd:7000\",“time”:“2024-09-17T09:20:37Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.aaa.bbb:60348\",“time”:“2024-09-17T09:20:47Z”}\n{“action”:“restapi_management”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“docker_image_tag”:“1.26.4”,“level”:“info”,“msg”:\"Shutting down… \",“time”:“2024-09-17T09:20:49Z”}\n{“action”:“restapi_management”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“docker_image_tag”:“1.26.4”,“level”:“info”,“msg”:“Stopped serving weaviate at http://[::]:8080”,“time”:“2024-09-17T09:20:49Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“info”,“msg”:“closing raft FSM store …”,“time”:“2024-09-17T09:20:49Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“info”,“msg”:“shutting down raft sub-system …”,“time”:“2024-09-17T09:20:49Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“info”,“msg”:“closing raft-net …”,“time”:“2024-09-17T09:20:49Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“info”,“msg”:“closing log store …”,“time”:“2024-09-17T09:20:49Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“info”,“msg”:“closing data store …”,“time”:“2024-09-17T09:20:49Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“info”,“msg”:“closing loaded database …”,“time”:“2024-09-17T09:20:49Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“component”:“index_queue”,“level”:“debug”,“msg”:“index queue closed”,“shard_id”:“myclass_nwkAu2cZVXzg”,“time”:“2024-09-17T09:20:49Z”}\n{“action”:“hnsw_delete_vector_cache”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:“deleting full vector cache”,“time”:“2024-09-17T09:20:49Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“component”:“index_queue”,“level”:“debug”,“msg”:“index queue closed”,“shard_id”:“myclass_uhCGgHQxXawb”,“time”:“2024-09-17T09:20:49Z”}\n{“action”:“hnsw_delete_vector_cache”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:“deleting full vector cache”,“time”:“2024-09-17T09:20:49Z”}\n{“action”:“raft-net”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“error”:“transport shutdown”,“level”:“error”,“msg”:“raft-net failed to decode incoming command”,“time”:“2024-09-17T09:20:49Z”}\n{“action”:“raft-net”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“error”:“transport shutdown”,“level”:“error”,“msg”:“raft-net failed to decode incoming command”,“time”:“2024-09-17T09:20:49Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-1 10.xxx.aaa.bbb:7000\",“time”:“2024-09-17T09:21:07Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-1 10.xxx.aaa.bbb:7000\",“time”:“2024-09-17T09:21:37Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.aaa.bbb:48332\",“time”:“2024-09-17T09:21:47Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-2 10.xxx.ccc.ddd:7000\",“time”:“2024-09-17T09:22:07Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.aaa.bbb:41448\",“time”:“2024-09-17T09:22:17Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.ccc.ddd:41304\",“time”:“2024-09-17T09:22:34Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-2 10.xxx.ccc.ddd:7000\",“time”:“2024-09-17T09:22:37Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-2 10.xxx.ccc.ddd:7000\",“time”:“2024-09-17T09:23:07Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.aaa.bbb:37156\",“time”:“2024-09-17T09:23:17Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.ccc.ddd:36930\",“time”:“2024-09-17T09:23:34Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-1 10.xxx.aaa.bbb:7000\",“time”:“2024-09-17T09:23:37Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.ccc.ddd:42362\",“time”:“2024-09-17T09:24:04Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-1 10.xxx.aaa.bbb:7000\",“time”:“2024-09-17T09:24:07Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-1 10.xxx.aaa.bbb:7000\",“time”:“2024-09-17T09:24:37Z”}\n\n----------\n\n[DudaNogueira (2024-09-18T21:56:09.158Z)]: hi @wvuser !!\nDo you know if this will also happen on a clean, fresh cluster or only with this specific one?\nAlso, this this log goes in loop for the entire terminationGracePeriodSeconds?\n\n----------\n\n[wvuser (2024-09-18T22:52:23.133Z)]: DudaNogueira:\n\nif this will also happen on a clean, fresh cluster\n\n\nCluster, schema and data-import are new (fresh). Not upgraded from previous version.\n\n\n\n DudaNogueira:\n\nthis this log goes in loop for the entire terminationGracePeriodSeconds?\n\n\nYes, after “raft-net” error records, “synch” log records are cyclic…\n\n----------\n\n[wvuser (2024-09-19T12:39:41.627Z)]: Hello, @DudaNogueira!\nSome detailed information about cluster/weaviate configuration:\n\ncluster stats\nenv vars\nnodes info\nschema info\n\nАccording to our observations and experiments… problem in ‘async replication’ processes (or other internal grpc communications?).\nWhen pods hangups on terminate, synchronization logs look like this:\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-1 10.xxx.aaa.bbb:7000\",“time”:“2024-09-17T09:21:07Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-1 10.xxx.aaa.bbb:7000\",“time”:“2024-09-17T09:21:37Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.aaa.bbb:48332\",“time”:“2024-09-17T09:21:47Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-2 10.xxx.ccc.ddd:7000\",“time”:“2024-09-17T09:22:07Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.aaa.bbb:41448\",“time”:“2024-09-17T09:22:17Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.xxx.ccc.ddd:41304\",“time”:“2024-09-17T09:22:34Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-2 10.xxx.ccc.ddd:7000\",“time”:“2024-09-17T09:22:37Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-2 10.xxx.ccc.ddd:7000\",“time”:“2024-09-17T09:23:07Z”}\nBut, if logs look like below - pods can normally/fast restarts without freezing:\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.aaa.bbb.ccc:59830\",“time”:“2024-09-19T11:09:27Z”}\n{“action”:“async_replication”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“class_name”:“MyClass”,“diff_calculation_took”:“26.801µs”,“hashbeat_iteration”:107,“hosts”:[“10.aaa.ddd.eee:7001”,“10.aaa.fff.ggg:7001”,“10.aaa.bbb.ccc:7001”],“level”:“info”,“local_objects”:0,“msg”:“hashbeat iteration successfully completed”,“object_progation_took”:“0s”,“objects_propagated”:0,“remote_objects”:0,“shard_name”:“2q4qSTnnbzwk”,“time”:“2024-09-19T11:09:34Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: weaviate-1 10.aaa.bbb.ccc:7000\",“time”:“2024-09-19T11:09:38Z”}\n{“action”:“async_replication”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“class_name”:“MyClass”,“diff_calculation_took”:“24.166µs”,“hashbeat_iteration”:107,“hosts”:[“10.aaa.fff.ggg:7001”,“10.aaa.ddd.eee:7001”,“10.aaa.bbb.ccc:7001”],“level”:“info”,“local_objects”:0,“msg”:“hashbeat iteration successfully completed”,“object_progation_took”:“0s”,“objects_propagated”:0,“remote_objects”:0,“shard_name”:“s5zw0VLZnClB”,“time”:“2024-09-19T11:09:39Z”}\n{“action”:“async_replication”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“class_name”:“MyClass”,“diff_calculation_took”:“23.906µs”,“hashbeat_iteration”:107,“hosts”:[“10.aaa.fff.ggg:7001”,“10.aaa.ddd.eee:7001”,“10.aaa.bbb.ccc:7001”],“level”:“info”,“local_objects”:0,“msg”:“hashbeat iteration successfully completed”,“object_progation_took”:“0s”,“objects_propagated”:0,“remote_objects”:0,“shard_name”:“qUdhGTwM36c5”,“time”:“2024-09-19T11:09:42Z”}\n{“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“level”:“debug”,“msg”:\" memberlist: Stream connection from=10.aaa.fff.ggg:39338\",“time”:“2024-09-19T11:09:50Z”}\n{“action”:“async_replication”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“class_name”:“MyClass”,“diff_calculation_took”:“24.117µs”,“hashbeat_iteration”:108,“hosts”:[“10.aaa.bbb.ccc:7001”,“10.aaa.ddd.eee:7001”,“10.aaa.fff.ggg:7001”],“level”:“info”,“local_objects”:0,“msg”:“hashbeat iteration successfully completed”,“object_progation_took”:“0s”,“objects_propagated”:0,“remote_objects”:0,“shard_name”:“2q4qSTnnbzwk”,“time”:“2024-09-19T11:09:54Z”}\n{“action”:“async_replication”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“class_name”:“MyClass”,“diff_calculation_took”:“22.584µs”,“hashbeat_iteration”:108,“hosts”:[“10.aaa.ddd.eee:7001”,“10.aaa.fff.ggg:7001”,“10.aaa.bbb.ccc:7001”],“level”:“info”,“local_objects”:0,“msg”:“hashbeat iteration successfully completed”,“object_progation_took”:“0s”,“objects_propagated”:0,“remote_objects”:0,“shard_name”:“s5zw0VLZnClB”,“time”:“2024-09-19T11:09:59Z”}\n{“action”:“async_replication”,“build_git_commit”:“584532a”,“build_go_version”:“go1.21.13”,“build_image_tag”:“1.26.4”,“build_wv_version”:“1.26.4”,“class_name”:“MyClass”,“diff_calculation_took”:“25.238µs”,“hashbeat_iteration”:108,“hosts”:[“10.aaa.fff.ggg:7001”,“10.aaa.bbb.ccc:7001”,“10.aaa.ddd.eee:7001”],“level”:“info”,“local_objects”:0,“msg”:“hashbeat iteration successfully completed”,“object_progation_took”:“0s”,“objects_propagated”:0,“remote_objects”:0,“shard_name”:“qUdhGTwM36c5”,“time”:“2024-09-19T11:10:02Z”}\nAlso noticed, that the “async replication” sometimes stops working… (/schema  replies that: “asyncEnabled”: true), but only re-update this param to ‘true’ again, helps activate async replication).",
    "date_created": "2024-09-18T21:14:21.334Z",
    "has_accepted_answer": false,
    "title": "Whole cluster hangups on pod termination",
    "topic_id": 4197
  },
  {
    "user_id": 1542,
    "conversation": "[sjogden (2024-09-15T05:14:26.878Z)]: Description\n\nI am trying to set up a RAG system with dockerized Weaviate and Ollama using a node JS backend, but am having trouble with the Ollama modules. When Weaviate tries to make a call to Ollama, it gives this error: WeaviateQueryError: Query call with protocol gRPC failed with message: /weaviate.v1.Weaviate/Search UNKNOWN: explorer: get class: concurrentTargetVectorSearch): explorer: get class: vectorize search vector: vectorize params: vectorize params: vectorize keywords: remote client vectorize: send POST request: Post \"http://localhost:11434/api/embeddings\": dial tcp [::1]:11434: connect: connection refused. This happens in both the vectorizer and generator, and both while loading data or searching it.\nI have set up both Weaviate and Ollama to start in the same docker-compose. In my collections configuration, I have tried several different api endpoints - http://ollama:11434, http://localhost:11434, and http://host.docker.internal:11434. I have confirmed that Ollama is accessible at localhost:11434 and that I can use the models through both http and the js ollama library.\nI’m assuming I’ve just made some mistake in the configuration here, but I’ve spent the better part of 2 days on this problem and no solution I’ve found works. Does anyone have any insights here?\nCollection configuration\n  async createCollection(collectionName, properties) {\n    const exists = this.client.collections.exists(collectionName)\n    if (!exists) {\n      await this.client.collections.create({\n        name: collectionName,\n        properties: properties,\n        vectorizers: vectorizer.text2VecOllama({\n          apiEndpoint: 'http://ollama:11434',\n          model: 'nomic-embed-text',\n        }),\n        generative: generative.ollama({\n          apiEndpoint: 'http://ollama:11434',\n          model: 'llama3.1:8b',\n        }),\n      })\n    }\n  }\n\ndocker-compose.yml (I’m pretty sure OLLAMA_URL, OLLAMA_MODEL, and OLLAMA_EMBED_MODEL are for Verba which I am not using, but I included them just in case)\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8765'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.4\n    ports:\n    - 8765:8765\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    container_name: weaviate\n    restart: on-failure:0\n    environment:\n      OLLAMA_URL: http://ollama:11434\n      OLLAMA_MODEL: llama3.1:8b\n      OLLAMA_EMBED_MODEL: nomic-embed-text:latest\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-ollama'\n      ENABLE_MODULES: 'text2vec-ollama,generative-ollama'\n      CLUSTER_HOSTNAME: 'node1'\n\n  ollama:\n    image: ollama/ollama\n    ports:\n      - 11434:11434\n    volumes:\n      - ollama_data:/root/.ollama\n      - ./entrypoint.sh:/entrypoint.sh\n    container_name: ollama\n    pull_policy: always\n    tty: true\n    restart: always\n    entrypoint: [\"/bin/bash\", \"/entrypoint.sh\"]\n\nvolumes:\n  weaviate_data:\n  ollama_data:\n\nentrypoint.sh is just a script to pull my ollama models once the container starts.\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: \nMulti Node? Number of Running Nodes: no\nClient Language and Version: JS API v3\nMultitenancy?: no\n\nAny additional Information\n\nIn case it matters, I originally had it set up with text2vec-transformers and that part worked fine, which is how I know what happens when there is data in the db. I can upload a version of the dockerfile I used for that if it would be relevant.\nI did also briefly run Verba to see if it was able to use the ollama integration, and I confirmed at least that it could see the models I had installed.  I didn’t test further than that though.\nSide note, I have also had trouble with deleting collections. When I try, it seems to partially but not fully delete it, and puts it into a weird state where I can’t recreate the collection because it think one still exists, but I can’t fully delete them either unless I clear the volume. I haven’t thoroughly tested this yet though because I’ve been focused on the Ollama problem.\n\n----------\n\n[DudaNogueira (2024-09-16T18:02:41.359Z)]: hi!\nOne way to make sure that your Weaviate can connect to Ollama is doing like this:\ndocker compose exec -ti weaviate sh -c \"wget --header=\\\"Content-Type: application/x-www-form-urlencoded\\\" --post-data=\\$'{\\\\n  \\\"model\\\": \\\"llama3.1:8b\\\",\\\\n  \\\"prompt\\\": \\\"Why is the sky blue?\\\"\\\\n}' --output-document - http://ollama:11434/api/generate\"\n\nThis command will run a ollama test query, using wget from within Weaviate container.\nI believe there is some docker connectivity issue going on \nI was able to spin up a working container. starting with your docker-compose, I have removed the entrypoint part, and called:\ndocker compose exec -ti ollama ollama pull llama3.1:8b\ndocker compose exec -ti ollama ollama pull nomic-embed-text\n\nI have run a quick python code that worked:\nfrom weaviate import classes as wvc\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n        api_endpoint=\"http://ollama:11434\",\n        model=\"nomic-embed-text\"\n    ),\n    generative_config=wvc.config.Configure.Generative.ollama(\n        api_endpoint=\"http://ollama:11434\",\n        model=\"llama3.1:8b\"\n    )\n)\ncollection.data.insert({\"text\": \"Something about dogs\"})\n\nobject = collection.query.fetch_objects(include_vector=True).objects[0]\ngenerate = collection.generate.fetch_objects(limit=1, single_prompt=\"Translate to Spanish: {text}\")\nprint(object.properties)\nprint(object.vector)\nprint(generate.objects[0].generated)\n\n\nLet me know what is the output of the docker compose exec command so we can start from there.\nThanks!\n\n----------\n\n[sjogden (2024-09-17T20:58:20.311Z)]: Thanks for your reply @DudaNogueira!\nI was able to successfully run both the command and the python script. I also converted the script to js and ran it successfully*, so it seems that the issue is with how I’ve implemented it. I’ll just have to hunt that down. I’ll update here if I figure out exactly what was causing it.\n* In js, everything worked except client.collections.delete(\"Test\"), which does not fully delete the collection and prevents me from re-creating it, since it appears to still be there.  The python version works fine, so it’s probably something in the js client. I’ll make a separate post about that though, since it seems to be unrelated.\nThanks for your help!\n*Edit: Never mind, I’m just dumb and forgot an await while deleting. It seems to be working totally fine now\n\n----------\n\n[DudaNogueira (2024-09-17T21:36:16.697Z)]: Glad to hear that @sjogden !\nand that now you are no longer blocked!!\nHappy coding!\nAnd remember: we are here to help whenever needed",
    "date_created": "2024-09-15T05:14:26.827Z",
    "has_accepted_answer": true,
    "title": "Ollama dial tcp [::1]:11434: connect: connection refused",
    "topic_id": 4162
  },
  {
    "user_id": 2474,
    "conversation": "[afstkla (2024-11-07T07:52:01.890Z)]: Description\nWe have a setup where we have multiple Documents, that are chunked into Chunks. For some of these documents, we have an automated service that updates the Document daily. To correctly update the documents we:\n\nGet all UUIDs of Chunks belonging to that specific Document\nUse generate a deterministic uuid5 to calculate the uuids for all new chunks\nFigure out which chunks to delete and which chunks to add\nAdd only the new chunks\nDelete the chunks that are no longer relevant\n\nThis allows us to:\n\nhave a fallback if any of the steps fail\nnot reupload unnecessary Chunks\nsave some cost & bandwidth\n\nHowever, step 1 is giving us some challenges, as to achieve that, we need to query all existing chunks. The ‘normal’ Get with offset doesn’t work above QUERY_MAXIMUM_RESULTS so the only other option we’ve seen so far has been to use the Cursor API, which requires us to dump our entire Weaviate instance, which can’t be the suggested way to achieve this.\nSo, I’m wondering how we’re supposed to solve this problem, we can’t find anything in the documentation so far, and we’re slightly scared of the implications of increasing the QUERY_MAXIMUM_RESULTS.\nServer Setup Information\n\nWeaviate Server Version: 1.24.6\nDeployment Method: Docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python v3\nMultitenancy?:  Nope\n\nAny additional Information\nNot really\n\n----------\n\n[Dirk (2024-11-07T09:05:19.741Z)]: Hello!\nYou could:\n\nhave a second class documents which references all chunks that belong to a given document\nadd another property document to your Chunk-class, which (for example) contains the ID of the document the chunk belongs to (make sure that you don’t include that field in your vectorization). When you want to get the chunks belonging to a document simply use a GET+ filter for that ID\n\n----------\n\n[afstkla (2024-11-08T07:39:00.745Z)]: Hi @Dirk , thanks, but either I don’t understand your proposed solution completely, or it will unfortunately not solve our issue.\nWe currently already have the following 2 schema’s:\n\nWeaviateDocument, which has information about the document\nWeaviateChunk, which has the chunk’s text, and it also has an inDocument cross-reference to a WeaviateDocument.\n\nWhen we want to update, we follow the steps outlined in my initial message.\n(Step 1 already contains a filter like here).\nHowever, if we start loading the existing chunks batch by batch, as soon as limit + offset > QUERY_MAXIMUM_RESULTS, we will get an error instead of getting more results. That’s where we actually run into the issues. And I don’t completely understand how your proposal would help us circumvent these issues. Could you please elaborate?\n\n----------\n\n[Dirk (2024-11-08T14:42:48.053Z)]: ahh I assumed that you were iterating through all of your Chunks and that that class was approaching QUERY_MAXIMUM_RESULTS.\nSo just to be sure: you have documents that have more chunks than QUERY_MAXIMUM_RESULTS?\n\n----------\n\n[afstkla (2024-11-08T17:07:09.310Z)]: Yes, we have quite a few documents that have (significantly) more chunks than QUERY_MAXIMUM_RESULTS\n\n----------\n\n[Dirk (2024-11-08T19:17:28.288Z)]: ok, I see!\nWhat I would try, but am not 100% sure if that works and how it scales:\n\nadd a reference from documents => chunks\nrequest a document including the reference to get all chunk IDs belonging to that document (for python v3 you’d need to parse the uri that is returned)\nnow you can query the chunks one by one and update/delete/add new ons\nafterwards you need to update the references (eg delete ones you don’t need anymore)\n\nOther possibility would be to increase QUERY_MAXIMUM_RESULTS. It is there to limit the memory usage of weaviate. Eg if you do a get query with offset=QUERY_MAXIMUM_RESULTS-100 and limit=100 it loades QUERY_MAXIMUM_RESULTS results into memory to then get the last 100 objects (unless you use the cursor API, which does not work for filters). Depending on how beefy your server is it might be ok to increase the value. I would do an expensive test query, see how much the memory spikes and then see if you can increase the value\n@DudaNogueira do you have another idea?\n\n----------\n\n[afstkla (2024-11-12T06:42:11.609Z)]: Hi @Dirk,\nThanks for the proposal. It seems like something that could work indeed, but I would highly prefer if we could find a solution that doesn’t involve maintaining a link from Chunk —> Document and a link from Document —> Chunk, as that seems like the source of a lot of unexpected behaviours.\nHave you since thought about other potential solutions? Or would there be anyone else we could ask?\n\n----------\n\n[DudaNogueira (2024-11-12T14:42:15.974Z)]: Hi @afstkla !\nIf you have a fixed id for each chunk you could also use deterministic ids, and use batch.\nNow when batch finds an existing UUID, it will update it, and when not found, it will insert it.\nDo you believe this could help somehow?\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCreate objects | Weaviate\n\n  The examples on this page demonstrate how to create individual objects in Weaviate.\n\n----------\n\n[afstkla (2024-11-12T14:56:33.511Z)]: Hi @DudaNogueira, thanks for the suggestion.\nYes, we already do that, but the challenge is removing old chunks.\nEvery time we update, some chunks will be out of date, and we have no way of finding these. So if we go your route, then unfortunately we will keep those outdated chunks (which will contain wrong information).\nSo I don’t think we can so that unfortunately.\nOr am I missing something?\n\n----------\n\n[DudaNogueira (2024-11-12T19:22:40.719Z)]: Hum. I see.\nYeah, not sure this can be done differently from the suggested options\n\n----------\n\n[afstkla (2024-11-12T20:04:10.953Z)]: Sad, feels like a use-case other users might run into… If only the cursor API would allow for filtering everything would be golden.\nFor now (and for other people reading this thread), we’ll probably go for:\n\nGrab the updated document & chunk it as normal & calculate deterministic UUIDs\nCreate a completely new Weaviate Document\nBatch by batch, 1) get chunks from the old Document, 2) upload all chunks with UUIDs that haven’t changed to the new Document, 3) remove the batch from the old Document\nUpload the remaining (aka new) Chunks to the new Document\nRemove the old Document\n\nThat’s so far the best solution with the least impact on continuity we’ve been able to come up with (though it does require us to revamp a lot of the stuff that we’ve built, which is quite unfortunate).\nDo you know if anything to solve issues like this is planned for any upcoming releases?",
    "date_created": "2024-11-07T07:52:01.817Z",
    "has_accepted_answer": false,
    "title": "Update existing chunks in a document with more than QUERY_MAXIMUM_RESULTS entries",
    "topic_id": 7477
  },
  {
    "user_id": 1203,
    "conversation": "[aleks (2024-07-16T06:54:07.720Z)]: Environment:\n\nweaviate 1.25.1\nweaviate client 4.6.4\nfastapi 0.111.0\n\nwhen using import batching like so:\nasync def batch_save(facts: Sequence[CreateWithVector],\nweaviate_class_name: str,\nweaviate_session: WeaviateClient):\ncollection = weaviate_session.collections.get(weaviate_class_name)\nwith collection.batch.dynamic() as batch:\n    for fact in facts:\n        fact_id = uuid.uuid4()\n        batch.add_object(\n            properties={\n                \"fact\": fact.content,\n            },\n            vector=fact.vector,\n            uuid=fact_id,\n        )\n        weaviate_uuid_list.append(str(fact_id))\n\nthere is an exception → batch thread died unexpectedly.\nAny help is appreciated! thanks!\n\n----------\n\n[Mohamed_Shahin (2024-07-16T09:46:05.849Z)]: Hi @aleks,\nWelcome to our community! it’s great to have you here \nHave you considered to capture more information about this error by implementing error handling and logging during the batch process?\nIn Weaviate Pythin Client, the following exception handling can help raises various error conditions:\n\nweaviate.exceptions.WeaviateConnectionError for failed connections.\nweaviate.exceptions.WeaviateQueryError for failed queries.\nweaviate.exceptions.WeaviateBatchError for failed batch operations.\nweaviate.exceptions.WeaviateClosedClientError for operations on a closed client.\n\nAs an example, to help catch more of what happens during batch import:\n\ntry:\ncollection = client.collections.get(“NonExistentCollection”)\ncollection.query.fetch_objects(limit=2)\nexcept weaviate.exceptions.WeaviateBaseError as e:\nprint(f\"Caught a Weaviate error: {e.message}\")\n\nYou can review this module which defines the exceptions that can be raised by the client library.\nAdditionally, I would recommend upgrading your Weaviate to the latest v1.25.7 as well. There are improvements since v1.25.1.\nException handling → \n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nError Handling → \n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate - Vector Database\n\n  Overview\n\n----------\n\n[Dirk (2024-07-16T12:45:41.670Z)]: aleks:\n\nasync def batch_save(facts: Sequence[CreateWithVector],\n\n\nbatching does not support being called within async functions. That is probably why it fails\n\n----------\n\n[aleks (2024-07-16T19:00:55.871Z)]: Thanks @Mohamed_Shahin  for your help and suggestion, but unluckily the exception thrown is Exception and not the one that you indicated.\nAs mentioned by @Dirk , batching is not supported in a asynchronous multithreaded environment.\nAre there any plans to support it? Is there any workaround?\nAny hint would be appreciated.\nThanks so much in advanced.\n\n----------\n\n[Dirk (2024-07-17T07:35:57.109Z)]: aleks:\n\nAre there any plans to support it? Is there any workaround?\n\n\nBatching is using async behind the scenes already. Adding objects is non-blocking and it automatically sends multiple concurrent requests. We do not think it makes sense to call this async\nIf you want to do async batching yourself you can use data.insert_many(). The latest developement version (4.7.0-rc-2) also contains an async client taht you could try out.\n\n----------\n\n[aleks (2024-07-17T08:50:17.521Z)]: @Dirk thanks for your reply and details.\nOne aspect that I do not have clear is. You said that batching is not supported being called by async, but in the previous post you commented that batching is using async already behind the scenes. I am confused because I thought batching is not supported in async environments.\nMaybe I am missing something \nThanks for your support and kind regards.\n\n----------\n\n[Dirk (2024-07-17T09:31:39.109Z)]: aleks:\n\nOne aspect that I do not have clear is. You said that batching is not supported being called by async, but in the previous post you commented that batching is using async already behind the scenes. I am confused because I thought batching is not supported in async environments.\n\n\nOur implementation of batch is using async-code to send batches.\nSo basically if you call batch.add_object() you add objects to a queue and then there are background threads that observer that queue and send batches. The internal send_batch function is async to allow for multiple concurrent requests without threading\n\n----------\n\n[aleks (2024-07-17T09:41:02.102Z)]: Ok, thanks for the details @Dirk . But then, why does batching not working using async methods using fastapi as web framework?\nThanks again for your support, patience and time. Really appreciated.\nKind regards\n\n----------\n\n[Dirk (2024-07-17T09:59:09.726Z)]: But then, why does batching not working using async methods using fastapi as web framework?\n\nI think (but not 100% sure) because we also create event loops inside of the batching\n\nusing fastapi as web framework\n\nI am not an fastapi expert, but our batching algorithm is mainly aimed for long running tasks eg 1000 objects+ and is not threadsafe.\nI would recommend to either:\n\nuse data.insert/insert_many() and build your own async wrapper around them\ninstall weaviate-client==4.7.0-rc.2 and test our new async client (please not directly in production  ) you can then do:\n\nasync with weaviate.use_async_with_local() as async_client\n    collection = async_client.collections.get(name)\n    await collection.data.insert()/insert_many(....)\n\n\ngive us feedback if anything does not work as expected\n\n----------\n\n[aleks (2024-07-19T07:03:44.730Z)]: Hi @Dirk ,\nto my surprise batching is working as expected using fastapi and async methods. The problem was that I was running pycharm in debug mode and in this mode batching, async and event loops are not good friends \nThanks for your support.\nKeep you posted in anything comes up.\nKind regards,\n\n----------\n\n[Dirk (2024-07-22T07:09:53.467Z)]: to my surprise batching is working as expected using fastapi and async methods. The problem was that I was running pycharm in debug mode and in this mode batching, async and event loops are not good friends \n\nI would be careful here - I think often it comes down to timing and the debug mode might just have the “wrong” timing. Meaning anything that changes the timing (different query, weird user input) could bring the error back.\n@tsmith023 - you are more experienced with async, what do you think?\n\n----------\n\n[aleks (2024-07-22T07:26:30.802Z)]: Yes, of course @Dirk , we will be watching if it works as expected. Anyway, I think there is a plan to release a Weaviate async client. Do you know when it would be the release?\nAnd lets see what is the opinion of @tsmith023 \nThanks a lot for your help?",
    "date_created": "2024-07-16T06:54:07.656Z",
    "has_accepted_answer": false,
    "title": "Batch thread died unexpectedly",
    "topic_id": 3056
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-08-20T04:40:47.560Z)]: I couldn’t find much information on how to set up syncing between the two so that the data gets replicated with cloud. Trying to create a local-first but cloud sync also solution\n\n----------\n\n[Mohamed_Shahin (2024-08-20T07:37:03.718Z)]: Good morning @Tejas_Sharma,\nI hope you having a lovely week!\nI understand that you are trying to replicate data to Weaviate Cloud Cluster from a Local Cluster, Am I correct?\nYou can use a migration script in our documentation where you can move collection (s) from local instance to could instance.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate - Vector Database\n\n  Overview\n\n----------\n\n[Tejas_Sharma (2024-08-20T14:32:08.381Z)]: Hi Mohamed,\nThanks for getting back.\nActually, I’m not trying to migrate but keep both since the user would want a local-first too in case their internet is not available. I was wondering if there was a recommended way to keep both in sync or on each operation, I would have to modify both instances (and in case of being offline, I guess would have to store the operations for when the internet connects)\n\n----------\n\n[Mohamed_Shahin (2024-08-21T09:08:58.043Z)]: Hi @Tejas_Sharma,\nWhat you’re trying to achieve sounds like a fantastic idea and a valuable feature to implement. Currently, there isn’t a straightforward way to establish such synchronous behavior between two instances. However, I believe this could be a very beneficial feature.\nI suggest opening a feature request here\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nBuild software better, together\n\n  GitHub is where people build software. More than 100 million people use GitHub to discover, fork, and contribute to over 420 million projects.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nWhen a feature gets enough votes from our users, it draws attention from our engineers, and we can add it to the roadmap.\nI mentioned migration as a method to replicate data from a source to a destination, ensuring you have a replicated instance. However, I agree with you that for now, tracking and storing operations locally and then queuing and batching them once online to match the instances might be the best approach.\n\n----------\n\n[Tejas_Sharma (2024-08-23T05:31:32.678Z)]: Thanks Mohamed, submitting it there",
    "date_created": "2024-08-20T04:40:47.503Z",
    "has_accepted_answer": false,
    "title": "[Question] Syncing embedded Weaviate with Cloud?",
    "topic_id": 3405
  },
  {
    "user_id": 655,
    "conversation": "[alisha_liu (2024-12-12T02:01:39.778Z)]: I am using weawiate typescript version3, I have below code :\nconst fileNameArrayFromPostgres = [ 'The-Unhoneymooners-PDF-Book-pages-3.pdf', 'The-Unhoneymooners-PDF-Book-pages-4.pdf' ] \nconst startUrlArrayFromPostgres = [ '[https://www.example.com](https://www.example.com/)', '[https://www.cibc.ca](https://www.cibc.ca/)' ]\n\ndeleteResult = await myCollection.data.deleteMany(combinedFilter, { dryRun: true, });\n\nI want to you help me write a logic of \"combinedFilter \"to delete items meet below requirements:\nthere are property named “file_name” and “start_url” inside weaviate collection.\ni want to delete items that’s “file_name” not inside fileNameArrayFromPostgres, and “start_url” not inside startUrlArrayFromPostgres\n\n----------\n\n[sebawita (2024-12-12T11:16:17.315Z)]: Hi @alisha_liu,\nThere is no filter for doesn't contain or a not operator in Weaviate.\nThere is a GH issue with a similar request if you would like to add you comment or vote in there.\nHere is an example of how you could delete objects where the values match. But that is the opposite of what you asked for \nimport weaviate, { Filters } from 'weaviate-client';\n\nmyCollection = client.collection.get(\"MyCollection\")\n\nawait myCollection.data.deleteMany(\n  Filters.and(\n    myCollection.filter.byProperty('file_name').containsAny(fileNameArrayFromPostgres),\n    myCollection.filter.byProperty('start_url').containsAny(startUrlArrayFromPostgres)\n  ),\n  { dryRun: true, }\n)\n\n----------\n\n[alisha_liu (2024-12-12T13:49:18.148Z)]: Thanks for your quick response, is their an alternative way to achieve my goal?\n\n----------\n\n[sebawita (2024-12-13T10:59:33.961Z)]: Yes, you could construct array of notEqual filters, like this:\nimport weaviate, { Filters } from 'weaviate-client';\n\nconst myCollection = client.collection.get(\"MyCollection\")\n\nconst fileNameFilters = fileNameArrayFromPostgres.map(\n  val => animals.filter.byProperty(\"file_name\").notEqual(val)\n)\nconst startUrlFilters = startUrlArrayFromPostgres.map(\n  val => animals.filter.byProperty(\"start_url\").notEqual(val)\n)\n\nThen, you could use a spread operator with Filters.and to construct your filter, and test it with a fetch query, like this:\nconst searchResults = await myCollection.query.fetchObjects({\n    filters: Filters.and(...kindFilters, ...nameFilters)\n})\n\nfor (const item of searchResults.objects) {\n    console.log(\"\\n Search Results \\n\");\n    console.log(JSON.stringify(item.properties, null, 2))        \n}\n\nAnd if you are happy with that, you can call delete with the same filter:\nawait myCollection.data.deleteMany(\n  Filters.and(...fileNameFilters, ...startUrlFilters),\n  { dryRun: true, }\n)\n\nSide note – tokenization for filter matching\nThis might be a topic for later, but if your filters don’t give the results you expect. It might be due to how Weaviate builds keyword indexes.\nWhere the equal and notEqual filters are keyword-based.\nYou may need to set the tokenization on your queried properties to something more strict like field tokenization.\nYou can learn more about different types of tokenization in the docs.\nAnd here is how you can set tokenization type on a property in your collection.",
    "date_created": "2024-12-12T02:01:39.730Z",
    "has_accepted_answer": true,
    "title": "Custom filter with weaviate typescrit v3",
    "topic_id": 9198
  },
  {
    "user_id": 1096,
    "conversation": "[Lakshman_Krishnamurt (2024-11-24T01:02:26.620Z)]: Description\n\n2024-11-23 16:46:12,656 - INFO - HTTP Request: GET https://xxxx.c0.us-west3.gcp.weaviate.cloud/v1/meta “HTTP/1.1 503 Service Unavailable”\nwhen I login to service - and look for the serverless clusters. It does not show. Is the service down?\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-11-24T13:02:10.439Z)]: hi @Lakshman_Krishnamurt !!\nThe best place for support on all our hosted servers is following the instructions at Weaviate Cloud\nMake sure to specify the name of the cluster or the endpoint, so we can identify it.\nTHanks!",
    "date_created": "2024-11-24T01:02:26.572Z",
    "has_accepted_answer": true,
    "title": "Service unavailable",
    "topic_id": 7817
  },
  {
    "user_id": 788,
    "conversation": "[Rio (2024-11-21T08:13:11.318Z)]: Hello.\nI have 2 questions regarding the weaviate-cli (GitHub - weaviate/weaviate-cli: CLI tool for Weaviate).\nI recently installed the newly released version 3.0.1 and tried to test it.\nI created a ~/.config/weaviate/config.json file in the following format as instructed:\n{\n“host”: “your-weaviate-host”,\n“http_port”: “your-http-port”,\n“grpc_port”: “your-grpc-port”,\n“auth”: {\n“type”: “api_key”,\n“api_key”: “your-api-key”\n}\n}\nHowever, when I specify the host as ‘localhost’, the commands work normally.\n$ weaviate-cli get collection\nCollection                    Multitenancy    Tenants         Objects         ReplicationFactor   VectorIndex     Vectorizer\nMovies                        False           0               1000            3                   hnsw            none\nQuestoin 1.\nBut when I specify the host as the server’s hostname or IP, I get the following error:\nError: Could not connect to Weaviate: Connection to Weaviate failed. Details: .\n\nI have confirmed that I can access the target port normally using the hostname and IP.\nWhat could be the problem?\nQuestoin 2.\nhow do I set the IP of http_port and grpc_port in different environments?\n\n----------\n\n[Jose_Luis_Franco (2024-11-21T09:06:18.634Z)]: Hello Rio,\nI am happy to see that other users from the community are starting to use this tool.\nThe main issue is that if your host contains the string “localhost” it will decide to connect using weaviate.connect_to_local() which infers things like the http_port or grpc_port, however if you specify the IP the tool will consider you are using a WCD cluster and use the weaviate.connect_to_wcs(), so this is a limitation at the moment.\nWould you be so kind to open an issue in the repository so that we can take care of changing it?\nThanks a lot for using weaviate-cli and for providing us with the feedback!\n\n----------\n\n[Rio (2024-11-22T01:17:58.987Z)]: Hello. Jose Luis Franco,\nThank you for your response.\nI am currently using Weaviate installed on a Kubernetes cluster in an on-premises environment.\nIt seems that it’s still difficult to use the weaviate-cli in this environment, correct?\nI look forward to continued improvements in this area.\nAdditionally, it would be great if a GUI Admin Tool could be developed as well.\nThank you.",
    "date_created": "2024-11-21T08:13:11.269Z",
    "has_accepted_answer": false,
    "title": "Weaviate-cli 3.0.1 Configuration Question",
    "topic_id": 7750
  },
  {
    "user_id": 11874,
    "conversation": "[Dima_Nagorny (2025-03-30T23:55:09.855Z)]: UnexpectedStatusCodeError: Collection may not have been created properly.! Unexpected status code: 422, with response body: {‘error’: [{‘message’: ‘vectorizer: no module with name “text2vec-ollama” present’}]}.\n\n----------\n\n[DudaNogueira (2025-03-31T13:54:30.400Z)]: hi @Dima_Nagorny !!\nWelcome to our community  !\nAre you running Weaviate locally, for example, using docker, or running the quick start in our cloud?\nThis error message will surfaced because text2vec-ollama doesn’t seem installed on that server.\nHow have you deployed Weaviate?\nCheck here on information on how to activate a module in Weaviate:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nModules | Weaviate\n\n  Weaviate's functionality can be customized by using modules. This page explains how to enable and configure modules.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!",
    "date_created": "2025-03-30T23:55:09.807Z",
    "has_accepted_answer": false,
    "title": "error on quickstart",
    "topic_id": 20419
  },
  {
    "user_id": 735,
    "conversation": "[curious (2024-06-19T07:11:15.165Z)]: Description\nHow to use trust_remote_code=True in case of locally downloaded gated model from huggingface to be used with Weaviate.\nServer Setup Information\n\nWeaviate Server Version: 1.25.4\nDeployment Method: docker\nMulti Node? Number of Running Nodes: Single Node\nClient Language and Version: Python\n\nI’m using Dockerfile as below to create the container of locally downloaded huggingface model:\n$ cat Nvidia-NV-Embed.Dockerfile \nFROM semitechnologies/transformers-inference:custom\n\n# Copy the locally downloaded model to the Docker image\nCOPY local_NV-Embed-v1 /app/models/model\n\n# Set the environment variable to trust remote code\nENV TRUST_REMOTE_CODE=True\n\nand using docker-compose file as:\n$ cat docker-compose.yml \n---\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.4\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - /path/to/weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'\n      QNA_INFERENCE_API: 'http://qna-transformers:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'\n      ENABLE_MODULES: 'text2vec-transformers,qna-transformers'\n      CLUSTER_HOSTNAME: 'node'\n  t2v-transformers:\n    image: nvidia-nv-embed-inference\n    environment:\n      ENABLE_CUDA: '0'\n      TRUST_REMOTE_CODE: 'true' \n  qna-transformers:\n    image: roberta_large_squad2_inference\n    environment:\n      ENABLE_CUDA: '0'\n...\n\nI’m using TRUST_REMOTE_CODE at both places, still I’m getting this error:\n$ sudo docker compose logs -f t2v-transformers\nweaviate_docker_2-t2v-transformers-1  | INFO:     Started server process [7]\nweaviate_docker_2-t2v-transformers-1  | INFO:     Waiting for application startup.\nweaviate_docker_2-t2v-transformers-1  | INFO:     CUDA_PER_PROCESS_MEMORY_FRACTION set to 1.0\nweaviate_docker_2-t2v-transformers-1  | INFO:     Running on CPU\nweaviate_docker_2-t2v-transformers-1  | The repository for ./models/model contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/./models/model.\nweaviate_docker_2-t2v-transformers-1  | You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\nweaviate_docker_2-t2v-transformers-1  | \nweaviate_docker_2-t2v-transformers-1  | ERROR:    Traceback (most recent call last):\nweaviate_docker_2-t2v-transformers-1  |   File \"/usr/local/lib/python3.11/site-packages/transformers/dynamic_module_utils.py\", line 599, in resolve_trust_remote_code\nweaviate_docker_2-t2v-transformers-1  |     answer = input(\nweaviate_docker_2-t2v-transformers-1  |              ^^^^^^\nweaviate_docker_2-t2v-transformers-1  | EOFError: EOF when reading a line\nweaviate_docker_2-t2v-transformers-1  | \nweaviate_docker_2-t2v-transformers-1  | During handling of the above exception, another exception occurred:\nweaviate_docker_2-t2v-transformers-1  | \nweaviate_docker_2-t2v-transformers-1  | Traceback (most recent call last):\nweaviate_docker_2-t2v-transformers-1  |   File \"/usr/local/lib/python3.11/site-packages/starlette/routing.py\", line 734, in lifespan\nweaviate_docker_2-t2v-transformers-1  |     async with self.lifespan_context(app) as maybe_state:\nweaviate_docker_2-t2v-transformers-1  |   File \"/usr/local/lib/python3.11/site-packages/starlette/routing.py\", line 610, in __aenter__\nweaviate_docker_2-t2v-transformers-1  |     await self._router.startup()\nweaviate_docker_2-t2v-transformers-1  |   File \"/usr/local/lib/python3.11/site-packages/starlette/routing.py\", line 713, in startup\nweaviate_docker_2-t2v-transformers-1  |     handler()\nweaviate_docker_2-t2v-transformers-1  |   File \"/app/app.py\", line 74, in startup_event\nweaviate_docker_2-t2v-transformers-1  |     meta_config = Meta(model_dir, model_name, use_sentence_transformer_vectorizer)\nweaviate_docker_2-t2v-transformers-1  |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nweaviate_docker_2-t2v-transformers-1  |   File \"/app/meta.py\", line 11, in __init__\nweaviate_docker_2-t2v-transformers-1  |     self.config = AutoConfig.from_pretrained(model_path).to_dict()\nweaviate_docker_2-t2v-transformers-1  |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nweaviate_docker_2-t2v-transformers-1  |   File \"/usr/local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1141, in from_pretrained\nweaviate_docker_2-t2v-transformers-1  |     trust_remote_code = resolve_trust_remote_code(\nweaviate_docker_2-t2v-transformers-1  |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\nweaviate_docker_2-t2v-transformers-1  |   File \"/usr/local/lib/python3.11/site-packages/transformers/dynamic_module_utils.py\", line 612, in resolve_trust_remote_code\nweaviate_docker_2-t2v-transformers-1  |     raise ValueError(\nweaviate_docker_2-t2v-transformers-1  | ValueError: The repository for ./models/model contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/./models/model.\nweaviate_docker_2-t2v-transformers-1  | Please pass the argument `trust_remote_code=True` to allow custom code to be run.\nweaviate_docker_2-t2v-transformers-1  | \nweaviate_docker_2-t2v-transformers-1  | ERROR:    Application startup failed. Exiting.\nweaviate_docker_2-t2v-transformers-1 exited with code 3\n\nPls help me how and where should I pass this argument trust_remote_code=True in case of locally downloaded gated model from huggingface to be used with Weaviate ?\n\n----------\n\n[curious (2024-06-20T12:42:16.897Z)]: I am not able to use the locally downloaded nvidia/NV-Embed-v1 model with Weaviate because of TRUST_REMOTE_CODE error, as stated above.\nAny help in this regard to resolve this TRUST_REMOTE_CODE error, highly appreciated.\nThanks.\n\n----------\n\n[DudaNogueira (2024-06-20T18:59:46.571Z)]: hi @curious !!\nI have to ask internally as I don’t have too much of expertise on this subject \nThanks!\n\n----------\n\n[curious (2024-06-21T05:30:30.831Z)]: Hi @DudaNogueira,\nThank you for looking into this. I appreciate your efforts and help to seek internal expertise. I’ll wait for further updates.\nMeanwhile, for the convenience, here are the steps to reproduce this issue:\nStep 1: Access to model\nAs nvidia/NV-Embed-v1 is a gated model, we have to accept the conditions to access its files and content in Hugging Face - https://huggingface.co/nvidia/NV-Embed-v1\nStep 2: Download the model locally\nmkdir weaviate_docker && cd weaviate_docker\ngit lfs install\n#Note: When prompted for a password, use an access token with write permissions.\n#Generate one from your settings: https://huggingface.co/settings/tokens\ngit clone https://huggingface.co/nvidia/NV-Embed-v1\nStep 3: Create docker container\nCreate a file Nvidia-NV-Embed.Dockerfile with contents:\nFROM semitechnologies/transformers-inference:custom  \nCOPY NV-Embed-v1 /app/models/model\n\nBuild the container\nsudo docker build -f Nvidia-NV-Embed.Dockerfile -t nvidia-nv-embed-inference .\nStep 4: Create docker-compose.yml\nContent of docker-compose.yml as mentioned in the original thread\nStep 5: Start the containers\nsudo docker compose up\nStep 6:\nExpected Outcome:\nAll containers, including t2v-transformers, should be up as usual.\nWhat actually happened:\nAs can be seen in logs:\nsudo docker compose logs -f weaviate\nsudo docker compose logs -f t2v-transformers\nThe text2vec-transformers container failed to start because of TRUST_REMOTE_CODE issue.\n\n\nIf I’m using the NV-Embed-v1 model directly using below code, it is working perfectly. But I’m unable to set the trust_remote_code=True settings in case of weaviate docker deployment.\nfrom sentence_transformers import SentenceTransformer\n\n# Load the NV-Embed-v1 model using sentence-transformers with trust_remote_code\nmodel_path = \"/path/to/model/weaviate_docker/NV-Embed-v1\"\nmodel = SentenceTransformer(model_path, device='cpu', trust_remote_code=True)\n\n# Generate embeddings for stored data and queries\nstored_embeddings = model.encode(stored_data, batch_size=2, normalize_embeddings=True)\nquery_embeddings = model.encode(queries, batch_size=2, normalize_embeddings=True)\n\n----------\n\n[DudaNogueira (2024-06-21T20:33:20.083Z)]: hi @curious !!\nGood news: Add`TRUST_REMOTE_CODE` env var by cdpierse · Pull Request #85 · weaviate/t2v-transformers-models · GitHub\n\nIt is worth mentioning to be cautious with this flag \n  \n      \n\n      BleepingComputer\n  \n\n  \n    \n\nMalicious AI models on Hugging Face backdoor users’ machines\n\n  At least 100 instances of malicious AI ML models were found on the Hugging Face platform, some of which can execute code on the victim's machine, giving attackers a persistent backdoor.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\n\n----------\n\n[curious (2024-06-24T12:49:57.624Z)]: Wow!! Thanks a lot @DudaNogueira to you and your team for updating the code and committing the changes to the main.\nI downloaded the latest repo, update dockerfile, re-built the container image, up the docker… and voila… there is no issue of trust_remote_code this time.\nHowever, for some strange reason, the code is trying to access the model at huggingface instead of using local model and thus throwing this error:\n$ sudo docker compose logs -f t2v-transformers \nweaviate_docker_2-t2v-transformers-1  | INFO:     Started server process [7]\nweaviate_docker_2-t2v-transformers-1  | INFO:     Waiting for application startup.\nweaviate_docker_2-t2v-transformers-1  | INFO:     CUDA_PER_PROCESS_MEMORY_FRACTION set to 1.0\nweaviate_docker_2-t2v-transformers-1  | INFO:     Running on CPU\nweaviate_docker_2-t2v-transformers-1  | ERROR:    Traceback (most recent call last):\nweaviate_docker_2-t2v-transformers-1  |   File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\nweaviate_docker_2-t2v-transformers-1  |     response.raise_for_status()\nweaviate_docker_2-t2v-transformers-1  |   File \"/usr/local/lib/python3.11/site-packages/requests/models.py\", line 1021, in raise_for_status\nweaviate_docker_2-t2v-transformers-1  |     raise HTTPError(http_error_msg, response=self)\nweaviate_docker_2-t2v-transformers-1  | requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/nvidia/NV-Embed-v1/resolve/main/config.json\nweaviate_docker_2-t2v-transformers-1  | \n.\n.\n.\nweaviate_docker_2-t2v-transformers-1  | Cannot access gated repo for url https://huggingface.co/nvidia/NV-Embed-v1/resolve/main/config.json.\nweaviate_docker_2-t2v-transformers-1  | Access to model nvidia/NV-Embed-v1 is restricted. You must be authenticated to access it.\nweaviate_docker_2-t2v-transformers-1  | \nweaviate_docker_2-t2v-transformers-1  | ERROR:    Application startup failed. Exiting.\nweaviate_docker_2-t2v-transformers-1 exited with code 3\n\nI tried adding logger info to the app.py to see why and from where it is calling the huggingface repo, but unfortunately could not find any useful info.\nI am also using a locally downloaded huggingface model roberta_large_squad2_inference for qna module (although not a gated model), and that is getting up and running perfectly fine without any issues.\nWhat could be going wrong in case of t2v-transformer module? Any clue/help pls.\n[PS: Sure, I’ll be cautious about the flag, thanks for sharing the link.  ]\n\n----------\n\n[DudaNogueira (2024-06-24T18:05:50.324Z)]: curious:\n\nweaviate_docker_2-t2v-transformers-1  | INFO:     Running on CPU\n\n\nThis message is strange. Shouldn’t it be using GPU?\nMaybe it wasn’t able to map the GPU into docker? I saw something with update nvidia drivers, and downgrading the driver helped.\n\n----------\n\n[curious (2024-06-24T19:08:41.443Z)]: @DudaNogueira Yes, the transformer is Running on CPU as we have set the same in docker-compose file:\n\n\n\n curious:\n\nt2v-transformers:\n    image: nvidia-nv-embed-inference\n    environment:\n      ENABLE_CUDA: '0'\n      TRUST_REMOTE_CODE: 'true' \n\n\n\nReason for the same is we are in process of getting a GPU based server, until then want to try weaviate on CPU machine (it is still 64 core Xeon Gold  ). Yes, we are aware that inference speed will be slow on CPU, but we are managing the same for the time being as given vectorizer results are of better accuracy in our case.\nDo you feel that the error we are facing where the code is trying to access the model on huggingface instead of using local folder has something to do with the GPU ?\n\nweaviate_docker_2-t2v-transformers-1  | requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/nvidia/NV-Embed-v1/resolve/main/config.json\n\nAlso, as metioned earlier, we were able to run the given model (locally downloaded) directly using separate python code. We are only getting error in case of weaviate docker setup (t2v-transformer module).\n\n----------\n\n[joe-schwartz-certara (2024-10-28T19:02:37.721Z)]: I’m still getting errors for this as well trying to use the built-in weaviate methods of manipulating models. After peeking at the files, I don’t see how any of this supposed to work in the first place.\nt2v-transformers-models/download.py at main · weaviate/t2v-transformers-models (github.com)\nTake this file for example. It tries to unpack via\ntrust_remote_code = os.getenv(“TRUST_REMOTE_CODE”, False)\nbut outside of the python script, I will always be setting a shell variable which I believe will just always be evaluated as a string by getenv. Then when that gets passed to the hf function, it just ignores it if its a string and the only time it is a real, python boolean, it is always False. This is a pretty common problem of working with shells and python scripts. see:\nWe’ve all been there: on boolean environment variables. - Ru (rusingh.com)",
    "date_created": "2024-06-19T07:11:15.076Z",
    "has_accepted_answer": true,
    "title": "How to use 'trust_remote_code=True' in case of locally downloaded gated model",
    "topic_id": 2745
  },
  {
    "user_id": 643,
    "conversation": "[garcia.e (2024-07-25T11:27:21.805Z)]: Hello,\nI’m trying to implement a weaviate database with question and answers. My idea is to search if a particular question is already in the data base, and I’m using this code:\nresponse = (\n            client.query\n            .get(\"Questions\", [\"answer\",\"question\", \"technology\"])\n            .with_near_text({\n                \"concepts\": [prompt],\n                \"distance\": distance    \n            })\n            .with_where({\n                \"path\": [\"technology\"],\n                \"operator\": \"Equal\",\n                \"valueText\": str(technology)\n            })\n            .with_additional([\"id\", \"distance\"])\n            .with_limit(2)\n            .do()\n        )\n\nWhere “prompt” is the question that I want to introduce.\nI’m using the distance parameter, but I only want to compare the distance of my questions, with the questions inside, not with the answers , it can be done? If yes… how?\nThanks!\n\n----------\n\n[DudaNogueira (2024-07-25T18:45:31.448Z)]: hi @garcia.e !!\nWhenever you do a nearText without a target_vector, you are comparing prompt against all vectorizable properties.\nNot sure how your collection was created, but you have two options:\n\nIntentionally let only question property to be vectorizable, by setting all other properties to skip_vectorization=True\nwith that, you only get 1 vector, that will be the representation of only your question.\n\n\nCreate a named vector only for your question, and when doing the nearText, specify that named vector as your target, as described here.\nYou can have two named vectors. One for the entire object, and a second one for only the question property. Of course, this will double the usage of your embedding service, as for each object, it will vectorize it twice: one for all properties you point, and another one only for question.\n\nLet me know if this helps \nThanks!",
    "date_created": "2024-07-25T11:27:21.750Z",
    "has_accepted_answer": false,
    "title": "Help searching inside the objects in my weaviate",
    "topic_id": 3169
  },
  {
    "user_id": 1085,
    "conversation": "[Ines (2024-07-08T07:42:36.875Z)]: Hello everyone,\nwhen deploying Weaviate in our Azure Kubernetes Cluster, two policies currently prevent the weaviate container “configure-sysctl” from being created/started.\nPolicies:\n\nKubernetes cluster should not allow container privilege escalation\nKubernetes cluster should not allow privileged containers\n\nDoes someone know what this container is doing and if it is essential? Why does it not fulfill these privileges?\n\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate-helm/blob/3f25c84040839eb595b05a7f2733d07e20c74495/weaviate/templates/weaviateStatefulset.yaml#L49\n\n\n\n    \n      \n          terminationGracePeriodSeconds: {{ .Values.terminationGracePeriodSeconds }}\n          {{- include \"image.pullSecrets\" (dict \"pullSecrets\" $.Values.image.pullSecrets) | nindent 6 }}\n          {{- include \"pod.priorityClassName\" ( dict \"global\" $.Values.globalPriorityClassName \"priorityClassName\" .Values.priorityClassName) | nindent 6 }}\n          {{- if or (.Values.initContainers.sysctlInitContainer.enabled) (.Values.initContainers.extraInitContainers) }}\n          initContainers:\n          {{- if .Values.initContainers.sysctlInitContainer.enabled }}\n          {{- with .Values.initContainers.sysctlInitContainer }}\n          - name: configure-sysctl\n            securityContext:\n              runAsUser: 0\n              privileged: true\n            image: \"{{ .image.registry }}/{{ .image.repo }}:{{ .image.tag }}\"\n            imagePullPolicy: \"{{ .image.pullPolicy }}\"\n            command: [\"sysctl\", \"-w\", \"vm.max_map_count={{ .sysctlVmMaxMapCount }}\", \"vm.overcommit_memory=1\"]\n          {{- end }}\n          {{- end }}\n          {{- if .Values.initContainers.ensureFileOwnershipContainer.enabled }}\n          {{- if and .Values.containerSecurityContext .Values.containerSecurityContext.runAsUser .Values.containerSecurityContext.fsGroup }}\n          - name: ensure-file-ownership\n            securityContext:\n              runAsUser: 0\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n\nDeployment Method: Helm Chart\n\nThanks for your help!\n\n----------\n\n[DudaNogueira (2024-07-08T12:25:17.064Z)]: hi @Ines !! Welcome to our community \nWe have recently added support for unprivileged docker image in our helm.\nHave you tried that option?\nNot sure it can help here, but it definitely seems related \nLet me know if that helps.\nTHanks!\n\n----------\n\n[dassum (2024-07-09T13:54:28.758Z)]: Thanks @DudaNogueira for the help.\nSharing it for others what changes worked for us.\nIn values.yaml we set the below properties.\ninitContainers:\n  sysctlInitContainer:\n    enabled: false\n ensureFileOwnershipContainer:\n   enabled: true\n\ncontainerSecurityContext:\n  runAsUser: 1000\n  runAsGroup: 1000\n  fsGroup: 1000\n  fsGroupChangePolicy: \"OnRootMismatch\"\n  runAsNonRoot: true\n  allowPrivilegeEscalation: false\n  privileged: false\n  readOnlyRootFilesystem: true\n\nsecurityContext:\n  runAsUser: 1000\n  runAsGroup: 1000\n  fsGroup: 1000\n  fsGroupChangePolicy: \"OnRootMismatch\"\n  runAsNonRoot: true\n  allowPrivilegeEscalation: false\n  privileged: false\n  readOnlyRootFilesystem: true\n\nNot sure what is the impact of disabling sysctlInitContainer init containers(not setting vm.max_map_count and vm.overcommit_memory).\n\n----------\n\n[DudaNogueira (2024-07-09T14:39:03.740Z)]: Thanks for sharing!!!\nI have edited your topic to format it better and marked and a solution!\nThanks!\n\n----------\n\n[Ines (2024-07-15T06:03:00.719Z)]: Thank you @DudaNogueira and @dassum a lot for your help.\n@DudaNogueira Unfortunately. This did not help.\nBut we would like to try the option @dassum mentioned. However, before doing so, does anyone know what the “sysctlInitContainer” is used for?\n\n----------\n\n[DudaNogueira (2024-07-15T19:57:19.869Z)]: Hi @Ines !!\nCheck here the info for this option:\n\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate-helm/blob/6ad5b697eec1f8a8e612415fa1d6b8e9d4b23ef5/weaviate/values.yaml#L41\n\n\n\n    \n      \n          # below is an example that can be used to set an arbitrary nofile limit at\n          # startup:\n          #\n          # command: \n          #   - \"/bin/sh\"\n          # args: \n          #   - \"-c\"\n          #   - \"ulimit -n 65535 && /bin/weaviate --host 0.0.0.0 --port 8080 --scheme http --config-file /weaviate-config/conf.yaml\"\n          \n          \n          # it is possible to change the sysctl's 'vm.max_map_count' using initContainer for Weaviate,\n          # the init Container runs before Weaviate Container and sets the value for the WHOLE node\n          # to the one provided below.\n          # it is possible to run additional initContainer before Weaviate is up and running. You can specify the\n          # containers as a list in `extraInitContainers`, exactly how they are defined in a kubernetes manifest:\n          #   https://kubernetes.io/docs/concepts/workloads/pods/init-containers/\n          initContainers:\n            sysctlInitContainer:\n              enabled: true\n              sysctlVmMaxMapCount: 524288\n              image:\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nfor instance:\n# it is possible to change the sysctl's 'vm.max_map_count' using initContainer for Weaviate,\n# the init Container runs before Weaviate Container and sets the value for the WHOLE node\n# to the one provided below.\n# it is possible to run additional initContainer before Weaviate is up and running. You can specify the\n# containers as a list in `extraInitContainers`, exactly how they are defined in a kubernetes manifest:\n#   https://kubernetes.io/docs/concepts/workloads/pods/init-containers/\n\n----------\n\n[Ines (2024-07-22T06:08:08.756Z)]: @DudaNogueira Thank you again for your help. I checked also with my colleagues. Problem is still, that we do not know what this container is doing and therefore we don’t want to just disable it.\nAny idea how to find out what this privileged container is doing?\n\n----------\n\n[DudaNogueira (2024-07-23T12:49:05.854Z)]: hi! AFAIK, this is not a container, but this will define some configuration to the container running Weaviate.\n\n----------\n\n[Ines (2024-07-25T09:18:19.547Z)]: Hi! @DudaNogueira What configurations will be changed then by doing so?\n\n----------\n\n[DudaNogueira (2024-07-26T23:22:02.393Z)]: Hi!\nThose settings, as fair as I could understand, will run a init container to just set the proper ownerships if this deployment didn’t have the security context.\nI believe for new deployments ensureFileOwnershipContainer may not be required.\n# it is possible to change the sysctl's 'vm.max_map_count' using initContainer for Weaviate,\n# the init Container runs before Weaviate Container and sets the value for the WHOLE node\n# to the one provided below.\n# it is possible to run additional initContainer before Weaviate is up and running. You can specify the\n# containers as a list in `extraInitContainers`, exactly how they are defined in a kubernetes manifest:\n#   https://kubernetes.io/docs/concepts/workloads/pods/init-containers/\ninitContainers:\n  sysctlInitContainer:\n    enabled: true\n    sysctlVmMaxMapCount: 524288\n    image:\n      registry: docker.io\n      repo: alpine\n      tag: latest\n      pullPolicy: IfNotPresent\n  ensureFileOwnershipContainer:\n    # This init container sets the file ownerships of /var/lib/weaviate directory to the ones set in\n    # containerSecurityContext.runAsUser and containerSecurityContext.fsGroup settings to ensure that Weaviate is able\n    # to start in unprivileged configuration.\n    # Enable this init container only if Weaviate was configured previously without security context\n    # and now containerSecurityContext is provided to run Weaviate container with non-root user.\n    # Please be sure to set at least containerSecurityContext.runAsUser and containerSecurityContext.fsGroup.\n    enabled: false",
    "date_created": "2024-07-08T07:42:36.817Z",
    "has_accepted_answer": true,
    "title": "Weaviate Deployment not possible due to Azure Policies",
    "topic_id": 2971
  },
  {
    "user_id": 3439,
    "conversation": "[junaidmalikfreyr (2025-02-14T08:25:39.971Z)]: Description\nWeaviate on AWS EKS (Marketplace subscription) consuming large amount of memory (more than 128GB across the two nodes) for hybrid search query with contains_any filter.\nServer Setup Information\n\nWeaviate Server Version: 1.24\nDeployment Method: AWS EKS (Through AWS Marketplace)\nMulti Node? Number of Running Nodes: Yes, 2\nNode instance type: rdi.4xlarge\nClient Language and Version: Python v4.10.2\nCollection size: 3.2M objects\nVector dimensions: 1536 (OpenAI ada)\nMultitenancy: No\nHelm chart: v17.4.1\n\nAny additional Information\nThe query that I am running is as follows. The r_ids list contains around 30k entries which are of the format “REGXXXX”.\nimage1130×1062 87.8 KB\nPlease let me know if any additional info is required about the deployment. Thanks in advance!\n\n----------\n\n[junaidmalikfreyr (2025-02-14T08:26:28.167Z)]: Memory consumption during the queries:\nimage1482×228 51.7 KB\n\n----------\n\n[Dirk (2025-02-14T09:38:47.594Z)]: junaidmalikfreyr:\n\nWeaviate Server Version: 1.24\n\n\nThis version is quite old and we had many improvements for filters in the last releases. Could you check again with 1.28?\n\n----------\n\n[junaidmalikfreyr (2025-02-14T11:15:52.978Z)]: Hi @Dirk. Thanks for your response. Based on your suggestion, we have updated to 1.28.4. The memory usage spike seems to be worse than before:\nimage1442×218 49.1 KB\nWe are running the same query as shared in the previous message. Would you recommend a way to troubleshoot this? Is there a specific log that we can refer to get more info about this abnormal memory usage?\n\n----------\n\n[Dirk (2025-02-17T07:47:11.348Z)]: Hey, ok\nthen let’s do the following:\ninstead of a hybrid query please do:\n\na bm25 query\na near_text query\n\nwith the same settings (returns, limits, filters) and check which one has high memory usage. Then please do that query with and without filters.\nThings to try out afterwards:\n\nif the near_text query is responsible with filters please try How we speed up filtered vector search with ACORN | Weaviate\nif the bm25 query is the problem, 1.29 (should be released today) contains a major speedup/efficiency improvement. Not involved with the details, but documentation should be available in the next days\n\nHaving said that, 30k entries in a list is a lot",
    "date_created": "2025-02-14T08:25:39.924Z",
    "has_accepted_answer": false,
    "title": "Huge memory consumption for filtering hybrid search queries on AWS EKS deployment (Marketplace subscription)",
    "topic_id": 10345
  },
  {
    "user_id": 3278,
    "conversation": "[VINCENT_NADAR (2025-01-28T03:43:13.070Z)]: @DudaNogueira,\nI have deployed Weaviate using Kubeadm on a cluster hosted on an EC2 instance. The setup consists of 1 master node and 1 worker node. On the worker node, I deployed 2 pods using a StatefulSet deployment. Both pods are running and accessible, but they are not forming a cluster. Additionally, I want to replicate data across the pods. Is it possible to achieve this with a StatefulSet deployment, where each pod has its own storage?\nRegarding the cluster formation issue, I’m unsure what the problem might be. Below are the StatefulSet and Service files I used for this deployment.\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\nname: weaviate\nnamespace: weaviate-v3\nspec:\nserviceName: weaviate-headless\nreplicas: 2\nselector:\nmatchLabels:\napp: weaviate\ntemplate:\nmetadata:\nlabels:\napp: weaviate\nspec:\ncontainers:\n- name: weaviate\nimage: cr.weaviate.io/semitechnologies/weaviate:1.28.2\nports:\n- containerPort: 8080\nname: http\n- containerPort: 50051\nname: grpc\n- containerPort: 7946\nname: gossip\n- containerPort: 7947\nname: data\ncommand:\n- /bin/weaviate\nargs:\n- --host\n- “0.0.0.0”\n- --port\n- “8080”\n- --scheme\n- “http”\nenv:\n- name: QUERY_DEFAULTS_LIMIT\nvalue: “25”\n- name: AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED\nvalue: “true”\n- name: PERSISTENCE_DATA_PATH\nvalue: “/var/lib/weaviate”\n- name: DEFAULT_VECTORIZER_MODULE\nvalue: “none”\n- name: ENABLE_MODULES\nvalue: “”\n- name: CLUSTER_HOSTNAME\nvalueFrom:\nfieldRef:\nfieldPath: metadata.name\n- name: CLUSTER_GOSSIP_PEERS\nvalue: “weaviate-0.weaviate-headless.weaviate-v3.svc.cluster.local,weaviate-1.weaviate-headless.weaviate-v3.svc.cluster.local”\n- name: CLUSTER_JOIN\nvalue: “true”\n- name: RAFT_JOIN\nvalue: “true”\n- name: CLUSTER_GOSSIP_BIND_PORT\nvalue: “7946”\n- name: CLUSTER_GOSSIP_ADVERTISE_PORT\nvalue: “7946”\n- name: CLUSTER_DATA_BIND_PORT\nvalue: “7947”\n- name: CLUSTER_DATA_ADVERTISE_PORT\nvalue: “7947”\nvolumeMounts:\n- name: data\nmountPath: /var/lib/weaviate\nresources:\nrequests:\nmemory: “512Mi”\ncpu: “200m”\nlimits:\nmemory: “1Gi”\ncpu: “500m”\nvolumeClaimTemplates:\n\nmetadata:\nname: data\nspec:\naccessModes: [ “ReadWriteOnce” ]\nstorageClassName: ebs-gp3\nresources:\nrequests:\nstorage: 2Gi\n\napiVersion: v1\nkind: Service\nmetadata:\nname: weaviate-headless\nnamespace: weaviate-v3\nspec:\nclusterIP: None\nselector:\napp: weaviate\nports:\n- port: 8080\ntargetPort: 8080\nname: http\n- port: 50051\ntargetPort: 50051\nname: grpc\n- port: 8300\ntargetPort: 8300\nname: raft\n- port: 7946\ntargetPort: 7946\nname: gossip\n- port: 7947\ntargetPort: 7947\nname: data\nCan you tell me where I am going wrong or the approach I am taking is wrong?\n\n----------\n\n[akshay_madiwale (2025-02-10T09:48:43.201Z)]: VINCENT_NADAR:\n\nCLUSTER_DATA_ADVERTISE_PORT\n\n\nI am also facing same issue\n\n----------\n\n[Mohamed_Shahin (2025-02-10T10:04:37.236Z)]: Hello @VINCENT_NADAR, @akshay_madiwale,\nWelcome to our community, it’s great to have you here!\nI’m not sure if you’ve managed to resolve the issue yet, but I haven’t personally tested this setup as you are trying to achieve. However, based on our documentation:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nDocker | Weaviate\n\n  Weaviate supports deployment with Docker.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThose steps are essential for multinode:\n\nConfigure one node as a “founding” member\nSet CLUSTER_JOIN for the other nodes in the cluster\nDefine CLUSTER_GOSSIP_BIND_PORT and CLUSTER_DATA_BIND_PORT for each node\nSet RAFT_JOIN and RAFT_BOOTSTRAP_EXPECT to specify the number of voters\nOptionally, use CLUSTER_HOSTNAME to define node names\n\nExample for the founding member:\nCLUSTER_JOIN: 'weaviate-node-1:7100'  # This must be the service name of the founding member node.\n\nIf you haven’t already, try running through these steps again to ensure everything is set up correctly.\nRegards,\nMohamed Shahin\nWeaviate Support\n\n----------\n\n[VINCENT_NADAR (2025-02-17T08:20:20.479Z)]: My setup consists of one master node and one worker node. I am attempting to deploy multiple pods on the single worker node, but I am facing issues with cluster formation between the pods and data replication among the pods. I am using Kubernetes to deploy pods, with StatefulSet and service files mentioned in the first post. Could you please assist me in configuring the first pod as the leader and having the other pods join as followers of that initial pod?",
    "date_created": "2025-01-28T03:43:13.005Z",
    "has_accepted_answer": false,
    "title": "Facing cluster formation between pods of running weaviate using kubeadm on EC2",
    "topic_id": 9917
  },
  {
    "user_id": 1185,
    "conversation": "[Mohammed_Sadiq (2024-07-10T07:04:58.329Z)]: Exploring AWSBedrock and Weaviate vectorDB for my person profile dataset\n\n----------\n\n[Mohamed_Shahin (2024-07-11T10:55:23.676Z)]: Hi @Mohammed_Sadiq,\nWelcome to our community and it’s nice to have you here.\nI understand you are exploring AWSBeRock & VectorDB for your use case.\nYou can deploy Weaviate on AWS Marketplace, if that’s what you are looking for.\n\n  \n      \n\n      aws.amazon.com\n  \n\n  \n    \n\nAWS Marketplace: Weaviate Vector Database\n\n----------\n\n[Mohammed_Sadiq (2024-07-11T16:30:33.000Z)]: Hi Shahin,\nThanks for your reply and advice. It means a lot to me. I have implemented Cohere and Claude sonnet for my business use case. If you don’t mind, can you please guide me to the latest GitHub repository with examples on search (hybrid/rerank) and GenAI search? Indexing and sharding.\nThanks\n\n----------\n\n[Mohamed_Shahin (2024-07-12T11:55:33.802Z)]: Blessed Friday @Mohammed_Sadiq\nSure, If I understand you correct, here are some resources that can help you:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHorizontal Scaling | Weaviate - Vector Database\n\n  Weaviate can be scaled horizontally by being run on a set of multiple nodes in a cluster. This section lays out various ways in which Weaviate can be scaled, as well as factors to consider while scaling, and Weaviate's architecture in relation to...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nIndexing | Weaviate - Vector Database\n\n  Weaviate supports two types of indices.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate - Vector Database\n\n  Hybrid search combines the results of a vector search and a keyword (BM25F) search by fusing the two result sets.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nGenerative AI | Weaviate - Vector Database\n\n  Weaviate's integration with Cohere's APIs allows you to access their models' capabilities directly from Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nReranker | Weaviate - Vector Database\n\n  Weaviate's integration with Cohere's APIs allows you to access their models' capabilities directly from Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAlso check on the following for more res:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCohere + Weaviate | Weaviate - Vector Database\n\n  Cohere offers a wide range of models for natural language processing and generation. Weaviate seamlessly integrates with Cohere's APIs, allowing users to leverage Cohere's models directly within the Weaviate database.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nGitHub - weaviate/weaviate: Weaviate is an open-source vector database that...\n\n  Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of ...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nGitHub - weaviate/weaviate-python-client: A python native client for easy...\n\n  A python native client for easy interaction with a Weaviate instance. - weaviate/weaviate-python-client\n\n----------\n\n[Mohammed_Sadiq (2024-07-12T16:53:50.000Z)]: Hi Shahin,\nThank you very much …\nThanks & regards\nMohammed Sadiq",
    "date_created": "2024-07-10T07:04:58.218Z",
    "has_accepted_answer": true,
    "title": "AWSBeRcok and Weaviate vectordb for persons profiles dataset",
    "topic_id": 3001
  },
  {
    "user_id": 1302,
    "conversation": "[wvuser (2024-08-28T10:18:39.170Z)]: Description\nWe have a problem with replica synchronization (deletions not fixed when nodes fail/restart) in a cluster of 3 nodes and 3 replicas. Running batch/cursor read process with ConsistencyLevel=ALL does not help. Tried even full reading with connect (route) to different (every) nodes.\nSome cluster info, private fields are masked (ip-addresses, schema/property names):\n\nCluster statistics\nNodes info\nNode #1 file-list\nNode #2 file-list\nNode #3 file-list\n\nFound some issues:\n\nSupport Read-Repairs (and async repair) for deleted objects\nObject count differs\n\nAre any advices avalaible?\nCan you tell about ‘SEARCH_FORCE_EXPAND_TO_ALL_REPLICAS’ flag:\nAdd flag to expand search to all available replicas\nHow to use it? Not found any use in v1.25.12 sources (or I’m wrong?).\nServer Setup Information\n\nWeaviate Server Version: 1.25.12\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: Yes, 3\nClient Language and Version: Python3, Python Client v3\nMultitenancy?: No\n\n----------\n\n[DudaNogueira (2024-09-18T21:59:01.308Z)]: hi @wvuser !!\nReally sorry, missed this thread \nDo you still see this error?\na lot changed specifically for this area om 1.26\nThanks!",
    "date_created": "2024-08-28T10:18:39.104Z",
    "has_accepted_answer": false,
    "title": "Nodes/shards objects imbalance",
    "topic_id": 3798
  },
  {
    "user_id": 323,
    "conversation": "[Dharanish (2025-03-27T10:18:01.384Z)]: Team, we can’t use helm in our production environment so we created a helm like tools for our production deployment. In weaviate deployment, the RAFT_JOIN is handled by helm based on the number of nodes. But for  our case of 3 node cluster, how to handle this .\nBy default each node make itself as leader.\nSo I added the env variable  RAFT_JOIN= weaviate-node-1,weaviate-node-2,weaviate-node-3.\nAfter adding this , All nodes elect weaviate-node-1 as leader. But in case of node-1 failure/restart. other nodes don’t become as candidate and they select only weaviate-node-1 as their leader\nHow to resolve this?\n\n----------\n\n[DudaNogueira (2025-03-27T12:00:11.578Z)]: hi @Dharanish !\nThat’s strange. After node-1 death as a leader, they should elect a new leader.\nDo you see anything outstanding on raft comms log?\n\n----------\n\n[Dharanish (2025-03-27T12:18:33.842Z)]: “build_git_commit”:“6edf2b8”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.28.11”,“build_wv_version”:“1.28.11”,“level”:“warning”,“msg”:\" memberlist: Was able to connect to weaviate-codeassistant-1 over TCP but UDP probes failed, network may be misconfigured\",\" │\n│ {“build_git_commit”:“6edf2b8”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.28.11”,“build_wv_version”:“1.28.11”,“level”:“info”,“msg”:\" memberlist: Suspect weaviate-codeassistant-0 has failed, no acks received\",“time”:“2025-03-27T12:16:53Z”}                      │\n│ {“build_git_commit”:“6edf2b8”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.28.11”,“build_wv_version”:“1.28.11”,“level”:“info”,“msg”:\" memberlist: Suspect weaviate-codeassistant-0 has failed, no acks received\",“time”:“2025-03-27T12:16:57Z”}                      │\n│ {“build_git_commit”:“6edf2b8”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.28.11”,“build_wv_version”:“1.28.11”,“level”:“info”,“msg”:\" memberlist: Marking weaviate-codeassistant-0 as failed, suspect timeout reached (0 peer confirmations)“,“time”:“2025-03-27T12: │\n│ {“build_git_commit”:“6edf2b8”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.28.11”,“build_wv_version”:“1.28.11”,“level”:“error”,“msg”:” memberlist: Conflicting address for weaviate-codeassistant-0. Mine: 10.244.5.72:7000 Theirs: 10.244.5.73:7000 Old state: 2”,\" │\n│ {“build_git_commit”:“6edf2b8”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.28.11”,“build_wv_version”:“1.28.11”,“level”:“error”,“msg”:\" memberlist: Conflicting address for weaviate-codeassistant-0. Mine: 10.244.5.72:7000 Theirs: 10.244.5.73:7000 Old state: 2\",\" │\n│ {“build_git_commit”:“6edf2b8”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.28.11”,“build_wv_version”:“1.28.11”,“level”:“error”,“msg”:\" memberlist: Conflicting address for weaviate-codeassistant-0. Mine: 10.244.5.72:7000 Theirs: 10.244.5.73:7000 Old state: 2\",\" │\n│ {“build_git_commit”:“6edf2b8”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.28.11”,“build_wv_version”:“1.28.11”,“level”:“error”,“msg”:\" memberlist: Conflicting address for weaviate-codeassistant-0. Mine: 10.244.5.72:7000 Theirs: 10.244.5.73:7000 Old state: 2\",\" │\n│ {“build_git_commit”:“6edf2b8”,“build_go_version”:“go1.22.12”,“build_image_tag”:“v1.28.11”,“build_wv_version”:“1.28.11”,“level”:“error”,“msg”:\" memberlist: Conflicting address for weaviate-codeassistant-0. Mine: 10.244.5.72:7000 Theirs: 10.244.5.73:7000 Old state: 2\",\"\nI get the above logs only\n\n----------\n\n[DudaNogueira (2025-03-27T14:57:53.834Z)]: Dharanish:\n\nweaviate-codeassistant-0.\n\n\nIt seems memberlist is not allowing this node to join, as it’s expecting weaviate-node-1\n\n----------\n\n[Dharanish (2025-03-28T05:14:37.203Z)]: No , actual node name is weaviate-codeassistant-x, we set those in RAFT_JOIN . I just used the term node-1 for simplicity.\n\n----------\n\n[DudaNogueira (2025-03-28T19:08:33.687Z)]: Could you share those manifests?\nOtherwise is hard to tackle.\nit looks like something may be blocking udp internal comms between nodes.\nSo nodes are probably crashlooping, changing ips between pods, and becoming suspects of each other, as the present themselves with a hostname, but now with a different ip.\nLet me know if this helps",
    "date_created": "2025-03-27T10:18:01.337Z",
    "has_accepted_answer": false,
    "title": "RAFT_JOIN without helm",
    "topic_id": 20349
  },
  {
    "user_id": 788,
    "conversation": "[Rio (2024-09-24T06:48:48.694Z)]: I’m using a Helm chart to deploy Weaviate, but I want to store images in a local cluster’s registry that is blocked from external access.\nIn the values.yaml file, I was able to specify a pull secret for the Weaviate image as follows, which works fine:\nimage:\nregistry: XXXXXXXXXXXXXXXXXXXXXXX\ntag: 1.26.4\nrepo: weaviate\npolicy\npullPolicy: IfNotPresent\npullSecrets:\n- XXX-secret\nHowever, I’m having trouble specifying the pull secret for the initContainers. Even if I use the same syntax, it doesn’t work.\nCould you please help me verify this?\n\n----------\n\n[andrewisplinghoff (2024-09-24T10:57:30.063Z)]: imagePullSecrets apply to both initContainers as well as regular containers, they are defined outside of the container specification. So I would assume that you have some different problem in the end - how did you come to the conclusion that the pull secrets are not being used to pull the init container image?\n\n----------\n\n[Rio (2024-09-26T12:49:11.886Z)]: The Weaviate image stored in the same registry can be successfully pulled, but when trying to pull Alpine as an init container, the following error occurs:\nEvents:\nType     Reason     Age                     From               Message\n\nNormal   Scheduled  8m18s                   default-scheduler  Successfully assigned weaviate/weaviate-0 to node1\nWarning  Failed     6m52s (x6 over 8m16s)   kubelet            Error: ImagePullBackOff\nNormal   Pulling    6m38s (x4 over 8m17s)   kubelet            Pulling image “my_registry_url/alpine:latest”\nWarning  Failed     6m37s (x4 over 8m17s)   kubelet            Failed to pull image “my_registry_url/alpine:latest”: rpc error: code = Unknown desc = failed to pull and unpack image “my_registry_url/alpine:latest”: failed to resolve reference “my_registry_url/alpine:latest”: failed to authorize: failed to fetch anonymous token: unexpected status: 401 Unauthorized\nWarning  Failed     6m37s (x4 over 8m17s)   kubelet            Error: ErrImagePull\nNormal   BackOff    3m15s (x20 over 8m16s)  kubelet            Back-off pulling image “my_registry_url/alpine:latest”\n\n----------\n\n[andrewisplinghoff (2024-09-26T20:12:17.039Z)]: Hm, a couple ideas:\n\nCould you check the YAML of the StatefulSet to verify that the imagePullSecrets are defined under spec.template.spec as one would expect? It’s defined as such in weaviate-helm/weaviate/templates/weaviateStatefulset.yaml at fc9717312c87ab7246bf38871af0a65a23e082a5 · weaviate/weaviate-helm · GitHub\nCould you verify that your image can be pulled successfully e.g. by trying to using it in a separate pod, e.g. as described in Pull an Image from a Private Registry | Kubernetes?\nMaybe also ctr/crictl commands can help in verifying that pulling in general is possible (Pod seemingly not using imagePullSecrets · Issue #66162 · kubernetes/kubernetes · GitHub).\n\n----------\n\n[Rio (2024-09-27T06:51:44.408Z)]: Thank you for your response.\nI was able to solve the problem thanks to you.\nThank you!",
    "date_created": "2024-09-24T06:48:48.648Z",
    "has_accepted_answer": true,
    "title": "How to specify pull secret of initContainers",
    "topic_id": 4267
  },
  {
    "user_id": 3196,
    "conversation": "[Supavit (2025-01-12T18:49:57.447Z)]: Hi everyone, I’m running into some challenges while trying to intergrate Weaviate with an Ollama Docker (with CUDA support) Instance. They are both ran in an docker container on the same server. However, I keep encoutering errors when Weaviate tries to connect to Ollama. I’m using the v4 Python client, and the main issue seems to be related to how Weaviate is trying to communicate with Ollama.\n( SInce im a new user I can only use to links so I will be replacing them as following: http://192.168.x.x with URL)\nSetup Details\n1.Weaviate Docker Setup\n\nImage: cr.weaviate.io/semitechnologies/weaviate:1.28.2\nEnvironment Variables:\nenvironment:\nENABLE_MODULES: text2vec-ollama,generative-ollama\nOLLAMA_URL: URL:11434\nWEAVIATE_HOST: 0.0.0.0\nWEAVIATE_PORT: 8080\nWEAVIATE_GRPC: 50051\nPorts:\nports:\n– 8080:8080\n– 50051:50051\n\n\nOllama Docker Setup\n\n\nImage: ollama/ollama\nCUDA Support: Configured with nvidia-container-toolkit\nPorts: 11434:11434\n\n\nSchema Configuration\n(since Weaviate is running in a docker container, I have tried host.docker.internal:11434 and localhost:11434 which don’t give a other result then with the current setup)\n{\n“class”: “Article”,\n“vectorizer”: “text2vec-ollama”,\n“vectorIndexConfig”: {\n“distance”: “cosine”\n},\n“modelConfig”: {\n“text2vec-ollama”: {\n“apiEndpoint”: “URL:11434”,\n“model”: “nomic-embed-text”\n},\n“generative-ollama”: {\n“apiEndpoint”: “URL:11434”,\n“model”: “llama3.2”\n}\n},\n“properties”: [\n{“name”: “title”, “dataType”: [“text”]},\n{“name”: “content”, “dataType”: [“text”]},\n{“name”: “authors”, “dataType”: [“text”]},\n{“name”: “publicationDate”, “dataType”: [“date”]},\n{“name”: “category”, “dataType”: [“text”]},\n{“name”: “tags”, “dataType”: [“text”]},\n{“name”: “url”, “dataType”: [“text”]},\n{“name”: “scrapeDate”, “dataType”: [“date”]},\n{“name”: “createdDate”, “dataType”: [“date”]},\n{“name”: “articleId”, “dataType”: [“text”], “index”: true, “primaryKey”: true}\n]\n}\nPython Client Initialization\nimport weaviate\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\nclient = weaviate.connect_to_local(\nhost=os.getenv(“WEAVIATE_HOST”, “127.0.0.1”),\nport=int(os.getenv(“WEAVIATE_PORT”, 8080)),\ngrpc_port=int(os.getenv(“WEAVIATE_GRPC”, 50051))\n)\nIssue\nWhen running my script to insert data into Weaviate (ran on an other computer then the docker containers), I encouter the following error:\nweaviate.exceptions.UnexpectedStatusCodeError: Object was not added! Unexpected status code: 500, with response body: {'error': [{'message': 'update vector: send POST request: Post \"http://localhost:11434/api/embed\": dial tcp [::1]:11434: connect: connection refused'}]}.\nQuestions\n\nWhy is Weaviate defaulting to localhost:11434 even thought the schema specifies URL:11434, host.docker.internal:11434 for apiEndpoint?\nIs there any additional configuration needed to make Weaviate v4 properly use the OLLAMA_URL?\nAm I missing any critical step in the setup to make these two services communicate?\nHow does Weaviate internally handle the communication with external modules like Ollama? Is there a way to debug these request in more detail?\n\nAppreciation\nThanks in advance for any help or pointers! I’m happy to provide additional logs or configuration details if needed. Let me know how I can further debug this.\nKind regards!\n\n----------\n\n[DudaNogueira (2025-01-27T21:02:13.294Z)]: hi @Supavit !!\nWelcome to our community \nHow are you creating this collection?\nBecause both ollama and weaviate are running on the same network, you need to set it up as http://ollama:11434\nCheck out this one forum thread for more:\n  \n    \n    \n    [Question] Getting Weaviate and Ollama working together running locally Support\n  \n  \n    I have been trying to get weaviate and ollama working together on my local machine.  I have yet to get weaviate to successfully connect to ollama at all.  Does anyone any tips? \nHere is my docker-compose.yml file: \nversion: \"3.7\"\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2\n    ports:\n      - 8080:8080\n      - 50051:50051\n    environment:\n      ENABLE_MODULES: text2vec-ollama\n      OLLAMA_URL: http://ollama:11434\n      TEXT2VEC_OLLAMA_BASE_URL: http://ollama:1…",
    "date_created": "2025-01-12T18:49:57.386Z",
    "has_accepted_answer": false,
    "title": "Issues Configuring weaviate to work with an ollama Docker Instance (v4 client)",
    "topic_id": 9690
  },
  {
    "user_id": 2419,
    "conversation": "[g_parki (2025-02-21T19:32:33.166Z)]: Description\nHello!\nI migrated some collections and used replication (async-enabled) for the first time. I waited some time and manually checked the shard object count to verify all my objects were migrated/replicated/synced, and after that I applied some simple environment variable changes to the Helm chart.\nWhen the update rolled out though, each pod - one at a time - became stuck in Terminating state for several minutes. I checked the logs stream and I saw it was still performing async replication checks while it was supposed to be terminating. The whole operation took 20+ minutes and I wound up intervening to forcefully kill the pods.\nLater on I did a k8s version update (for separate reasons), and the same issue happened as k8s attempted to relocate the pods to updated nodes.\nServer Setup Information\n\nWeaviate Server Version: 1.26.5\nDeployment Method: k8s\nNumber of Running Nodes: 5\n\n----------\n\n[jeronimo_irazabal (2025-02-21T19:49:59.997Z)]: Hello @g_parki , thanks for reaching out.\nIn order to use async replication we highly recommend to upgrade to latest release 1.29.0. If that were an impediment for you we could discuss about it otherwise the upgrade will be the way to go.\nBest,\nJeronimo\n\n----------\n\n[g_parki (2025-02-21T20:19:20.654Z)]: Gotcha, thanks for the quick response. For the time being I’m stuck on this version due to broken support for Azure OpenAI ada-002 models. Vector dimension erroneously being sent to ada-002 model when using Azure OpenAI · Issue #6334 · weaviate/weaviate · GitHub\nI’ll up the priority on revectorizing everything and will give 1.29.0 a try.",
    "date_created": "2025-02-21T19:32:33.113Z",
    "has_accepted_answer": false,
    "title": "Pods hang in \"Terminating\" state, continue performing async replication checks",
    "topic_id": 10496
  },
  {
    "user_id": 3473,
    "conversation": "[Haris_khan_Khakwani (2025-02-17T14:43:24.080Z)]: example\nclient.collections.create(\n    \"DemoCollection\",\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_huggingface(\n            name=\"title_vector\",\n            source_properties=[\"title\"],\n            # NOTE: Use only one of (`model`), (`passage_model` and `query_model`), or (`endpoint_url`)\n            #model=\"sentence-transformers/all-MiniLM-L6-v2\",\n            # passage_model=\"sentence-transformers/facebook-dpr-ctx_encoder-single-nq-base\",    # Required if using `query_model`\n            # query_model=\"sentence-transformers/facebook-dpr-question_encoder-single-nq-base\", # Required if using `passage_model`\n            endpoint_url=\"<custom_huggingface_url>\",\n            #\n            # wait_for_model=True,\n            # use_cache=True,\n            # use_gpu=True,\n        )\n    ],\n)\n\n----------\n\n[DudaNogueira (2025-02-18T13:10:50.916Z)]: hi @Haris_khan_Khakwani !!\nUnfortunately, we currently don’t have the option to change huggingface’s baseurl url on run time \nMost of other modules, for example, text2vec-cohere do have this option:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nText Embeddings | Weaviate\n\n  Weaviate's integration with Cohere's APIs allows you to access their models' capabilities directly from Weaviate.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor now, I believe the only option is migrating your data to a new collection with the new endpoint  I know, should be easier \nWe will work on adding this feature in future releases.\nThanks!",
    "date_created": "2025-02-17T14:43:24.034Z",
    "has_accepted_answer": false,
    "title": "How to update the endpoint_url of huggingface vectorizer of an existing collection ? given the model is same",
    "topic_id": 10417
  },
  {
    "user_id": 3185,
    "conversation": "[AnnTade (2025-01-10T08:41:01.715Z)]: Hi Everyone. I really need your guys help here!\nI am given a weaviate URL which has been deployed as a web app. I am given the url to it - say its https://sample-weaviate.myorg.com (hiding the url for the sake of security). I am not given any ports or any grcp related data.\nI had a version 3 code that could connect to it in the following manner\nfrom weaviate import Client as wClient\nself.weaviate = wClient(WEAVIATE_ENDPOINT)\nNow for version 4, which offers the following ways to connect to it, I am failing miserably, trying to connect to the weaviate instance using just the URL, which I code easily do in v3\n\nWeaviate Cloud (not the case for me as its not hosted on weaviate cloud)\nLocal instances (this seems to pre and post append the port to it, so couldn’t get it to work)\nCustom connections again requires http port, grpc host & port, which I am not provided.\nEmbedded Weaviate (not the case for me)\n\nCan anyone please help me by providing the python code to connect to a weaviate instance, provided only the URL? I’m using weaviate client v4.10.2\nYour help will be much appreciated. Thanks folks!\n\n----------\n\n[DudaNogueira (2025-01-10T11:11:49.391Z)]: hi @AnnTade !!\nWelcome to our community  !!\nThe python client v4 introduces the GRPC connection. So in order to use it, you need to make sure you server is a recent version (1.25+ should be fine) and has the GRPC port exposed.\nNow, if your cluster is under a SSL/TLS endpoint, you need to make sure that both grpc and http endpoints are secure in the client.\nHere you can customize your connection. So let’s say you expose http and grpc on different ports, or different domains, etc:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCustom connections | Weaviate\n\n  The Python Client v4 and the TypeScript Client v3 provide helper methods for common connection types. They also provide custom methods for when you need additional connection configuration.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps!\n\n----------\n\n[DudaNogueira (2025-01-10T11:12:54.299Z)]: By the way, to find out the version your server is running, you can hit this endpoint:\nhttps://sample-weaviate.myorg.com/v1/meta\n\n----------\n\n[AnnTade (2025-01-10T12:23:52.043Z)]: that was really helpful. Thank you! and is there a way to check is gRPC ports are being exposed? Also to use custom connections function to connect\nmy http_host would be the url of the weaviate and the port would be something like 8080. Is that correct?\n\n----------\n\n[DudaNogueira (2025-01-23T14:47:20.568Z)]: hi @AnnTade !!\nSorry for the late response here. I was out on   vacations \nHere I have written some examples on how to check the availability for both endpoints using curl and grpcurl and also when behind a reverse proxy serving TLS/SSL like traefik:\n\n  \n    \n    \n    Weaviate with Traefik and gRPC Support\n  \n  \n    Hi @qnlbnsl ! Sorry for the delay here. \nLooks like I was finally able to tame this \nHere is what I got: \nNOTE: Check this updated gist on how to correctly expose Weaviate under SSL/TLS using Traefik and running everything with a docker compose \n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:1.23.5\n    #ports:\n    # - 8081:8080 # unsafe http\n    # - 50052:50051 # unsafe grpc…\n  \n\n\nMaybe that doc can help you on this.\nLet me know if that helps!\nHappy coding/deploying!",
    "date_created": "2025-01-10T08:41:01.648Z",
    "has_accepted_answer": false,
    "title": "Cannot connect to weaviate in v4 using only url",
    "topic_id": 9661
  },
  {
    "user_id": 273,
    "conversation": "[kokogrr (2023-09-05T15:18:29.160Z)]: Hello,\nI’m setting up self hosted instance of Weaviate on an Ubuntu VPS  with Weaviate running in a Docker container. My question is can Weaviate instance support SSL connections by itself like eg. MySQL server does or do I need a reverse proxy eg. Nginx that will handle that? I looked into docs and searched ‘weaviate ssl’ online but didn’t find anything useful.\n\n----------\n\n[DudaNogueira (2023-09-05T15:22:05.014Z)]: Hi @kokogrr ! Welcome to our community \nNo. You will need to reverse-proxy it in order to get SSL.\nYou can do it with traefik or nginx, for example.\nI will add a note about this in our docs, thank you!\n\n----------\n\n[kokogrr (2023-09-05T15:42:59.951Z)]: Thanks a lot for quick reply!\n\n----------\n\n[salik_Lari (2023-09-26T06:12:51.411Z)]: is document updated for SSL? I cant find anything\n\n----------\n\n[lakshminarayana (2024-06-28T15:39:10.028Z)]: @DudaNogueira  Thanks a lot for your response. Do u have any handy documentation  for the same, if any Please share with us.\n\n----------\n\n[DudaNogueira (2024-06-28T19:20:48.235Z)]: hi @lakshminarayana ! Welcome to our community.\nOur documentation usually doesn’t cover the SSL/TLS side of the deployment for two main reasons:\n1 - Usually, self deployments will not expose Weaviate directly. Their applications will be exposed. but not Weaviate.\n2 - Whenever there is a reason to expose Weaviate under a SSL/TLS connection, one can use a variety of reverse proxies, load balancers and so on.\nI have crafted here a gist on how to deploy Weaviate, with a single node, using docker compose and properly exposing it using traefik:\n\n  \n      \n\n      GitHub\n  \n\n  \n    \n\nBuild software better, together\n\n  GitHub is where people build software. More than 100 million people use GitHub to discover, fork, and contribute to over 420 million projects.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAccording to this docker compose, this is how you would connect to it:\nclient = weaviate.connect_to_custom(\n    http_host=\"weaviate.yourcompany.com\",\n    http_port=443,\n    http_secure=True,\n    grpc_host=\"grpc.weaviate.yourcompany.com\",\n    grpc_port=50051,\n    grpc_secure=True\n)\n\nIf running on a VPS, you will need to have both weaviate.yourcompany.com and grpc.weaviate.yourcompany.com pointing to the public IP of this VPS.\nHere the content of the docker compose as of now:\n---\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.25.5\n    # uncomment only if you want to connect unnsecured\n    #ports:\n    #- 8081:8080\n    #- 50052:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node1'\n    labels:\n      - \"traefik.enable=true\"\n      # http\n      - \"traefik.http.services.weaviate_http_service.loadbalancer.server.port=8080\"\n      - \"traefik.http.routers.weaviate_http_router.rule=Host(`weaviate.yourdomain.com`)\"\n      - \"traefik.http.routers.weaviate_http_router.entrypoints=websecure\"\n      - \"traefik.http.routers.weaviate_http_router.service=weaviate_http_service\"\n      - \"traefik.http.routers.weaviate_http_router.tls.certresolver=myresolver\"\n      # # grpc\n      - \"traefik.http.services.weaviate_grpc_service.loadbalancer.server.scheme=h2c\"\n      - \"traefik.http.services.weaviate_grpc_service.loadbalancer.server.port=50051\"\n      - \"traefik.http.routers.weaviate_grpc_router.rule=Host(`grpc.weaviate.yourdomain.com`)\"\n      - \"traefik.http.routers.weaviate_grpc_router.entrypoints=grpc\"\n      - \"traefik.http.routers.weaviate_grpc_router.service=weaviate_grpc_service\"\n      - \"traefik.http.routers.weaviate_grpc_router.tls.certresolver=myresolver\"\n\n  traefik:\n    #image: \"traefik:v2.11\"\n    image: \"traefik:v3.0.3\"\n    container_name: \"traefik\"\n    command:\n      - \"--log.level=DEBUG\"\n      - \"--providers.docker.exposedbydefault=false\"\n      - \"--entrypoints.web.address=:80\"\n      - \"--entrypoints.websecure.address=:443\"\n      - \"--entrypoints.web.http.redirections.entryPoint.to=websecure\"\n      - \"--entrypoints.web.http.redirections.entryPoint.scheme=https\"\n      - \"--entrypoints.grpc.address=:50051\"\n      - \"--providers.docker\"\n      - \"--api\"\n      # - \"--certificatesresolvers.myresolver.acme.caserver=https://acme-staging-v02.api.letsencrypt.org/directory\"\n      - \"--certificatesresolvers.myresolver.acme.tlschallenge=true\"\n      - \"--certificatesresolvers.myresolver.acme.httpchallenge.entrypoint=web\"\n      - \"--certificatesresolvers.myresolver.acme.email=you@yourcompany.com\"\n      - \"--certificatesresolvers.myresolver.acme.storage=/letsencrypt/acme.json\"\n\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n      - \"50051:50051\"\n    volumes:\n      - \"./letsencrypt:/letsencrypt\"\n      - \"/var/run/docker.sock:/var/run/docker.sock:ro\"\n\nvolumes:\n  weaviate_data:\n...\n\nlet me know if this helps\n\n----------\n\n[lakshminarayana (2024-07-01T02:48:54.603Z)]: Thanks a lot for support and help We will update once we were able to access weaviate with https:\n\n----------\n\n[lakshminarayana (2024-07-11T09:33:49.813Z)]: While accessing the gRPC client am facing below error\n2024/07/11 09:22:21 [error] 26#26: *9358 upstream sent no valid HTTP/1.0 header while reading response header from upstream, client: 10.0.131.66, server: grpc.weaviatedev.test.com, request: “GET / HTTP/1.1”, upstream: “http://10.0.141.246:50051/”, host: “grpc.weaviatedev.test.com”\n2024/07/11 09:22:21 [error] 26#26: *9358 recv() failed (104: Connection reset by peer) while reading upstream, client: 10.0.131.66, server: grpc.weaviatedev.test.com, request: “GET / HTTP/1.1”, upstream: “http://10.0.141.246:50051/”, host: “grpc.weaviatedev.test.com”\n10.0.131.66 - - [11/Jul/2024:09:22:21 +0000] “GET / HTTP/1.1” 009 15 “-” “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 (scanner.ducks.party)” 228 0.003 [weaviate-weaviate-grpc-50051]  10.0.141.246:50051 15 0.003 200 1d8e05cbe04f47be9b601d3a3fac3fa0\n10.0.131.66 - - [11/Jul/2024:09:22:24 +0000] “GET / HTTP/1.1” 308 164 “-” “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 (scanner.ducks.party)” 228 0.000 [weaviate-weaviate-grpc-50051]  - - - - 51cb606133e373c434cd851fdbfc52a9\n2024/07/11 09:22:28 [error] 27#27: *9418 upstream sent no valid HTTP/1.0 header while reading response header from upstream, client: 10.0.131.66, server: grpc.weaviatedev.test.com, request: “GET / HTTP/1.1”, upstream: “http://10.0.157.18:50051/”, host: “grpc.weaviatedev.test.com”, referrer: “http://grpc.weaviatedev.test.com”\n2024/07/11 09:22:28 [error] 27#27: *9418 recv() failed (104: Connection reset by peer) while reading upstream, client: 10.0.131.66, server: grpc.weaviatedev.test.com, request: “GET / HTTP/1.1”, upstream: “http://10.0.157.18:50051/”, host: “grpc.weaviatedev.test.com”, referrer: “http://grpc.weaviatedev.test.com”\n10.0.131.66 - - [11/Jul/2024:09:22:28 +0000] “GET / HTTP/1.1” 009 15 “http://grpc.weaviatedev.test.com” “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36(scanner.ducks.party)” 278 0.001 [weaviate-weaviate-grpc-50051]  10.0.157.18:50051 15 0.001 200 48ee60f00f83722e720314166b7b2c5a\nubuntu@ip-10-0-9-110:~$\nany one can be able to help me on this\n@DudaNogueira\n\n----------\n\n[lakshminarayana (2024-07-11T09:35:58.815Z)]: Nginx-Ingress Rule:\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\nname: weaviate-ingress\nnamespace: weaviate\nannotations:\ncert-manager.io/cluster-issuer: letsencrypt-prod\nnginx.ingress.kubernetes.io/ssl-redirect: “true”\nnginx.ingress.kubernetes.io/backend-protocol: “GRPC”\nnginx.ingress.kubernetes.io/backend-protocol: “HTTP”\nspec:\ningressClassName: nginx\ntls:\n\nhosts:\n\nweaviatedev.test.com\ngrpc.weaviatedev.test.com\nsecretName: weaviate-tls\nrules:\n\n\nhost: weaviatedev.test.com\nhttp:\npaths:\n\npath: /\npathType: Prefix\nbackend:\nservice:\nname: weaviate\nport:\nnumber: 8080\n\n\nhost: grpc.weaviatedev.test.com\nhttp:\npaths:\n\npath: /\npathType: Prefix\nbackend:\nservice:\nname: weaviate-grpc\nport:\nnumber: 50051\n\n\n\n@DudaNogueira Any help on the above issue…\n\n----------\n\n[DudaNogueira (2024-07-15T13:20:03.522Z)]: Hi!\nare those logs from nginx?\n\n----------\n\n[lakshminarayana (2024-07-16T12:00:30.728Z)]: Yes Logs from Nginx only @DudaNogueira\n\n----------\n\n[DudaNogueira (2024-07-16T14:14:46.882Z)]: Exposing the deployment has a lot of options and varies a lot.\nI have crafted a docker compose for traefik here.\nbecause of the new grpc endpoint, it got a little bit more tricky than only a common http port.\nI have not played with nginx on k8s yet. I will try to get a hold of those an try to come up with some samples, as exposing weaviate is a common questions I see around.\nBut bottom line, this is will be about exposing both the http port and grpc port.\nfor the grpc part, you can use tools like grpcurl to make sure you deployment is serving. Check this thread on this\nfor instance:\n grpcurl -d '{\"service\": \"Weaviate\"}' -proto health.proto grpc.weaviate.mydomain.com:50051 grpc.health.v1.Health/Check\n\n\nLet me know if this helps and let’s keep it going!\nThanks for using Weaviate and engaging here on forums, we really appreaciate it\n\n----------\n\n[lakshminarayana (2024-07-28T12:34:03.429Z)]: @DudaNogueira\nNeed Your help here .\nroot@i-xxxxxxxxx-server:~# grpcurl -d ‘{“service”: “Weaviate”}’ -proto health.proto grpc.pocweviate.mydomain.com:443 grpc.health.v1.Health/Check\n{\n“status”: “SERVING”\n}\nroot@i-xxxxxxxxx-server:~# grpcurl -v -insecure -H “apikey: weaviatetest-readOnly-Key-lakshmi” grpc.pocweviate.mydomain.com:443 list\nFailed to list services: server does not support the reflection API\nroot@i-xxxxxxxxx-server:~# grpcurl -v -insecure -H “apikey: weaviatetest-readOnly-Key-lakshmi” grpc.pocweviate.mydomain.com:50051 list\nFailed to dial target host “grpc.pocweviate.mydomain.com:50051”: context deadline exceeded\nroot@i-xxxxxxxxx-server:~#\nI have applied SSL using Nginx Ingress\nam using NetworkLoadbalencer\nFailed to list services: server does not support the reflection API\nFailed to dial target host “grpc.pocweviate.mydomain.com:50051”: context deadline exceeded\nWhy this error, Any help from your side. It’s littile urjent.  Your inputs will help me a lot.\nHope GRPC endpoint health looks Good.\nstatus\": \"SERVING\n\n----------\n\n[DudaNogueira (2024-07-29T18:14:20.925Z)]: Hi!\nThis looks like something on k8s\nExposing Weaviate is a topic we can never cover all the basis, as it will depend a lot on how and where you are deploying it.\nthe reflection error is probably grpcurl hitting somewhere different to what we expect and not being able to list.",
    "date_created": "2023-09-05T15:18:29.119Z",
    "has_accepted_answer": true,
    "title": "Does Weaviate support SSL out of the box?",
    "topic_id": 620
  },
  {
    "user_id": 1646,
    "conversation": "[emmanuelkatto (2025-01-14T12:42:33.040Z)]: Hi everyone,\nI’m Emmanuel Katto, I’ve added a reference property to a Weaviate collection using the Python client, but now I’m looking for a way to remove it without recreating the entire collection and losing data.\nHere’s the code I used to add the reference property:\nI’m wondering if there’s a way to remove this reference property using the Weaviate Python client without the need to recreate the collection and lose the data. Has anyone done this before or can point me in the right direction?\nLooking forward to hearing your suggestions!\nfrom weaviate.classes.config import ReferenceProperty\ncategory = client.collections.get(“Rechtspraak_nl”)\ncategory.config.add_reference(\nReferenceProperty(\nname=“extracted_content_outline”,\ntarget_collection=“Rechtspraak_nl_metadata”\n)\n)\n\n----------\n\n[Mohamed_Shahin (2025-01-16T09:20:08.092Z)]: Hello @emmanuelkatto,\nSome parameters are mutable after you create your collection, but not all. To modify immutable parameters, you’ll need to export your data, create a new collection, and then import your data into it.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection definition | Weaviate\n\n  Schema Configuration in Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNote that changes involving Cross-References will require a re-import as they involve schema changes.\nRegards,\nMohamed Shahin,\nWeaviate Support",
    "date_created": "2025-01-14T12:42:32.993Z",
    "has_accepted_answer": false,
    "title": "Emmanuel Katto : How to Remove a Reference Property from Weaviate Collection Using Python Client?",
    "topic_id": 9743
  },
  {
    "user_id": 934,
    "conversation": "[saurbhhsharrma (2024-08-19T08:44:03.872Z)]: Description\nWe are planning to host Weaviate in our AWS environment, and would like to understand whether Weaviate provides any UI Client to view the data of the Weaviate.\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: AWS ECS\nMulti Node? Number of Running Nodes: 2 Nodes\nClient Language and Version: v4, 1.26\nMultitenancy?: Yes\n\n----------\n\n[DudaNogueira (2024-08-19T12:35:42.185Z)]: hi @saurbhhsharrma !!\nWe don’t have a UI app you could access your self hosted clusters.\nWe are developing some of those Apps in our console.\nHowever, you can easily use a client, eg python v4 client and connect and explore the data in your cluster.\nLet me know if I can help you with that.\nThanks!",
    "date_created": "2024-08-19T08:44:03.829Z",
    "has_accepted_answer": false,
    "title": "Weaviate Client for Self-Hosted environment",
    "topic_id": 3393
  },
  {
    "user_id": 3309,
    "conversation": "[roei.nuvei (2025-02-04T08:07:09.920Z)]: We’re testing Weaviate v4 for our vector database and have two collections (classes) set up. Our users often ask questions where we don’t know which collection contains the relevant answer, so we need to query multiple collections simultaneously.\nSo far, the best solution I’ve found is using this GraphQL query:\n{\n  Get {\n    Features (\n      hybrid: {\n        query: \"some query...\"\n        alpha: 0.5\n      }\n      limit: 5\n    ) {\n      product\n      channel\n      _additional { score }\n    }\n    Banks (\n      hybrid: {\n        query: \"some query...\"\n        alpha: 0.5\n      }\n      limit: 5\n    ) {\n      bank_name\n      aBU\n      _additional { score }\n    }\n  }\n}\n\nThis works, but hardcoding each collection isn’t scalable as more collections are added.\nMy question:\nIs there a way to dynamically query multiple collections in v4 without listing each one manually? Only thing we saw is the Explore method, which is not supported anymore as far as we see.\nThanks in advance!\n\n----------\n\n[DudaNogueira (2025-02-04T12:35:55.497Z)]: hi @roei.nuvei !!\nWelcome to our community \nThis graphql is the equivalent of calling collection.query.hybrid in sequence \nYou can certainly leverage some of the tools that frameworks like langchain or llamaindex has to offer.\nHere for example, we have a recipe on how to use llamaindex Router Query Engine:\n\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/llm-frameworks/llamaindex at main · weaviate/recipes\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYou basically describe each collection, and it will check how close your query is to each query engine description and decide based on that.\nLet me know if this helps.\nThanks!\n\n----------\n\n[roei.nuvei (2025-02-04T14:19:24.523Z)]: Hey @DudaNogueira , thanks for the quick response.\nMy main question is about querying all collections at once, is that supported?\nI saw you had the Explore function but it seems to be disabled\n\n----------\n\n[Dirk (2025-02-04T14:31:56.868Z)]: roei.nuvei:\n\nMy main question is about querying all collections at once, is that supported?\n\n\nNot directly. However we have an async client for python, so you can query them all concurrently by yourself with asyncio.gather (random link that looked ok)\n\nI saw you had the Explore function but it seems to be disabled\n\nExplore is very outdated and basically dead",
    "date_created": "2025-02-04T08:07:09.870Z",
    "has_accepted_answer": false,
    "title": "Querying Multiple Collections Dynamically in Weaviate v4",
    "topic_id": 10012
  },
  {
    "user_id": 10376,
    "conversation": "[Satyam_Namdev (2025-03-11T19:46:10.134Z)]: I was trying to get Make ETL pipelines from aws-S3 to Weaviate for multiple users, But couldn’t find a way to utilize Weaviate’s Multi-Tenancy via Unstructured.\nNow, I’m creating separate Collection for Each User !\nIs there any alternative for this?\n\n----------\n\n[Mohamed_Shahin (2025-03-17T10:59:18.971Z)]: Hey @Satyam_Namdev,\nWelcome to the community!\nI get the challenge you’re facing, and honestly, I’d highly recommend Multi-Tenancy for your use case—it’s much better for schema operations and overall performance.\nAre you saying that with Unstructured, you can’t configure a collection with Multi-Tenancy enabled and then ingest from S3 directly into a tenant instead of the collection?\nWould love to understand more about your setup! and code as well if possible.",
    "date_created": "2025-03-11T19:46:09.993Z",
    "has_accepted_answer": false,
    "title": "Multi-Tenant support for Unstructured ETL Pipelines!",
    "topic_id": 18716
  },
  {
    "user_id": 650,
    "conversation": "[fairymane (2024-09-16T08:36:25.345Z)]: Description\n\nI use the following two option to delete object:\n\n\n\n\nlog_name = ‘**’\ndelete_response = collection.data.delete_many(\nwhere=Filter.by_property(“log_name”).equal(log_name)\n)\n\n2.>\n\n…\nwhile not query_response or (len(query_response.objects) > 0 and failed_batch_delete_count < 5):\nquery_response = collection.query.fetch_objects(\nfilters=Filter.by_property(“log_date”).equal(log_date.replace(tzinfo=timezone.utc)),\nlimit=batch_size,\n)\nif len(query_response.objects) > 0:\ndelete_response = collection.data.delete_many(\nwhere=Filter.by_id().contains_any([object.uuid for object in query_response.objects]),\n)\n…\n\nIn both cases, it seems not all the objects match the filter conditions were deleted, a.k.a there would be some object matches the filter remains:\nquery_response = collection.query.fetch_objects(\nfilters=Filter.by_property(“log_date”).equal(log_date.replace(tzinfo=timezone.utc)),\nlimit=batch_size,\n)\nwould still return some matched objects.\nWhat is the problem?  Is the index apply to all the properties?\nNote this does not happen when the collection size is small, e.g. ~ 1M\nBut happens when collection size is large, e.g. ~200M.\nServer Setup Information\n\nWeaviate Server Version:  v17.0.0\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 7\nClient Language and Version: 4.7.1\nMultitenancy?: No\n\nAny additional Information\n\n----------\n\n[andrewisplinghoff (2024-09-16T17:49:06.540Z)]: This sounds a bit similar to the issue Some objects not readable after batch import / flush and switch failed - Support - Weaviate Community Forum we are having from time to time. Could you try if in your case the affected objects are retrievable when using the same filter as in your delete? Also, it would be interesting if you encounter similar errors in the logs as in that ticket. If possible, also try restarting the Weaviate instances to see if that allows for the objects to be found again as that helped in our case.\nAlso I saw you are using a very old Weaviate version, is there a reason for that?",
    "date_created": "2024-09-16T08:36:25.302Z",
    "has_accepted_answer": false,
    "title": "Deletion (delete_many with filter) not fully delete all the matched objects",
    "topic_id": 4169
  },
  {
    "user_id": 574,
    "conversation": "[Kavali_Kranthi_Kumar (2024-02-02T11:17:24.822Z)]: panic: runtime error: slice bounds out of range [:1066] with capacity 922\n\n\n\ngoroutine 132 [running]:\n\ngithub.com/weaviate/weaviate/usecases/byteops.(*ReadWriter).CopyBytesFromBuffer(...)\n\n\t/go/src/github.com/weaviate/weaviate/usecases/byteops/byteops.go:77\n\ngithub.com/weaviate/weaviate/adapters/repos/db/lsmkv/segmentindex.(*DiskTree).readNode(0x4002243c00?, {0xffff6ceaf320, 0x39a, 0x39a})\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/segmentindex/disk_tree.go:106 +0x448\n\ngithub.com/weaviate/weaviate/adapters/repos/db/lsmkv/segmentindex.(*DiskTree).AllKeys(0x4002eba930)\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/segmentindex/disk_tree.go:180 +0x8c\n\ngithub.com/weaviate/weaviate/adapters/repos/db/lsmkv.(*segment).computeAndStoreBloomFilter(0x40031203c0, {0x4003200770, 0x70})\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/segment_bloom_filters.go:88 +0x38\n\ngithub.com/weaviate/weaviate/adapters/repos/db/lsmkv.(*segment).initBloomFilter(0x40031203c0)\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/segment_bloom_filters.go:75 +0x90\n\ngithub.com/weaviate/weaviate/adapters/repos/db/lsmkv.(*segment).initBloomFilters(0x40031203c0, 0xffff6ceae000?)\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/segment_bloom_filters.go:38 +0x28\n\ngithub.com/weaviate/weaviate/adapters/repos/db/lsmkv.newSegment({0x4003200310, 0x6d}, {0x181bc18?, 0x4002b638f0}, 0x0, 0x0?, 0x1, 0x1, 0x1)\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/segment.go:150 +0x738\n\ngithub.com/weaviate/weaviate/adapters/repos/db/lsmkv.newSegmentGroup({0x181bc18, 0x4002b638f0}, 0x0, {0x17fca40, 0x40031d4840}, {{0x40030facd0, 0x4e}, {0x13f7698, 0xa}, 0x0, ...})\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/segment_group.go:140 +0x654\n\ngithub.com/weaviate/weaviate/adapters/repos/db/lsmkv.NewBucket({0x1805c08, 0x2410b20}, {0x40030facd0, 0x4e}, {0x40030e9280, 0x36}, {0x181bc18?, 0x4002b638f0?}, 0x0, {0x17fca40, ...}, ...)\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/bucket.go:151 +0x2b4\n\ngithub.com/weaviate/weaviate/adapters/repos/db/lsmkv.(*Store).CreateOrLoadBucket(0x40031d47e0, {0x1805c08, 0x2410b20}, {0x40031bf3b0, 0x13}, {0x4002f54960, 0x4, 0x6})\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/lsmkv/store.go:122 +0xec\n\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).createPropertyValueIndex(0x40031201e0, {0x1805c08, 0x2410b20}, 0x40026e97a0)\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard.go:660 +0x4b8\n\ngithub.com/weaviate/weaviate/adapters/repos/db.(*Shard).createPropertyIndex.func1()\n\n\t/go/src/github.com/weaviate/weaviate/adapters/repos/db/shard.go:609 +0x48\n\ngolang.org/x/sync/errgroup.(*Group).Go.func1()\n\n\t/go/pkg/mod/golang.org/x/sync@v0.3.0/errgroup/errgroup.go:75 +0x58\n\ncreated by golang.org/x/sync/errgroup.(*Group).Go in goroutine 16\n\n\t/go/pkg/mod/golang.org/x/sync@v0.3.0/errgroup/errgroup.go:72 +0x98\n\n----------\n\n[DudaNogueira (2024-02-06T17:17:49.019Z)]: Hi @Kavali_Kranthi_Kumar !\nWelcome to our community.\nDoes this happend when you perform any action or on start up?\nAlso, what is the version you are using?\n\n----------\n\n[J_Marcos_del_Ser (2024-04-08T21:59:19.135Z)]: To me it happens when trying to fetch all objects of my class Chunk using offset 10000, or trying to use a limit higher than 10000:\nCode:\nchunks_query_response_1 = (\nclient.query\n.get(“Chunk”,“post_id”)\n.with_limit(10000)\n.do()\n)\nchunks_query_response_2 = (\nclient.query\n.get(“Chunk”,“post_id”)\n# .with_limit(10000)\n.with_offset(10000)\n.do()\n)\nSchema:\nclass_Document= {\n“class”: “Document”,\n“description”: “Represents a document with metadata and associated text chunks.”,\n“properties”: [\n{\n“name”: “tags”,\n“dataType”: [“string”],\n“description”: “Tags from WordPress”\n},\n{\n“name”: “categories”,\n“dataType”: [“string”],\n“description”: “Categories from WordPress”\n},\n{\n“name”: “postUpdatedAt”,\n“dataType”: [“date”],\n“description”: “WordPress post last updated timestamp”\n},\n{\n“name”: “title”,\n“dataType”: [“string”],\n“description”: “Title of the post”\n},\n{\n“name”: “author”,\n“dataType”: [“string”],\n“description”: “author of the post”\n},\n{\n“name”: “permalink”,\n“dataType”: [“string”],\n“description”: “Link of the post”\n},\n{\n“name”: “post_id”,\n“dataType”: [“int”],\n“description”: “WordPress ID for the post”\n},\n{\n“name”: “post_type”,\n“dataType”: [“string”],\n“description”: “Type of the post, e.g., report, blog, etc.”\n}\n]\n}\nclass_Chunk= {\n“class”: “Chunk”,\n“description”: “Represents a chunk of text from a document.”,\n“vectorizer”: “text2vec-openai”,\n“moduleConfig”: {\n“text2vec-openai”: {\n“model”: “text-embedding-3-large”,\n“type”: “text”,\n“dimensions”:1024\n}\n},\n“properties”: [\n{\n“name”: “text”,\n“dataType”: [“text”],\n“description”: “Plain text of the chunk”,\n“moduleConfig”: {\n“text2vec-openai”: {\n“skip”: False\n}\n}\n},\n{\n“name”: “post_id”,\n“dataType”: [“int”],\n“description”: “WordPress ID for the post”,\n“moduleConfig”: {\n“text2vec-openai”: {\n“skip”: True\n}\n}\n}\n]\n}\n\n----------\n\n[DudaNogueira (2024-04-12T13:51:32.987Z)]: HI @J_Marcos_del_Ser ! Welcome to our community \nDoes it also happens with the new python client v4?\nthe v3 client only uses REST, while v4 uses GRPC and that brings a huge improvement in connectivity.\nThis may be reaching a connection limit\nLet me know if this helps!\n\n----------\n\n[hanumanhuda (2024-07-24T06:02:54.887Z)]: I am also getting the similar error with Azure File share and as per my analysis and community this issue happens with Azure file share.\n( here and here,)\n\n----------\n\n[DudaNogueira (2024-07-24T20:58:07.745Z)]: Hi!\nPlease, can you create a new forum thread ?\nAlso, provide the request infos, specially server version.\nThanks!\n\n----------\n\n[DudaNogueira (2024-07-24T20:58:10.979Z)]: ",
    "date_created": "2024-02-02T11:17:24.764Z",
    "has_accepted_answer": false,
    "title": "Weaviate crashing because of following error, can someone help on this",
    "topic_id": 1359
  },
  {
    "user_id": 3241,
    "conversation": "[Nicolas_Lurkin (2025-01-20T09:23:40.658Z)]: Description\nWhenever I instantiate a client connection to a weaviate database within a gRPC server (not even using the connection), I get such errors when making parallel calls to the gRPC route:\nException in callback PollerCompletionQueue._handle_events(<_UnixSelecto...e debug=False>)()\nhandle: <Handle PollerCompletionQueue._handle_events(<_UnixSelecto...e debug=False>)()>\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"src/python/grpcio/grpc/_cython/_cygrpc/aio/completion_queue.pyx.pxi\", line 147, in grpc._cython.cygrpc.PollerCompletionQueue._handle_events\nBlockingIOError: [Errno 35] Resource temporarily unavailable\n\nServer Setup Information\n\nWeaviate Server Version: 1.25.13\nDeployment Method:  docker\nMulti Node? Number of Running Nodes: Single node\nClient Language and Version: Python client 4.10.4\nMultitenancy?: No\n\nAny additional Information\nHere is a minimal code that reproduces the issue:\ntest.proto\nsyntax = \"proto3\";\nimport \"google/protobuf/empty.proto\";\n\nservice TestService{\n rpc TestRoute(google.protobuf.Empty) returns (TestMessage) {};\n}\n\nmessage TestMessage {\n string test = 1;\n}\n\ntest_server.py\nimport asyncio\n\nimport grpc\nimport test_pb2 as pb2\nimport test_pb2_grpc as pb2_grpc\nimport weaviate\n\n\nclass DocumentServer(pb2_grpc.TestServiceServicer):\n\n    def __init__(self):\n        self.client = weaviate.connect_to_custom(\n            http_host=\"localhost\",\n            http_port=8080,\n            http_secure=False,\n            grpc_host=\"localhost\",\n            grpc_port=50051,\n            grpc_secure=False,\n        )\n\n    def TestRoute(self, request, context):\n        return pb2.TestMessage(test=\"Hello, World!\")\n\n    async def serve(self, port):\n        server = grpc.aio.server()\n        pb2_grpc.add_TestServiceServicer_to_server(self, server)\n        server.add_insecure_port(f\"[::]:{port}\")\n        await server.start()\n        await server.wait_for_termination()\n\n\nif __name__ == \"__main__\":\n    server = DocumentServer()\n    asyncio.run(server.serve(50052))\n\ntest_client.py\nfrom threading import Thread\n\nimport grpc\nimport test_pb2_grpc as pb2_grpc\nfrom google.protobuf import empty_pb2\n\n\nclass TestClient(object):\n    def __init__(self, host, server_port):\n        self.host = host\n        self.server_port = server_port\n\n    def test_route(\n        self,\n    ):\n        with grpc.insecure_channel(\n            \"{}:{}\".format(self.host, self.server_port)\n        ) as channel:\n            stub = pb2_grpc.TestServiceStub(channel)\n            return stub.TestRoute(empty_pb2.Empty())\n\n\ndef run_test():\n    client = TestClient(\"localhost\", 50052)\n    print(client.test_route())\n\n\nif __name__ == \"__main__\":\n    threads = []\n    for _ in range(10):\n        threads.append(Thread(target=run_test))\n\n    for thread in threads:\n        thread.start()\n\n    for thread in threads:\n        thread.join()\n\nCommenting out the line self.client = weaviate.connect_to_custom(... in the DocumentServer, the error does not appear anymore\n\n----------\n\n[DudaNogueira (2025-01-24T20:10:46.333Z)]: hi @Nicolas_Lurkin !!\nWelcome to our community \nCan you check if this also happens on latest (1.28.3)?\nI was not able to run to missing import test_pb2_grpc as pb2_grpc\nIs that a lib?\nThanks!\n\n----------\n\n[Nicolas_Lurkin (2025-01-27T07:29:05.713Z)]: Thanks for your help.\nThose files are those that are automatically generated by gRPC (with the command\npython3 -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. ./test.proto)\nI can try a new version of the weaviate database, but I have the feeling that this is linked to the python client. If I revert to an older version (4.6.5 for instance), the problem is not present.\n\n----------\n\n[Nicolas_Lurkin (2025-01-27T08:14:45.703Z)]: I confirm that switching to weaviate database version 1.28.3 changes nothing.\n\n----------\n\n[tsmith023 (2025-01-27T14:58:08.622Z)]: Hi @Nicolas_Lurkin, thanks for raising this one!\nThis specific issue is emitted by the grpc library under-the-hood but is benign and doesn’t signify a serious error .Here is the open issue (nearly four years old at this point )\nThe reason that you see this with our client is because the sync client creates a sidecar event loop thread where it runs its fundamental async methods in. I see in your MRE that you run your gRPC server with asyncio. To avoid seeing these types of errors I’d recommend using the async client with it. Then you shouldn’t see any such errors. E.g.:\nclass DocumentServer(pb2_grpc.TestServiceServicer):\n\n    def __init__(self):\n        self.client = weaviate.use_async_with_custom(\n            http_host=\"localhost\",\n            http_port=8080,\n            http_secure=False,\n            grpc_host=\"localhost\",\n            grpc_port=50051,\n            grpc_secure=False,\n        )\n\n    def TestRoute(self, request, context):\n        return pb2.TestMessage(test=\"Hello, World!\")\n\n    async def serve(self, port):\n        # must connect manually since use_async_x doesn't do any \n        # connecting as it involves I/O and so returns a Coroutine\n        await self.client.connect()\n\n        server = grpc.aio.server()\n        pb2_grpc.add_TestServiceServicer_to_server(self, server)\n        server.add_insecure_port(f\"[::]:{port}\")\n        await server.start()\n        await server.wait_for_termination()\n\nI hope that works for you, let me know if it doesn’t!",
    "date_created": "2025-01-20T09:23:40.604Z",
    "has_accepted_answer": false,
    "title": "\"[Errno 35] Resource temporarily unavailable\" when client instantiated in a gRPC server",
    "topic_id": 9820
  },
  {
    "user_id": 948,
    "conversation": "[Rajesh_Kumar_Boda (2024-05-16T16:27:21.258Z)]: Description\nI installed weaviate on a openshift cluster using the helm chart. I can able to acess the v1/schema endpoint. But when I try to access any other endpoint, I am getting application not available error. What could be the problem\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: Helm\nChart name\nweaviate\nChart version\n16.8.8\nApp version\n1.24.8\n\n----------\n\n[DudaNogueira (2024-05-16T18:16:46.199Z)]: hi @Rajesh_Kumar_Boda! Welcome to our community!\nDo you see all pods running as expected?\nAny outstanding logs from pods or service or events?\nThanks!\n\n----------\n\n[Rajesh_Kumar_Boda (2024-05-17T05:45:37.390Z)]: Hi @DudaNogueira Thank you for welcoming.\nyes, I see all pods are running.\nI tried deploying by manually creating deployment and service yaml. Even then I saw the same issue. After changing the default path to “/” instead of “/v1/search”, I was able to access all Urls. Now I am trying to see If I can change the default path to “/” when deployed through Helm. I cannot find any such field in Values.yaml to change the default path. I keep trying that. Let me know If you have any thoughts. Thank you in advance.\n\n----------\n\n[DudaNogueira (2024-05-17T19:42:48.626Z)]: Hi!\nI wouldn’t remove the /v1/* path as the clients will expect for that part.\nEven if you are not using a client and querying directly, this would remove this functionality.\n\n----------\n\n[Pie_Thib (2024-12-02T15:56:17.306Z)]: HI, did you have problem with grpc  port with openshift ?  I get the http port over openshift thats fine but I struggle with grpc . I create services and routes, all mappings is good but I think  the http2 is creating problem for openshift . any thoughts?",
    "date_created": "2024-05-16T16:27:21.209Z",
    "has_accepted_answer": false,
    "title": "Installing weaviate on openshift",
    "topic_id": 2360
  },
  {
    "user_id": 1979,
    "conversation": "[omarmhaimdat (2024-10-21T13:57:34.650Z)]: Description\nI am trying to deploy a Weaviate cluster using Docker Swarm or Docker Compose, but I’m encountering issues where the nodes fail to join the cluster. The problem seems to be related to network interface selection during the cluster setup, as the nodes are unable to resolve each other’s addresses despite being able to ping one another successfully.\nServer Setup Information\n\nWeaviate Server Version: 1.26.5\nDeployment Method: Docker Compose or Docker Swarm\nMulti Node? Number of Running Nodes: 3 nodes on symmetrical servers\n\nAny additional Information\n\nDocker network:\nShared network in the swarm\n\ndocker network create --driver overlay --subnet=10.11.0.0/16 weaviate_euler_net\n\n\nDocker Compose configuration:\n\nversion: '3.8'\n\nservices:\n  weaviate-node1:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.5\n    hostname: weaviate-node1\n    deploy:\n      replicas: 1\n      placement:\n        constraints: [node.hostname == euler-01]\n    ports:\n      - \"8080:8080\"\n      - \"50051:50051\"\n    environment:\n      - TRANSFORMERS_INFERENCE_API=http://gpu-server:1000\n      - QNA_INFERENCE_API=http://gpu-server:2000\n      - NER_INFERENCE_API=http://gpu-server:3000\n      - SUM_INFERENCE_API=http://gpu-server:4000\n      - SPELLCHECK_INFERENCE_API=http://gpu-server:5000\n      - RERANKER_INFERENCE_API=http://gpu-server:6000\n      - QUERY_DEFAULTS_LIMIT=25\n      - PERSISTENCE_DATA_PATH=/var/lib/weaviate\n      - DEFAULT_VECTORIZER_MODULE=text2vec-transformers\n      - ENABLE_MODULES=text2vec-transformers,qna-transformers,ner-transformers,sum-transformers,text-spellcheck,reranker-transformers\n      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=tr ue\n      - CLUSTER_HOSTNAME=weaviate-node1\n      - CLUSTER_GOSSIP_BIND_PORT=7100\n      - CLUSTER_DATA_BIND_PORT=7101\n      - RAFT_JOIN=weaviate-node1,weaviate-node2,weaviate-node3\n      - RAFT_BOOTSTRAP_EXPECT=3\n    volumes:\n      - weaviate_data_node1:/var/lib/weaviate\n    networks:\n      - weaviate_euler_net\n\n  weaviate-node2:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.5\n    hostname: weaviate-node2\n    deploy:\n      replicas: 1\n      placement:\n        constraints: [node.hostname == euler-02]\n    ports:\n      - \"8081:8080\"\n      - \"50052:50051\"\n    environment:\n      - TRANSFORMERS_INFERENCE_API=http://gpu-server:1000\n      - QNA_INFERENCE_API=http://gpu-server:2000\n      - NER_INFERENCE_API=http://gpu-server:3000\n      - SUM_INFERENCE_API=http://gpu-server:4000\n      - SPELLCHECK_INFERENCE_API=http://gpu-server:5000\n      - RERANKER_INFERENCE_API=http://gpu-server:6000\n      - QUERY_DEFAULTS_LIMIT=25\n      - PERSISTENCE_DATA_PATH=/var/lib/weaviate\n      - DEFAULT_VECTORIZER_MODULE=text2vec-transformers\n      - ENABLE_MODULES=text2vec-transformers,qna-transformers,ner-transformers,sum-transformers,text-spellcheck,reranker-transformers\n      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true\n      - CLUSTER_HOSTNAME=weaviate-node2\n      - CLUSTER_GOSSIP_BIND_PORT=7102\n      - CLUSTER_DATA_BIND_PORT=7103\n      - CLUSTER_JOIN=weaviate-node1:7100\n      - RAFT_JOIN=weaviate-node1,weaviate-node2,weaviate-node3\n      - RAFT_BOOTSTRAP_EXPECT=3\n    volumes:\n      - weaviate_data_node2:/var/lib/weaviate\n    networks:\n      - weaviate_euler_net\n\n  weaviate-node3:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.5\n    hostname: weaviate-node3\n    deploy:\n      replicas: 1\n      placement:\n        constraints: [node.hostname == euler-03]\n    ports:\n      - \"8082:8080\"\n      - \"50053:50051\"\n    environment:\n      - TRANSFORMERS_INFERENCE_API=http://gpu-server:1000\n      - QNA_INFERENCE_API=http://gpu-server:2000\n      - NER_INFERENCE_API=http://gpu-server:3000\n      - SUM_INFERENCE_API=http://gpu-server:4000\n      - SPELLCHECK_INFERENCE_API=http://gpu-server:5000\n      - RERANKER_INFERENCE_API=http://gpu-server:6000\n      - QUERY_DEFAULTS_LIMIT=25\n      - PERSISTENCE_DATA_PATH=/var/lib/weaviate\n      - DEFAULT_VECTORIZER_MODULE=text2vec-transformers\n      - ENABLE_MODULES=text2vec-transformers,qna-transformers,ner-transformers,sum-transformers,text-spellcheck,reranker-transformers\n      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true\n      - CLUSTER_HOSTNAME=node3\n      - CLUSTER_GOSSIP_BIND_PORT=7104\n      - CLUSTER_DATA_BIND_PORT=7105\n      - CLUSTER_JOIN=weaviate-node1:7100\n      - RAFT_JOIN=weaviate-node1,weaviate-node2,weaviate-node3\n      - RAFT_BOOTSTRAP_EXPECT=3\n    volumes:\n      - weaviate_data_node3:/var/lib/weaviate\n    networks:\n      - weaviate_euler_net\n\nvolumes:\n  weaviate_data_node1:\n  weaviate_data_node2:\n  weaviate_data_node3:\n\nnetworks:\n  weaviate_euler_net:\n    external: true\n\n\nLaunch Command:\n\ndocker stack deploy --compose-file docker-compose.yaml --with-registry-auth weaviate\n\n\nDeployment output:\n\nweaviate_weaviate-node3.1.uos43z7w2kar@euler-03    | {\"action\":\"bootstrap\",\"build_git_commit\":\"353d907\",\"build_go_version\":\"go1.22.7\",\"build_image_tag\":\"1.26.5\",\"build_wv_version\":\"1.26.5\",\"join_list\":{\"weaviate-node1\":8300,\"weaviate-node2\":8300,\"weaviate-node3\":8300},\"level\":\"warning\",\"msg\":\"unable to resolve any node address to join\",\"time\":\"2024-10-16T14:52:05Z\"}\nweaviate_weaviate-node3.1.uos43z7w2kar@euler-03    | {\"action\":\"bootstrap\",\"build_git_commit\":\"353d907\",\"build_go_version\":\"go1.22.7\",\"build_image_tag\":\"1.26.5\",\"build_wv_version\":\"1.26.5\",\"join_list\":{\"weaviate-node1\":8300,\"weaviate-node2\":8300,\"weaviate-node3\":8300},\"level\":\"warning\",\"msg\":\"unable to resolve any node address to join\",\"time\":\"2024-10-16T14:52:06Z\"}\nweaviate_weaviate-node3.1.uos43z7w2kar@euler-03    | {\"action\":\"bootstrap\",\"build_git_commit\":\"353d907\",\"build_go_version\":\"go1.22.7\",\"build_image_tag\":\"1.26.5\",\"build_wv_version\":\"1.26.5\",\"join_list\":{\"weaviate-node1\":8300,\"weaviate-node2\":8300,\"weaviate-node3\":8300},\"level\":\"warning\",\"msg\":\"unable to resolve any node address to join\",\"time\":\"2024-10-16T14:52:08Z\"}\nweaviate_weaviate-node3.1.uos43z7w2kar@euler-03    | {\"action\":\"bootstrap\",\"build_git_commit\":\"353d907\",\"build_go_version\":\"go1.22.7\",\"build_image_tag\":\"1.26.5\",\"build_wv_version\":\"1.26.5\",\"join_list\":{\"weaviate-node1\":8300,\"weaviate-node2\":8300,\"weaviate-node3\":8300},\"level\":\"warning\",\"msg\":\"unable to resolve any node address to join\",\"time\":\"2024-10-16T14:52:09Z\"}\n\nMeanwhile hosts are resolved on other nodes, so there are clearly in the same network and using the correct network interface:\n➜  ~ docker exec -it weaviate_weaviate-node3.1.uos43z7w2kark46wsfjt8o6vc ping weaviate-node1\nPING weaviate-node1 (10.11.4.186): 56 data bytes\n64 bytes from 10.11.4.186: seq=0 ttl=64 time=0.056 ms\n64 bytes from 10.11.4.186: seq=1 ttl=64 time=0.097 ms\n64 bytes from 10.11.4.186: seq=2 ttl=64 time=0.099 ms\n64 bytes from 10.11.4.186: seq=3 ttl=64 time=0.097 ms\n64 bytes from 10.11.4.186: seq=4 ttl=64 time=0.103 ms\n64 bytes from 10.11.4.186: seq=5 ttl=64 time=0.097 ms\n64 bytes from 10.11.4.186: seq=6 ttl=64 time=0.101 ms\n64 bytes from 10.11.4.186: seq=7 ttl=64 time=0.097 ms\n^C\n--- weaviate-node1 ping statistics ---\n8 packets transmitted, 8 packets received, 0% packet loss\nround-trip min/avg/max = 0.056/0.093/0.103 ms\n\nI feel like RAFT_JOIN and CLUSTER_HOSTNAME are not correctly resolved with the correct network interface, no matter what hosts you specify it picks another host, so even if you specify the public IP (I know, it’s not good but just for testing) all nodes will try to join with docker network interface. I don’t understand this behavior.\nThe same logic applies with a simple docker compose file on each node using public/private IPs.\n\n----------\n\n[DudaNogueira (2024-10-21T21:39:05.948Z)]: hi @omarmhaimdat !!\nWelcome to our community \nI started playing around with deploying a multi node using docker swarm, using as a base our multi node docker compose example.\nWhile the docker compose without swarm works just fine, I was also not able to spin it on docker swarm, also with some connectivity issues and nodes not being able to reach its peers.\nI will dig further into this topic this week, and will report my findings here.\nI also agree that while K8s is a great tools for such a deployment, it may be overkill in some scenarios \nThanks!",
    "date_created": "2024-10-21T13:57:34.582Z",
    "has_accepted_answer": false,
    "title": "Weaviate Cluster Deployment on Docker Swarm/Docker Compose Fails Due to Node Address Resolution",
    "topic_id": 5822
  },
  {
    "user_id": 11544,
    "conversation": "[cyf121232145 (2025-03-31T08:31:22.135Z)]: Description\nHelp, when I use local asynchronous connection to the database, I want to use the afrom_documents to insert data, and I always get the error ‘coroutine’ object has no attribute ‘multi_tenancy_config’\nIs this because the method is not suitable? How do I insert attributed fragments into the database asynchronously, like a from_documents in a synchronous operation? I’ve noticed that there’s a method insert_many(), but there’s a saying that this will request all fragments to be inserted at once. Is there a good way to insert asynchronously.\nServer Setup Information\nWeaviate Server Version:  Weaviate服务器版本：\nName: weaviate-client  名称：weaviate-client\nVersion: 4.11.1  版本：4.11.1\nAny additional Information\n\n----------\n\n[DudaNogueira (2025-03-31T13:56:10.239Z)]: hi @cyf121232145 !!\nAre you using some a framework, for example llamaindex or langchain?\nCan you share some code where we could try reproducing it?\nThanks!\n\n----------\n\n[cyf121232145 (2025-04-01T01:55:10.164Z)]: i’m using langgraph,but now i’ve solved this problem,\nasync def load_documents(\nself,\ndocuments: List[Any],\nmethod: str = “from_documents”,\nmetadatas: Optional[List[Dict]] = None\n) → None:\n“”\"\n加载文档到Weaviate集合（使用insert_many批量插入）\n    Args:\n        documents: 文档列表（LangChain Document 对象）\n        method: 保留参数（兼容旧接口，实际不再使用）\n        metadatas: 保留参数（兼容旧接口，实际不再使用）\n    \"\"\"\n    # 获取Weaviate集合\n    collection = self.client.collections.get(self.config.collection_name)\n    \n    # 准备批量插入数据\n    objects_to_insert = []\n    for doc in documents:\n        obj = {\n            \"content\": doc.page_content,\n            \"source\": doc.metadata.get(\"source\", \"\"),\n            \"page\": doc.metadata.get(\"page\", 0),\n            # 可以添加其他metadata字段\n            \"document_type\": doc.metadata.get(\"document_type\", \"unknown\")\n        }\n        objects_to_insert.append(obj)\n    \n    # 批量插入数据\n    try:\n        response = await collection.data.insert_many(objects_to_insert)\n        print(f\"成功插入 {len(response.all_responses)} 个文档块\")\n        print(f\"失败 {len(response.errors)} 个（如果有）\")\n        return response\n    except Exception as e:\n        print(f\"文档插入失败: {str(e)}\")\n        raise\n\ni’ve got another question。\nasync def aenter(self):\n“”“初始化 Weaviate 客户端”“”\ntry:\n# self.client =weaviate.use_async_with_local(\n#     port=self.config.weaviate_port,\n#     headers={\n#         “X-OpenAI-Api-Key”: self.config.openai_api_key,\n#         “X-OpenAI-Baseurl”: self.config.openai_base_url,\n#     },\n# )\nself.client = WeaviateAsyncClient(\nconnection_params=ConnectionParams.from_params(\nhttp_host=self.config.http_host,\nhttp_port=self.config.http_port,\nhttp_secure=self.config.http_secure,\ngrpc_host=self.config.grpc_host,\ngrpc_port=self.config.grpc_port,\ngrpc_secure=self.config.grpc_secure,\n),\n# auth_client_secret=Auth.api_key(“secr3tk3y”),\nadditional_headers={\n“X-OpenAI-Api-Key”: self.config.openai_api_key,\n“X-OpenAI-Baseurl”: self.config.openai_base_url,\n},\nadditional_config=AdditionalConfig(\ntimeout=Timeout(init=30, query=60, insert=120),  # Values in seconds\n),\nskip_init_checks=False\n)\n        await self.client.connect()  # 确保 Weaviate 连接\n        \n        \n        self.vectorstore = await WeaviateVectorStore(\n            client=self.client,\n            index_name=self.config.collection_name,\n            text_key=\"text\",\n            embedding=self.embeddings\n        )\n        \n        print(f\"Weaviate 连接状态: {await self.client.is_ready()}\")\n        return self\n    except Exception as e:\n        print(f\"Weaviate 初始化失败: {e}\")\n        raise\n\nerror\nWeaviate 初始化失败: ‘coroutine’ object has no attribute ‘multi_tenancy_config’\nTraceback (most recent call last):\nFile “/home/wyk/zxz_test_0327/answer_weaviate_async.py”, line 68, in \nasyncio.run(main())\nFile “/usr/lib/python3.11/asyncio/runners.py”, line 188, in run\nreturn runner.run(main)\n^^^^^^^^^^^^^^^^\nFile “/usr/lib/python3.11/asyncio/runners.py”, line 120, in run\nreturn self._loop.run_until_complete(task)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “/usr/lib/python3.11/asyncio/base_events.py”, line 650, in run_until_complete\nreturn future.result()\n^^^^^^^^^^^^^^^\nFile “/home/wyk/zxz_test_0327/answer_weaviate_async.py”, line 31, in main\nasync with VectorStoreManager(config) as vector_manager:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “/home/wyk/zxz_test_0327/utils/VectorStoreManager_weaviate_v1_async.py”, line 90, in aenter\nself.vectorstore = await WeaviateVectorStore(\n^^^^^^^^^^^^^^^^^^^^\nFile “/home/wyk/.local/lib/python3.11/site-packages/langchain_weaviate/vectorstores.py”, line 126, in init\n).multi_tenancy_config.enabled\n^^^^^^^^^^^^^^^^^^^^\nAttributeError: ‘coroutine’ object has no attribute ‘multi_tenancy_config’\nsys:1: RuntimeWarning: coroutine ‘_ConfigCollectionAsync.get’ was never awaited\nThis doesn’t mean I can’t wrap an asynchronous client with await WeaviateVectorStore().",
    "date_created": "2025-03-31T08:31:22.089Z",
    "has_accepted_answer": true,
    "title": "Async insert question",
    "topic_id": 20424
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-12-20T19:41:31.014Z)]: Description\nIt’s coming from the Weavaite cluster, not our server at all, tested it on 2 devices, please help / fix this fast!!\nweaviate.exceptions.UnexpectedStatusCodeError: Object was not added! Unexpected status code: 500, with response body: {'error': [{'message': 'put object: import into index nodes: put local object: shard=\"OqM7QKj5G0Vhse46WmL22K35pXT2\": flush prop length tracker to disk: open /var/lib/weaviate/nodes/OqM7QKj5G0Vhse46WmL22K35pXT2/proplengths.tmp: no space left on device'}]}\n\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-12-20T19:47:41.242Z)]: Hi @Tejas_Sharma !\nIs this in one of our hosted clusters?\nThe error indicates that there is no space left in disk.\n\n----------\n\n[Tejas_Sharma (2024-12-20T20:01:23.357Z)]: Hey @DudaNogueira yes it’s coming from the hosted, and at first I thought it was our server, but no, I tested across multiple devices, the error is coming directly from the node on Weaviate\n\n----------\n\n[DudaNogueira (2024-12-20T20:41:54.394Z)]: Hi! Issue was solved.\nFor any issues with our clusters hosted in our cloud, please, use this channel for faster responses:\n\n  \n\n      console.weaviate.cloud\n  \n\n  \n    \n\nWeaviate Cloud\n\n  Weaviate Cloud\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!",
    "date_created": "2024-12-20T19:41:30.968Z",
    "has_accepted_answer": true,
    "title": "URGENT bug!",
    "topic_id": 9367
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-09-23T22:53:12.464Z)]: As a prototype, I was passing the base64 encoding of an image to a property in the record (‘i.e. imageData’). However, I think this might stress the Weaviate database, so I was wondering if it would be okay to store images in the Weaviate database this way.\n\n----------\n\n[Mohamed_Shahin (2024-09-24T09:10:32.263Z)]: Good morning @Tejas_Sharma,\nIf I understand you correct, you are looking to efficiently store images. It’s perfectly right approach to store images in Weaviate as base64. This is how the blob data type is intended to function\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nData types | Weaviate\n\n  - Configuration: Schema\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThere is no specific file size limit for the blob data type in Weaviate, which means you can store large images. However, keep in mind that larger images may affect overall database performance, depending on your setup, the number of images stored and infrastructure.\nIf the concern is about stress on the DB in a heavy load production, then consider offload images to a storage such as AWS S3 and store references (URLs) in Weaviate instead. This way, the database handles smaller pieces of data, reducing memory and disk usage.\n\n----------\n\n[Tejas_Sharma (2024-09-24T15:14:57.026Z)]: Morning @Mohamed_Shahin , thanks for the response!\nI’m particularly using the serverless cloud from the Weaviate console, so I’m curious how it would impact performance and how large the images would have to be. Generally, it’s users uploading images so I expect it to be from all shapes and sizes, but since Weaviate is handling the underlying storage and infrastructure, I wanted to know if my base64 implementation was safe.\nThanks for the doc link, I just saw it and it says base64 is safe to use, but just wanted to confirm if it would not degrade performance for all tenants if one tenant for example uploads a lot of really large images.\n\n----------\n\n[Mohamed_Shahin (2024-09-25T10:18:37.443Z)]: @Tejas_Sharma\nIt’s indeed safe, and performance would depend on best practices and infrastructure to handle the load. However, I would highly recommend High Availability in Cloud to ensure reliability and performance, preventing stress on a single node.\nIf you face any issues or would like to run some checks, feel free to open a ticket with support@weaviate.io, and I’d be happy to review your cluster and recommend improvements if necessary.\n\n----------\n\n[Tejas_Sharma (2024-09-25T16:21:22.364Z)]: Mohamed_Shahin:\n\nHigh Availability in Cloud\n\n\nOh I see, is this supported natively in the Weaviate serverless architecture?\n\n----------\n\n[Mohamed_Shahin (2024-09-26T07:59:27.234Z)]: @Tejas_Sharma when you create a cloud cluster, there is an option to turn on HA, which will set up a 3-node cluster in the cloud. I highly recommend enabling this for better performance and reliability.",
    "date_created": "2024-09-23T22:53:12.422Z",
    "has_accepted_answer": true,
    "title": "Storing images in Weaviate",
    "topic_id": 4264
  },
  {
    "user_id": 11803,
    "conversation": "[iA_tashema (2025-03-26T00:59:20.354Z)]: Hi everyone,\nI’m evaluating Weaviate and I have a question regarding the pricing. On the public Weaviate Cloud page, it states that pricing starts at $25/month, with a storage cost of $0.095 per 1M vector dimensions per month.\nHowever, when I create a cluster, the pricing is significantly different: the minimum cost is $75/month, and the storage cost is $0.285 per 1M vector dimensions per month.\nDoes anyone know why these differences exist? Does the $25/month price apply only to specific plans, or is the public information outdated?\nAny insights would be greatly appreciated. Thanks!\nimage734×1446 102 KB\nimage1186×438 23.8 KB\n\n----------\n\n[maryannc (2025-03-26T01:05:39.260Z)]: Hi @iA_tashema ,\nGood Day! Welcome to Weaviate Community!\nBased from screenshot provided, the cluster you are creating is a High Availability Cluster which explains the estimate cost of $75/month. If you would like to spin up a non-HA Serverless Cluster, kindly disable Enable HIgh Availability toogle. This would set the cost estimate to $25/month.\nScreenshot 2025-03-26 at 9.04.49 AM790×120 3.59 KB\nHope this helps.",
    "date_created": "2025-03-26T00:59:20.306Z",
    "has_accepted_answer": true,
    "title": "Question about Weaviate pricing: Differences between public pricing and actual cluster pricing",
    "topic_id": 20316
  },
  {
    "user_id": 1214,
    "conversation": "[elias.gabriel (2024-07-24T17:50:56.587Z)]: Hi,\nI have 2 questions regarding the new GroupBy functionality with hybrid searches:\n\nCan you use a cross-reference as the property to group by? For example, running a hybrid search on a “DocChunk” collection and grouping by a cross-ref to the parent “Doc”.\nIf yes, what does the objects_per_group parameter actually do? If I set that to 1, does that mean each group will consist of the highest ranking object in that group of objects? Does that also mean that if I specify objects_per_group=1 and number_of_groups=20, I should expect to get back the top “DocChunk” object for 20 different “Doc” objects?\n\n----------\n\n[DudaNogueira (2024-07-25T19:29:34.980Z)]: hi @elias.gabriel !!\nThe only groupBy that will work with cross-reference, for now, is the Aggregate one:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAggregate | Weaviate - Vector Database\n\n  This page covers aggregation queries. They are collectively referred to as Aggregate queries within.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI have crafted this code to play around with it:\nimport weaviate\nfrom weaviate.util import generate_uuid5\nfrom weaviate import classes as wvc\nclient = weaviate.connect_to_local()\n\nclient.collections.delete(\"TestCategory\")\ncollection_category = client.collections.create(\n    \"TestCategory\",\n    properties=[\n        wvc.config.Property(\n            name=\"name\", data_type=wvc.config.DataType.TEXT),\n    ],\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(\n        base_url=\"http://host.docker.internal:1234\"\n        # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n    ),\n    generative_config=wvc.config.Configure.Generative.openai(\n        base_url=\"http://host.docker.internal:1234\"\n    )  # Ensure the `generative-openai` module is used for generative queries\n)\n\nclient.collections.delete(\"TestItem\")\ncollection_item = client.collections.create(\n    \"TestItem\",\n    properties=[\n        wvc.config.Property(name=\"title\", data_type=wvc.config.DataType.TEXT),\n        wvc.config.Property(name=\"flat_cat\", data_type=wvc.config.DataType.TEXT),\n    ],\n    references=[\n        wvc.config.ReferenceProperty(name=\"category\", target_collection=\"TestCategory\"),\n    ],\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(\n        base_url=\"http://host.docker.internal:1234\" # using LM Studio. Comment to use openai\n    ),\n    generative_config=wvc.config.Configure.Generative.openai(\n        base_url=\"http://host.docker.internal:1234\" # using LM Studio. Comment to use openai\n    ) \n)\n\nadding some data\ncollection_category.data.insert({\"name\": \"Home\"}, uuid=generate_uuid5(\"home\"))\ncollection_category.data.insert({\"name\": \"Car\"}, uuid=generate_uuid5(\"car\"))\n# car\ncollection_item.data.insert(\n    {\"title\": \"Natural Car Smell\", \"flat_cat\": \"cat\"}, \n    references={\"category\": generate_uuid5(\"car\")}\n)\ncollection_item.data.insert(\n    {\"title\": \"Natural Car Chair\", \"flat_cat\": \"cat\"}, \n    references={\"category\": generate_uuid5(\"car\")}\n)\n# home\ncollection_item.data.insert(\n    {\"title\": \"Natural Home Smell\", \"flat_cat\": \"home\"}, \n    references={\"category\": generate_uuid5(\"home\")}\n)\ncollection_item.data.insert(\n    {\"title\": \"Natural Home plants\", \"flat_cat\": \"home\"}, \n    references={\"category\": generate_uuid5(\"home\")}\n)\n\ngroup using aggregate:\nquery = collection_item.aggregate.over_all(\n    group_by=wvc.aggregate.GroupByAggregate(prop=\"category\")\n)\nfor group in query.groups:\n    print(group)\n\nthis will not work:\nquery = collection_item.query.hybrid(\n    query=\"nature\",\n    group_by=wvc.query.GroupBy(prop=\"category\", objects_per_group=1, number_of_groups=2)\n)\nfor object in query.objects:\n    print(object)\n\nthis will work. Note that I am using flat_cat property as the property to group by\nquery = collection_item.query.hybrid(\n    query=\"nature\",\n    group_by=wvc.query.GroupBy(prop=\"flat_cat\", objects_per_group=1, number_of_groups=2)\n)\nfor object in query.objects:\n    print(object)\n\nAlso, please, feel free to voice your feature request on this issue so we can channel all discussions on this topic there:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Improve Hybrid Search\n    \n\n    \n      \n        opened 10:18PM - 26 Feb 24 UTC\n      \n\n\n      \n        \n          \n          parkerduckworth\n        \n      \n    \n\n    \n    \n  \n\n\n  \n    ### Describe your feature request\n\nHybrid search is relatively new, and it's lac…king some functionality that would bring it into feature parity with the other more established searching methods.\n\nNamely, hybrid search should support:\n- `moveTo/moveAway`\n- distance/certainty filtering\n- property selection for `Aggregation{}` hybrid search (already supported for `Get{}` queries)\n- `groupBy` (this also needs to be supported by BM25)\n\nThere are already feature request issues open for some of these:\n- #3872\n- #4113\n\nBut having all these required features in one place is convenient, so here lies this issue\n\n### Code of Conduct\n\n- [X] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[elias.gabriel (2024-07-31T23:19:10.048Z)]: Hi,\nThanks for clarifying cross-refs can only be used in aggregate queries; I certainly support expanding that to other operators as well.\nWould you mind answering my second question as well?\n\n----------\n\n[DudaNogueira (2024-08-01T19:38:37.336Z)]: Oh, Sorry!\nYour assumption for the item 2 are correct, AFAIK.",
    "date_created": "2024-07-24T17:50:56.534Z",
    "has_accepted_answer": true,
    "title": "[Question] Hybrid GroupBy with cross-ref",
    "topic_id": 3156
  },
  {
    "user_id": 1178,
    "conversation": "[AbhiP (2024-07-09T11:58:24.780Z)]: Description\n\nHey, I have weviate version 1.25.2 running in a docker instance deployed on AWS EC2. I’m connecting to it via the weviate python client v4 (grpc connection).\nData object upload and data deletion seems to time out with no response from the server every day or two. And restarting the docker container fixes it (sometimes) for a while, but it goes back to a state where any data upload or deletion times out. How do I fix this?\nServer Setup Information\n\nWeaviate Server Version: 1.25.2\nDeployment Method: Docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python3.10 v4\nMultitenancy: Using collections only\n\nAny additional Information\nThese are some of the logs form the docker container:\n{“action”:“lsm_recover_from_active_wal”,“class”:“66879dbd3c40e9cdf”,“index”:“_66879dbd3c40e9cdf”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/66879dbd3c40e9cd1/3rPXMbHcJoMl/lsm/property__id/segment-1720443038073474385”,“shard”:“3rPXMbHcJoMl”,“time”:“2024-07-08T16:11:49Z”}\n{“level”:“info”,“msg”:“Completed loading shard 66879dbd3c40e9cdf_3rPXMbHcJoMl in 7.394234ms”,“time”:“2024-07-08T16:11:49Z”}\n{“index”:“6672b5b6cd7159bdb”,“level”:“info”,“msg”:“restore local index”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“hnsw_vector_cache_prefill”,“count”:5000,“index_id”:“main”,“level”:“info”,“limit”:1000000000000,“msg”:“prefilled vector cache”,“time”:“2024-07-08T16:11:49Z”,“took”:26883467}\n{“action”:“telemetry_push”,“level”:“info”,“msg”:“telemetry started”,“payload”:“\\u0026{MachineID:f6835ccc-31c8-4fe8-8442-90f075d8d2b3 Type:INIT Version:1.25.2 NumObjects:0 OS:linux Arch:arm64 UsedModules:}”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“6672b5b6cd7159”,“index”:“6672b5b6cd7159bdb”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/6672b5b6cd7159bd5/7EtZRTDHZyWY/lsm/objects/segment-1720454667233976221”,“shard”:“7EtZRTDHZyWY”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“6672b5b6cd7159bd”,“index”:“6672b5b6cd7159b”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/lsm/property_dataType/segment-1720454667243683422”,“shard”:“7EtZRTDHZyWY”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_6672b5b6cd7159bdb2f6b575”,“index”:“_6672b5b6cd7159bdb2f6b575”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/lsm/property_dataType_searchable/segment-1720454667250774444”,“shard”:“7EtZRTDHZyWY”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_6672b5b6cd7159bdb2f6b575”,“index”:“_6672b5b6cd7159bdb2f6b575”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/lsm/property_docName/segment-1720454300546997303”,“shard”:“7EtZRTDHZyWY”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_6672b5b6cd7159bdb2f6b575”,“index”:“_6672b5b6cd7159bdb2f6b575”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/lsm/property_docName_searchable/segment-1720454300550333412”,“shard”:“7EtZRTDHZyWY”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_6672b5b6cd7159bdb2f6b575”,“index”:“_6672b5b6cd7159bdb2f6b575”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/lsm/property_key/segment-1720454667258914344”,“shard”:“7EtZRTDHZyWY”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_6672b5b6cd7159bdb2f6b575”,“index”:“_6672b5b6cd7159bdb2f6b575”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/lsm/property_text/segment-1720454667265382584”,“shard”:“7EtZRTDHZyWY”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_6672b5b6cd7159bdb2f6b575”,“index”:“_6672b5b6cd7159bdb2f6b575”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/lsm/property_text_searchable/segment-1720454667272903507”,“shard”:“7EtZRTDHZyWY”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_6672b5b6cd7159bdb2f6b575”,“index”:“_6672b5b6cd7159bdb2f6b575”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/lsm/property__id/segment-1720454667280362040”,“shard”:“7EtZRTDHZyWY”,“time”:“2024-07-08T16:11:49Z”}\n{“level”:“info”,“msg”:“Completed loading shard _6672b5b6cd7159bdb2f6b575_7EtZRTDHZyWY in 3.9361ms”,“time”:“2024-07-08T16:11:49Z”}\n{“index”:“_66879e0b3c40e9cdf374f8ea”,“level”:“info”,“msg”:“restore local index”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“hnsw_vector_cache_prefill”,“count”:3000,“index_id”:“main”,“level”:“info”,“limit”:1000000000000,“msg”:“prefilled vector cache”,“time”:“2024-07-08T16:11:49Z”,“took”:91757}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_66879e0b3c40e9cdf374f8ea”,“index”:“_66879e0b3c40e9cdf374f8ea”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_66879e0b3c40e9cdf374f8ea/jSUejNL3pdFG/lsm/objects/segment-1720443037283495175”,“shard”:“jSUejNL3pdFG”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_66879e0b3c40e9cdf374f8ea”,“index”:“_66879e0b3c40e9cdf374f8ea”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_66879e0b3c40e9cdf374f8ea/jSUejNL3pdFG/lsm/property_docName/segment-1720443037284478051”,“shard”:“jSUejNL3pdFG”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_66879e0b3c40e9cdf374f8ea”,“index”:“_66879e0b3c40e9cdf374f8ea”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_66879e0b3c40e9cdf374f8ea/jSUejNL3pdFG/lsm/property_docName_searchable/segment-1720443037284928456”,“shard”:“jSUejNL3pdFG”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_66879e0b3c40e9cdf374f8ea”,“index”:“_66879e0b3c40e9cdf374f8ea”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_66879e0b3c40e9cdf374f8ea/jSUejNL3pdFG/lsm/property_key/segment-1720443037285297770”,“shard”:“jSUejNL3pdFG”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_66879e0b3c40e9cdf374f8ea”,“index”:“_66879e0b3c40e9cdf374f8ea”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_66879e0b3c40e9cdf374f8ea/jSUejNL3pdFG/lsm/property_text/segment-1720443037285733078”,“shard”:“jSUejNL3pdFG”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_66879e0b3c40e9cdf374f8ea”,“index”:“_66879e0b3c40e9cdf374f8ea”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_66879e0b3c40e9cdf374f8ea/jSUejNL3pdFG/lsm/property_text_searchable/segment-1720443037286143541”,“shard”:“jSUejNL3pdFG”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_66879e0b3c40e9cdf374f8ea”,“index”:“_66879e0b3c40e9cdf374f8ea”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_66879e0b3c40e9cdf374f8ea/jSUejNL3pdFG/lsm/property_dataType/segment-1720443037286500975”,“shard”:“jSUejNL3pdFG”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_66879e0b3c40e9cdf374f8ea”,“index”:“_66879e0b3c40e9cdf374f8ea”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_66879e0b3c40e9cdf374f8ea/jSUejNL3pdFG/lsm/property_dataType_searchable/segment-1720443037286748076”,“shard”:“jSUejNL3pdFG”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“lsm_recover_from_active_wal”,“class”:“_66879e0b3c40e9cdf374f8ea”,“index”:“_66879e0b3c40e9cdf374f8ea”,“level”:“warning”,“msg”:“active write-ahead-log found. Did weaviate crash prior to this? Trying to recover…”,“path”:“/var/lib/weaviate/_66879e0b3c40e9cdf374f8ea/jSUejNL3pdFG/lsm/property__id/segment-1720443037287251378”,“shard”:“jSUejNL3pdFG”,“time”:“2024-07-08T16:11:49Z”}\n{“level”:“info”,“msg”:“Completed loading shard _66879e0b3c40e9cdf374f8ea_jSUejNL3pdFG in 5.402865ms”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“hnsw_vector_cache_prefill”,“count”:3000,“index_id”:“main”,“level”:“info”,“limit”:1000000000000,“msg”:“prefilled vector cache”,“time”:“2024-07-08T16:11:49Z”,“took”:4717552}\n{“action”:“bootstrap”,“leader”:“172.25.0.2:8300”,“level”:“info”,“msg”:“successfully joined cluster”,“time”:“2024-07-08T16:11:49Z”}\n{“action”:“attach_tombstone_to_deleted_node”,“level”:“info”,“msg”:“found a deleted node (21) without a tombstone, tombstone was added”,“node_id”:21,“time”:“2024-07-08T16:15:06Z”}\n{“action”:“requests_total”,“api”:“rest”,“class_name”:“_6672b5b6cd7159bdb2f6b575”,“error”:“put object: import into index _6672b5b6cd7159bdb2f6b575: put local object: shard=\"7EtZRTDHZyWY\": update vector index: insert doc id 23 to vector index: find and connect neighbors: at level 0: pick entrypoint at level beginning: context deadline exceeded”,“level”:“error”,“msg”:\"unexpected\n{“action”:“hybrid”,“error”:“explorer: get class: vector search: object vector search at index _6672b5b6cd7159bdb2f6b575: shard _6672b5b6cd7159bdb2f6b575_7EtZRTDHZyWY: vector search: entrypoint was deleted in the object store, it has been flagged for cleanup and should be fixed in the next cleanup cycle”,“level”:“error”,“msg”:“denseSearch failed”,“time”:“2024-07-08T16:17:39Z”}\n{“action”:“hybrid”,“error”:“explorer: get class: vector search: object vector search at index _6672b5b6cd7159bdb2f6b575: shard _6672b5b6cd7159bdb2f6b575_7EtZRTDHZyWY: vector search: entrypoint was deleted in the object store, it has been flagged for cleanup and should be fixed in the next cleanup cycle”,“level”:“error”,“msg”:“denseSearch failed”,“time”:“2024-07-08T16:22:40Z”}\ntime=“2024-07-08T16:23:53Z” level=error msg=“unregistering callback ‘shard/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/vector/tombstone_cleanup’ of ‘index/_6672b5b6cd7159bdb2f6b575/vector/tombstone_cleanup’ failed: context deadline exceeded, unregistering callback ‘shard/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/geoProps/tombstone_cleanup’ of ‘index/_6672b5b6cd7159bdb2f6b575/geo_props/tombstone_cleanup’ failed: context deadline exceeded, unregistering callback ‘shard/_6672b5b6cd7159bdb2f6b575/7EtZRTDHZyWY/geo_props/commit_logger’ of ‘index/_6672b5b6cd7159bdb2f6b575/geo_props/commit_logger’ failed: context deadline exceeded” action=drop_shard class=_6672b5b6cd7159bdb2f6b575 id=_6672b5b6cd7159bdb2f6b575_7EtZRTDHZyWY\n{“action”:“delete_index”,“class”:“_6672b5b6cd7159bdb2f6b575”,“level”:“error”,“msg”:“drop: stop vector tombstone cleanup cycle: context deadline exceeded”,“time”:“2024-07-08T16:24:53Z”}\n{“level”:“warning”,“msg”:“prop len tracker file /var/lib/weaviate/_6672b5b6cd7159bdb2f6b575/ZW2YQ2tGWrQ1/proplengths does not exist, creating new tracker”,“time”:“2024-07-08T16:32:48Z”}\n{“level”:“info”,“msg”:“Created shard _6672b5b6cd7159bdb2f6b575_ZW2YQ2tGWrQ1 in 2.132659ms”,“time”:“2024-07-08T16:32:48Z”}\n{“action”:“hnsw_vector_cache_prefill”,“count”:1000,“index_id”:“main”,“level”:“info”,“limit”:1000000000000,“msg”:“prefilled vector cache”,“time”:“2024-07-08T16:32:48Z”,“took”:76692}\n{“level”:“warning”,“msg”:“prop len tracker file /var/lib/weaviate/_6676cbe571e518ab887dd0ae/hGkeYTzf7eMF/proplengths does not exist, creating new tracker”,“time”:“2024-07-08T16:34:26Z”}\n{“level”:“info”,“msg”:“Created shard _6676cbe571e518ab887dd0ae_hGkeYTzf7eMF in 761.399µs”,“time”:“2024-07-08T16:34:26Z”}\n{“action”:“hnsw_vector_cache_prefill”,“count”:1000,“index_id”:“main”,“level”:“info”,“limit”:1000000000000,“msg”:“prefilled vector cache”,“time”:“2024-07-08T16:34:26Z”,“took”:79843}\n{“action”:“tombstone_cleanup_begin”,“class”:“_6672b5b6cd7159bdb2f6b575”,“level”:“info”,“msg”:“class _6672b5b6cd7159bdb2f6b575: shard ZW2YQ2tGWrQ1: starting tombstone cleanup”,“shard”:“ZW2YQ2tGWrQ1”,“time”:“2024-07-08T16:37:48Z”,“tombstones_in_cycle”:1,“tombstones_total”:1}\n{“action”:“tombstone_cleanup_begin”,“class”:“_6676cbe571e518ab887dd0ae”,“level”:“info”,“msg”:“class _6676cbe571e518ab887dd0ae: shard hGkeYTzf7eMF: starting tombstone cleanup”,“shard”:“hGkeYTzf7eMF”,“time”:“2024-07-08T17:14:26Z”,“tombstones_in_cycle”:1,“tombstones_total”:1}\n\n----------\n\n[AbhiP (2024-07-09T16:05:57.546Z)]: Hey, could someone please help answer this.\n@DudaNogueira\nPlease let me know if any additional information is required.\n\n----------\n\n[DudaNogueira (2024-07-10T13:34:00.989Z)]: hi @AbhiP !!\nDo you have any readings from resource usage?\nAlso, have you tried the latest version? I believe this issue was recently fixed.\n\n----------\n\n[AbhiP (2024-07-10T15:03:05.758Z)]: Hey @DudaNogueira , thanks for responding to my query!\nI’m running 2 docker containers within an EC2 instance (one of which is the Weaviate server). The EC2 instance has 1vCPU and 8GB of RAM.\nWith Weaviate python v3 client - if I use a batch upload operation, the CPU usage rises to 100%, a batch upload error is thrown, but on automatic retry, the operation completed.\nI moved to weviate v3 client from v4 python client due to the issues mentioned when I started this thread.\nNow on Weaviate v3 client, when attempting retrieval, I get this error:\n“explorer: get class: vector search: object vector search at index superdash_6672b5b6cd7159bdb2f6b575: shard superdash_6672b5b6cd7159bdb2f6b575_ZW2YQ2tGWrQ1: vector search: entrypoint was deleted in the object store, it has been flagged for cleanup and should be fixed in the next cleanup cycle”\nOn regular usage (only retrieval operations with Weaviate v4 python client), the server CPU usage doesn’t rise above 5%.\nIn response to your other question, no, I haven’t tried the latest version.\nQuestions:\n\nAre the server specs mentioned insufficient for me to run Weaviate in a docker container?\nIs it possible to upgrade the version of Weaviate server instance running in the docker container without necessitating a complete data migration?\n\n----------\n\n[AbhiP (2024-07-11T05:32:26.273Z)]: Hey @DudaNogueira, I can confirm that on the Weaviate Python v4 client as well, the CPU usage rises to 100% on object upload.\nObject deletion works well sometimes, and times out other times. It is not consistent.\nWill increasing the CPU cores on the EC2 instance help to mitigate this problem?\n\n----------\n\n[ThomDB (2024-07-11T21:32:23.388Z)]: @DudaNogueira  Facing this issue. What is one way to resolve this issue?\n\n----------\n\n[AbhiP (2024-07-12T15:52:59.585Z)]: Hey @DudaNogueira, any support here?\nWould be happy even if you can point us to some documentation that we may have missed reading; that could help us solve the issue.\n\n----------\n\n[DudaNogueira (2024-07-15T18:51:40.454Z)]: Hi @ThomDB !! Welcome to our community. What is the server version you are using?\n@AbhiP Have you tried this on latest version?\nAnd what are the number of objects in place?\nThanks!\n\n----------\n\n[AbhiP (2024-07-16T03:59:17.613Z)]: Hey @DudaNogueira , As I have already mentioned, I have not yet tried this on the latest version, because this is a production DB. I have asked you certain specific questions already related to this. Let me repeat them:\n\nAre the server specs mentioned insufficient for me to run Weaviate in a docker container?\nIs it possible to upgrade the version of Weaviate server instance running in the docker container without necessitating a complete data migration?\n\nThe number of individual objects are in the order of about ~10,000 or so\n\n----------\n\n[DudaNogueira (2024-07-17T16:38:36.013Z)]: hi!\nYou can take a backup and change the image tag at your docker compose.\nThen, if something goes wrong. just revert back the original version docker image, and restore the data.\nYou can also do the backup, spin a new Weaviate server, restore, and do some tests.\nLet me know if this helps!\nThankjs!",
    "date_created": "2024-07-09T11:58:24.686Z",
    "has_accepted_answer": false,
    "title": "Upload to and Deletion from Custom Weviate Instance Always Times out",
    "topic_id": 2988
  },
  {
    "user_id": 2987,
    "conversation": "[Kaan_Tiftikci (2024-12-09T08:35:38.861Z)]: hello,\nI am using weaviate-client==4.9.6 and I am getting the error AttributeError: ‘WeaviateClient’ object has no attribute ‘query’. When I run it with visual studio on my Windows device, I do not get such an error, but when I try to run it with visual studio and colab on my macOS device, I encounter this error. In which version can I use query? I would be very happy if you could help me.\nThanks\n\n----------\n\n[andrewisplinghoff (2024-12-09T13:29:14.396Z)]: That sounds to me like in the installation where you are getting the error, you are using the current Python v4 API (as you mention, you retrieve a WeaviateClientobject which is the case when using the v4 API).\nIn the v4 API, query() is to be called on Collection instances as described here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate from v3 to v4 | Weaviate\n\n  The current Python client version is v||site.pythonclientversion||\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIf you want to keep using your old code with the v3 API,  you need to create instances of the deprecated weaviate.Client(). You can find details on that here:\nLegacy (v3) API (DEPRECATED) | Weaviate\n\n----------\n\n[DudaNogueira (2024-12-09T13:29:54.848Z)]: hi @Kaan_Tiftikci !!\nWelcome to our community \nCan you share the code you are using? It seems like you are using different client versions.\nThis is python v3 client:\nv3c = weaviate.Client(\"http://localhost:8080\")\nv3c.query.get(\"Test\", \"text\").do()\n\nand this is the python v4 client:\nclient = weaviate.connect_to_local()\ncollection = client.collections.get(\"Test\")\ncollection.query.fetch_objects().objects\n\nNote that the python v3 client is included in the python v4 client package. However, it is deprecated, a will be removed in future versions. Right now, if you instantiate a v3 client using the v4 client package, this warning will be printed:\n\nDeprecationWarning:\nPython client v3 weaviate.Client(...) connections and methods are deprecated and will\nbe removed by 2024-11-30.\n        Upgrade your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n            - For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n            - For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n\n        If you have to use v3 code, install the v3 client and pin the v3 dependency in your requirements file: `weaviate-client>=3.26.7;<4.0.0`\n\n\nSo this exact error you mentioned will surface when you call .query on the python v4 client:\nclient.query\n\n\nAttributeError Traceback (most recent call last) Cell In[9], line 1 ----> 1 client.query AttributeError: ‘WeaviateClient’ object has no attribute ‘query’\n\nLet me know if this helps!\n\n----------\n\n[Dirk (2024-12-09T13:43:11.049Z)]: DudaNogueira:\n\nHowever, it is deprecated, a will be removed in future versions\n\n\nI just deleted it, it will be gone in the next release (4.10.0)",
    "date_created": "2024-12-09T08:35:38.809Z",
    "has_accepted_answer": false,
    "title": "AttributeError: 'WeaviateClient' object has no attribute 'query'",
    "topic_id": 9162
  },
  {
    "user_id": 1562,
    "conversation": "[jenu9417 (2024-09-20T05:04:14.115Z)]: Description\nWe are using weaviate v1.24.2 running using docker in single node. We are observing that, weaviate automatically shuts down after running fine for a couple of days. There is no OOM expected since the machine has sufficient memory available. There is not much available in the logs as well.\nServer Setup Information\n\nWeaviate Server Version: 1.24.2\nDeployment Method: docker\nMulti Node? Number of Running Nodes: No. 1 node.\nClient Language and Version: Python.\nMultitenancy: No\n\nAny additional Information\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry update\",\"payload\":\"\\u0026{MachineID:c7ea6393-5c1a-4c1a-92ba-ead71cbbfad9 Type:UPDATE Version:1.24.2 Modules:generative-openai,text2vec-openai NumObjects:910511 OS:linux Arch:amd64}\",\"time\":\"2024-09-18T01:01:34Z\"}\n{\"action\":\"requests_total\",\"api\":\"graphql\",\"class_name\":\"\",\"error\":\"context canceled\",\"level\":\"error\",\"msg\":\"unexpected error\",\"query_type\":\"\",\"time\":\"2024-09-18T09:41:25Z\"}\n{\"action\":\"requests_total\",\"api\":\"graphql\",\"class_name\":\"\",\"error\":\"context canceled\",\"level\":\"error\",\"msg\":\"unexpected error\",\"query_type\":\"\",\"time\":\"2024-09-18T13:19:36Z\"}\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry update\",\"payload\":\"\\u0026{MachineID:c7ea6393-5c1a-4c1a-92ba-ead71cbbfad9 Type:UPDATE Version:1.24.2 Modules:generative-openai,text2vec-openai NumObjects:910511 OS:linux Arch:amd64}\",\"time\":\"2024-09-19T01:01:33Z\"}\n{\"level\":\"info\",\"msg\":\"Created shard byskryvdofxoqahloxdzigeskjam_ahqdoowkumnwonnvxxouwmzrdxjs_4SOl1Y7CFpiz in 1.778589ms\",\"time\":\"2024-09-19T06:25:54Z\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-09-19T06:25:54Z\",\"took\":44132}\n{\"level\":\"info\",\"msg\":\"Created shard bufbvoexajkthedtwfkeidqknppk_bhgckdjhnvpuzuthiacwxzspbkmh_xIGiqOKLpF36 in 1.612693ms\",\"time\":\"2024-09-19T06:49:24Z\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-09-19T06:49:24Z\",\"took\":43992}\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Shutting down... \",\"time\":\"2024-09-19T20:27:31Z\"}\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Stopped serving weaviate at http://[::]:8080\",\"time\":\"2024-09-19T20:27:31Z\"}\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry terminated\",\"payload\":\"\\u0026{MachineID:c7ba8293-5c13-4c1a-94ba-eaf71cbbfad9 Type:TERMINATE Version:1.24.2 Modules:generative-openai,text2vec-openai NumObjects:914984 OS:linux Arch:amd64}\",\"time\":\"2024-09-19T20:27:32Z\"}\n\nThe above are the logs i see. Basically I just see this one log line, before it goes down.\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Shutting down... \",\"time\":\"2024-09-19T20:27:31Z\"}\n\nPlease help me on why this issue is happening? How can I resolve it? or How can I debug further.\n\n----------\n\n[DudaNogueira (2024-09-23T08:10:37.063Z)]: hi @jenu9417 !!\nWelcome to our community \nThat’s strange. It seems that something external to Weaviate is sending a TERM SIGNAL, as considering the logs you have shared, I see nothing that would make it shut down.\nDo you have any health check set up for this container?\n\n----------\n\n[jenu9417 (2024-09-23T11:47:59.394Z)]: Hi @DudaNogueira\nNo. I haven’t setup any healthcheck. There is no loadbalancer for this as well. Its in a single VM machine.\nFrom our service, before each request we check if weaviate is Alive using the is_live() method, which inturn hits the /.well-known/live endpoint.\nI wanted to understand, what all could be possible chances here:\na) Can weaviate be crashing here due to some resource constraints? I have set the config:\nLIMIT_RESOURCES to true.\nAlso I have added restart: on-failure:1 as part of the docker compose file.\nb) Can this be induced by a weaviate client as part of a call failure? I’m using python weaviate client.(v3.23.2) I didn’t see any issues as part of my application logs.\nc) How can we debug more regarding this?\nThanks.\n\n----------\n\n[DudaNogueira (2024-09-25T11:03:06.178Z)]: hi! I don’t think this is something from Weaviate itself, but something on your deployment.\nThere is no error logs prior the shit down info log, so this is probably docker sending the term signal to this container\n\n----------\n\n[jenu9417 (2024-09-30T05:44:28.171Z)]: Hi @DudaNogueira ,\nSure. Thanks for the update. Will check again internally.\n\n----------\n\n[DudaNogueira (2024-09-30T15:13:40.025Z)]: Ok, let me know if you have found something!\nThanks!",
    "date_created": "2024-09-20T05:04:14.060Z",
    "has_accepted_answer": true,
    "title": "Weaviate Shutting Down Automatically",
    "topic_id": 4213
  },
  {
    "user_id": 633,
    "conversation": "[flash (2024-03-28T19:48:39.738Z)]: Raptor (RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval) has been getting a lot of attention this month. I think this is a very interesting idea and I’m in the process of implementing it.\nI have a very hierarchical data set with 4 levels, The top level applies to all clients, the second and third levels applies to groups of clients and the 4th level is the client. I have everything broken into individual tenants (i.e. the root tenant that applies to everyone, then group tenants for the second and third levels) and then each client gets a tenant.\nIn order to implement the idea presented in that paper, I need to perform a vector search across multiple tenants (i.e. the client, and the three levels above them). I can do this with 4 searches and then combine them but that is a lot of overhead.\nIs it currently possible to search across tenants? If not, how much work would it be to implement such a request?\nthank you\n\n----------\n\n[DudaNogueira (2024-04-01T16:47:56.543Z)]: Hi @flash !\nThis is not possible, however, it is in our roadmap:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nWeaviate Core Roadmap | Weaviate - Vector Database\n\n  Weaviate is an open source project that is hosted on GitHub. GitHub uses issues to request features and to track projects. This page highlights some of the issues that Weaviate is working on for upcoming releases.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nunder this feature request:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Feature request: Cross-tenant queries\n    \n\n    \n      \n        opened 08:02PM - 04 Sep 23 UTC\n      \n\n\n      \n        \n          \n          vmg-dev\n        \n      \n    \n\n    \n        \n          backlog\n        \n    \n  \n\n\n  \n    # Feature description\nAbility to search vectors across multiple tenants in a si…ngle query.\n\n# Use case\nImagine a scenario where different tenants grant partial access to data to a user. For this user to search all the documents they were granted access to multiple queries need to be made to weaviate since the data is stored on multiple tenants. This feature request is to add the ability to search across multiple tenants.\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nPLease, leave a thumbs up and comments there so we can understand it’s popularity.\nThanks!\n\n----------\n\n[Luka_Secerovic (2024-09-13T08:51:09.177Z)]: DudaNogueira:\n\nWeaviate Core Roadmap | Weaviate\n\n\nHope this gets on your work plates soon",
    "date_created": "2024-03-28T19:48:39.675Z",
    "has_accepted_answer": true,
    "title": "Searching across multiple tenancies",
    "topic_id": 1844
  },
  {
    "user_id": 1600,
    "conversation": "[izharg (2024-09-26T04:18:58.954Z)]: Hi,\nI’m trying to understand how sharding works in multi-tenant collections.\nWhen I create a regular sharded collection (without multi-tenancy) that contains 300,000 data objects on a 3-node cluster, the data is sharded, and each node holds a shard with 100,000 objects.\nMy understanding is that this setup doesn’t work the same way with multi-tenancy. Specifically, if I have a multi-tenant collection and one of the tenants has 300,000 records, all 300,000 records would be stored on a single shard on one node, and there’s no way to distribute them evenly across multiple nodes.\nIs my understanding correct?\n\n----------\n\n[Mohamed_Shahin (2024-09-26T12:50:05.947Z)]: Hello @izharg,\nWelcome to our community and it’s great to have you here with us \nYes, your understanding is correct.\nIn a multi-tenant setup, each tenant is allocated its own dedicated shard, meaning that all data for a specific tenant resides in a single shard on one node. If a tenant has 300,000 records, they would all be stored within that one shard.\nMulti-tenant sharding is designed to keep each tenant’s data isolated within a single shard.\n\n----------\n\n[jinx (2025-02-26T05:09:59.770Z)]: But if I have 3 tenants each with 100,000 records, in a 3 node cluster, will the shards for these 3 tenants be distributed across the 3 nodes? Tenant 1 shard on node 1, tenant 2 shard on node 2, …\n\n----------\n\n[Mohamed_Shahin (2025-02-26T09:23:38.986Z)]: Distributed across our 3-node cluster:\nNode 1 :\n• Tenant 1 (shard): 100,000 records\n• Tenant 2 (shard): 100,000 records\n• Tenant 3 (shard): 100,000 records\nNode 2 (Same as Node 1):\n• Tenant 1 (shard): 100,000 records\n• Tenant 2 (shard): 100,000 records\n• Tenant 3 (shard): 100,000 records\nNode 3 (Same as Node1):\n• Tenant 1 (shard): 100,000 records\n• Tenant 2 (shard): 100,000 records\n• Tenant 3 (shard): 100,000 records\n\n----------\n\n[jinx (2025-03-03T03:55:30.368Z)]: Ohh okay, understood. Thank you!",
    "date_created": "2024-09-26T04:18:58.910Z",
    "has_accepted_answer": true,
    "title": "Understanding sharding in muti-tenant collections",
    "topic_id": 4335
  },
  {
    "user_id": 968,
    "conversation": "[zhou_yangbo (2024-05-30T09:39:34.214Z)]: after modified the weaviate module in docker envs  with text2vec-ollama then tried collection quering then errors happen as following:\nvectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: send POST request: Post \"http://localhost:11434/api/embeddings\\“: dial tcp 127.0.0.1:11434: connect: connection refused”}\"\nif with local ollama embedding vectorizer working code example we will be greatly appreciated.\nany idea ?\n\n----------\n\n[DudaNogueira (2024-05-30T23:26:55.400Z)]: Hi @zhou_yangbo !\nI have just published this ollama recipe:\n  \n\n      github.com\n  \n\n  \n    weaviate/recipes/blob/main/integrations/ollama/local_rag_using_ollama_integration_using_embedded.ipynb\n\n\n      {\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Local RAG with Ollama and Weaviate\\n\",\n    \"## Using Weaviate integration\\n\",\n    \"\\n\",\n    \"This example shows how to use the text2vec-ollama as well the generative-ollama \"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Setup \\n\",\n    \"1. Download and install Ollama for your operating system: https://ollama.com/download\\n\",\n    \"2. `pip` install the Python library to generate vector embeddings from the model  with `pip install ollama`. (REST API or JavaScript library also available)\"\n   ]\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNote the part:\nBelow we use http://localhost:11434 for calling ollama models.\nAs we are using Weaviate Embedded instead of Docker, and we assume here your ollama instalation is on the host, we should call ollama, from Weaviate, at http://localhost:11434\nIf your are running Weaviate as a docker container, the api_endpoint must be http://host.docker.internal:11434.\n\n----------\n\n[zhou_yangbo (2024-05-31T06:48:07.188Z)]: yes , and what I did is only copy pasted your codebase , then post  to ollama embedding get response , then followed  Building a Local RAG System for Privacy Preservation with Ollama and Weaviate | Weaviate - Vector Database to do near vector querying , then errors happen as following: grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n###nearVector queried results: QueryReturn(objects=)\n###queried response: QueryReturn(objects=)\nTraceback (most recent call last):\nFile “/Users/yangboz/anaconda3/envs/py311/lib/python3.11/site-packages/weaviate/collections/grpc/query.py”, line 649, in __call\nres, _ = self._connection.grpc_stub.Search.with_call(\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “/Users/yangboz/anaconda3/envs/py311/lib/python3.11/site-packages/grpc/_channel.py”, line 1198, in with_call\nreturn _end_unary_response_blocking(state, call, True, None)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “/Users/yangboz/anaconda3/envs/py311/lib/python3.11/site-packages/grpc/_channel.py”, line 1006, in _end_unary_response_blocking\nraise _InactiveRpcError(state)  # pytype: disable=not-instantiable\nstatus = StatusCode.UNKNOWN\ndetails = “explorer: get class: vectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: send POST request: Post “http://localhost:11434/api/embeddings”: dial tcp 127.0.0.1:11434: connect: connection refused”\ndebug_error_string = “UNKNOWN:Error received from peer  {grpc_message:“explorer: get class: vectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: send POST request: Post \"http://localhost:11434/api/embeddings\\”: dial tcp 127.0.0.1:11434: connect: connection refused”, grpc_status:2, created_time:“2024-05-31T14:41:52.814425+08:00”}\"\nany idea? thanks\n\n----------\n\n[coolrazor (2024-11-05T21:49:58.729Z)]: I just stumbled on to this after making my own post.  I think I’m seeing the same issue.  Ollama API is listening on /api/embed not /api/embeddings/\nCheck out my post for context: Text2vec ollama embedding error - #3 by zhou_yangbo\nSadly I don’t have a fix for it yet\nI made a Github issue for this: text2vec_ollama takes api_endpoint but has wrong path appended · Issue #1394 · weaviate/weaviate-python-client · GitHub",
    "date_created": "2024-05-30T09:39:34.167Z",
    "has_accepted_answer": false,
    "title": "Text2vec ollama embedding error",
    "topic_id": 2551
  },
  {
    "user_id": 1575,
    "conversation": "[Analitiq (2024-09-25T12:52:44.934Z)]: Description\nI looked at the support page for delete_many but nowhere does it mention how to put multiple properties: Delete objects | Weaviate\nIs it even possible?\nCan I delete all objects where property A = “Hello” and property B = “World”?\nHere is the code I have so far, but it is throwing assertion error:\nmetadata = {\n            \"document_name\": \"my_document\",\n            \"document_type\": \"xml\",\n            \"source\": \"source1\"\n        }\n\nfilters = {\n            \"operator\": \"And\",\n            \"operands\": [\n                {\n                    \"path\": [key],\n                    \"operator\": \"Equal\",\n                    \"valueString\": value\n                } for key, value in metadata.items()\n            ]\n        }\n        print(filters)\n        collection = self.__get_tenant_collection_object(self.collection_name, tenant_name)\n\n        response = collection.data.delete_many(\n            where=filters\n        )\n\nI want to delete all documents that have\n            \"document_name\" = \"my_document\"\nAND\n            \"document_type\" = \"xml\"\nAND\n            \"source\" = \"source1\"\n\nServer Setup Information\n\nWeaviate Server Version: Cloud\nDeployment Method: \nMulti Node? Number of Running Nodes: Cloud\nClient Language and Version: Python 3.10, Weaviate 4.8.1\nMultitenancy?: yes\n\n----------\n\n[Analitiq (2024-09-30T06:27:50.795Z)]: @Mohamed_Shahin is this something you could assist with? It is a blocker for further development on Weaviate.\n\n----------\n\n[DudaNogueira (2024-10-01T08:49:52.795Z)]: hi @Analitiq !\nYou can for sure do that.\nThis is how to do it using python v4 client:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n    properties=[\n        wvc.config.Property(\n            name=\"text\", data_type=wvc.config.DataType.TEXT\n        )\n    ]\n)\ncollection.data.insert({\"document_name\": \"my_document\", \"document_type\": \"xml\", \"source\": \"source1\"})\ncollection.data.insert({\"document_name\": \"my_document\", \"document_type\": \"xml\", \"source\": \"source2\"})\n\nWe now have two objects:\ncollection.aggregate.over_all()\n\n\nAggregateReturn(properties={}, total_count=2)\n\nNow we delete:\ncollection.data.delete_many(\n    where=(\n        wvc.query.Filter.by_property(\"document_name\").equal(\"my_document\") &\n        wvc.query.Filter.by_property(\"document_type\").equal(\"xml\") &\n        wvc.query.Filter.by_property(\"source\").equal(\"source1\")\n    )\n)\n\nIf we now check the total count, we get:\n\nAggregateReturn(properties={}, total_count=1)\n\n----------\n\n[Mohamed_Shahin (2024-10-01T09:05:48.894Z)]: @Analitiq I was about to confirm that with you, but @DudaNogueira was faster! Thank you so much, @DudaNogueira.\nAlso, adding to Duda’s response, I would recommend you always refer to the Python client to learn more about available features. For example, in relation to deletion, you can check this out: Python Client Test Collection Filter.",
    "date_created": "2024-09-25T12:52:44.879Z",
    "has_accepted_answer": true,
    "title": "Anyone used many WHERE filters in DELETE",
    "topic_id": 4319
  },
  {
    "user_id": 30,
    "conversation": "[SomebodySysop (2024-09-13T23:25:24.434Z)]: Description\n\nWeaviate has introduced this “Late Chunking” methodology:  Late Chunking: Balancing Precision and Cost in Long Context Retrieval | Weaviate\nThe email I received refers to code here: recipes/weaviate-features/services-research/late_chunking_berlin.ipynb at main · weaviate/recipes · GitHub\nBut my question is:  Is there a more language agnostic approach to this?  Or, you can only do it using Python code.\nServer Setup Information\nI use Weaviate Cloud.\nAny additional Information\n\nI currently use PHP curl commands to upsert my embeddings.\n\n----------\n\n[DudaNogueira (2024-09-16T14:03:12.683Z)]: hi @SomebodySysop !!\nThat’s a great question.\nI will ask internally. Thanks!\n\n----------\n\n[Danny_Williams (2024-09-19T08:14:12.368Z)]: Hi there! Author of the notebook recipe here. Thank you for asking, this is indeed a great question.\nThe methodology behind late chunking is simply a switch in the order between document embedding and chunking, so this is entirely language agnostic. Whatever method you are currently using to embed individual chunks you can transfer to the document itself. I.e. chunk the embeddings instead of the document text itself, based on their token positions instead of markers in the text.\nOne important thing to note however, is that the embedding model you use must be capable of handling longer context documents. The method introduced by Jina.ai also recommended their embedding models, capable of processing 8192 token length documents: Embedding API. You can acquire these as an API call but this is outside of the Weaviate ecosystem. Jina AI’s v3 embeddings can also handle late chunking natively, but I am afraid I cannot vouch for it as personally I have not used it nor am I a developer for it, but this might be a much simpler way of doing things.\nSo overall if you follow the general python syntax outlined in the notebook but converted to other languages there should be no issues.\nWe are working for future implementation for late chunking as well as easier ways of handling embeddings within the Weaviate ecosystem as well, so keep an eye out for updates! I hope that helps and let me know if there’s any additional information or help I can give\n\n----------\n\n[SomebodySysop (2024-09-19T08:46:45.816Z)]: Thank you very much for the reply.  This is what I do not understand:\n\n\n\n Danny_Williams:\n\nWhatever method you are currently using to embed individual chunks you can transfer to the document itself. I.e. chunk the embeddings instead of the document text itself, based on their token positions instead of markers in the text.\n\n\nRight now, let’s say I have a PDF that has 3 pages.\na. extract the text from the PDF\nb. chunk the text, either semantically or by “sliding window”\nc. individually upsert the chunks to Weaviate as embeddings.\nBy upsert, I meant that I send all the class properties for that object to:\n$this->endpoint . '/v1/objects?consistency_level=ALL\nI am using the latest OpenAI text-embedding-3-large model which, I assume, has a 8192 token length.\nNow, in my current class properties, I identify the order of these chunks so that I am able to do Small to Big retrieval (retrieve adjacent chunks).\nI am thinking it would be nice to do this instead with one Weaviate retrieval call rather than an extra steps I currently have to perform.\nSo my follow up question is, what exactly do I do different from what I am doing now to achieve Late Chunking?\nI’m not a Python coder.  I’m a PHP guy.  But if I can do this through the API, all I need to know are the steps.\n\n----------\n\n[Danny_Williams (2024-09-19T11:37:19.823Z)]: So can I ask, are you embedding your chunks separately, and then uploading them to your Weaviate collection as vector embeddings? I.e., using the Bring your own vectors? Or are you using OpenAI’s embedding service as provided by weaviate?\nTo use late chunking at the moment, you’ll need to\n\nEmbed your entire document using your own embedding method\nTake note of where your chunks start and end, in terms of the token positions\nAverage across the token embeddings from step 1 to obtain the chunk embeddings\nUse these chunk embeddings in the Bring your own vectors with Weaviate\n\nCurrently, step 2 is the trickiest part, especially when not using Python, because you’ll need to access the token start/end points which are specific to the tokenizer that your embedding method uses.\nIn which case I’d highly recommend using the new Jina embedding API, which has late chunking enabled. I have just gone and tested this out, and it works very well and easily.\nHere is the link again: Embedding API\nYou can specify the language as PHP as well as many others.\nTo be clear, this is not using OpenAI’s text embeddings any more, but is far easier to use late chunking for. Once you have these embeddings, you need to use the Bring your own vectors service in Weaviate to add it to your collection.\nHope that helps!\n\n----------\n\n[SomebodySysop (2024-09-19T20:19:30.971Z)]: Thank you for taking the time to explain.  I have a much better understanding of what’s going on.\nThis is a direct solution to this query: Retrieving “Adjacent” Chunks for Better Context\nThat query is also what led me to develop my own “Comprehension Level” retrieval methodology (based on the Small to Big retrieval strategy), which also solves the issue of retrieving adjacent chunks within a specific radius of the core chunk.\nI do see that the Jina embedding model does allow for REST API interaction which would allow me to develop my solution in PHP (Yay!).  But, at this point, I am not anxious to change my Weaviate class embeddings model – I am getting very good results with the OpenAI model.\nAnd, I am getting essentially the same functionality as Late Chunking without altering my current embedding techniques.  So for now, I think I’ll put it on hold.\nBut I do appreciate you taking the time to explain how this works.  I think it’s a great solution and hopefully I will be able to incorporate it down the line.\n\n----------\n\n[Danny_Williams (2024-09-20T09:18:42.578Z)]: No problem at all, I’m glad you understand better!\nIn the future, late chunking will hopefully be included in our embedding service (this is not my department, but I’ve heard rumours), so eventually this will be extremely straight forward to implement.\nI’ll just point out finally that late chunking only changes the values of the embedded vectors - it doesn’t retrieve adjacent chunks at query time, but the chunks themselves are ‘aware’ in some capacity of the chunks that originally neighboured them, even though they are separate now. So this is slightly different to retrieving adjacent chunks to the returned chunk from querying, which I imagine you can do by giving all chunks a unique index and then retrieving those indices after you have retrieved the relevant chunk. But I’ll stop there in case I’ve just confused things any further.\nIf you have any more questions I’m more than happy to answer them, but for now all sounds good and best of luck with what you’re working on!\n\n----------\n\n[SomebodySysop (2024-09-20T09:53:21.544Z)]: Danny_Williams:\n\ngiving all chunks a unique index and then retrieving those indices after you have retrieved the relevant chunk\n\n\nNot confusing at all.  Precisely what I am now doing.\n\n----------\n\n[brianjking (2024-09-23T01:26:09.334Z)]: Fantastic news, do you envision Late Chunking can be implemented into Verba as well assuming I use jina-embeddings-v2?\nThanks for the notebook, really curious about applying Late Interaction or Late Chunking into a system I’m working on, it seems like the unlock I need.\n\n----------\n\n[Danny_Williams (2024-09-23T09:29:08.149Z)]: Really glad you appreciated the notebook and are excited about late chunking - there’s a lot going on in retrieval right now that’s really interesting.\nThere aren’t currently any plans to implement this into Verba, but this is something I’ve wanted to do since hearing about late chunking!\nNo promises to be made but it is on my to-do list at some point",
    "date_created": "2024-09-13T23:25:24.393Z",
    "has_accepted_answer": false,
    "title": "Late Chunking",
    "topic_id": 4155
  },
  {
    "user_id": 3155,
    "conversation": "[DhanushKumar_R (2025-01-08T06:38:57.856Z)]: import weaviate\nfrom weaviate.classes.init import Auth\nimport google.generativeai as genai\nfrom typing import List, Dict\nimport os\nfrom typing import List, Dict\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom weaviate.classes import query as wvc\nfrom langchain.chains import create_retrieval_chain\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\n\nWEAVIATE_API_KEY = \"\"\nWEAVIATE_URL = \"\"\ngemini_api_key = \"\"\nhuggingface_api_key = \"\"\n\n# Connect to Weaviate Cloud\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url= WEAVIATE_URL,\n    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n)\n\nprint(client.is_ready())\n\nhuggingface_key = huggingface_api_key\nheaders = {\n    \"X-HuggingFace-Api-Key\": huggingface_key,\n}\n\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=WEAVIATE_URL,                       # `weaviate_url`:  Weaviate URL\n    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),      # `weaviate_key`:  Weaviate API key\n    headers=headers\n)\n\n\n# Initialize Gemini\ngenai.configure(api_key=gemini_api_key)\n\n\n\nprint(\"Client is Ready?\", client.is_ready())\nfrom weaviate import classes as wvc\n\nclient.collections.delete(\"WikipediaLangChain\")\n\nfrom weaviate.classes.config import Configure\n\nclient.collections.create(\n    \"WikipediaLangChain\",\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_huggingface(\n            name=\"title_vector\",\n            source_properties=[\"title\"],\n            model=\"sentence-transformers/all-MiniLM-L6-v2\",\n        )\n    ],\n\n)\n\nembeddings = GoogleGenerativeAIEmbeddings(\n        model=\"models/embedding-001\",  # Google's text embedding model\n        google_api_key= gemini_api_key\n    )\n\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n\n\n\n# import first article\nloader = PyPDFLoader(\"brazil-wikipedia-article-text.pdf\", extract_images=False)\ndocs = loader.load_and_split(text_splitter)\nprint(f\"GOT {len(docs)} docs for Brazil\")\ndb = WeaviateVectorStore.from_documents(docs, embeddings, client=client, index_name=\"WikipediaLangChain\")\n\n\n# import second article\nloader = PyPDFLoader(\"netherlands-wikipedia-article-text.pdf\", extract_images=False)\ndocs = loader.load_and_split(text_splitter)\nprint(f\"GOT {len(docs)} docs for Netherlands\")\ndb = WeaviateVectorStore.from_documents(docs, embeddings, client=client, index_name=\"WikipediaLangChain\")\n\n# Create vector store\nvector_store = WeaviateVectorStore(\n    client=client,\n    index_name=\"WikipediaLangChain\",\n    text_key=\"text\",\n    embedding=embeddings,  \n    attributes=[\"source\"]\n)\n\nvector_store.add_documents(docs)\ncollection = client.collections.get(\"WikipediaLangChain\")\n# lets first get our collection\ncollection = client.collections.get(\"WikipediaLangChain\")\n\nresponse = collection.aggregate.over_all(total_count=True)\nprint(response)\n\n# Group by source\nresponse = collection.aggregate.over_all(group_by=\"source\")\nfor group in response.groups:\n    print(group.grouped_by.value, group.total_count)\n\n# View object properties\nobject = collection.query.fetch_objects(limit=1).objects[0]\nprint(object.properties.keys())\nprint(object.properties.get(\"source\"))\nprint(object.properties.get(\"page\"))\nprint(object.properties.get(\"text\"))\n\n# Query in French using Gemini\ngenerateTask = \"Quelle est la nourriture traditionnelle de ce pays?\"\nsource_file = \"brazil-wikipedia-article-text.pdf\"\n\nmodel = ChatGoogleGenerativeAI(\n    model=\"gemini-pro\", \n    google_api_key= gemini_api_key\n)\n\n# lets do a RAG directly using only Weaviate\n\n\n\nquery = collection.generate.near_text(\n    query=\"tradicional food\",\n  \n    limit=10,\n    grouped_task=generateTask\n)\nprint(query.generated)\n\n\nAioRpcError                               Traceback (most recent call last)\nFile c:\\Users\\dhanu.conda\\envs\\idk_gpu\\lib\\site-packages\\weaviate\\collections\\grpc\\query.py:805, in _QueryGRPC.__call(self, request)\n804 assert self._connection.grpc_stub is not None\n → 805 res = await _Retry(4).with_exponential_backoff(\n806     0,\n807     f\"Searching in collection {request.collection}\",\n808     self._connection.grpc_stub.Search,\n809     request,\n810     metadata=self._connection.grpc_headers(),\n811     timeout=self._connection.timeout_config.query,\n812 )\n813 return cast(search_get_pb2.SearchReply, res)\nFile c:\\Users\\dhanu.conda\\envs\\idk_gpu\\lib\\site-packages\\weaviate\\collections\\grpc\\retry.py:31, in _Retry.with_exponential_backoff(self, count, error, f, *args, kwargs)\n30 if e.code() != StatusCode.UNAVAILABLE:\n—> 31     raise e\n32 logger.info(\n33     f\"{error} received exception: {e}. Retrying with exponential backoff in {2count} seconds\"\n34 )\nFile c:\\Users\\dhanu.conda\\envs\\idk_gpu\\lib\\site-packages\\weaviate\\collections\\grpc\\retry.py:28, in _Retry.with_exponential_backoff(self, count, error, f, *args, **kwargs)\n27 try:\n—> 28     return await f(*args, **kwargs)\n29 except AioRpcError as e:\nFile c:\\Users\\dhanu.conda\\envs\\idk_gpu\\lib\\site-packages\\grpc\\aio_call.py:327, in _UnaryResponseMixin.await(self)\n326     else:\n → 327         raise _create_rpc_error(\n328             self._cython_call._initial_metadata,\n329             self._cython_call._status,\n330         )\n331 else:\nAioRpcError: <AioRpcError of RPC that terminated with:\nstatus = StatusCode.UNKNOWN\ndetails = “explorer: get class: concurrentTargetVectorSearch): explorer: get class: vector search: object vector search at index wikipedialangchain: shard wikipedialangchain_mj30ETuKNGfK: vector search: knn search: distance between entrypoint and query node: 768 vs 384: vector lengths don’t match”\ndebug_error_string = “UNKNOWN:Error received from peer  {grpc_message:“explorer: get class: concurrentTargetVectorSearch): explorer: get class: vector search: object vector search at index wikipedialangchain: shard wikipedialangchain_mj30ETuKNGfK: vector search: knn search: distance between entrypoint and query node: 768 vs 384: vector lengths don't match”, grpc_status:2, created_time:“2025-01-08T06:29:39.4893321+00:00”}”\n\nDuring handling of the above exception, another exception occurred:\nWeaviateQueryError                        Traceback (most recent call last)\nCell In[59], line 5\n1 # lets do a RAG directly using only Weaviate\n----> 5 query = collection.generate.near_text(\n6     query=“tradicional food”,\n7\n8     limit=10,\n9     grouped_task=generateTask\n10 )\n11 print(query.generated)\nFile c:\\Users\\dhanu.conda\\envs\\idk_gpu\\lib\\site-packages\\weaviate\\syncify.py:23, in convert..sync_method(self, __new_name, *args, **kwargs)\n20 @wraps(method)  # type: ignore\n21 def sync_method(self, *args, __new_name=new_name, **kwargs):\n22     async_func = getattr(cls, __new_name)\n—> 23     return _EventLoopSingleton.get_instance().run_until_complete(\n24         async_func, self, *args, **kwargs\n25     )\nFile c:\\Users\\dhanu.conda\\envs\\idk_gpu\\lib\\site-packages\\weaviate\\event_loop.py:42, in _EventLoop.run_until_complete(self, f, *args, **kwargs)\n40     raise WeaviateClosedClientError()\n41 fut = asyncio.run_coroutine_threadsafe(f(*args, **kwargs), self.loop)\n—> 42 return fut.result()\nFile c:\\Users\\dhanu.conda\\envs\\idk_gpu\\lib\\concurrent\\futures_base.py:458, in Future.result(self, timeout)\n456     raise CancelledError()\n457 elif self._state == FINISHED:\n → 458     return self.__get_result()\n459 else:\n460     raise TimeoutError()\nFile c:\\Users\\dhanu.conda\\envs\\idk_gpu\\lib\\concurrent\\futures_base.py:403, in Future.__get_result(self)\n401 if self._exception:\n402     try:\n → 403         raise self._exception\n404     finally:\n405         # Break a reference cycle with the exception in self._exception\n406         self = None\nFile c:\\Users\\dhanu.conda\\envs\\idk_gpu\\lib\\site-packages\\weaviate\\collections\\queries\\near_text\\generate.py:101, in _NearTextGenerateAsync.near_text(self, query, single_prompt, grouped_task, grouped_properties, certainty, distance, move_to, move_away, limit, offset, auto_limit, filters, group_by, rerank, target_vector, include_vector, return_metadata, return_properties, return_references)\n28 async def near_text(\n29     self,\n30     query: Union[List[str], str],\n(…)\n49     return_references: Optional[ReturnReferences[TReferences]] = None,\n50 ) → GenerativeSearchReturnType[Properties, References, TProperties, TReferences]:\n51     “”“Perform retrieval-augmented generation (RaG) on the results of a by-image object search in this collection using the image-capable vectorization module and vector-based similarity search.\n52\n53     See the docs for a more detailed explanation.\n(…)\n99             If the request to the Weaviate server fails.\n100     “””\n → 101     res = await self._query.near_text(\n102         near_text=query,\n103         certainty=certainty,\n104         distance=distance,\n105         move_to=move_to,\n106         move_away=move_away,\n107         limit=limit,\n108         offset=offset,\n109         autocut=auto_limit,\n110         filters=filters,\n111         group_by=_GroupBy.from_input(group_by),\n112         rerank=rerank,\n113         target_vector=target_vector,\n114         generative=_Generative(\n115             single=single_prompt,\n116             grouped=grouped_task,\n117             grouped_properties=grouped_properties,\n118         ),\n119         return_metadata=self._parse_return_metadata(return_metadata, include_vector),\n120         return_properties=self._parse_return_properties(return_properties),\n121         return_references=self._parse_return_references(return_references),\n122     )\n123     return self._result_to_generative_return(\n124         res,\n125         _QueryOptions.from_input(\n(…)\n135         return_references,\n136     )\nFile c:\\Users\\dhanu.conda\\envs\\idk_gpu\\lib\\site-packages\\weaviate\\collections\\grpc\\query.py:817, in _QueryGRPC.__call(self, request)\n815     if e.code().name == PERMISSION_DENIED:\n816         raise InsufficientPermissionsError(e)\n → 817     raise WeaviateQueryError(str(e), “GRPC search”)  # pyright: ignore\n818 except WeaviateRetryError as e:\n819     raise WeaviateQueryError(str(e), “GRPC search”)\nWeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\nstatus = StatusCode.UNKNOWN\ndetails = “explorer: get class: concurrentTargetVectorSearch): explorer: get class: vector search: object vector search at index wikipedialangchain: shard wikipedialangchain_mj30ETuKNGfK: vector search: knn search: distance between entrypoint and query node: 768 vs 384: vector lengths don’t match”\ndebug_error_string = “UNKNOWN:Error received from peer  {grpc_message:“explorer: get class: concurrentTargetVectorSearch): explorer: get class: vector search: object vector search at index wikipedialangchain: shard wikipedialangchain_mj30ETuKNGfK: vector search: knn search: distance between entrypoint and query node: 768 vs 384: vector lengths don't match”, grpc_status:2, created_time:“2025-01-08T06:29:39.4893321+00:00”}”\n\n.\n\n----------\n\n[DudaNogueira (2025-01-08T14:20:18.568Z)]: hi @DhanushKumar_R !!\nWelcome to our community \nYour error message indicates that there is a dimension mismatch.\nSo your store vectors have on dimensions length, and the query is being passed as a different dimension length:\n\n\n\n DhanushKumar_R:\n\nvector search: knn search: distance between entrypoint and query node: 768 vs 384: vector lengths don’t match”, grpc_status:2, created_time:“2025-01-08T06:29:39.4893321+00:00”}”\n\n\nI see you are using the recipe I have written: recipes/integrations/llm-frameworks/langchain/loading-data at main · weaviate/recipes · GitHub\nNice!! \nThe root cause of your error is because you are defining one vectorizer to be used by Weaviate, while using a different one for Langchain here:\nclient.collections.create(\n    \"WikipediaLangChain\",\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_huggingface(\n            name=\"title_vector\",\n            source_properties=[\"title\"],\n            model=\"sentence-transformers/all-MiniLM-L6-v2\",\n        )\n    ],\n\n)\n\nembeddings = GoogleGenerativeAIEmbeddings(\n        model=\"models/embedding-001\",  # Google's text embedding model\n        google_api_key= gemini_api_key\n    )\n\nThose two must be configured for the same model.\nLet me know if this helps!\nThanks!\n\n----------\n\n[DhanushKumar_R (2025-01-29T10:12:22.541Z)]: Thank you so much !!",
    "date_created": "2025-01-08T06:38:57.767Z",
    "has_accepted_answer": true,
    "title": "Trying to resolve the error ,here are my code and error",
    "topic_id": 9620
  },
  {
    "user_id": 696,
    "conversation": "[pu007 (2024-09-20T11:05:44.871Z)]: the weaviate pod does not go up again, so when I look at the log,\nI see the error message “error”: \"init bolt_db: open \"/“var/lib/weaviate/schema.db\": no locks available”.\nThis occurs when the node with the pod up is forcibly stopped and displayed for availability test, and even if all the weather pods are deleted or Helm uninstalled with the existing values.yaml setting and then installed again, the same error occurs and the pod does not run normally. (status: CrashLoopBackOff)\nHow to solve it?\n\n----------\n\n[pu007 (2024-09-22T00:28:48.150Z)]: the weaviate was running in k8s cluster with two nodes. and the schema.db file was in NFS(BlockStorage).\nAnd I can still access the path of schema.db through node server and the schema.db, tx.db file and other files and collections directory.\nBut it still shows ‘no locks available’ error.\nAnd I tried to make new weaviate instance, but it also shows no locks available error and there’s only 0 size schema.db file.\n\n----------\n\n[DudaNogueira (2024-09-25T11:01:31.818Z)]: Hi!\nI believe this might be something with how you are mounting the volume to Weaviate.\nIf you use regular volumes, not NFS, do you still see this kind of issue?\n\n----------\n\n[pu007 (2024-09-26T06:24:28.581Z)]: We’ve solved it by changing NFS mount options from ver3 to 4.\nver3 is using lockd, statd to lock files but I think it’s not that stable.",
    "date_created": "2024-09-20T11:05:44.810Z",
    "has_accepted_answer": true,
    "title": "[Question] weaviate pod restart unavailable - no locks available",
    "topic_id": 4219
  },
  {
    "user_id": 1312,
    "conversation": "[pc10 (2025-02-12T19:05:14.485Z)]: Description\nI am using hybrid search with max-vector-distance to limit the vector similarity contributions in my search results. However, when I inspect the results using explain_score, I notice that the vector similarity scores still exceed the max-vector-distance threshold.\nThis behavior is unexpected, as I assumed setting max-vector-distance would filter out any results beyond the specified threshold. The scores seem inconsistent with my expectations for hybrid search.\nAm I misunderstanding how max-vector-distance is applied in hybrid search?\nServer Setup Information\n\nWeaviate Server Version: semitechnologies/weaviate:1.26.1\nDeployment Method:  k8s\nMulti Node? Number of Running Nodes:  1\nClient Language and Version: 4.8.0\nMultitenancy?: No\n\nAny additional Information\nHere is the example search result.\nMax Vector Distance: 0.3\nHybrid Search results: Object(uuid=_WeaviateUUIDInt('02acc4a4-d186-51bd-8b17-a25470a6a053'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=0.6219874620437622, explain_score='\\nHybrid (Result Set keyword,bm25) Document 02acc4a4-d186-51bd-8b17-a25470a6a053: original score 7.7068768, normalized score: 0.343784 - \\nHybrid (Result Set vector,hybridVector) Document 02acc4a4-d186-51bd-8b17-a25470a6a053: **original score 0.5154053**, normalized score: 0.27820346', is_consistent=None, rerank_score=-10.181857109069824)\nAny insights would be greatly appreciated!\n\n----------\n\n[DudaNogueira (2025-02-12T22:28:42.223Z)]: pc10:\n\n1.26.1\n\n\nHi @pc10 !!\nCan you make sure this also happens on latest version?\nThis is what I got running on 1.28.4:\nimport weaviate\nfrom weaviate import classes as wvc\n\n\nheaders = {\n    \"X-Openai-Api-Key\": os.environ.get(\"OPENAI_APIKEY\"),\n}\n\nclient = weaviate.connect_to_local(\n    headers=headers\n)\nprint(f\"Client: {weaviate.__version__}, Server: {client.get_meta().get('version')}\")\n# Client: 4.10.4, Server: 1.28.4\n\nclient.collections.delete(\"Test\")\nclient.collections.create(\n    name=\"Test\",\n    vectorizer_config=[\n        wvc.config.Configure.NamedVectors.text2vec_openai(\n            name=\"default\"\n        ),\n    ],\n)\ncollection = client.collections.get(\"Test\")\ncollection.data.insert({\"text\": \"Something about Brazil\", })\ncollection.data.insert({\"text\": \"Something about Pelé, best soccer player\", })\ncollection.data.insert({\"text\": \"Something about indian food\", })\n\nNow, I performed a search and printed all the infos:\nfor o in collection.query.hybrid(\n    query=\"futebol\", \n    #max_vector_distance=0.4,\n    return_metadata=wvc.query.MetadataQuery(score=True, explain_score=True, distance=True)\n    ).objects:\n    print(\"#\"*10)\n    print(o.properties)\n    print(o.metadata.distance, o.metadata.score, o.metadata.explain_score)\n\nand got this as output:\n##########\n{'text': 'Something about Pelé, best soccer player'}\nNone 0.699999988079071 \nHybrid (Result Set vector,hybridVector) Document 5f8f8671-27cb-407b-81cf-ae4560fc0186: original score 0.35348773, normalized score: 0.7\n##########\n{'text': 'Something about Brazil'}\nNone 0.46075865626335144 \nHybrid (Result Set vector,hybridVector) Document d194fb42-1bb5-414c-8e72-02fccb48039d: original score 0.23937017, normalized score: 0.46075866\n##########\n{'text': 'Something about indian food'}\nNone 0.0 \nHybrid (Result Set vector,hybridVector) Document 0e1fba05-f908-4a3c-9ce2-711ecd4ed062: original score 0.019589365, normalized score: 0\n\nNow, using max_vector_distance in a way to better understand it \nThose are the distances we will filter out:\n\nscore 0.35348773\nscore 0.23937017\nscore 0.019589365\n\nfor o in collection.query.hybrid(\n    query=\"futebol\", \n    max_vector_distance=1-0.020,\n    return_metadata=wvc.query.MetadataQuery(score=True, explain_score=True, distance=True)\n    ).objects:\n    print(\"#\"*10)\n    print(o.properties)\n    print(o.metadata.distance, o.metadata.score, o.metadata.explain_score)\n\nand this was the output:\n##########\n{'text': 'Something about Pelé, best soccer player'}\nNone 0.699999988079071 \nHybrid (Result Set vector,hybridVector) Document aa55119a-6d83-4161-85b6-217861031f0f: original score 0.35347474, normalized score: 0.7\n##########\n{'text': 'Something about Brazil'}\nNone 0.0 \nHybrid (Result Set vector,hybridVector) Document 2091b86c-e835-4da7-922f-24bcdd63c70c: original score 0.23937523, normalized score: 0\n\nI believe this is filtering against the scored vector distance (as it is in a hybrid search).\nSo whenever that value is closer to 1, it is closer to the query, instead of the other way around: bigger the value bigger the distance.\nLet me know if this helps!\nThanks!\n\n----------\n\n[pc10 (2025-02-14T15:50:13.237Z)]: DudaNogueira:\n\n    max_vector_distance=1-0.020,\n\n\n\nThank you for the quick response! I haven’t seen any filtering of results in weaviate 1.26.1, regardless of the max-vector-distance value I set. I will try this again on the upgraded version. Since we are using weaviate-vectorstore in production, I’ll need to check for potential regressions before upgrading.\nI’d also like to clarify the behavior of max-vector-distance. My understanding is that documents with a vector distance greater than max-vector-distance should be excluded. However, is the intuition here that the score returned from hybrid search represents similarity rather than actual distance?\nIf that’s the case, then the following values are similarity scores, and setting max_vector_distance = 0.98 filters out the 0.0195 document because its distance is higher:\n\n0.3534\n0.2393\n0.0195\n\nIs there a way to explicitly display the distance values in the search results to compare them directly with max-vector-distance for a more apples-to-apples comparison?\nThank you !\n\n----------\n\n[DudaNogueira (2025-02-14T18:30:16.071Z)]: Hi!\nThere isn’t, AFAIK.\nAlso, the vector distance may vary for different query and objects, so you couldn’t define a threshold solely on vector distance.\nSo when you do a hybrid search, the distance calculated for the vector part of the search will be normalized in order to be fused. And that normalized vector distance is the one you can filter out with max-vector-distance.\nLet me know if that helps!\nThanks!\n\n----------\n\n[Dirk (2025-02-17T08:30:06.019Z)]: Hi,\nIIRC there was a bug in the first release of the max vector distance that could cause some objects to be included even if their vector distance was larger than the threshold.\n\n\n\n pc10:\n\nI’d also like to clarify the behavior of max-vector-distance. My understanding is that documents with a vector distance greater than max-vector-distance should be excluded.\n\n\nyes, this is correct.\n\nSo when you do a hybrid search, the distance calculated for the vector part of the search will be normalized in order to be fused. And that normalized vector distance is the one you can filter out with max-vector-distance.\n\nThe filtering is happening before the normalization+fusion\n\n----------\n\n[pc10 (2025-02-18T18:58:34.591Z)]: Thank you. Do we know what stable-version has this bug fixed/resolved?\n\n----------\n\n[Dirk (2025-02-19T06:35:28.496Z)]: IIRC correctly one of the early 1.26.X releases. If I were you I would update to the lastest 1.26 point release",
    "date_created": "2025-02-12T19:05:14.410Z",
    "has_accepted_answer": false,
    "title": "Hybrid Search: max-vector-distance not filtering results as expected",
    "topic_id": 10288
  },
  {
    "user_id": 1312,
    "conversation": "[pc10 (2024-08-15T18:32:03.459Z)]: Description\n\nI am in the process of migrating  weaviate client from v3 to v4 and I am using haystack to integrate weaviate for my usecase. However when querying on collection using filters, I am getting the following grpc error\n\nWeaviateQueryError: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"grpc: trying to send message larger than max (486438681 vs. 104858000)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"grpc: trying to send message larger than max (486438681 vs. 104858000)\", grpc_status:8, created_time:\"2024-08-15T18:22:12.13303888+00:00\"}\"\n\nHere is the haystack link to query with filters. Haystack\nI am filtering on a very small subset of documents  in index and I see this error trying to get anything over 70-80 documents.\nI also did increase my timeout config to 600 sec. With default timeout config, I can hardly query 5 docs.\nAppreciate any help resolving this.\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method:  k8\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: Python\nMultitenancy?: No\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-08-15T21:20:26.346Z)]: Hi @pc10 !!\nWelcome to our community \nWhat is the size of each objects?\nThis error message indicates you are hitting the limit for the GRPC endpoint. This limit comes from here:\n\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate/blob/502456b502bbffac6f47e880eb1343662c5be16e/adapters/handlers/grpc/server.go#L33\n\n\n\n    \n      \n          \t\"github.com/weaviate/weaviate/usecases/auth/authentication/composer\"\n          \t\"google.golang.org/grpc\"\n          \t\"google.golang.org/grpc/credentials\"\n          \t_ \"google.golang.org/grpc/encoding/gzip\" // Install the gzip compressor\n          \t\"google.golang.org/grpc/health/grpc_health_v1\"\n          \n          \tv0 \"github.com/weaviate/weaviate/adapters/handlers/grpc/v0\"\n          \tv1 \"github.com/weaviate/weaviate/adapters/handlers/grpc/v1\"\n          )\n          \n          const maxMsgSize = 104858000 // 10mb, needs to be synchronized with clients\n          \n          func CreateGRPCServer(state *state.State) *GRPCServer {\n          \to := []grpc.ServerOption{\n          \t\tgrpc.MaxRecvMsgSize(maxMsgSize),\n          \t\tgrpc.MaxSendMsgSize(maxMsgSize),\n          \t}\n          \n          \t// Add TLS creds for the GRPC connection, if defined.\n          \tif len(state.ServerConfig.Config.GRPC.CertFile) > 0 || len(state.ServerConfig.Config.GRPC.KeyFile) > 0 {\n          \t\tc, err := credentials.NewServerTLSFromFile(state.ServerConfig.Config.GRPC.CertFile,\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nMy guess is that either payload in or out is passing that limit.\nLet me know if that helps.\nThanks!\n\n----------\n\n[pc10 (2024-08-15T21:52:53.285Z)]: I am  just trying to query using collection.query.fetch_objects with filter on a  property that takes the documentName.\nThe query filter is something like this -\nfilters = {\"field\": \"documentId\", \"operator\": \"in\", \"value\": [\"document_name1\", \"document_name2\", \"document_name3\"...etc] }\nis being sent to : collection.query.fetch_objects\nSo the payload to query isnt very huge.\nOn the flip side, When i extract ALL the documents in the index using\ncollection.iterator(include_vector=False, return_properties=properties) it returns the result. The index has document size about 9000 and return all of them without throwing an error.\nIt just with filtering, the underlying query.fecth_objects function is failing the request.\n\n----------\n\n[pc10 (2024-08-15T21:56:23.457Z)]: I see the limit is being set in the python-client. Is there a way to override it.\nI am confused as why simple query is maxing out the limit.\n\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate-python-client/blob/v4.7.1/weaviate/connect/base.py#L23\n\n\n\n    \n      \n          \n          from pydantic import BaseModel, field_validator, model_validator\n          \n          from weaviate.config import Proxies\n          from weaviate.types import NUMBER\n          \n          \n          JSONPayload = Union[dict, list]\n          TIMEOUT_TYPE_RETURN = Tuple[NUMBER, NUMBER]\n          MAX_GRPC_MESSAGE_LENGTH = 104858000  # 10mb, needs to be synchronized with GRPC server\n          GRPC_DEFAULT_OPTIONS = [\n              (\"grpc.max_send_message_length\", MAX_GRPC_MESSAGE_LENGTH),\n              (\"grpc.max_receive_message_length\", MAX_GRPC_MESSAGE_LENGTH),\n          ]\n          \n          \n          class ProtocolParams(BaseModel):\n              host: str\n              port: int\n              secure: bool\n\n----------\n\n[Dirk (2024-08-16T06:53:52.657Z)]: How big are your objects? You can set which objects are returned using return_properties=[“prop1”,…]. by default all non-blob properties are returned\n\n----------\n\n[pc10 (2024-08-27T18:15:09.134Z)]: Sorry for delayed response. Realized one of the properties being queried from weaviate (using  haystack)  is a metadata field that is quite large. Excluding that solved this error.\n\n\n\n Dirk:\n\nHow big are your objects? You can set which objects are returned using return_properties=[“prop1”,…]. by default all non-blob properties are returned\n\n----------\n\n[DudaNogueira (2024-08-27T18:23:57.644Z)]: Glad to hear that, @pc10 !!\nThanks for sharing!\n\n----------\n\n[dch239 (2024-09-20T23:29:47.801Z)]: Why is the GRPC MAX_GRPC_MESSAGE_LENGTH hardcoded on both weaviate core and client? I have a simple weaviate object with two properties, title and poster. My avg images are around 3 mb. When i try indexing using batch.dynamic() i see the same error described in this thread. Using batch.fixed() is a hacky workaround which can fail. It seems like such a basic feature. Not to mention we have been bottlenecked and forced to abandon Weaviate just because of this issue.\n\n----------\n\n[DudaNogueira (2024-09-23T08:51:56.104Z)]: hi @dch239 !! Welcome to our community \nUsing the fixed size batch is not a hacky solution at all.\nthe dynamic size batch will calculate the amount of objects to send based on the latency of the connection to the server.\nHowever, if your objects are big (for example, images), the size of your batches shouldn’t be defined by the number of objects to send, but by the size of each objects that are being sent.\nOn that case, using fixed size is more interesting, as you have a clear control of the size of the batch, and avoid to have a few big sized batches in favor of correctly sized batches depending on your objects.\nAlso, given enough resources, that is not a bottleneck, as you can increase the concurrent requests and have enough nodes on a cluster that can handle the load of your data.\nLet me know if that helps.\nThanks!\n\n----------\n\n[dch239 (2024-09-25T08:21:58.025Z)]: Nevertheless, the 10 mb harcoded limit still applies, right? If each of my image is >10 mb would I be able to import even with a fixed batch size of 1? My point is why is MAX_GRPC_MESSAGE_LENGTH hardcoded in the python client (weaviate/connect/base.py) and server side? Why is this not a variable in docker compose since it is technically possible to set the max message size?\n\n----------\n\n[gfwgfw (2024-12-04T04:48:55.384Z)]: Meet this issue today, and fix with set this environment variable:\nGRPC_MAX_MESSAGE_SIZE=104857600\n\n----------\n\n[DudaNogueira (2024-12-06T11:28:08.104Z)]: hi @gfwgfw !!\nThis environment variable GRPC_MAX_MESSAGE_SIZE was recently reproduced, so I have changed the solution to this thread to yours!\nThanks for sharing!",
    "date_created": "2024-08-15T18:32:03.399Z",
    "has_accepted_answer": true,
    "title": "GRPC trying to send message larger than max error : when trying collection.query.fetch_objects",
    "topic_id": 3362
  },
  {
    "user_id": 3003,
    "conversation": "[Michael_Clervi (2024-12-11T22:46:51.488Z)]: This question is not specific to Weaviate, however I am using Weaviate in an enterprise environment and the answer might inform future deployment decisions.\nI’ve noticed that DSPy has recently added support for images, like this:\n\n  \n      \n\n      langtrace.ai\n  \n\n  \n    \n\nAttribute Extraction from Images using DSPy - Langtrace\n\n  Transform AI Prototypes into Enterprise-Grade Products\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI’ve semi-successfully run the MIPROv2 optimizer on a simple program with a small training set of images. I can get it to work with gemini because of the long context window but it fails with openai, etc. - I suspect it’s stuffing many images base64 encoded into the text prompt during the prompt-writing stage.\nMy question is - are you aware of a way to send the image as an image instead of stuffing it in the text prompt, thereby overcoming context length limitations during the DSPy optimization process?\nUltimately this will become part of a multimodal RAG pipeline using Weaviate.\nThanks very much.",
    "date_created": "2024-12-11T22:46:51.435Z",
    "has_accepted_answer": false,
    "title": "DSPy with images",
    "topic_id": 9197
  },
  {
    "user_id": 3155,
    "conversation": "[DhanushKumar_R (2025-01-29T09:46:56.045Z)]: Consider i have two files one for HR and another for credit cards ,I have to build a vector store for both them but separately ,like when I have ask a HR related query ,i goes to HR and fetch only from there ,it should not go to credit card.Will anyone please share the documents for this to work on it\n\n----------\n\n[DudaNogueira (2025-01-29T10:33:07.010Z)]: Hi!\nCheckout this recipe we have using llamaindex:\n  \n\n      github.com/weaviate/recipes\n  \n\n  \n    integrations/llm-frameworks/llamaindex/sql-router-query-engine/sql-query-router.ipynb\n\n\n  main\n\n\n\n      {\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"pVo_25Tge76N\"\n   },\n   \"source\": [\n    \"## Installations\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"mBoH4EYA0oGq\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"%pip install llama_index llama_hub weaviate_client urllib3 llama-cpp-python llama-hub-youtube-transcript llama-index-readers-youtube-transcript\"\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThe llamaindex’s RouterQueryEngine will allow you to set up different indexes, and depending on the initial query, it will route to the most related one.\nDo you think this helps?\nThanks!\n\n----------\n\n[DhanushKumar_R (2025-01-29T11:02:27.274Z)]: Thanks for the reply,\nI am requesting any reference ,where i create two different collections for two different documents (i.e.)., HR document will store in separate vector store ,similarly credit card document will store in separate vector store ,\nhow can i perform embedding on both the documents simulatenously and push it into weaviate under different collections .\n\n----------\n\n[DudaNogueira (2025-01-29T19:11:21.229Z)]: Hi!\nYou can create the two collections, and define the vectorizer configurations for each.\nWhenever you ingest content, Weaviate will vectorize it for you.\nIf you are using llamaindex, you can definie the collection name using a different index_name.\nLet me know if that helps!\nThanks!\n\n----------\n\n[DhanushKumar_R (2025-01-30T04:39:53.966Z)]: Thank you so much for your response ,May I have any references, please\n\n----------\n\n[DudaNogueira (2025-01-30T13:38:36.970Z)]: Hi!\nWe have some recipes using llamaindex here:\n  \n      \n\n      github.com\n  \n\n  \n    recipes/integrations/llm-frameworks/llamaindex at main · weaviate/recipes\n\n\n  This repository shares end-to-end notebooks on how to use various Weaviate features and integrations! - weaviate/recipes\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI have recently rewritten them to use the v4 client and integration, so they are up to date.\nHere you can find a simple query engine:\n\n  \n\n      github.com/weaviate/recipes\n  \n\n  \n    integrations/llm-frameworks/llamaindex/simple-query-engine/simple-query-engine.ipynb\n\n\n  main\n\n\n\n      {\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"%pip install -U weaviate-client llama-index llama-index-vector-stores-weaviate llama-index-embeddings-openai\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 3,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import os\\n\",\n    \"import openai\\n\",\n    \"import weaviate\\n\",\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor instance:\n# Let's name our index properly as BlogPost, as we will need it later.\nvector_store = WeaviateVectorStore(\n    weaviate_client=client, index_name=\"BlogPost\"\n)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\nindex = VectorStoreIndex.from_documents(\n    documents, storage_context=storage_context\n)\n\nThis is how you can set the name of the collection (note the index_name).\nNow this recipe, combined with the aforementioned example, can get you two indices, that you can feed to the query router as per the Query Router example.\nLet me know if that helps.",
    "date_created": "2025-01-29T09:46:56.001Z",
    "has_accepted_answer": false,
    "title": "Vector database",
    "topic_id": 9937
  },
  {
    "user_id": 1214,
    "conversation": "[elias.gabriel (2024-10-10T02:04:46.242Z)]: Description\nI see that there’s a limit on the number of results that can be returned by a query - on K8 deployments, looks like that limit is 100 by default.\nThe default behavior is just to cut off the response at that limit; regardless of whether or not there could be more results.\nIs there a way to tell if a query response was cut off? otherwise it seems really difficult to diagnose problems where returned results don’t meet expectations (or worse, things fly under the radar) — i say that having not known about the limit, encountering problems with missing response data, and spending a while trying to figure out what’s going on\nIn any case, a documentation update would also be useful to explain the behavior.\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python 3, latest\nMultitenancy?: No\n\n----------\n\n[elias.gabriel (2024-10-15T20:06:23.259Z)]: Just want to bump this, in case there is something obvious I’m missing.\n\n----------\n\n[DudaNogueira (2024-10-15T21:20:50.046Z)]: hi @elias.gabriel !!\nSorry for the delay here, had some vacation last weeks  \nI am not sure yet what that 100 limit is about, but it definitely isn’t a Weaviate configuration. Probably a K8s one. Could not find much info about it, TBH.\nHere is where you define the QUERY_MAXIMUM_RESULTS:\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate-helm/blob/9f03c480efb75e40e0b302fb185a6bb8501ccfca/weaviate/values.yaml#L325\n\n\n\n    \n      \n          PROMETHEUS_MONITORING_ENABLED: false\n          PROMETHEUS_MONITORING_GROUP: false\n          \n          # Set a MEM limit for the Weaviate Pod so it can help you both increase GC-related \n          # performance as well as avoid GC-related out-of-memory (“OOM”) situations\n          # GOMEMLIMIT: 6GiB\n          \n          # Maximum results Weaviate can query with/without pagination\n          # NOTE: Affects performance, do NOT set to a very high value.\n          # The default is 100K\n          QUERY_MAXIMUM_RESULTS: 100000\n          \n          # whether to enable vector dimensions tracking metric\n          TRACK_VECTOR_DIMENSIONS: false\n          \n          # whether to re-index/-compute the vector dimensions metric (needed if upgrading from weaviate < v1.16.0)\n          REINDEX_VECTOR_DIMENSIONS_AT_STARTUP: false\n          \n          ##########################\n          # API Keys with ENV Vars #\n          ##########################\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThe outcut will only jump in if you explicitly call it.\nHere we have a nice explanation about it\nNow, let’s see it in action!\nconsider this code:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n)\n\ncollection.data.insert_many([\n    {\"text\": \"something about dogs\"},\n    {\"text\": \"something about cats\"},\n    {\"text\": \"something about houses\"},\n    {\"text\": \"something about commercial buildings\"},\n\n])\n\nNow, if I do a query, without outcut, I get everything:\nresults = collection.query.near_text(\n    query=\"animals\",\n    # auto_limit=2,\n    return_metadata=wvc.query.MetadataQuery(distance=True)\n)\nfor i in results.objects:\n    print(\"###\")\n    print(i.properties)\n    print(i.metadata.distance)\n\nthe results:\n\n\n{‘text’: ‘something about dogs’}\n0.16042447090148926\n\n{‘text’: ‘something about cats’}\n0.17177188396453857\n\n{‘text’: ‘something about houses’}\n0.22456467151641846\n\n{‘text’: ‘something about commercial buildings’}\n0.23881018161773682\n\nIf I now add auto_limit=1, it will only bring the dogs and cats object. If set it to 2, it will bring me all objects.\nLet me know if this clarifies.\nThanks!\n\n----------\n\n[elias.gabriel (2024-10-15T23:24:06.189Z)]: Hi @DudaNogueira,\nI made a small example to clarify what I’m talking about:\n\n  \n      \n\n      github.com\n  \n\n  \n    GitHub - thearchitector/code-snippets: Code snippets and reproductions for bug...\n\n  main\n\n  Code snippets and reproductions for bug reports, etc. - thearchitector/code-snippets\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI span up a minikube cluster on my machine, and installed the latest weaviate helm chart using a really simple config and all the chart defaults (including the env variable you mention).\nIf you create a basic collection, then add 200 objects, then query for all those objects using the created uuids, it only returns 100 of them; there is no indication that the query response was incomplete.\n\n----------\n\n[DudaNogueira (2024-10-16T02:17:44.007Z)]: Oh, ok. Now I understand it! I was totally off, hehehe\nThat’s strange, as it only returned 44, if no limits are defined.\nhere simpler code to reproduce:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n)\n\nresponse = collection.data.insert_many([{\"index\": i} for i in range(200)])\ninserted_uids_count = len(response.uuids.values())\n\nquery = collection.query.fetch_objects(\n            filters=wvc.query.Filter.by_id().contains_any(response.uuids.values()),\n            # limit=200\n        )\nassert len(query.objects) == inserted_uids_count\n\nhowever, if we specify a limit, it will work.\nThis smells like a bug to me. I have asked about this internally.\nI’ll get back here when I get more info.\nThanks!\n\n----------\n\n[elias.gabriel (2024-10-16T04:20:04.588Z)]: Huh, that’s interesting; your snippet only ever returns 100 for me, same as the one I provided, not 44; that seems like a bug in itself.\nIf I update the query_defaults.limit parameter in the chart values to 150, the query then returns 150, so that chart configuration (which looks like gets mounted to a YAML configuration and passed through to weaviate --config-file), is definitely responsible for the behavior.\nYou are right, though, in that if I explicitly pass a limit to the query then I get all 200 objects as expected; I guess that makes sense given that the config seems to imply its the “default limit for queries that don’t supply one.”\nIf that is indeed the behavior, then my original question is more like “is there a way to tell if a query hit the limit (default or provided) or not?”\nAlso I want to emphasize that I can’t actually reproduce this problem using a Docker Compose setup, even if I supply the helm-produced yaml config to weaviate via the same CLI argument. It’s only in K8 deployments. If the default limit thing is an intended feature, then the fact it doesn’t work on Docker depls seems like another bug?\n\n----------\n\n[DudaNogueira (2024-10-16T12:10:52.201Z)]: Oh, by the way, my outcome was using a docker image.\nAh!!! just checked, silly me. hehehe\nBecause I have reused a docker-compose.yaml I have in my “lab” folder, I had QUERY_DEFAULTS_LIMIT set to 44… \nSo if I remove that property, the query will result by default in 10, which is consistent with the doc here\nSo I query_defaults is the same as QUERY_DEFAULTS_LIMIT.\nNow if you know the QUERY_DEFAULTS_LIMIT, and your results is exactly that value, you probably have more objects",
    "date_created": "2024-10-10T02:04:46.196Z",
    "has_accepted_answer": false,
    "title": "Determine if a query response was cut off",
    "topic_id": 4518
  },
  {
    "user_id": 30,
    "conversation": "[SomebodySysop (2024-11-27T18:10:53.476Z)]: Description\n\nWhat is the process for changing the vectorizer model in my schema?\n$schema = [\n“class” => “SolrCopy01”,\n“description” => “Class representing the SolrAI index”,\n“vectorizer” => “text2vec-openai”,\n“moduleConfig” => [\n“generative-openai” => [\n“model” => “gpt-3.5-turbo”,\n],\nI’d like to change it to gpt-4o-mini.\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: WCS\nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\nI do everything using REST API.\n\n----------\n\n[DudaNogueira (2024-11-28T11:47:56.113Z)]: hi @SomebodySysop !!\nChanging the vectorization model of a collection would trigger a re-vectorization of the entire collection, which Weaviate does not support.\nThis is not possible as of now, as well as adding a named vector, as we have not implemented async vectorization.\nThe only way for now is to create a new collection with the new vectorizer configuration, and then copy the data from the old collection to the new one.\n\n----------\n\n[SomebodySysop (2024-11-28T22:01:37.418Z)]: OK.  Do you know if gpt-4o or gpt-4o-mini are supported in generative-openai?\nUpdate:  Never mind.  Yes, they are:  Generative AI | Weaviate\n\n----------\n\n[SomebodySysop (2024-11-28T22:09:38.067Z)]: So, I know how to create a new collection in the cluster.\nHow do I copy the data from the old collection to the new one using REST API?  That is not discussed in the documentation: Migrate data | Weaviate\n\n----------\n\n[DudaNogueira (2024-11-29T10:42:15.798Z)]: Note that on 1.27+ you can now change the generative configuration without the need to recreate the collection.\nThe best approach for the migration is the one described here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate\n\n  Learn how to migrate data within Weaviate for easy data handling.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBecause this will leverage GRPC for reading and inserting the data.\nYou can get all objects if using the “cursor api”. It will give you the after parameter that allows you to bring the next objects:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAdditional operators | Weaviate\n\n  Syntax\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[SomebodySysop (2024-11-29T12:16:12.460Z)]: DudaNogueira:\n\nThe only way for now is to create a new collection with the new vectorizer configuration, and then copy the data from the old collection to the new one.\n\n\nI am confused by this, because your next message says:\n\n\n\n DudaNogueira:\n\nNote that on 1.27+ you can now change the generative configuration without the need to recreate the collection.\n\n\nBut I still have to migrate the data.\nSo, I’m utterly confused.\n$schema = [\n“class” => “SolrCopy01”,\n“description” => “Class representing the SolrAI index”,\n“vectorizer” => “text2vec-openai”,\n“moduleConfig” => [\n“generative-openai” => [\n“model” => “gpt-3.5-turbo”,\n],\n\nI want to change the model to gpt-4o-mini\nWhat I thought I understood was that I needed to create a new schema, which would create a new collection, and then migrate the data from the old collection to the new.\nscbbs01 collection 2024-11-29_4-07-341078×330 30.3 KB\nSo, in my case, I would create a new schema SolrCopy02 which would then create the SolrCopy02 collection.  Then I would migrate the SolrCopy01 collection data to the SolrCopy02 collection.\nWhat you wrote above doesn’t sound like that process.  Or, I’m just not understanding the terminology.  But, as gpt-3.5-turbo is a legacy model, I probably need to update soon.\n\n----------\n\n[DudaNogueira (2024-11-29T19:30:56.666Z)]: OK, let me clarify.\nWhen you configure the vectorizer, it means that your data is going to be vectorized with that model.\nSo for example, let’s say you select a vectorizer that embed vectors with 300 dimensions.\nNow you want to change to a different model with, let’s say, 1536 dimensions.\nYou will need to vectorize all your content again, because the vectors came from different models. Even if they had the same dimensionality, they came from different models.\nSo in order to change the vectorizer, you need to both define the model accordingly and to vectorize all your content again.\nSo the vectorizer configuration of a collection is not mutable.\nSince Weaviate 1.27 version, the generative configuration is now mutable. This means that if you configured your collection to use, for example, cohere as the generative, you can change it to open ai, for example.\ngpt-3.5, gpt-4 and so on, is a generative configuration.\nLet me know if this helps!\nThanks!\n\n----------\n\n[SomebodySysop (2024-11-30T03:46:19.980Z)]: DudaNogueira:\n\nSince Weaviate 1.27 version, the generative configuration is now mutable. This means that if you configured your collection to use, for example, cohere as the generative, you can change it to open ai, for example.\ngpt-3.5, gpt-4 and so on, is a generative configuration.\n\n\nI really appreciate the explanation, but it’s a bird’s eye view of the process whereas I need the steps.  I want to change the schema from:\n$schema = [\n“class” => “SolrCopy01”,\n“description” => “Class representing the SolrAI index”,\n“vectorizer” => “text2vec-openai”,\n“moduleConfig” => [\n“generative-openai” => [\n“model” => “gpt-3.5-turbo”,\n],\n\nto\n$schema = [\n“class” => “SolrCopy01”,\n“description” => “Class representing the SolrAI index”,\n“vectorizer” => “text2vec-openai”,\n“moduleConfig” => [\n“generative-openai” => [\n“model” => “gpt-4o-mini”,\n],\n\nFrom the explanation above, it sounds like all I need to do is update the schema and I’m done.  But, you also state that since I’m changing the vectorizer, I need to re-vectorize the content – which makes sense.  And if that’s the case, I’m really talking about migrating content from SolrCopy01 to SolrCopy02, as opposed to just modifying the schema of SolrCopy01.\nSo, I still do not know how to proceed.\n\n----------\n\n[andrewisplinghoff (2024-12-02T10:47:27.699Z)]: From what you wrote, you do not actually want to change the vectorizer, in both your schemas you state it as text2vec-openai. So the embedding model will stay the same and with that, you can keep your collection with the precalculated embeddings of that type.\nThe generative part is different from the vectorizer, it is used in RAG to come up with a response suitable returning to a user query at runtime (while embeddings are calculated during data ingestion). So it makes sense that Weaviate does not have a problem with the user changing that setting lateron. Hope that clarifies things - if not, maybe check out the documentation here to read more on the topic: Generative AI | Weaviate\n\n----------\n\n[SomebodySysop (2024-12-04T08:18:33.497Z)]: andrewisplinghoff:\n\nFrom what you wrote, you do not actually want to change the vectorizer, in both your schemas you state it as text2vec-openai. So the embedding model will stay the same and with that, you can keep your collection with the precalculated embeddings of that type.\n\n\nThis seems to indicate that the opposite is true: Slack\nHowever, if I can update the schema without updating the collection, that sounds great!  So, using just curl, how do I get from\n\n\n\n SomebodySysop:\n\n$schema = [\n“class” => “SolrCopy01”,\n“description” => “Class representing the SolrAI index”,\n“vectorizer” => “text2vec-openai”,\n“moduleConfig” => [\n“generative-openai” => [\n“model” => “gpt-3.5-turbo”,\n],\n\nto\n$schema = [\n“class” => “SolrCopy01”,\n“description” => “Class representing the SolrAI index”,\n“vectorizer” => “text2vec-openai”,\n“moduleConfig” => [\n“generative-openai” => [\n“model” => “gpt-4o-mini”,\n],\n\n\n\nCan I do from the query screen in WCS?  If not, how can I do it using REST API (curl)?\n\n----------\n\n[SomebodySysop (2024-12-04T08:45:55.884Z)]: It would also be nice if I could edit the collection in WCS, as this screen seems to indicate, but it doesn’t allow me to change anything:\nedit collection in wcs 2024-12-04_0-44-051103×779 51.4 KB\n\n----------\n\n[DudaNogueira (2024-12-06T18:59:39.144Z)]: Hi!\nYou can change the generative model as stated here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage collections | Weaviate\n\n  Every object in Weaviate belongs to exactly one collection. Use the examples on this page to manage your collections.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nIt doesn’t have a curl example. For that, you need to use this endpoint:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nWeaviate\n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFirst, get the collection json, change it, and PUT the payload, just like it is need for activating the ACORN\nLet me know if this help!\nThanks!\n\n----------\n\n[SomebodySysop (2024-12-08T23:39:22.021Z)]: OK, I think I’m getting it through my thick skull.  Since I’m using curl, I just have three steps:\n\nGet the existing schema:\n\ncurl --request GET \n-H “Content-Type: application/json” \n–url http://localhost:8080/v1/schema/Test\n\n\nMake whatever change I want.\n\n\nPut it back:\n\n\ncurl \n–request PUT \n-H “Content-Type: application/json” \n–url http://localhost:8080/v1/schema/Test \n–data '{\n“class”:“Test”, etc…\nRight?\nFinal, last question:\nIf all I am changing in the schema is the model of the generative-openai:\n\n\n\n SomebodySysop:\n\n$schema = [\n“class” => “SolrCopy01”,\n“description” => “Class representing the SolrAI index”,\n“vectorizer” => “text2vec-openai”,\n“moduleConfig” => [\n“generative-openai” => [\n“model” => “gpt-3.5-turbo”,\n],\n\nto\n$schema = [\n“class” => “SolrCopy01”,\n“description” => “Class representing the SolrAI index”,\n“vectorizer” => “text2vec-openai”,\n“moduleConfig” => [\n“generative-openai” => [\n“model” => “gpt-4o-mini”,\n],\n\n\n\nDo I need to rebuild / migrate the collection?\nThanks for hanging in there with me.  Once I get it, I’ve got it.  But it sometimes takes me a  minute.\n\n----------\n\n[Dirk (2024-12-09T06:05:41.536Z)]: SomebodySysop:\n\nIf all I am changing in the schema is the model of the generative-openai:\n…\nDo I need to rebuild / migrate the collection?\n\n\nNo  This can be changed without rebuilding since 1.27.X (don’t remember the exact version)\n\n----------\n\n[DudaNogueira (2024-12-09T12:52:29.106Z)]: Hi @SomebodySysop !\nNo need to reindex / rebuild / migrate the collection for changing the generative configuration.\nhere we have a list of collection mutability:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection definition | Weaviate\n\n  Schema Configuration in Weaviate\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nAll configurations in that list can be changed using the client or calling the REST endpoint as you mentioned.\nEverything else will require a new collection with that setting already changed, copy the data over, and with that, a reindex will be triggered.\nHope this helps!\nThanks!\n\n----------\n\n[SomebodySysop (2025-01-22T01:01:33.383Z)]: I followed the steps to change the generative-openai model, and it worked.\nHOWEVER, I am now getting this error on all hybrid searches:\nobject vector search at index solrcopy01: shard solrcopy01_rsFKdoPa7JaL: vector search: 3072 vs 1536: vector lengths don’t match\nNeed Help!\nMessage\tQuery (solrai_getContext) : { Get { SolrCopy01 ( limit: 10 hybrid: { query: “Rules for reuse of photography in television agreements between episodes. Be sure to always reference any relevant memorandums of agreement and MOAs in your response.” alpha: 0.8 } where: { operator: And, operands: [ { path: [“site”], operator: Equal, valueText:“https://labor.booksai.org/”},{ operator: Or, operands: [ { path: [“groups”], operator: Equal, valueText: “SAG-AFTRA” } ] },{ operator: Or, operands: [ { path: [“taxonomy”], operator: Equal, valueText: “Current” }, { path: [“taxonomy”], operator: Equal, valueText: “Archived” } ] } ] } ){ _additional { distance score } docId site title nid type public url content taxonomy groups date summary questions sourceUrl solrId } } }\nMessage\tResponse (solrai_getContext) : Array ( [data] => Array ( [Get] => Array ( [SolrCopy01] => ) ) [errors] => Array ( [0] => Array ( [locations] => Array ( [0] => Array ( [column] => 4 [line] => 4 ) ) [message] => explorer: get class: vector search: object vector search at index solrcopy01: shard solrcopy01_rsFKdoPa7JaL: vector search: 3072 vs 1536: vector lengths don’t match [path] => Array ( [0] => Get [1] => SolrCopy01 ) ) ) [_elapsed_time] => 0.73112106323242 )\n\n----------\n\n[Mohamed_Shahin (2025-01-22T12:13:06.983Z)]: Hi @SomebodySysop, If you are not on latest 1.28.3, you may encountered this bug Mismatch in Vector Dimensions During Hybrid Search vs Vector Search · Issue #6873 · weaviate/weaviate · GitHub\nCould you please upgrade and retry? If this is not your case, please open a new topic with all information so we can investigate.\n\n----------\n\n[SomebodySysop (2025-01-22T22:53:36.590Z)]: These queries are on the scbbs01 cluster, which I upgraded last night to 1.28.3.\nThe first hybrid query I executed went through.  But the second returned this error, which I’ve never seen before:\nQuestion: where are the special cases discussed, in which document(s)?\nconcept: Core concept: “Location of special cases in specific documents.” Be sure to always reference any relevant memorandums of agreement and MOAs in your response.\nArray\n(\n[errors] => Array\n(\n[0] => Array\n(\n[locations] => Array\n(\n[0] => Array\n(\n[column] => 37\n[line] => 7\n)\n                    )\n\n                [message] => Syntax Error GraphQL request (7:37) Expected :, found Name \"of\"\n\n6: \\u0009\\u0009\\u0009  hybrid: {\n7: \\u0009\\u0009\\u0009\\u0009query: “Core concept: “Location of special cases in specific documents.” Be sure to always reference any relevant memorandums of agreement and MOAs in your response.”\n^\n8: \\u0009\\u0009\\u0009\\u0009alpha: 0.7\n                [path] => \n            )\n\n    )\n\n[_elapsed_time] => 0.10042881965637\n\n)\nThis is the exact query sent:\nQuery (solrai_getContext) : { Get { SolrCopy01 ( limit: 30 hybrid: { query: “Core concept: “Location of special cases in specific documents.” Be sure to always reference any relevant memorandums of agreement and MOAs in your response.” alpha: 0.7 } where: { operator: And, operands: [ { path: [“site”], operator: Equal, valueText:“https://labor.booksai.org/”},{ operator: Or, operands: [ { path: [“groups”], operator: Equal, valueText: “SAG-AFTRA” } ] },{ operator: Or, operands: [ { path: [“taxonomy”], operator: Equal, valueText: “Current” } ] } ] } ){ _additional { distance score } docId site title nid type public url content taxonomy groups date summary questions sourceUrl solrId } } }\nWhen I tried it again, using different concept, it worked.  Can you see what the problem might be?\n\n----------\n\n[DudaNogueira (2025-01-23T19:44:58.504Z)]: hi @SomebodySysop !!\n\n\n\n SomebodySysop:\n\n{query: “Core concept: “Location of special cases in specific documents.” Be sure to always reference any relevant memorandums of agreement and MOAs in your response.”}\n\n\nIn your query, it seems to have an unescaped \" there \nCan you try escaping that inside \" with \\ \"\nLet me know if that helps.\nThanks!\n\n----------\n\n[SomebodySysop (2025-01-23T20:57:31.613Z)]: Yep.  That was it.\nquery solrai_getContext { Get { SolrCopy01 ( limit: 30 hybrid: { query: “Core concept: \"Location of special cases in specific documents.\" Be sure to always reference any relevant memorandums of agreement and MOAs in your response.” alpha: 0.7 } where: { operator: And, operands: [ { path: [“site”], operator: Equal, valueText:“https://labor.booksai.org/”},{ operator: Or, operands: [ { path: [“groups”], operator: Equal, valueText: “SAG-AFTRA” } ] },{ operator: Or, operands: [ { path: [“taxonomy”], operator: Equal, valueText: “Current” } ] } ] } ){ _additional { distance score } docId site title nid type public url content taxonomy groups date summary questions sourceUrl solrId } } }",
    "date_created": "2024-11-27T18:10:53.434Z",
    "has_accepted_answer": true,
    "title": "What is the process for changing vectorizer model",
    "topic_id": 8661
  },
  {
    "user_id": 3143,
    "conversation": "[AbhinavKasubojula (2025-01-03T17:04:35.347Z)]: if i wanted to store persisted data. is it possible with weaviate?\n\n----------\n\n[DudaNogueira (2025-01-03T18:09:33.424Z)]: hi @AbhinavKasubojula !!\nWelcome to our community! \nSure thing!\nHow are you deploying Weaviate?\nThis information (along with others that we ask when you open the thread) will allow me to help you better.\nThanks!\n\n----------\n\n[AbhinavKasubojula (2025-03-13T17:45:55.095Z)]: Thanks @DudaNogueira, for reviewing my query.\nhere is my docker-compose yaml:\nversion: '3.4'\n \nservices:\n  weaviate:\n    image: semitechnologies/weaviate:1.28.1\n    ports:\n        - \"8080:8080\"\n        - \"50051:50051\"\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: \"true\"\n      ENABLE_MODULES: text2vec-ollama,generative-ollama  # Ensure both modules are enabled\n      DEFAULT_VECTORIZER_MODULE: text2vec-ollama\n      TEXT2VEC_OLLAMA_APIKEY: \"http://ollama:11434\"  # Use container name 'ollama' instead of localhost\n      TEXT2VEC_OLLAMA_ENDPOINT: \"http://ollama:11434\"  # Use container name 'ollama' instead of localhost\n      GENERATIVE_MODEL_APIKEY: \"\"  # Empty as you're not using this for now\n      GENERATIVE_MODEL_ENDPOINT: \"http://ollama:11434\"  # Use container name 'ollama' instead of localhost\n \n  ollama:\n    image: ollama/ollama:latest\n    ports:\n      - \"11434:11434\"\n    volumes:\n      - ollama_data:/root/.ollama\n \nvolumes:\n  ollama_data:\n\n\nwe are using docker container to run the weaviate - client.\ndata = [{\n\"company_name\" : \"XXX\",\n\"projects\" : \"1.Dam 42 rehabilitation Design, scope of work: Design, project value: 217000, 2.Dam44,45,48 and 50 rehabilitation design, scope of work: design, project value:962,000,3.Ajies & daguey rehab design, scope of work:design and assessments, project value:112,500,4.south Carolina dam assessment, scope of work: design and assessments, project value:87,500\",\n\"engineers\" : \"Administrative:5, architect:1, CADD technician:4, civil engineer:4, construction inspector:10, electrical engineer:1, environmental engineer: 1, geotechnical engineer:3, gis specialist:1, hydrologist:1, mechanical engineer:2,project manager:4\"\n},\n{\n\"company_name\" : \"YYY\",\n\"projects\" : \"1.Cherokee nation roads department multiple task orders, scope of work:roadway, bridge,ROW,drainage,waterline, sewer, structural design, storm design, project value: 2,449794, 2.BIA A-E services, scope of work:field investigation, waterline, construction docs, SUE level B, project value:243931, 3.BIA A-E services, TO-3 Quinault detention, WA, scope of work:stormwater drainage, site design, waterline, sewer, project value:172,000\" ,\n\"engineers\" : \"administrative:7, CADD technician:2, civil engineer:12, land surveyor:1, engineer intern:4, land survey intern:2, survey technician:5, right of way agent:3, field technician:3\"\n},\n{\n\"company_name\" : \"AA Engineering, Inc.\",\n\"projects\" : \"Automation; Controls; Instrumentation;  Educational Facilities; Classrooms;  Industrial; Manufacturing\",\n\"engineers\" : \"Administravite:14, CADD Technician:14, construction inspector:1, cost engineer/estimator:1, electrical engineer:9, mechanical engineer:17\"\n},\n{\n\"company_name\" : \"VV Consultants, Inc\",\n\"projects\" : \"Airports; Terminals and Hangars; Freight; Bridges; commecal building; shopping; das(concrete arch); urba renewals; comunitydevelopment\",\n\"engineers\" : \"Administravite:114, CADD Technician:31, construction inspector:1, cost engineer/estimator:1, electrical engineer:9, mechanical engineer:17,civil engineer:181,archaeologist:12,structual engineer:44\"\n}]\n\ndef CreateCollectionAndLoad():\n\n    client = weaviate.connect_to_local()\n    print(f\"Client: {weaviate.__version__}, Server: client.get_meta().get('version')\")\n    collection_name1 = \"name\"\n\n    client.collections.delete(collection_name1)\n    client.collections.create(\n            name=collection_name1,\n            vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n            #vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n            #   api_endpoint=\"http://host.docker.internal:11434\",\n            #  model=\"nomic-embed-text\"\n            \n            generative_config=wvc.config.Configure.Generative.ollama(\n                api_endpoint=\"http://host.docker.internal:11434\",  \n                model=\"llama3.2\"\n            )\n        )\n    collection = client.collections.get(\"name\")\n    with collection.batch.dynamic() as batch:\n        for item in data:\n            emb = compute_embeddings(item[\"projects\"]).tolist()\n            batch.add_object({\n                \"company_name\":item[\"company_name\"],\n                \"projects\":item[\"projects\"],\n                \"engineers\":item[\"engineers\"]\n            },\n            vector=emb)\n\n\nCreateCollectionAndLoad()\n\n----------\n\n[DudaNogueira (2025-03-13T20:06:24.398Z)]: AbhinavKasubojula:\n\nGENERATIVE_MODEL_ENDPOINT\n\n\nHi!\nWhere did you get this environment variable? It doesn’t exist. \nNote that you are not defining any vectorizer:\nvectorizer_config=wvc.config.Configure.Vectorizer.none(),\n\nit must be:\nvectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(),\n\nApart from that, you have a mounted volume, so your data should persist.\nCan you send the exact steps you are doing to spin it up and down?\nLet me know if that helps.\nThanks!\n\n----------\n\n[AbhinavKasubojula (2025-03-13T21:00:49.511Z)]: Hi @DudaNogueira ,\nThanks for pointing that out!\nHere’s what I’m doing to spin it up and down:\n\nTo start: docker-compose up -d\nTo stop: docker-compose down\nLet me know if I should be doing anything differently or if you have any suggestions.\n\n----------\n\n[AbhinavKasubojula (2025-03-13T21:12:38.252Z)]: if I change\nvectorizer_config=wvc.config.Configure.Vectorizer.none(),\nto: vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(),\nI’m unable to load data in collection,\nclient = weaviate.connect_to_local(\n    port=8080,\n    grpc_port=50051,\n    additional_config=AdditionalConfig(\n        timeout=Timeout(init=30, query=60, insert=120)  # Values in seconds\n    )\n)\nprint(f\"Client: {weaviate.__version__}, Server: client.get_meta().get('version')\")\ncollection_name = \"Notices\"\nclient.collections.create(\n        name=collection_name,\n        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(),\n        generative_config=wvc.config.Configure.Generative.ollama(\n            api_endpoint=\"http://host.docker.internal:11434\",  \n            model=\"llama3.2\"\n        )\n    )\ncollection = client.collections.get(collection_name)\nwith collection.batch.dynamic() as batch:\n    for item in data:\n        emb = compute_embeddings(item[\"engineers\"]).tolist()\n        batch.add_object({\n            \"company_name\":item[\"company_name\"],\n            \"engineers\":item[\"engineers\"]\n        },\n        vector=emb)\nfor i in collection.iterator():\n    print(i)\n\ncollection = client.collections.get(collection_name)\nprint(len(list(collection.iterator())))\nfor i in collection.iterator():\nprint(i.properties)\nclient.close()\n\n----------\n\n[DudaNogueira (2025-03-14T20:04:52.587Z)]: Can you check this:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBatch import | Weaviate\n\n  Batch imports are an efficient way to add multiple data objects and cross-references.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBasically, adding a way to check if there was any issues in the batch:\nthis part, outside of the with context\nfailed_objects = collection.batch.failed_objects\nif failed_objects:\n    print(f\"Number of failed imports: {len(failed_objects)}\")\n    print(f\"First failed object: {failed_objects[0]}\")\n\n----------\n\n[AbhinavKasubojula (2025-03-14T20:49:23.011Z)]: AbhinavKasubojula:\n\nHi @DudaNogueira ,\nThanks for pointing that out!\nHere’s what I’m doing to spin it up and down:\n\nTo start: docker-compose up -d\nTo stop: docker-compose down\nLet me know if I should be doing anything differently or if you have any suggestions.\n\n\n\nCould you please help me resolve the issue with data persistence?\n\n----------\n\n[DudaNogueira (2025-03-17T14:41:24.279Z)]: Can you try this one?\nversion: '3.4'\n \nservices:\n  weaviate:\n    image: semitechnologies/weaviate:1.28.1\n    volumes:\n        - weaviate_data:/var/lib/weaviate\n    ports:\n        - \"8080:8080\"\n        - \"50051:50051\"\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: \"true\"\n      ENABLE_MODULES: text2vec-ollama,generative-ollama  # Ensure both modules are enabled\n      DEFAULT_VECTORIZER_MODULE: text2vec-ollama\n      TEXT2VEC_OLLAMA_APIKEY: \"http://ollama:11434\"  # Use container name 'ollama' instead of localhost\n      TEXT2VEC_OLLAMA_ENDPOINT: \"http://ollama:11434\"  # Use container name 'ollama' instead of localhost\n      GENERATIVE_MODEL_APIKEY: \"\"  # Empty as you're not using this for now\n      GENERATIVE_MODEL_ENDPOINT: \"http://ollama:11434\"  # Use container name 'ollama' instead of localhost\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n \n  ollama:\n    image: ollama/ollama:latest\n    ports:\n      - \"11434:11434\"\n    volumes:\n      - ollama_data:/root/.ollama\n \nvolumes:\n  ollama_data:\n  weaviate_data:\n\nCheck here for more information on using Weaviate with docker compose:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nDocker | Weaviate\n\n  Weaviate supports deployment with Docker.",
    "date_created": "2025-01-03T17:04:35.302Z",
    "has_accepted_answer": false,
    "title": "Create persisted database",
    "topic_id": 9555
  },
  {
    "user_id": 512,
    "conversation": "[rlima (2024-02-21T18:04:01.641Z)]: Description\nI’m facing a frequent issue, the “Deadline Exceeded”.\nOn batching insert:\n“weaviate.exceptions.WeaviateBatchError: Query call with protocol GRPC batch failed with message Deadline Exceeded.”\nOn near_text query:\n“weaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message Deadline Exceeded.”\nHow to solve this issue?\nServer Setup Information\n\nWeaviate Server Version: 1.23.10\nDeployment Method: docker\nMulti Node? Number of Running Nodes:  1\nClient Language and Version: english\n\nAny additional Information\n\npython: 3.10\nweaviate-python:4.4.4\nos: debian 12 bookworm\n\n“”\" docker-compose config\n´´´\nversion: ‘3.4’\nservices:\nweaviate:\ncommand:\n- --host\n- 0.0.0.0\n- --port\n- ‘8080’\n- --scheme\n- http\nimage: semitechnologies/weaviate:1.23.10\nports:\n- 8080:8080\n- 50051:50051\nvolumes:\n- weaviate_data:/var/lib/weaviate\nrestart: on-failure:0\nenvironment:\nQUERY_DEFAULTS_LIMIT: 25\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: ‘true’\nPERSISTENCE_DATA_PATH: ‘/var/lib/weaviate’\nDEFAULT_VECTORIZER_MODULE: ‘text2vec-openai’\nENABLE_MODULES: ‘text2vec-openai,generative-openai,qna-openai’\nASYNC_INDEXING: ‘true’\nLOG_LEVEL: ‘debug’\nLOG_FORMAT: ‘text’\nCLUSTER_HOSTNAME: ‘node1’\n´´´\n\n----------\n\n[DudaNogueira (2024-02-21T19:08:58.094Z)]: Hi @rlima! Welcome to our community \nCan you try initializing the client using skip_init_check=True?\nLike so:\nclient = weaviate.connect_to_local(skip_init_checks=True)\n\nAlso, do you see any outstanding logs in Weaviate server?\nThis may be a symptom of an under resourced server taking too long to answer your read/writes.\nHow big is your dataset and how much of memory and cpu do you have for this server?\n\n----------\n\n[rlima (2024-02-21T19:32:19.162Z)]: DudaNogueira:\n\nAlso, do you see any outstanding logs in Weaviate server?\n\n\nThe logs on batch insert:\n2024-02-21 16:22:40 time=“2024-02-21T19:22:40Z” level=debug msg=“received HTTP request” action=restapi_request method=GET url=“/v1/nodes?output=verbose”\n2024-02-21 16:25:48 time=“2024-02-21T19:25:48Z” level=debug msg=“received HTTP request” action=restapi_request method=GET url=/v1/.well-known/openid-configuration\n2024-02-21 16:25:48 time=“2024-02-21T19:25:48Z” level=debug msg=“received HTTP request” action=restapi_request method=GET url=/v1/meta\n2024-02-21 16:25:51 time=“2024-02-21T19:25:51Z” level=debug msg=“received HTTP request” action=restapi_request method=GET url=/v1/.well-known/openid-configuration\n2024-02-21 16:25:52 time=“2024-02-21T19:25:52Z” level=debug msg=“received HTTP request” action=restapi_request method=GET url=/v1/meta\n2024-02-21 16:25:52 time=“2024-02-21T19:25:52Z” level=debug msg=“received HTTP request” action=restapi_request method=GET url=/v1/.well-known/openid-configuration\n2024-02-21 16:25:53 time=“2024-02-21T19:25:53Z” level=debug msg=“received HTTP request” action=restapi_request method=GET url=/v1/meta\nthe logs on near_text.\n2024-02-21 16:28:46 time=“2024-02-21T19:28:46Z” level=debug msg=“received HTTP request” action=restapi_request method=GET url=/v1/.well-known/openid-configuration\n2024-02-21 16:28:47 time=“2024-02-21T19:28:47Z” level=debug msg=“received HTTP request” action=restapi_request method=GET url=/v1/meta\nIt is a small dataset ~10mb. It is running on compose with 7.61GB memory and all cpus available.\n\n----------\n\n[rlima (2024-02-21T20:15:35.794Z)]: After your suggestion, I noted that the timeout set too low. I changed to handle longer period.\nclient = WeaviateClient(\n            connection_params=ConnectionParams.from_params(\n                http_host=,\n                http_port=8080,\n                grpc_host=,\n                grpc_port=50051,\n            ),\n            additional_headers={\"X-OpenAI-Api-Key\": OPENAI_ACCESS_KEY},\n            additional_config=AdditionalConfig(\n                connection=ConnectionConfig(\n                    session_pool_connections=30,\n                    session_pool_maxsize=200,\n                    session_pool_max_retries=3,\n                ),\n                **timeout=(60, 180),**\n            ),\n        )\n\nThank you for the support.\n\n----------\n\n[ksrev (2025-03-31T21:23:40.315Z)]: @rlima Thank you for providing the solution!",
    "date_created": "2024-02-21T18:04:01.467Z",
    "has_accepted_answer": true,
    "title": "Query call with protocol GRPC batch failed with message Deadline Exceeded",
    "topic_id": 1539
  },
  {
    "user_id": 931,
    "conversation": "[Maxence_Oden (2024-10-08T08:47:49.933Z)]: Hello,\nWe are running a Kubernetes cluster with 3 nodes. During a stress test, where 4 processes were performing dynamic batch imports on the weaviate-0 node, the node was OOM killed, which is not surprising. However, the main issue was during the node restoration process.\nFew hours after weaviate-0 came back online, we observed a discrepancy in the number of objects in the collection compared to the other two nodes (weaviate-1 and weaviate-2). Attempts to query the collection resulted in the following errors:\nPOST objects:\n{\n    \"error\": [\n        {\n            \"message\": \"put object: import into index documentationlocaldemo: replicate insertion: shard=\\\"u2an3dWDzMUF\\\": broadcast: cannot reach enough replicas\"\n        }\n    ]\n}\n\nREAD objects:\n{\n    \"error\": [\n        {\n            \"message\": \"cannot achieve consistency level \\\"QUORUM\\\": read error\" \n        }\n    ]\n}\n\nv1/nodes on weaviate-0\n{\n    \"error\": [\n        {\n            \"message\": \"node: weaviate-2: unexpected status code 401 ()\"\n        }\n    ]\n}\n\nIt seems that when weaviate-0 came back online, it did not have permission to communicate with the Raft cluster. We attempted to restart weaviate-0 without success. However, after restarting both weaviate-1 and weaviate-2, the cluster appeared to stabilize.\nWe got a desynchronization in the collection metadata across the nodes because of this weaviate-0 state. But the objects imported during the unstable state doesn’t exist in the check route.\nimage1050×842 73.6 KB\n893 objects for node 1 and 2, 709 for node 0\nUnfortunately, there is now a desynchronization in the collection metadata objects across the nodes.\nIssue:\n\nNode weaviate-0 was OOM killed during stress testing.\nUpon restoration, the node wasn’t able to communicate with the cluster.\nQuerying data results in replica or quorum errors and collection metadata desync.\nRestarting the entire cluster temporarily resolved the communication issue, but there is still a desync in the collection.\n\nQuestion:\nHow can we prevent the 401 issue when restarting a node to ensure proper cluster re-join and avoid collection metadata desynchronization?\nServer Setup Information\n\nWeaviate Server Version:  Weaviate 1.25.19\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: python 1.6.7\nMultitenancy?: No\n\nAny additional Information\nCollection config\n\"replicationConfig\": {\n     \"factor\": 3,\n      \"objectDeletionConflictResolution\": \"PermanentDeletion\"\n},\n\"shardingConfig\": {\n       \"actualCount\": 1,\n       \"actualVirtualCount\": 128,\n       \"desiredCount\": 1,\n       \"desiredVirtualCount\": 128,\n       \"function\": \"murmur3\",\n       \"key\": \"_id\",\n       \"strategy\": \"hash\",\n       \"virtualPerPhysical\": 128\n}\n\nRelated:\n  \n    \n    \n    Horizontal Scaling or Upgrade issue - Weaviate cluster Support\n  \n  \n    There is now what looks like a different issue, caused by the same process of  replacing one pod out of the cluster. \nStill same setup: 3 replicas, collection has a replication factor of 3 and async replication enabled. When pod weaviate-1 got replaced, it now has this message in logs: \n{\"action\":\"async_replication\",\"build_git_commit\":\"9a4ea6d\",\"build_go_version\":\"go1.21.13\",\"build_image_tag\":\"1.26.3\",\"build_wv_version\":\"1.26.3\",\"class_name\":\"AndriiTest\",\"hashbeat_iteration\":51,\"level\":\"warning\"…\n\n----------\n\n[DudaNogueira (2024-11-01T14:49:43.164Z)]: hi @Maxence_Oden !!\nSorry for the delay here. Just found that missed some messages \nI believe this was tackled in 1.26:\n  \n      \n\n      weaviate.io – 31 Jul 24\n  \n\n  \n    \n\nWeaviate 1.26 Release | Weaviate\n\n  Weaviate 1.26 is released! Updates include ...\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nDo you still see this issue?\nThanks!",
    "date_created": "2024-10-08T08:47:49.879Z",
    "has_accepted_answer": false,
    "title": "Node Desync and Cluster Inconsistencies After OOM on Weaviate-0",
    "topic_id": 4466
  },
  {
    "user_id": 1967,
    "conversation": "[Bryan_Jenson (2024-10-28T20:44:21.655Z)]: I am performing a bm25 search with a geo filter provided.  I know that there should be more results coming back from the query.  But most results are not returned even though I know that they exist and are included within the geo parameters.\nThis is the schema for my location field\n{\n“name”: “location”,\n“dataType”: “geoCoordinates”,\n“indexFilterable”: true,\n“indexInverted”: false,\n“indexRangeFilters”: false,\n“indexSearchable”: false,\n“tokenization”: “none”\n}\nMuch of our dataset has geo coordinates around Salt Lake City, Utah (40.76066207885742, -111.89395141601562). Here is an example of several of them.\n{ longitude: -111.65492248535156, latitude: 40.11495590209961 }\n{ longitude: -111.89215850830078, latitude: 40.871612548828125 }\n{ longitude: -111.89104461669922, latitude: 40.760780334472656 }\n{ longitude: -111.88826751708984, latitude: 40.718833923339844 }\n{ longitude: -111.61075592041016, latitude: 40.16523361206055 }\n{ longitude: -111.89215850830078, latitude: 40.871612548828125 }\n{ longitude: -111.89215850830078, latitude: 40.871612548828125 }\n{ longitude: -111.89215850830078, latitude: 40.871612548828125 }\n{ longitude: -111.89215850830078, latitude: 40.871612548828125 }\n{ longitude: -111.89215850830078, latitude: 40.871612548828125 }\n{ longitude: -111.89215850830078, latitude: 40.871612548828125 }\n{ longitude: -111.89215850830078, latitude: 40.871612548828125 }\n{ longitude: -111.89104461669922, latitude: 40.760780334472656 }\n{ longitude: -111.89215850830078, latitude: 40.871612548828125 }\n{ longitude: -111.89104461669922, latitude: 40.760780334472656 }\n{ longitude: -111.89215850830078, latitude: 40.871612548828125 }\n{ longitude: -111.65853118896484, latitude: 40.23384475708008 }\n{ longitude: -111.89104461669922, latitude: 40.760780334472656 }\n{ longitude: -111.89104461669922, latitude: 40.760780334472656 }\n{ longitude: -111.89104461669922, latitude: 40.760780334472656 }\n{ longitude: -111.61075592041016, latitude: 40.16523361206055 }\n{ longitude: -111.89104461669922, latitude: 40.760780334472656 }\nIf I add a withinGeoRange filter to a “bm25” query, I get very few if any results.\nMy filter is:\n“filters”: {\n“operator”: “WithinGeoRange”,\n“target”: {\n“property”: “location”\n},\n“value”: {\n“latitude”: 40.76066207885742,\n“longitude”: -111.89395141601562,\n“distance”: 321868 // 200 miles\n}\n}\nResults: 0\nI do get some results by calling fetchObjects with the geo filter, but it’s not all of them.\n\n----------\n\n[DudaNogueira (2024-11-01T14:40:58.573Z)]: hi @Bryan_Jenson !!\nSorry for the delay here, missed this one \nWere you able to solve this?\nDo you get the same results if filtering with python v4?\n\n----------\n\n[Bryan_Jenson (2024-11-01T14:54:41.000Z)]: We have tried it with python and no it does not work.\n\n----------\n\n[DudaNogueira (2024-11-01T21:20:03.430Z)]: hi @Bryan_Jenson !\nWhat version are you using?\nCheck out this code I did to reproduce this scenario:\nimport weaviate\nfrom weaviate import classes as wvc\nimport os\nclient = weaviate.connect_to_local()\nprint(weaviate.__version__, client.get_meta().get(\"version\"))\n\nclient.collections.delete(\"Geo\")\ncollection = client.collections.create(\n    \"Geo\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n    properties=[\n        wvc.config.Property(name=\"location\", data_type=wvc.config.DataType.GEO_COORDINATES)\n    ]\n)\n\nlocations = [\n    {\"longitude\": -111.65492248535156, \"latitude\": 40.11495590209961},\n    {\"longitude\": -111.89215850830078, \"latitude\": 40.871612548828125},\n    {\"longitude\": -111.89104461669922, \"latitude\": 40.760780334472656},\n    {\"longitude\": -111.88826751708984, \"latitude\": 40.718833923339844},\n    {\"longitude\": -111.61075592041016, \"latitude\": 40.16523361206055},\n    {\"longitude\": -111.89215850830078, \"latitude\": 40.871612548828125},\n    {\"longitude\": -111.89215850830078, \"latitude\": 40.871612548828125},\n    {\"longitude\": -111.89215850830078, \"latitude\": 40.871612548828125},\n    {\"longitude\": -111.89215850830078, \"latitude\": 40.871612548828125},\n    {\"longitude\": -111.89215850830078, \"latitude\": 40.871612548828125},\n    {\"longitude\": -111.89215850830078, \"latitude\": 40.871612548828125},\n    {\"longitude\": -111.89215850830078, \"latitude\": 40.871612548828125},\n    {\"longitude\": -111.89104461669922, \"latitude\": 40.760780334472656},\n    {\"longitude\": -111.89215850830078, \"latitude\": 40.871612548828125},\n    {\"longitude\": -111.89104461669922, \"latitude\": 40.760780334472656},\n    {\"longitude\": -111.89215850830078, \"latitude\": 40.871612548828125},\n    {\"longitude\": -111.65853118896484, \"latitude\": 40.23384475708008},\n    {\"longitude\": -111.89104461669922, \"latitude\": 40.760780334472656},\n    {\"longitude\": -111.89104461669922, \"latitude\": 40.760780334472656},\n    {\"longitude\": -111.89104461669922, \"latitude\": 40.760780334472656},\n    {\"longitude\": -111.61075592041016, \"latitude\": 40.16523361206055},\n    {\"longitude\": -111.89104461669922, \"latitude\": 40.760780334472656}\n]\n\nwith client.batch.dynamic() as batch:\n    for location in locations:\n        batch.add_object(\n            collection=\"Geo\",\n            properties={\n                \"location\": wvc.data.GeoCoordinate(\n                    latitude=location.get(\"latitude\"),\n                    longitude=location.get(\"longitude\")\n                )\n            }\n        )\n\nprint(\"Errors found\", client.batch.failed_objects)\n\nprint(\"Indexed\", collection.aggregate.over_all())\n\nquery = collection.query.fetch_objects(\n    filters=(\n        wvc.query.Filter.by_property(\"location\").within_geo_range(\n            wvc.data.GeoCoordinate(\n                latitude=40.76066207885742,\n                longitude=-111.89395141601562,\n            ),\n            distance=321868\n        )\n    )\n)\nprint(\"Found\", len(query.objects))\n\n\nThis was the output:\nClient: 4.9.2, Server: 1.27.0\nErrors found []\nIndexed AggregateReturn(properties={}, total_count=22)\nFound 22\n\n----------\n\n[Bryan_Jenson (2024-11-04T15:53:18.000Z)]: I apologize I don’t think that I was clear enough on the problem. I am not having a problem with the test code you did. Thanks for doing that however. The issue that I am having with Weaviate is when I search our database using either\n\nthe “nearVector” or “bm25” searches\nwith a geo filter.\n\nnearVector works great by itself\nbm25 works great by itself.\nBut if I add a geo filter then it will return no results. Even though I know that the data exists. My example was to show that I have data in the db near that geo coordinates that I am filtering by. But Weaviate will not return them.\nBryan\n\n----------\n\n[DudaNogueira (2024-11-04T16:46:23.738Z)]: Oh. I see.\nAnd what is the version you are running?\nDoes it also happens on latest versions?\n\n----------\n\n[Dirk (2024-11-04T18:16:50.234Z)]: Could it be this issue?\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Improvements to geo-coordinate based filtering\n    \n\n    \n      \n        opened 01:45PM - 19 Apr 24 UTC\n      \n\n\n      \n        \n          \n          databyjp\n        \n      \n    \n\n    \n        \n          API design & UX\n        \n        \n          data types\n        \n        \n          Filtering / Sorting / Aggregation\n        \n        \n          feature request\n        \n    \n  \n\n\n  \n    ### Describe your feature request\n\n**Challenge**\nCurrent implementation of the …geo-coordinate filtering uses a vector search. A limitation of the implementation is that the size of the list is fixed to 800. \n\nThis limits usefulness of filter when combined with other parameters, as the geo-coordinate search does not accept an allow list, and also it is carried out before being used as an allow list for any subsequent searches.\n\n**Proposal**\n1. Allow the user to increase the dynamic list size to a larger number, at the cost of speed.\n2. When a geo-coordinate filter is used in combination with other filters, perform the other filters first & pass the results as an allow list to the geo-coordinate filter.\n\n### Code of Conduct\n\n- [X] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n\n----------\n\n[Bryan_Jenson (2024-11-05T00:11:29.000Z)]: Yes, that very well could be the issue that I am seeing.",
    "date_created": "2024-10-28T20:44:21.597Z",
    "has_accepted_answer": false,
    "title": "Searching with bm25 does not return all results with GeoCoordinate filter",
    "topic_id": 7112
  },
  {
    "user_id": 674,
    "conversation": "[Freddy (2025-01-10T10:54:44.294Z)]: Hi everyone,\nI’m currently using the Python Client v4 for Weaviate. Here’s the code snippet I use to create a schema directly in Python:\ncollection = self.client.collections.create(\n    name=collection_name,\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai()\n)\n\nIn the above code, I’m only providing the collection_name and vectorizer_config, and the rest of the values are set to default.\nNow, I am converting this functionality into a custom API class. I need to pass the schema details through the API body and create the schema programmatically via an HTTP POST request.\nFor example:\n\nEndpoint: POST http://localhost:8311/matching-engine/v1/collection/add_schema\nRequest Body: Contains schema details.\n\nI want to achieve this without using the default Weaviate endpoint like:\ncurl http://localhost:8080/v1/schema \\\n  --request POST \\\n  --header 'Content-Type: text/plain;charset=UTF-8'\n\n\nCould someone guide me on how to structure the API body and write the server-side logic in Python to handle this? Any code examples or documentation references would be greatly appreciated.\nThanks in advance!\n\n----------\n\n[Freddy (2025-01-10T11:05:40.031Z)]: @DudaNogueira Need your guidance here\n\n----------\n\n[DudaNogueira (2025-01-10T11:08:00.716Z)]: Hi!\nNot sure I understood it here.\nIn order to create a collection, that’s the only endpoint available:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nWeaviate\n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nthe client, by the way, is using that very same endpoint.\nSo you can use both the direct call to that api or the client, that will under the hood also call that endpoint.\n\n----------\n\n[Freddy (2025-01-10T11:12:24.090Z)]: I have defined my client like below\n        self.client = weaviate.connect_to_custom(\n            http_host=host,\n            http_port=port,\n            http_secure=False,\n            grpc_secure=False,\n            grpc_host=grpc_host,\n            grpc_port=grpc_port,\n            headers={\n                \"X-OpenAI-Api-Key\": os.environ.get(\"OPENAI_APIKEY\", \"\")\n            }\n        )\n\n\nso If I call default endpoint will it follow the authentication.\nI want to using python\n\n----------\n\n[DudaNogueira (2025-01-10T11:20:01.373Z)]: Yes, you can both use the python client or call the endpoint directly.\nIf you have set the auth in Weaviate server, you can use it as a bearer token for the rest call",
    "date_created": "2025-01-10T10:54:44.247Z",
    "has_accepted_answer": false,
    "title": "How to Create a Schema Using Python Client V4 via a Custom API Endpoint?",
    "topic_id": 9664
  },
  {
    "user_id": 1602,
    "conversation": "[AdamHeard (2024-09-26T22:53:13.784Z)]: Description\nSeeing this error pop up in our logs\n2024-09-26T18:36:47.646Z\nError finding nearest neighbors: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\nstatus = StatusCode.UNAVAILABLE\ndetails = “recvmsg:Connection reset by peer”\ndebug_error_string = “UNKNOWN:Error received from peer {created_time:“2024-09-26T18:36:47.646280137+00:00”, grpc_status:14, grpc_message:“recvmsg:Connection reset by peer”}”\nServer Setup Information\n\nWeaviate Server Version: 1.26.4\nDeployment Method: Weaviate Cloud\nMulti Node? Number of Running Nodes: 1??\nClient Language and Version: Python\nMultitenancy?: No.\n\nAny additional Information\nCode where the error is populated:\ndef find_nearest_neighbors(item, settings):\nvector_similarity = settings[“vector_similarity”]\nmatching_vectors = settings[“matching_vectors”]\ntry:\n    description = item[\"description\"]\n    item_id = item[\"id\"] if \"id\" in item else item[\"item_id\"]\n    embedding = get_embedding(description)\n    collection = vector_client.collections.get(\"items\")\n\n    if embedding is None:\n        raise ValueError(\"No embedding found for item\")\n\n    results = collection.query.near_vector(\n        near_vector=embedding,\n        certainty=vector_similarity,\n        filters=Filter.by_property(\"item_id\").not_equal(item_id),\n        return_metadata=wvc.query.MetadataQuery(certainty=True),\n        limit=matching_vectors\n    )\n\n    items_dict_list = [item.properties for item in results.objects]\n    return items_dict_list\n\nexcept Exception as e:\n    print(f\"Error finding nearest neighbors: {e}\")\n    return []\n\n----------\n\n[DudaNogueira (2024-09-30T08:41:16.447Z)]: hi @AdamHeard !!\nWelcome to our community \nDo you have any reading on resource usage?\nHow many of memory and cpu do you have available? How many objects have stored?\nthis error message indicates that the connection was closed from the server.\nSo I believe there may be requiring more resources.\nIf you have not fine tuned Weaviate for resource usage, check this documentation on how to do that:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nResource Planning | Weaviate\n\n  Weaviate scales well for large projects. Smaller projects, less than 1M objects, do not require resource planning. For medium and large-scale projects, you should plan how to get the best performance from your resources. While you design you system,...\n\n----------\n\n[AdamHeard (2024-09-30T22:43:22.725Z)]: Thanks for the response @DudaNogueira.\nPer resources on the Fargate Instance:\nCPU: 2 vCPU\nMemory: 4 GB\nObjects Stored: 1.6M\nHow much more resources do you feel it would require?\n\n----------\n\n[DudaNogueira (2024-10-01T08:28:38.023Z)]: Hi!\nThis will vary according to the dimension length of your vectors.\nHere we have an example for this calculation\nAssuming your vectors has 1536 dimensions, this is the calculation you need to do, for storing 1 million objects:\n2 * 1e6 * (1536 * 4)\nAs a rule of thumb, we always double the required memory (this is the 2x)\nso you are looking to something around 12G of ram. This is not counting the maxconnections.\nLet me know if this helps.\n\n----------\n\n[dastankg (2024-12-20T10:06:23.810Z)]: Снимок экрана от 2024-12-20 16-05-30848×708 35.8 KB\ni need help\n\n----------\n\n[DudaNogueira (2024-12-20T13:57:24.903Z)]: hi @dastankg !!\nWelcome to our community!\nDo you mind opening a new thread in the Support category?\nAnd please, make sure to answer the required questions like versions, deployment methods, etc.\nThe issue with the screen shot seems to be that there isn’t any objects indexed.\nPlease, also provide any outstanding logs messages on the new thread you create.\nTHanks!",
    "date_created": "2024-09-26T22:53:13.731Z",
    "has_accepted_answer": false,
    "title": "GRPC Query failed AioRpcError of RPC terminated status UNAVAILABLE",
    "topic_id": 4345
  },
  {
    "user_id": 3139,
    "conversation": "[Rohini_vaidya (2025-01-06T03:30:24.758Z)]: Query:\nI am trying to add multiple vectors from a DataFrame into a collection using the following code, but I notice that the vectors are not being added to the collection. Am I missing something or doing anything wrong?\nCode:\nimport weaviate.classes as wvc\n\nres = []\nfor i, row in d.iterrows():\n    res.append(wvc.data.DataObject(\n        properties={\n            \"a\": row[\"a\"],\n            \"b\": row[\"b\"]\n        },\n        vector={\n            \"a_vector\": emb[row[\"a\"]],\n            \"b_vector\": emb[row[\"b\"]]\n        }\n    ))\n\nquestions = client.collections.get(\"collection_name\")\nquestions.data.insert_many(res)\n\nVerification:\nTo verify the data, I used the following snippet:\nfor item in questions.iterator():\n    print(item.uuid, item.vector, item.properties)\n\nHowever, while I can retrieve the uuid and properties correctly, the vector is always empty ({}).\nCould you please help identify the issue? Am I misunderstanding how to add vectors or missing a step in the process?\n\n----------\n\n[DudaNogueira (2025-01-06T18:04:10.246Z)]: answer here: Scores for Hybrid search - #6 by DudaNogueira\n\n----------\n\n[Rohini_vaidya (2025-01-08T16:12:14.967Z)]: Thank you for response @DudaNogueira",
    "date_created": "2025-01-06T03:30:24.709Z",
    "has_accepted_answer": true,
    "title": "Could not import multiple vectors into collection using insert many",
    "topic_id": 9577
  },
  {
    "user_id": 2964,
    "conversation": "[Troligen (2024-12-04T16:04:41.293Z)]: Description\n\nI’m trying to find if it’s possible to update an object through the WeaviateVectorStore module.\nU can use WeaviateVectorStore to add documents and initiate a connection to a collection but I can’t find if there’s any way to update some object inside of a collection.\nIt seems weird that langchain would limit you to just adding objects and then force you to use the native weaviate solution to update an object.\nServer Setup Information\n\nWeaviate Server Version: 0.4\nDeployment Method: docker\nClient Language and Version: Python\n\n----------\n\n[DudaNogueira (2024-12-05T14:55:03.815Z)]: hi @Troligen !!\nWelcome to our community \nYou need to pass the uuid to that doc as the id parameter\nHere is a code example in python:\nfrom weaviate.util import generate_uuid5\nfrom langchain_weaviate.vectorstores import WeaviateVectorStore\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain.docstore.document import Document\n\n\nembeddings = OpenAIEmbeddings()\ndoc =  Document(page_content=\"text1\", metadata={\"source\": \"local\"}, id=generate_uuid5(\"my-id\"))\ndb = WeaviateVectorStore.from_documents([doc], embeddings, client=client, index_name=\"Test\")\n\nnow we can check our doc:\nclient.collections.get(\"Test\").query.fetch_objects().objects[0].properties\n# {'text': 'text1', 'source': 'local'}\n\nLet’s update that object\ndoc =  Document(page_content=\"text1_changed\", metadata={\"source\": \"local\"}, id=generate_uuid5(\"my-id\"))\ndb = WeaviateVectorStore.from_documents([doc], embeddings, \nclient=client, index_name=\"Test\")\n\nWe have updated!\nclient.collections.get(\"Test\").query.fetch_objects().objects[0].properties\n# {'text': 'text1_changed', 'source': 'local'}\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[Troligen (2024-12-06T11:31:15.331Z)]: Thanks you for your warm welcome and thank you for the solution!\nI see you’re using the deterministic ID which seems to make the handling of the updates more streamlined as well?\nIn any case thank you for the help!\nBest Regards,\nJesper/Troligen",
    "date_created": "2024-12-04T16:04:41.244Z",
    "has_accepted_answer": true,
    "title": "Update an object through LangChain",
    "topic_id": 9096
  },
  {
    "user_id": 1489,
    "conversation": "[halcyoncv (2024-09-06T10:13:23.423Z)]: Hey everyone!\nI am fairly new to Weaviate and have been working on a project that involves using vector search to improve the accuracy of some recommendation algorithms. So far, it’s been pretty exciting, but I feel like there’s still a lot more potential that I could unlock with Weaviate.\nRight now, I’m looking for some advice on a few things:\n\nIndex configurations: Are there any specific settings you recommend to optimize performance when dealing with large datasets?\nVector dimensions: Is there an ideal range of vector dimensions I should aim for, or does it really depend on the type of data I’m working with?\nHybrid search: I’ve read a bit about hybrid search (vector + keyword) but haven’t tried it out yet. Has anyone had success with this, and if so, how did you set it up?\n\nWhen I was searching about this, I came across these resources/articles 🔍 Seeking Assistance with Weaviate Vector Search UiPath Tutorial, however, they are quite good, but I wanted to learn more form community members.\nWould love to hear your thoughts, suggestions, or even experiences with similar projects.\nAppreciate any guidance you can share.\nThanks in advance\n\n----------\n\n[DudaNogueira (2024-09-06T20:29:38.363Z)]: hi @halcyoncv !!\nGlad you are enjoying your Weaviate journey \n\n\nRegarding index configuration, some options that can help you on having a more performant vector index are ef efConstruction and maxConnections, as stated here: Vector indexes | Weaviate\n\n\nFor the right embedded model and vector dimension, it will indeed depend on your data. For example, if you need multi language support, you will need to use a model that has support for the target languages. If your chunks are larger, a high dimension vector can capture more meaning, and give you better results. So before deciding on the model, it is interesting to do some tests/benchmarks.\n\n\nOnce you have data indexed, you can start doing hybrid queries right away. Then you can start fine tuning it, specifying different alfa or different weights for specific properties.\n\n\nLet me know if this helps.\nThanks!",
    "date_created": "2024-09-06T10:13:23.376Z",
    "has_accepted_answer": false,
    "title": "Advice Needed on Optimizing Vector Search in Weaviate",
    "topic_id": 3990
  },
  {
    "user_id": 1537,
    "conversation": "[Juan_Rodriguez (2024-09-19T17:17:54.798Z)]: Hi there!\nI’ve been trying to set up 3 weaviate servers in a cluster for High Availability, using Google Cloud.\nI’m nearly done with the configuration, but when I review on v1/cluster/statistics, it displays “synchronized”: false at the bottom, despite all nodes being Healthy, with one marked as a Leader and the other 2 as followers\nI’ve reviewed ports/firewalls to make sure communication can happen on ports:\n7100, 7101, 8080, 8300, 8301, 50051\nI’m using the same 7100/7101 ports on all 3 servers, not sure if that’s an issue, but the fact that they seem to be talking to each other (even if they aren’t synching yet) leads me to believe that’s not a major issue.\nI’m running 1.26.4,\nwith the following env vars:\nCLUSTER_GOSSIP_BIND_PORT 7100\nCLUSTER_DATA_BIND_PORT 7101\nRAFT_JOIN main-server-name.us-central1-a.c.google-project.internal,alt-one.us-west1-b.c.google-project.internal,alt-two.us-east1-b.c.google-project.internal\nRAFT_BOOTSTRAP_EXPECT 3\nCLUSTER_JOIN main-server-name.us-central1-a.c.google-project.internal:7100\nRAFT_ENABLE_FQDN_RESOLVER true\nThe CLUSTER_JOIN var isn’t set on the main server, as per the documentation.\nHelp is very much appreciated. Thanks!\nEdit:\nThey’re up and running now. I ended up destroying all 3 hard drives and letting weaviate recreate the /var/lib/weaviate data, and it seems to be fine now.\n\n----------\n\n[DudaNogueira (2024-09-23T08:06:46.554Z)]: hi @Juan_Rodriguez !!\nWelcome to our community \nGlad you found a solution.\nNot sure you are using our helm chart, but we strongly suggest using it as it’s the best way to have the same environment as our users have and that our team expects so we can help.\nLet me know if there is any other issues we can help with!\nHappy building with Weaviate",
    "date_created": "2024-09-19T17:17:54.747Z",
    "has_accepted_answer": false,
    "title": "[Question] synchronized:false but nodes can see each other",
    "topic_id": 4210
  },
  {
    "user_id": 621,
    "conversation": "[Dhinesh_Prabakaran (2024-02-15T07:01:59.484Z)]: Hi Team,\nI’ve created a free tier cluster in WCS. Upon trying to connect from my python code, I’m facing the below chalenge.\nweaviate.exceptions.WeaviateStartUpError: Weaviate did not start up in 10 seconds. Either the Weaviate URL https://wcsurl  is wrong or Weaviate did not start up in the interval given in ‘startup_period’.\nCould I get some help on this ?\n\n----------\n\n[DudaNogueira (2024-02-15T14:35:12.474Z)]: Hi @Dhinesh_Prabakaran!\nCan you share the code you are using to connect??\nThis is usually some connectivy issue, or wrong url.\nPlease, feel free to ping me in our Slack so I can take a close look.\nThanks!\n\n----------\n\n[Dhinesh_Prabakaran (2024-02-16T06:35:04.793Z)]: Hi Duda,\nPlease find the code below,\nimport weaviate\nimport os\nSet these environment variables\nURL = os.getenv(“YOUR_WCS_URL”)\nAPIKEY = os.getenv(“YOUR_WCS_API_KEY”)\nConnect to a WCS instance\nclient = weaviate.connect_to_wcs(\ncluster_url=URL,\nauth_credentials=weaviate.auth.AuthApiKey(APIKEY))\n\n----------\n\n[sebawita (2024-02-16T11:59:23.459Z)]: Hi @Dhinesh_Prabakaran,\nDo you have the following env variables configured in your environment?\n\nYOUR_WCS_URL – you can get it from the WCS console, click on Details (1), and copy Cluster URL (2)\nYOUR_WCS_API_KEY – click on API Keys (3), and copy your key (note, free sandboxes have only one key)\n\nWCS-Steps-1-2-31454×540 43.7 KB\nWCS-Step-41358×642 48.8 KB\nNote, if you run your code locally (and don’t publish it to GitHub or somewhere else), you can just enter your Cluster URL and API Key straight in the code (not recommended for production). Like this:\nimport weaviate\n  \n# Set these connection variables\nURL = \"https://YOUR_WCS_URL\"\nAPIKEY = \"YOUR_WCS_API_KEY\"\n  \n# Connect to a WCS instance\nclient = weaviate.connect_to_wcs(\n    cluster_url=URL,\n    auth_credentials=weaviate.auth.AuthApiKey(APIKEY))\n\n----------\n\n[shaheen (2024-07-30T13:01:00.642Z)]: I still get this error even after hard coding url and api key\n\n----------\n\n[DudaNogueira (2024-07-30T13:25:02.710Z)]: hi @shaheen !!\nWelcome to our community!\nWhat is the exact error code you get?\nAlso, please, feel free to create a new thread so we can help you.\nThanks!\n\n----------\n\n[DudaNogueira (2024-07-30T13:25:06.579Z)]: ",
    "date_created": "2024-02-15T07:01:59.439Z",
    "has_accepted_answer": true,
    "title": "Weaviate didn't start up",
    "topic_id": 1495
  },
  {
    "user_id": 1285,
    "conversation": "[Viktar (2024-08-06T10:03:04.251Z)]: Description\nGetting the next error while trying to filter the collection on date type field\nError: Query call with protocol gRPC failed with message: /weaviate.v1.Weaviate/Search UNKNOWN: unknown value type \nCollection has a date field ‘importDate’\nconst collection = client.collections.get('CollectionName')\nconst response = await collection.data.deleteMany(\n       collection.filter.byProperty('importDate').lessOrEqual((new Date()).toISOString())\n    )\n\n\nServer Setup Information\n\nDocker image: semitechnologies/weaviate:1.25.8\nDeployment Method: docker\nClient Language and Version: “weaviate-client”: “^3.0.5”\n\n----------\n\n[DudaNogueira (2024-08-07T18:12:20.429Z)]: hi @Viktar !!\nWelcome to our community \nI believe this is the same case of:\n  \n    \n    \n    Total_count not working with filters on date values Support\n  \n  \n    hi @longspearfish !! \nWelcome to our community!  \nThis is a  bug in the python client. \nEdit: Not really… \nthis is because whatever you pass as the comparison argument, the client will infer the data type to pass it over to Weaviate. \nSo when you pass a date using string, it will use valueText instead of valueDate. \nHence the error code: \ncannot use \\\"valueText\\\" on type \\\"date\\\", use \\\"valueDate\\\" instead\"\n\nHere is the client code for this \nSo you need to pass a python date object. \nt…\n  \n\n\nyou are passing a string object.\nSo the client is inferring from that value to build the query.\nCan you try passing the date object directly?\nThanks!",
    "date_created": "2024-08-06T10:03:04.186Z",
    "has_accepted_answer": false,
    "title": "Filter by date field, JS",
    "topic_id": 3275
  },
  {
    "user_id": 154,
    "conversation": "[gabriel (2023-07-04T20:27:46.352Z)]: I’m trying to perform a search on an Article class object (each associated with an Author class via an Article → Author cross-reference).\nI would like to do a hybrid search matching the Article class for the vector and bm25 on the author’s name. However I’m getting the following error:\n Searching by property 'Author.name' requires inverted index. Is `indexSearchable` option of property 'Author.name' enabled\n\nMy understanding is that indexSearchable defaults to true so is it possible that we can’t do a hybrid search on a cross-reference?\n\n----------\n\n[jphwang (2023-07-05T19:36:53.155Z)]: Hi @gabriel and welcome!\nYeah I think you’re right but I’ll check with the team and get back to you to confirm.\n\n----------\n\n[jphwang (2023-07-06T13:06:48.617Z)]: Yeah unfortunately BM25/hybrid searches are not yet possible on cross-referenced properties.\n\n----------\n\n[oliver (2025-01-23T14:05:42.449Z)]: Hi @jphwang is BM25 search based on cross-referenced properties in your roadmap or at least planned for future releases please?",
    "date_created": "2023-07-04T20:27:46.309Z",
    "has_accepted_answer": true,
    "title": "Hybrid Search on Class and cross-referenced class",
    "topic_id": 321
  },
  {
    "user_id": 753,
    "conversation": "[rhuang (2024-12-23T02:53:25.328Z)]: We are using weaviate python v4 library.\nWe have an application that has 10 threads, and we will do a search with weaviate in each thread whenever there is a request come in. We do not want to keep opening and closing connections to the weaviate db.\nWhat is the recommended way to build and maintain a connection pool for such multithreaded application?\nThanks,\nRobert\n\n----------\n\n[DudaNogueira (2024-12-23T13:33:42.211Z)]: hi @rhuang !!\nI believe the best option here is leveraging out Async Client:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAsync API | Weaviate\n\n  The async Python client is available in weaviate-client versions 4.7.0 and higher.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.\nTHanks!",
    "date_created": "2024-12-23T02:53:25.282Z",
    "has_accepted_answer": false,
    "title": "Multithread with weaviate",
    "topic_id": 9395
  },
  {
    "user_id": 1146,
    "conversation": "[Ghattas_Salloum (2024-07-02T09:47:05.971Z)]: Hey,\nthanks for great work,\ni am trying to write a python code that can merge multiple index’s into a new one using weavite v4 api.\nThe merged index’s are already vectorized i only need to merge them into a new index along with there vectors.\ncan you please help me on how to do that?\nThanks in advance for help\n\n----------\n\n[DudaNogueira (2024-07-03T19:21:55.653Z)]: hi @Ghattas_Salloum !!\nWelcome to our community!\nYou need to copy over two collections into one?\nIf that’s the case, you can probably use our migration guide as a starting point:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate data | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this is your objective and if this helps you.\nThanks!\n\n----------\n\n[Ghattas_Salloum (2024-07-12T08:25:35.250Z)]: Thanks for reply,\nthe problem i am having is when doing migration it is revectorizing the data again even though it has been already vectorized\nand i couldn’t find a way around it so i decided not to vectorize the data at the beginning but do that when i migrate\nany thanks for help\n\n----------\n\n[DudaNogueira (2024-07-15T18:47:36.718Z)]: Hi!\nIf your target collection has a vectorizer properly configured, and you do not provide the vectors, Weaviate will trigger the vectorization of that objects.\nTo avoid that, you can provide the vector for that object. This is what we call bring your own vectors\nCheck here for more on that:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBring your own vectors | Weaviate - Vector Database\n\n  Weaviate is a vector database. Vector databases store data objects and vectors that represent those objects. The vector representation is also called an \"embedding.\"\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if you need assistance on that!\nThanks!\n\n----------\n\n[Ghattas_Salloum (2024-07-18T09:51:14.299Z)]: Thanks for help\nI will try that",
    "date_created": "2024-07-02T09:47:05.928Z",
    "has_accepted_answer": true,
    "title": "[Question] Merging multiple index's into a new one",
    "topic_id": 2900
  },
  {
    "user_id": 1741,
    "conversation": "[wtavares (2024-10-11T20:37:05.331Z)]: Description\nThe build was complete… but when try to start the error happens.\nUsing the docker compose only with the OpenAI env.\nServer Setup Information\n\nVerba Version: 2.1.0\nDeployment Method: docker\nMulti Node? Number of Running Nodes: no\nClient Language and Version: Docker\nMultitenancy?: no\n\nAny additional Information\n/usr/local/lib/python3.11/site-packages/google/protobuf/runtime_version.py:112: UserWarning: Protobuf gencode version 5.27.2 is older than the runtime version 5.28.2 at grpc_health/v1/health.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\nwarnings.warn(\nOpenBLAS blas_thread_init: pthread_create failed for thread 1 of 2: Operation not permitted\nOpenBLAS blas_thread_init: RLIMIT_NPROC -1 current, -1 max\nTraceback (most recent call last):\nFile “/usr/local/bin/verba”, line 33, in \nsys.exit(load_entry_point(‘goldenverba’, ‘console_scripts’, ‘verba’)())\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “/usr/local/bin/verba”, line 25, in importlib_load_entry_point\nreturn next(matches).load()\n^^^^^^^^^^^^^^^^^^^^\nFile “/usr/local/lib/python3.11/importlib/metadata/init.py”, line 202, in load\nmodule = import_module(match.group(‘module’))\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “/usr/local/lib/python3.11/importlib/init.py”, line 126, in import_module\nreturn _bootstrap._gcd_import(name[level:], package, level)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “”, line 1204, in _gcd_import\nFile “”, line 1176, in _find_and_load\nFile “”, line 1147, in _find_and_load_unlocked\nFile “”, line 690, in _load_unlocked\nFile “”, line 940, in exec_module\nFile “”, line 241, in _call_with_frames_removed\nFile “/Verba/goldenverba/server/cli.py”, line 6, in \nfrom goldenverba import verba_manager\nFile “/Verba/goldenverba/verba_manager.py”, line 16, in \nfrom goldenverba.components.document import Document\nFile “/Verba/goldenverba/components/document.py”, line 2, in \nfrom goldenverba.components.chunk import Chunk\nFile “/Verba/goldenverba/components/chunk.py”, line 1, in \nfrom spacy.tokens import Doc, Span\nFile “/usr/local/lib/python3.11/site-packages/spacy/init.py”, line 6, in \nfrom .errors import setup_default_warnings\nFile “/usr/local/lib/python3.11/site-packages/spacy/errors.py”, line 3, in \nfrom .compat import Literal\nFile “/usr/local/lib/python3.11/site-packages/spacy/compat.py”, line 4, in \nfrom thinc.util import copy_array\nFile “/usr/local/lib/python3.11/site-packages/thinc/init.py”, line 2, in \nimport numpy\nFile “/usr/local/lib/python3.11/site-packages/numpy/init.py”, line 130, in \nfrom numpy.config import show as show_config\nFile “/usr/local/lib/python3.11/site-packages/numpy/config.py”, line 4, in \nfrom numpy.core._multiarray_umath import (\nFile “/usr/local/lib/python3.11/site-packages/numpy/core/init.py”, line 24, in \nfrom . import multiarray\nFile “/usr/local/lib/python3.11/site-packages/numpy/core/multiarray.py”, line 10, in \nfrom . import overrides\nFile “/usr/local/lib/python3.11/site-packages/numpy/core/overrides.py”, line 8, in \nfrom numpy.core._multiarray_umath import (\nFile “”, line 216, in _lock_unlock_module\nKeyboardInterrupt\n\n----------\n\n[DudaNogueira (2024-10-11T20:38:43.458Z)]: hi!\nI have seen some issues from users while running Verba on Window \nAre you running on WSL?\n\n----------\n\n[wtavares (2024-10-11T20:40:09.144Z)]: No… is a docker for Windows 10.\n\n----------\n\n[wtavares (2024-10-11T20:40:54.407Z)]: I’m setting the docker with 3 CPUS now. Was 2.\n\n----------\n\n[wtavares (2024-10-11T20:46:15.645Z)]: Did not worked!\n/usr/local/lib/python3.11/site-packages/google/protobuf/runtime_version.py:112: UserWarning: Protobuf gencode version 5.27.2 is older than the runtime version 5.28.2 at grpc_health/v1/health.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\nwarnings.warn(\nOpenBLAS blas_thread_init: pthread_create failed for thread 1 of 2: Operation not permitted\nOpenBLAS blas_thread_init: RLIMIT_NPROC -1 current, -1 max\nTraceback (most recent call last):\nFile “/usr/local/bin/verba”, line 33, in \nsys.exit(load_entry_point(‘goldenverba’, ‘console_scripts’, ‘verba’)())\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “/usr/local/bin/verba”, line 25, in importlib_load_entry_point\nreturn next(matches).load()\n^^^^^^^^^^^^^^^^^^^^\nFile “/usr/local/lib/python3.11/importlib/metadata/init.py”, line 202, in load\nmodule = import_module(match.group(‘module’))\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “/usr/local/lib/python3.11/importlib/init.py”, line 126, in import_module\nreturn _bootstrap._gcd_import(name[level:], package, level)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile “”, line 1204, in _gcd_import\nFile “”, line 1176, in _find_and_load\nFile “”, line 1147, in _find_and_load_unlocked\nFile “”, line 690, in _load_unlocked\nFile “”, line 940, in exec_module\nFile “”, line 241, in _call_with_frames_removed\nFile “/Verba/goldenverba/server/cli.py”, line 6, in \nfrom goldenverba import verba_manager\nFile “/Verba/goldenverba/verba_manager.py”, line 16, in \nfrom goldenverba.components.document import Document\nFile “/Verba/goldenverba/components/document.py”, line 2, in \nfrom goldenverba.components.chunk import Chunk\nFile “/Verba/goldenverba/components/chunk.py”, line 1, in \nfrom spacy.tokens import Doc, Span\nFile “/usr/local/lib/python3.11/site-packages/spacy/init.py”, line 6, in \nfrom .errors import setup_default_warnings\nFile “/usr/local/lib/python3.11/site-packages/spacy/errors.py”, line 3, in \nfrom .compat import Literal\nFile “/usr/local/lib/python3.11/site-packages/spacy/compat.py”, line 4, in \nfrom thinc.util import copy_array\nFile “/usr/local/lib/python3.11/site-packages/thinc/init.py”, line 2, in \nimport numpy\nFile “/usr/local/lib/python3.11/site-packages/numpy/init.py”, line 130, in \nfrom numpy.config import show as show_config\nFile “/usr/local/lib/python3.11/site-packages/numpy/config.py”, line 4, in \nfrom numpy.core._multiarray_umath import (\nFile “/usr/local/lib/python3.11/site-packages/numpy/core/init.py”, line 24, in \nfrom . import multiarray\nFile “/usr/local/lib/python3.11/site-packages/numpy/core/multiarray.py”, line 10, in \nfrom . import overrides\nFile “/usr/local/lib/python3.11/site-packages/numpy/core/overrides.py”, line 8, in \nfrom numpy.core._multiarray_umath import (\nFile “”, line 216, in _lock_unlock_module\nKeyboardInterrupt\n\n----------\n\n[wtavares (2024-10-11T23:43:27.326Z)]: I managed to fix. Changed the dockerfile. I’m  going to send here for your information.\nI’ll try to configure the service now.\n\n----------\n\n[wtavares (2024-10-12T15:48:05.017Z)]: Here goes de Dockerfile:\n# Usando uma imagem Python baseada no Debian Bullseye\nFROM python:3.12-bullseye\n\n# Instalar dependências do sistema necessárias\nRUN apt-get update \\\n    && apt-get install -y \\\n    libopenblas-dev \\\n    && apt-get clean \\\n    && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*\n\nENV UWSGI_CHEAPER 2\nENV UWSGI_PROCESSES 4\n\nWORKDIR /Verba\nCOPY . /Verba\n\n# Instalar dependências Python\nRUN pip install -e '.'\n\nEXPOSE 8000\nCMD [\"verba\", \"start\", \"--port\", \"8000\", \"--host\", \"0.0.0.0\"]\n\n----------\n\n[DudaNogueira (2024-10-14T23:12:43.896Z)]: Opa! Muito bom!!!\nObrigado\n\n----------\n\n[wtavares (2024-10-15T13:32:54.289Z)]: Imagina! Sigo testando e vou trazendo novidades pra vocês!\n\n----------\n\n[wtavares (2024-10-16T14:34:05.287Z)]: At the end the CPUs was not the issue. Change the base imagem solved.\nTry the Dockerfile that I sent.",
    "date_created": "2024-10-11T20:37:05.280Z",
    "has_accepted_answer": true,
    "title": "Failed to start Verba on Docker in Windows",
    "topic_id": 4888
  },
  {
    "user_id": 30,
    "conversation": "[SomebodySysop (2025-02-14T21:17:36.826Z)]: Description\n\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\nI just got a note that my OpenAI API key was leaked.  As I use OpenAI for embedding as well as text-2vec, where do I go to enter the new key in Weaviate.  Thanks!\n\n----------\n\n[DudaNogueira (2025-02-14T21:31:27.370Z)]: hi @SomebodySysop !!\nThere are two places that you can pass your API Keys to Weaviate.\n\nAt the client instantiation, as header:\n\n# Recommended: save sensitive data as environment variables\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\nheaders = {\n    \"X-OpenAI-Api-Key\": openai_key,\n}\n\nor at the server level, providing the environment variable OPENAI_APIKEY\nLet me know if that helps!\nThanks!\n\n----------\n\n[SomebodySysop (2025-02-14T21:46:15.508Z)]: So the openai key is not stored anywhere in weaviate, but always sent dynamically with every query/embed request?\n\n----------\n\n[DudaNogueira (2025-02-16T11:08:06.115Z)]: That’s correct. It is not stored in Weaviate itself.",
    "date_created": "2025-02-14T21:17:36.784Z",
    "has_accepted_answer": true,
    "title": "OpenAI API Key Leaked",
    "topic_id": 10347
  },
  {
    "user_id": 1596,
    "conversation": "[Mit_Patel (2024-09-25T12:43:03.413Z)]: Hello , I am trying to built RAG pipeline and i am a new commer in this field.\nMy setup is like two containers one for vector store and one for querying from the data. I am using llama3 embedding model from my machine locally.\nI am facing isuue that embeddings are created but they are not added to the database and so i cannot query them, i am using client method to do it. The script runs without error but while accessing the data base there are no embeddings. Any suggestion or guidance will be helpful.\nThank you !\n\n----------\n\n[DudaNogueira (2024-09-30T14:39:07.101Z)]: hi @Mit_Patel !!\nWelcome to our community \nIf I understood it correctly, you are vectorizing the data yourself, and inserting the vector alongside your object.\nIf that’s the case, this is what we call “Bring your own vectors”.\nThe other option is to let Weaviate vectorize it for you. On that case you need to set up the collection properly with the vectorizer you want.\nCan you share the code snippet where you ingest the data?\nThat will allow to troubleshoot it better.\nTHanks!",
    "date_created": "2024-09-25T12:43:03.359Z",
    "has_accepted_answer": false,
    "title": "Embeddings",
    "topic_id": 4318
  },
  {
    "user_id": 271,
    "conversation": "[kranthi_kumar (2023-09-05T12:21:50.691Z)]: Hi Team,\ni have enabled the  LOG_LEVEL: ‘debug’ and restarted my docker image.\nI am trying to verify the logs it created, but not able to get the location of log file.\nCan you please help on it.\n\n----------\n\n[DudaNogueira (2023-09-05T15:07:01.883Z)]: Hi!\nWeaviate will log at stdout.\nThis means that you can check the log running, for example:\ndocker compose logs -f --tail 10 weaviate\n\nif you know the id of your container (docker ps will show), you can discover where the .json file will be in your host system by issuing:\ndocker inspect --format='{{.LogPath}}' <id-of-your-weaviate-container>\n\nLet me know if that helps!\nThanks!\n\n----------\n\n[kranthi_kumar (2023-09-06T10:02:10.062Z)]: Hello,\nThank you very much … it helped to identify the log location.\nThanks again…!!\n\n----------\n\n[bewakes (2024-12-18T02:29:46.883Z)]: That’s helpful.\nI want to write logs to a file. Is there an option to set log file? I could not find it.\n\n----------\n\n[DudaNogueira (2024-12-18T14:36:46.150Z)]: hi @bewakes !!\nWelcome to our community \nI am not sure I understood this question.\nDo you want to write logs on the server log stream?\n\n----------\n\n[bewakes (2024-12-18T16:16:31.752Z)]: Hi @DudaNogueira !! Thank you for your prompt reply.\nWhat I needed to do was to stream weaviate logs to grafana via loki. The weaviate instance runs inside docker. It seems that there’s a docker plugin for logging to loki. So, my issue is resolved.\nAnyways, thank you weaviate team for creating this wonderful database.\n\n----------\n\n[DudaNogueira (2024-12-18T19:16:59.784Z)]: Oh, I see.\nYou can expose prometheus metrics, as documented here:\n  \n      \n\n      weaviate.io – 28 Mar 23\n  \n\n  \n    \n\nMonitoring Weaviate in Production | Weaviate\n\n  Learn about how to monitor Weaviate in production and observe key metrics.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!",
    "date_created": "2023-09-05T12:21:50.647Z",
    "has_accepted_answer": true,
    "title": "Where is the weaviate log file location",
    "topic_id": 617
  },
  {
    "user_id": 1317,
    "conversation": "[hugmun (2024-08-17T11:37:50.000Z)]: Hi !\nI have a debian linux runing all fine.\nI have made a venv and installed Verba with   pip install .\nI have made a   verba.env  file and placed it in the venv/verrba/  folder.\nIn the file I have spec for Ollama and 2 api-keyes\nGNU nano 7.2                                       verba.env\nOLLAMA_MODEL=“dolphin-mistral”:latest\nOLLAMA_EMBED_MODEL=“snowflake-arctic-embed”\nOLLAMA_URL=“http://localhost:11434”\nCOHERE_API_KEY=“ZvyJeBa6Cab7KLBI8wlIDyGRzQ3uokGJVpeRK”\nOPENAI_API_KEY=“org-kMcoaROCz7eZHtFn727fe”\nI have ttyed both with and with out  =“”\nI have  chmod 777   on it for full access.\nIt just gets ignored.\nWhat am I missing?\nBest regard\n//Magnus\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-08-19T12:43:50.155Z)]: hi! Welcome to our community \nThe environment variable file must be called .env and not verba.env\nPs: @hugmun  hope those keys are not valid ones \nLet me know if this helps!\nThanks!",
    "date_created": "2024-08-17T11:37:49.939Z",
    "has_accepted_answer": false,
    "title": "Verba doesn't read my .env-file",
    "topic_id": 3381
  },
  {
    "user_id": 513,
    "conversation": "[rjalex (2025-01-07T09:21:30.505Z)]: In my application I need to apply apply fuzzy search on a text field to find matches even if the string was mis-typed. Imagine an application that needs to filter objects on a “surname” field and especially with foreign names the exact match could not work. Cosine nearness on embeddings would not help either in this case.\nIn my application I use this python library RapidFuzz · PyPI which is very very good.\nWould there be any mechanism to apply an external function such as this to a text field in a collection without having to applicatively iterate through all the collection?\nThanks\n\n----------\n\n[Dirk (2025-01-07T13:14:29.252Z)]: I don’t think we have anything directly like this but the following could work:\n\nuse named vectors\ndefine a named vector with the vectorizer text2vec-bigram that takes your surname field as input. This is more of a test vectorizer and not documented but I think it could work for your usecase. You can check the code here: weaviate/modules/text2vec-bigram/bigram.go at main · weaviate/weaviate · GitHub\nThose vectors should be very close when there is just a typo in the name and most of it is the same\n\nNote that this module is probably not enabled in weaviate cloud\n\n----------\n\n[rjalex (2025-01-07T14:19:44.252Z)]: Very interesting Dirk, thanks.\nI will definitely experiment.\nBut actually my example was very simplistic. The true task is quite tough with searching through a long list of wordplays.\nThese wordplays are obtained though techniques such as splitting or fusing a legal word, making deliberate typos etc, therefore the various algorithms of the rapidfuzz library give me more latitude.\n\n----------\n\n[Dirk (2025-01-08T07:00:51.854Z)]: The true task is quite tough with searching through a long list of wordplays.\n\nSadly don’t have a better idea \nThe mentioned vectorizer has a few options so maybe play around and see if any of them works. Please let me know if something comes out of this!",
    "date_created": "2025-01-07T09:21:30.463Z",
    "has_accepted_answer": false,
    "title": "Fuzzy matching algorithms",
    "topic_id": 9603
  },
  {
    "user_id": 967,
    "conversation": "[Bill_R (2024-05-22T05:35:49.614Z)]: Description\nWhat is the procedure to backup my set of collections when using Weaviate cloud?\nIt was unclear from reviewing\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBackups | Weaviate - Vector Database\n\n  Weaviate's Backup feature is designed to feel very easy to use and work natively with cloud technology. Most notably, it allows:\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: Cloud\nMulti Node? No\nClient Language and Version:\n\nAny additional Information\nNA\n\n----------\n\n[DudaNogueira (2024-05-22T08:26:32.363Z)]: hi @Bill_R ! Welcome to our community! \nAll cluster running in our Cloud are automatically backed up.\nYou don’t need to worry about it. We got you covered \nLet me know if this helps!\nThanks!\n\n----------\n\n[Bill_R (2024-05-22T16:08:07.383Z)]: Thanks Duda, It is nice that the cloud content is automatically backed up.\nWe need a way to archive the data outside of Weaviate so that we\ncan support tutorials for example that others can run through using their own cluster. That requires the importing step as well of course. The datasets are not going to be large. We require them to be versioned in our own source code world too.\n\n----------\n\n[DudaNogueira (2024-05-23T08:20:45.163Z)]: Hi Bill!\nUnderstood. On that case, The best option is to have a script to import and export that dataset, where you can version the export.\nBy default, we do not expose those backups outside. You can call the backup command, and a new backup is generated.\nAlso, you can remove all your collections and then restore. But there isn’t a way, as of now, to download your backup from our cloud service.\nLet me know if this helps!\nThanks!\n\n----------\n\n[Tejas_Sharma (2024-12-17T11:31:52.982Z)]: Hey @DudaNogueira going off of this, so if I have a cluster in the cloud, Weaviate automatically backs this up?\nLet’s say I need to backup to a version 2 days ago or an hour ago, etc., how can we do this?",
    "date_created": "2024-05-22T05:35:49.565Z",
    "has_accepted_answer": false,
    "title": "Weaviate cloud backup to file system",
    "topic_id": 2414
  },
  {
    "user_id": 1476,
    "conversation": "[ivan075 (2024-08-30T23:50:13.583Z)]: Description\nI noticed when we ingest data in weaviate cluster from time to time some nodes/pods will loose connectivity and I will see messages like this:\n{\"level\":\"error\",\"msg\":\"\\\"10.89.161.62:7001\\\": connect: Post \\\"http://10.89.161.62:7001/replicas/indices/..../shards/CdbqEZkp7uPZ/objects?request_id=weaviate-0-64-191a5978c3f-ce00c\\u0026schema_version=34\\\": dial tcp 10.89.161.62:7001: connect: connection refused\",\"op\":\"broadcast\",\"time\":\"2024-08-30T23:20:58Z\"}\n{\"level\":\"error\",\"msg\":\"\\\"10.89.139.73:7001\\\": connect: Post \\\"http://10.89.139.73:7001/replicas/indices/..../shards/8x9pGGpLfof6/objects?request_id=weaviate-0-64-191a5978c3f-ce002\\u0026schema_version=34\\\": dial tcp 10.89.139.73:7001: connect: connection refused\",\"op\":\"broadcast\",\"time\":\"2024-08-30T23:20:58Z\"}\n{\"level\":\"error\",\"msg\":\"\\\"10.89.139.73:7001\\\": connect: Post \\\"http://10.89.139.73:7001/replicas/indices/..../shards/05i1dRqNYiPq/objects?request_id=weaviate-0-64-191a597aa92-cfa26\\u0026schema_version=34\\\": dial tcp 10.89.139.73:7001: connect: connection refused\",\"op\":\"broadcast\",\"time\":\"2024-08-30T23:21:05Z\"}\n{\"level\":\"error\",\"msg\":\"\\\"10.89.139.73:7001\\\": connect: Post \\\"http://10.89.139.73:7001/replicas/indices/..../shards/URlrEqICLG0s/objects?request_id=weaviate-0-64-191a597aa91-cfa06\\u0026schema_version=34\\\": dial tcp 10.89.139.73:7001: connect: connection refused\",\"op\":\"broadcast\",\"time\":\"2024-08-30T23:21:05Z\"}\n{\"action\":\"raft\",\"fields.time\":514781564,\"level\":\"warning\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-1\",\"time\":\"2024-08-30T23:21:11Z\"}\n{\"action\":\"raft\",\"fields.time\":512243048,\"level\":\"warning\",\"msg\":\"raft failed to contact\",\"server-id\":\"weaviate-2\",\"time\":\"2024-08-30T23:21:17Z\"}\n\nAfter some time things normalizes. During the process of ingestion our resource utilization are normal. We are not hitting any resource limitation of the pods. So for now no need to scale up resources of the pods.\nQuestions:\n\n\nIs there any useful tunning option or optimization we can do on weaviate which might help us about this situation (so far we are with pretty default config / we have already upgraded our clients to v4 and grpc)? We’ll see what we can improve on the ingestion pipeline but I was curious if I can tune up something on weaviate itself too.\n\n\nOn a separate topic what prometheus/grafana metrics I can find for weaviate to monitor shards and connections? I cant seem to find any? What’s exposed by weaviate or where I can see/check whats available to me?\n\n\nServer Setup Information\n\nWeaviate Server Version: 1.25.0\nDeployment Method:  deployed with helm in k8 /aws eks\nMulti Node? Number of Running Nodes: 7 nodes (3 replication factor for our collection; multiple shards)\nClient Language and Version: python with version 3 and version 4 (grpc)\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-09-02T12:19:32.368Z)]: hi @ivan075 !!\nWelcome to our community \nRegarding tuning for optimization, there are some options as stated here: Resource Planning | Weaviate\nIngesting data is a heavy CPU bound process, so it is interesting to keep an eye on that resource usage and make sure you can ingest at a rate that doesn’t overwhelm the resources you have.\nConsider that at ingestion, Weaviate will not only receive the data, write it into DB but also index your vector (for similarity search) and inverted index (for keyword search).\nConsidering your error logs, it seems that that node is having a hard time connecting to nodes weaviate-1 and weaviate-2.\nDo you have any resource reading on those at that timestamp?\nRegarding monitoring, here is the documentation on what are the current metrics we can scrap using prometheus:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMonitoring | Weaviate\n\n  Weaviate can expose Prometheus-compatible metrics for monitoring. A standard\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-08-30T23:50:13.530Z",
    "has_accepted_answer": false,
    "title": "Issue with weaviate shards and ingestion",
    "topic_id": 3937
  },
  {
    "user_id": 3308,
    "conversation": "[Hayden_111 (2025-02-03T08:20:54.070Z)]: Hi,\nMy company is currently using AWS Weaviate DB and already importing the articles as data source. We plan to integrate the AWS GenAI LLM into our mobile application.\nThe concept is to utilize our own articles, which have already been imported into the database, as the source. Users can ask questions, and the results will be determined by the relevance of the article’s content.\nHere’s my question:\nIs it possible to control the data source based on specific criteria, such as news categories, certain publication period of articles, or the source (e.g. searching from the db or internet)?\n\n----------\n\n[DudaNogueira (2025-02-03T13:51:08.369Z)]: hi @Hayden_111 !!\nWelcome to our community \nIn Weaviate you can perform a search and use different filter criterias based on your data using filters.\nHowever, you can only search in Weaviate what it has indexed by the time you perform the search.\nSo if you want your app to search over the internet to add context for your content generation, you need to first index that content or add it to the prompt while generating the content.\nLet me know if this answer your questions.\nTHanks!",
    "date_created": "2025-02-03T08:20:54.017Z",
    "has_accepted_answer": false,
    "title": "Compatibility of AWS GenAI <> Weaviate",
    "topic_id": 10003
  },
  {
    "user_id": 3056,
    "conversation": "[Hassan_Raza (2024-12-19T06:22:44.045Z)]: I am unable to connect my weaviate serverless cloud. I am facing errors related to connection like 401. I am giving my correct APIs.\nFailed to connect: 401, {“code”:401,“message”:“anonymous access not enabled, please provide an auth scheme such as OIDC”}\n\n----------\n\n[DudaNogueira (2024-12-19T21:31:33.666Z)]: hi @Hassan_Raza !!\nWelcome to our community \nFor any help on our hosted clusters, the best place for support is:\n  \n\n      console.weaviate.cloud\n  \n\n  \n    \n\nWeaviate Cloud\n\n  Weaviate Cloud\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if you were able to connect, and I would love to jump on a call with you to help out.\nTHanks!",
    "date_created": "2024-12-19T06:22:43.985Z",
    "has_accepted_answer": false,
    "title": "Unable to connect to weaviate cloud",
    "topic_id": 9327
  },
  {
    "user_id": 1491,
    "conversation": "[bharath97 (2024-09-06T12:37:33.775Z)]: Hi team,\nI’m running weaviate(V1.25) in kubernetes.\nWhen I try to bulk index documents, I randomly get this exception:\nweaviate.exceptions.UnexpectedStatusCodeException: batch response!\nUnexpected status code: 404, with response body: None.`\nThis isn’t happening always though. For the same set of documents, when I try to index the same documents after sometime, it works.\nCan someone please help.\n\n----------\n\n[DudaNogueira (2024-09-06T20:36:16.531Z)]: hi @bharath97 !!\nWelcome to our community \nHow have you exposed Weaviate service http and grpc services at your K8s?\nThis may be related as this messages indicates that the client got 404 from the server. Considering that this is not happening always, it may be k8s load balancer returning 404 instead of the corresponding service.\nLet me know if this helps.\nThanks!\n\n----------\n\n[bharath97 (2024-09-10T06:34:53.256Z)]: Hey @DudaNogueira , thanks for your response.\nThis is exposed over http only. (Traefik is the proxy, just FYI).\nMy traefik proxy has recorded a 499 status code for batch operations. The default timeout configured is 60 seconds. The document size is not too high as well.\nFor records of similar sizes, few batch inserts response was under 20ms.\nAfter looking at the logs of weaviate server, the batch operation is completed in 3.7ms. Attached the log from weaviate server:\n{\n  \"action\": \"batch_objects\",\n  \"batch_size\": 5,\n  \"level\": \"trace\",\n  \"msg\": \"object batch took 3.702183ms\",\n  \"time\": \"2024-09-10T06:36:42Z\",\n  \"took\": 3702183\n}\n\nAnother log on my proxy server says:\n10.2.2.131 - - [10/Sep/2024:06:36:42 +0000] \"POST /v1/batch/objects HTTP/1.1\" 499 21 \"-\" \"-\" 1211875 \"xplus-weaviate-weaviate-xplus-xplus-weaviate-prodca-phenom-local@kubernetes\" \"http://10.2.214.160:8080\" 60059ms\n\nIf I understand this correctly, the batch insert happened instantaneously, however the response wasn’t sent back to the client.\nAny help is appreciated!\n\n----------\n\n[DudaNogueira (2024-09-10T19:07:22.499Z)]: Ok, what version specifically are you running?\nWhat client language and version are you using?\nCan you map it directly to a port so we can isolate any Traefik intereference?\n\n----------\n\n[bharath97 (2024-09-11T07:30:33.893Z)]: Hi @DudaNogueira ,\nMy weaviate server version is: 1.25.0\nClient language - Python(via langchain)\nClient version - 3.24.1\nI tried calling the kubernetes service port endpoint, bypassing traefik and I haven’t observed any timeouts after testing.\nI’m surprised why this issue has popped up very recently when I’ve been using the same version of weaviate and traefik for over an year.\nEdit: I reverted back to using r53 record now and I don’t see any failures. There was one retry out of my 100 requests and the rest worked seamlessly.\n\n----------\n\n[DudaNogueira (2024-09-11T12:40:05.159Z)]: Glad to hear that!\nNotice that you are using python v3 client, while the new python v4 will get you a lot of improvements, specially on batch inserts, as it uses GRPC instead of HTTP.\nCheck this doc on how to migrate your code from v3 to v4:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nMigrate from v3 to v4 | Weaviate\n\n  The current Python client version is v||site.pythonclientversion||\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThe cool part is that the new python v4 client also includes the python v3, so you can migrate your codebase gradually, and start for example on the batch, already leveraging the GRPC features.\nTHanks!\n\n----------\n\n[bharath97 (2024-09-13T03:34:25.967Z)]: Thank you!\nWould you mind explaining the reason for these intermittent timeouts on http?\nAlso, I believe using http with v4 client wouldn’t still solve the issue right?\n\n----------\n\n[DudaNogueira (2024-09-16T20:46:29.199Z)]: Hi! I believe this is an issue on how your Weaviate is exposed.\nMaybe, the client is hitting the url, but traefik is not delivering the request correctly, and returning with a 404 error.\nand yes, if the services are not exposed correctly, using v4 should make no difference.\n\n----------\n\n[bharath97 (2024-09-17T05:50:11.096Z)]: Hello,\nI believe that too. I can check on the configuration of ingress for this.\nHowever, from the logs, the request was forwarded from traefik to weavaite server as I could see the log with message: object batch took 3.702183ms\nAfter this the response was not received for traefik.\nAlso, if you have any references on how to expose weaviate on kubernetes cluster, can you please share?",
    "date_created": "2024-09-06T12:37:33.725Z",
    "has_accepted_answer": true,
    "title": "Batch inserts failing for weaviate",
    "topic_id": 3993
  },
  {
    "user_id": 1258,
    "conversation": "[haozhuoyuan (2024-07-30T02:57:27.456Z)]: import time\nimport weaviate\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\nfrom llama_index.vector_stores.weaviate import WeaviateVectorStore\nfrom llama_index.core.node_parser import SentenceSplitter\nfrom llama_index.core import StorageContext, Settings\nfrom llama_index.readers.file import PyMuPDFReader\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.llms.openai import OpenAI\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\nimport nest_asyncio\nnest_asyncio.apply()  # Only needed in Jupyter notebooks\nweaviate_client = weaviate.connect_to_local()\nweaviate_client.connect()\nSettings.llm = OpenAI(temperature=0, model=\"gpt-4o\")\nSettings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=512)\nsplitter = SentenceSplitter(chunk_size=512, chunk_overlap=100)\ndocuments = SimpleDirectoryReader(\"./data1\").load_data()\nnodes = splitter.get_nodes_from_documents(documents)\nprint(nodes)\nif weaviate_client.collections.exists(\"TextNode\"):\n    weaviate_client.collections.delete(\"TextNode\")\nschema = {\n           \"class\": \"TextNode\",\n           \"properties\": [\n               {\"name\": \"id_\", \"dataType\": [\"string\"], },\n               {\"name\": \"embedding\", \"dataType\": [\"number[]\"], },\n               {\"name\": \"file_path\", \"dataType\": [\"string\"], },\n               {\"name\": \"file_name\", \"dataType\": [\"string\"], },\n               {\"name\": \"file_type\", \"dataType\": [\"string\"], },\n               {\"name\": \"file_size\", \"dataType\": [\"int\"], },\n               {\"name\": \"creation_date\", \"dataType\": [\"string\"], },\n               {\"name\": \"last_modified_date\", \"dataType\": [\"string\"], },\n               # {\"name\": \"source\", \"dataType\": [\"string\"], },\n               {\"name\": \"text\", \"dataType\": [\"text\"], },\n               {\"name\": \"start_char_idx\", \"dataType\": [\"int\"], },\n               {\"name\": \"end_char_idx\", \"dataType\": [\"int\"], }\n               # {\"name\": \"metadata_str\", \"dataType\": [\"string\"], },\n               # {\"name\": \"content\", \"dataType\": [\"text\"], },\n           ]\n       }\nweaviate_client.collections.create_from_dict(schema)\ntry:\n    collection = weaviate_client.collections.get(\"TextNode\")\n    data_lines = []\n    for node in nodes:\n        embedding = Settings.embed_model.get_text_embedding(node.text)  # 生成嵌入\n        node.embedding = embedding \n        properties = {\n            \"id\": node.id_,\n            \"embedding\": node.embedding,\n            \"file_path\": node.metadata.get(\"file_path\"),\n            \"file_name\": node.metadata.get(\"file_name\"),\n            \"file_type\": node.metadata.get(\"file_type\"),\n            \"file_size\": node.metadata.get(\"file_size\"),\n            \"creation_date\": node.metadata.get(\"creation_date\"),\n            \"last_modified_date\": node.metadata.get(\"last_modified_date\"),\n            # \"source\": node.metadata.get(\"source\"),\n            \"text\": node.text,\n            \"start_char_idx\": node.start_char_idx,\n            \"end_char_idx\": node.end_char_idx,\n            # \"metadata_str\": node.metadata_template,\n            # \"content\": node.text,\n        }\n        data_lines.append(properties)\n    print(data_lines)\n    with collection.batch.dynamic() as batch:\n        for data_line in data_lines:\n            batch.add_object(properties=data_line)\n    print(\"node insert completation！！！！！！！！！！！\")\n    vector_store = WeaviateVectorStore(weaviate_client=weaviate_client, index_name=\"TextNode\")\n    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n    index = VectorStoreIndex.from_vector_store(vector_store)\n    print(index.index_struct)\n    print(index.storage_context)\n\n    query_engine = index.as_query_engine()\n\n    while True:\n        question = input(\"User: \")\n        if question.strip() == \"\":\n            break\n        start_time = time.time()\n        response = query_engine.query(question)\n        end_time = time.time()\n        print(f\"Time taken: {end_time - start_time} seconds\")\n        print(f\"AI: {response}\")\nfinally:\n    weaviate_client.close()\n\nError message is:\n{‘message’: ‘Failed to send 1 objects in a batch of 1. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\nHow should I solve it?Thank you\n\n----------\n\n[DudaNogueira (2024-07-30T14:51:33.778Z)]: Hi!\nYou need to inspect client.batch.failed_objects and check the error log in there.\nIt can be apikeys, timeout, or anything in between.\nCan you check the content of that objects?\nMore info on error handling in python batch:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate - Vector Database\n\n  Overview\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!\nThanks!",
    "date_created": "2024-07-30T02:57:27.383Z",
    "has_accepted_answer": false,
    "title": "[Question] client.batch.failed_objects",
    "topic_id": 3217
  },
  {
    "user_id": 915,
    "conversation": "[Jonathan_Yapp (2024-05-11T16:01:06.597Z)]: I’m deploying a simple test function to a python 3.11 lambda function. I have a weaviate layer attached to it with weaviate-client installed. when i try and import weaviate, I get:\n“errorMessage”: “/lib64/libc.so.6: version `GLIBC_2.28’ not found (required by /opt/python/cryptography/hazmat/bindings/_rust.abi3.so)”\nit is my understanding that lambda uses an older version of GLIBC. Usually the solution to something like this would be to use an older wheel,\nfor example: pip install weaviate-client --platform manylinux_2_12_x86_64 --only-binary=:all:\nbut this leads to conflicting dependancies and wont install. any ideas?\n\n----------\n\n[DudaNogueira (2024-05-12T13:31:22.577Z)]: hi @Jonathan_Yapp ! Welcome to our community \nI have not used weaviate-client with Lambda. \nI will try to experiment on that this week and will get back here. Also, I can try escalating this with our team.\nThanks!\n\n----------\n\n[niknokseyer (2024-05-30T18:59:30.924Z)]: Were you able to resolve this as well? We added a Lambda Layer with weviate and couldn’t make it to work either.\n\n----------\n\n[Jonathan_Yapp (2024-05-30T19:18:37.008Z)]: No i wasn’t able to resolve this and used the REST API instead of the client. You can easily replicate the issue in a docker container that  has the older GLIBC.\n\n----------\n\n[DudaNogueira (2024-06-01T00:23:11.777Z)]: HI!!\nHey @niknokseyer! Welcome to our community.\n@Jonathan_Yapp Good news! I found a fix for this (or I was able to run in lambda)\nSorry for the delay, I was out the past days \nI was able to make it work.\nhere was how with some example code.\nFirst, create the package and install the dependency\nmkdir -p my-lambda-function/package\ncd my-lambda-function/package\npip install weaviate-client --platform manylinux2014_x86_64 -t . --only-binary=:all:\ncd ..\n\nnow we have in our root folder a package folder with all dependencies so far.\nI created a lambda_function.py file on this root folder with the contents:\nimport json\nimport os\nimport requests\n\nimport weaviate\nfrom weaviate import classes as wvc\n\nCLUSTER_URL = os.environ.get(\n    \"CLUSTER_URL\",\n    \"https://duda-test-sdfsdfsdf.weaviate.network\"\n)\n\nCLUSTER_APIKEY = os.environ.get(\n    \"CLUSTER_APIKEY\",\n    \"PasdasdpUrmLsdfsdfsdfsdfsdfokj\"\n)\n\nOPENAPI_KEY = os.environ.get(\n    \"OPENAI_APIKEY\",\n    \"sk-j0sdfsdfsdfsdfdasdasdaO5MsdfsdfsdfYoGVw\"\n)\n\ndef lambda_handler(event, context):\n    # if not ?query=some_query, defaults to biology\n    query = event.get(\"queryStringParameters\", {}).get(\"query\", \"biology\")\n\n    client = weaviate.connect_to_wcs(\n        cluster_url=CLUSTER_URL,\n        auth_credentials=weaviate.auth.AuthApiKey(CLUSTER_APIKEY),\n        headers={\n                \"X-OpenAI-Api-Key\": OPENAPI_KEY  # Replace with your inference API key\n            }        \n    )\n    if not client.collections.exists(\"Question\"):\n        # create content and import some data\n        questions = client.collections.create(\n            name=\"Question\",\n            vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),  # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n            generative_config=wvc.config.Configure.Generative.openai()  # Ensure the `generative-openai` module is used for generative queries\n        )\n        # add some data\n        resp = requests.get('https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json')\n        data = json.loads(resp.text)  # Load data\n\n        question_objs = list()\n        for i, d in enumerate(data):\n            question_objs.append({\n                \"answer\": d[\"Answer\"],\n                \"question\": d[\"Question\"],\n                \"category\": d[\"Category\"],\n            })\n        questions.data.insert_many(question_objs)\n    questions = client.collections.get(\"Question\")\n    # return results\n    response = {}\n    # single prompt\n    results = questions.generate.near_text(\n        query=query,\n        limit=1,\n        single_prompt=\"Explain {answer} as you might to a five-year-old.\"\n    )\n    response[\"single_prompt\"] = results.objects[0].generated\n    # group task\n    results = questions.generate.near_text(\n        query=query,\n        limit=2,\n        grouped_task=\"Write a tweet with emojis about these facts.\"\n    )\n    response[\"grouped_task\"] = results.generated\n    client.close()\n    return {\n        'statusCode': 200,\n        'body': json.dumps(response)\n    }\n\n\nnow you need to zip those files on this specific order/way:\ncd package\nzip -r ../deployment.zip .\ncd ..\nzip deployment.zip lambda_function.py\n\nLet me know if this works on your side, as this could be a starter pack recipe for weaviate client in lambda \nThanks!\n\n----------\n\n[Jonathan_Yapp (2024-06-01T00:47:03.000Z)]: Thank you, I will try that out (post vacation!) and report back.\n\n----------\n\n[Rafael_Castelli (2024-12-20T22:37:56.191Z)]: Same issue here, and your solution worked perfectly. Thanks a lot!\n\n----------\n\n[DudaNogueira (2024-12-20T23:27:23.416Z)]: hi @Rafael_Castelli !!\nThanks for sharing!\nI have now marked this as solved\n\n----------\n\n[DudaNogueira (2024-12-20T23:27:54.280Z)]: AAaaaaaannnd… welcome to our friendly community",
    "date_created": "2024-05-11T16:01:06.544Z",
    "has_accepted_answer": true,
    "title": "Deploying Weaviate Python Client to Lambda",
    "topic_id": 2269
  },
  {
    "user_id": 389,
    "conversation": "[TweedBeetle (2024-07-22T20:12:34.467Z)]: I am using versionp 4.6.7 of the python client have a managed production cluster (not sanbox)\nI am getting a total count of 0 when I run collection.aggregate.over_all(total_count=True)\nHowever, on the dashboard, I can see there are 60k items in the collection.\nI am certain I’ve got the collection name right. In fact, I only have a single collection.\nAlso, I don’t know if this is related, but I could swear my collection definition reverted to a previous version of itself on it’s own in the last two days. I can’t explain it and am quite confused.\nAny additional debug steps or insight appreciated!\n\n----------\n\n[DudaNogueira (2024-07-23T21:30:58.883Z)]: hi @TweedBeetle !! Welcome to our forum! \nFor all clusters that we host, the best place to ask for support is opening a support ticket by sending an email to support@weaviate.io\nThis way we can check the cluster directly and take a closer look.\nThanks!",
    "date_created": "2024-07-22T20:12:34.413Z",
    "has_accepted_answer": false,
    "title": "Total count of collection items yielding 0 despite 60k objects according to dashboard",
    "topic_id": 3123
  },
  {
    "user_id": 3301,
    "conversation": "[FullyLost (2025-02-01T12:47:36.739Z)]: Description\nI’m very lost in the rest API documentation. The AI Assistant told me i can use the rest api to search using this GET /v1/objects?class=JeopardyQuestion&nearText={\"concepts\":[\"animals in movies\"]}&limit=2. It does work. The assistant cites this article Vector similarity search. But there seem to be only examples for graphql and no mention of rest.\nI also can’t find anything in the description of this rest-site rest. It clearly works, but i can’t any documentation for it. I used google and the search on the page.\nI’m new to weaviate and try to play a bit with it to evaluate it.\nCan anyone point me to the correct page on how to use nearText search?\nThe example from the AI works, but i need documentation for this feature to be able to implement it at work.\nServer Setup Information\n\nWeaviate Server Version: weaviate:1.28.2\nDeployment Method: docker\nMulti Node? Number of Running Nodes: single node\nClient Language and Version: ?\nMultitenancy?: no\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2025-02-03T13:46:42.265Z)]: hi @FullyLost !!\nWelcome to our community \nIn order to perform a bm25, or vector or hybrid search using rest, you need to send in a graphql query, as per this api reference:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nWeaviate\n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNow, for each of the features, you will see tabs showing to use that feature using different clients. You can also find a tab for graphql, like in here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate\n\n  Hybrid search combines the results of a vector search and a keyword (BM25F) search by fusing the two result sets.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHere is an example:\ncurl --request POST \\\n  --url http://localhost:8080/v1/graphql \\\n  --header 'Content-Type: application/json' \\\n  --data '{\"query\":\"{Get{Test(nearText:{concepts:[\\\"dogs\\\"]}){text}}}\"}'\n\nOne nice trick is to use a tool like insomnia, and use it to autocomplete while creating the graphql query:\nimage1406×952 43.6 KB\nThen you can just generate a “curl command”\nLet me know if that helps!",
    "date_created": "2025-02-01T12:47:36.679Z",
    "has_accepted_answer": false,
    "title": "Can't find documentation for the search via rest",
    "topic_id": 9991
  },
  {
    "user_id": 3087,
    "conversation": "[Ayush_Singh (2024-12-23T09:04:18.189Z)]: Below is my .yaml file\nversion: '3.9'\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2\n    container_name: weaviate\n    ports:\n      - \"8080:8080\"\n      - \"50051:50051\"\n\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      ENABLE_API_BASED_MODULES: 'true'\n      LIMIT_RESOURCES: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      CLUSTER_HOSTNAME: 'node1'\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:3\nvolumes:\n  weaviate_data:\n    driver: local\n\nI want am running the Docker Container on an Azure VM.\nWith inbound ports exposed: 8080 and 50051\nI am getting the error of failed to join remoteNode: 172.28.0.2:8300\nI dont even want to have a cluster, standalone node is something I am looking for but I am not able to achieve it.\nAny solution?\n\n----------\n\n[DudaNogueira (2024-12-23T13:44:47.803Z)]: hi @Ayush_Singh !!\nWelcome to our community \nCan you paste the entire error stack?\nAlso, can you paste how you are doing to connect to that cluster?\nthis should work if you deploy this very same docker compose on a VPS and making sure you expose ports 8080 and 50051, and using our python client:\nclient = weaviate.connect_to_local(\n    headers=headers,\n    #auth_credentials=weaviate.auth.AuthApiKey(\"YOUR-WEAVIATE-API-KEY\")\n    host=\"192.168.28.99\"\n)\nprint(f\"Client: {weaviate.__version__}, Server: {client.get_meta().get('version')}\")\n\n Note: this will exposes you server without any security inplace: SSL encryption and authentication!\nLet me know if this helps!\nThanks!\n\n----------\n\n[Ayush_Singh (2024-12-24T01:57:07.930Z)]: Below are the container logs:\n{\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"level\":\"info\",\"msg\":\"attempting to join\",\"remoteNodes\":[\"192.168.176.2:8300\"],\"time\":\"2024-12-24T01:53:10Z\"}\n{\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"level\":\"info\",\"msg\":\"attempted to join and failed\",\"remoteNode\":\"192.168.176.2:8300\",\"status\":8,\"time\":\"2024-12-24T01:53:10Z\"}\n{\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"level\":\"info\",\"msg\":\"attempting to join\",\"remoteNodes\":[\"192.168.176.2:8300\"],\"time\":\"2024-12-24T01:53:11Z\"}\n{\"build_git_commit\":\"5a3991d\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.2\",\"build_wv_version\":\"1.28.2\",\"level\":\"info\",\"msg\":\"attempted to join and failed\",\"remoteNode\":\"192.168.176.2:8300\",\"status\":8,\"time\":\"2024-12-24T01:53:11Z\"}\n\nupdated yml file:\nversion: '3.9'\nservices:\n  weaviate:\n    container_name: weaviate\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_API_BASED_MODULES: 'true'\n      CLUSTER_HOSTNAME: \"node1\"\n      CLUSTER_GOSSIP_BIND_PORT: \"7102\"\n      CLUSTER_DATA_BIND_PORT: \"7103\"\nvolumes:\n  weaviate_data:\n\n\nMy Weaviate Instance is not able to connect to remoteNode for some reason.\nI also tried to ping the remoteNode explicitly from within the container and it was working. But for some reason the instance is not able to connect to the remoteNode\nAlso when i try to access the remoteNode from the container.\nI dont face any issue.\n/ # nc -zv 192.168.176.2 8300\n192.168.176.2 (192.168.176.2:8300) open\n\n----------\n\n[Ayush_Singh (2024-12-24T12:15:24.125Z)]: Resolved: deleted the cache and it worked.",
    "date_created": "2024-12-23T09:04:18.135Z",
    "has_accepted_answer": true,
    "title": "Couldn't connect to Cluster Remote Node",
    "topic_id": 9402
  },
  {
    "user_id": 1209,
    "conversation": "[arielmoraes (2024-07-17T01:47:11.075Z)]: Description\nWhen executing hybrid searches with relativeScoreFusion, documents without any bm25 score can be scored better than the last bm25 result which receives a score of 0 after normalization.\nIMHO the documents retrieved only via vector search must be assigned a value of 0 for the bm25 part before applying the fusion, by doing that the last bm25 result will rank up as the normalized score won’t be zero.\nIs that a bug or is it by design?\nServer Setup Information\n\nWeaviate Server Version: 1.24.8\nDeployment: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: api directly\nMultitenancy?: no\n\n----------\n\n[Dirk (2024-07-18T04:47:20.083Z)]: IMHO the documents retrieved only via vector search must be assigned a value of 0 for the bm25 part before applying the fusion, by doing that the last bm25 result will rank up as the normalized score won’t be zero.\n\nrelativeScoreFusion just normalizes linearly from [worst_score, best_score] to [0, 1]. The problem is that if a document does not have a BM25 score, we simply cannot scale it.\n\nIs that a bug or is it by design?\n\nIt is more a limitation of the current design. In principle, you could compute the missing vector/Bm25 scores before fusion, but it is not trivial\n\n----------\n\n[arielmoraes (2024-07-18T10:40:40.215Z)]: I know the algorithm is expected to have only one worst case, but before the final normalization we could assume a value of 0 for all the documents missing a BM25 score. Don’t know if it’s a oversight, but it could be done right after querying the vector results.\n\n----------\n\n[Dirk (2024-07-18T11:43:17.739Z)]: arielmoraes:\n\nvalue of 0 for all the documents missing a BM25 score\n\n\nBm25 scores can be negative, this won’t work",
    "date_created": "2024-07-17T01:47:11.023Z",
    "has_accepted_answer": false,
    "title": "Possible bug with relativeScoreFusion",
    "topic_id": 3064
  },
  {
    "user_id": 2578,
    "conversation": "[sravan_j_35 (2024-11-23T16:02:34.662Z)]: Description\n\ni have created a weaviate:1.26.1 instance using docker-compose file in spot instance  in azure  i was running fine and having data and i wanted to migrate this data to azure general purpose instance and used same docker file to spin up weaviate:1.26.1 in new general purpose instance, so while migrating data from spot instance to genral purpose instance i have copied mount path dirctory from the spot instance and copied to general purpose instance (newly created) and changed mount path then i was facing below error\nplease refere to docker-compose file\nversion: '3.4'\n\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.1\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    environment:\n      LOG_LEVEL: trace\n      QUERY_SLOW_LOG_ENABLED: 'true'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n    ports:\n      - 8080:8080\n      - 50051:50051\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n\n  prometheus:\n    image: prom/prometheus:latest\n    volumes:\n      - ./prometheus:/etc/prometheus/\n      - ./data/prometheus:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--web.console.libraries=/usr/share/prometheus/console_libraries'\n      - '--web.console.templates=/usr/share/prometheus/consoles'\n    ports:\n      - 9090:9090\n\n  grafana:\n    image: grafana/grafana\n    ports:\n      - 3000:3000\n    volumes:\n      - ./grafana/grafana.ini:/etc/grafana/grafana.ini\n      - ./grafana/datasource.yml:/etc/grafana/provisioning/datasources/prometheus.yml\n      - ./grafana/dashboard_provider.yml:/etc/grafana/provisioning/dashboards/dashboards.yml\n      - ./grafana/dashboards:/var/lib/grafana/dashboards\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n\nvolumes:\n  weaviate_data:\n```Preformatted text\n\nplease refer to new docker-compse file in  mew vm then after copy docker volume data to newly created vm then \ni have mounted data diretory  \n\nversion: '3.4'\n\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.26.1\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    environment:\n      LOG_LEVEL: trace\n      QUERY_SLOW_LOG_ENABLED: 'true'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n    ports:\n      - 8080:8080\n      - 50051:50051\n    volumes:\n      - /home/azureuser/_data:/var/lib/weaviate   #(old vm data copied to /home/azureuser/_data)\n    restart: on-failure:0\n\n  prometheus:\n    image: prom/prometheus:latest\n    volumes:\n      - ./prometheus:/etc/prometheus/\n      - ./data/prometheus:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--web.console.libraries=/usr/share/prometheus/console_libraries'\n      - '--web.console.templates=/usr/share/prometheus/consoles'\n    ports:\n      - 9090:9090\n\n  grafana:\n    image: grafana/grafana\n    ports:\n      - 3000:3000\n    volumes:\n      - ./grafana/grafana.ini:/etc/grafana/grafana.ini\n      - ./grafana/datasource.yml:/etc/grafana/provisioning/datasources/prometheus.yml\n      - ./grafana/dashboard_provider.yml:/etc/grafana/provisioning/dashboards/dashboards.yml\n      - ./grafana/dashboards:/var/lib/grafana/dashboards\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n\n\n\nthen i was facing below error \n\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [172.27.0.2:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"172.27.0.2:8300\"],\"time\":\"2024-11-23T16:01:56Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"172.27.0.2:8300\"],\"time\":\"2024-11-23T16:01:56Z\"}\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [172.27.0.2:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"172.27.0.2:8300\"],\"time\":\"2024-11-23T16:01:58Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"172.27.0.2:8300\"],\"time\":\"2024-11-23T16:01:58Z\"}\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [172.27.0.2:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"172.27.0.2:8300\"],\"time\":\"2024-11-23T16:02:00Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"172.27.0.2:8300\"],\"time\":\"2024-11-23T16:02:00Z\"}\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [172.27.0.2:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"172.27.0.2:8300\"],\"time\":\"2024-11-23T16:02:02Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"172.27.0.2:8300\"],\"time\":\"2024-11-23T16:02:02Z\"}\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [172.27.0.2:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"172.27.0.2:8300\"],\"time\":\"2024-11-23T16:02:03Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"172.27.0.2:8300\"],\"time\":\"2024-11-23T16:02:03Z\"}\n\nthanks in advance \n\n \n### Server Setup Information\n\n- Weaviate Server Version: \n- Deployment Method: <!-- docker/k8s/binary/embedded -->\n- Multi Node? Number of Running Nodes: \n- Client Language and Version:\n- Multitenancy?: \n\n### Any additional Information\n<!-- logs, additional setup information, anything extra you did in the setup or variables not included in any guide you followed -->\n\n----------\n\n[DudaNogueira (2024-11-26T20:31:08.046Z)]: hi @sravan_j_35 !!\nWelcome to our community \nCan you upgrade it to 1.26.latest? As I write, it would be 1.26.11\nTip: try to always use 1.26.latest, or 1.27.latest, etc. As this will make sure that all issues on that semver are patched.\nLet me know if this helps!",
    "date_created": "2024-11-23T16:02:34.593Z",
    "has_accepted_answer": false,
    "title": "{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [172.27.0.4:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"172.27.0.4:8300\"],\"time\":\"2024-11-23T14:54:05Z\",\"voter\":true} {\"action\":\"bootstrap\",\"le",
    "topic_id": 7813
  },
  {
    "user_id": 1650,
    "conversation": "[gmegh (2024-10-08T21:29:35.317Z)]: How can I specify OPENAI API KEY as envsecret?\n\n----------\n\n[DudaNogueira (2024-10-10T07:17:11.773Z)]: hi @gmegh !\nYou can define, as a env variable:\nOPENAI_APIKEY\nHere you can find the mention in our docs:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nText Embeddings | Weaviate\n\n  For Azure OpenAI integration docs, see this page instead.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!",
    "date_created": "2024-10-08T21:29:35.274Z",
    "has_accepted_answer": false,
    "title": "Specify OPENAI API KEY as envsecret",
    "topic_id": 4473
  },
  {
    "user_id": 497,
    "conversation": "[fredespi (2023-12-27T07:35:23.633Z)]: Hi! I want Weaviate to create my embeddings for me but I want to host the models myself and I want to specify a different transformers model per class. I think that would require a separate inference end point per class similarly to how the hugging face module can configure the endpointURL. Is it possible?\n\n----------\n\n[DudaNogueira (2024-01-05T21:10:40.570Z)]: Hi @fredespi !! Welcome to our community \nSorry for the delay here \nUnfortunately this is not possible \nI have brought this use case for our team, so we can think about how we can make this more flexible.\nBut for now, this is not possible. Sorry\n\n----------\n\n[bobvanluijt (2024-01-08T08:09:06.664Z)]: This is actually a very interesting use case. Do you have some more context @fredespi?\nMight be good for us to look into this use case.\n\n----------\n\n[DudaNogueira (2024-01-08T17:45:54.759Z)]: @bobvanluijt one possible solution I was thinking about and have brought to our team is if the text2vec-transformers passes the class name with the payload.\nThis would allow a custom inference container to use different models.\nAlso, to set the base url for the model per class, so each class could have a different inference model.\nWhat do you think?\n\n----------\n\n[fredespi (2024-02-14T10:42:47.355Z)]: Hi, sure. We serve customers in various markets and their data is in various languages. We want to host embeddings models ourselves in order to have full control over costs, language support, updates, etc. We want to be flexible when it comes to assigning models to collections of data. This is what we would like to do: when a customer wants to create a collection we pick a model that best fits their data. We create the collection in Weaviate and then index their data using the model. But then we we query the data we have to keep track of which embedding model we used originally for that collection. It would be convenient if that was baked into the collection so that the collection itself knows which embedding model/server to use.\n\n----------\n\n[pc10 (2024-11-07T15:45:10.782Z)]: Hi I am interested in a similar use-case. Following up on the thread to see if there is any update on this feature. We are interested to host multiple transformer containers so we can assign different embedders for different collections based on the the customer-use case.\nThank you.\n\n----------\n\n[DudaNogueira (2024-11-08T11:02:58.135Z)]: hi @pc10 !!\nYou can now specify a different inference_url per collection, like so:\nfrom weaviate.classes.config import Configure\n\ncollection = client.collections.create(\n    \"DemoCollection2\",\n    vectorizer_config=[\n        Configure.NamedVectors.text2vec_transformers(\n            name=\"title_vector\",\n            source_properties=[\"title\"],\n            inference_url=\"https://webhook.site/ec8436b5-4a54-4705-b8e0-95f50b81b9f6\"\n        )\n    ],\n    # Additional parameters not shown\n)",
    "date_created": "2023-12-27T07:35:23.588Z",
    "has_accepted_answer": false,
    "title": "Separate transformers inference APIs per class",
    "topic_id": 1146
  },
  {
    "user_id": 3245,
    "conversation": "[clpurcell (2025-01-21T20:06:47.696Z)]: Description\n\nWhen I add a property to an existing class skip_vectorization is not being propagated to the _PropertyVectorizerConfig making it impossible to add a property with skip_vectorization=True. It seems only to happen if generative_config is not null. If generative_config is null, this bug doesn’t happen.\nServer Setup Information\n\nWeaviate Server Version:  Docker Image 1.28.2\nDeployment Method: Docker\nMulti Node? Number of Running Nodes: No\nClient Language and Version: Python 3.12\nMultitenancy?: No\n\nAny additional Information\nCode:\nclient = weaviate.connect_to_local(host=‘127.0.0.1’,port=8080,grpc_port=50051)\ntry:\nclient.collections.delete(‘Test’)\nexcept:\npass\nclient.collections.create(\n“Test”,\nvectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\napi_endpoint=“http://localhost:11434”,\nmodel=“snowflake-arctic-embed2:568m”\n),\ngenerative_config=Configure.Generative.ollama(\napi_endpoint=“http://localhost:11434”,  # If using Docker, use this to contact your local Ollama instance\nmodel=“dolphin3:8b-llama3.1-q4_K_M”  # The model to use, e.g. “phi3”, or “mistral”, “command-r-plus”, “gemma”\n),\nproperties=[\nProperty(name=“property_made_during_class_creation”,data_type=DataType.BOOL,vectorize_property_name=False,skip_vectorization=True),\n]\n\n)\ntestCollection = client.collections.get(‘Test’)\ntestCollection.config.add_property(Property(name=“property_made_after_class_creation”,data_type=DataType.BOOL,vectorize_property_name=False,skip_vectorization=True))\ntestCollection.config.get().properties\nOutput:\n[_Property(name=‘property_made_during_class_creation’, description=None, data_type=<DataType.BOOL: ‘boolean’>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=_PropertyVectorizerConfig(skip=True, vectorize_property_name=False), vectorizer=‘text2vec-ollama’),\n_Property(name=‘property_made_after_class_creation’, description=None, data_type=<DataType.BOOL: ‘boolean’>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer=‘text2vec-ollama’)]\nExpected Behavior:\nBoth properties would have _PropertyVectorizerConfig.skip = True\nDeployment Config:\nservices:\nweaviate:\ncommand:\n- --host\n- 0.0.0.0\n- --port\n- ‘8080’\n- --scheme\n- http\nimage: cr.weaviate.io/semitechnologies/weaviate:1.28.2\nnetwork_mode: ‘host’\nvolumes:\n- /Volume:/var/lib/weaviate\nrestart: on-failure:0\nenvironment:\nQUERY_DEFAULTS_LIMIT: 25\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: ‘true’\nPERSISTENCE_DATA_PATH: ‘/var/lib/weaviate’\nENABLE_API_BASED_MODULES: ‘true’\nCLUSTER_HOSTNAME: ‘node1’\nENABLE_MODULES: ‘text2vec-ollama,generative-ollama’\nOLLAMA_API_BASE_URL: ‘http://127.0.0.1:11434/api’\n~\n\n----------\n\n[Mohamed_Shahin (2025-01-22T13:30:35.682Z)]: Hello @clpurcell,\nI’ve tried to replicate the behavior you described using the Python Client: 4.10.4, and I observed that my property reflects with skip=True as expected.\nAt this point, I’m not certain if this is a bug, but it’s important to verify this on the latest client version rather than on a deprecated one. Is there a specific reason you’re not using Client V4?\nIt’s possible that my replication setup isn’t exactly like yours—I’ve configured my vectorizer and generative model in a collection, then created properties, and later added a property with skip vectorization, and it all reflected fine.\nCould you please retry your tests using latest client version, and if the issue persists, could you send me your script code for further debugging? The reason I recommend this is that if a bug is present in V3, which is deprecated, the likely recommendation would be to upgrade to V4. This way, we can determine if the issue is client-related or server-related.\nBest regards,\nMohamed Shahin\nWeaviate Support\n\n----------\n\n[clpurcell (2025-02-03T21:30:14.221Z)]: clpurcell:\n\n\nClient Language and Version: Python 3.12\n\n\n\nHi Mohamed,\nSorry for the confusion, 3.12 was in reference to my Python version, not my weaviate client version. My weaviate client is version 4.10.2, so I am indeed using V4.\nI just reran the code and had the same error. Is there anything else I can send you to help reproduce this?\nBest regards,\nCollin",
    "date_created": "2025-01-21T20:06:47.639Z",
    "has_accepted_answer": false,
    "title": "Skip Vectorization Not Applying To Added Properties When Generative Config Is Not Null",
    "topic_id": 9843
  },
  {
    "user_id": 1196,
    "conversation": "[maiduchuy321 (2024-07-12T21:46:44.258Z)]: Hello\nI’m new to Verba\nI deploy verba on Docker\nEverything works perfectly.\nBut now I have a question?. How to add external data into Verba.\nI use LLamaIndex and use Semantic chunking to split the document. The problem I want to ask is how to put these chunks into Verba and I want each chunk to be considered a document for querying.\nI used Weaviate on LlamaIndex to create a collection named “VERBA_Document_…” or “VERBA_Chunk_…” . However, this does not help me retrival these chunks.\nIs there any solution to the problem I’m having??\nHelp me please. Thanks\n\n----------\n\n[DudaNogueira (2024-07-31T20:53:52.673Z)]: hi @maiduchuy321 !!\nReally sorry, missed this message \nThe best way to ingest data into Verba is using its own UI.\nThere are some improvements coming to Verba v2 (under development) that will help bulk imports.\nSo I believe it is best to check this new version. Also feel free to test and suggest improvements \nThanks!",
    "date_created": "2024-07-12T21:46:44.206Z",
    "has_accepted_answer": false,
    "title": "Import custom data in Verba",
    "topic_id": 3035
  },
  {
    "user_id": 1478,
    "conversation": "[gfwgfw (2024-11-22T13:54:41.579Z)]: How to reproduce this bug?\nquery Get {\n    Get {\n        NewspaperArticle_V2(\n            limit: 10000\n            nearVector: {\n                vector: [... ]\n            }\n            where: {\n                operator: Or\n                operands: [{ path: [\"content\"], operator: ContainsAll, valueText: [\"黄海峰\",\"刘捷\"] }]\n            }\n        ) {\n            title\n            articleId\n            content\n        }\n    }\n}\n\nIn the some case, when the GSE.CutAll will not generate correctly tokens from input the Chinese text.\nFor example:\nsource: “本报讯（首席记者 赵芳洲）平安杭州建设20周年大会昨日下午召开。省委副书记、市委书记刘捷”\nresult in\nGSE.CutAll: [本报 本报讯 （ 首席 首席记者 记者 赵 芳 洲 ） 平安 杭州 建设 2 0 周年 大会 昨日 下午 召开 。 省委 副 书记 、 市委 市委书记 书记 刘 捷]\n// use DAG and HMM GSE.Cut(text, true): [本报讯 （ 首席记者 赵芳洲 ） 平安 杭州 建设 20 周年 大会 昨日 下午 召开 。 省委 副 书记 、 市委书记 刘捷]\n//cut search use hmm: GSE.CutSearch(text, true): [本报 本报讯 （ 首席 记者 首席记者 赵芳洲 ） 平安 杭州 建设 20 周年 大会 昨日 下午 召开 。 省委 副 书记 、 市委 书记 市委书记 刘捷]\nSome Chinese person name and others has wrong tokenized: ‘刘 捷’ should be ‘刘捷’, ‘赵 芳 洲’ should be ‘赵芳洲’, ‘2 0’ should be ‘20’ (there is a unnecessary space between the two chars)\nEven in go-ego/gse 's example can see the difference,\n  \n\n      github.com\n  \n\n  \n    go-ego/gse/blob/627fa87efa481d4f734d6e06798363a4e1dde1d8/examples/main.go#L99C3-L99C4\n\n\n\n    \n      \n          \t// cut all:  [《复仇者联盟3：无限战争》 复仇 复仇者 仇者 联盟 3 ： 无限 战争 》 是 全片 使用 i m a x 摄影 摄影机 拍摄 摄制 制作 的 的 科幻 科幻片 .]\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n‘imax’ is tokenized ‘i m a x’ in CutAll method, that’s not correct.\nWhat is the expected behavior?\nuse DAG and HMM GSE.Cut(text, true) or cut search use hmm: GSE.CutSearch(text, true) to generate tokens\nWhat is the actual behavior?\nwrong tokens generate by GSE.CutAll method\nSupporting information\nNo response\nServer Version\n1.27.0\nWeaviate Setup\nSingle Node",
    "date_created": "2024-11-22T13:54:41.525Z",
    "has_accepted_answer": false,
    "title": "GSE.CutAll not work well for some Chinese text",
    "topic_id": 7789
  },
  {
    "user_id": 869,
    "conversation": "[peguerosdc (2024-08-29T06:14:07.143Z)]: Hi!\nI am trying to test my weaviate flows using github actions and I’m having trouble starting the weaviate server. I am using the following action.yaml file based on the docker-compose.yaml file in the docs:\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [\"3.11\"]\n    services:\n      weaviate:\n        image: cr.weaviate.io/semitechnologies/weaviate:1.26.1\n        env:\n          QUERY_DEFAULTS_LIMIT: 25\n          AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n          PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n          DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'\n          ENABLE_MODULES: 'text2vec-openai'\n          CLUSTER_HOSTNAME: 'node1'\n        ports:\n          - 8080:8080\n        options: >-\n          --health-cmd \"curl --request GET --url http://localhost:8080/v1/ || exit 1 || exit 1\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\nBut even though I’m able to see weaviate logs in the action logs, the health command times out.\nHere are the full logs:\n\n\nSummary\n2024-08-29T05:50:36.1165582Z Current runner version: '2.319.1'\n2024-08-29T05:50:36.1188282Z ##[group]Operating System\n2024-08-29T05:50:36.1188917Z Ubuntu\n2024-08-29T05:50:36.1189390Z 22.04.4\n2024-08-29T05:50:36.1189681Z LTS\n2024-08-29T05:50:36.1190007Z ##[endgroup]\n2024-08-29T05:50:36.1190463Z ##[group]Runner Image\n2024-08-29T05:50:36.1190859Z Image: ubuntu-22.04\n2024-08-29T05:50:36.1191282Z Version: 20240825.1.0\n2024-08-29T05:50:36.1192352Z Included Software: https://github.com/actions/runner-images/blob/ubuntu22/20240825.1/images/ubuntu/Ubuntu2204-Readme.md\n2024-08-29T05:50:36.1193773Z Image Release: https://github.com/actions/runner-images/releases/tag/ubuntu22%2F20240825.1\n2024-08-29T05:50:36.1194659Z ##[endgroup]\n2024-08-29T05:50:36.1195131Z ##[group]Runner Image Provisioner\n2024-08-29T05:50:36.1195586Z 2.0.384.1\n2024-08-29T05:50:36.1195937Z ##[endgroup]\n2024-08-29T05:50:36.1210542Z ##[group]GITHUB_TOKEN Permissions\n2024-08-29T05:50:36.1212234Z Contents: read\n2024-08-29T05:50:36.1212682Z Metadata: read\n2024-08-29T05:50:36.1213198Z Packages: read\n2024-08-29T05:50:36.1213756Z ##[endgroup]\n2024-08-29T05:50:36.1216675Z Secret source: Actions\n2024-08-29T05:50:36.1217360Z Prepare workflow directory\n2024-08-29T05:50:36.2113503Z Prepare all required actions\n2024-08-29T05:50:36.2270076Z Getting action download info\n2024-08-29T05:50:36.4186244Z Download action repository 'actions/checkout@v3' (SHA:f43a0e5ff2bd294095638e18286ca9a3d1956744)\n2024-08-29T05:50:36.5144524Z Download action repository 'actions/setup-python@v3' (SHA:3542bca2639a428e1796aaa6a2ffef0c0f575566)\n2024-08-29T05:50:36.5948105Z Download action repository 'actions/upload-artifact@v3' (SHA:a8a3f3ad30e3422c9c7b888a15615d19a852ae32)\n2024-08-29T05:50:36.7702724Z Complete job name: build (3.11)\n2024-08-29T05:50:36.8282281Z ##[group]Checking docker version\n2024-08-29T05:50:36.8296617Z ##[command]/usr/bin/docker version --format '{{.Server.APIVersion}}'\n2024-08-29T05:50:36.8847308Z '1.45'\n2024-08-29T05:50:36.8885650Z Docker daemon API version: '1.45'\n2024-08-29T05:50:36.8886937Z ##[command]/usr/bin/docker version --format '{{.Client.APIVersion}}'\n2024-08-29T05:50:36.9049229Z '1.45'\n2024-08-29T05:50:36.9062579Z Docker client API version: '1.45'\n2024-08-29T05:50:36.9067743Z ##[endgroup]\n2024-08-29T05:50:36.9070978Z ##[group]Clean up resources from previous jobs\n2024-08-29T05:50:36.9076938Z ##[command]/usr/bin/docker ps --all --quiet --no-trunc --filter \"label=c9bac7\"\n2024-08-29T05:50:36.9226170Z ##[command]/usr/bin/docker network prune --force --filter \"label=c9bac7\"\n2024-08-29T05:50:36.9354940Z ##[endgroup]\n2024-08-29T05:50:36.9355453Z ##[group]Create local container network\n2024-08-29T05:50:36.9366171Z ##[command]/usr/bin/docker network create --label c9bac7 github_network_53f3d15128bb4222b79e014618e62d45\n2024-08-29T05:50:37.0065716Z c20769e4fc16559c0d2b18ad0c4ac0936f7c4ee5a0dcb25df1f2f620992040f5\n2024-08-29T05:50:37.0084879Z ##[endgroup]\n2024-08-29T05:50:37.0161484Z ##[group]Starting weaviate service container\n2024-08-29T05:50:37.0210636Z ##[command]/usr/bin/docker pull cr.weaviate.io/semitechnologies/weaviate:1.26.1\n2024-08-29T05:50:38.2632498Z 1.26.1: Pulling from semitechnologies/weaviate\n2024-08-29T05:50:38.6226670Z c6a83fedfae6: Already exists\n2024-08-29T05:50:38.6236297Z 1b38ab12ecb2: Pulling fs layer\n2024-08-29T05:50:38.6238557Z 132c4bf96a52: Pulling fs layer\n2024-08-29T05:50:38.6240257Z 0eb39e2e2a5e: Pulling fs layer\n2024-08-29T05:50:38.6246150Z 9efb6211700a: Pulling fs layer\n2024-08-29T05:50:38.6247094Z 3f7fbcd922fe: Pulling fs layer\n2024-08-29T05:50:38.6247930Z 345cef12759b: Pulling fs layer\n2024-08-29T05:50:38.6248845Z 9efb6211700a: Waiting\n2024-08-29T05:50:38.6249525Z 3f7fbcd922fe: Waiting\n2024-08-29T05:50:38.6250167Z 345cef12759b: Waiting\n2024-08-29T05:50:38.9660801Z 0eb39e2e2a5e: Verifying Checksum\n2024-08-29T05:50:38.9665949Z 0eb39e2e2a5e: Download complete\n2024-08-29T05:50:39.1484013Z 1b38ab12ecb2: Verifying Checksum\n2024-08-29T05:50:39.1485585Z 1b38ab12ecb2: Download complete\n2024-08-29T05:50:39.3134528Z 132c4bf96a52: Verifying Checksum\n2024-08-29T05:50:39.3140629Z 132c4bf96a52: Download complete\n2024-08-29T05:50:39.4746733Z 1b38ab12ecb2: Pull complete\n2024-08-29T05:50:39.5256989Z 9efb6211700a: Verifying Checksum\n2024-08-29T05:50:39.5260315Z 9efb6211700a: Download complete\n2024-08-29T05:50:39.6483197Z 3f7fbcd922fe: Verifying Checksum\n2024-08-29T05:50:39.6484889Z 3f7fbcd922fe: Download complete\n2024-08-29T05:50:39.6824520Z 345cef12759b: Verifying Checksum\n2024-08-29T05:50:39.6825714Z 345cef12759b: Download complete\n2024-08-29T05:50:40.2567027Z 132c4bf96a52: Pull complete\n2024-08-29T05:50:40.2765124Z 0eb39e2e2a5e: Pull complete\n2024-08-29T05:50:40.6291500Z 9efb6211700a: Pull complete\n2024-08-29T05:50:40.7352983Z 3f7fbcd922fe: Pull complete\n2024-08-29T05:50:40.7466497Z 345cef12759b: Pull complete\n2024-08-29T05:50:40.7523309Z Digest: sha256:987edeaf57b6fefe9b8bea0e62f848028f99a527100259e2760a1c9b57be6f4c\n2024-08-29T05:50:40.7592835Z Status: Downloaded newer image for cr.weaviate.io/semitechnologies/weaviate:1.26.1\n2024-08-29T05:50:40.7599412Z cr.weaviate.io/semitechnologies/weaviate:1.26.1\n2024-08-29T05:50:40.7707579Z ##[command]/usr/bin/docker create --name 70bf7ba7fa50490d83ba3b9b025bc359_crweaviateiosemitechnologiesweaviate1261_bb5cd5 --label c9bac7 --network github_network_53f3d15128bb4222b79e014618e62d45 --network-alias weaviate -p 8080:8080 --health-cmd \"curl -f http://localhost:8080/v1/.well-known/ready || exit 1\" --health-interval 10s --health-timeout 5s --health-retries 5 -e \"QUERY_DEFAULTS_LIMIT=25\" -e \"AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true\" -e \"PERSISTENCE_DATA_PATH=/var/lib/weaviate\" -e \"DEFAULT_VECTORIZER_MODULE=text2vec-openai\" -e \"ENABLE_MODULES=text2vec-openai\" -e \"CLUSTER_HOSTNAME=node1\" -e GITHUB_ACTIONS=true -e CI=true cr.weaviate.io/semitechnologies/weaviate:1.26.1\n2024-08-29T05:50:40.8133048Z c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:50:40.8158907Z ##[command]/usr/bin/docker start c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:50:41.1274133Z c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:50:41.1306414Z ##[command]/usr/bin/docker ps --all --filter id=c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9 --filter status=running --no-trunc --format \"{{.ID}} {{.Status}}\"\n2024-08-29T05:50:41.1460732Z c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9 Up Less than a second (health: starting)\n2024-08-29T05:50:41.1495560Z ##[command]/usr/bin/docker port c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:50:41.1701091Z 8080/tcp -> 0.0.0.0:8080\n2024-08-29T05:50:41.1702166Z 8080/tcp -> [::]:8080\n2024-08-29T05:50:41.1813029Z ##[endgroup]\n2024-08-29T05:50:41.1848664Z ##[group]Waiting for all services to be ready\n2024-08-29T05:50:41.1902692Z ##[command]/usr/bin/docker inspect --format=\"{{if .Config.Healthcheck}}{{print .State.Health.Status}}{{end}}\" c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:50:41.2093202Z starting\n2024-08-29T05:50:41.2127250Z weaviate service is starting, waiting 2 seconds before checking again.\n2024-08-29T05:50:43.2108069Z ##[command]/usr/bin/docker inspect --format=\"{{if .Config.Healthcheck}}{{print .State.Health.Status}}{{end}}\" c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:50:43.2267597Z starting\n2024-08-29T05:50:43.2281643Z weaviate service is starting, waiting 4 seconds before checking again.\n2024-08-29T05:50:47.3536289Z ##[command]/usr/bin/docker inspect --format=\"{{if .Config.Healthcheck}}{{print .State.Health.Status}}{{end}}\" c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:50:47.3666962Z starting\n2024-08-29T05:50:47.3682013Z weaviate service is starting, waiting 8 seconds before checking again.\n2024-08-29T05:50:56.1057165Z ##[command]/usr/bin/docker inspect --format=\"{{if .Config.Healthcheck}}{{print .State.Health.Status}}{{end}}\" c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:50:56.1194519Z starting\n2024-08-29T05:50:56.1210790Z weaviate service is starting, waiting 18 seconds before checking again.\n2024-08-29T05:51:14.3098885Z ##[command]/usr/bin/docker inspect --format=\"{{if .Config.Healthcheck}}{{print .State.Health.Status}}{{end}}\" c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:51:14.3232438Z starting\n2024-08-29T05:51:14.3247699Z weaviate service is starting, waiting 31 seconds before checking again.\n2024-08-29T05:51:45.9027651Z ##[command]/usr/bin/docker inspect --format=\"{{if .Config.Healthcheck}}{{print .State.Health.Status}}{{end}}\" c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:51:45.9179298Z unhealthy\n2024-08-29T05:51:45.9198290Z ##[endgroup]\n2024-08-29T05:51:45.9198660Z ##[group]Service container weaviate failed.\n2024-08-29T05:51:45.9204408Z ##[command]/usr/bin/docker logs --details c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:51:45.9344819Z  {\"action\":\"startup\",\"default_vectorizer_module\":\"text2vec-openai\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"text2vec-openai\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9361516Z  {\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9365017Z  {\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9370607Z  {\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9373273Z  {\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9375595Z  {\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"node1\":8300},\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9376946Z  {\"address\":\"172.18.0.2:8301\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9377731Z  {\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9378714Z  {\"address\":\"172.18.0.2:8300\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9379591Z  {\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9380260Z  {\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9380996Z  {\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9381872Z  {\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"node1\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9382856Z  {\"action\":\"raft\",\"index\":0,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[]]\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9384196Z  {\"last_snapshot_index\":0,\"last_store_applied_index\":0,\"last_store_log_applied_index\":0,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":0,\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9385499Z  {\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-08-29T05:50:41Z\"}\n2024-08-29T05:51:45.9386924Z  {\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [172.18.0.2:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"172.18.0.2:8300\"],\"time\":\"2024-08-29T05:50:42Z\",\"voter\":true}\n2024-08-29T05:51:45.9388600Z  {\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"node1\",\"Address\":\"172.18.0.2:8300\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-08-29T05:50:42Z\"}\n2024-08-29T05:51:45.9389860Z  {\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"172.18.0.2:8300\"],\"time\":\"2024-08-29T05:50:42Z\"}\n2024-08-29T05:51:45.9391342Z  {\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-08-29T05:50:42Z\"}\n2024-08-29T05:51:45.9392505Z  {\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":2,\"time\":\"2024-08-29T05:50:42Z\"}\n2024-08-29T05:51:45.9393413Z  {\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":2,\"time\":\"2024-08-29T05:50:42Z\"}\n2024-08-29T05:51:45.9394282Z  {\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-08-29T05:50:42Z\"}\n2024-08-29T05:51:45.9395303Z  {\"docker_image_tag\":\"1.26.1\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-08-29T05:50:43Z\"}\n2024-08-29T05:51:45.9396237Z  {\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-08-29T05:50:43Z\"}\n2024-08-29T05:51:45.9397105Z  {\"address\":\"172.18.0.2:8300\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-08-29T05:50:43Z\"}\n2024-08-29T05:51:45.9397948Z  {\"level\":\"info\",\"msg\":\"starting migration from old schema\",\"time\":\"2024-08-29T05:50:43Z\"}\n2024-08-29T05:51:45.9398710Z  {\"level\":\"info\",\"msg\":\"legacy schema is empty, nothing to migrate\",\"time\":\"2024-08-29T05:50:43Z\"}\n2024-08-29T05:51:45.9399730Z  {\"level\":\"info\",\"msg\":\"migration from the old schema has been successfully completed\",\"time\":\"2024-08-29T05:50:43Z\"}\n2024-08-29T05:51:45.9400907Z  {\"action\":\"restapi_management\",\"docker_image_tag\":\"1.26.1\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2024-08-29T05:50:43Z\"}\n2024-08-29T05:51:45.9402605Z  {\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:4b0f3da8-92f2-44c1-8575-515b11f04507 Type:INIT Version:1.26.1 NumObjects:0 OS:linux Arch:amd64 UsedModules:[]}\",\"time\":\"2024-08-29T05:50:43Z\"}\n2024-08-29T05:51:45.9404836Z  {\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-08-29T05:50:43Z\"}\n2024-08-29T05:51:45.9417023Z ##[error]Failed to initialize container cr.weaviate.io/semitechnologies/weaviate:1.26.1\n2024-08-29T05:51:45.9424345Z ##[endgroup]\n2024-08-29T05:51:45.9511677Z ##[error]One or more containers failed to start.\n2024-08-29T05:51:45.9856946Z ##[group]Run actions/upload-artifact@v3\n2024-08-29T05:51:45.9857459Z with:\n2024-08-29T05:51:45.9857898Z   name: pytest-results-3.11\n2024-08-29T05:51:45.9858287Z   path: server/junit/test-results-3.11.xml\n2024-08-29T05:51:45.9858756Z   if-no-files-found: warn\n2024-08-29T05:51:45.9859175Z env:\n2024-08-29T05:51:45.9859448Z   WEAVIATE_HOST: localhost\n2024-08-29T05:51:45.9859831Z   WEAVIATE_API_KEY: dummy\n2024-08-29T05:51:45.9860299Z   WEAVIATE_COLLECTION_NAME: therapists\n2024-08-29T05:51:45.9860682Z   OPENAI_API_KEY: dummy\n2024-08-29T05:51:45.9861044Z ##[endgroup]\n2024-08-29T05:51:46.1199811Z ##[warning]No files were found with the provided path: server/junit/test-results-3.11.xml. No artifacts will be uploaded.\n2024-08-29T05:51:46.1370448Z Stop and remove container: 70bf7ba7fa50490d83ba3b9b025bc359_crweaviateiosemitechnologiesweaviate1261_bb5cd5\n2024-08-29T05:51:46.1375760Z ##[command]/usr/bin/docker rm --force c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:51:46.3320586Z c8457c49e47654330f35237142bb4f39a5b65e3ac64b45c76b41db380092f4d9\n2024-08-29T05:51:46.3354006Z Remove container network: github_network_53f3d15128bb4222b79e014618e62d45\n2024-08-29T05:51:46.3359122Z ##[command]/usr/bin/docker network rm github_network_53f3d15128bb4222b79e014618e62d45\n2024-08-29T05:51:46.5418396Z github_network_53f3d15128bb4222b79e014618e62d45\n2024-08-29T05:51:46.5584804Z Cleaning up orphan processes\n\n\nNote: I have also tried testing with embedded weaviate, but I didn’t find it reliable enough (probably because it is experimental).\n\n----------\n\n[DudaNogueira (2024-08-29T19:16:11.779Z)]: peguerosdc:\n\ncurl --request GET --url http://localhost:8080/v1/\n\n\nhi @peguerosdc !!\nIf this command is running inside that weaviate container, note that curl is not included by default in weaviate.\ncan you try changing it to:\nwget --no-verbose --tries=1 --spider http://localhost:8080/v1/.well-known/ready || exit 1\n\nWeaviate seems to be running fine, considering your logs:\n\n2024-08-29T05:51:45.9400907Z  {“action”:“restapi_management”,“docker_image_tag”:“1.26.1”,“level”:“info”,“msg”:“Serving weaviate at http://[::]:8080”,“time”:“2024-08-29T05:50:43Z”}\n\nCheck how we run those for our python client.\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate-python-client/blob/main/.github/workflows/main.yaml\n\n\n      name: Main\n\non:\n  push:\n    branches:\n      - main\n    tags:\n      - '**'\n    paths-ignore:\n      - docs/**\n      - README.rst\n      - LICENSE.md\n      - publishing.md\n  pull_request:\n\nenv:\n  WEAVIATE_123: 1.23.16\n  WEAVIATE_124: 1.24.21\n  WEAVIATE_125: 1.25.8\n  WEAVIATE_126: preview-increase-version-number-8b44fe6\n\n\n\n\n  This file has been truncated. show original\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\n\n----------\n\n[peguerosdc (2024-08-29T22:48:51.861Z)]: That did the trick, thank you!",
    "date_created": "2024-08-29T06:14:06.978Z",
    "has_accepted_answer": true,
    "title": "How to run weaviate in a github action?",
    "topic_id": 3891
  },
  {
    "user_id": 1509,
    "conversation": "[matt (2025-02-03T18:55:43.884Z)]: Hi, I am considering deploying a Weaviate database on a server in my data centre. I am curious to find out if anyone has done it before. If so, how is it possible? How to secure it. How to access it from the public internet ( application hosted outside). What are the key considerations? Thanks a lot!\n\n----------\n\n[DudaNogueira (2025-02-03T19:38:29.001Z)]: hi @matt !!\nIf you are using docker, you can install, secure and expose it using for example traefik.\nCheck this answer on how to do it:\n  \n    \n    \n    Weaviate with Traefik and gRPC Support\n  \n  \n    Hi @qnlbnsl ! Sorry for the delay here. \nLooks like I was finally able to tame this \nHere is what I got: \nNOTE: Check this updated gist on how to correctly expose Weaviate under SSL/TLS using Traefik and running everything with a docker compose \n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:1.23.5\n    #ports:\n    # - 8081:8080 # unsafe http\n    # - 50052:50051 # unsafe grpc…\n  \n\n\nBottom line is that you will need to expose both http and grpc ports, and depending on how you have exposed it, you change the client initialization accordingly using the custom connection:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCustom connections | Weaviate\n\n  The Python Client v4 and the TypeScript Client v3 provide helper methods for common connection types. They also provide custom methods for when you need additional connection configuration.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[matt (2025-02-04T05:02:37.366Z)]: I am basically looking for the most safest, secure way of deploying it ( obviously there is a network component involved). Docker can be an option - is it just running docker deamon tool on the server or anything else could be considered?\nAlso, how it is the backup option available whilst dockerising the weaviate database?\n\n----------\n\n[DudaNogueira (2025-02-04T15:26:47.712Z)]: Hi!\nDocker will work fine for a single node cluster.\nIf you want to run a multi node cluster, then we suggest Kubernetes:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nKubernetes | Weaviate\n\n  For a tutorial on how to use minikube to deploy Weaviate on Kubernetes, see the Weaviate Academy course, Weaviate on Kubernetes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nFor backups, sor single node, you can use the filesystem module, or for all kinds of cluster (single or multi node) you can use a remote one, like S3 ou GCP buckets for example.\nLet me know if this helps!\nThanks!",
    "date_created": "2025-02-03T18:55:43.837Z",
    "has_accepted_answer": false,
    "title": "Deploy on local server",
    "topic_id": 10008
  },
  {
    "user_id": 713,
    "conversation": "[Sridhar_Iyer (2024-08-20T18:14:35.508Z)]: Description\nExisting vector collection based on google vertex multi2vec_palm embeddings.\nCollection created and working fine. (with following configuration)\nvectorizer_config=Configure.Vectorizer.multi2vec_palm(\nimage_fields=[“image”],\ntext_fields=[“image_description”, “summary_description”, “problem_description”],\nproject_id = “XXXXX”,\nlocation = “us-central1”,\nmodel_id = “multimodalembedding@001”,\ndimensions = 1408,\n)\nNeed to change the project id. Do I need to create the embeddings for the collection with the new project id or can I change the project id. (this is usually configured during collection creation).\nQUESTION: Once a (vector) collection is created with a particular google cloud project_id, can the project_Id be changed without recreating the entire collection?\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method:  docker on AWS (self-hosted)\nMulti Node? 1\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[Mohamed_Shahin (2024-08-21T09:33:24.725Z)]: Hi @Sridhar_Iyer,\nI hope you’re having an awesome week!\nIf I understood you correctly, you would like to change the project_id property by renaming it to something else or deleting it, right?\nIn such cases, you would need to recreate the collection, similar to the concept of mutable vs. immutable parameters\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCollection schema | Weaviate - Vector Database\n\n  Introduction\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI also want to add something that might be useful to know: If you add a new property to your collection definition, Weaviate only vectorizes the new objects. It doesn’t re-vectorize and re-index existing objects when a new property is defined.\n\nQUESTION: Once a (vector) collection is created with a particular Google Cloud project_id, can the project_id be changed without recreating the entire collection?\n\nIf the changes updating values within the objects, that’s fine. But if you need to change the entire property in terms of its configuration, name, etc., you will need to delete the collection and recreate it except description parameter as it’s mutable.\nDoes that make sense? Let me know if you have any further questions!",
    "date_created": "2024-08-20T18:14:35.455Z",
    "has_accepted_answer": false,
    "title": "Changing vertex project_id in embeddings configuration",
    "topic_id": 3408
  },
  {
    "user_id": 1516,
    "conversation": "[Kugelhaufen (2024-09-10T14:44:12.313Z)]: Description\nI tried to use Verba v1.0.3 and v2.0.0 with Docker on Windows.\nI followed the instructions from GitHub\nBoth v1.0.3 and v.2.0.0 always produce an error. Verba v1.0.0 works fine.\nThis is the content of my .env file that i copy into the goldenverba dir:\nOLLAMA_URL=http://localhost:11434\nOLLAMA_MODEL=llama3\nOLLAMA_EMBED_MODEL=nomic-embed-text:latest\n\nDocker compose always successfully executes and creates the containers.\nVerba v1.0.3 always produces the following error:\n2024-09-10 15:56:16 INFO:     Will watch for changes in these directories: ['/Verba']\n2024-09-10 15:56:16 INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n2024-09-10 15:56:16 INFO:     Started reloader process [1] using WatchFiles\n2024-09-10 15:56:17 /usr/local/lib/python3.11/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n2024-09-10 15:56:17   from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n2024-09-10 15:56:17 Process SpawnProcess-1:\n2024-09-10 15:56:17 Traceback (most recent call last):\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n2024-09-10 15:56:17     self.run()\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/multiprocessing/process.py\", line 108, in run\n2024-09-10 15:56:17     self._target(*self._args, **self._kwargs)\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/site-packages/uvicorn/_subprocess.py\", line 78, in subprocess_started\n2024-09-10 15:56:17     target(sockets=sockets)\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/site-packages/uvicorn/server.py\", line 65, in run\n2024-09-10 15:56:17     return asyncio.run(self.serve(sockets=sockets))\n2024-09-10 15:56:17            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/asyncio/runners.py\", line 190, in run\n2024-09-10 15:56:17     return runner.run(main)\n2024-09-10 15:56:17            ^^^^^^^^^^^^^^^^\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/asyncio/runners.py\", line 118, in run\n2024-09-10 15:56:17     return self._loop.run_until_complete(task)\n2024-09-10 15:56:17            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2024-09-10 15:56:17   File \"uvloop/loop.pyx\", line 1517, in uvloop.loop.Loop.run_until_complete\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/site-packages/uvicorn/server.py\", line 69, in serve\n2024-09-10 15:56:17     await self._serve(sockets)\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/site-packages/uvicorn/server.py\", line 76, in _serve\n2024-09-10 15:56:17     config.load()\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/site-packages/uvicorn/config.py\", line 433, in load\n2024-09-10 15:56:17     self.loaded_app = import_from_string(self.app)\n2024-09-10 15:56:17                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/site-packages/uvicorn/importer.py\", line 22, in import_from_string\n2024-09-10 15:56:17     raise exc from None\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/site-packages/uvicorn/importer.py\", line 19, in import_from_string\n2024-09-10 15:56:17     module = importlib.import_module(module_str)\n2024-09-10 15:56:17              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2024-09-10 15:56:17   File \"/usr/local/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n2024-09-10 15:56:17     return _bootstrap._gcd_import(name[level:], package, level)\n2024-09-10 15:56:17            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2024-09-10 15:56:17   File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n2024-09-10 15:56:17   File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n2024-09-10 15:56:17   File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n2024-09-10 15:56:17   File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n2024-09-10 15:56:17   File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n2024-09-10 15:56:17   File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n2024-09-10 15:56:17   File \"/Verba/goldenverba/server/api.py\", line 14, in <module>\n2024-09-10 15:56:17     from goldenverba import verba_manager\n2024-09-10 15:56:17   File \"/Verba/goldenverba/verba_manager.py\", line 23, in <module>\n2024-09-10 15:56:17     from goldenverba.components.managers import (\n2024-09-10 15:56:17   File \"/Verba/goldenverba/components/managers.py\", line 17, in <module>\n2024-09-10 15:56:17     from goldenverba.components.reader.GitLabReader import GitLabReader\n2024-09-10 15:56:17 ModuleNotFoundError: No module named 'goldenverba.components.reader.GitLabReader'\n2024-09-10 15:56:17 sys:1: ResourceWarning: unclosed file <_io.TextIOWrapper name=0 mode='r' encoding='UTF-8'>\n\n\nVerba v2.0.0 always produces this error:\n2024-09-10 16:11:43 /usr/local/lib/python3.11/site-packages/google/protobuf/runtime_version.py:112: UserWarning: Protobuf gencode version 5.27.2 is older than the runtime version 5.28.0 at grpc_health/v1/health.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n2024-09-10 16:11:43   warnings.warn(\n2024-09-10 16:11:49 Traceback (most recent call last):\n2024-09-10 16:11:49   File \"/usr/local/bin/verba\", line 33, in <module>\n2024-09-10 16:11:49     sys.exit(load_entry_point('goldenverba', 'console_scripts', 'verba')())\n2024-09-10 16:11:49              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2024-09-10 16:11:49   File \"/usr/local/bin/verba\", line 25, in importlib_load_entry_point\n2024-09-10 16:11:49     return next(matches).load()\n2024-09-10 16:11:49            ^^^^^^^^^^^^^^^^^^^^\n2024-09-10 16:11:49   File \"/usr/local/lib/python3.11/importlib/metadata/__init__.py\", line 202, in load\n2024-09-10 16:11:49     module = import_module(match.group('module'))\n2024-09-10 16:11:49              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2024-09-10 16:11:49   File \"/usr/local/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n2024-09-10 16:11:49     return _bootstrap._gcd_import(name[level:], package, level)\n2024-09-10 16:11:49            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2024-09-10 16:11:49   File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n2024-09-10 16:11:49   File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n2024-09-10 16:11:49   File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n2024-09-10 16:11:49   File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n2024-09-10 16:11:49   File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n2024-09-10 16:11:49   File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n2024-09-10 16:11:49   File \"/Verba/goldenverba/server/cli.py\", line 6, in <module>\n2024-09-10 16:11:49     from goldenverba import verba_manager\n2024-09-10 16:11:49   File \"/Verba/goldenverba/verba_manager.py\", line 24, in <module>\n2024-09-10 16:11:49     from goldenverba.components.managers import (\n2024-09-10 16:11:49   File \"/Verba/goldenverba/components/managers.py\", line 98, in <module>\n2024-09-10 16:11:49     CohereEmbedder(),\n2024-09-10 16:11:49     ^^^^^^^^^^^^^^^^\n2024-09-10 16:11:49   File \"/Verba/goldenverba/components/embedding/CohereEmbedder.py\", line 27, in __init__\n2024-09-10 16:11:49     value=models[0],\n2024-09-10 16:11:49           ~~~~~~^^^\n2024-09-10 16:11:49 TypeError: 'NoneType' object is not subscriptable\n\n----------\n\n[DudaNogueira (2024-09-10T19:04:33.567Z)]: hi @Kugelhaufen !!\nWelcome to our community \nFor version v2 it looks like there are no models configured/available.\nare those env vars the same one you are using on Verba 2.0?\n\n----------\n\n[Kugelhaufen (2024-09-10T20:27:24.982Z)]: I tried everything with different .env files, including a completely empty one or no .env file at all. I always get the same error on both versions. I don’t think it has to do with the .env file.\n\n----------\n\n[DudaNogueira (2024-09-11T12:47:09.972Z)]: Can you define this env variables with a working cohere api key?\nCOHERE_API_KEY\nFor some reason, your deployment is trying to get cohere models, and is failing.\n\n----------\n\n[Kugelhaufen (2024-09-12T12:57:00.823Z)]: Ok Verba v2 worked after defining a cohere and an OpenAI API key.\nBut as far as I know it is supposed to work without these keys in the .env file as well, right?\n\n----------\n\n[DudaNogueira (2024-09-12T13:26:05.578Z)]: definitely.\nI am not sure why the Cohere embedded kick in.\nMaybe some env vars are set.\nThere are more changes coming to Verba that will improve this deployment part.\nThanks!\n\n----------\n\n[doc97040 (2024-10-06T09:44:12.392Z)]: Hello ,\nI am running ollama on wsl2 and weaviate&Verba on docker.\nI had the same error.  i solved it by using the ununtu/wsl2 ip\nOLLAMA_URL was the issue\nVerba:\nimage: verba-verba\nports:\n- 8000:8000\nenvironment:\nWEAVIATE_URL_VERBA:\nOLLAMA_URL: ‘http://112.28.24.23:11434’  # Depending on your Docker environment   (localhost or internal)\nvolumes:\n- ./data:/data/\nvolumes:\nweaviate_data:\n\n----------\n\n[DudaNogueira (2024-10-07T09:24:47.294Z)]: hi @doc97040 !!\nWelcome to our community and thanks for sharing!\nwhile using docker, it’s best to use http://host.docker.internal:11434 instead of a fixed ip as it may change.\nhost.docker.internal will always point to your host, where ollama should be running locally.\nIndeed, ubuntu/wsl2 can make things hard, as there are some additional layers in between the components, when compared to linux or mac.",
    "date_created": "2024-09-10T14:44:12.258Z",
    "has_accepted_answer": true,
    "title": "Unable to deploy Verba v1.0.3 and v2.0.0 with Docker on Windows",
    "topic_id": 4092
  },
  {
    "user_id": 513,
    "conversation": "[rjalex (2024-08-06T17:20:15.246Z)]: Description\nI have a collection which is declared as follows:\nwv_client.collections.create(\n    name=wv_artcollname,\n    description=\"A collection of Articles with only a custom list of stopwords\",\n    vectorizer_config=None,\n    inverted_index_config=wvcc.Configure.inverted_index(**BM25_PARAMS),\n    properties=[\n        wvcc.Property(\n            name=\"kg_article_id\",\n            data_type=wvcc.DataType.TEXT,\n            skip_vectorization=True,\n            tokenization=wvcc.Tokenization.FIELD,\n        ),  # {GRAPH_BASE}/article/{isoEditionDate}-{slug}\n        wvcc.Property(\n            name=\"articletitle\",\n            data_type=wvcc.DataType.TEXT,\n            skip_vectorization=True,\n        ),  # as displayed on the page\n        wvcc.Property(\n            name=\"isoEditionDate\",\n            data_type=wvcc.DataType.DATE,  # DATE for RFC3339 ISO8601 date\n            skip_vectorization=True,\n        ),  # alternative, declare it as TEXT and tokenization=wvcc.Tokenization.FIELD,\n        wvcc.Property(\n            name=\"author\",\n            data_type=wvcc.DataType.TEXT,\n            skip_vectorization=True,\n        ),  # the author string as displayed on the page\n        wvcc.Property(\n            name=\"category\",\n            data_type=wvcc.DataType.TEXT,\n            skip_vectorization=True,\n            tokenization=wvcc.Tokenization.FIELD,\n        ),  # the category string\n        wvcc.Property(\n            name=\"prose\",\n            data_type=wvcc.DataType.TEXT,\n        ),  # title+excerpt+kicker\n        wvcc.Property(\n            name=\"keywords\",\n            data_type=wvcc.DataType.TEXT,\n            skip_vectorization=True,\n        ),  # category+tag+topic+namedentities\n    ],\n)\n\nand filled with around 650K objects along with custom embedings for the “prose” property. See at the bottom for the BM25 properties if needed.\nI am querying this collection with the following example: “attentato trump” and  use the same embedding model for the query.\nI then build an hybrid query as follows (but as I set alpha to 0 I should be doing a pure BM25 keyword search right?):\nresponse = wv_artcoll.query.hybrid(\n                query=\"attentato trump\",\n                query_properties=[\n                    \"keywords^1.3\",\n                    \"prose\"\n                ],\n                vector=query_vector, # this has the embedding\n                target_vector=graphql_model_name, # embedding name\n                limit=60,\n                alpha=0,\n                return_metadata=MetadataQuery(score=True, explain_score=True),\n            )\n\nfrom the above query I fetch 60 results from which I show you two results that matter to me. The LAST result from the 60 limit query above is as follows:\n        {\n            \"properties\": {\n                \"kg_article_id\": \"https://ilmanifesto.it/mema/article/2000-10-06-sri-lanka-attentato-pre-elettorale\",\n                \"articletitle\": \"Sri lanka,attentato pre elettorale\",\n                \"isoEditionDate\": \"2000-10-06\",\n                \"author\": \"Redazione\",\n                \"category\": \"Mondo\",\n                \"prose\": \"Sri lanka,attentato pre elettorale; Attentato kamikaze indipendentista; \",\n                \"keywords\": \"Redazione, Sri Lanka, Medawachchiya\"\n            },\n            \"score\": 0.24272824823856354,\n            \"explain_score\": \"\\nHybrid (Result Set keyword,bm25) Document cbd3bb20-4570-543c-9ac9-972ac559e480: original score 4.068611, normalized score: 0.24272825\"\n        }\n\nNow if I repeat the very same query with a limit raised from 60 to 200 I get the same object as above with the following different score and related explanation:\n        {\n            \"properties\": {\n                \"kg_article_id\": \"https://ilmanifesto.it/mema/article/2000-10-06-sri-lanka-attentato-pre-elettorale\",\n                \"articletitle\": \"Sri lanka,attentato pre elettorale\",\n                \"isoEditionDate\": \"2000-10-06\",\n                \"author\": \"Redazione\",\n                \"category\": \"Mondo\",\n                \"prose\": \"Sri lanka,attentato pre elettorale; Attentato kamikaze indipendentista; \",\n                \"keywords\": \"Redazione, Sri Lanka, Medawachchiya\"\n            },\n            \"score\": 0.46517714858055115,\n            \"explain_score\": \"\\nHybrid (Result Set keyword,bm25) Document cbd3bb20-4570-543c-9ac9-972ac559e480: original score 4.068611, normalized score: 0.46517715\"\n        },\n\nso the BM25 search with the input terms “attentato” and “trump” as I have performed are matching TWO instances of the string “attentato” in the “prose” property yielding that score. Right?\nWhat I’m not understanding is that in the limit=200 version of the search I also fetch the following object:\n            \"properties\": {\n                \"kg_article_id\": \"http://ilmanifesto.it/mema/article/2024-07-14-attentato-a-trump-spari-durante-un-comizio\",\n                \"articletitle\": \"Attentato a Trump: spari durante un comizio\",\n                \"isoEditionDate\": \"2024-07-14\",\n                \"author\": \"Marina Catucci\",\n                \"category\": \"Internazionale\",\n                \"prose\": \"Attentato a Trump: spari durante un comizio; Alle 18.20 ora locale il comizio di Donald Trump a Butler in Pennsylvania era cominciato da poco, quando sono esplosi gli spari. Quando il tycoon si è abbassato dietro il […]; L'ex presidente ferito a un orecchio. L'attentatore, un ventenne, è morto. Biden: «Non c'è posto in America per questo tipo di violenza»\",\n                \"keywords\": \"Marina Catucci; Thomas Matthew Crooks; Chuck Schumer; Nancy Pelosi; Mike Johnson; Donald Trump; Trump; Noé Chartier; Butler; Truth; Obama; Biden; Rehoboth Beach; Pennsylvania; New Jersey; Bedminster; Milwaukee; America; Associated Press; polizia; Usa Usa; Camera; Senato; Fbi;\"\n            },\n            \"score\": 0.3737032413482666,\n            \"explain_score\": \"\\nHybrid (Result Set keyword,bm25) Document cc993586-255d-5084-8bf9-f2c69fc34ec1: original score 3.9525168, normalized score: 0.37370324\"\n        },\n\nwith a 0.373 score which is lower than the “Sri Lanka” bject match, but if I try matching the two search terms (attentato and trump) with the strings in the object I find trump twice in the “prose” property and also “trump” twice in the keywords property (which I also weigh more with the ^1.3 modifier).\nSo why is this score lower for this object even though apparently it has more matches? Thank you for clarifying\nServer Setup Information\n\nWeaviate Server Version:  1.25.4\nDeployment Method: docker compose\nMulti Node? Number of Running Nodes:  1\nClient Language and Version: python 4.6.4\nMultitenancy?: no\n\nother info\nBM25_PARAMS = {\n    \"bm25_b\": 0.75,\n    \"bm25_k1\": 1.2,\n    \"cleanup_interval_seconds\": 60,\n    \"index_timestamps\": False,\n    \"index_property_length\": False,\n    \"index_null_state\": False,\n    \"stopwords_preset\": None,\n    \"stopwords_additions\": italian_stopwords,\n    \"stopwords_removals\": None,\n}\n\n----------\n\n[DudaNogueira (2024-08-07T18:33:20.720Z)]: cia @rjalex !!\nAwesome question! Thanks!\nI noticed that articletitle is also tokenized as word, so “attentato” has 3 hits.\nTwo in prose, and one in articletitle.\nthe other object has “2.3” hits (1.3 prose and 1 in articletitle ) hits and a “attentatore” that I don’t believe matches.\nBut that doesn’t explain the “trump” part \nOne wild guess: if you change the order of the words, do you get the same results?\nAlso, if you run bm25, will you get same scoring?\nThanks!\n\n----------\n\n[rjalex (2024-08-07T19:22:38.675Z)]: As usual thanks a lot @DudaNogueira. Now it’s late but tomorrow will try if a pure BM25 behaves in the same way and report back.\nThe “prose” and “keywords” properties are indexed case insensitive and word tokenized (Keep only alpha-numeric characters, lowercase them, and split by whitespace.) right?\nThe same holds true for the query string, right?\n\n----------\n\n[DudaNogueira (2024-08-07T19:25:05.637Z)]: Ops, sorry.\nMissed that you provide the properties, so the articletitle will not count towards the score.\nI am pretty sure it does lowercase both properties content and query.\n\n----------\n\n[rjalex (2024-08-08T08:16:43.426Z)]: Ok so the first test tells us that the “trump attentato” or “attentato trump” queries give identical results (as expected).\nStill no clue as of why this object:\n            \"properties\": {\n                \"kg_article_id\": \"http://ilmanifesto.it/mema/article/2024-07-14-attentato-a-trump-spari-durante-un-comizio\",\n                \"articletitle\": \"Attentato a Trump: spari durante un comizio\",\n                \"isoEditionDate\": \"2024-07-14\",\n                \"author\": \"Marina Catucci\",\n                \"category\": \"Internazionale\",\n                \"prose\": \"Attentato a Trump: spari durante un comizio; Alle 18.20 ora locale il comizio di Donald Trump a Butler in Pennsylvania era cominciato da poco, quando sono esplosi gli spari. Quando il tycoon si è abbassato dietro il […]; L'ex presidente ferito a un orecchio. L'attentatore, un ventenne, è morto. Biden: «Non c'è posto in America per questo tipo di violenza»\",\n                \"keywords\": \"Marina Catucci; Thomas Matthew Crooks; Chuck Schumer; Donald Trump; Trump; Mike Johnson; Nancy Pelosi; Noé Chartier; Butler; Truth; Biden; Obama; Rehoboth Beach; Pennsylvania; Bedminster; New Jersey; Milwaukee; America; Associated Press; polizia; Usa Usa; Camera; Senato; Fbi;\"\n            },\n            \"score\": 0.3737860321998596,\n            \"explain_score\": \"\\nHybrid (Result Set keyword,bm25) Document cc993586-255d-5084-8bf9-f2c69fc34ec1: original score 3.952838, normalized score: 0.37378603\"\n        },\n\nhas a lower (0.374) score while counting manually for the “attentato” and “trump” keywords there should be 3 matches for the prose property (one attentato and two trump) and 2 matches for the keyword property (trump twice) and as the keywords property is queried with a 1.3 factor the overall naif score should be 5.6 (2.6 for the keywords and 3 for the prose).\nWith the same query the following object:\n        {\n            \"properties\": {\n                \"kg_article_id\": \"https://ilmanifesto.it/mema/article/2000-10-06-sri-lanka-attentato-pre-elettorale\",\n                \"articletitle\": \"Sri lanka,attentato pre elettorale\",\n                \"isoEditionDate\": \"2000-10-06\",\n                \"author\": \"Redazione\",\n                \"category\": \"Mondo\",\n                \"prose\": \"Sri lanka,attentato pre elettorale; Attentato kamikaze indipendentista; \",\n                \"keywords\": \"Redazione, Sri Lanka, Medawachchiya\"\n            },\n            \"score\": 0.46509456634521484,\n            \"explain_score\": \"\\nHybrid (Result Set keyword,bm25) Document cbd3bb20-4570-543c-9ac9-972ac559e480: original score 4.068744, normalized score: 0.46509457\"\n        },\n\ngets an higher score despite to my untrained eye I only see “attentato” matching twice in the prose property so a naif score of 2.\nNow the second test is even more interesting. I change the query to a pure BM25 one, not an hybrid with alpha=0:\n            response = wv_artcoll.query.bm25(\n                query=request.query_text,\n                query_properties=[\n                    \"keywords^1.3\",\n                    \"prose\"\n                ],\n                limit=request.result_limit,\n                return_metadata=MetadataQuery(score=True, explain_score=True),\n            )\n\nand with this the “attentato trump” query changes the score and explains it in a different way:\n        {\n            \"properties\": {\n                \"kg_article_id\": \"http://ilmanifesto.it/mema/article/2024-07-14-attentato-a-trump-spari-durante-un-comizio\",\n                \"articletitle\": \"Attentato a Trump: spari durante un comizio\",\n                \"isoEditionDate\": \"2024-07-14\",\n                \"author\": \"Marina Catucci\",\n                \"category\": \"Internazionale\",\n                \"prose\": \"Attentato a Trump: spari durante un comizio; Alle 18.20 ora locale il comizio di Donald Trump a Butler in Pennsylvania era cominciato da poco, quando sono esplosi gli spari. Quando il tycoon si è abbassato dietro il […]; L'ex presidente ferito a un orecchio. L'attentatore, un ventenne, è morto. Biden: «Non c'è posto in America per questo tipo di violenza»\",\n                \"keywords\": \"Marina Catucci; Thomas Matthew Crooks; Chuck Schumer; Donald Trump; Trump; Mike Johnson; Nancy Pelosi; Noé Chartier; Butler; Truth; Biden; Obama; Rehoboth Beach; Pennsylvania; Bedminster; New Jersey; Milwaukee; America; Associated Press; polizia; Usa Usa; Camera; Senato; Fbi;\"\n            },\n            \"score\": 4.247416973114014,\n            \"explain_score\": \", BM25F_attentato_frequency:1, BM25F_attentato_propLength:48, BM25F_trump_frequency:8, BM25F_trump_propLength:82\"\n        },\n\nbut I cannot understand why is this scoring higher?\n           \"properties\": {\n                \"kg_article_id\": \"http://ilmanifesto.it/mema/article/2017-05-21-il-silenzio-usa-su-julian-assange\",\n                \"articletitle\": \"Il silenzio Usa su Julian Assange\",\n                \"isoEditionDate\": \"2017-05-21\",\n                \"author\": \"BenOld\",\n                \"category\": \"Internazionale\",\n                \"prose\": \"Il silenzio Usa su Julian Assange; Caduta l’accusa di stupro, per Julian Assange la partita più complicata da giocare è con le autorità americane. Negli Stati Uniti il fondatore di Wikileaks è accusato di attentato alla […]; Archiviata l'accusa di stupro, per il fondatore di Wikileaks la partita più importate da giocare è con l'Amministrazione Trump \",\n                \"keywords\": \"BenOld; Hillary Clinton; Julian Assange; Assange; Donald Trump; Trump; Usa; Usa; Casa Bianca; Stati Uniti; Wikileaks; Pentagono; Onu; Fbi;\"\n            },\n            \"score\": 4.8405938148498535,\n            \"explain_score\": \", BM25F_attentato_frequency:1, BM25F_attentato_propLength:35, BM25F_trump_frequency:7, BM25F_trump_propLength:51\"\n        },\n\nvisually I only see “attentato” once in “prose” and “trump” once in “prose” plus twice in “keywords”, the latter with a weight of 1.3\nWhy the BM25F_trump_frequency:7 ???\n\n----------\n\n[rjalex (2024-08-08T11:02:59.073Z)]: Ok I have been reading some literature on BM25F and it is shedding some light \nI also asked ChatGPT to explain and it might be an interesting read.\nThe short summary is that the scoring is not only counting matches but also search term proximity, search terms to target material length etc etc\nEnjoy\nThe BM25F algorithm is a popular ranking function used in search engines to evaluate the relevance of documents based on the query terms. It is an extension of the BM25 algorithm, incorporating field weighting to handle documents with structured fields, such as titles, keywords, and body text. Here’s a detailed breakdown of why the search “attentato trump” yields a higher score for the first object than the second, even though the second object seems more directly relevant at first glance:\nBM25F Scoring Factors\n\nTerm Frequency (TF): How often the query terms appear in the document.\nInverse Document Frequency (IDF): How common or rare the query terms are across all documents.\nField Length Normalization: Adjusts the influence of terms based on the length of the field they appear in.\nField Weights: Different fields (e.g., title, keywords, body) can have different weights assigned, affecting their impact on the final score.\n\nAnalysis of the Provided Objects\nFirst Object:\n\nProse:Il silenzio Usa su Julian Assange; Caduta l’accusa di stupro, per Julian Assange la partita più complicata da giocare è con le autorità americane. Negli Stati Uniti il fondatore di Wikileaks è accusato di attentato alla […]; Archiviata l'accusa di stupro, per il fondatore di Wikileaks la partita più importate da giocare è con l'Amministrazione Trump\n\n\nKeywords:BenOld; Hillary Clinton; Julian Assange; Assange; Donald Trump; Trump; Usa; Usa; Casa Bianca; Stati Uniti; Wikileaks; Pentagono; Onu; Fbi;\n\n\n\nSecond Object:\n\nProse:Attentato a Trump: spari durante un comizio; Alle 18.20 ora locale il comizio di Donald Trump a Butler in Pennsylvania era cominciato da poco, quando sono esplosi gli spari. Quando il tycoon si è abbassato dietro il […]; L'ex presidente ferito a un orecchio. L'attentatore, un ventenne, è morto. Biden: «Non c'è posto in America per questo tipo di violenza»\n\n\nKeywords:Marina Catucci; Thomas Matthew Crooks; Chuck Schumer; Donald Trump; Trump; Mike Johnson; Nancy Pelosi; Noé Chartier; Butler; Truth; Biden; Obama; Rehoboth Beach; Pennsylvania; Bedminster; New Jersey; Milwaukee; America; Associated Press; polizia; Usa Usa; Camera; Senato; Fbi;\n\n\n\nDetailed Explanation\n\n\nTerm Frequency in Keywords:\n\nThe first object’s keywords contain both “Trump” and “attentato”. These exact matches contribute significantly to the score due to high term frequency within a heavily weighted field (keywords).\nThe second object’s keywords contain “Trump” but do not contain “attentato”.\n\n\n\nProximity and Co-occurrence in Prose:\n\nIn the first object’s prose, “attentato” and “Trump” are not directly adjacent but are mentioned in the same context. The BM25F algorithm recognizes their presence within a relevant field, contributing to a higher score.\nThe second object has a direct mention of an “attentato” involving Trump, which seems more relevant contextually. However, if the overall term frequency and field weights are not as optimized, this direct mention might not outscore the weighted factors from the first object.\n\n\n\nField Length Normalization:\n\nThe first object may have shorter prose or keyword fields, making the occurrences of the terms more significant relative to the field length.\nThe second object might have longer prose or keyword fields, diluting the impact of the term frequencies.\n\n\n\nField Weights:\n\nIf the system assigns higher weights to the keywords field, the first object benefits more since both terms appear in this highly weighted field.\nEven if the prose in the second object is highly relevant, lower field weights for prose compared to keywords might result in a lower overall score.\n\n\n\nConclusion\nThe BM25F score is a function of term frequencies, field lengths, and field weights. In this case, the first object’s keywords field, containing both query terms, outweighs the relevance of the direct mention in the second object’s prose, leading to a higher score for the first object. This demonstrates the importance of term distribution across different fields and their respective weights in determining relevance in BM25F.\n\n----------\n\n[DudaNogueira (2024-08-12T21:22:00.397Z)]: Oh wow!!!\nAlso learned this hahaha.\nThanks!!!",
    "date_created": "2024-08-06T17:20:15.188Z",
    "has_accepted_answer": true,
    "title": "Unable to fully comprehend the computed score",
    "topic_id": 3281
  },
  {
    "user_id": 2463,
    "conversation": "[_Viliam_Durina (2024-11-05T14:38:20.905Z)]: I think the ranges for hamming and manhattan distance metrics are swapped here: Distance metrics | Weaviate. Hamming is 0..dims and manhattan is 0 .. Inf.\n\n----------\n\n[DudaNogueira (2024-11-06T12:18:30.690Z)]: hi @_Viliam_Durina !!\nWelcome to our community  !!\nThanks! I have forwarded it to our team!\n\n----------\n\n[jphwang (2024-11-06T16:23:06.849Z)]: Hi @_Viliam_Durina \nThank you for this! We have fixed it here - it will be merged to main shortly \n\n  \n\n      github.com/weaviate/weaviate-io\n  \n\n  \n    \n    \n      \n    \n\n\n\n\n  \n      \n        Fix hamming & manhattan dist ranges\n      \n\n      \n        \n          Commit by\n          \n            \n            databyjp\n           - [Draft] Weaviate Docs v20241107\n        \n      \n\n\n\n\n    \n      weaviate:main ← weaviate:v20241107",
    "date_created": "2024-11-05T14:38:20.838Z",
    "has_accepted_answer": true,
    "title": "[Docs] Distance metrics incorrect range",
    "topic_id": 7456
  },
  {
    "user_id": 1201,
    "conversation": "[Matthew_Leung (2024-07-15T18:39:27.051Z)]: Description\n\nServer Setup Information\n\nWeaviate Server Version: 1.19.1\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 3\nClient Language and Version: Python, weaviate-client==3.19.1\nMultitenancy?: No\n\nAny additional Information\n\nHi Team,\nWe would like to create a schema property on our Weaviate instance, which is hosted on Kubernetes with 3 nodes. We have forwarded the Weaviate port to local and run the Python Weaviate client script, but we encountered a timeout error.\nWe have performed similar actions on a local Weaviate instance and on Kubernetes with 1 node without encountering this issue. Do you have any ideas on what might be causing this problem?\nimage2462×574 73 KB\nScreenshot 2024-07-15 at 5.45.13 PM1996×718 95.1 KB\nScreenshot 2024-07-15 at 5.45.21 PM1750×764 76.1 KB\nScreenshot 2024-07-15 at 5.45.40 PM2252×898 247 KB\n\n----------\n\n[DudaNogueira (2024-07-15T18:42:25.937Z)]: hi @Matthew_Leung !!\nWelcome to our community  !!\nFirst, this is a fairly old version. We strongly suggest you to upgrade to latest as there are a lot of improvements and bug fixes between those versions.\nThis error message will usually surface when the port (in your case it seems to be 61926) is not properly exposed.\nYou will need to expose this port in K8s and make sure it is accessible from the application you are connecting from.\nLet me know if this helps.\nThanks!\n\n----------\n\n[Matthew_Leung (2024-07-16T22:17:11.877Z)]: Hi @DudaNogueira,\nWe have deployed the Python function on AWS Lambda, and it successfully connects to the Weaviate endpoint, listing the database. However, when we try to create the schema property on the database, it still throws a timeout error. May I know if there is any Weaviate configuration that may prevent the creation of schema properties?\nimage3252×1224 366 KB\n\n----------\n\n[DudaNogueira (2024-07-19T13:43:07.447Z)]: Hi!\nDoes this error happen only when running from AWS Lambda?\nIf you run this locally, does it work as expected?\nThanks!\n\n----------\n\n[Matthew_Leung (2024-07-24T09:07:44.270Z)]: Issue fixed. I think there is some problem on our db.\n\n----------\n\n[DudaNogueira (2024-07-24T20:59:05.383Z)]: Thanks for sharing! We really appreciate!",
    "date_created": "2024-07-15T18:39:26.975Z",
    "has_accepted_answer": true,
    "title": "Timeout Error While Creating Schema Property on Weaviate with 3-Node Kubernetes Cluster",
    "topic_id": 3051
  },
  {
    "user_id": 2267,
    "conversation": "[pavan (2024-11-04T15:16:50.104Z)]: I am trying to run vectored bench on weaviate which is running on Kubernetes on EC2 instance.  when vectordb is trying to connect to weaviate its getting the below error:\n“failed to run, reason=Weaviate did not start up in 5 seconds. Either the Weaviate URL http://10.103.208.135:80/v1 is wrong or Weaviate did not start up in the interval given in 'startup_period”\nNow, when I opened weaviate logs below are the output:\nubuntu@ip-172-30-7-158:~$ kubectl logs weaviate-0 --namespace weaviate\nDefaulted container “weaviate” out of: weaviate, configure-sysctl (init)\n{“action”:“config_load”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“config_file_path”:“/weaviate-config/conf.yaml”,“level”:“info”,“msg”:“Usage of the weaviate.conf.json file is deprecated and will be removed in the future. Please use environment variables.”,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“deprecation”:{“apiType”:“Configuration”,“id”:“config-files”,“locations”:[“–config-file=\"\"”],“mitigation”:“Configure Weaviate using environment variables.”,“msg”:“use of deprecated command line argument --config-file”,“sinceTime”:“2020-09-08T09:46:00.000Z”,“sinceVersion”:“0.22.16”,“status”:“deprecated”},“level”:“warning”,“msg”:“use of deprecated command line argument --config-file”,“time”:“2024-11-04T08:59:46Z”}\n{“action”:“startup”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“default_vectorizer_module”:“none”,“level”:“info”,“msg”:“the default vectorizer modules is set to \"none\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer”,“time”:“2024-11-04T08:59:46Z”}\n{“action”:“startup”,“auto_schema_enabled”:true,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“auto schema enabled setting is set to \"true\"”,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true”,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“module offload-s3 is enabled”,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“open cluster service”,“servers”:{“weaviate-0”:8300},“time”:“2024-11-04T08:59:46Z”}\n{“address”:“10.244.0.13:8301”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“starting cloud rpc server …”,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“starting raft sub-system …”,“time”:“2024-11-04T08:59:46Z”}\n{“address”:“10.244.0.13:8300”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“tcp transport”,“tcpMaxPool”:3,“tcpTimeout”:10000000000,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“loading local db”,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“local DB successfully loaded”,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“schema manager loaded”,“n”:0,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“metadata_only_voters”:false,“msg”:“construct a new raft node”,“name”:“weaviate-0”,“time”:“2024-11-04T08:59:46Z”}\n{“action”:“raft”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“index”:10,“level”:“info”,“msg”:“raft initial configuration”,“servers”:“[[{Suffrage:Voter ID:weaviate-0 Address:10.244.0.10:8300}]]”,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“last_snapshot_index”:0,“last_store_applied_index_on_start”:0,“level”:“info”,“msg”:“raft node constructed”,“raft_applied_index”:0,“raft_last_index”:10,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“hasState”:true,“level”:“info”,“msg”:“raft init”,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“10.244.0.13:8300”],“time”:“2024-11-04T08:59:46Z”}\n{“action”:“raft”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“follower”:{},“leader-address”:“”,“leader-id”:“”,“level”:“info”,“msg”:“raft entering follower state”,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“10.244.0.13:8300”,“status”:8,“time”:“2024-11-04T08:59:46Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“10.244.0.13:8300”],“time”:“2024-11-04T08:59:47Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“attempted to join and failed”,“remoteNode”:“10.244.0.13:8300”,“status”:8,“time”:“2024-11-04T08:59:47Z”}\n{“action”:“raft”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“last-leader-addr”:“”,“last-leader-id”:“”,“level”:“warning”,“msg”:“raft heartbeat timeout reached, starting election”,“time”:“2024-11-04T08:59:47Z”}\n{“action”:“raft”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“raft entering candidate state”,“node”:{},“term”:7,“time”:“2024-11-04T08:59:47Z”}\n{“action”:“raft”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“raft pre-vote successful, starting election”,“refused”:0,“tally”:1,“term”:7,“time”:“2024-11-04T08:59:47Z”,“votesNeeded”:1}\n{“action”:“raft”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“raft election won”,“tally”:1,“term”:7,“time”:“2024-11-04T08:59:47Z”}\n{“action”:“raft”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“leader”:{},“level”:“info”,“msg”:“raft entering leader state”,“time”:“2024-11-04T08:59:47Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“configured versions”,“server_version”:“1.27.0”,“time”:“2024-11-04T08:59:48Z”,“version”:“1.27.0”}\n{“action”:“grpc_startup”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“grpc server listening at [::]:50051”,“time”:“2024-11-04T08:59:48Z”}\n{“address”:“10.244.0.13:8300”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“current Leader”,“time”:“2024-11-04T08:59:48Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“starting migration from old schema”,“time”:“2024-11-04T08:59:48Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“legacy schema is empty, nothing to migrate”,“time”:“2024-11-04T08:59:48Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“migration from the old schema has been successfully completed”,“time”:“2024-11-04T08:59:48Z”}\n{“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“attempting to join”,“remoteNodes”:[“10.244.0.13:8300”],“time”:“2024-11-04T08:59:48Z”}\n{“action”:“raft”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“command”:0,“level”:“info”,“msg”:“raft updating configuration”,“server-addr”:“10.244.0.13:8300”,“server-id”:“weaviate-0”,“servers”:“[[{Suffrage:Voter ID:weaviate-0 Address:10.244.0.13:8300}]]”,“time”:“2024-11-04T08:59:48Z”}\n{“action”:“restapi_management”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“Serving weaviate at http://[::]:8080”,“time”:“2024-11-04T08:59:48Z”,“version”:“1.27.0”}\n{“action”:“telemetry_push”,“build_git_commit”:“6c571ff”,“build_go_version”:“go1.22.8”,“build_image_tag”:“”,“build_wv_version”:“”,“level”:“info”,“msg”:“telemetry started”,“payload”:“\\u0026{MachineID:c02cd97c-78aa-4ad7-bd89-9f3ec42b0524 Type:INIT Version:1.27.0 NumObjects:0 OS:linux Arch:amd64 UsedModules:}”,“time”:“2024-11-04T08:59:48Z”}\n\n----------\n\n[DudaNogueira (2024-11-04T16:12:37.507Z)]: Hi!\nAre you using our oficial helm chart?\n\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate/weaviate-helm: Helm charts to deploy Weaviate to k8s\n\n    Helm charts to deploy Weaviate to k8s\n\n----------\n\n[pavan (2024-11-04T16:44:11.422Z)]: yes , I was using your official helm chart. using : helm repo add weaviate Weaviate Helm Charts | Weaviate Helm chart repo\n\n----------\n\n[DudaNogueira (2024-11-04T17:39:07.066Z)]: Ok!\nWhat is the software you want to connect it with Weaviate?\nWere you able to connect using the python client for example?\n\n----------\n\n[pavan (2024-11-04T19:22:27.349Z)]: I am trying to run vectorDBbench on weaviate for the performance run. (GitHub - zilliztech/VectorDBBench: A Benchmark Tool for VectorDB).\nWere you able to connect using the python client for example? >> I  haven’t done this.\n\n----------\n\n[DudaNogueira (2024-11-04T21:30:17.037Z)]: Oh, I see.\nThat code/benchmark is using our old client that doesn’t leverage the recent improvements over GRPC. It also targets our cloud, that should be instantiated first and with the proper resources allocated.\nYou should be able to connect to your cluster like that:\nimport weaviate\nclient = weaviate.Client(\n    url=\"http://localhost:8080\",\n    auth_client_secret=weaviate.auth.AuthApiKey(\"YOUR API KEY HERE\"),\n)\n\nthat from the same pod running that code.\nNote that your error log suggests that you may be passing http://10.103.208.135:80/v1 as the url instead of http://10.103.208.135:80\nLet me know if this helps.\n\n----------\n\n[DudaNogueira (2024-11-04T21:31:01.890Z)]: And by the way, if you want to learn about our take on benchmarking Weaviate, there are some nice contents here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nBenchmarks | Weaviate\n\n  You can find the following vector database performance benchmarks:\n\n----------\n\n[pavan (2024-11-05T05:28:47.985Z)]: Thanks @DudaNogueira  for replying.so , I have three questions here based on ur reply:\n\n\nwhether the vectiordbBench benchmark code is compatible with latest weaviate code base?\n\n\nsince u have mentioned \" It also targets our cloud\" , does it mean it cannot connect to my Kubernetes cluster locally?\n\n\nwill u be able to tell me which weaviate version (lower version) is compatible with the vectordbBench code?\n\n\nI will get more clarity on how to move forward,  based on these answers.\n\n----------\n\n[pavan (2024-11-06T05:30:12.480Z)]: Hi @DudaNogueira, I tried running the solution u proposed from my local machine using python code.\nimport weaviate\nclient = weaviate.Client(\nurl=“http://localhost:8080”,\nauth_client_secret=weaviate.auth.AuthApiKey(“YOUR API KEY HERE”),\n)\nIts showing the error:\nweaviate.exceptions.WeaviateStartUpError: Weaviate did not start up in 5 seconds. Either the Weaviate URL http://localhost:50051 is wrong or Weaviate did not start up in the interval given in ‘startup_period’.\nSo , giving u more info on my setup on which weaviate is running:\nI followed:  Create a Kubernetes cluster | Weaviate\nso , I installed Minikube and kubectl and dowloaded hem chart. so , in the doc it told me to use Minikube tunnel to expose external ip. so after that when I run the python client its giving the above error.\n\n----------\n\n[DudaNogueira (2024-11-06T13:56:03.463Z)]: Oh I see. You will need to forward the http service port from that pod to 8080.\nThis is not covered on that docs.\nDo you know how to forward those?\nAre you also using minikube?\n\n----------\n\n[pavan (2024-11-06T14:33:09.557Z)]: yes @DudaNogueira , I am using minikuve . I have followed the exact steps mentioned in: Create a Kubernetes cluster | Weaviate. I am facing issue forwarding request inside Minikube into weaviate cluster\n\n----------\n\n[pavan (2024-11-07T08:58:50.123Z)]: I was able to send requests on http port exposed via Minikube tunnel s external IP. whereas for the grpc port I am not able to get it through to the weaviate running in minikube.  I tried port forwarding but that is also not working.\n\n----------\n\n[00.lope.naughts (2024-11-20T18:49:37.695Z)]: @pavan @DudaNogueira I also tried minikube, and I followed this blog (Achieve Zero-Downtime Upgrades with Weaviate’s Multi-Node Setup | Weaviate). I am unsure if this is already a bit dated (since we have v4 client). I successfully reached step “minikube service weaviate --namespace weaviate” to expose to “outside world”, and it launched http://127.0.0.1:/v1and there was no apparent error anywhere. But if I tried to connect using client v4:\nclient = weaviate.connect_to_local(‘localhost’, …)\nI got errors, and this may be pertinent:\nAioRpcError: <AioRpcError of RPC that terminated with:\nstatus = StatusCode.UNAVAILABLE\ndetails = “failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:50051: Failed to connect to remote host: Connection refused”\ndebug_error_string = “UNKNOWN:Error received from peer  {grpc_message:“failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:50051: Failed to connect to remote host: Connection refused”, grpc_status:14, created_time:“2024-11-20T13:31:57.896269-05:00”}”\n\nit seems it says there’s no grpc available. I thought it was mentioned this is used in the client and not REST. So I suspect the blog is missing another step where grpc should also be exposed?\n\n----------\n\n[DudaNogueira (2024-11-21T14:26:06.989Z)]: Hi!\nHere is how I do to connect to a minikube cluster with 3 nodes:\n>> minikube start --nodes 3\n\n>> kubectl get nodes\nNAME           STATUS   ROLES           AGE     VERSION\nminikube       Ready    control-plane   4m17s   v1.31.0\nminikube-m02   Ready    <none>          4m7s    v1.31.0\nminikube-m03   Ready    <none>          3m59s   v1.31.0\n\n>> helm repo add weaviate https://weaviate.github.io/weaviate-helm\n\n>> helm show values weaviate/weaviate > values.yaml\n\nedit the values.yaml and enable the openai and set the replicas to 3\ncreate the namespace:\n>> kubectl create namespace weaviate\n\ndeploy the helm chart:\n>> helm upgrade --install \\\n  \"weaviate\" \\\n  weaviate/weaviate \\\n  --namespace \"weaviate\" \\\n  --values ./values.yaml\n\nwatch your cluster starting, and wait all pods to be ready\n>> kubectl -n weaviate get pods -w\n\nthose are the services we have:\n>> kubectl -n weaviate get services\nNAME                TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)           AGE\nweaviate            LoadBalancer   10.107.66.168   <pending>     80:32443/TCP      106s\nweaviate-grpc       LoadBalancer   10.97.59.100    <pending>     50051:30758/TCP   106s\nweaviate-headless   ClusterIP      None            <none>        80/TCP            106s\n\nwe need to forward both http and grpc ports\nnote that the service for http is on port 80 and grpc 50051\nkubectl port-forward service/weaviate 8080:80 -n weaviate\nkubectl port-forward service/weaviate-grpc 50051:50051 -n weaviate\n\nIn order to test the GRPC endpoint, you can use grpcurl. Here is how to test without any auth or ssl\n>> wget https://raw.githubusercontent.com/grpc/grpc/master/src/proto/grpc/health/v1/health.proto\n>> grpcurl -plaintext -d '{\"service\": \"Weaviate\"}' -proto health.proto localhost:50051 grpc.health.v1.Health/Check\n{\n  \"status\": \"SERVING\"\n}\n\nLet me know if this helps!\n\n----------\n\n[00.lope.naughts (2024-11-21T16:26:45.943Z)]: This works! thanks a lot.",
    "date_created": "2024-11-04T15:16:50.034Z",
    "has_accepted_answer": false,
    "title": "Not able to connect to weaviate instance from vectordbBench",
    "topic_id": 7441
  },
  {
    "user_id": 655,
    "conversation": "[alisha_liu (2024-08-18T14:10:33.426Z)]: Description:\nDoes there is a way that I can get the disk usage for weaviate data for each collection?\nServer Setup Information\n\nWeaviate Server Version: 1.26\nDeployment Method: docker/k8s/AWS\nMulti Node?  no, only one node\nClient Language and Version: JS/TS Client v3\nMultitenancy?: no\n\nAny additional Information\\\n\n----------\n\n[DudaNogueira (2024-08-19T12:41:01.862Z)]: Hi Alisha!\nWhenever a new collection is created on a node, a folder will be created that stores all content related to that collection in the wherever your PERSISTENCE_DATA_PATH is defined.\nSo AFAIK, that is the best way to measure the consumption of a collection in your cluster.\nLet me know if that helps.\nThanks!\n\n----------\n\n[alisha_liu (2024-08-19T20:25:58.946Z)]: Thanks for your response, I will try your solution.",
    "date_created": "2024-08-18T14:10:33.383Z",
    "has_accepted_answer": true,
    "title": "How to get the disk usage for weaviate data for each collection",
    "topic_id": 3386
  },
  {
    "user_id": 1634,
    "conversation": "[Waleed_Chaudhry (2024-10-04T10:42:24.353Z)]: How can we print the quantized vectors after creating a collection with quantized configuration\n\n----------\n\n[DudaNogueira (2025-01-28T15:42:13.369Z)]: hi @Waleed_Chaudhry !!\nWelcome to our community and sorry for the delay here.\nThis is not possible as of now. I will gather more info on this and if necessary open an issue in GH.\nThanks!\n\n----------\n\n[DudaNogueira (2025-01-28T19:19:00.097Z)]: Here we have the GH Issue so we can track it down!\n\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Expose suggested segment size on PQ when segments=0 and expose quantized vectors\n    \n\n    \n      \n        opened 07:16PM - 28 Jan 25 UTC\n      \n\n\n      \n        \n          \n          dudanogueira\n        \n      \n    \n\n    \n        \n          feature request\n        \n    \n  \n\n\n  \n    ### Describe your feature request\n\nWhen we create a PQ compressed collection and… let `segments` unconfigured (default to 0), Weaviate will figure out the best segments configuration.\n\nHowever, this information is not exposed anywhere and it can be valuable if you want to benchmark the compression against different segment sizes or for debugging.\n\nAlso, Weaviate will not expose the quantized vectors. For this I am not sure what is the value of having access to the quantized vectors, so if anyone can think about the use cases :)\n\n### Code of Conduct\n\n- [x] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!",
    "date_created": "2024-10-04T10:42:24.302Z",
    "has_accepted_answer": false,
    "title": "[Question] Quantized Vectors in Weaviate",
    "topic_id": 4418
  },
  {
    "user_id": 3065,
    "conversation": "[Aprameyan_V (2024-12-20T07:27:42.477Z)]: my code\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=URL,\n    auth_credentials=Auth.api_key(APIKEY),\n    additional_config=AdditionalConfig(timeout=Timeout(init=100, query=60, insert=120)),  # Increased timeout\n    skip_init_checks=True,  # Skip initial connection checks to avoid timeouts\n    headers={\n        \"X-HuggingFace-Api-Key\": os.getenv(\"HUGGING_FACE_API\")  # Pass custom headers if needed\n    }\n)\n\n\nThe error traceback is as follows\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.13/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n    yield\n  File \"/usr/local/lib/python3.13/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n    raise exc from None\n  File \"/usr/local/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n    response = await connection.handle_async_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        pool_request.request\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/usr/local/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n    raise exc\n  File \"/usr/local/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request\n    stream = await self._connect(request)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 124, in _connect\n    stream = await self._network_backend.connect_tcp(**kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.13/site-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp\n    return await self._backend.connect_tcp(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n    )\n    ^\n  File \"/usr/local/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp\n    with map_exceptions(exc_map):\n         ~~~~~~~~~~~~~~^^^^^^^^^\n  File \"/usr/local/lib/python3.13/contextlib.py\", line 162, in __exit__\n    self.gen.throw(value)\n    ~~~~~~~~~~~~~~^^^^^^^\n  File \"/usr/local/lib/python3.13/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.13/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 88, in exec_func_with_error_handling\n    result = func()\n  File \"/usr/local/lib/python3.13/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 579, in code_to_exec\n    exec(code, module.__dict__)\n    ~~~~^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/app.py\", line 31, in <module>\n    client = weaviate.connect_to_weaviate_cloud(\n        cluster_url=URL,\n    ...<5 lines>...\n        }\n    )\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/connect/helpers.py\", line 80, in connect_to_weaviate_cloud\n    return __connect(\n        WeaviateClient(\n    ...<8 lines>...\n        )\n    )\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/connect/helpers.py\", line 411, in __connect\n    raise e\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/connect/helpers.py\", line 407, in __connect\n    client.connect()\n    ~~~~~~~~~~~~~~^^\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/syncify.py\", line 23, in sync_method\n    return _EventLoopSingleton.get_instance().run_until_complete(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        async_func, self, *args, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/event_loop.py\", line 42, in run_until_complete\n    return fut.result()\n           ~~~~~~~~~~^^\n  File \"/usr/local/lib/python3.13/concurrent/futures/_base.py\", line 456, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/usr/local/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/client_base.py\", line 153, in connect\n    await self._connection.connect(self._skip_init_checks)\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/connect/v4.py\", line 158, in connect\n    meta = await self.get_meta()\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/connect/v4.py\", line 609, in get_meta\n    response = await self.get(path=\"/meta\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/connect/v4.py\", line 568, in get\n    return await self.__send(\n           ^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n    )\n    ^\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/connect/v4.py\", line 489, in __send\n    raise e\n  File \"/usr/local/lib/python3.13/site-packages/weaviate/connect/v4.py\", line 476, in __send\n    res = await self._client.send(req)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.13/site-packages/httpx/_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n  File \"/usr/local/lib/python3.13/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/usr/local/lib/python3.13/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.13/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.13/site-packages/httpx/_transports/default.py\", line 393, in handle_async_request\n    with map_httpcore_exceptions():\n         ~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/usr/local/lib/python3.13/contextlib.py\", line 162, in __exit__\n    self.gen.throw(value)\n    ~~~~~~~~~~~~~~^^^^^^^\n  File \"/usr/local/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectTimeout\n\n----------\n\n[DudaNogueira (2024-12-20T13:51:01.249Z)]: hi @Aprameyan_V !!\nWelcome to our community \nweaviate.connect_to_weaviate_cloud should only be used with clusters hosted in our cloud.\nif running with docker, and exposing the 8080 and 50051 ports as configured in the default docker-compose, you can use weaviate.connect_to_local\nIf you have any differente deployment, you can customize it as stated here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCustom connections | Weaviate\n\n  The Python Client v4 and the TypeScript Client v3 provide helper methods for common connection types. They also provide custom methods for when you need additional connection configuration.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.\nAre you by any chance trying to use the connect_to_weaviate_cloud to connect to a weaviate running on localhost with docker?",
    "date_created": "2024-12-20T07:27:42.408Z",
    "has_accepted_answer": false,
    "title": "When I run the app locally, it works fine, but after building a Docker image and running it, I’m getting a ConnectionTimeout error.Tried skipping init checks and increasing timeout in the additional configs, but no luck. What should I do?",
    "topic_id": 9354
  },
  {
    "user_id": 1570,
    "conversation": "[EpiphanyFall (2024-09-22T03:25:55.035Z)]: Description\nI have a schema.json:\n{\n  \"classes\": [\n    {\n      \"class\": \"Pack\",\n      \"properties\": [\n        {\n          \"name\": \"pack_name\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"version\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"author\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"website\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"state\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"date\",\n          \"dataType\": [\n            \"date\"\n          ]\n        }\n      ]\n    },\n    {\n      \"class\": \"TextFile\",\n      \"properties\": [\n        {\n          \"name\": \"path_in_pack\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"simhash\",\n          \"dataType\": [\n            \"vector\"\n          ]\n        },\n        {\n          \"name\": \"sequences\",\n          \"dataType\": [\n            \"string[]\"\n          ]\n        },\n        {\n          \"name\": \"belongs_to_pack\",\n          \"dataType\": [\n            \"Pack\"\n          ]\n        },\n        {\n          \"name\": \"md5\",\n          \"dataType\": [\n            \"string\"\n          ]\n        }\n      ],\n      \"vectorIndexConfig\": {\n        \"distance\": \"hamming\"\n      }\n    },\n    {\n      \"class\": \"ImageFile\",\n      \"properties\": [\n        {\n          \"name\": \"md5\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"path_in_pack\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"histogram\",\n          \"dataType\": [\n            \"vector\"\n          ]\n        },\n        {\n          \"name\": \"phash\",\n          \"dataType\": [\n            \"vector\"\n          ]\n        },\n        {\n          \"name\": \"lbp_features\",\n          \"dataType\": [\n            \"vector\"\n          ]\n        },\n        {\n          \"name\": \"belongs_to_pack\",\n          \"dataType\": [\n            \"Pack\"\n          ]\n        }\n      ]\n    },\n    {\n      \"class\": \"AudioFile\",\n      \"properties\": [\n        {\n          \"name\": \"path_in_pack\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"belongs_to_pack\",\n          \"dataType\": [\n            \"Pack\"\n          ]\n        },\n        {\n          \"name\": \"md5\",\n          \"dataType\": [\n            \"string\"\n          ]\n        }\n      ]\n    }\n  ]\n}\n\nand I load the schema with\nself.client = weaviate.Client(WEAVIATE_URL)\n        try:\n            self.load_schema('database/schema.gql')\n        except Exception as e:\n            print(e)\n\nIf GET the schemas\n            schema = self.client.schema.get()\n\n{\n    \"classes\": [\n        {\n            \"class\": \"TextFile\",\n            \"invertedIndexConfig\": {\n                \"bm25\": {\n                    \"b\": 0.75,\n                    \"k1\": 1.2\n                },\n                \"cleanupIntervalSeconds\": 60,\n                \"stopwords\": {\n                    \"additions\": null,\n                    \"preset\": \"en\",\n                    \"removals\": null\n                }\n            },\n            \"multiTenancyConfig\": {\n                \"autoTenantActivation\": false,\n                \"autoTenantCreation\": false,\n                \"enabled\": false\n            },\n            \"properties\": [\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"path_in_pack\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"text[]\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"sequences\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"md5\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"uuid\"\n                    ],\n                    \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Sep 20 12:16:53 2024\",\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": false,\n                    \"name\": \"belongs_to_pack\"\n                },\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Sep 20 12:16:53 2024\",\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"file_path\",\n                    \"tokenization\": \"word\"\n                },\n                {\n                    \"dataType\": [\n                        \"number[]\"\n                    ],\n                    \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Sep 20 12:16:53 2024\",\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": false,\n                    \"name\": \"simhash\"\n                }\n            ],\n            \"replicationConfig\": {\n                \"factor\": 1\n            },\n            \"shardingConfig\": {\n                \"actualCount\": 1,\n                \"actualVirtualCount\": 128,\n                \"desiredCount\": 1,\n                \"desiredVirtualCount\": 128,\n                \"function\": \"murmur3\",\n                \"key\": \"_id\",\n                \"strategy\": \"hash\",\n                \"virtualPerPhysical\": 128\n            },\n            \"vectorIndexConfig\": {\n                \"bq\": {\n                    \"enabled\": false\n                },\n                \"cleanupIntervalSeconds\": 300,\n                \"distance\": \"hamming\",\n                \"dynamicEfFactor\": 8,\n                \"dynamicEfMax\": 500,\n                \"dynamicEfMin\": 100,\n                \"ef\": -1,\n                \"efConstruction\": 128,\n                \"flatSearchCutoff\": 40000,\n                \"maxConnections\": 64,\n                \"pq\": {\n                    \"bitCompression\": false,\n                    \"centroids\": 256,\n                    \"enabled\": false,\n                    \"encoder\": {\n                        \"distribution\": \"log-normal\",\n                        \"type\": \"kmeans\"\n                    },\n                    \"segments\": 0,\n                    \"trainingLimit\": 100000\n                },\n                \"skip\": false,\n                \"vectorCacheMaxObjects\": 1000000000000\n            },\n            \"vectorIndexType\": \"hnsw\",\n            \"vectorizer\": \"none\"\n        },\n        {\n            \"class\": \"AudioFile\",\n            \"invertedIndexConfig\": {\n                \"bm25\": {\n                    \"b\": 0.75,\n                    \"k1\": 1.2\n                },\n                \"cleanupIntervalSeconds\": 60,\n                \"stopwords\": {\n                    \"additions\": null,\n                    \"preset\": \"en\",\n                    \"removals\": null\n                }\n            },\n            \"multiTenancyConfig\": {\n                \"autoTenantActivation\": false,\n                \"autoTenantCreation\": false,\n                \"enabled\": false\n            },\n            \"properties\": [\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"path_in_pack\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"md5\",\n                    \"tokenization\": \"whitespace\"\n                }\n            ],\n            \"replicationConfig\": {\n                \"factor\": 1\n            },\n            \"shardingConfig\": {\n                \"actualCount\": 1,\n                \"actualVirtualCount\": 128,\n                \"desiredCount\": 1,\n                \"desiredVirtualCount\": 128,\n                \"function\": \"murmur3\",\n                \"key\": \"_id\",\n                \"strategy\": \"hash\",\n                \"virtualPerPhysical\": 128\n            },\n            \"vectorIndexConfig\": {\n                \"bq\": {\n                    \"enabled\": false\n                },\n                \"cleanupIntervalSeconds\": 300,\n                \"distance\": \"cosine\",\n                \"dynamicEfFactor\": 8,\n                \"dynamicEfMax\": 500,\n                \"dynamicEfMin\": 100,\n                \"ef\": -1,\n                \"efConstruction\": 128,\n                \"flatSearchCutoff\": 40000,\n                \"maxConnections\": 64,\n                \"pq\": {\n                    \"bitCompression\": false,\n                    \"centroids\": 256,\n                    \"enabled\": false,\n                    \"encoder\": {\n                        \"distribution\": \"log-normal\",\n                        \"type\": \"kmeans\"\n                    },\n                    \"segments\": 0,\n                    \"trainingLimit\": 100000\n                },\n                \"skip\": false,\n                \"vectorCacheMaxObjects\": 1000000000000\n            },\n            \"vectorIndexType\": \"hnsw\",\n            \"vectorizer\": \"none\"\n        },\n        {\n            \"class\": \"ImageFile\",\n            \"invertedIndexConfig\": {\n                \"bm25\": {\n                    \"b\": 0.75,\n                    \"k1\": 1.2\n                },\n                \"cleanupIntervalSeconds\": 60,\n                \"stopwords\": {\n                    \"additions\": null,\n                    \"preset\": \"en\",\n                    \"removals\": null\n                }\n            },\n            \"multiTenancyConfig\": {\n                \"autoTenantActivation\": false,\n                \"autoTenantCreation\": false,\n                \"enabled\": false\n            },\n            \"properties\": [\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"md5\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"path_in_pack\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Sep 20 12:16:53 2024\",\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"file_path\",\n                    \"tokenization\": \"word\"\n                },\n                {\n                    \"dataType\": [\n                        \"number[]\"\n                    ],\n                    \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Sep 20 12:16:53 2024\",\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": false,\n                    \"name\": \"phash\"\n                },\n                {\n                    \"dataType\": [\n                        \"number[]\"\n                    ],\n                    \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Sep 20 12:16:53 2024\",\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": false,\n                    \"name\": \"lbp_features\"\n                },\n                {\n                    \"dataType\": [\n                        \"uuid\"\n                    ],\n                    \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Sep 20 12:16:53 2024\",\n                    \"indexFilterabl53 2024\",\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": false,\n                    \"name\": \"belongs_to_pack\"\n                }\n            ],\n            \"replicationConfig\": {\n                \"factor\": 1\n            },\n            \"shardingConfig\": {\n                \"actualCount\": 1,\n                \"actualVirtualCount\": 128,\n                \"desiredCount\": 1,\n                \"desiredVirtualCount\": 128,\n                \"function\": \"murmur3\",\n                \"key\": \"_id\",\n                \"strategy\": \"hash\",\n                \"virtualPerPhysical\": 128\n            },\n            \"vectorIndexConfig\": {\n                \"bq\": {\n                    \"enabled\": false\n                },\n                \"cleanupIntervalSeconds\": 300,\n                \"distance\": \"cosine\",\n                \"dynamicEfFactor\": 8,\n                \"dynamicEfMax\": 500,\n                \"dynamicEfMin\": 100,\n                \"ef\": -1,\n                \"efConstruction\": 128,\n                \"flatSearchCutoff\": 40000,\n                \"maxConnections\": 64,\n                \"pq\": {\n                    \"bitCompression\": false,\n                    \"centroids\": 256,\n                    \"enabled\": false,\n                    \"encoder\": {\n                        \"distribution\": \"log-normal\",\n                        \"type\": \"kmeans\"\n                    },\n                    \"segments\": 0,\n                    \"trainingLimit\": 100000\n                },\n                \"skip\": false,\n                \"vectorCacheMaxObjects\": 1000000000000\n            },\n            \"vectorIndexType\": \"hnsw\",\n            \"vectorizer\": \"none\"\n        },\n        {\n            \"class\": \"Pack\",\n            \"invertedIndexConfig\": {\n                \"bm25\": {\n                    \"b\": 0.75,\n                    \"k1\": 1.2\n                },\n                \"cleanupIntervalSeconds\": 60,\n                \"stopwords\": {\n                    \"additions\": null,\n                    \"preset\": \"en\",\n                    \"removals\": null\n                }\n            },\n            \"multiTenancyConfig\": {\n                \"autoTenantActivation\": false,\n                \"autoTenantCreation\": false,\n                \"enabled\": false\n            },\n            \"properties\": [\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"pack_name\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"version\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"author\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"website\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"text\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": true,\n                    \"name\": \"state\",\n                    \"tokenization\": \"whitespace\"\n                },\n                {\n                    \"dataType\": [\n                        \"date\"\n                    ],\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": false,\n                    \"name\": \"date\"\n                }\n            ],\n            \"replicationConfig\": {\n                \"factor\": 1\n            },\n            \"shardingConfig\": {\n                \"actualCount\": 1,\n                \"actualVirtualCount\": 128,\n                \"desiredCount\": 1,\n                \"desiredVirtualCount\": 128,\n                \"function\": \"murmur3\",\n                \"key\": \"_id\",\n                \"strategy\": \"hash\",\n                \"virtualPerPhysical\": 128\n            },\n            \"vectorIndexConfig\": {\n                \"bq\": {\n                    \"enabled\": false\n                },\n                \"cleanupIntervalSeconds\": 300,\n                \"distance\": \"cosine\",\n                \"dynamicEfFactor\": 8,\n                \"dynamicEfMax\": 500,\n                \"dynamicEfMin\": 100,\n                \"ef\": -1,\n                \"efConstruction\": 128,\n                \"flatSearchCutoff\": 40000,\n                \"maxConnections\": 64,\n                \"pq\": {\n                    \"bitCompression\": false,\n                    \"centroids\": 256,\n                    \"enabled\": false,\n                    \"encoder\": {\n                        \"distribution\": \"log-normal\",\n                        \"type\": \"kmeans\"\n                    },\n                    \"segments\": 0,\n                    \"trainingLimit\": 100000\n                },\n                \"skip\": false,\n                \"vectorCacheMaxObjects\": 1000000000000\n            },\n            \"vectorIndexType\": \"hnsw\",\n            \"vectorizer\": \"none\"\n        }\n    ]\n}\n\nYou can tall that the class references turned into UUID\n{\n                    \"dataType\": [\n                        \"uuid\"\n                    ],\n                    \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Sep 20 12:16:53 2024\",\n                    \"indexFilterabl53 2024\",\n                    \"indexFilterable\": true,\n                    \"indexSearchable\": false,\n                    \"name\": \"belongs_to_pack\"\n                }\n\nBut when I query the references, wether use python sdk(v3) or use native gql:\nself.client.query.get(\"TextFile\", [\"path_in_pack\",\n# LinkTo(\n#     link_on=\"belongs_to_pack\",           # 要查询的字段\n#     linked_class=\"Pack\",                 # 引用的类\n#     properties=[\"pack_name\"]             # 查询该引用类中的字段\n# )\n\"\"\"\nbelongs_to_pack {\n    name\n}\"\"\"\n]).with_near_vector(query).do()\n\nIt errors:\n{'errors': [{'locations': [{'column': 17, 'line': 2}], 'message': 'Field \"belongs_to_pack\" of type \"String\" must not have a sub selection.', 'path': None}]}\n\nHow to solve this, pls.\nServer Setup Information\n\nWeaviate Server Version: {\"action\":\"startup\",\"build_git_commit\":\"447949c\",\"build_go_version\":\"go1.22.7\",\"build_image_tag\":\"1.25.17\",\"build_wv_version\":\"1.25.17\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-09-17T17:20:52Z\"}\nDeployment Method: docker\nNumber of Running Nodes: 1\nClient Language and Version: python weaviate==0.1.0 weaviate-client==4.8.1\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-09-23T08:34:54.478Z)]: Hi!\nI was not able to create the collections using this schema.\nI got this error, due to the data type “vector” that is not valid:\n        {\n          \"name\": \"simhash\",\n          \"dataType\": [\n            \"vector\"\n          ]\n        },\n\nthis was the error:\n\nUnexpectedStatusCodeError: Collection may not have been created properly.! Unexpected status code: 422, with response body: {‘error’: [{‘message’: “property ‘simhash’: invalid dataType: unknown primitive data type ‘vector’”}]}.\n\nI was able to comment that property, and create the class, however it was working properly.\nI have used python v4 syntax (you are using python v3). Here is what I have done:\nimport weaviate\nclient = weaviate.connect_to_local()\nprint(weaviate.__version__, client.get_meta().get(\"version\"))\n\nschema = {\n  \"classes\": [\n    {\n      \"class\": \"Pack\",\n      \"properties\": [\n        {\n          \"name\": \"pack_name\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"version\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"author\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"website\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"state\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"date\",\n          \"dataType\": [\n            \"date\"\n          ]\n        }\n      ]\n    },\n    {\n      \"class\": \"TextFile\",\n      \"properties\": [\n        {\n          \"name\": \"path_in_pack\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        # {\n        #   \"name\": \"simhash\",\n        #   \"dataType\": [\n        #     \"vector\"\n        #   ]\n        # },\n        {\n          \"name\": \"sequences\",\n          \"dataType\": [\n            \"string[]\"\n          ]\n        },\n        {\n          \"name\": \"belongs_to_pack\",\n          \"dataType\": [\n            \"Pack\"\n          ]\n        },\n        {\n          \"name\": \"md5\",\n          \"dataType\": [\n            \"string\"\n          ]\n        }\n      ],\n      \"vectorIndexConfig\": {\n        \"distance\": \"hamming\"\n      }\n    },\n    {\n      \"class\": \"ImageFile\",\n      \"properties\": [\n        {\n          \"name\": \"md5\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"path_in_pack\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"histogram\",\n          \"dataType\": [\n            \"vector\"\n          ]\n        },\n        {\n          \"name\": \"phash\",\n          \"dataType\": [\n            \"vector\"\n          ]\n        },\n        {\n          \"name\": \"lbp_features\",\n          \"dataType\": [\n            \"vector\"\n          ]\n        },\n        {\n          \"name\": \"belongs_to_pack\",\n          \"dataType\": [\n            \"Pack\"\n          ]\n        }\n      ]\n    },\n    {\n      \"class\": \"AudioFile\",\n      \"properties\": [\n        {\n          \"name\": \"path_in_pack\",\n          \"dataType\": [\n            \"string\"\n          ]\n        },\n        {\n          \"name\": \"belongs_to_pack\",\n          \"dataType\": [\n            \"Pack\"\n          ]\n        },\n        {\n          \"name\": \"md5\",\n          \"dataType\": [\n            \"string\"\n          ]\n        }\n      ]\n    }\n  ]\n}\n\nc = client.collections.create_from_dict(schema[\"classes\"][0])\nc = client.collections.create_from_dict(schema[\"classes\"][1])\n\nwe have now created the first and second classes.\nAnd the property that is a cross reference is correctly created:\ncollection = client.collections.get(\"TextFile\")\nfor p in collection.config.get().references:\n    print(\"----\")\n    print(p)\n\nhere is the output:\n_ReferenceProperty(name='belongs_to_pack', description=None, target_collections=['Pack'])\nLet me know if this hels!\nThanks!",
    "date_created": "2024-09-22T03:25:54.970Z",
    "has_accepted_answer": false,
    "title": "Collection Reference turned into UUID, and couldn't be link",
    "topic_id": 4247
  },
  {
    "user_id": 3165,
    "conversation": "[Sachi_Patankar (2025-01-08T06:21:48.375Z)]: Description\nI have set up weaviate on K8s as per this article.\nI’m trying to send a grpc seach object query on postman, but im getting operation cancelled. I also tried on cloud instance, the req is working fine there\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version: v4\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2025-01-08T14:27:54.656Z)]: hi @Sachi_Patankar !!\nWelcome to our community \nThat doc will not cover on how to expose your Weaviate cluster, because that can be done in a lot of different ways.\nThe easiest way is forwarding the port to your local machine, so you can test and play with it, and a common used is to put it behind a reverse proxy like traefik, and provide TLS/SSL termination.\nI have used traefik but with docker compose here to use Weaviate + SSL. Also, there is a nice GRPCURL examples on how to properly test the grpc endpoint:\nWeaviate with Traefik and gRPC - #3 by DudaNogueira\nLet me know if this helps.",
    "date_created": "2025-01-08T06:21:48.331Z",
    "has_accepted_answer": false,
    "title": "I Have set up weaviate on K8s, but im not able to send any grpc requests from grpc endpt",
    "topic_id": 9619
  },
  {
    "user_id": 1108,
    "conversation": "[dhanshew72 (2024-07-22T22:01:13.270Z)]: Description\nI get the following error message running a batch job to load records into my Weaviate nodes.\nReason: local index \"<INDEX_NAME>\" not found: deadline exceeded for waiting for update: version got=0 want=64\n\nAfter doing some digging I found this on my node:\n{\"got\":0,\"level\":\"debug\",\"msg\":\"wait for update version\",\"time\":\"2024-07-22T21:49:57Z\",\"want\":64}\n\nAny ideas what could be causing this?\nServer Setup Information\n\nWeaviate Server Version: 1.25.8\nDeployment Method: Docker on AWS ECS using Fargate\nMulti Node? Number of Running Nodes: 2\nClient Language and Version: Python 4.6.5\nMultitenancy?: Yes\n\n----------\n\n[dhanshew72 (2024-07-22T22:22:14.650Z)]: Oh, had to increase my timeout time for this. Here’s the config I ended up using:\nweaviate.config.AdditionalConfig(\n            timeout=weaviate.config.Timeout(init=30, query=60, insert=120)\n        )\n\n----------\n\n[DudaNogueira (2024-07-24T14:07:14.150Z)]: Hi!\nCan you share the docker compose you have used?\nAlso, for multi node, it is best to have at least 3 nodes.\n\n----------\n\n[dhanshew72 (2024-07-24T16:17:19.144Z)]: I’m using Services and Task Definitions on AWS ECS so it’s a bit tricky to mimic a Docker compose. I’ll increase the nodes to 3 based on recommendation, but what is the benefit of doing that?\n\n----------\n\n[DudaNogueira (2024-07-24T21:14:00.587Z)]: Hi!\nIt should show on logs, but if not properly configured, it may have a hard time defining the leader in the cluster:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCluster Architecture | Weaviate - Vector Database\n\n  This page describes how the nodes or clusters in Weaviate's replication design behave.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHowever, not sure it would produce the symptoms you had, but wouldn’t work at all.\n\n----------\n\n[dhanshew72 (2024-07-24T21:31:16.093Z)]: Perfect, I’ll dig in and read.",
    "date_created": "2024-07-22T22:01:13.215Z",
    "has_accepted_answer": false,
    "title": "Trouble Batch Inserting Records Using Langchain w/ Weaviate",
    "topic_id": 3124
  },
  {
    "user_id": 952,
    "conversation": "[David_Nguyen (2024-05-17T11:51:16.848Z)]: Do someone has this error to test verba ?\nI build verba from source\nWebSocket Error: Extra data: line 1 column 5 (char 4)\nERROR:    Exception in ASGI application\njson.decoder.JSONDecodeError: Extra data: line 1 column 5 (char 4)\nDuring handling of the above exception, another exception occurred:\nTypeError: Object of type JSONDecodeError is not JSON serializable\n\n----------\n\n[Edward_Schmuhl (2024-05-17T12:48:32.879Z)]: Hey, thanks for the issue!\nWere you able to install from source successfully, or did any errors occur while installation?\nCan you provide more information about when the error occurs? Is it directly on startup of Verba when accessing the site, or is it appearing when querying Verba? Let me know, happy to help!\n\n----------\n\n[David_Nguyen (2024-05-17T13:21:38.946Z)]: Hi,\nI was able to install from source successfully, while installation i had no error.\nThe error occurs when i want to querying, i just say “Hi” for test and below there is a message who tell me “Websocket Connection Offline”\nwhile it used to show “Websocket Online” before I made the query.\nI don’t know if you need more information but tell me if needed  .\nThanks for replying\n\n----------\n\n[warner (2024-05-19T11:24:35.669Z)]: I’d be glad to help you troubleshoot the “WebSocket Error: Extra data” you’re encountering while testing Verba built from source.\nUnderstanding the Error:\n\nWebSocket Error: This indicates an issue with the WebSocket connection, which Verba uses for real-time communication.\nExtra data: This suggests the server received unexpected characters after a valid JSON message.\nJSONDecodeError: The server tried to parse the received data as JSON but encountered invalid formatting.\nTypeError: An attempt was made to serialize (convert) the JSONDecodeError object into JSON, which is not possible.\n\nPotential Causes and Solutions:\n\nIncomplete/Corrupted Data:\n\n\nDouble-check your Verba code to ensure messages are sent as complete, well-formed JSON strings.\nVerify that any intermediate processing steps (e.g., data encoding/decoding) aren’t introducing extra characters.\nConsider using a debugging tool to inspect the raw data being sent over the WebSocket.\n\n\nClient-Side Issues:\n\n\nIf testing from a client application, make sure it’s sending valid JSON messages and handling potential network errors gracefully.\nUse a tool like browser developer console to inspect client-side errors.\n\n----------\n\n[Edward_Schmuhl (2024-05-23T13:09:13.222Z)]: Are you able to ingest documents into Verba?\n\n----------\n\n[Zain_Syed (2024-05-28T20:55:41.059Z)]: Hi,\nI am actually having the same issue. Sorry if this is a simple solution.\nbelow is what I see in the terminal up until the error.\nINFO:     Will watch for changes in these directories: ['/media/zain/Seagate 1TB/rag application/verba']\nINFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [24553] using WatchFiles\nℹ Setting up client\nℹ Using Weaviate Embedded\nStarted /home/zain/.cache/weaviate-embedded: process ID 24558\n{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-05-28T15:47:13-05:00\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-05-28T15:47:13-05:00\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_cache_minilm_OpOxyh0Yh1zs\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":19019}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_cache_ollama_TrbZXem6A3hA\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":17690}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_cache_text2vec_cohere_zoy81ihTCKNg\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":16050}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_cache_text2vec_openai_hW626EysIZbv\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":17140}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_chunk_minilm_PTizXIKxeTt4\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":73039}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_chunk_ollama_D3l7vB6x3M4S\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":25219}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_chunk_text2vec_cohere_G52kMo5c3Sdp\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":17409}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_chunk_text2vec_openai_RZLxs2iHSQNe\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":21040}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_config_7aWR2bffor77\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":22369}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_document_minilm_oBk2EwWpWBxr\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":17559}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_document_ollama_B5TfvXJ3e9Yu\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":32719}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_document_text2vec_cohere_EDJ9loflo0Bi\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":24100}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_document_text2vec_openai_v8nLrQv8CxPb\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":16710}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"verba_suggestion_NnsmZ4qnwRAx\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-28T15:47:13-05:00\",\"took\":17989}\n{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-05-28T15:47:13-05:00\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-05-28T15:47:13-05:00\"}\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:6666\",\"time\":\"2024-05-28T15:47:13-05:00\"}\n✔ Connected to Weaviate\nℹ Setting up components\nℹ Retrieve Config From Weaviate\n✔ Config Saved in Weaviate\nℹ Setting READER to BasicReader\nℹ Setting CHUNKER to TokenChunker\nℹ Setting EMBEDDER to OllamaEmbedder\nℹ Setting RETRIEVER to WindowRetriever\nℹ Setting GENERATOR to Ollama\nℹ Updating BasicReader config (document_type) Research  -> Research\nℹ Updating TokenChunker config (overlap) 50 -> 40\nINFO:     Started server process [24555]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     127.0.0.1:49100 - \"GET / HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:49100 - \"GET /static/media/2b3f1035ed87a788-s.p.woff2 HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49128 - \"GET /static/media/3d9ea938b6afa941-s.p.woff2 HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49142 - \"GET /static/media/c9a5bc6a7c948fb0-s.p.woff2 HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49138 - \"GET /static/media/4049f3f580e14086-s.p.woff2 HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49114 - \"GET /static/css/afc8501c2b22bb29.css HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49156 - \"GET /static/css/7af5f0c0467cb98b.css HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49100 - \"GET /static/chunks/737dfa3e-71fd4aa07f7d84a6.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49138 - \"GET /static/chunks/23-5e3f67a9ac794630.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49142 - \"GET /static/chunks/main-app-6d8fe3bc29305481.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49114 - \"GET /static/chunks/fd9d1056-13318e87e7edaf08.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49156 - \"GET /static/chunks/webpack-f7ec7a24106fdb21.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49128 - \"GET /static/chunks/bc9c3264-d07564fa5e9c78e4.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49128 - \"GET /static/chunks/ec3863c0-51ee858d5ca1a7f6.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49114 - \"GET /static/chunks/39aecf79-4a889f14de9b85cb.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49156 - \"GET /static/chunks/12038df7-6e0eda258325d644.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49142 - \"GET /static/chunks/93854f56-29cce777bbb44957.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49100 - \"GET /static/chunks/3627521c-57ae5a9df6c7e5b9.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49138 - \"GET /static/chunks/9081a741-61a1020146c5d975.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49138 - \"GET /static/chunks/558-ac85fa7667d15ac6.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49100 - \"GET /static/chunks/app/page-a9dac4e4664785de.js HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49100 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:49138 - \"GET /icon.ico HTTP/1.1\" 304 Not Modified\nINFO:     127.0.0.1:49138 - \"GET /api/health HTTP/1.1\" 200 OK\nℹ Config Retrieved\nINFO:     127.0.0.1:49138 - \"GET /api/config HTTP/1.1\" 200 OK\nINFO:     ('127.0.0.1', 49168) - \"WebSocket /ws/generate_stream\" [accepted]\n✔ Config Saved in Weaviate\nℹ Setting READER to BasicReader\nℹ Setting CHUNKER to TokenChunker\nℹ Setting EMBEDDER to OllamaEmbedder\nℹ Setting RETRIEVER to WindowRetriever\nℹ Setting GENERATOR to Ollama\nINFO:     127.0.0.1:49138 - \"POST /api/set_config HTTP/1.1\" 200 OK\nINFO:     connection open\n⚠ WebSocket connection closed by client.\nINFO:     connection closed\n✔ Config Saved in Weaviate\nℹ Setting READER to BasicReader\nℹ Setting CHUNKER to TokenChunker\nℹ Setting EMBEDDER to OllamaEmbedder\nℹ Setting RETRIEVER to WindowRetriever\nℹ Setting GENERATOR to Ollama\nℹ Loading in cureus-0015-00000035077.pdf\n✔ Loaded 1 documents in 0.63s\nChunking documents: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 195.01it/s]\n✔ Chunking completed with 224 chunks in 0.01s\nVectorizing Chunks:   0%|                                                                                                                                                                                                                                   | 0/224 [00:00<?, ?it/s]\nVectorizing document chunks:   0%|                                                                                                                                                                                                                            | 0/1 [00:00<?, ?it/s]\nINFO:     127.0.0.1:53612 - \"POST /api/import HTTP/1.1\" 200 OK\n\nMy .env file has\nOLLAMA_URL=http://localhost:11434/\nOLLAMA_MODEL=llama3\nOLLAMA_EMBED_MODEL=mxbai-embed-large\nscreencapture-localhost-8000-2024-05-28-15_52_591920×973 89.3 KB\n\n----------\n\n[Daniel_Hangan (2024-08-08T10:45:33.009Z)]: experiencing the same issue as @Zain_Syed",
    "date_created": "2024-05-17T11:51:16.803Z",
    "has_accepted_answer": false,
    "title": "Error WebSocket Error: Extra data: line 1 column 5 (char 4)",
    "topic_id": 2369
  },
  {
    "user_id": 3004,
    "conversation": "[chris31522 (2024-12-12T09:45:07.071Z)]: i already have the text2vec and multi2vec modules, why the result shows  dont have the nearText option when i use it to query\nimage1496×247 24.1 KB\n\n----------\n\n[Mohamed_Shahin (2024-12-12T10:09:39.741Z)]: Hello @chris31522 \nWelcome to our community! We’re glad to have you here.\nThe error you’re encountering suggests there may be an issue with the vectorizer configuration—either it isn’t being recognized, or the collection might have been created without specifying a vectorizer.\nCould you please share the following details with me so I can help you further:\n\nYour Weaviate version\nThe deployment details\nThe code you’re using for vectorizer configuration & Creating the schema\n\nThis will help me pinpoint where the issue might be coming from.\nBest regards,\nMohamed Shahin\nWeaviate Support Engineer\n\n----------\n\n[chris31522 (2024-12-12T10:46:11.552Z)]: thanks for the help!\n\nschema = {\n    \"classes\": [\n        {\n            \"class\": \"Article\", # name of the class\n            \"description\": \"An Article class to store the article summary and its authors\", # a description of what this class represents\n            \"properties\": [ # class properties\n                {\n                    \"name\": \"title\",\n                    \"dataType\": [\"string\"],\n                    \"description\": \"The title of the article\", \n                },\n                {\n                    \"name\": \"summary\",\n                    \"dataType\": [\"text\"],\n                    \"description\": \"The summary of the article\",\n                },\n                {\n                    \"name\": \"wordCount\",\n                    \"dataType\": [\"int\"],\n                    \"description\": \"The number of words in the article's summary\",\n                },\n                {\n                    \"name\": \"hasAuthors\",\n                    \"dataType\": [\"Author\"],\n                    \"description\": \"The authors this article has\",\n                },\n                {\n                    \"name\": \"hasCategory\",\n                    \"dataType\": [\"Category\"],\n                    \"description\": \"The category of this article\",\n                }\n            ]\n        }, {\n            # Write the Author class here\n            \"class\": \"Author\", \n            \"description\": \"An Author class to store the author's name and the articles who wrote\", \n            \"properties\": [\n                {\n                    \"name\": \"name\",\n                    \"dataType\": [\"string\"],\n                    \"description\": \"The name of the author\", \n                },\n                {\n                    \"name\": \"wroteArticles\",\n                    \"dataType\": [\"Article\"],\n                    \"description\": \"The articles this author has\",\n                }\n            ]\n        }, {\n            # Write the Category class here\n            \"class\":\"Category\",\n            \"description\":\"A Category class to store the category that article belongs to\",\n            \"properties\":[\n                {\n                    \"name\":\"name\",\n                    \"dataType\":[\"string\"],\n                    \"description\":\"the name of the category\"\n                }\n            ]\n        }\n\n ]\n}\n\nthis is the schema and i download the news from the cnn.com as my data\nimport newspaper\nimport uuid\nimport json\nfrom tqdm import tqdm\n\ndef get_articles_from_newspaper(\n        news_url: str, \n        max_articles: int=100\n    ) -> None:\n    \"\"\"\n    Download and save newspaper articles as weaviate schemas.\n    Parameters\n    ----------\n    newspaper_url : str\n        Newspaper title.\n    \"\"\"\n    \n    objects = []\n    \n    # Build the actual newspaper    \n    news_builder = newspaper.build(news_url, memoize_articles=False)\n    \n    if max_articles > news_builder.size():\n        max_articles = news_builder.size()\n    pbar = tqdm(total=max_articles)\n    pbar.set_description(f\"{news_url}\")\n    i = 0\n    while len(objects) < max_articles and i < news_builder.size():\n        article = news_builder.articles[i]\n        try:\n            article.download()\n            article.parse()\n            article.nlp()\n\n            if (article.title != '' and \\\n                article.title is not None and \\\n                article.summary != '' and \\\n                article.summary is not None and\\\n                article.authors):\n\n                # create an UUID for the article using its URL\n                article_id = uuid.uuid3(uuid.NAMESPACE_DNS, article.url)\n\n                # create the object\n                objects.append({\n                    'id': str(article_id),\n                    'title': article.title,\n                    'summary': article.summary,\n                    'authors': article.authors,\n                    'word_count': len(article.summary.split())\n                })\n                \n                pbar.update(1)\n\n        except:\n            # something went wrong with getting the article, ignore it\n            pass\n        i += 1\n    pbar.close()\n    return objects\n\ndata = []\ndata += get_articles_from_newspaper('http://cnn.com')\n\nand then i upload my data\nfrom weaviate.batch import Batch # for the typing purposes\nfrom weaviate.util import generate_uuid5\n\n\ndef add_article(batch: Batch, article_data: dict) -> str:\n    \n    article_object = {\n        'title': article_data['title'],\n        'wordCount': article_data['word_count'],\n        'summary': article_data['summary'].replace('\\n', '') # remove newline character\n    }\n    article_id = article_data['id']\n    \n    # add article to the batch\n    batch.add_data_object( \n        data_object=article_object,\n        class_name='Article',\n        uuid=article_id\n    )\n    \n    return article_id\n\ndef add_author(batch: Batch, author_name: str) -> str:\n    \n    author_object = {'name': author_name}\n\n    # generate an UUID for the Author\n    author_id = generate_uuid5(author_name)\n    \n    # add author to the batch\n    # EXERCISE: call here the batch.add_data_object function to add the author to the batch\n    batch.add_data_object( \n        data_object=author_object,\n        class_name='Author',\n        uuid=author_id\n    )\n    \n    return author_id\n\ndef add_references(batch: Batch, article_id: str, author_id: str)-> None:\n    # add references to the batch\n    ## Author -> Article\n    batch.add_reference(\n        from_object_uuid=author_id,\n        from_object_class_name='Author',\n        from_property_name='wroteArticles',\n        to_object_uuid=article_id\n    )\n    \n    ## Article -> Author \n    # EXERCISE: call here the batch.add_reference function to add the article->author reference\n    batch.add_reference(\n        from_object_uuid=article_id,\n        from_object_class_name='Article',\n        from_property_name='hasAuthors',\n        to_object_uuid=author_id\n    )\nclient.batch.configure(batch_size=50, dynamic=True, callback=None)\nwith client.batch as batch:\n\n    for i in data:\n\n        # add article to the batch\n        article_id = add_article(batch, i)\n\n        for author in i['authors']:\n\n            # add author to the batch\n            author_id = add_author(batch, author)\n\n            # add cross references to the batch\n            add_references(batch, article_id=article_id, author_id=author_id)\n\n----------\n\n[Mohamed_Shahin (2024-12-12T12:10:35.036Z)]: Hi @chris31522,\nThank you so much for sharing this information — it’s really helpful! I’ve taken a look, and I can see that the issue is to the fact that a vectorizer hasn’t been specified in your schema ‘vectorizer’.\nHere’s an example of how you can add a vectorizer - in the deprecated client:\n\nclass_obj = {\n“class”: “Article”,\n“properties”: [\n{\n“name”: “title”,\n“dataType”: [“text”],\n},\n],\n“vectorizer”: “text2vec-openai”  # This can be any vectorizer of your choice\nclient.schema.create_class(class_obj)\n}\n\nAdditionally, you’re using an old version of the client / deprecated, which is making things a bit more complicated for you. I highly recommend upgrading to Python Client v4. This version offers friendly syntax and better performance, making it much easier to work with.\nHere is how easy you can specify vectorizer in V4:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage collections | Weaviate\n\n  Every object in Weaviate belongs to exactly one collection. Use the examples on this page to manage your collections.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nHere’s what I recommend for your use case:\n\n\nRemove the current schema.\n\n\nUpgrade your Weaviate Client locally by running the following: pip install -U weaviate-client\n\n\nRecreate the schema using the updated syntax (including the vectorizer) - see below:\n\n\n\nfrom weaviate.classes.config import Configure, Property, DataType\nclient.collections.create(\n“Article”,\nvectorizer_config=Configure.Vectorizer.text2vec_openai(),\nproperties=[  # This part is optional, depending on your needs\nProperty(name=“title”, data_type=DataType.TEXT),\nProperty(name=“body”, data_type=DataType.TEXT),\n]\n)\n\nAs you can see, the new syntax is much more user-friendly and easier compared to the old version!\n\nIngest data using the batch method in v4 — you’ll find it much faster and easier.\n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Utilize the Python client library to access Weaviate and streamline data processes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nOne of the main benefits of using the v4 client is that uses a gRPC interface.  It is based on HTTP/2 and Protocol Buffers, and is therefore very fast and efficient.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\ngRPC | Weaviate\n\n  Integrate gRPC API with Weaviate for efficient data access.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nI hope this helps! If you have any questions or need further assistance, don’t hesitate to reach out — I’m here to help.\nBest regards,\nMohamed Shahin\nWeaviate Support Engineer\n\n----------\n\n[Mohamed_Shahin (2024-12-12T12:52:27.095Z)]: Hi @chris31522,\nI was curious to know why you opted for the v3 client, as it’s an older version. Were you following a specific tutorial or guide? If so, I’d be happy to assist in updating it to the latest version (v4).\nBest regards,\nMohamed Shahin\nWeaviate Support\n\n----------\n\n[chris31522 (2024-12-13T06:59:10.954Z)]: i tried your solution,but there is a new problem:(\ni can’t upload my data successfully and the query result is empty! Before I change my code, it can be upload successfully…\nimage1510×272 10.4 KB\n\n----------\n\n[Mohamed_Shahin (2024-12-13T07:39:10.659Z)]: Hi @chris31522,\nCould you please share the code you used to create the collection? and I’ll help you with that.\nBest regards,\nMohamed Shahin,\nWeaviate Support Engineer\n\n----------\n\n[chris31522 (2024-12-13T08:02:51.120Z)]: it seems like the collection are created automatically,here is the detail of a collection\nimage1210×967 47.8 KB\n\n----------\n\n[Mohamed_Shahin (2024-12-13T15:03:42.516Z)]: Hi @chris31522,\nCould you please share the scripts you used to create the collection and ingest data? This will help me better understand the configuration and pinpoint the issue.\nAdditionally, could you provide the Sandbox URL you’re working with?\nBest regards,\nMohamed Shahin\nWeaviate Support",
    "date_created": "2024-12-12T09:45:06.997Z",
    "has_accepted_answer": false,
    "title": "nearText operaion isn't work",
    "topic_id": 9201
  },
  {
    "user_id": 1302,
    "conversation": "[wvuser (2024-11-29T05:32:57.418Z)]: Description\nWe have a K8s cluster with 3 servers and 3 pods (1 pod per server).\nWeaviate has 20mln objects (2 named vectors per object: 1024 and 768).\nAll requests (set of CRUD+vectors-search operations) executed with QUORUM concistency level.\nWith 3 active (READY) pods we have a total performance with ~380RPS.\nWhen downscaling cluster to 2 pods (“weaviate-2” goes away), cluster’s performance returns to same.\nUpscaling cluster back to 3 pods (“weaviate-2” returns) make performance dropping to ~160RPS… on period while pod loading data/index (not in READY state).\nCan’t see any CRUD/search requests in weaviate-2’s logs.\nWhen “weaviate-2’s” loading finished (became READY), performance returns to normal ~380RPS.\ndownscale_to_21442×1127 85.1 KB\nServer Setup Information\n\nWeaviate Server Version: 1.25.25\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: yes, 3 nodes, repl.factor=3\nClient Language and Version: Python-3, weaviate-client-4.6.2\nMultitenancy?: no\n\nAny additional Information\nDISABLE_LAZY_LOAD_SHARDS=true\nHNSW_STARTUP_WAIT_FOR_VECTOR_CACHE=true\n\n----------\n\n[DudaNogueira (2024-11-29T10:11:38.001Z)]: hi @wvuser !!\nA lot has changed since 1.25, so if possible, I would suggest you to upgrade to latest version.\nCan you see any logs while doing those changes?\n\n----------\n\n[wvuser (2024-12-19T09:42:53.569Z)]: Hi @DudaNogueira !\nSorry for the long absence…\nWhat LOG_LEVEL minimum value do you recommend/require?\nThe logs (from all PODs) will be large because with a ‘light load’ the performance drop is not so visible.",
    "date_created": "2024-11-29T05:32:57.363Z",
    "has_accepted_answer": false,
    "title": "Catastrophic performance drop when upscaling a cluster - while pod not in READY state (loading data/index)",
    "topic_id": 8861
  },
  {
    "user_id": 1332,
    "conversation": "[Fakhri_Prayatna_Putr (2024-08-22T08:31:58.835Z)]: Hi all,\nI currently have a problem using near_text with reference\nI want to match my query with the reference chunk I have for example\nresponse = building_collection.query.near_text(\n                query=\"Green garden city\",\n                target_vector=\"buildingDetails\", // namedVector in chunk class\n                filters=Filter.all_of(filter_array) if len(filter_array) > 0 else None,\n                limit=limit,\n                offset=offset,\n                return_references=[\n                    QueryReference(\n                        include_vector=True,\n                        link_on=\"hasChunks\"\n                    ),\n                ],\n            )\n\nthis is my class definition\ndef create_buildings_vectordb_schema(client: WeaviateClient, logger: LoggerInterface) -> None:\n    collection_name = BUILDINGS_COLLECTION_NAME    \n    if not client.collections.exists(collection_name):\n        new_collection = client.collections.create(\n            name=collection_name,\n            properties=[\n                wvc.config.Property(\n                    name=\"buildingTitle\",\n                    data_type=wvc.config.DataType.TEXT,\n                    vectorize_property_name=False,\n                    skip_vectorization=True\n                ),\n                wvc.config.Property(\n                    name=\"buildingAddress\",\n                    data_type=wvc.config.DataType.TEXT,\n                    vectorize_property_name=False,\n                    skip_vectorization=True\n                ),\n                wvc.config.Property(\n                    name=\"buildingDescription\",\n                    data_type=wvc.config.DataType.TEXT,\n                    vectorize_property_name=False,\n                    skip_vectorization=True\n                ),\n                wvc.config.Property(\n                    name=\"housingPrice\",\n                    data_type=wvc.config.DataType.NUMBER,\n                    vectorize_property_name=False,\n                    skip_vectorization=True\n                ),\n                wvc.config.Property(\n                    name=\"ownerName\",\n                    data_type=wvc.config.DataType.TEXT,\n                    vectorize_property_name=False,\n                    skip_vectorization=True\n                ),\n                wvc.config.Property(\n                    name=\"ownerEmail\",\n                    data_type=wvc.config.DataType.TEXT,\n                    vectorize_property_name=False,\n                    skip_vectorization=True\n                ),\n                wvc.config.Property(\n                    name=\"ownerWhatsapp\",\n                    data_type=wvc.config.DataType.TEXT,\n                    vectorize_property_name=False,\n                    skip_vectorization=True\n                ),\n                wvc.config.Property(\n                    name=\"ownerPhoneNumber\",\n                    data_type=wvc.config.DataType.TEXT,\n                    vectorize_property_name=False,\n                    skip_vectorization=True\n                ),\n                wvc.config.Property(\n                    name=\"imageURL\",\n                    data_type=wvc.config.DataType.TEXT,\n                    vectorize_property_name=False,\n                    skip_vectorization=True\n                ),\n            ]\n        )\n        \n        logger.log_info(f\"Successfully create collection: {new_collection}\")\n\nthis is my class chunk definition\ndef create_building_chunks_vectordb_schema(client: WeaviateClient, logger: LoggerInterface) -> None:\n    collection_name = BUILDING_CHUNKS_COLLECTION_NAME  \n    if not client.collections.exists(collection_name):\n        new_collection = client.collections.create(\n            name=collection_name,\n            vectorizer_config=define_transformers(),\n            generative_config=define_generative(),\n            properties=[\n                wvc.config.Property(\n                    name=\"chunk\",\n                    data_type=wvc.config.DataType.TEXT,\n                    tokenization=wvc.config.Tokenization.WORD,\n                ),\n            ],\n        )\n        \n        # the parent class collection\n        building_collection = client.collections.get(BUILDINGS_COLLECTION_NAME)\n        building_collection.config.add_reference(\n            wvc.config.ReferenceProperty(\n                name=\"hasChunks\",\n                target_collection=BUILDING_CHUNKS_COLLECTION_NAME\n            )\n        )\n        logger.log_info(f\"Successfully create collection: {new_collection}\")\n\nI have one chunk that has value of “This building located near Green garden city”, but the query result is not even similar at all\nI actually tried to do the query from the chunk collection, it works but I need 2 or more reference similarity so I can perform query like, “Near Green garden and has maid cafe in it”\nim sorry if this is confusing but I hope I get some enlightenment thanks\n\n----------\n\n[DudaNogueira (2024-08-29T19:23:40.312Z)]: hi @Fakhri_Prayatna_Putr !!! Welcome to our community \nHave you tried hybrid search instead?\nOn those cases, I believe a hybrid search with fit better, and you do want some similarity search, but have a key word of interest too.\nLet me know if this helps!\n\n----------\n\n[Fakhri_Prayatna_Putr (2024-08-31T06:48:59.015Z)]: so we can’t query the reference? cause that would be awesome if i can query the reference aswell instead of only having filter by reference, and also by for example if the references got similarity match, it also give the total similarity score to the parent class based on how similar the reference queried\ni actually also querying it by hybrid but i think that’s not the case\n\n----------\n\n[Fakhri_Prayatna_Putr (2024-09-24T08:17:48.938Z)]: hi is there any way for this?",
    "date_created": "2024-08-22T08:31:58.783Z",
    "has_accepted_answer": false,
    "title": "How do I match reference with near_text or hybrid",
    "topic_id": 3431
  },
  {
    "user_id": 11848,
    "conversation": "[louisja1 (2025-03-28T15:42:12.725Z)]: Description\n\nServer Setup Information\n\nWeaviate Server Version: Weaviate Cloud\nDeployment Method: Weaviate Cloud\nMulti Node? Number of Running Nodes: 1\nClient Language and Version: python connector 4.11.2\nMultitenancy?:\n\nAny additional Information\n\nWe are populating our own vector databases into Weaviate Cloud and using a python connector to query against it. Is there a way to monitor the process and extract more information like querying time?\nThere is a Monitoring module by Prometheus, but is it possible to set it up on Weaviate Cloud?\n\n----------\n\n[DudaNogueira (2025-03-28T19:02:31.721Z)]: hi @louisja1 !!\nWelcome to our community \nWe do not expose those informations for our serverless cluster yet.\nExposing prometheus metrics directly can be done for enterprise and bring your own cloud plans.\nIt is important to note that all clusters hosted in our cloud are actively auto scaled and monitored by our team 24/7.\nIf you ever need any help, or for example, you know you are going to ingest a lot of data in a short period of time, you can reach us at any time by opening a support ticket.\nWe can then provision your cluster with the necessary resource so the first import runs smoothly.\nLet me know if that helps!\nThanks!\n\n----------\n\n[louisja1 (2025-03-28T20:01:47.452Z)]: Is there an easy way to get the query time without accounting round-trip network overhead between our machine and Weaviate cloud?\n\n----------\n\n[DudaNogueira (2025-03-31T14:01:51.564Z)]: hi @louisja1 !!\nFor that you would need to run a pod inside the cluster and do the query.\nOr, replicate the dataset on a local/on-prem cluster and run the query against it.\nSo this is possible for serverless, but It can certainly be done for bring your own cloud plans, as you have access to your cluster.\nLet me know if that helps!\nThanks!",
    "date_created": "2025-03-28T15:42:12.673Z",
    "has_accepted_answer": false,
    "title": "Monitoring Query Performance on Weaviate Cloud",
    "topic_id": 20366
  },
  {
    "user_id": 1281,
    "conversation": "[Tejas_Sharma (2024-12-11T18:13:28.929Z)]: Description\nI’m syncing in a user’s emails but sometimes the user may add the same entire email list twice. As a counter measure, I can do this to check if the email with this title exists:\nquery_result = tenant_collection.query.fetch_objects(\n\t\t\tfilters=Filter.by_property(\"title\").equal(email_title) & Filter.by_property(\"recordType\").equal(\"email\"),\n\t\t\tinclude_vector=True,\n\t\t\tlimit=top_k\n\t\t)\n\nHowever, this could be done on thousands of emails sequentially. Is this an expensive operation?\nI’m using the hosted Weaviate serverless instance.\nServer Setup Information\n\nWeaviate Server Version: Serverless\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?: Yes\n\nAny additional Information",
    "date_created": "2024-12-11T18:13:28.886Z",
    "has_accepted_answer": false,
    "title": "How expensive is the filter by property for a string operation?",
    "topic_id": 9195
  },
  {
    "user_id": 219,
    "conversation": "[JLiz2803 (2025-01-24T05:26:37.564Z)]: Description\nHi we have a use case where we are creating thousands of tenants.  When we initially did this Weaviate started choking because it was holding too many tenant files in memory.  Given this we were instructed to move our tenant states out of the HOT status.  So now when a new tenant comes through we will create them, flip their status to HOT save data into the tenant, and flip their status to COLD.  When we need to query the tenant, which is sparingly we will flip the tenant to HOT, run our query, and then flip them back to COLD.  However, we are now getting the following error message for a little over half of our tenants\nUpdate classes tenants! Unexpected status code: 401, with response body: {'message': 'Unauthorized'}\n\nOur setup anonymous access enabled so we should never see this error from Weaviate, and it only seems to happen when we are updating the status of multiple tenants in parallel.  If I go back and retry the updating of the tenants one by one they will pass, but when it is happening at scale weaviate throws the error.  Upon looking through the kubernetes pod logs it throws a shard not found error.\n{\"build_git_commit\":\"9069628\",\"build_go_version\":\"go1.22.10\",\"build_image_tag\":\"v1.28.0\",\"build_wv_version\":\"1.28.0\",\"cmd_class\":\"Contractexcellence\",\"cmd_type\":17,\"cmd_type_name\":\"TYPE_UPDATE_TENANT\",\"error\":\"updating schema: TYPE_UPDATE_TENANT: shard not found: [a5b556a195816880939bbc2d4bf9d37a24c3c654db564de633b648bfc16beaeb]\",\"level\":\"error\",\"log_index\":54947,\"log_name\":\"LogCommand\",\"log_type\":0,\"msg\":\"apply command\",\"time\":\"2025-01-24T06:07:13Z\"}\n\nAny suggestions or guidance on how to solve this issue or why it is happening at all would be greatly appreciated.\nServer Setup Information\n\nWeaviate Server Version: 1.28.0\nDeployment Method: AWS EKS Fargate instance backed by EFS\nMulti Node? Number of Running Nodes:  1\nClient Language and Version: python V3\nMultitenancy?: Yes\n\nAny additional Information\n\n----------\n\n[Dirk (2025-01-24T08:17:28.432Z)]: Hello, could you try again with v1.28.4? We recently refactored our error handling a bit and found a couple cases where a wrong error type was returned.\nThis will most likely not solve it, but return the correct error which might have more pointers",
    "date_created": "2025-01-24T05:26:37.518Z",
    "has_accepted_answer": false,
    "title": "401 Unauthorized When Anonymous Access Enabled",
    "topic_id": 9876
  },
  {
    "user_id": 3328,
    "conversation": "[Rodney_Puplampu (2025-02-07T16:17:00.752Z)]: Description\n\nI am trying to deploy Verba via a docker on a debian server.\nit fails with this:\nFailed to establish a new connection: [Errno -3] Temporary failure in name resolution’)':\n=> => #  /simple/weaviate-client/\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: Docker-Verba+Ollama \nMulti Node? No Number of Running Nodes:\nClient Language and Version:  Python 3.11\nMultitenancy?:\nNo\n\nAny additional Information\n\nNOTE:  I have Ollama up and working on the local machine, the same machine I am trying to run the verba docker.\n=> => # d0037590>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution’)‘:\n=> => #  /simple/weaviate-client/\n=> => # WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connec\n=> => # tion broken by ‘NewConnectionError(’<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f1d\n=> => # d0035750>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution’)':\n=> => #  /simple/weaviate-client/\n\nI verified my variables are set.\nand Here is my docker-compose.yml file content\n\ndocker-compose.yml\n\nservices:\nverba:\nbuild:\ncontext: ./\ndockerfile: Dockerfile\nports:\n- 8000:8000\nenvironment:\n- WEAVIATE_URL_VERBA=localhost:8000\n- OLLAMA_URL=localhost:11434\n- OLLAMA_MODEL=$OLLAMA_MODEL\n- UNSTRUCTURED_API_KEY=$UNSTRUCTURED_API_KEY\n- UNSTRUCTURED_API_URL=$UNSTRUCTURED_API_URL\nvolumes:\n  - ./data:/data/\ndepends_on:\n  weaviate:\n    condition: service_healthy\nhealthcheck:\n  test: wget --no-verbose --tries=3 --spider http://localhost:8000 || exit 1\n  interval: 5s\n  timeout: 10s\n  retries: 5\n  start_period: 10s\nnetworks:\n  - ollama-docker\n\nweaviate:\ncommand:\n- --host\n- 0.0.0.0\n- --port\n- ‘8080’\n- --scheme\n- http\nimage: semitechnologies/weaviate:1.25.10\nports:\n- 8080:8080\n- 3000:8080\nvolumes:\n- weaviate_data:/var/lib/weaviate\nrestart: on-failure:0\nhealthcheck:\ntest: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\ninterval: 5s\ntimeout: 10s\nretries: 5\nstart_period: 10s\nenvironment:\nOPENAI_APIKEY: $OPENAI_API_KEY\nCOHERE_APIKEY: $COHERE_API_KEY\nQUERY_DEFAULTS_LIMIT: 25\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: ‘true’\nPERSISTENCE_DATA_PATH: ‘/var/lib/weaviate’\nENABLE_MODULES: ‘e’\nCLUSTER_HOSTNAME: ‘node1’\nnetworks:\n- ollama-docker\nUncomment to use Ollama within the same docker compose\nollama:\nimage: ollama/ollama:latest\nports:\n- 7869:11434\nvolumes:\n- .:/code\n- ./ollama/ollama:/root/.ollama\ncontainer_name: ollama\npull_policy: always\ntty: true\nrestart: always\nenvironment:\n- OLLAMA_KEEP_ALIVE=24h\n- OLLAMA_HOST=0.0.0.0\nnetworks:\n- ollama-docker\nvolumes:\nweaviate_data: {}\nnetworks:\nollama-docker:\nexternal: false\n\n----------\n\n[Rodney_Puplampu (2025-02-09T16:56:57.756Z)]: I successfully installed from source.\n\n----------\n\n[DudaNogueira (2025-02-10T21:08:40.836Z)]: hi @Rodney_Puplampu !!\nThanks for sharing!\nWe provide a docker image here:\nhttps://hub.docker.com/r/semitechnologies/verba\nSo o need to build it",
    "date_created": "2025-02-07T16:17:00.692Z",
    "has_accepted_answer": true,
    "title": "Verba Docker installation on Debian",
    "topic_id": 10040
  },
  {
    "user_id": 513,
    "conversation": "[rjalex (2024-05-21T07:16:58.187Z)]: I am writing an exploratory program using connect_to_embedded()\nIn my program I have a few print statements to follow the logic but they are drowned amidst a deluge of messages such as the following:\n{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-05-21T09:12:06+02:00\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-05-21T09:12:06+02:00\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-05-21T09:12:06+02:00\"}\n{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-05-21T09:12:06+02:00\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-05-21T09:12:06+02:00\"}\n{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-05-21T09:12:06+02:00\"}\n\nHow to I control/filter them? Thank you\n\n----------\n\n[DaveCuthbert (2024-05-21T13:47:58.712Z)]: Hello @rjalex -\nThanks for your question, have you tried to pipe the system messages on STDERR to /dev/null or another file?\nHere’s a link to the embedded docs: [link]\nIt looks like this:\npython3 your_embedded_client_script.py 2>/dev/null\n\n----------\n\n[Guillermo_Ripa (2024-08-27T21:01:33.493Z)]: I did this to reduce messages.\nweaviate.connect_to_embedded(\n...,\nenvironment_variables={ \"LOG_LEVEL\": \"error\"}\n)\n\nYou can also use a warnings context manager to wrap your code and suppress weaviate messages\nimport warnings\nimport weaviate\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", module=\"weaviate\")\n    client = weaviate.connect_to_embedded(...",
    "date_created": "2024-05-21T07:16:58.135Z",
    "has_accepted_answer": false,
    "title": "How to inhibit weaviate embedded messages?",
    "topic_id": 2395
  },
  {
    "user_id": 1155,
    "conversation": "[pon_raj (2024-07-11T18:14:53.695Z)]: Thank for all your help and I am at the final step to get the generative search working. As I am going through the document at Generative Search - OpenAI | Weaviate - Vector Database, I understand that weaviate will work only with openAI and OPENAI_API_KEY. Is that right?\nWe have locally hosted (within the firewall) LLM with front-ended REST API with basic authentication.\nFor an example, the following API call works:\nprompt=’{“inputs”: “What is Docker?”}’\ncurl –silent –output -X POST $URL -H “Authentication Basic $BASIC_AUTH” -H “Content-Type: application-json” –data “$prompt”\nWhere URL is https:///gpt/api/v1/models/Llama-2-70b-chat-hf/generate\nIs there a way in weaviate configuration to set the internal REST API URL and BASIC_AUTH while using generative search?\nSo far, I have been successful in hosting weaviate on OpenShift and loading data using text2vec-contextionary, and querying the data. Now I am trying to call the internally hosted REST API (LLM) with basic_auth to send the prompt and weaviate query result.\nPlease let me know how to accomplish this last step with Weaviate.\nThanks.\n\n----------\n\n[DudaNogueira (2024-07-11T20:18:31.102Z)]: hi @pon_raj !!\nI believe this is a case of crafting a custom module \n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nCustom modules | Weaviate - Vector Database\n\n  Introduction\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYou can override the baseurl for openai modules (check here the code) but not sure on the basic auth part.\nAlso, that would mean that if initializing the client with a different base url, it would replace both for text2vec-openai and generative.\n\n----------\n\n[pon_raj (2024-07-15T12:06:23.197Z)]: Thank you for the helpful advice. I will give a try.",
    "date_created": "2024-07-11T18:14:53.649Z",
    "has_accepted_answer": true,
    "title": "How to use Generative Search with locally hosted LLM (within the firewall) and front-ended with REST API with basic authentication?",
    "topic_id": 3021
  },
  {
    "user_id": 3185,
    "conversation": "[AnnTade (2025-01-22T00:33:53.333Z)]: I have a cluster of weaviate nodes setup on openstack. I am able to connect to it using weaviate-client v4, using connect_to_custom() function, by specifying http port & host, as well as gRPC port and host.\nIt passes the “if client.is_connected() check” successfully so I assume the connection is established.\nHowever, when i try to batch insert into it like this\nScreenshot 2025-01-22 at 4.31.07 AM1648×606 26.3 KB\nI am getting the following error. What is the issue?\n‘message’: ‘Failed to send all objects in a batch of 48’, ‘error’: ‘WeaviateBatchError('Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.UNAVAILABLE\\n\\tdetails = “failed to connect to all addresses; last error: UNKNOWN: ipv4:1<MY_IP_HERE>:50051: Ssl handshake failed (TSI_PROTOCOL_FAILURE): SSL_ERROR_SSL: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER: Invalid certificate verification context”\\n\\tdebug_error_string = “UNKNOWN:Error received from peer {created_time:“2025-01-22T00:06:53.099332986+00:00”, grpc_status:14, grpc_message:“failed to connect to all addresses; last error: UNKNOWN: ipv4:<MY_IP_HERE>:50051: Ssl handshake failed (TSI_PROTOCOL_FAILURE): SSL_ERROR_SSL: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER: Invalid certificate verification context”}”\\n>.')’}\n{‘message’: ‘Failed to send 48 objects in a batch of 48. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\n{‘message’: ‘Failed to send all objects in a batch of 48’, ‘error’: ‘WeaviateBatchError('Query call with protocol GRPC batch failed with message <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.UNAVAILABLE\\n\\tdetails = “failed to connect to all addresses; last error: UNKNOWN: ipv4:<MY_IP_HERE>:50051: Ssl handshake failed (TSI_PROTOCOL_FAILURE): SSL_ERROR_SSL: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER: Invalid certificate verification context”\\n\\tdebug_error_string = “UNKNOWN:Error received from peer {created_time:“2025-01-22T00:06:53.099347418+00:00”, grpc_status:14, grpc_message:“failed to connect to all addresses; last error: UNKNOWN: ipv4:<MY_IP_HERE>50051: Ssl handshake failed (TSI_PROTOCOL_FAILURE): SSL_ERROR_SSL: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER: Invalid certificate verification context”}”\\n>.')’}\n{‘message’: ‘Failed to send 4 objects in a batch of 4. Please inspect client.batch.failed_objects or collection.batch.failed_objects for the failed objects.’}\n\n----------\n\n[Mohamed_Shahin (2025-01-22T14:00:17.095Z)]: Hello @AnnTade,\nCould you please share with me your connection method, batch method in full, and a sample of the object? Also, could you confirm the full server version and full client version you are using? This information will help me replicate the issue.\nPrint out details about any failed objects during your batch operations:\nfailed_objects = client.batch.failed_objects\nif failed_objects:\n    print(f\"Number of failed objects: {len(failed_objects)}\")\n    for i, failed_obj in enumerate(failed_objects, 1):\n        print(f\"Failed object {i}: {failed_obj}\")\nelse:\n    print(f\"All objects successfully inserted into '{collection_name}'.\")\n\nBest regards,\nMohamed Shahin\nWeaviate Support",
    "date_created": "2025-01-22T00:33:53.278Z",
    "has_accepted_answer": false,
    "title": "gRPC failed due to SSL handshake failure using v4",
    "topic_id": 9844
  },
  {
    "user_id": 2333,
    "conversation": "[jlee (2024-10-28T22:41:32.106Z)]: Description\n\nI’m currently investigating some discrepancies in behaviors between Weaviate’s implementation of a pure vector similiarity search using HNSW + cosine distance metrics (e.g. the defaults according to docs) and a rival database (Redis) using a 3rd party integration library (LangChain).\nI just wanted to confirm Weaviate’s baked-in behavior utilizing the text2VecCohere integrations described here for managing Cohere embedding API calls.\nCould someone confirm that input_type is correctly being populated as search_document when vectorizing new objects in the database and search_query when a nearText search is being performed?\nI’ve dug through all the Cohere-related integration docs for Weaviate I could find as well as the client library but didn’t see any indications that I could specify input types for search/addition embedding operations. If there’s any integration docs I missed that explain this my apologies!\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method: k8s\nNumber of Running Nodes: 3\nClient Language and Version: Typescript 3.1.4\n\nAny additional Information\n\n----------\n\n[Dirk (2024-10-29T07:42:23.479Z)]: Hello,\nyou can check the code here:\n  \n\n      github.com\n  \n\n  \n    weaviate/weaviate/blob/6144e518154906f3ed4ad002028ff4f59a441dad/modules/text2vec-cohere/clients/cohere.go#L88\n\n\n\n    \n      \n          \treturn &vectorizer{\n          \t\tapiKey: apiKey,\n          \t\thttpClient: &http.Client{\n          \t\t\tTimeout: timeout,\n          \t\t},\n          \t\turlBuilder: newCohereUrlBuilder(),\n          \t\tlogger:     logger,\n          \t}\n          }\n          \n          func (v *vectorizer) Vectorize(ctx context.Context, input []string,\n          \tcfg moduletools.ClassConfig,\n          ) (*modulecomponents.VectorizationResult, *modulecomponents.RateLimits, error) {\n          \tconfig := v.getVectorizationConfig(cfg)\n          \tres, err := v.vectorize(ctx, input, config.Model, config.Truncate, config.BaseURL, searchDocument)\n          \treturn res, nil, err\n          }\n          \n          func (v *vectorizer) VectorizeQuery(ctx context.Context, input []string,\n          \tcfg moduletools.ClassConfig,\n          ) (*modulecomponents.VectorizationResult, error) {\n      \n    \n\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nVectorize (new objects) is using search_document\nVectorizeQuery (nearText, right below) is using search_query",
    "date_created": "2024-10-28T22:41:32.052Z",
    "has_accepted_answer": false,
    "title": "Question regarding input_type designation for cohere embeddings",
    "topic_id": 7114
  },
  {
    "user_id": 934,
    "conversation": "[saurbhhsharrma (2024-09-10T10:35:34.303Z)]: Description\nWe have added below to increase the query limit in our terraform file. But, it is causing service restart due to health check fail.\nPrior to these variables, our Weaviate Instance was stable.\nmap_environment = {\n“QUERY_DEFAULTS_LIMIT”  = 11000\n“QUERY_MAXIMUM_RESULTS” = 20000\n“LIMIT_RESOURCES”       = true\n“GOMAXPROCS”            = 1\n}\nServer Setup Information\n\nWeaviate Server Version: 1.26\nDeployment Method: Docker\nMulti Node? Number of Running Nodes: Single\nClient Language and Version: Python\nMultitenancy?: No\n\n@DudaNogueira\n\n----------\n\n[DudaNogueira (2024-09-10T19:01:08.563Z)]: hi @saurbhhsharrma !!\nDo you see any outstanding logs from server side?\nwas GOMAXPROCS and LIMIT_RESOURCES already set before this change?\ndo you have any readings on resource usage?\n\n----------\n\n[saurbhhsharrma (2024-09-10T19:19:36.233Z)]: The logs aren’t having much information. Neither, it is showing any error.\nWe have already set GOMAXPROCS and LIMIT_RESOURCES before this change was made.\nBelow were already set before this change:\nLIMIT_RESOURCES : true\nGOMAXPROCS: 1\nWeaviate Docker config: 2vCPU, 4GB memory.\nResource usage looks normal.\n\n----------\n\n[DudaNogueira (2024-09-11T12:42:19.251Z)]: I believe that because of the increase of QUERY_MAXIMUM_RESULTS, it may be failing to answer the check probe.\nIf you use QUERY_MAXIMUM_RESULTS with the defaults, it does get back to normal, right?\n\n----------\n\n[saurbhhsharrma (2024-09-19T15:47:44.360Z)]: DudaNogueira:\n\nyou see any outstanding logs from server\n\n\nI have removed QUERY_MAXIMUM_RESULTS from the environment and it is still creating issue.\nEverytime, it is failing to start and it doesn’t even print any logs for the same.\n@DudaNogueira @Mohamed_Shahin\nimage846×476 16.2 KB\n\n----------\n\n[DudaNogueira (2024-09-23T08:46:32.280Z)]: I believe this is a resource issue.\nDo you still see this issue if you increase the allocated resource for this cluster?",
    "date_created": "2024-09-10T10:35:34.248Z",
    "has_accepted_answer": false,
    "title": "Issue with QUERY_DEFAULTS_LIMIT and QUERY_MAXIMUM_RESULTS",
    "topic_id": 4073
  },
  {
    "user_id": 1593,
    "conversation": "[Praveenkasani (2024-11-19T07:31:47.123Z)]: Description\n\nCan you please provide an example GraphQL query for synonym search in weaviate. I wanted to know the vectorizers that can be used.\nMy example is simple as below:\nWhen a user search for ‘phone’, he has to see results such Mobile, smartphones, ‘call’ etc…\nThanks for the Help in Advance!!!\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[Mohamed_Shahin (2024-11-19T11:48:34.519Z)]: Hi @Praveenkasani, how are you doing?\nYou can use a basic hybrid search example like this:\n\n{\nGet {\nJeopardyQuestion(\nlimit: 3\nhybrid: {\nquery: “food”\n}\n) {\nquestion\nanswer\n}\n}\n}\n\nOr a more advanced example with additional control:\n\n{\nGet {\nJeopardyQuestion(\nlimit: 3\nhybrid: {\nquery: “food”\nproperties: [“question^2”, “answer”]\nalpha: 0.25\n}\n) {\nquestion\nanswer\n}\n}\n}\n\nHave you seen Hybrid search documentation? it will help you greatly for this.\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate\n\n  Hybrid search combines the results of a vector search and a keyword (BM25F) search by fusing the two result sets.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nRegards,\nMohamed Shahin,\nWeaviate Support\n\n----------\n\n[Praveenkasani (2024-11-19T12:13:39.861Z)]: Hi Shahnin,\nThanks for the reply, I will go through the queries and Hybrid search documentation.\nRegards,\nPraveen\n\n----------\n\n[Praveenkasani (2024-11-25T06:51:30.417Z)]: Hi Shahnin,\nI tried with the above query but looks like search is happening on all fields in my dictionary.\nBelow is my hybrid query and under the property I have only question and answers but the results are fetched with respect to subjects or topics also i.e. ‘Car’ word doesn’t exist in question or answers but exist in subjects/topics.\nCan you help me with the exact synonym search query on the select fields i.e. I should query only on question & answer fields but should be able to retrieve all other fields of that document.\nAlso, Please provide the modules that can be used for synonym’s. As of now we are using the below modules for our dictionary:\nimage1138×379 19.3 KB\nThanks in Advance!!!\n{\nGet {\nMyDictionary_1(\nwhere: {\noperator: And,\noperands: [\n{ path: [“attribute3”],\noperator: Equal,\nvalueString: “abcd”\n}\n{ path: [“attribute1”],\noperator: Equal,\nvalueString: “xyz”\n}\n{ path: [“attribute2”],\noperator: Equal,\nvalueString: “subject”\n}\n]\n}\nhybrid: {\nquery:“car”,\nproperties: [“question”, “answers”]\nalpha:0.25\n}\nlimit:100\n) {\nanswers\nquestion\nsubjects\ntopics\n}\n\n}\n}\n\n----------\n\n[Mohamed_Shahin (2024-11-25T15:14:15.863Z)]: Hi @Praveenkasani,\nI’m not familiar with your schema; the example I shared was a general one to illustrate how to structure a hybrid search. Could you share your schema with me?\nAdditionally, regarding the modules you’re referring to, are you using OpenAI, Google Palm, or Cohere APIs for vectorization? Weaviate can integrate with these providers to leverage their capabilities.\nHave you seen this guide if you are using our Cloud services?\nRegards,\nMohamed Shahin\nWeaviate Support",
    "date_created": "2024-11-19T07:31:47.077Z",
    "has_accepted_answer": true,
    "title": "Synonym Search example using GraphQL query",
    "topic_id": 7691
  },
  {
    "user_id": 2676,
    "conversation": "[Kostjanix2 (2024-11-25T15:25:29.641Z)]: Description\nHello I have used the Cohere reranker with the Rest Api from Weaviate to fetch documents and use them. Suddenly a few Weeks ago, it stopped working for all our collections, classes and calls. We run into this error:\n{\n\t\"errors\": [\n\t\t{\n\t\t\t\"locations\": [\n\t\t\t\t{\n\t\t\t\t\t\"column\": 19600,\n\t\t\t\t\t\"line\": 1\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"message\": \"Cannot query field \\\"rerank\\\" on type \\\"ClassAdditional\\\".\",\n\t\t\t\"path\": null\n\t\t}\n\t]\n}\n\nAs before we add the X-Cohere-Api-Key and our JSON Body did not change:\n{\n    \"query\":\"{Get{Class(limit:100 nearVector:{vector:}){title url imageUrl description short_description color manufacturer _additional{ distance rerank(property:\\\"description\\\",query:\\\"grill\\\"){score}}}}}\"\n}\n\nDid something change is the api and how to find out where the Problem is coming from?\nServer Setup Information\n\nWeaviate Server Version:\n1.24.25\nDeployment Method: Just an api http call\n\n----------\n\n[DudaNogueira (2024-11-26T20:28:28.909Z)]: hi @Kostjanix2 !! Welcome to our community \nThis is probably because you don’t have rerank-cohere in your ENABLE_MODULES.\nI was able to create this exact same error message both with client and graphql under this scenario:\nGraphql\n\n{\n“errors”: [\n{\n“locations”: [\n{\n“column”: 5,\n“line”: 6\n}\n],\n“message”: “Cannot query field \"rerank\" on type \"TestAdditional\".”,\n“path”: null\n}\n]\n}\n\npython client:\n\n{grpc_message:“explorer: get class: extend: unknown capability: rerank”, grpc_status:2, created_time:“2024-11-26T17:25:51.248127-03:00”}\"\n\nLet me know if this helps!\n\n----------\n\n[Kostjanix2 (2024-11-27T14:18:13.432Z)]: Thanks for your message @DudaNogueira !\nI think we already have cohere active in our Modules. At least I can see following Enabled Modules:\nimage812×288 13.2 KB\nI am not sure if we actually have the wrong ones active (reranker-cohere instead of rerank-cohere? But I am sure that a few weeks ago it worked without changing anything\n\n----------\n\n[DudaNogueira (2024-11-27T17:16:58.931Z)]: Ah, ok.\nWhen the issue is with an instance in our cloud, the best place to ask for support is following this for opening a support ticket:\n\n  \n\n      console.weaviate.cloud\n  \n\n  \n    \n\nWeaviate Cloud\n\n  Weaviate Cloud\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThat way we can know exactly what is the instance you are working with.\nThanks!",
    "date_created": "2024-11-25T15:25:29.593Z",
    "has_accepted_answer": false,
    "title": "Cohere Reranker not working in APi anymore",
    "topic_id": 8161
  },
  {
    "user_id": 778,
    "conversation": "[Mariam (2024-08-26T13:56:44.578Z)]: Description\nI’ve successfully set up Weaviate nodes across three different servers, and all nodes show a healthy connection. Below are the results of my v1/nodes endpoint, as well as the schema configuration.\nHowever, when I attempt to create an index on the original node, the other two nodes do not create the index. I also tried manually creating the index individually and storing data on the main node, but the data is not being shared across the nodes. Could you help me identify what might be missing in my configuration?\nServer Setup Information\n\nWeaviate Version: v.1.26.1\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 3\nClient Language and Version:v4\nMultitenancy?:\n\nnodes\n{\n    \"nodes\": [\n        {\n            \"batchStats\": {\n                \"queueLength\": 0,\n                \"ratePerSecond\": 12\n            },\n            \"gitHash\": \"6fd2432\",\n            \"name\": \"node1\",\n            \"shards\": null,\n            \"status\": \"HEALTHY\",\n            \"version\": \"1.26.1\"\n        },\n        {\n            \"batchStats\": {\n                \"queueLength\": 0,\n                \"ratePerSecond\": 12\n            },\n            \"gitHash\": \"6fd2432\",\n            \"name\": \"node2\",\n            \"shards\": null,\n            \"status\": \"HEALTHY\",\n            \"version\": \"1.26.1\"\n        },\n        {\n            \"batchStats\": {\n                \"queueLength\": 0,\n                \"ratePerSecond\": 0\n            },\n            \"gitHash\": \"6fd2432\",\n            \"name\": \"node3\",\n            \"shards\": null,\n            \"status\": \"HEALTHY\",\n            \"version\": \"1.26.1\"\n        }\n    ]\n}\n\nschema configuration\ncollection = client.collections.create(\n            collection_name,\n            vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n               api_endpoint=model_endpoint,\n               model=vectorizer_model\n            ),\n            replication_config=wvc.config.Configure.replication(\n                factor=3,\n\n            ),\n\n            properties=[my propeties]\n\nindex schema replication and sharding are in my index\n\"replicationConfig\": {\n                \"asyncEnabled\": false,\n                \"factor\": 3\n            },\n            \"shardingConfig\": {\n                \"actualCount\": 3,\n                \"actualVirtualCount\": 384,\n                \"desiredCount\": 3,\n                \"desiredVirtualCount\": 384,\n                \"function\": \"murmur3\",\n                \"key\": \"_id\",\n                \"strategy\": \"hash\",\n                \"virtualPerPhysical\": 128\n            },\n\n----------\n\n[DudaNogueira (2024-08-26T14:04:25.323Z)]: hi @Mariam !!\nDo you see anything out of ordinary on logs?\nYour configuration seems fine, so it should be replicating to all notes.\n\n----------\n\n[Mariam (2024-08-26T15:17:57.142Z)]: here is my logs:\n{“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: node3 192.168.1.24:7100\",“time”:“2024-08-26T15:06:10Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:06:11Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:06:21Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:06:31Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: node2 192.168.1.23:7100\",“time”:“2024-08-26T15:06:40Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:06:41Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:06:51Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:07:01Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: node3 192.168.1.24:7100\",“time”:“2024-08-26T15:07:10Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:07:11Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“level”:“debug”,“msg”:\" memberlist: Stream connection from=192.168.1.24:58996\",“time”:“2024-08-26T15:07:14Z”}\n{“level”:“debug”,“msg”:\" memberlist: Stream connection from=192.168.1.23:58336\",“time”:“2024-08-26T15:07:18Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:07:21Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:07:31Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: node2 192.168.1.23:7100\",“time”:“2024-08-26T15:07:40Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:07:41Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“level”:“debug”,“msg”:\" memberlist: Stream connection from=192.168.1.24:36854\",“time”:“2024-08-26T15:07:44Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:07:51Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:08:01Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n{“level”:“debug”,“msg”:\" memberlist: Initiating push/pull sync with: node3 192.168.1.24:7100\",“time”:“2024-08-26T15:08:10Z”}\n{“action”:“restapi_request”,“level”:“debug”,“method”:“GET”,“msg”:“received HTTP request”,“time”:“2024-08-26T15:08:11Z”,“url”:{“Scheme”:“”,“Opaque”:“”,“User”:null,“Host”:“”,“Path”:“/metrics”,“RawPath”:“”,“OmitHost”:false,“ForceQuery”:false,“RawQuery”:“”,“Fragment”:“”,“RawFragment”:“”}}\n\n----------\n\n[DudaNogueira (2024-08-26T18:00:24.382Z)]: can you share your docker compose?\n\n----------\n\n[Mariam (2024-08-28T15:31:58.358Z)]: hi @DudaNogueira ,\nhere is the docker configuration\nmaster node\nversion: ‘3.7’\nservices:\nweaviate-node-1:\ninit: true\nnetwork_mode: “host”\ncommand:\n- --host\n- 0.0.0.0\n- --port\n- ‘8080’\n- --scheme\n- http\nimage: cr.weaviate.io/semitechnologies/weaviate:1.26.1\nports:\n- 8080:8080\n- 6060:6060\n- 50051:50051/tcp\n- 50051:50051/udp\n- 7100:7100/tcp\n- 7100:7100/udp\n- 7101:7101/tcp\n- 7101:7101/udp\n- 8300:8300/tcp\n- 8300:8300/udp\n- 8301:8301/tcp\nrestart: on-failure:0\nvolumes:\n- ./data-node-1:/var/lib/weaviate\nenvironment:\nLOG_LEVEL: ‘debug’\nQUERY_DEFAULTS_LIMIT: 25\nAUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: ‘true’\nPERSISTENCE_DATA_PATH: ‘/var/lib/weaviate’\nENABLE_MODULES: ‘text2vec-ollama,generative-ollama’\nDEFAULT_VECTORIZER_MODULE: ‘none’\nCLUSTER_HOSTNAME: ‘node1’\nCLUSTER_GOSSIP_BIND_PORT: ‘7100’\nCLUSTER_DATA_BIND_PORT: ‘7101’\nRAFT_JOIN: ‘192.168.1.52:8300,192.168.1.23:8300,192.168.1.24:8300’\nRAFT_BOOTSTRAP_EXPECT: 3\nREPLICATION_FACTOR: ‘2’\nREPLICATION_CONSISTENCY: ‘QUORUM’\n\n----------\n\n[jasper2077 (2024-12-02T09:20:48.067Z)]: Hello, could you please share the Docker commands for setting up a cluster across multiple machines? Any help would be greatly appreciated.\n\n----------\n\n[Mariam (2024-12-03T14:33:18.032Z)]: Hi @jasper2077,\nOn two or three different servers,  you should create a docker-compose.yml  file like in the above example with the corresponding configurations for each server. Update the IPs and set the REPLICATION_FACTOR to 2 or 3(based on how many replications you want to have), and specify ENABLE_MODULES with your preferred models or custom models. Run the same docker-compose.yml file on both servers using the command:\ndocker-compose up\n\nOnce Weaviate is up, define your index in the code as follows:\n    collection_name,\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n        api_endpoint=model_endpoint,\n        model=vectorizer_model\n    ),\n    replication_config=wvc.config.Configure.replication(\n        factor=3,  # Adjust based on your setup\n    ),\n    properties=[my_properties]  # Replace with your actual properties\n)",
    "date_created": "2024-08-26T13:56:44.518Z",
    "has_accepted_answer": true,
    "title": "Data replication issue",
    "topic_id": 3656
  },
  {
    "user_id": 1210,
    "conversation": "[Jackzz (2024-07-19T07:36:44.974Z)]: Hello there,\nRecently, I posted a thread: https://forum.weaviate.io/t/assistance-needed-to-improve-weaviates-vector-search-performance/3096/1\nScreenshot 2024-07-19 1306061882×699 63.3 KB\nAfter few minutes, I got a notification that left me disappointed as it shows my content is spam. I don’t know what is the reason behind it but I didn’t make anything wrong that violate community guideline. As a professional, I respect community guideline and make useful contribution to help community members.\nAs my query is genuine and I really need a quick solution to that and I don’t\nthink there is better platform than this to solve my query.\nKindly live my post.\n\n----------\n\n[DudaNogueira (2024-07-19T13:37:14.437Z)]: hi @Jackzz !!\nReally sorry. For some reason, akismet marked that post as  SPAM.\nI have already reverted that.\nSorry for the inconvenience.\nThanks!",
    "date_created": "2024-07-19T07:36:44.913Z",
    "has_accepted_answer": true,
    "title": "Why Am I Unable to See My Post?",
    "topic_id": 3098
  },
  {
    "user_id": 1108,
    "conversation": "[dhanshew72 (2024-07-19T18:13:43.325Z)]: Description\nHow do I know my setup is using multiple nodes with tenancy or how would I verify this state? I’ve been running a 2 node cluster playing around with the setup by loading data. However, I’m not what I would think would be the right things to ensure that this setup is working and wanted some guidance.\nWhen I hit the endpoint /v1/nodes/<MY_COLLECTION_NAME>\n{\"nodes\":[{\"batchStats\":{\"queueLength\":0,\"ratePerSecond\":3},\"gitHash\":\"1ea5766\",\"name\":\"node0\",\"shards\":null,\"status\":\"HEALTHY\",\"version\":\"1.25.7\"},{\"batchStats\":{\"queueLength\":0,\"ratePerSecond\":0},\"gitHash\":\"1ea5766\",\"name\":\"node1\",\"shards\":null,\"status\":\"HEALTHY\",\"version\":\"1.25.7\"}]}\n\nI have 2 tenants loaded up at the moment so I’d expected to see at least a value for shards for node0. The only logs I see that confirms the nodes are connected is debug logs:\n\"msg\":\" memberlist: Initiating push/pull sync with: node0\n\nThese logs are just repeating itself.\nHowever, I’m not clear if these nodes are being used to store tenants individually or if I need to change my setup in some way to search across multiple ones. I also am not near to filling up a single node. The only thing I’ve seen is when I was developing this I would get error messages if my node1 wasn’t reachable.\nAny advice on this? I just want to prove that multiple nodes will be used loading data for multiple tenants.\nServer Setup Information\n\nWeaviate Server Version: 1.25.7\nDeployment Method: Docker on AWS ECS\nMulti Node? Number of Running Nodes: 2\nClient Language and Version: 4.6.5\nMultitenancy?: Yes.\n\n----------\n\n[DudaNogueira (2024-07-26T14:58:25.195Z)]: hi @dhanshew72 !!\nSorry for the delay here.\nMissed this one \nWere you able to figure this out?\nWeaviate should distribute the tenants across different available nodes.\nHere is a test I did using latest 1.26.1 version with 3 nodes:\nfrom weaviate import classes as wvc\nclient.collections.delete(\"MyMTCollection\")\ncollection = client.collections.create(\n    \"MyMTCollection\",\n    multi_tenancy_config=wvc.config.Configure.multi_tenancy(enabled=True, auto_tenant_activation=True, auto_tenant_creation=True),\n    vectorizer_config=wvc.config.Configure.Vectorizer.none()\n)\n\nnow let’s check we have 0 shards yet:\nfor node in client.cluster.nodes(output=\"verbose\"):\n    print(node.name, len(node.shards))\n\noutputs:\n\nweaviate-0 0\nweaviate-1 0\nweaviate-2 0\n\nNow let’s add 100 tenants with some sample data\nfor i in range(100):\n    tenant_data = f\"T{i}\"\n    collection.with_tenant(tenant_data).data.insert({\"text\": tenant_data})\n\nThis is how it is distributed (it varies for every run) after adding the tenants and content:\n\nweaviate-0 40\nweaviate-1 28\nweaviate-2 32\n\nLet me know if that helps.\nTHanks!\n\n----------\n\n[dhanshew72 (2024-07-26T16:30:11.766Z)]: Apologies, I should have reported back. I got this working now.\n\n----------\n\n[jinx (2025-02-25T17:14:12.015Z)]: Will the tenants be distributed such that each node has roughly the same amount of data?\n\n----------\n\n[dhanshew72 (2025-02-25T17:23:10.834Z)]: No, they’re based on the tenant size and stay on the same node. Each tenant is considered a shard at least on 1.24\n\n----------\n\n[DudaNogueira (2025-02-25T18:39:35.930Z)]: that is also true for 1.29\n\n----------\n\n[jinx (2025-02-26T02:50:55.119Z)]: I am sorry, let me rephrase. I am running a weaviate cluster on kubernetes. I have multiple weaviate pods running across multiple kubernetes nodes. Let’s assume I have 4 pods running across 4 nodes. And each pod was allocated 8 GB of memory. So if one pod can hold n vectors, I know that my weaviate cluster can support roughly 4*n vectors. Correct?\nNow instead of specifying sharding config for the collection, if I make the collection multi-tenant, can I assume that my cluster will still be able to support 4*n vectors? Does Weaviate distribute tenants evenly across all pods, or do I need to manage this manually?\n\n----------\n\n[DudaNogueira (2025-02-27T17:33:40.480Z)]: hi @jinx !\nThat’s correct. This is considering you have replication factor of 4 (so each object will be replicated 4 times across the cluster). Now each collection/tenant will have shards spreaded on all 4 nodes.\nIf you have 4 nodes, and you have a replication factor of 3, Weaviate will allocate shards on the node that is use the least resources.\nWe do not have the feature of shard movement. This is planned in experimental mode for Weaviate 1.30.\nLet me know if that helps!\nThanks!\n\n----------\n\n[jinx (2025-03-03T03:57:03.668Z)]: Okay, understood. Thank you!",
    "date_created": "2024-07-19T18:13:43.207Z",
    "has_accepted_answer": true,
    "title": "Using Multiple Nodes with Tenancy",
    "topic_id": 3105
  },
  {
    "user_id": 3657,
    "conversation": "[franz_hals (2025-03-05T11:54:48.764Z)]: Description\nHello,\nI would like to specify the api version that Weaviate uses to query the Azure OpenAI endpoint.\nFrom what I read in the discussions here I am not sure where I can specify the api_version - when creating the Collection or as an environment parameter.\nIf it is an environment parameter for the docker container, what value would it be? Is it\n\nAZURE_OPENAI_API_VERSION\nOPENAI_API_VERSION\nsomething else?\n\nAdditionally I have the issue that I want to use a “text-embedding-3-large”  - which is deployed on azure - with 1536 dimensions. Anyhow, after creating the collection, the “model” parameter of the collection lists the “model” parameter as “text-embedding-3-large”. As far as I found out the model can only be specified in the OpenAI class directly, not in Azure OpenAI. Can I just ignore the wrong “model” parameter of the created collection or will this be an issue?\nTHANKS\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? No\nClient Language and Version: 1.28\nMultitenancy?: No\n\n----------\n\n[Mohamed_Shahin (2025-03-05T13:38:05.902Z)]: Hey @franz_hals\nPlease have a look at:\n\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Incorrect Config Assignment for text2vec_azure_openai in Named Vectors and General Vectorizer\n    \n\n    \n      \n        opened 12:20PM - 05 Mar 25 UTC\n      \n\n\n      \n        \n          \n          Shah91n\n        \n      \n    \n\n    \n        \n          bug\n        \n    \n  \n\n\n  \n    ### How to reproduce this bug?\n\nWhen creating a collection using the text2vec_az…ure_openai vectorizer and specifying the parameters:\n\n```\nresource_name=\"RES_HERE\",\ndeployment_id=\"DEPLOY_ID_HERE\"\n```\n\nRegardless of what is added in the configuration, the result always defaults to the model text-embedding-3-small and dimensions 1536, instead of the expected model from Azure OpenAI.\n\nCode used to reproduce:\n\n```\nfrom weaviate.classes.config import Configure, Property, DataType\n\nclient.collections.create(\n    \"embed\",\n     # Define properties\n    properties=[\n        Property(name=\"embed_desc\", data_type=DataType.TEXT),\n    ],\n    vectorizer_config=[\n        # Set a named vector\n        Configure.NamedVectors.text2vec_azure_openai(\n            resource_name=\"RESOURCE_NAME\",\n            deployment_id=\"DEPLOYMENT_ID\",\n            name=\"embed_descNamedVector\",\n            source_properties=[\"embed_desc\"]       \n        )\n    ]\n)\n```\nOR\n\n```\nfrom weaviate.classes.config import Configure, Property, DataType\n\nclient.collections.create(\n    \"CollNam\",\n     # Define properties\n    properties=[\n        Property(name=\"embedding\", data_type=DataType.TEXT),\n    ],\n    vectorizer_config=Configure.Vectorizer.text2vec_azure_openai(\n            resource_name=\"RES_HERE\",\n            deployment_id=\"DEPLOY_ID_HERE\"\n    )\n)\n```\n\n### What is the expected behavior?\n\n- The vectorizer should respect the resource_name and deployment_id and use the correct Azure OpenAI model.\n- The correct configuration reflect on the collection definition.\n\n### What is the actual behavior?\n\n- Despite specifying a different resource_name and deployment_id, the model is always set to text-embedding-3-small and the dimensions remain 1536.\n\n- This occurs consistently across different Weaviate versions.\n\n### Supporting information\n\n- Attached are screenshots demonstrating the issue below.\n- The bug persists on multiple setups.\n- It also occurs on 1.27 version.\n\n<img width=\"1425\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6c214004-6f00-4b0f-bfba-abbae25b1ecb\" />\n\n### Server Version\n\n1.29.0\n\n### Weaviate Setup\n\nSingle Node\n\n### Nodes count\n\n1\n\n### Code of Conduct\n\n- [x] I have read and agree to the Weaviate's [Contributor Guide](https://weaviate.io/developers/contributor-guide) and [Code of Conduct](https://weaviate.io/service/code-of-conduct)\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that reflects what you are reporting and feel free to add a comment there in the Github issue if needed.\nRegards,\nMohamed Shahin,\nSupport Engineer\n\n----------\n\n[franz_hals (2025-03-05T16:21:55.558Z)]: Hi Mohamed, thanks for creating the issue - it reflects my experience except that I did not try for bigger vector dimensions than 1536.",
    "date_created": "2025-03-05T11:54:48.715Z",
    "has_accepted_answer": false,
    "title": "Where to specify the Azure OpenAI api version / model?",
    "topic_id": 10796
  },
  {
    "user_id": 778,
    "conversation": "[Mariam (2024-08-07T06:21:12.360Z)]: Description\nTo deploy weaviate as a cluster with replication, what deployment models do we have?\n\nDocker\nEmbedded model\nis there anything like a local installation - typically as one would install Elastic Search or Redis?\n\n----------\n\n[DudaNogueira (2024-08-07T18:34:35.589Z)]: Hi @Mariam !!\nThe best way is using our official helm.\nHere is the doc for that:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nKubernetes | Weaviate - Vector Database\n\n  For a tutorial on how to use minikube to deploy Weaviate on Kubernetes, see the Weaviate Academy course, Weaviate on Kubernetes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if that helps.\nThanks!",
    "date_created": "2024-08-07T06:21:12.292Z",
    "has_accepted_answer": false,
    "title": "To deploy weaviate as a cluster with replication, what deployment models do we have?",
    "topic_id": 3283
  },
  {
    "user_id": 3081,
    "conversation": "[artisticcheese (2024-12-22T01:26:09.042Z)]: Description\nHello,\nOur weaviate deployment was accidentally deployed to system nodepool before taints were put onto it. So we have replica set to 5 and end up with 2 pods on system nodepool and 3 on user node pool. We tried to put taint on system nodepool and evict weaviate but it will not budge since weaviate-0 pod was scheduled on system nodepool. What are out options of running just 3 replicas on user nodepools?\nServer Setup Information\n\nWeaviate Server Version:\nDeployment Method: k8s\nMulti Node? Number of Running Nodes: 5\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-12-23T13:32:25.361Z)]: hi @artisticcheese !!\nWelcome to our community  !!\nLooks like this question is more about k8s than Weaviate \nFrom Weaviate side, as long as each node can communicate with the other, it should be fine.\nAlso, while moving your pods around, the content of the PERSISTENCE_DATA_PATH must be the same from the nodeX.\nSo for example, if you set replica to 5, you will have, for eg. weaviate-data-0 all the way to weaviate-4 and each node ant its configuration need to be attached to the corresponding pvc.\nNow, if you already have collections with replica factor 5, and want to now use replica facto 3 instead, you will need to migrate that collection to a new collection or cluster, considering that we do not have the dynamic scaling yet.\nLet me know if that helps.\nThanks!",
    "date_created": "2024-12-22T01:26:08.994Z",
    "has_accepted_answer": true,
    "title": "How do I scale in/out statefulset in weaviate",
    "topic_id": 9385
  },
  {
    "user_id": 1033,
    "conversation": "[Luka_Secerovic (2025-03-04T15:23:56.293Z)]: Description\nGot this error when ingesting:\nFailed to ingest data, error[usage error (500): \n{\"error\":[{\"message\":\"update vector: unmarshal response body: invalid character 'e' looking for beginning of value\"}]}]\n\nWhat does it mean? What could be the cause?\nServer Setup Information\n\nWeaviate Server Version: 1.25.25, US East\nMultitenancy?: yes\n\n----------\n\n[DudaNogueira (2025-03-04T16:11:13.121Z)]: Hi!\nDo you see this issue also if using 1.25.latest?\nfor instance: 1.25.34\nThanks!\n\n----------\n\n[Luka_Secerovic (2025-03-04T17:12:05.349Z)]: Hi! I’m using WCS, do you suggest that I update the instance?\n\n----------\n\n[Luka_Secerovic (2025-03-04T19:14:27.477Z)]: I’ve updated to 1.28.8, will post here if the issue is encountered again, but I’m curious why the error has happened\n\n----------\n\n[DudaNogueira (2025-03-06T13:27:30.312Z)]: Hi Luka!\nFor all hosted clusters, the best place for a faster support is opening a support ticket here:\n\n  \n\n      console.weaviate.cloud\n  \n\n  \n    \n\nWeaviate Cloud\n\n  Weaviate Cloud\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThis will allow us to directly access your cluster logs and metrics.\nCan you share the entire stack trace?\nI have seen this kind of error on old versions of Weaviate, and happening due to Weaviate not handling vectorizer or generative 5XX error response.\nSo most probably your vectorizer failed (considering it was on ingestion), and Weaviate have not presented the error message on a readable way (apart from the \" [usage error (500)…]\"\nLet me know if this helps!\nThanks!",
    "date_created": "2025-03-04T15:23:56.240Z",
    "has_accepted_answer": true,
    "title": "Error during ingestion: Failed to ingest data, error[usage error (500): {\"error\":[{\"message\":\"update vector: unmarshal response body: invalid character 'e' looking for beginning of value\"}]}]",
    "topic_id": 10739
  },
  {
    "user_id": 753,
    "conversation": "[rhuang (2024-03-29T05:25:51.846Z)]: Description\nWith python V3 client, we can use the following to add a new property to a collection:\nclient.schema.property.create(collection_name, prop)\n\nHow can we do the same with V4 client?\n\n----------\n\n[Dirk (2024-03-30T08:37:24.181Z)]: Hi, you can do\n        collection.config.add_property(Property(name=\"name\", data_type=DataType.TEXT))\n\n----------\n\n[abdimussa (2024-12-18T12:49:17.058Z)]: Hi Dirk, does this have any conflict with what is mentioned below:\n\nAdding a property after importing objects can lead to limitations in inverted-index related behavior, such as filtering by the new property’s length or null status.\nThis is caused by the inverted index being built at import time. If you add a property after importing objects, the inverted index for metadata such as the length or the null status will not be updated to include the new properties. This means that the new property will not be indexed for existing objects. This can lead to unexpected behavior when querying.\nTo avoid this, you can either:\n\nAdd the property before importing objects.\nDelete the collection, re-create it with the new property and then re-import the data.\n\nWe are working on a re-indexing API to allow you to re-index the data after adding a property. This will be available in a future release.\n\n----------\n\n[DudaNogueira (2024-12-18T13:14:39.146Z)]: hi @abdimussa !!\nIf you add a property to a previously created collection that had the inverted index to index null state and property length, then yes.\nHere you have the python code to create such a collection:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nManage collections | Weaviate\n\n  Every object in Weaviate belongs to exactly one collection. Use the examples on this page to manage your collections.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nBy default, those configs are off.\nHere is how to check the default inverted index config of a collection:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    \"Test\",\n)\ncollection.config.get().inverted_index_config.to_dict()\n\nthis should output:\n{'bm25': {'b': 0.75, 'k1': 1.2},\n 'cleanupIntervalSeconds': 60,\n 'indexNullState': False,\n 'indexPropertyLength': False,\n 'indexTimestamps': False,\n 'stopwords': {'preset': 'en'}}\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[abdimussa (2024-12-18T13:41:16.136Z)]: Thank you @DudaNogueira, it is now clear. One question I have though is, what is the purpose of having those set to True.\n\n----------\n\n[DudaNogueira (2024-12-18T14:34:35.462Z)]: Hi!\nindexNullState=True will create an index for the fields that doesn’t have it. So let’s say you have 10 objects, 4 with the property colors set to something, and 6 that doesn’t have a colors property.\nIf you set indexNullState to True, you will be able to filter objects that has nothing set as has_color. Here is the section of the docs about it\nThe same goes to indexPropertyLength, (more info here) that will allow you to filter by that value, as described here.\nAnd similarly, you can set indexTimestamps, as described here\nLet me know if that helps!\nThanks!\n\n----------\n\n[abdimussa (2024-12-19T08:07:51.145Z)]: @DudaNogueira this definitely helps. Thank you. Regarding the indexTimestamps, I got an answer that I need to recreate the collection in order to change its value, and had a question about it here Filtering based on creation_time requires index_timestamps - Support - Weaviate Community Forum.\nI would appreciate it if you can help. Thank you",
    "date_created": "2024-03-29T05:25:51.786Z",
    "has_accepted_answer": true,
    "title": "How to add new property to an existing collection with V4 client",
    "topic_id": 1850
  },
  {
    "user_id": 1096,
    "conversation": "[Lakshman_Krishnamurt (2024-10-27T05:58:56.334Z)]: Description\n\nHere is what I would like to do for a RAG system using weaviate.\n\nAdd a data field to say metadata.\nAble to retriver all documents in ascending date order.\n\nHow would one go about doing this?\nThank you\n\n----------\n\n[DudaNogueira (2024-10-27T13:18:48.348Z)]: hi! Check how to do sorting in our documentation:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAdditional operators | Weaviate\n\n  Syntax\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nfor instance:\nfrom weaviate.classes.query import Sort\n\nresponse = questions.query.fetch_objects(\n        # Note: To sort by multiple properties, chain the relevant `by_xxx` methods.\n        sort=Sort.by_property(name=\"points\", ascending=False).by_property(name=\"answer\", ascending=True),\n        limit=3\n    )\n\nLet me know if this helps.\nThanks!",
    "date_created": "2024-10-27T05:58:56.296Z",
    "has_accepted_answer": false,
    "title": "Sort by date",
    "topic_id": 6562
  },
  {
    "user_id": 1555,
    "conversation": "[Rishi_Prakash (2024-09-18T18:15:31.193Z)]: I am creating a schema as below\nimage738×566 25.1 KB\nI’ve added the data to the collection, but when I query it for the nearest results to the test term “Art Briefs” (which is an exact match in the collection), I’m getting unexpectedly low scores. Here’s an example:\nFor search of\norg_collection = client.collections.get(“Org_Test”)\nresponse = org_collection.query.near_text(\nquery=“Art Briefs”,\nlimit=5,\nreturn_metadata=MetadataQuery.full()\n)\nfor o in response.objects:\nprint(o.properties[‘skill_name’])\ncosine_similarity = 2 * o.metadata.certainty - 1\nprint(f\"Cosine similarity: {cosine_similarity}“)\nprint(f\"Certainty: {o.metadata.certainty}”)\nI get\n{Art Briefs\nCosine similarity: 0.8635821342468262\nCertainty: 0.9317910671234131}\nI’ve set vectorize_property_name=True for the skill name field only. This low score is causing issues with my API, and I need the score to be much higher. I’ve searched extensively but I’m stuck. Please provide a resolution as soon as possible.\n\n----------\n\n[DudaNogueira (2024-09-18T18:42:55.389Z)]: hi @Rishi_Prakash !!\nWelcome to our community \nthe near_text (similarity/vector search) will not be a literal search. So even if you have a exact match, it may not be placed near to your query.\nFor that, the bm25/keyword and hybrid search will be more effective.\nHow far on the ranking the exact match object from the query is?\n\n----------\n\n[Rishi_Prakash (2024-09-18T19:03:53.081Z)]: Hi Duda,\nThanks for the response,\nCould you update the below code to use bm25/keyword and hybrid search.\norg_collection = client.collections.get(“Org_Test”)\nresponse = org_collection.query.near_text(\nquery=“Art Briefs”,\nlimit=5,\nreturn_metadata=MetadataQuery.full()\n)\nfor o in response.objects:\nprint(o.properties[‘skill_name’])\ncosine_similarity = 2 * o.metadata.certainty - 1\nprint(f\"Cosine similarity: {cosine_similarity}“)\nprint(f\"Certainty: {o.metadata.certainty}”)\nBecause I don’t see the V4 code in documentation.\nThanks!\n\n----------\n\n[DudaNogueira (2024-09-18T21:01:00.708Z)]: Hi!\nit is here:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate\n\n  Hybrid search combines the results of a vector search and a keyword (BM25F) search by fusing the two result sets.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nNote that you get distance with a vector search, but for hybrid and bm25/keyword, you get score.\nhere is the docs for bm25:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nKeyword search | Weaviate\n\n  Keyword search, also called \"BM25 (Best match 25)\" or \"sparse vector\" search, returns objects that have the highest BM25F scores.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nYour code will be need to change to:\nresponse = org_collection.query.hybrid(\n    query=\"Art Briefs\",\n    limit=5,\n    return_metadata=MetadataQuery.full()\n)",
    "date_created": "2024-09-18T18:15:31.144Z",
    "has_accepted_answer": true,
    "title": ".near_text vector search score is very low",
    "topic_id": 4195
  },
  {
    "user_id": 1108,
    "conversation": "[dhanshew72 (2024-10-14T22:42:30.977Z)]: Description\nIs it possible to use the not equal filter on properties with word tokenization even if they don’t have alphanumeric characters? Unfortunately I have data like test.com/2 with word tokenization when it wasn’t intended.\nFor example, I’d want to query test.com/2 using a not equal filter like below:\nFilter.by_property(\"my_property\").not_equal(\"test.com/2\")\n\nDoes any workaround exist like query against “test com 2” or update tokenization or search with a different tokenization? My main issue is adding a new field or replacing with the proper tokenization is a lengthy process in a production system.\nServer Setup Information\n\nWeaviate Server Version: 1.24.0\nDeployment Method: Docker\nMulti Node? Number of Running Nodes: No.\nClient Language and Version: 4.6.5\nMultitenancy?: Yes\n\n----------\n\n[DudaNogueira (2024-10-15T21:30:17.117Z)]: hi @dhanshew72 !\nbecause you had tokenization set to word, the property value test.com/2 will be tokenized as test com 2\nThis will proves our point:\nclient.collections.delete(\"Test\")\ncollection = client.collections.create(\n    name=\"Test\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n)\n\ncollection.data.insert_many([\n    {\"text\": \"test.com/2\"},\n    {\"text\": \"test.com/3\"},\n    {\"text\": \"test.com/4\"},\n\n])\n\nnow we query:\nresults = collection.query.fetch_objects(\n    filters=(\n        wvc.query.Filter.by_property(\"text\").equal(\"test\") & \n        wvc.query.Filter.by_property(\"text\").equal(\"com\") & \n        wvc.query.Filter.by_property(\"text\").equal(\"2\")\n    )\n)\nfor i in results.objects:\n    print(\"###\")\n    print(i.properties)\n\nresults:\n\n{‘text’: ‘test.com/2’}\n\nAs you want to exclude that filtered objects, not equal on a word tokenization will not help you.\nSo you can try adding a new property, with the field tokenization, and then filling in the content of that property so you can filter it out.\nLet me know if this helps\n\n----------\n\n[dhanshew72 (2024-10-16T16:09:53.201Z)]: Interesting, I’ll make note of that. Thank you.",
    "date_created": "2024-10-14T22:42:30.935Z",
    "has_accepted_answer": true,
    "title": "Not Equal Filter with Word Tokenization with non-alphanumeric characters",
    "topic_id": 5289
  },
  {
    "user_id": 1503,
    "conversation": "[gaurav_sharma (2024-09-09T15:49:19.469Z)]: Description\nI am new to Weaviate and would appreciate some clarification. Here’s a bit of background about my situation:\nI have been working with vector databases, specifically testing Pinecone for a personal project. In my project, I want to implement hybrid search, but with Pinecone, I face a challenge. To perform hybrid search there, I need to create a sparse vector beforehand. This requires access to the full corpus to create a featurizer for the sparse vector. The problem arises because I don’t have access to the entire corpus upfront — data is inserted incrementally as it becomes available.\nI understand that Weaviate handles hybrid search differently. Specifically, it seems like I don’t need to explicitly create or insert a sparse vector during data insertion, unlike with other databases like Pinecone. I would like to confirm if this understanding is correct.\nMy Questions:\n\nData Insertion for Hybrid Search: Is it true that when using Weaviate, I don’t need to specify any additional arguments related to hybrid search during data insertion?\nHow Weaviate Implements Hybrid Search: Could you explain how Weaviate manages hybrid search without needing the sparse vector to be explicitly provided or created ahead of time?\n\n----------\n\n[DudaNogueira (2024-09-09T17:44:12.281Z)]: hi @gaurav_sharma !!\nWelcome to our community \nYour assumptions are correct.\nWhen you create a collection in Weaviate, you can specify a vectorizer, like so:\nfrom weaviate import classes as wvc\n\nwcd_url = os.environ[\"WCD_DEMO_URL\"]\nwcd_api_key = os.environ[\"WCD_DEMO_RO_KEY\"]\nopenai_api_key = os.environ[\"OPENAI_APIKEY\"]\n\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=wcd_url,                                    # Replace with your Weaviate Cloud URL\n    auth_credentials=wvc.init.Auth.api_key(wcd_api_key),    # Replace with your Weaviate Cloud key\n    headers={\"X-OpenAI-Api-Key\": openai_api_key}            # Replace with appropriate header key/value pair for the required API\n)\n\nons = client.collections.create(\n    name=\"Question\",\n    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),  # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n    generative_config=wvc.config.Configure.Generative.openai()  # Ensure the `generative-openai` module is used for generative queries\n)\n\nNow Weaviate has everything it needs to vectorize your data: both for ingestion and for querying. Including the API Key for the embedder service (in this example, OpenAI)\nThat alone will allow you to do hybrid search, both providing your own vector query, or letting Weaviate vectorize it for you.\nFor example, here we are doing a keyword search for “food” and passing a vector for the vector search part:\nresponse = jeopardy.query.hybrid(\n    query=\"food\",\n    vector=query_vector,\n    alpha=0.25,\n    limit=3,\n)\n\nIf you do not specify the vector parameter, it will now vectorize the word “food” and use the generated vector for the vector search as well.\nLet me know if this clarifies it for you \nTHanks!\n\n----------\n\n[gaurav_sharma (2024-09-09T19:49:38.865Z)]: DudaNogueira:\n\nIf you do not specify the vector parameter, it will now vectorize the word “food” and use the generated vector for the vector search as well.\n\n\nThank you for the clarification @DudaNogueira .\nMy understanding is that to calculate sparse embeddings (such as TF-IDF or BM25), a featurizer is internally created by the vector database based on the ingested data. This could happen either periodically or every time new data is added, and the sparse embeddings for the corpus are then recalculated.\nQuestion: Is this understanding correct? If so, how often are these recalculations performed — every time new data is ingested, or on a periodic basis? Also, can you refer me to any documentation/ code on the git repo that can help me understand it better.\n\n----------\n\n[DudaNogueira (2024-09-09T20:37:28.888Z)]: it will happen when data is added/updated.\nSo when you ingest/update data, Weaviate will vectorize your data, ingest and index into the vector index, like hnsw. That will give you the vector side of your search.\nIt will also create all the necessary inverted index for BM25 search. Then you can do the hybrid search, using both keyword and similarity search.\nOne resource I really like is our python recipes, as they give you reproducible examples on using Weaviate directly and with other integrations:\n\n  \n\n      github.com\n  \n\n  \n    \n  \n\n  GitHub - weaviate/recipes: This repository shares end-to-end notebooks on how...\n\n    This repository shares end-to-end notebooks on how to use various Weaviate features and integrations!\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[LauraZ (2024-09-16T08:31:49.985Z)]: Morning\nI have a question related to hybrid search. We are testing weaviate locally and doing the embedding out of the database, and pass it the vector to insert and query data. But, because of this, If I fill query parameter query in the following call, it raises an error because the database can´t embed the query so I don´t know how I can pass the “keyword” part to the hybrid search\n            results = self.collection.query.hybrid(query=None,# No se puede pasar str pq falla al intentar hacer el embedding en la BD y no está configurado\n                                                   vector=vector,\n                                                   return_metadata=weaviate.classes.query.MetadataQuery(distance=True,score=True, explain_score=True),\n                                                   alpha=alpha,\n                                                   limit=top_k)\n\nAfter reading the forum, I have understood that the sparse vector is obtained inside the database. Is any configuration needed? How could we pass the text for the database to obtain the sparse vector in the hybrid search?\nThanks a lot for your help!\n\n----------\n\n[DudaNogueira (2024-09-16T20:47:57.146Z)]: this question was also asked and answered here:\n  \n    \n    \n    Hybrid search with embedding outside the database Support\n  \n  \n    hi @LauraZ !! \nThe hybrid search is a fusion of the keyword search and the vector search. \nWhen you provide the vector parameter, Weaviate will not vectorize the query for you. The query parameter will be used only for the keyword search phase. \nIf you do not provide the vector parameter, then Weaviate will vectorize it for you, considering you have a working vectorizer configured. \nCheck here for more information on that: \n\nLet me know if this helps. \nThanks!",
    "date_created": "2024-09-09T15:49:19.417Z",
    "has_accepted_answer": true,
    "title": "Hybrid Search Implementation Without Predefined Sparse Vectors in Weaviate",
    "topic_id": 4035
  },
  {
    "user_id": 1575,
    "conversation": "[Analitiq (2024-09-23T10:59:40.729Z)]: Description\nI keep getting an error when trying to run a query against the Weavaite cloud:\nAttributeError: '_QueryCollection' object has no attribute 'aggregate'\nI am lost as to what could be causing it as I have checked the documentation and done all the updates I could.\nThe code that I am running:\n# Establish a connection to Weaviate Cloud\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=\"\",\n    auth_credentials=weaviate.AuthApiKey(api_key=\"\")\n)\n\ncollection = client.collections.get(\"Test\")\n\n# Get collection specific to the required tenant\nmulti_tenants = collection.with_tenant(\"test\")\n\nmulti_tenants.query.aggregate(\"Test\") \\\n    .with_where({\n    \"path\": [\"document_name\"],\n    \"operator\": \"Equal\",\n    \"valueString\": \"document1\"\n}) \\\n    .with_tenant(tenant_id) \\\n    .with_fields(\"date_loaded { minimum maximum }\") \\\n    .do()\n\nServer Setup Information\n\nWeaviate Server Version: Weaviate Cloud\nDeployment Method:\nMulti Node? Number of Running Nodes:\nClient Language and Version: Python 3.11, Weaviate v.4.8.1\nMultitenancy\n\nAny additional Information\n\n----------\n\n[Mohamed_Shahin (2024-09-23T14:22:39.849Z)]: Hello @Analitiq,\nWelcome to our community! It’s lovely having you here.\nYou can aggregate with a condition as shown below:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAggregate data | Weaviate\n\n  Aggregate queries process the result set to return calculated results. Use aggregate queries for groups of objects or the entire result set.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nCould you please provide me your cluster endpoint? I will try to replicate and show you the method to aggregate.\nI recommend you to update your client and weaviate db to the latest version as client v3 will be deprecated very soon.\nAlso, I see you’re on Weaviate Cloud. Feel free to email us at support@weaviate.io, which will create a support ticket in our system for our paid customers.\nHave a lovely week!\n\n----------\n\n[Analitiq (2024-09-25T12:38:10.722Z)]: I have solved this like this:\nresponse = collection.aggregate.over_all(total_count=True, filters=filters)",
    "date_created": "2024-09-23T10:59:40.683Z",
    "has_accepted_answer": true,
    "title": "[Question] Running Aggregate against Weaviate Cloud",
    "topic_id": 4258
  },
  {
    "user_id": 3183,
    "conversation": "[Jyothi_Ram (2025-01-12T06:33:16.599Z)]: i am getting above error while connecting to my Weaviate client\nit is deployed in the eks\nbelow is my config i am unable to set the api-key\nauthentication:\n  anonymous_access:\n    enabled: false\n  # This configuration allows to add API keys to Weaviate. This configuration allows only\n  # plain text API Keys, if you want to store the API Keys in a Kubernetes secret you can\n  # configure the same configuration with ENV Vars. Read the `env` section below on what\n  # needs to be configured. If using ENV Vars over this make sure to comment out the whole\n  # `apikey` section (as it is by default). ENV Vars has priority over this config.\n  apikey:\n    enabled: true\n    #   # Any number of allowed API Keys as plain text\n    allowed_keys:\n    - testKey123\n    #     - admin-plainText-API-Key\n    #   # You can either set a single user for all the listed Allowed API keys OR\n    #   # one user per API Key, i.e. length(apikey.allowed_keys) == length(apikey.users) OR\n    #   # length(apikey.users) == 1\n    #   # NOTE: Make sure the lister Users are added to the Authorization as well.\n    users:\n    - admin\n    - dev\n  oidc:\n    enabled: false\n    # issuer: ''\n    # username_claim: ''\n    # groups_claim: ''\n    # client_id: ''\n\nauthorization:\n  rbac:\n    enabled: fasle\n    #  admins:\n    #  - admin\n    # - admin_user2\n    # viewers:\n    # - viewer_user1\n    # - readonly_user1\n  admin_list:\n    enabled: true\n    users:\n    - admin\n    # - admin_user2\n    # - api-key-user-admin\n    read_only_users:\n    - dev\n    # - readonly_user2\n    # - api-key-user-readOnly\nAUTHENTICATION_APIKEY_ENABLED: 'true'\n\n  # List one or more keys, separated by commas. Each key corresponds to a specific user identity below.\n  # If you want to use a kubernetes secret for the API Keys comment out this Variable and use the one in `envSecrets` below\n  AUTHENTICATION_APIKEY_ALLOWED_KEYS: 'secret1,secret2'\n\n  # List one or more user identities, separated by commas. You can have only one User for all the keys or one user per key.\n  # The User/s can be a simple name or an email, no matter if it exists or not.\n  # NOTE: Make sure to add the users to the authorization above overwise they will not be allowed to interact with Weaviate.\n  AUTHENTICATION_APIKEY_USERS: 'admin,dev'\n  # Enabling RBAC authorization. It is mutually exclusive with the AUTHORIZATION_ADMIN_LISTS variable. Either RBAC or the\n  # admin lists mechanism can be used.\n  # AUTHORIZATION_ENABLE_RBAC: \"true\"\n\n  # Users with admin's RBAC role. List one or more user identities, separated by commas, which will\n  # have the admin role assigned to. This role provides all permissions to the user, but it's required at least\n  # in one of the user for managing the cluster.\n  AUTHORIZATION_ADMIN_USERS: \"admin\"\n\n  # Users with viewer's RBAC role. List one or more user identities, separated by commas, which will\n  # have the viewer role assigned to. This role allows read permissions in all different areas. Once assigned via\n  # config, it can't be revoked via API AuthZ calls.\n  AUTHORIZATION_VIEWER_USERS: \"dev\"\n\nenvSecrets:\n  # create a Kubernetes secret with AUTHENTICATION_APIKEY_ALLOWED_KEYS key and its respective value\n  # AUTHENTICATION_APIKEY_ALLOWED_KEYS: name-of-the-k8s-secret-containing-the-comma-separated-api-keys\n\n----------\n\n[Mohamed_Shahin (2025-01-14T11:31:16.070Z)]: Good morning @Jyothi_Ram\nWelcome to our community! It’s great to have you here.\nHere is how to configure it:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nKubernetes | Weaviate\n\n  For a tutorial on how to use minikube to deploy Weaviate on Kubernetes, see the Weaviate Academy course, Weaviate on Kubernetes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nSee:\nauthentication:\n  anonymous_access:\n    enabled: false\n  apikey:\n    enabled: true\n    allowed_keys:\n      - testKey123\n    users:\n      - admin\n      - dev\nauthorization:\n  rbac:\n    enabled: false\n  admin_list:\n    enabled: true\n    users:\n      - admin\n      - api-key-user-admin\n  read_only_users:\n    - dev\n    - api-key-user-readOnly\n\nHope this helps!\nRegards,\nMohamed Shahin,\nWeaviate Support Engineer\n\n----------\n\n[Jyothi_Ram (2025-01-16T07:19:40.702Z)]: hi @Mohamed_Shahin thank you for responding\nimport weaviate, os\nfrom weaviate.classes.init import Auth\nclient = weaviate.connect_to_custom(\n    http_host=\"aXXXXXXXXXXX912472cb0cd4db7-XXXXXXXXX.eu-west-1.elb.amazonaws.com\",        # Hostname for the HTTP API connection\n    http_port=80,              # Default is 80, WCD uses 443\n    http_secure=False,           # Whether to use https (secure) for the HTTP API connection\n    grpc_host=\"acXXXXXXXXXXXXXXXX547ee912472cb0cd4db7-XXXXXXXXXXXX.eu-west-1.elb.amazonaws.com\",        # Hostname for the gRPC API connection\n    grpc_port=50051,              # Default is 50051, WCD uses 443\n    grpc_secure=False,           # Whether to use a secure channel for the gRPC API connection\n    auth_credentials=\"XXXXXXXX\",  # API key for authentication\n)\n\nprint(client.is_ready())\n\nusing above client to connect weaviate\ngetting the following error on running the client\n/home/jyothiram/.local/lib/python3.10/site-packages/weaviate/warnings.py:15: UserWarning: Auth001: The client is configured to use authentication, but weaviate is configured without\n                    authentication. Are you sure this is correct?\n  warnings.warn(\n    raise UnexpectedStatusCodeError(location, response)\nweaviate.exceptions.UnexpectedStatusCodeError: Meta endpoint! Unexpected status code: 401, with response body: {'code': 401, 'message': 'anonymous access not enabled, please provide an auth scheme such as OIDC'}.\n\nwe are useing below config\n---\nauthentication:\n  anonymous_access:\n    enabled: false\n  apikey:\n    allowed_keys:\n    - testKey123\n    - devKey\n    enabled: true\n    users:\n    - admin\n    - dev\n  oidc:\n    enabled: false\nauthorization:\n  admin_list:\n    enabled: true\n    read_only_users:\n    - dev\n    users:\n    - admin\n  rbac:\n    enabled: false\n\nquery_defaults:\n  limit: 100\ndebug: false\n\n----------\n\n[cfloressuazo (2025-02-13T21:01:22.774Z)]: Hi, your issue may be indentation. Check the following.\nUsing this config:\nauthentication:\n  anonymous_access:\n    enabled: false\n  apikey:\n    enabled: true\n    allowed_keys:\n      - XXXXXXXXX\n    users:\n      - user-1\n  oidc:\n    enabled: false\n\nauthorization:\n  rbac:\n    enabled: false\n  admin_list:\n    enabled: true\n    users:\n      - user-1\n\nand this python client:\nclient = weaviate.connect_to_custom(\n    http_host = \"host.name\",\n    http_port = 80,\n    http_secure = False,\n    grpc_host = \"grpc.host.name\",\n    grpc_port = 50051,\n    grpc_secure = False,\n    auth_credentials = Auth.api_key(weaviate_api_key)\n)\n\n----------\n\n[Jyothi_Ram (2025-03-13T07:01:24.269Z)]: hi @cfloressuazo  i follwed your instruction getting the same error\n---\nauthentication:\n  anonymous_access:\n    enabled: false\n  apikey:\n    enabled: true\n    allowed_keys:\n      - kejhkerhfgowrfghkuhruhjkfg\n    users:\n      - admin\n  oidc:\n    enabled: false\n\nauthorization:\n  rbac:\n    enabled: false\n  admin_list:\n    enabled: true\n    users:\n      - admin\n\nquery_defaults:\n  limit: 100\ndebug: false\n\nabove one is the config.yaml\non the  running the below code\nimport weaviate, os\nfrom weaviate.classes.init import Auth\nclient = weaviate.connect_to_custom(\n    http_host=\"a9cXXXXXXXXXXXXX776e0-1583455182.eu-west-1.elb.amazonaws.com\",        # Hostname for the HTTP API connection\n    http_port=80,              # Default is 80, WCD uses 443\n    http_secure=False,           # Whether to use https (secure) for the HTTP API connection\n    grpc_host=\"a76XXXXXXXXXXXXXXXb0f1583-1913758883.eu-west-1.elb.amazonaws.com\",        # Hostname for the gRPC API connection\n    grpc_port=50051,              # Default is 50051, WCD uses 443\n    grpc_secure=False,           # Whether to use a secure channel for the gRPC API connection\n    auth_credentials=\"kejhkerhfgowrfghkuhruhjkfg\",  # API key for authentication\n)\n\nprint(client.is_ready())\n\ngetting this error\nUserWarning: Auth001: The client is configured to use authentication, but weaviate is configured without\n                    authentication. Are you sure this is correct?\n\nweaviate.exceptions.UnexpectedStatusCodeError: Meta endpoint! Unexpected status code: 401, with response body: {'code': 401, 'message': 'anonymous access not enabled. Please authenticate through one of the available methods: [API-keys]'}.\n\n----------\n\n[Dirk (2025-03-13T07:19:54.553Z)]: Jyothi_Ram:\n\nauth_credentials=\"kejhkerhfgowrfghkuhruhjkfg\n\n\nThis needs to be auth_credentials=wvc.init.Auth.api_key(\"kejhkerhfgowrfghkuhruhjkfg\")\nI’ll see if we can improve this!\n\n----------\n\n[Jyothi_Ram (2025-03-15T13:55:46.444Z)]: Thanks @Dirk Now its Working",
    "date_created": "2025-01-12T06:33:16.547Z",
    "has_accepted_answer": true,
    "title": "Meta endpoint! Unexpected status code: 401, with response body: {'code': 401, 'message': 'anonymous access not enabled, please provide an auth scheme such as OIDC'}",
    "topic_id": 9682
  },
  {
    "user_id": 1545,
    "conversation": "[LauraZ (2024-09-16T11:10:52.288Z)]: Morning\nI have a question related to hybrid search. We are testing weaviate locally and doing the embedding out of the database, and pass it the vector to insert and query data. But, because of this, If I fill query parameter in the following code, it raises an error because the database can´t embed the query so I don´t know how I can pass the “keyword” part to the hybrid search\n            results = self.collection.query.hybrid(query=None,# No se puede pasar str pq falla al intentar hacer el embedding en la BD y no está configurado\n                                                   vector=vector,\n                                                   return_metadata=weaviate.classes.query.MetadataQuery(distance=True,score=True, explain_score=True),\n                                                   alpha=alpha,\n                                                   limit=top_k)\n\nAfter reading the forum, I have understood that the sparse vector is obtained inside the database. Is any configuration needed? How could we pass the text for the database to obtain the sparse vector in the hybrid search?\nThanks a lot for your help!\n\nWeaviate Server Version:\nDeployment Method: \nMulti Node? Number of Running Nodes:\nClient Language and Version:\nMultitenancy?:\n\nAny additional Information\n\n----------\n\n[DudaNogueira (2024-09-16T20:40:59.776Z)]: hi @LauraZ !!\nThe hybrid search is a fusion of the keyword search and the vector search.\nWhen you provide the vector parameter, Weaviate will not vectorize the query for you. The query parameter will be used only for the keyword search phase.\nIf you do not provide the vector parameter, then Weaviate will vectorize it for you, considering you have a working vectorizer configured.\nCheck here for more information on that:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nHybrid search | Weaviate\n\n  Hybrid search combines the results of a vector search and a keyword (BM25F) search by fusing the two result sets.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps.\nThanks!",
    "date_created": "2024-09-16T11:10:52.245Z",
    "has_accepted_answer": false,
    "title": "Hybrid search with embedding outside the database",
    "topic_id": 4171
  },
  {
    "user_id": 1168,
    "conversation": "[SmitNGRA (2024-07-31T20:04:48.724Z)]: On the Weaviate dashboard I am able to see the number of objects stored and dimension stored. I want to see how much MB/GB the cluster takes. I tried going through the documentation about collections statistics or meta data and I found a method related to collection configuration /collection properties.\nIs there any endpoint exposed for collection storage statistics ?\nThanks\n\n----------\n\n[DudaNogueira (2024-07-31T20:50:41.795Z)]: hi @SmitNGRA !!\nThose informations are not exposed in our Cloud Console.\nWe are working on having more metrics exposed in our dashboard.\nBut for now, I don’t have an ETA \nThanks!\n\n----------\n\n[bobvanluijt (2024-08-01T09:07:10.391Z)]: To add to this, this is coming!",
    "date_created": "2024-07-31T20:04:48.675Z",
    "has_accepted_answer": true,
    "title": "How to check size of cluster (GB/MB and not number of objects)",
    "topic_id": 3233
  },
  {
    "user_id": 530,
    "conversation": "[Alan_S (2024-08-20T20:23:41.976Z)]: Description\nHi Support Team,\nI have seen a lot of documentation on filtering by a reference. However, I do not see anything on how to filter for objects that do not have a reference. I am trying to do a fetch_objects query and only return objects that do not have a specific reference established at the object level. Any links or code snippets are much appreciated. Thank you!\n\n----------\n\n[Dirk (2024-08-21T06:52:28.119Z)]: Hi, please have a look here: Conditional filters | Weaviate - Vector Database",
    "date_created": "2024-08-20T20:23:41.929Z",
    "has_accepted_answer": true,
    "title": "Filter By Missing References",
    "topic_id": 3411
  },
  {
    "user_id": 513,
    "conversation": "[rjalex (2025-01-07T09:43:54.937Z)]: I am working on a project where the backend is a python application using weaviate and a next.js frontend to interact with the users.\nI would like to mantain a single source for the data schema and am using pydantic classes for this purpose.\nMy application objects are a pydantic class and my weaviate collection is described by a class derived from it with the collection name and the embedding module as aded metadata.\nI am using the same application object to generate the typescript interfaces from it.\nI would ideally want to use that pydantic class to generate the weaviate collection definition and/or constrain/typecheck the weaviate queries.\nAny good practices to suggest?\nHappy 2025 to all.\n\n----------\n\n[Dirk (2025-01-07T09:50:46.680Z)]: Hello and happy new year!\nWe should have direct support for this in the clients:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nPython | Weaviate\n\n  Utilize the Python client library to access Weaviate and streamline data processes.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nJS/TS client v3 | Weaviate\n\n  TypeScript Client Library v3\n\n----------\n\n[rjalex (2025-01-07T10:49:27.371Z)]: Thank you. Take care.",
    "date_created": "2025-01-07T09:43:54.895Z",
    "has_accepted_answer": false,
    "title": "Pydantic classes as single source of truth",
    "topic_id": 9604
  },
  {
    "user_id": 1214,
    "conversation": "[elias.gabriel (2024-07-31T23:15:37.116Z)]: Description\nI upgraded my Weaviate version to 1.26.1, but am observing all three of my Weaviate replicas in crash loops despite having a rolling update of 1; they all are crashing with the same error, though obviously the peer ids change depending on the node I’m looking at.\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":792,\"time\":\"2024-07-31T23:10:31Z\"}\n{\"action\":\"raft-net\",\"error\":\"could not resolve server id weaviate-2\",\"fallback\":\"10.0.20.103:8300\",\"id\":\"weaviate-2\",\"level\":\"warning\",\"msg\":\"raft-net unable to get address for server, using fallback address\",\"time\":\"2024-07-31T23:10:31Z\"}\n{\"action\":\"raft-net\",\"error\":\"could not resolve server id weaviate-1\",\"fallback\":\"10.0.3.69:8300\",\"id\":\"weaviate-1\",\"level\":\"warning\",\"msg\":\"raft-net unable to get address for server, using fallback address\",\"time\":\"2024-07-31T23:10:31Z\"}\n{\"action\":\"raft\",\"error\":\"dial tcp 10.0.20.103:8300: connect: connection refused\",\"level\":\"error\",\"msg\":\"raft failed to make requestVote RPC\",\"target\":{\"Suffrage\":0,\"ID\":\"weaviate-2\",\"Address\":\"10.0.20.103:8300\"},\"term\":792,\"time\":\"2024-07-31T23:10:31Z\"}\n{\"action\":\"raft\",\"error\":\"dial tcp 10.0.3.69:8300: connect: connection refused\",\"level\":\"error\",\"msg\":\"raft failed to make requestVote RPC\",\"target\":{\"Suffrage\":0,\"ID\":\"weaviate-1\",\"Address\":\"10.0.3.69:8300\"},\"term\":792,\"time\":\"2024-07-31T23:10:31Z\"}\n{\"level\":\"warning\",\"msg\":\"raft Election timeout reached, restarting election\",\"time\":\"2024-07-31T23:10:32Z\"}\n\n\nupdate: i deleted all the pods to see if recreating all together would solve the issue, but now i’m seeing a different error in all of them. The first 2 lines are repeated thousands of times (I assume corresponding with every object I had in every collection).\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Chunk_89043da9b84a4a8a9ef299c9f608602a\",\"index\":\"chunk_89043da9b84a4a8a9ef299c9f608602a\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/var/lib/weaviate/chunk_89043da9b84a4a8a9ef299c9f608602a/J0VmCeiHB40Q/lsm/property__lastUpdateTimeUnix/segment-1722465036274445156\",\"shard\":\"J0VmCeiHB40Q\",\"time\":\"2024-07-31T23:26:07Z\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Chunk_89043da9b84a4a8a9ef299c9f608602a\",\"index\":\"chunk_89043da9b84a4a8a9ef299c9f608602a\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/var/lib/weaviate/chunk_89043da9b84a4a8a9ef299c9f608602a/J0VmCeiHB40Q/lsm/property__lastUpdateTimeUnix/segment-1722468246818239897\",\"shard\":\"J0VmCeiHB40Q\",\"time\":\"2024-07-31T23:26:07Z\"}\n{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-07-31T23:26:07Z\",\"wait_for_cache_prefill\":false}\n{\"level\":\"info\",\"msg\":\"Completed loading shard chunk_89043da9b84a4a8a9ef299c9f608602a_J0VmCeiHB40Q in 12.150606ms\",\"time\":\"2024-07-31T23:26:07Z\"}\n{\"checkpoint\":0,\"component\":\"index_queue\",\"count\":0,\"last_stored_id\":1,\"level\":\"info\",\"msg\":\"enqueued vectors from last indexed checkpoint\",\"shard_id\":\"chunk_89043da9b84a4a8a9ef299c9f608602a_J0VmCeiHB40Q\",\"target_vector\":\"\",\"time\":\"2024-07-31T23:26:07Z\",\"took\":58961}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-07-31T23:26:07Z\",\"took\":369480}\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [10.0.5.66:8300 10.0.28.8:8300 10.0.27.24:8300]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"10.0.5.66:8300\",\"10.0.28.8:8300\",\"10.0.27.24:8300\"],\"time\":\"2024-07-31T23:26:07Z\",\"voter\":true}\n{\"action\":\"bootstrap\",\"error\":\"rpc error: code = DeadlineExceeded desc = context deadline exceeded\",\"level\":\"error\",\"msg\":\"notify all peers\",\"servers\":[\"10.0.5.66:8300\",\"10.0.28.8:8300\",\"10.0.27.24:8300\"],\"time\":\"2024-07-31T23:26:07Z\"}\n{\"action\":\"startup\",\"error\":\"bootstrap: context deadline exceeded\",\"level\":\"fatal\",\"msg\":\"could not open cloud meta store\",\"time\":\"2024-07-31T23:26:07Z\"}\n\nOnce they hit the last line, after ~30s or so, the pods get killed and it restart:\n{\"action\":\"config_load\",\"config_file_path\":\"/weaviate-config/conf.yaml\",\"level\":\"info\",\"msg\":\"Usage of the weaviate.conf.json file is deprecated and will be removed in the future. Please use environment variables.\",\"time\":\"2024-07-31T23:33:48Z\"}\n{\"deprecation\":{\"apiType\":\"Configuration\",\"id\":\"config-files\",\"locations\":[\"--config-file=\\\"\\\"\"],\"mitigation\":\"Configure Weaviate using environment variables.\",\"msg\":\"use of deprecated command line argument --config-file\",\"sinceTime\":\"2020-09-08T09:46:00.000Z\",\"sinceVersion\":\"0.22.16\",\"status\":\"deprecated\"},\"level\":\"warning\",\"msg\":\"use of deprecated command line argument --config-file\",\"time\":\"2024-07-31T23:33:48Z\"}\n{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-07-31T23:33:48Z\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":false,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"false\\\"\",\"time\":\"2024-07-31T23:33:48Z\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-07-31T23:33:48Z\"}\n{\"level\":\"info\",\"msg\":\"async indexing enabled\",\"time\":\"2024-07-31T23:33:48Z\"}\n{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-07-31T23:33:48Z\"}\n{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"weaviate-0\":8300,\"weaviate-1\":8300,\"weaviate-2\":8300},\"time\":\"2024-07-31T23:33:50Z\"}\n{\"address\":\"10.0.5.66:8301\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-07-31T23:33:50Z\"}\n{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-07-31T23:33:50Z\"}\n{\"address\":\"10.0.5.66:8300\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-07-31T23:33:50Z\"}\n{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-07-31T23:33:50Z\"}\n{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-07-31T23:33:50Z\"}\n{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-07-31T23:33:50Z\"}\n{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"weaviate-0\",\"time\":\"2024-07-31T23:33:50Z\"}\n{\"action\":\"raft\",\"index\":616,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:weaviate-2 Address:10.0.27.24:8300} {Suffrage:Voter ID:weaviate-1 Address:10.0.28.8:8300} {Suffrage:Voter ID:weaviate-0 Address:10.0.5.66:8300}]]\",\"time\":\"2024-07-31T23:33:50Z\"}\n{\"last_snapshot_index\":0,\"last_store_applied_index\":0,\"last_store_log_applied_index\":553,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":616,\"time\":\"2024-07-31T23:33:50Z\"}\n{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-07-31T23:33:50Z\"}\n{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-07-31T23:33:52Z\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":917,\"time\":\"2024-07-31T23:33:52Z\"}\n{\"docker_image_tag\":\"1.26.1\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-07-31T23:33:52Z\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2024-07-31T23:33:52Z\"}\n{\"action\":\"restapi_management\",\"docker_image_tag\":\"1.26.1\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://[::]:8080\",\"time\":\"2024-07-31T23:33:52Z\"}\n{\"level\":\"warning\",\"msg\":\"raft Election timeout reached, restarting election\",\"time\":\"2024-07-31T23:33:53Z\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":918,\"time\":\"2024-07-31T23:33:53Z\"}\n{\"level\":\"warning\",\"msg\":\"raft Election timeout reached, restarting election\",\"time\":\"2024-07-31T23:33:54Z\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":919,\"time\":\"2024-07-31T23:33:54Z\"}\n{\"level\":\"warning\",\"msg\":\"raft Election timeout reached, restarting election\",\"time\":\"2024-07-31T23:33:56Z\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":920,\"time\":\"2024-07-31T23:33:56Z\"}\n{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-07-31T23:33:57Z\"}\n{\"action\":\"raft\",\"error\":\"log not found\",\"last-index\":616,\"level\":\"warning\",\"msg\":\"raft failed to get previous log\",\"previous-index\":620,\"time\":\"2024-07-31T23:33:57Z\"}\n{\"address\":\"10.0.28.8:8300\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-07-31T23:33:58Z\"}\n\nServer Setup Information\n\nWeaviate Server Version: 1.26.1\nDeployment Method: Kubernetes\nMulti Node? Number of Running Nodes: 3\nClient Language and Version:\nMultitenancy?: No\n\n----------\n\n[DudaNogueira (2024-08-01T15:14:23.953Z)]: Hi!\nFrom which version you upgraded from?\nThere is some specific instructions for migrating from 1.24+ and onwards. Let me know if you have followed this:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\n1.25 (For Kubernetes users) | Weaviate - Vector Database\n\n  Assumptions & requirements\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!\n\n----------\n\n[elias.gabriel (2024-08-01T16:44:36.268Z)]: I upgraded from 1.25.8, which was the initial version of the cluster.\n\n----------\n\n[DudaNogueira (2024-08-01T19:46:36.390Z)]: Considering the first logs, it seems that the nodes were not able to communicate between them.\nthe first log is probably from weaviate-0. Probably this was a network issue that could be solved with the new pods \nabout the second log, the first two is Weaviate try to restore from previous crash. Nothing to worry.\nthe last ones are the ones to look. Seems it again cannot join the cluster.\nHow many objects are there? One possibility is that, it doesn’t have enough resources to spin up the nodes.\nDo you see any outstanding k8s events?\n\n----------\n\n[elias.gabriel (2024-08-09T16:23:52.424Z)]: I have since resolved this by deleting all the persistent volumes & claims attached to my replicas and starting fresh, so I don’t think I can further debug anything.\nBut at the time, I know it was not a networking issue on the clusters because I verified connectivity between the pods themselves before posting here. I also deleted the pods several times but hit the same error on each pod each time.\nIf you have a cluster of nodes, should the cluster still come up even if all 3 nodes are down? Again, none of the replicas were alive, but based on the logs it seems like each replica assumed that at least 1 other node would be running (or at least that another node would decide to be the leader, which none of them did).\nThere were no noteworthy K8 events.\nAre there resource constraints in order to spin up a node? I was under the impression that they would max out whatever node is available to them. My replicas are running on nodes with 32 GiB of RAM, and I certainly did not have even remotely close to that amount of data.",
    "date_created": "2024-07-31T23:15:37.062Z",
    "has_accepted_answer": false,
    "title": "Node crashloop in K8 deployment",
    "topic_id": 3236
  },
  {
    "user_id": 1509,
    "conversation": "[matt (2024-09-10T06:00:41.218Z)]: Deploy Weaviate in Azure port issue\nI have followed the following article:\nSetting up Weaviate on Azure with Multi-Container App - Stochastic Coder\nIt is up and running however, the web app container app needs to be exposed 8080 which is not possible. I am trying to make this app accessible so that 2 other apps reaches and utilise this. How is it possible? thanks\n\n----------\n\n[DudaNogueira (2024-09-10T14:34:14.428Z)]: Hi! You may not need to expose Weaviate, if your apps will be running alongside it at the same docker network.\nIf you still need to expose Weaviate, so an app can access it remotely, you can change the port Weaviate will run.\nYou can do that by changing the default command:\nlike specified here:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nDocker | Weaviate\n\n  Weaviate supports deployment with Docker.\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps",
    "date_created": "2024-09-10T06:00:41.167Z",
    "has_accepted_answer": false,
    "title": "Weaviate Azure Container App port",
    "topic_id": 4055
  },
  {
    "user_id": 3595,
    "conversation": "[OpperLourens (2025-03-02T13:23:43.990Z)]: I created a sandbox Weaviate instance and quickly hit my sandbox rate limit, so I upgraded to a paid plan, though I still get:\n“update vector: Weaviate embed API error: 429 Daily sandbox request limit exceeded. Please try again tomorrow.”\nI was not aware of such a limit existing and it kind of defeats the purpose (I have a big database that does not change frequently but should not be limited by an API rate limit as long as the package is nowhere near its limits…)\nWhat do I do?\n\n----------\n\n[Mohamed_Shahin (2025-03-02T20:30:43.571Z)]: Hi @OpperLourens,\nWelcome to our community! It’s great to have you with us.\nSince you’ve upgraded and are now using our cloud services, please reach out to us via support@weaviate.io to open a ticket in our internal system. We’ll look into your issue immediately.\nPease make sure to provide all the details about the sandbox details and we’ll get you sorted right away.\nBest regards,\nMohamed Shahin\nSupport Engineer",
    "date_created": "2025-03-02T13:23:43.945Z",
    "has_accepted_answer": false,
    "title": "429 after upgrading",
    "topic_id": 10627
  },
  {
    "user_id": 1249,
    "conversation": "[SergioEanX (2024-11-22T09:33:49.123Z)]: Description\nI stored objects in Weaviate Embedded like the following:\n\nexample_object_1 = {\n“name”: “John Smith”,\n“home_address”: {\n“street”: {\n“number”: 123,\n“name”: “Main Street”,\n},\n“city”: “London”,\n},\n“office_addresses”: [\n{\n“office_name”: “London HQ”,\n“street”: {“number”: 456, “name”: “Oxford Street”},\n},\n{\n“office_name”: “Manchester Branch”,\n“street”: {“number”: 789, “name”: “Piccadilly Gardens”},\n},\n],\n}\n\nI would like to filter on street number, is this possible? Alternative approach?\nI tried with\nresponse = persons.query.near_text(\n    query=\"person named John\",\n    limit=2,\n    filters=(\n        Filter.by_property(\"office_addresses\").contains_any([ {\"street\":{\"number\":789}}])\n \n    ),\n    # distance= 0.8,       \n    return_metadata=MetadataQuery(distance=True)\n)\n\nBut does not work giving error:\nvalue.json-or-python[json=list[union[str,uuid]],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]].0.uuid\n  UUID input should be a string, bytes or UUID object [type=uuid_type, input_value={'street': {'number': 789}}, input_type=dict]\n\nThe collection was created as:\nmy_collection = client.collections.create(\n    name=\"Person\",\n    vectorizer_config=Configure.Vectorizer.text2vec_cohere(model=\"embed-multilingual-light-v3.0\"),\n    properties=[\n        Property(name=\"name\", data_type=DataType.TEXT, ),\n        Property(\n            name=\"home_address\",\n            data_type=DataType.OBJECT,\n            nested_properties=[\n                Property(\n                    name=\"street\",\n                   \n                    data_type=DataType.OBJECT,\n                    nested_properties=[\n                        Property(name=\"number\", data_type=DataType.INT),\n                        Property(name=\"name\", data_type=DataType.TEXT),\n                    ],\n                ),\n                Property(name=\"city\", data_type=DataType.TEXT,  index_searchable=True),\n            ],\n        ),\n        Property(\n            name=\"office_addresses\",\n            index_filterable=True,\n            data_type=DataType.OBJECT_ARRAY,\n            nested_properties=[\n                Property(name=\"office_name\", data_type=DataType.TEXT, index_searchable=True, index_filterable=True),\n                Property(\n                    name=\"street\",\n                    data_type=DataType.OBJECT,\n                    nested_properties=[\n                        Property(name=\"name\", data_type=DataType.TEXT, index_searchable=True),\n                        Property(name=\"number\", data_type=DataType.INT),\n                    ],\n                ),\n            ],\n        ),\n    ],\n    \n)\n\nServer Setup Information\n\nWeaviate Server Version: 2.7.4\nDeployment Method:  embedded\nMulti Node? Number of Running Nodes:  single node\nClient Language and Version: Python\nMultitenancy?: No\n\nAny additional Information\nPython weaviate-client version 4.9.3\n\n----------\n\n[DudaNogueira (2024-11-22T13:05:01.589Z)]: hi @SergioEanX !!\nThe object data type has some limitations, as of now.\nfrom our docs:\n\nLIMITATIONS:\nCurrently, object and object[] datatype properties are not indexed and not vectorized.\nFuture plans include the ability to index nested properties, for example to allow for filtering on nested properties and vectorization options.\n\nSo in that case, you need to bring that information you want to filter out from the object data type, for example, a number or text.\nLet me know if this helps!\nTHanks!",
    "date_created": "2024-11-22T09:33:49.024Z",
    "has_accepted_answer": true,
    "title": "How filter array objects",
    "topic_id": 7772
  },
  {
    "user_id": 126,
    "conversation": "[Iammsd07 (2024-01-16T11:53:07.543Z)]: Hi Team,\nMy data looks something like below:\n{\n\"article_id\": \"122\",\n\"product\": [\"all\"],\n\"annotations\": [\n            {\n                \"label\": \"08\",\n                \"type\": \"error-code\"\n            },\n            {\n                \"label\": \"37\",\n                \"type\": \"error-code\"\n            }\n        ]\n}\n\nI am using below where filter:\n{'operator': 'And', 'operands': [{'path': ['product'], 'operator': 'ContainsAny', 'valueTextArray': ['all']}, {'path': ['annotations', 'type'], 'operator': 'ContainsAny', 'valueTextArray': ['error-code']}]}\n\nAnd I am getting below error:\n{'data': {'Get': {'Class_name': None}}, 'errors': [{'locations': [{'column': 6, 'line': 1}], 'message': \"could not extract filters: invalid where filter: operand 1: invalid where filter: missing an argument after 'type'\", 'path': ['Get', 'Class_name']}]}\n\nHow should I build a query?\nI am using Weaviate 1.21.0 image and python weaviate-client 3.25.3.\nThanks in advance.\n\n----------\n\n[DudaNogueira (2024-01-17T15:32:01.212Z)]: Hi!\nNested object filtering is not supported as of now.\nCheck here for more information on that:\n  \n      \n\n      weaviate.io – 23 Oct 23\n  \n\n  \n    \n\nWeaviate 1.22 Release | Weaviate - Vector Database\n\n  Weaviate 1.22 released with nest object storage, async indexing, further gRPC support, and more!\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!\n\n----------\n\n[Isaac_Yimgaing_Kuiss (2024-08-25T00:38:41.708Z)]: Hi,\nDo you now suppose nested field filtering please ?\n\n----------\n\n[DudaNogueira (2024-08-26T12:40:10.560Z)]: hi @Isaac_Yimgaing_Kuiss !\nThis is not supported yet.\nPlease, leave your thumbs up  (so it can go higher in our roadmap)  and follow this Github ticket for updates:\n  \n\n      github.com/weaviate/weaviate\n  \n\n  \n    \n  \n\t  \n  \n\n  \n    \n      Filtering and Vectorization for Nested Objects\n    \n\n    \n      \n        opened 07:34AM - 29 Oct 23 UTC\n      \n\n\n      \n        \n          \n          etiennedi\n        \n      \n    \n\n    \n        \n          backlog\n        \n    \n  \n\n\n  \n    #2424 introduced storing of nested objects. The next step is to make filtering (…and vectorization for modules) available for them.\n  \n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!",
    "date_created": "2024-01-16T11:53:07.495Z",
    "has_accepted_answer": false,
    "title": "Not able to perform nested search query",
    "topic_id": 1235
  },
  {
    "user_id": 815,
    "conversation": "[ujjwalm29 (2024-04-13T14:53:16.107Z)]: I was wondering if there’s a way to to get the total number of objects stored in the index through the python client library?\nRight now, I get the collection, run through the entire iterator and count instances?\n\n----------\n\n[DudaNogueira (2024-04-15T10:26:09.111Z)]: hi @ujjwalm29 !! Welcome to our community! \niterating thru all the objects is not the optimal way.\nYou can aggregate over all your objects and get the top count:\naggregation = questions.aggregate.over_all(total_count=True)\nprint(aggregation.total_count)\n\nCheck here for more options on that:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nAggregate | Weaviate - Vector Database\n\n  This page covers aggregation queries. They are collectively referred to as Aggregate queries within.\n\n----------\n\n[thortek (2024-08-15T00:41:09.621Z)]: How about when using the JS/TS Client v3?  I can’t locate documentation in v3 on the same sort of aggregate functionality found in v2.\n\n----------\n\n[DudaNogueira (2024-08-15T15:14:30.700Z)]: hi @thortek !!\nWelcome to our community!! \nYou are right! We are missing some examples there \nhere is how to do it using all the bells and whistles:\n  await client.collections.delete(\"Test\");\n  const collection = await client.collections.create({\n    name: \"Test\", \n  });\n  await collection.data.insert({\"text\": \"aaa\"})\n  await collection.data.insert({\"text\": \"bbb\"})\n\n  const r = await collection.aggregate.overAll({\n    filters: collection.filter.byProperty('text').equal(\"aaa\"),\n    returnMetrics: collection.metrics\n    .aggregate('text')\n    .text(['count', 'topOccurrencesOccurs', 'topOccurrencesValue'])\n  })\n  console.log(\"Total Count\", r.totalCount)\n  console.log(\"text property\", r.properties.text)\n\nthis will output:\n\nTotal Count 1\ntext property { count: 1, topOccurrences: [ { occurs: 1, value: ‘aaa’ } ] }\n\nLet me know if this helps!\nThanks!\n\n----------\n\n[thortek (2024-08-28T14:09:13.941Z)]: Yes, that is what I needed.  Thanks for providing the example code!",
    "date_created": "2024-04-13T14:53:16.048Z",
    "has_accepted_answer": true,
    "title": "Get total number of objects in an index?",
    "topic_id": 2009
  },
  {
    "user_id": 927,
    "conversation": "[maddios (2024-05-23T06:44:51.557Z)]: Description\nGetting the following error in my docker logs:\n{“action”:“lsm_compaction”,“class”:“SearchMedia”,“error”:“write index: unlinkat /var/lib/weaviate/searchmedia/IfEh5Wm9v9no/lsm/property__id/segment-1716445594153867176.dbcompaction.scratch.d: directory not empty”,“index”:“searchmedia”,“level”:“error”,“msg”:“compaction failed”,“path”:“/var/lib/weaviate/searchmedia/IfEh5Wm9v9no/lsm/property__id”,“shard”:“IfEh5Wm9v9no”,“time”:“2024-05-23T06:28:05Z”}\nI’m not certain what action is even causing this as I’m currently running a long batch script which does a whole bunch of stuff, like read, write, delete, etc.\nQuestion is, when this error is triggered, does this block data insertion/deletion/update?\nHow do I avoid/fix this issue?\nThanks.\nServer Setup Information\n\nWeaviate Server Version:  1.24.12\nDeployment Method: docker\nMulti Node? Number of Running Nodes: single node\nClient Language and Version: graphql api\n\nAny additional Information\nthe log is full of errors like that across various schemas\n{\"action\":\"lsm_compaction\",\"class\":\"SearchMediaAiData\",\"error\":\"write index: unlinkat /var/lib/weaviate/searchmediaaidata/MBpQZ57WbgJ4/lsm/property_media_id/segment-1716446470745179201.dbcompaction.scratch.d: directory not empty\",\"index\":\"searchmediaaidata\",\"level\":\"error\",\"msg\":\"compaction failed\",\"path\":\"/var/lib/weaviate/searchmediaaidata/MBpQZ57WbgJ4/lsm/property_media_id\",\"shard\":\"MBpQZ57WbgJ4\",\"time\":\"2024-05-23T06:42:28Z\"}\n{\"action\":\"lsm_compaction\",\"class\":\"SearchMedia\",\"error\":\"write index: unlinkat /var/lib/weaviate/searchmedia/IfEh5Wm9v9no/lsm/property_workspace_id/segment-1716446450236052497.dbcompaction.scratch.d: directory not empty\",\"index\":\"searchmedia\",\"level\":\"error\",\"msg\":\"compaction failed\",\"path\":\"/var/lib/weaviate/searchmedia/IfEh5Wm9v9no/lsm/property_workspace_id\",\"shard\":\"IfEh5Wm9v9no\",\"time\":\"2024-05-23T06:41:54Z\"}\n\n----------\n\n[maddios (2024-05-25T05:43:50.550Z)]: Just did some poking around and noticed that the folder mentioned in the error, eg\n2024-05-25T05:40:42Z ERR action=lsm_memtable_flush class=SearchMedia error=flush: unlinkat /var/lib/weaviate/searchmedia/IfEh5Wm9v9no/lsm/property_species/segment-1716615577153457021.scratch.d: directory not empty index=searchmedia msg=flush and switch failed path=/var/lib/weaviate/searchmedia/IfEh5Wm9v9no/lsm/property_species shard=IfEh5Wm9v9no\n\n\nsearchmedia/IfEh5Wm9v9no/lsm/property_species\n\nhas a bunch of temp files within it\n-rw-r--r--. 1 root root    44 May 21 13:30 segment-1716288681209710108_1716288762729670859.bloom.tmp\n-rw-r--r--. 1 root root     0 May 21 16:51 segment-1716324171938779796.db\ndrwxr-xr-x. 2 root root  6144 May 21 16:51 segment-1716324171938779796.scratch.d\n-rw-r--r--. 1 root root 15957 May 21 16:51 segment-1716324171938779796.wal\n-rw-r--r--. 1 root root     0 May 23 02:22 segment-1716445285001700267.db\ndrwxr-xr-x. 2 root root  6144 May 23 02:22 segment-1716445285001700267.scratch.d\n-rw-r--r--. 1 root root 25183 May 23 02:22 segment-1716445285001700267.wal\n-rw-r--r--. 1 root root     0 May 23 02:45 segment-1716446691485583063.db\ndrwxr-xr-x. 2 root root  6144 May 23 02:45 segment-1716446691485583063.scratch.d\n-rw-r--r--. 1 root root 12452 May 23 02:45 segment-1716446691485583063.wal\n-rw-r--r--. 1 root root   180 May 23 03:15 segment-1716448427893915688.bloom\n-rw-r--r--. 1 root root 30594 May 23 03:15 segment-1716448427893915688.db\n-rw-r--r--. 1 root root     0 May 23 03:17 segment-1716448617499313354.db\ndrwxr-xr-x. 2 root root  6144 May 23 03:18 segment-1716448617499313354.scratch.d\n-rw-r--r--. 1 root root 32350 May 23 03:17 segment-1716448617499313354.wal\n-rw-r--r--. 1 root root    68 May 25 01:24 segment-1716614577068659393.bloom\n-rw-r--r--. 1 root root 12986 May 25 01:24 segment-1716614577068659393.db\n-rw-r--r--. 1 root root    60 May 25 01:33 segment-1716615087990253309.bloom\n-rw-r--r--. 1 root root  6760 May 25 01:33 segment-1716615087990253309.db\n-rw-r--r--. 1 root root     0 May 25 01:35 segment-1716615240522512874.db\ndrwxr-xr-x. 2 root root  6144 May 25 01:35 segment-1716615240522512874.scratch.d\n-rw-r--r--. 1 root root  6988 May 25 01:34 segment-1716615240522512874.wal\n-rw-r--r--. 1 root root    52 May 25 01:38 segment-1716615443820378940.bloom\n-rw-r--r--. 1 root root  4956 May 25 01:38 segment-1716615443820378940.db\n-rw-r--r--. 1 root root     0 May 25 01:40 segment-1716615577153457021.db\ndrwxr-xr-x. 2 root root  6144 May 25 01:40 segment-1716615577153457021.scratch.d\n-rw-r--r--. 1 root root 24940 May 25 01:40 segment-1716615577153457021.wal\n-rw-r--r--. 1 root root    44 May 25 01:41 segment-1716615642151563559.bloom\n-rw-r--r--. 1 root root  2562 May 25 01:41 segment-1716615642151563559.db\n-rw-r--r--. 1 root root 19046 May 25 01:42 segment-1716615708499458602.wal\n\nWhat’s up with these files?\nHow do I clean these files up to get rid of the errors? Should I make a backup and just delete them?\nAs far as I can tell all the data is inserting just fine and I’m able to query it.\n\n----------\n\n[saurbhhsharrma (2024-07-02T00:29:08.730Z)]: @maddios - I’m also facing similar issue and got below error. Did you find any resolution for this?\n{\"action\":\"lsm_memtable_flush\",\"class\":\"WeaviateDemo3\",\"error\":\"flush: unlinkat /var/lib/weaviate/weaviatedemo3/PXksOv6syq7H/lsm/objects/segment-1719829104648996364.scratch.d: directory not empty\",\"index\":\"weaviatedemo3\",\"level\":\"error\",\"msg\":\"flush and switch failed\",\"path\":\"/var/lib/weaviate/weaviatedemo3/PXksOv6syq7H/lsm/objects\",\"shard\":\"PXksOv6syq7H\",\"time\":\"2024-07-01T10:18:50Z\"}\n\n@jphwang\n\n----------\n\n[saurbhhsharrma (2024-09-16T18:48:22.848Z)]: Any update on this? I’m still facing this issue with the latest version as well.\n@DudaNogueira @maddios",
    "date_created": "2024-05-23T06:44:51.508Z",
    "has_accepted_answer": false,
    "title": "Compation failed",
    "topic_id": 2435
  },
  {
    "user_id": 1221,
    "conversation": "[GaryKung67 (2024-07-19T08:06:58.211Z)]: Vector Database got scoring STD to make rank from user feedback.\n\n----------\n\n[DudaNogueira (2024-07-19T16:19:21.700Z)]: Hi!\nWelcome to our community \nNot sure I understood this question \nCan you elaborate on that?\nThis doc may be related:\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nDistance metrics | Weaviate - Vector Database\n\n  - Configuration: Schema\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nThanks!\n\n----------\n\n[GaryKung67 (2024-07-22T05:10:47.377Z)]: should we need to define the training format for vector database or GAI if we want to build up common vector database…\n\n----------\n\n[DudaNogueira (2024-07-23T12:47:19.512Z)]: Hi! you mean the model?\nWe have an upcoming event on Intro to Weaviate. I believe it would be interesting to attend to set some basics on WeaviatE:\n\n  \n      \n\n      weaviate.io\n  \n\n  \n    \n\nOnline Workshops & Events | Weaviate - Vector Database\n\n  -Join us at conferences, meetups, webinars or workshops\n\n\n  \n\n  \n    \n    \n  \n\n  \n\n\nLet me know if this helps, as I was not able to understand your questions properly",
    "date_created": "2024-07-19T08:06:58.160Z",
    "has_accepted_answer": false,
    "title": "How to build up Vector Database ranking criteria?",
    "topic_id": 3100
  },
  {
    "user_id": 1226,
    "conversation": "[swetag (2024-08-21T10:35:46.103Z)]: Description\nHi,\nWhen the weaviate sever is deployed, in the first 15 minutes if we perform a hybrid search, we are getting this error from weaviate:\nTraceback (most recent call last):   File \"/app/venv/lib/python3.10/site-packages/weaviate/collections/grpc/query.py\", line 649, in __call     res, _ = self._connection.grpc_stub.Search.with_call(   File \"/app/venv/lib/python3.10/site-packages/grpc/_channel.py\", line 1198, in with_call     return _end_unary_response_blocking(state, call, True, None)   File \"/app/venv/lib/python3.10/site-packages/grpc/_channel.py\", line 1006, in _end_unary_response_blocking     raise _InactiveRpcError(state)  # pytype: disable=not-instantiable grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with: \\tstatus = StatusCode.UNAVAILABLE \\tdetails = \"sendmsg: Socket operation on non-socket (88)\" \\tdebug_error_string = \"UNKNOWN:\nError\nreceived from peer {created_time:\"2024-08-21T10:04:43.533570886+00:00\", grpc_status:14, grpc_message:\"sendmsg: Socket operation on non-socket (88)\"}\" >\nFile \"/app/venv/lib/python3.10/site-packages/weaviate/collections/queries/hybrid/query.py\", line 105, in hybrid res = self._query.hybrid( File \"/app/venv/lib/python3.10/site-packages/weaviate/collections/grpc/query.py\", line 246, in hybrid return self.__call(request) File \"/app/venv/lib/python3.10/site-packages/weaviate/collections/grpc/query.py\", line 658, in __call raise WeaviateQueryError(e.details(), \"GRPC search\") # pyright: ignore weaviate.exceptions.WeaviateQueryError: Query call with protocol GRPC search failed with message sendmsg: Socket operation on non-socket (88).\nThis is getting resolved in next 15-20 minutes on its own but what is the reason for this error and how to resolve this?\nI am getting error at this line :\ncollection.query.hybrid(**hybrid_params).objects\nThis is how the client is created:\nweaviate_connection_config = AdditionalConfig(\nconnection=ConnectionConfig(\nsession_pool_connections=20,\nsession_pool_maxsize=20,\n),\ntimeout=(\n60,180),\n)\nclient = weaviate.connect_to_custom(\nhttp_host=url,\nhttp_port=8080,\nhttp_secure=False,\ngrpc_host=url,\ngrpc_port=50051,\ngrpc_secure=False,\nadditional_config=weaviate_connection_config,\n)\nServer Setup Information\n\nWeaviate Server Version: 1.23.7\nDeployment Method: docker\nMulti Node? Number of Running Nodes: 1\nClient Language and Version:4.6.5\n\nTIA.\n\n----------\n\n[DudaNogueira (2024-08-21T12:06:38.457Z)]: hi @swetag !!\nDo you see any logs in the server side?\nAlso, do you have any readings on resource and have you tweaked any of the parameters as stated in Resource Planning?\n1.23.7 is fairly “old”. \nIs it possible to test this on latest version?\n\n----------\n\n[swetag (2024-08-22T05:50:44.124Z)]: Hi @DudaNogueira,\n\nNo logs on the server side.\nThese are the resource related env variables for weaviate.\nLIMIT_RESOURCES: true\nGOMEMLIMIT: 7680MiB\nQUERY_MAXIMUM_RESULTS: 1000000\nDISK_USE_READONLY_PERCENTAGE: 95\nI had to use this version because most of the 1.24.x, 1.25.x, 1.26.0 (all of which I tried) are leading me to this issue, but 1.23.7 is not.\nAdditionally, I was also getting the same behavior with 1.25.6\n\n----------\n\n[DudaNogueira (2024-08-22T18:09:09.120Z)]: Do you still have this kind of issue even when allocating more memory from the host?\nIs this cluster exposed somehow, for example, using a load balancer, or is the client connecting directly to the server within the same docker network?",
    "date_created": "2024-08-21T10:35:46.041Z",
    "has_accepted_answer": false,
    "title": "Query call with protocol GRPC search failed with message sendmsg: Socket operation on non-socket (88)",
    "topic_id": 3414
  },
  {
    "user_id": 3145,
    "conversation": "[Rishav_Kumar_Paramha (2025-01-06T14:34:02.173Z)]: Description\nHi All, I have create a docker image for Weaviate using the docker compose file:\n---\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.27.8\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_API_BASED_MODULES: 'true'\n      CLUSTER_HOSTNAME: 'node1'\nvolumes:\n  weaviate_data:\n...\n\nand trying to connect to the Wevaite client like this:\n# Now use the host, port, and grpc_port in the connection\nclient = weaviate.connect_to_local(\n    host=\"127.0.0.1\",  # Use a string to specify the host\n    port=8080,\n    grpc_port=50051,\n)\n\nIt works absolutely fine when i have Weaviate container running on my local machine using Docker desktop and a script to connect to the instance. But as soon as i try to connect to the Weaviate container from another container - it always ends up with this error:\n2025-01-04 15:02:30 Traceback (most recent call last):\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpx/_transports/default.py”, line 69, in map_httpcore_exceptions\n2025-01-04 15:02:30     yield\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpx/_transports/default.py”, line 373, in handle_async_request\n2025-01-04 15:02:30     resp = await self._pool.handle_async_request(req)\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpcore/_async/connection_pool.py”, line 256, in handle_async_request\n2025-01-04 15:02:30     raise exc from None\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpcore/_async/connection_pool.py”, line 236, in handle_async_request\n2025-01-04 15:02:30     response = await connection.handle_async_request(\n2025-01-04 15:02:30                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpcore/_async/connection.py”, line 101, in handle_async_request\n2025-01-04 15:02:30     raise exc\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpcore/_async/connection.py”, line 78, in handle_async_request\n2025-01-04 15:02:30     stream = await self._connect(request)\n2025-01-04 15:02:30              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpcore/_async/connection.py”, line 124, in _connect\n2025-01-04 15:02:30     stream = await self._network_backend.connect_tcp(**kwargs)\n2025-01-04 15:02:30              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpcore/_backends/auto.py”, line 31, in connect_tcp\n2025-01-04 15:02:30     return await self._backend.connect_tcp(\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpcore/_backends/anyio.py”, line 113, in connect_tcp\n2025-01-04 15:02:30     with map_exceptions(exc_map):\n2025-01-04 15:02:30          ^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/contextlib.py”, line 158, in exit\n2025-01-04 15:02:30     self.gen.throw(value)\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpcore/_exceptions.py”, line 14, in map_exceptions\n2025-01-04 15:02:30     raise to_exc(exc) from exc\n2025-01-04 15:02:30 httpcore.ConnectError: All connection attempts failed\n2025-01-04 15:02:30\n2025-01-04 15:02:30 The above exception was the direct cause of the following exception:\n2025-01-04 15:02:30\n2025-01-04 15:02:30 Traceback (most recent call last):\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/weaviate/connect/v4.py”, line 264, in _open_connections_rest\n2025-01-04 15:02:30     response = await client.get(oidc_url)\n2025-01-04 15:02:30                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpx/_client.py”, line 1801, in get\n2025-01-04 15:02:30     return await self.request(\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpx/_client.py”, line 1574, in request\n2025-01-04 15:02:30     return await self.send(request, auth=auth, follow_redirects=follow_redirects)\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpx/_client.py”, line 1661, in send\n2025-01-04 15:02:30     response = await self._send_handling_auth(\n2025-01-04 15:02:30                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpx/_client.py”, line 1689, in _send_handling_auth\n2025-01-04 15:02:30     response = await self._send_handling_redirects(\n2025-01-04 15:02:30                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpx/_client.py”, line 1726, in _send_handling_redirects\n2025-01-04 15:02:30     response = await self._send_single_request(request)\n2025-01-04 15:02:30                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpx/_client.py”, line 1763, in _send_single_request\n2025-01-04 15:02:30     response = await transport.handle_async_request(request)\n2025-01-04 15:02:30                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpx/_transports/default.py”, line 372, in handle_async_request\n2025-01-04 15:02:30     with map_httpcore_exceptions():\n2025-01-04 15:02:30          ^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/contextlib.py”, line 158, in exit\n2025-01-04 15:02:30     self.gen.throw(value)\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/httpx/_transports/default.py”, line 86, in map_httpcore_exceptions\n2025-01-04 15:02:30     raise mapped_exc(message) from exc\n2025-01-04 15:02:30 httpx.ConnectError: All connection attempts failed\n2025-01-04 15:02:30\n2025-01-04 15:02:30 During handling of the above exception, another exception occurred:\n2025-01-04 15:02:30\n2025-01-04 15:02:30 Traceback (most recent call last):\n2025-01-04 15:02:30   File “/usr/local/bin/uvicorn”, line 8, in \n2025-01-04 15:02:30     sys.exit(main())\n2025-01-04 15:02:30              ^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/click/core.py”, line 1157, in call\n2025-01-04 15:02:30     return self.main(*args, **kwargs)\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/click/core.py”, line 1078, in main\n2025-01-04 15:02:30     rv = self.invoke(ctx)\n2025-01-04 15:02:30          ^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/click/core.py”, line 1434, in invoke\n2025-01-04 15:02:30     return ctx.invoke(self.callback, **ctx.params)\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/click/core.py”, line 783, in invoke\n2025-01-04 15:02:30     return __callback(*args, **kwargs)\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/uvicorn/main.py”, line 416, in main\n2025-01-04 15:02:30     run(\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/uvicorn/main.py”, line 587, in run\n2025-01-04 15:02:30     server.run()\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/uvicorn/server.py”, line 61, in run\n2025-01-04 15:02:30     return asyncio.run(self.serve(sockets=sockets))\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/asyncio/runners.py”, line 194, in run\n2025-01-04 15:02:30     return runner.run(main)\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/asyncio/runners.py”, line 118, in run\n2025-01-04 15:02:30     return self._loop.run_until_complete(task)\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “uvloop/loop.pyx”, line 1518, in uvloop.loop.Loop.run_until_complete\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/uvicorn/server.py”, line 68, in serve\n2025-01-04 15:02:30     config.load()\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/uvicorn/config.py”, line 467, in load\n2025-01-04 15:02:30     self.loaded_app = import_from_string(self.app)\n2025-01-04 15:02:30                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/uvicorn/importer.py”, line 21, in import_from_string\n2025-01-04 15:02:30     module = importlib.import_module(module_str)\n2025-01-04 15:02:30              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/importlib/init.py”, line 90, in import_module\n2025-01-04 15:02:30     return _bootstrap._gcd_import(name[level:], package, level)\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “”, line 1387, in _gcd_import\n2025-01-04 15:02:30   File “”, line 1360, in _find_and_load\n2025-01-04 15:02:30   File “”, line 1331, in _find_and_load_unlocked\n2025-01-04 15:02:30   File “”, line 935, in _load_unlocked\n2025-01-04 15:02:30   File “”, line 999, in exec_module\n2025-01-04 15:02:30   File “”, line 488, in _call_with_frames_removed\n2025-01-04 15:02:30   File “/PrivatAI-backend/backend.py”, line 63, in \n2025-01-04 15:02:30     client = weaviate.connect_to_local(\n2025-01-04 15:02:30              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/weaviate/connect/helpers.py”, line 210, in connect_to_local\n2025-01-04 15:02:30     return __connect(\n2025-01-04 15:02:30            ^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/weaviate/connect/helpers.py”, line 411, in __connect\n2025-01-04 15:02:30     raise e\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/weaviate/connect/helpers.py”, line 407, in __connect\n2025-01-04 15:02:30     client.connect()\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/weaviate/syncify.py”, line 23, in sync_method\n2025-01-04 15:02:30     return _EventLoopSingleton.get_instance().run_until_complete(\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/weaviate/event_loop.py”, line 42, in run_until_complete\n2025-01-04 15:02:30     return fut.result()\n2025-01-04 15:02:30            ^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/concurrent/futures/_base.py”, line 456, in result\n2025-01-04 15:02:30     return self.__get_result()\n2025-01-04 15:02:30            ^^^^^^^^^^^^^^^^^^^\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/concurrent/futures/_base.py”, line 401, in __get_result\n2025-01-04 15:02:30     raise self._exception\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/weaviate/client_base.py”, line 153, in connect\n2025-01-04 15:02:30     await self._connection.connect(self._skip_init_checks)\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/weaviate/connect/v4.py”, line 154, in connect\n2025-01-04 15:02:30     await self._open_connections_rest(self._auth, skip_init_checks)\n2025-01-04 15:02:30   File “/usr/local/lib/python3.12/site-packages/weaviate/connect/v4.py”, line 266, in _open_connections_rest\n2025-01-04 15:02:30     raise WeaviateConnectionError(\n2025-01-04 15:02:30 weaviate.exceptions.WeaviateConnectionError: Connection to Weaviate failed. Details: Error: All connection attempts failed.\n2025-01-04 15:02:30 Is Weaviate running and reachable at http://127.0.0.1:8080?\n\nWeaviate Server Version:\nDeployment Method: connect to local>\nMulti Node? Number of Running Nodes:\nClient Language and Version: I am using Python Client v4\n\nAny additional Information\nI tried it both as conatinerized code on my local machine using Docker desktop also on AWS EC2 instance running this docker containers using the Public IPs as host. Note: When i try to directly connect to wevaite using  http://host:port-- i always see the reponse, so i know that the port 8080 is open an accessible\nCan you please help me as soon as possible… I am stuck on this from past two days and find no way to solve this.\nThanks\nRegards\nRishav\n\n----------\n\n[DudaNogueira (2025-01-06T18:09:06.199Z)]: hi @Rishav_Kumar_Paramha\nWelcome to our community \nFrom what you are describing, indeed Weaviate should be available.\nAre you running the python code from your computer, or from within a second container?\nFeel free to reach out to me in our public slack so I can take a closer look. By experience, this kind of issues are better solved with a quick screen sharing session.\nThanks!",
    "date_created": "2025-01-06T14:34:02.089Z",
    "has_accepted_answer": false,
    "title": "Can't connect to Weviate Client in using helper function in Container",
    "topic_id": 9581
  },
  {
    "user_id": 397,
    "conversation": "[asido (2024-09-24T08:42:54.544Z)]: Description\nYesterday I created a second WCD cluster on the latest version of 1.26.4.\nMy first cluster was running 1.25.7 so I started the process of upgrading it. I upgraded it to 1.25.17 but I seem to no longer be able to upgrade it any further.\nI used the upgrade button in the cloud console for the first upgrade. The button no longer appears for me to upgrade any further.\nHow can I upgrade my first cluster to match the version of the new one (1.26.4)?\n\n----------\n\n[Mohamed_Shahin (2024-09-24T09:15:09.513Z)]: Hello @asido,\nHow are you? I hope you having amazing week! \nWe do not have 1.26 in the Cloud just yet. We are currently testing some parts before pushing the upgrade path from 1.25 to 1.26 in production.\nHowever, any newly created clusters are already landing on version 1.26.\nThe upgrade paths for existing clusters are coming either this week or next, depending on whether there are any blockers. Once it is available, the upgrade button will appear as usual.\nAlso, if you’re a subscribed customer or using our cloud service (not self-hosted), you can always reach out to us by opening a ticket at support@weaviate.io. This service is available for all our cloud customers .\n\n----------\n\n[asido (2024-09-24T14:09:22.271Z)]: Thanks for the prompt response. That sounds great, thanks for the update. I’ll open a ticket next time",
    "date_created": "2024-09-24T08:42:54.496Z",
    "has_accepted_answer": true,
    "title": "Unable to upgrade WCD db",
    "topic_id": 4270
  }
]
